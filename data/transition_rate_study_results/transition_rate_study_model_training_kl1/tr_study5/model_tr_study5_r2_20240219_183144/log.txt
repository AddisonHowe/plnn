Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r2', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4151350064

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.604358791403612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.604358791403612 | validation: 11.359927849728477]
	TIME [epoch: 54.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.973540698783083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.973540698783083 | validation: 11.60456570389204]
	TIME [epoch: 9.58 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.74767451065178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.74767451065178 | validation: 10.417374516194146]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.954536387255384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.954536387255384 | validation: 10.229874710658432]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.443705059287169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.443705059287169 | validation: 10.53578330069785]
	TIME [epoch: 9.55 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.179940931398908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.179940931398908 | validation: 9.430501995425344]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.234096391067265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.234096391067265 | validation: 9.096988575070384]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.523316925778756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.523316925778756 | validation: 9.374513201622605]
	TIME [epoch: 9.54 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.533510437013666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.533510437013666 | validation: 8.04370677513668]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.174549138279152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.174549138279152 | validation: 8.061685657949676]
	TIME [epoch: 9.54 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.081220855681355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.081220855681355 | validation: 8.109206346215272]
	TIME [epoch: 9.53 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.014839089579784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.014839089579784 | validation: 11.245222773247038]
	TIME [epoch: 9.55 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.493406509574529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.493406509574529 | validation: 9.202061205708182]
	TIME [epoch: 9.54 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.139175996809216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.139175996809216 | validation: 8.39554633461992]
	TIME [epoch: 9.53 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.7247484535634765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.7247484535634765 | validation: 7.50030418465055]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.159729436356145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.159729436356145 | validation: 7.309489238818607]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.124369882995869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.124369882995869 | validation: 7.080613148808229]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.935908720830537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.935908720830537 | validation: 6.847015171216281]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.843827416369017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.843827416369017 | validation: 7.290587663711488]
	TIME [epoch: 9.56 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.740351123440902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.740351123440902 | validation: 6.625550100199803]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.527221757436848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.527221757436848 | validation: 6.27018853035712]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.641756246528604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.641756246528604 | validation: 6.351875646486389]
	TIME [epoch: 9.56 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.377441817936829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.377441817936829 | validation: 6.235612067510843]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.276052324532343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.276052324532343 | validation: 6.599411407094075]
	TIME [epoch: 9.54 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.539663152177523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.539663152177523 | validation: 5.861745774080231]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.015526506226971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.015526506226971 | validation: 5.779586539183145]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.86830668372138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.86830668372138 | validation: 6.386737884077088]
	TIME [epoch: 9.53 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.044816519668183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.044816519668183 | validation: 5.697678234142911]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.905066635583258		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.905066635583258 | validation: 5.989635609837164]
	TIME [epoch: 9.54 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.25654498554724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.25654498554724 | validation: 5.571798376925641]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.031121025294475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.031121025294475 | validation: 6.299614780554905]
	TIME [epoch: 9.52 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.272479130664413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.272479130664413 | validation: 5.624967166846493]
	TIME [epoch: 9.53 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.129165277457427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.129165277457427 | validation: 5.591848361744505]
	TIME [epoch: 9.55 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.77708208548534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.77708208548534 | validation: 5.908287903770758]
	TIME [epoch: 9.54 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.827724055413073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.827724055413073 | validation: 5.774416308991548]
	TIME [epoch: 9.53 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.000872536955439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.000872536955439 | validation: 5.87383314605248]
	TIME [epoch: 9.53 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.9845779935634855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9845779935634855 | validation: 5.714039998951115]
	TIME [epoch: 9.55 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.952485930084177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.952485930084177 | validation: 5.574941925325634]
	TIME [epoch: 9.52 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.295904741151328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.295904741151328 | validation: 5.770089875253311]
	TIME [epoch: 9.52 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.894287134001972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.894287134001972 | validation: 5.721246453790382]
	TIME [epoch: 9.54 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.966112135270626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.966112135270626 | validation: 5.802320895147675]
	TIME [epoch: 9.54 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.740390480869418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.740390480869418 | validation: 5.427110822576799]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.506146044277882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.506146044277882 | validation: 6.069347445863037]
	TIME [epoch: 9.53 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.841042627308044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.841042627308044 | validation: 5.578636364324539]
	TIME [epoch: 9.53 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.786701780908423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.786701780908423 | validation: 5.738535690721699]
	TIME [epoch: 9.52 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.840839321003562		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.840839321003562 | validation: 5.47059313082777]
	TIME [epoch: 9.52 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.78017489137982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.78017489137982 | validation: 5.771669110749167]
	TIME [epoch: 9.52 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.050017142219753		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.050017142219753 | validation: 5.844843409720709]
	TIME [epoch: 9.54 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.987696820551002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.987696820551002 | validation: 5.449804965415602]
	TIME [epoch: 9.52 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.770185068209217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.770185068209217 | validation: 5.730314940191886]
	TIME [epoch: 9.52 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.855331143419596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.855331143419596 | validation: 5.84322060275739]
	TIME [epoch: 9.53 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.837275489839891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.837275489839891 | validation: 5.678841124872846]
	TIME [epoch: 9.53 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.746535425637145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.746535425637145 | validation: 5.402820065234411]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.6134724497737025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6134724497737025 | validation: 5.601129730966697]
	TIME [epoch: 9.53 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.653948577708088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.653948577708088 | validation: 6.028352746013801]
	TIME [epoch: 9.53 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.666730194526914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.666730194526914 | validation: 5.448372773324771]
	TIME [epoch: 9.53 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.400411352363973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.400411352363973 | validation: 5.453487799468835]
	TIME [epoch: 9.51 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.324691951831312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.324691951831312 | validation: 5.382194330958254]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.703914717735843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.703914717735843 | validation: 5.486913680748662]
	TIME [epoch: 9.55 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.627992900941409		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.627992900941409 | validation: 5.519606838219643]
	TIME [epoch: 9.51 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.397963550048696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.397963550048696 | validation: 5.398826660676446]
	TIME [epoch: 9.52 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.494762734146681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.494762734146681 | validation: 5.587905878126905]
	TIME [epoch: 9.54 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.526601445510212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.526601445510212 | validation: 5.340670684584349]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5426790012166975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5426790012166975 | validation: 5.392258359125858]
	TIME [epoch: 9.51 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.459947107554023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.459947107554023 | validation: 5.559824519756394]
	TIME [epoch: 9.51 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.50680610112576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.50680610112576 | validation: 5.772253255830826]
	TIME [epoch: 9.53 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.561563562974283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.561563562974283 | validation: 7.71853176732183]
	TIME [epoch: 9.51 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.366298104135339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.366298104135339 | validation: 5.0149395255692255]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.326664417545736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.326664417545736 | validation: 5.151120593693925]
	TIME [epoch: 9.53 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.735283815651812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.735283815651812 | validation: 7.023197255019703]
	TIME [epoch: 9.53 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.899782307861651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.899782307861651 | validation: 5.256814222328824]
	TIME [epoch: 9.52 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.169379946621647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.169379946621647 | validation: 5.212142675872431]
	TIME [epoch: 9.52 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.391052932423529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.391052932423529 | validation: 5.557097008026147]
	TIME [epoch: 9.54 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.285945711013331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.285945711013331 | validation: 5.421819236663997]
	TIME [epoch: 9.52 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.357232173272704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.357232173272704 | validation: 5.569869781651992]
	TIME [epoch: 9.52 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.6567261889656315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6567261889656315 | validation: 5.339963693662578]
	TIME [epoch: 9.52 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.2652479057982635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2652479057982635 | validation: 4.910275065461538]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.136763380474331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.136763380474331 | validation: 4.978455251324572]
	TIME [epoch: 9.52 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.910744899892224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.910744899892224 | validation: 5.088114242809852]
	TIME [epoch: 9.51 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.905629082264033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.905629082264033 | validation: 4.704995797530483]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.009752881746428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.009752881746428 | validation: 6.26553010358618]
	TIME [epoch: 9.53 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.3909848089668815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3909848089668815 | validation: 5.035403388628045]
	TIME [epoch: 9.51 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.602197414279331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.602197414279331 | validation: 5.065007583536963]
	TIME [epoch: 9.51 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.4643486661719844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4643486661719844 | validation: 4.685336610374078]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.715030512005807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.715030512005807 | validation: 4.737307395207514]
	TIME [epoch: 9.53 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.10325611706612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.10325611706612 | validation: 5.778726682736996]
	TIME [epoch: 9.51 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.273775646035844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.273775646035844 | validation: 5.2874831807708995]
	TIME [epoch: 9.51 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.451745404689593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.451745404689593 | validation: 5.786578873401363]
	TIME [epoch: 9.53 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.83933953348828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.83933953348828 | validation: 4.764788458600134]
	TIME [epoch: 9.52 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.870850757301671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.870850757301671 | validation: 4.474243311596844]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.671819372265427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.671819372265427 | validation: 5.1110222501039795]
	TIME [epoch: 9.55 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.19702689112462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.19702689112462 | validation: 4.4387034721953995]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.575041814523183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.575041814523183 | validation: 4.555747398322309]
	TIME [epoch: 9.53 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.522200317866682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.522200317866682 | validation: 4.204890161093827]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.400540945440992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.400540945440992 | validation: 4.256619543799123]
	TIME [epoch: 9.54 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.078513443292088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.078513443292088 | validation: 4.49570465741309]
	TIME [epoch: 9.53 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.28812587536842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.28812587536842 | validation: 3.93424324743414]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.208996471425981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.208996471425981 | validation: 4.207931131334368]
	TIME [epoch: 9.53 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.111209781011001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.111209781011001 | validation: 4.101448535746797]
	TIME [epoch: 9.53 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.593646413709115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.593646413709115 | validation: 6.988281022928564]
	TIME [epoch: 9.52 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.256199149755706		[learning rate: 0.0099806]
	Learning Rate: 0.00998063
	LOSS [training: 7.256199149755706 | validation: 5.224705868781675]
	TIME [epoch: 9.52 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.677121222474137		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 4.677121222474137 | validation: 4.161536954706956]
	TIME [epoch: 9.53 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.261203281966391		[learning rate: 0.0099324]
	Learning Rate: 0.00993236
	LOSS [training: 4.261203281966391 | validation: 4.051671764682062]
	TIME [epoch: 9.53 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.113073687972455		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 4.113073687972455 | validation: 4.255707363923237]
	TIME [epoch: 9.52 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3289961789569364		[learning rate: 0.0098843]
	Learning Rate: 0.00988433
	LOSS [training: 4.3289961789569364 | validation: 3.9333498396703637]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.534214920817432		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 4.534214920817432 | validation: 5.387029769067965]
	TIME [epoch: 9.54 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.370916316366008		[learning rate: 0.0098365]
	Learning Rate: 0.00983653
	LOSS [training: 4.370916316366008 | validation: 3.8528261960234578]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.630955623751466		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 3.630955623751466 | validation: 3.7622688162246254]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.426034859068287		[learning rate: 0.009789]
	Learning Rate: 0.00978897
	LOSS [training: 3.426034859068287 | validation: 3.1936801231628493]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.265806449448623		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 3.265806449448623 | validation: 3.1177399181960332]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.098427846957728		[learning rate: 0.0097416]
	Learning Rate: 0.00974163
	LOSS [training: 5.098427846957728 | validation: 6.609723164646475]
	TIME [epoch: 9.52 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.720408830411742		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 4.720408830411742 | validation: 3.633450527924139]
	TIME [epoch: 9.51 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6154294933082816		[learning rate: 0.0096945]
	Learning Rate: 0.00969452
	LOSS [training: 3.6154294933082816 | validation: 3.2109238774278084]
	TIME [epoch: 9.54 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6030466152367993		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 3.6030466152367993 | validation: 3.787604295744011]
	TIME [epoch: 9.52 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.464150599790746		[learning rate: 0.0096476]
	Learning Rate: 0.00964764
	LOSS [training: 3.464150599790746 | validation: 3.310574688841399]
	TIME [epoch: 9.52 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.360771530992641		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 3.360771530992641 | validation: 3.1334565286543326]
	TIME [epoch: 9.53 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3391256494261805		[learning rate: 0.009601]
	Learning Rate: 0.00960098
	LOSS [training: 3.3391256494261805 | validation: 3.300861772832343]
	TIME [epoch: 9.53 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2117329761612035		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 3.2117329761612035 | validation: 2.815554691436331]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2424848413506453		[learning rate: 0.0095546]
	Learning Rate: 0.00955456
	LOSS [training: 3.2424848413506453 | validation: 3.338995406108756]
	TIME [epoch: 9.51 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.773050195151029		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 3.773050195151029 | validation: 3.671597855765068]
	TIME [epoch: 9.52 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.964203135824989		[learning rate: 0.0095084]
	Learning Rate: 0.00950835
	LOSS [training: 2.964203135824989 | validation: 2.829625529161518]
	TIME [epoch: 9.52 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.76067596615601		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 2.76067596615601 | validation: 2.5495113186852327]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.972209115314822		[learning rate: 0.0094624]
	Learning Rate: 0.00946237
	LOSS [training: 2.972209115314822 | validation: 2.7975275231008414]
	TIME [epoch: 9.52 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.954132479572917		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 2.954132479572917 | validation: 3.485172344354645]
	TIME [epoch: 9.54 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9666952061940037		[learning rate: 0.0094166]
	Learning Rate: 0.00941661
	LOSS [training: 2.9666952061940037 | validation: 2.7810148535348125]
	TIME [epoch: 9.52 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5707436390716563		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 2.5707436390716563 | validation: 3.049703493551832]
	TIME [epoch: 9.52 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.818681009430123		[learning rate: 0.0093711]
	Learning Rate: 0.00937108
	LOSS [training: 2.818681009430123 | validation: 3.9254641328743096]
	TIME [epoch: 9.53 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.285632938990344		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 3.285632938990344 | validation: 2.6528102046822553]
	TIME [epoch: 9.54 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5448465640453266		[learning rate: 0.0093258]
	Learning Rate: 0.00932576
	LOSS [training: 2.5448465640453266 | validation: 3.2918780572567727]
	TIME [epoch: 9.52 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.482097101511074		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 2.482097101511074 | validation: 2.231868128289565]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_130.pth
	Model improved!!!
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3828364547701715		[learning rate: 0.0092807]
	Learning Rate: 0.00928066
	LOSS [training: 2.3828364547701715 | validation: 2.1289242686749477]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_131.pth
	Model improved!!!
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.17737248018359		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 2.17737248018359 | validation: 2.0798130331936524]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1407762534621946		[learning rate: 0.0092358]
	Learning Rate: 0.00923578
	LOSS [training: 2.1407762534621946 | validation: 2.2026010739516826]
	TIME [epoch: 9.52 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1372986849912357		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 2.1372986849912357 | validation: 2.8668209468004195]
	TIME [epoch: 9.54 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3004850583956262		[learning rate: 0.0091911]
	Learning Rate: 0.00919112
	LOSS [training: 2.3004850583956262 | validation: 2.6721317816065744]
	TIME [epoch: 9.53 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.305984457728905		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 2.305984457728905 | validation: 2.5553514670435122]
	TIME [epoch: 9.52 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.040612489235207		[learning rate: 0.0091467]
	Learning Rate: 0.00914667
	LOSS [training: 2.040612489235207 | validation: 2.346431360383011]
	TIME [epoch: 9.51 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4233980579756262		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 2.4233980579756262 | validation: 3.082755881584674]
	TIME [epoch: 9.53 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.72222429586992		[learning rate: 0.0091024]
	Learning Rate: 0.00910244
	LOSS [training: 2.72222429586992 | validation: 2.128187934971659]
	TIME [epoch: 9.51 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1678796090000185		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 2.1678796090000185 | validation: 2.1204287093304215]
	TIME [epoch: 9.52 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.217632361384547		[learning rate: 0.0090584]
	Learning Rate: 0.00905842
	LOSS [training: 2.217632361384547 | validation: 1.9196166074317436]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_141.pth
	Model improved!!!
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.247632836678801		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 2.247632836678801 | validation: 2.0126225195287986]
	TIME [epoch: 9.53 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.215463729746012		[learning rate: 0.0090146]
	Learning Rate: 0.00901462
	LOSS [training: 2.215463729746012 | validation: 2.039220251126599]
	TIME [epoch: 9.52 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9621068848788734		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 1.9621068848788734 | validation: 1.6995726491530456]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9915396648319532		[learning rate: 0.008971]
	Learning Rate: 0.00897103
	LOSS [training: 1.9915396648319532 | validation: 1.8124782699969149]
	TIME [epoch: 9.53 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7950263172550787		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 1.7950263172550787 | validation: 1.7020702066854654]
	TIME [epoch: 9.52 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.239640221904666		[learning rate: 0.0089276]
	Learning Rate: 0.00892764
	LOSS [training: 2.239640221904666 | validation: 3.3505746001778194]
	TIME [epoch: 9.51 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1161858432594527		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 2.1161858432594527 | validation: 1.891429310250869]
	TIME [epoch: 9.51 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7581002169996023		[learning rate: 0.0088845]
	Learning Rate: 0.00888447
	LOSS [training: 1.7581002169996023 | validation: 1.8531379741558929]
	TIME [epoch: 9.53 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.726712618124645		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 1.726712618124645 | validation: 2.574471329882714]
	TIME [epoch: 9.51 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.51725224486279		[learning rate: 0.0088415]
	Learning Rate: 0.00884151
	LOSS [training: 2.51725224486279 | validation: 1.6408369529041396]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8118096470916067		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 1.8118096470916067 | validation: 1.5414872457289626]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.277186347860497		[learning rate: 0.0087988]
	Learning Rate: 0.00879875
	LOSS [training: 2.277186347860497 | validation: 1.708314129146676]
	TIME [epoch: 9.54 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.603078776271588		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 1.603078776271588 | validation: 1.401006410608838]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.691010380941633		[learning rate: 0.0087562]
	Learning Rate: 0.0087562
	LOSS [training: 1.691010380941633 | validation: 1.56258015926417]
	TIME [epoch: 9.53 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6049402709063691		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 1.6049402709063691 | validation: 3.6520855016072566]
	TIME [epoch: 9.53 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.235748337712392		[learning rate: 0.0087139]
	Learning Rate: 0.00871386
	LOSS [training: 2.235748337712392 | validation: 2.50970684733417]
	TIME [epoch: 9.52 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7426885698795989		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 1.7426885698795989 | validation: 1.6568243963735165]
	TIME [epoch: 9.51 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.767082132701868		[learning rate: 0.0086717]
	Learning Rate: 0.00867172
	LOSS [training: 1.767082132701868 | validation: 1.5637336652981797]
	TIME [epoch: 9.51 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5187170204586953		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 1.5187170204586953 | validation: 1.3630351599146144]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8564041256494916		[learning rate: 0.0086298]
	Learning Rate: 0.00862979
	LOSS [training: 1.8564041256494916 | validation: 1.7199544351065565]
	TIME [epoch: 9.52 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.59616026838717		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 1.59616026838717 | validation: 1.3161137224821784]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_162.pth
	Model improved!!!
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5596568210574984		[learning rate: 0.0085881]
	Learning Rate: 0.00858805
	LOSS [training: 1.5596568210574984 | validation: 1.94410295173901]
	TIME [epoch: 9.54 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9657395470166095		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 1.9657395470166095 | validation: 1.960022400952944]
	TIME [epoch: 9.54 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7464534231629323		[learning rate: 0.0085465]
	Learning Rate: 0.00854652
	LOSS [training: 1.7464534231629323 | validation: 1.6806776784477486]
	TIME [epoch: 9.53 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.49235634507673		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.49235634507673 | validation: 1.7324386280516348]
	TIME [epoch: 9.53 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4693959955706317		[learning rate: 0.0085052]
	Learning Rate: 0.00850519
	LOSS [training: 1.4693959955706317 | validation: 1.2736170385709595]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_167.pth
	Model improved!!!
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3954293006636718		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.3954293006636718 | validation: 1.9461058320638296]
	TIME [epoch: 9.52 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.532960593019896		[learning rate: 0.0084641]
	Learning Rate: 0.00846406
	LOSS [training: 1.532960593019896 | validation: 1.4879178225143563]
	TIME [epoch: 9.51 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2959925285477132		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 1.2959925285477132 | validation: 1.3937779914158848]
	TIME [epoch: 9.53 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.322689429925731		[learning rate: 0.0084231]
	Learning Rate: 0.00842313
	LOSS [training: 1.322689429925731 | validation: 1.5386049895440579]
	TIME [epoch: 9.55 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4621052097433875		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 1.4621052097433875 | validation: 1.794105837798104]
	TIME [epoch: 9.53 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.60278248242676		[learning rate: 0.0083824]
	Learning Rate: 0.0083824
	LOSS [training: 1.60278248242676 | validation: 1.4208154434262725]
	TIME [epoch: 9.52 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4167661285464863		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.4167661285464863 | validation: 1.5585760151308452]
	TIME [epoch: 9.54 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.493232126310185		[learning rate: 0.0083419]
	Learning Rate: 0.00834186
	LOSS [training: 1.493232126310185 | validation: 1.338551690602429]
	TIME [epoch: 9.53 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2766487054746811		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.2766487054746811 | validation: 1.5738022716290405]
	TIME [epoch: 9.52 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4782080926781025		[learning rate: 0.0083015]
	Learning Rate: 0.00830153
	LOSS [training: 1.4782080926781025 | validation: 1.2630937908689739]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.283010900756572		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.283010900756572 | validation: 1.0055876880983141]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2483283961257015		[learning rate: 0.0082614]
	Learning Rate: 0.00826138
	LOSS [training: 1.2483283961257015 | validation: 1.646910404510429]
	TIME [epoch: 9.52 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5105650067618965		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.5105650067618965 | validation: 1.7782963698042613]
	TIME [epoch: 9.51 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4453793559174941		[learning rate: 0.0082214]
	Learning Rate: 0.00822143
	LOSS [training: 1.4453793559174941 | validation: 2.1473739995927947]
	TIME [epoch: 9.52 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.593276925853146		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.593276925853146 | validation: 1.2606001248496588]
	TIME [epoch: 9.53 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5752052795222493		[learning rate: 0.0081817]
	Learning Rate: 0.00818167
	LOSS [training: 1.5752052795222493 | validation: 1.5763295940039217]
	TIME [epoch: 9.52 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4902116002206807		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 1.4902116002206807 | validation: 1.34575473059126]
	TIME [epoch: 9.51 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4283988084367618		[learning rate: 0.0081421]
	Learning Rate: 0.00814211
	LOSS [training: 1.4283988084367618 | validation: 1.4482419124865633]
	TIME [epoch: 9.53 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4971571400490962		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.4971571400490962 | validation: 1.3558677981440987]
	TIME [epoch: 9.51 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.336396948921519		[learning rate: 0.0081027]
	Learning Rate: 0.00810273
	LOSS [training: 1.336396948921519 | validation: 1.3150208993552515]
	TIME [epoch: 9.52 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3108003412907234		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.3108003412907234 | validation: 0.9531748939589679]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2093233028910126		[learning rate: 0.0080636]
	Learning Rate: 0.00806355
	LOSS [training: 1.2093233028910126 | validation: 1.2511964309898083]
	TIME [epoch: 9.54 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5578074298447262		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.5578074298447262 | validation: 1.3841315484736645]
	TIME [epoch: 9.51 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2076112936250585		[learning rate: 0.0080246]
	Learning Rate: 0.00802456
	LOSS [training: 1.2076112936250585 | validation: 1.1923924403046906]
	TIME [epoch: 9.51 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.32887888832818		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 1.32887888832818 | validation: 1.60727713639961]
	TIME [epoch: 9.52 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2549346994359725		[learning rate: 0.0079858]
	Learning Rate: 0.00798575
	LOSS [training: 1.2549346994359725 | validation: 1.2458126606155475]
	TIME [epoch: 9.53 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3255132365811177		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 1.3255132365811177 | validation: 0.8609958837115103]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4485376192446815		[learning rate: 0.0079471]
	Learning Rate: 0.00794713
	LOSS [training: 1.4485376192446815 | validation: 1.3349899522340198]
	TIME [epoch: 9.52 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.233484298443195		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.233484298443195 | validation: 1.0861390800752668]
	TIME [epoch: 9.53 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1104723189746326		[learning rate: 0.0079087]
	Learning Rate: 0.0079087
	LOSS [training: 1.1104723189746326 | validation: 1.7631975343085384]
	TIME [epoch: 9.53 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6676360385896127		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.6676360385896127 | validation: 1.0111500069299741]
	TIME [epoch: 9.52 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2823369921622425		[learning rate: 0.0078705]
	Learning Rate: 0.00787046
	LOSS [training: 1.2823369921622425 | validation: 0.9658246777938502]
	TIME [epoch: 9.52 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3717311256226778		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.3717311256226778 | validation: 1.9123614536697984]
	TIME [epoch: 9.53 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2639011949814631		[learning rate: 0.0078324]
	Learning Rate: 0.0078324
	LOSS [training: 1.2639011949814631 | validation: 1.3505666952408106]
	TIME [epoch: 9.52 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2651494187776147		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.2651494187776147 | validation: 1.3007647931779993]
	TIME [epoch: 9.52 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3198585296805114		[learning rate: 0.0077945]
	Learning Rate: 0.00779452
	LOSS [training: 1.3198585296805114 | validation: 1.4899268817307343]
	TIME [epoch: 9.53 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3416604641201204		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.3416604641201204 | validation: 1.160093507750307]
	TIME [epoch: 9.51 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2620363574112212		[learning rate: 0.0077568]
	Learning Rate: 0.00775683
	LOSS [training: 1.2620363574112212 | validation: 1.083826097010564]
	TIME [epoch: 9.51 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2433870251468424		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.2433870251468424 | validation: 1.458121573841012]
	TIME [epoch: 9.5 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.518441985921684		[learning rate: 0.0077193]
	Learning Rate: 0.00771932
	LOSS [training: 1.518441985921684 | validation: 1.2600074547597782]
	TIME [epoch: 9.53 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2494143780774352		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.2494143780774352 | validation: 1.6738783308341696]
	TIME [epoch: 9.51 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2886007118194631		[learning rate: 0.007682]
	Learning Rate: 0.00768199
	LOSS [training: 1.2886007118194631 | validation: 1.3105424846611748]
	TIME [epoch: 9.51 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2876160600788287		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.2876160600788287 | validation: 0.9464457014610858]
	TIME [epoch: 9.52 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3640995182465818		[learning rate: 0.0076448]
	Learning Rate: 0.00764484
	LOSS [training: 1.3640995182465818 | validation: 1.446784227125232]
	TIME [epoch: 9.54 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3622069962340366		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.3622069962340366 | validation: 0.9996883658344305]
	TIME [epoch: 9.52 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.472920513515336		[learning rate: 0.0076079]
	Learning Rate: 0.00760787
	LOSS [training: 1.472920513515336 | validation: 1.911661045209346]
	TIME [epoch: 9.52 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5180386858408055		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.5180386858408055 | validation: 1.3244495358826347]
	TIME [epoch: 9.53 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2673119871877945		[learning rate: 0.0075711]
	Learning Rate: 0.00757108
	LOSS [training: 1.2673119871877945 | validation: 1.5357229915752149]
	TIME [epoch: 9.53 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2701056236078507		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.2701056236078507 | validation: 1.1784042021002805]
	TIME [epoch: 9.52 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.318338646632355		[learning rate: 0.0075345]
	Learning Rate: 0.00753447
	LOSS [training: 1.318338646632355 | validation: 1.1357002184172293]
	TIME [epoch: 9.51 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3958800541304348		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.3958800541304348 | validation: 1.2440890485977303]
	TIME [epoch: 9.54 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1436502837979612		[learning rate: 0.007498]
	Learning Rate: 0.00749803
	LOSS [training: 1.1436502837979612 | validation: 2.240736294232948]
	TIME [epoch: 9.53 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.366416281231483		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.366416281231483 | validation: 1.014126743747975]
	TIME [epoch: 9.52 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0223779176156804		[learning rate: 0.0074618]
	Learning Rate: 0.00746177
	LOSS [training: 1.0223779176156804 | validation: 0.9941232276963274]
	TIME [epoch: 9.52 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0079686188104522		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.0079686188104522 | validation: 1.7585395416554732]
	TIME [epoch: 9.54 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2864771104379762		[learning rate: 0.0074257]
	Learning Rate: 0.00742569
	LOSS [training: 1.2864771104379762 | validation: 1.4742161383462236]
	TIME [epoch: 9.52 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1809714961320847		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.1809714961320847 | validation: 1.1197465128694584]
	TIME [epoch: 9.52 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4954932760850164		[learning rate: 0.0073898]
	Learning Rate: 0.00738978
	LOSS [training: 1.4954932760850164 | validation: 1.6445255882093468]
	TIME [epoch: 9.53 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9630124124661374		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 1.9630124124661374 | validation: 1.0046402057387736]
	TIME [epoch: 9.53 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0028829047941925		[learning rate: 0.007354]
	Learning Rate: 0.00735405
	LOSS [training: 1.0028829047941925 | validation: 1.1671270150685533]
	TIME [epoch: 9.52 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0454289873988525		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.0454289873988525 | validation: 1.0994128871711246]
	TIME [epoch: 9.52 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0212790939881198		[learning rate: 0.0073185]
	Learning Rate: 0.00731848
	LOSS [training: 1.0212790939881198 | validation: 1.4079799081839142]
	TIME [epoch: 9.53 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1299926615538718		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.1299926615538718 | validation: 0.9778868891478214]
	TIME [epoch: 9.52 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9848113125662683		[learning rate: 0.0072831]
	Learning Rate: 0.00728309
	LOSS [training: 0.9848113125662683 | validation: 1.1328105426083457]
	TIME [epoch: 9.52 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0247261897811777		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.0247261897811777 | validation: 0.9196727585828662]
	TIME [epoch: 9.52 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9588074186376069		[learning rate: 0.0072479]
	Learning Rate: 0.00724787
	LOSS [training: 0.9588074186376069 | validation: 2.2242940856479403]
	TIME [epoch: 9.54 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4122992782609622		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.4122992782609622 | validation: 1.1122819713106673]
	TIME [epoch: 9.53 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1446791391290234		[learning rate: 0.0072128]
	Learning Rate: 0.00721282
	LOSS [training: 1.1446791391290234 | validation: 1.0229504085720396]
	TIME [epoch: 9.53 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0459082077598656		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.0459082077598656 | validation: 1.501414764098443]
	TIME [epoch: 9.52 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1807654169164898		[learning rate: 0.0071779]
	Learning Rate: 0.00717794
	LOSS [training: 1.1807654169164898 | validation: 1.3299775945196235]
	TIME [epoch: 9.53 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1783546287565283		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.1783546287565283 | validation: 1.5324133454444735]
	TIME [epoch: 9.51 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.222318110052019		[learning rate: 0.0071432]
	Learning Rate: 0.00714323
	LOSS [training: 1.222318110052019 | validation: 0.7706946336382923]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1822164903116301		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.1822164903116301 | validation: 1.00401453618801]
	TIME [epoch: 9.53 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0119011281542867		[learning rate: 0.0071087]
	Learning Rate: 0.00710869
	LOSS [training: 1.0119011281542867 | validation: 1.0368442457095821]
	TIME [epoch: 9.52 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.146981746297149		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.146981746297149 | validation: 1.3086109525514564]
	TIME [epoch: 9.51 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1109055370654046		[learning rate: 0.0070743]
	Learning Rate: 0.00707431
	LOSS [training: 1.1109055370654046 | validation: 1.646667155825676]
	TIME [epoch: 9.52 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2599279022059142		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.2599279022059142 | validation: 1.1395678794099668]
	TIME [epoch: 9.54 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2018386825448313		[learning rate: 0.0070401]
	Learning Rate: 0.0070401
	LOSS [training: 1.2018386825448313 | validation: 0.8089306783202815]
	TIME [epoch: 9.51 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0670222245725518		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.0670222245725518 | validation: 0.9058819115798649]
	TIME [epoch: 9.52 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.057184417220236		[learning rate: 0.0070061]
	Learning Rate: 0.00700606
	LOSS [training: 1.057184417220236 | validation: 1.14003636883242]
	TIME [epoch: 9.53 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0827283978717435		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.0827283978717435 | validation: 1.065443828271343]
	TIME [epoch: 9.51 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0186380600076475		[learning rate: 0.0069722]
	Learning Rate: 0.00697218
	LOSS [training: 1.0186380600076475 | validation: 0.9353720383762034]
	TIME [epoch: 9.51 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1212584280828413		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.1212584280828413 | validation: 1.2497170307394248]
	TIME [epoch: 9.51 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8725138910535273		[learning rate: 0.0069385]
	Learning Rate: 0.00693846
	LOSS [training: 0.8725138910535273 | validation: 0.8297678742664915]
	TIME [epoch: 9.53 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0178331701494827		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.0178331701494827 | validation: 1.2347935258337217]
	TIME [epoch: 9.52 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0828545144911612		[learning rate: 0.0069049]
	Learning Rate: 0.00690491
	LOSS [training: 1.0828545144911612 | validation: 1.383836930260786]
	TIME [epoch: 9.53 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.052951685584208		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.052951685584208 | validation: 1.0925410410658183]
	TIME [epoch: 9.51 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0884080669822036		[learning rate: 0.0068715]
	Learning Rate: 0.00687152
	LOSS [training: 1.0884080669822036 | validation: 1.4228441901048827]
	TIME [epoch: 9.54 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4099723225753007		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.4099723225753007 | validation: 1.103288470443103]
	TIME [epoch: 9.51 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8866864184366193		[learning rate: 0.0068383]
	Learning Rate: 0.00683829
	LOSS [training: 0.8866864184366193 | validation: 1.140827509490985]
	TIME [epoch: 9.52 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1991606401960568		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.1991606401960568 | validation: 1.2063166603568614]
	TIME [epoch: 9.54 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9334480517473306		[learning rate: 0.0068052]
	Learning Rate: 0.00680522
	LOSS [training: 0.9334480517473306 | validation: 0.8830886153139095]
	TIME [epoch: 9.52 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9504604313359211		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.9504604313359211 | validation: 0.927377759874686]
	TIME [epoch: 9.52 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0216495307230926		[learning rate: 0.0067723]
	Learning Rate: 0.00677231
	LOSS [training: 1.0216495307230926 | validation: 1.0806188974116282]
	TIME [epoch: 9.52 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1987012268055897		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 1.1987012268055897 | validation: 2.1283314073033632]
	TIME [epoch: 9.54 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.250062357256207		[learning rate: 0.0067396]
	Learning Rate: 0.00673956
	LOSS [training: 1.250062357256207 | validation: 1.0447147760599205]
	TIME [epoch: 9.52 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.935745311113814		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.935745311113814 | validation: 1.0471881304380408]
	TIME [epoch: 9.51 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0288926463564674		[learning rate: 0.006707]
	Learning Rate: 0.00670697
	LOSS [training: 1.0288926463564674 | validation: 0.9969700865991513]
	TIME [epoch: 9.52 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.203282307870621		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 1.203282307870621 | validation: 1.2104432745129576]
	TIME [epoch: 9.53 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9303938159500508		[learning rate: 0.0066745]
	Learning Rate: 0.00667454
	LOSS [training: 0.9303938159500508 | validation: 1.0800884885201427]
	TIME [epoch: 9.52 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1302542691681303		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.1302542691681303 | validation: 4.119864963997099]
	TIME [epoch: 9.52 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9103441312179794		[learning rate: 0.0066423]
	Learning Rate: 0.00664226
	LOSS [training: 1.9103441312179794 | validation: 1.0289335555979398]
	TIME [epoch: 9.54 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3559155783830572		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.3559155783830572 | validation: 1.4819384352666498]
	TIME [epoch: 9.52 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1031952197313306		[learning rate: 0.0066101]
	Learning Rate: 0.00661014
	LOSS [training: 1.1031952197313306 | validation: 1.1272045720596797]
	TIME [epoch: 9.53 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.182518985080027		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.182518985080027 | validation: 1.2669203544243326]
	TIME [epoch: 9.52 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0049434010584104		[learning rate: 0.0065782]
	Learning Rate: 0.00657817
	LOSS [training: 1.0049434010584104 | validation: 0.9580504083630111]
	TIME [epoch: 9.54 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8786362175475257		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.8786362175475257 | validation: 0.8546551372285337]
	TIME [epoch: 9.51 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.094184894804234		[learning rate: 0.0065464]
	Learning Rate: 0.00654636
	LOSS [training: 1.094184894804234 | validation: 1.5725245183022498]
	TIME [epoch: 9.53 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4110256656398754		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.4110256656398754 | validation: 0.9442333529711183]
	TIME [epoch: 9.52 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1376218058076382		[learning rate: 0.0065147]
	Learning Rate: 0.0065147
	LOSS [training: 1.1376218058076382 | validation: 0.9595972383784535]
	TIME [epoch: 9.54 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.110835652992867		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 1.110835652992867 | validation: 1.0860697513109092]
	TIME [epoch: 9.51 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9681188081126215		[learning rate: 0.0064832]
	Learning Rate: 0.0064832
	LOSS [training: 0.9681188081126215 | validation: 0.7602221361218108]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_279.pth
	Model improved!!!
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9793798426601352		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.9793798426601352 | validation: 1.296777043128265]
	TIME [epoch: 9.54 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0628982273515069		[learning rate: 0.0064518]
	Learning Rate: 0.00645185
	LOSS [training: 1.0628982273515069 | validation: 1.3231508801641143]
	TIME [epoch: 9.51 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8145677380306651		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.8145677380306651 | validation: 0.6261565183713624]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7589252173124794		[learning rate: 0.0064206]
	Learning Rate: 0.00642065
	LOSS [training: 0.7589252173124794 | validation: 0.9736741491475617]
	TIME [epoch: 9.53 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.265190729758784		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.265190729758784 | validation: 1.125549823705156]
	TIME [epoch: 9.54 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1752913535768519		[learning rate: 0.0063896]
	Learning Rate: 0.0063896
	LOSS [training: 1.1752913535768519 | validation: 0.8754302619750094]
	TIME [epoch: 9.53 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9545479151454351		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.9545479151454351 | validation: 0.9594794746492592]
	TIME [epoch: 9.52 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1219568496319208		[learning rate: 0.0063587]
	Learning Rate: 0.0063587
	LOSS [training: 1.1219568496319208 | validation: 1.0528972875092106]
	TIME [epoch: 9.53 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1336659560405182		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 1.1336659560405182 | validation: 1.0139294551354638]
	TIME [epoch: 9.53 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8209055551905404		[learning rate: 0.006328]
	Learning Rate: 0.00632795
	LOSS [training: 0.8209055551905404 | validation: 0.6029949352888927]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.744788162830884		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.744788162830884 | validation: 0.7288949962554497]
	TIME [epoch: 9.54 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7728890180017058		[learning rate: 0.0062974]
	Learning Rate: 0.00629735
	LOSS [training: 0.7728890180017058 | validation: 0.8915211646913668]
	TIME [epoch: 9.54 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9844163829662369		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.9844163829662369 | validation: 0.5348476869557427]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7556217532997822		[learning rate: 0.0062669]
	Learning Rate: 0.0062669
	LOSS [training: 0.7556217532997822 | validation: 0.8587017565443289]
	TIME [epoch: 9.53 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7346480173859702		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.7346480173859702 | validation: 0.45414844819650924]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_294.pth
	Model improved!!!
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6973489765595146		[learning rate: 0.0062366]
	Learning Rate: 0.00623659
	LOSS [training: 0.6973489765595146 | validation: 0.7276780688671781]
	TIME [epoch: 9.55 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8038900852377798		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.8038900852377798 | validation: 1.114133545886999]
	TIME [epoch: 9.54 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9423528802556399		[learning rate: 0.0062064]
	Learning Rate: 0.00620643
	LOSS [training: 0.9423528802556399 | validation: 0.9071979131858138]
	TIME [epoch: 9.54 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7005806293119162		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.7005806293119162 | validation: 0.7187485457302856]
	TIME [epoch: 9.55 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.622798632129867		[learning rate: 0.0061764]
	Learning Rate: 0.00617642
	LOSS [training: 0.622798632129867 | validation: 0.43042683657090414]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_299.pth
	Model improved!!!
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6119399923238659		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.6119399923238659 | validation: 0.6594777385254235]
	TIME [epoch: 9.52 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7024306492353454		[learning rate: 0.0061466]
	Learning Rate: 0.00614655
	LOSS [training: 0.7024306492353454 | validation: 0.5606657061421786]
	TIME [epoch: 9.52 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7326741643103182		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.7326741643103182 | validation: 1.5433866696434597]
	TIME [epoch: 9.54 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6866561368329318		[learning rate: 0.0061168]
	Learning Rate: 0.00611683
	LOSS [training: 1.6866561368329318 | validation: 2.584628520574775]
	TIME [epoch: 9.52 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6636161907650646		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 1.6636161907650646 | validation: 3.6821069819483268]
	TIME [epoch: 9.52 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.024244959063166		[learning rate: 0.0060872]
	Learning Rate: 0.00608725
	LOSS [training: 2.024244959063166 | validation: 1.2577258161250435]
	TIME [epoch: 9.52 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7329255370729164		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.7329255370729164 | validation: 0.8497807529558855]
	TIME [epoch: 9.54 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0638183040179958		[learning rate: 0.0060578]
	Learning Rate: 0.00605781
	LOSS [training: 1.0638183040179958 | validation: 0.772643150669808]
	TIME [epoch: 9.52 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9039158714236637		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.9039158714236637 | validation: 1.1644816565461822]
	TIME [epoch: 9.52 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.756939757965528		[learning rate: 0.0060285]
	Learning Rate: 0.00602852
	LOSS [training: 0.756939757965528 | validation: 1.4861327536215267]
	TIME [epoch: 9.54 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1811833374983096		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 2.1811833374983096 | validation: 4.158355611682839]
	TIME [epoch: 9.53 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6406247935154936		[learning rate: 0.0059994]
	Learning Rate: 0.00599936
	LOSS [training: 2.6406247935154936 | validation: 3.235151525229726]
	TIME [epoch: 9.51 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.735167264257687		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.735167264257687 | validation: 0.7739056214628599]
	TIME [epoch: 9.51 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7325332778463374		[learning rate: 0.0059704]
	Learning Rate: 0.00597035
	LOSS [training: 0.7325332778463374 | validation: 0.575723079322361]
	TIME [epoch: 9.53 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9182665674699193		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.9182665674699193 | validation: 0.8254119026498072]
	TIME [epoch: 9.51 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6464021205845316		[learning rate: 0.0059415]
	Learning Rate: 0.00594148
	LOSS [training: 0.6464021205845316 | validation: 0.47042704808866775]
	TIME [epoch: 9.51 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6709648001633336		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.6709648001633336 | validation: 0.5640403412992148]
	TIME [epoch: 9.53 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0809749974615257		[learning rate: 0.0059127]
	Learning Rate: 0.00591275
	LOSS [training: 1.0809749974615257 | validation: 1.3725875131670051]
	TIME [epoch: 9.52 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9459072352895639		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.9459072352895639 | validation: 0.6268723902951837]
	TIME [epoch: 9.52 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.709943609708905		[learning rate: 0.0058842]
	Learning Rate: 0.00588416
	LOSS [training: 0.709943609708905 | validation: 0.5574188564908671]
	TIME [epoch: 9.51 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6783660637019067		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.6783660637019067 | validation: 1.4156865652712787]
	TIME [epoch: 9.54 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9479596033147558		[learning rate: 0.0058557]
	Learning Rate: 0.0058557
	LOSS [training: 0.9479596033147558 | validation: 0.4745389410555737]
	TIME [epoch: 9.52 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6658681595505405		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.6658681595505405 | validation: 0.7146163096101887]
	TIME [epoch: 9.52 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.744772354101642		[learning rate: 0.0058274]
	Learning Rate: 0.00582738
	LOSS [training: 0.744772354101642 | validation: 0.5211213661312153]
	TIME [epoch: 9.52 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6124098326081885		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.6124098326081885 | validation: 0.49546111317031777]
	TIME [epoch: 9.54 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5916707004788743		[learning rate: 0.0057992]
	Learning Rate: 0.0057992
	LOSS [training: 0.5916707004788743 | validation: 0.46968579784510556]
	TIME [epoch: 9.52 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6185345571449112		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.6185345571449112 | validation: 0.6626235266051864]
	TIME [epoch: 9.52 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3212040431210499		[learning rate: 0.0057712]
	Learning Rate: 0.00577116
	LOSS [training: 1.3212040431210499 | validation: 1.258528506754532]
	TIME [epoch: 9.53 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9195571040304891		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.9195571040304891 | validation: 0.9774905047379072]
	TIME [epoch: 9.53 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7161040686538919		[learning rate: 0.0057433]
	Learning Rate: 0.00574325
	LOSS [training: 0.7161040686538919 | validation: 0.6989027860445054]
	TIME [epoch: 9.52 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.598570788226187		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.598570788226187 | validation: 0.7550120797356425]
	TIME [epoch: 9.52 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6161955530167809		[learning rate: 0.0057155]
	Learning Rate: 0.00571548
	LOSS [training: 0.6161955530167809 | validation: 0.7627497356185237]
	TIME [epoch: 9.53 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5951149729854986		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.5951149729854986 | validation: 0.5467770831404984]
	TIME [epoch: 9.52 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6651785467681296		[learning rate: 0.0056878]
	Learning Rate: 0.00568784
	LOSS [training: 0.6651785467681296 | validation: 0.5050248723854095]
	TIME [epoch: 9.52 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7944494426958446		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.7944494426958446 | validation: 0.6629014314601043]
	TIME [epoch: 9.51 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8633246861735383		[learning rate: 0.0056603]
	Learning Rate: 0.00566033
	LOSS [training: 0.8633246861735383 | validation: 1.1398563941881752]
	TIME [epoch: 9.54 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8218636880526967		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.8218636880526967 | validation: 0.6637253529387869]
	TIME [epoch: 9.52 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8025778978126444		[learning rate: 0.005633]
	Learning Rate: 0.00563296
	LOSS [training: 0.8025778978126444 | validation: 0.5662778405219158]
	TIME [epoch: 9.52 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6475860023326786		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.6475860023326786 | validation: 0.8015027297946751]
	TIME [epoch: 9.53 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7200360330524986		[learning rate: 0.0056057]
	Learning Rate: 0.00560572
	LOSS [training: 0.7200360330524986 | validation: 0.7700111115240884]
	TIME [epoch: 9.53 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5073083158558522		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.5073083158558522 | validation: 0.6620527128818224]
	TIME [epoch: 9.52 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7210712979719689		[learning rate: 0.0055786]
	Learning Rate: 0.00557861
	LOSS [training: 0.7210712979719689 | validation: 0.8817247915254106]
	TIME [epoch: 9.52 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6200510820119763		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.6200510820119763 | validation: 0.7817198148938214]
	TIME [epoch: 9.54 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5937653836236393		[learning rate: 0.0055516]
	Learning Rate: 0.00555164
	LOSS [training: 0.5937653836236393 | validation: 0.7425401985749883]
	TIME [epoch: 9.52 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6354581959538018		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.6354581959538018 | validation: 0.8063849330011111]
	TIME [epoch: 9.53 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6943355268758451		[learning rate: 0.0055248]
	Learning Rate: 0.00552479
	LOSS [training: 0.6943355268758451 | validation: 0.49617832147297913]
	TIME [epoch: 9.51 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6510859997040674		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.6510859997040674 | validation: 0.3935438933167879]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333696721974862		[learning rate: 0.0054981]
	Learning Rate: 0.00549807
	LOSS [training: 0.6333696721974862 | validation: 0.7291843783815745]
	TIME [epoch: 9.52 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6431611278551388		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.6431611278551388 | validation: 0.6361088958672899]
	TIME [epoch: 9.52 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7593827342103083		[learning rate: 0.0054715]
	Learning Rate: 0.00547149
	LOSS [training: 0.7593827342103083 | validation: 0.7150943677971258]
	TIME [epoch: 9.53 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.596206540377011		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.596206540377011 | validation: 1.3245051959973708]
	TIME [epoch: 9.53 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.797585752583564		[learning rate: 0.005445]
	Learning Rate: 0.00544503
	LOSS [training: 0.797585752583564 | validation: 0.4011667328596284]
	TIME [epoch: 9.52 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49699004062172075		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.49699004062172075 | validation: 0.6340572194147862]
	TIME [epoch: 9.51 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9844825597113971		[learning rate: 0.0054187]
	Learning Rate: 0.0054187
	LOSS [training: 0.9844825597113971 | validation: 0.7231884539846221]
	TIME [epoch: 9.53 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5549702638637768		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.5549702638637768 | validation: 0.8032828607052062]
	TIME [epoch: 9.52 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7106984740326365		[learning rate: 0.0053925]
	Learning Rate: 0.00539249
	LOSS [training: 0.7106984740326365 | validation: 0.797730954820687]
	TIME [epoch: 9.51 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6273287234631268		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.6273287234631268 | validation: 0.5942059645873784]
	TIME [epoch: 9.51 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0529670276497016		[learning rate: 0.0053664]
	Learning Rate: 0.00536641
	LOSS [training: 1.0529670276497016 | validation: 1.199193590854908]
	TIME [epoch: 9.54 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8243892294082436		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.8243892294082436 | validation: 0.8231106017050897]
	TIME [epoch: 9.51 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6277150258734139		[learning rate: 0.0053405]
	Learning Rate: 0.00534046
	LOSS [training: 0.6277150258734139 | validation: 1.0449295437591453]
	TIME [epoch: 9.52 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6958446007316794		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.6958446007316794 | validation: 0.5399803491979835]
	TIME [epoch: 9.53 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4998202304098707		[learning rate: 0.0053146]
	Learning Rate: 0.00531464
	LOSS [training: 0.4998202304098707 | validation: 0.3835610545625913]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4879441717591962		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.4879441717591962 | validation: 0.48919318933217754]
	TIME [epoch: 9.51 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6491133209119491		[learning rate: 0.0052889]
	Learning Rate: 0.00528894
	LOSS [training: 0.6491133209119491 | validation: 0.4931122562114911]
	TIME [epoch: 9.51 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5760844234072243		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.5760844234072243 | validation: 1.4961865007226482]
	TIME [epoch: 9.52 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9717091086765208		[learning rate: 0.0052634]
	Learning Rate: 0.00526336
	LOSS [training: 0.9717091086765208 | validation: 0.4260958303932012]
	TIME [epoch: 9.52 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6606429802055876		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.6606429802055876 | validation: 0.4940848754807288]
	TIME [epoch: 9.51 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6414802746413526		[learning rate: 0.0052379]
	Learning Rate: 0.00523791
	LOSS [training: 0.6414802746413526 | validation: 0.6491043167159612]
	TIME [epoch: 9.52 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7298524051739637		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.7298524051739637 | validation: 0.7964286380452305]
	TIME [epoch: 9.52 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6293858134275865		[learning rate: 0.0052126]
	Learning Rate: 0.00521258
	LOSS [training: 0.6293858134275865 | validation: 0.6545254903249899]
	TIME [epoch: 9.51 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7479667504548084		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.7479667504548084 | validation: 0.6497542275666016]
	TIME [epoch: 9.51 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.662578787211194		[learning rate: 0.0051874]
	Learning Rate: 0.00518737
	LOSS [training: 0.662578787211194 | validation: 0.5669434691967639]
	TIME [epoch: 9.54 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5610323961967116		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.5610323961967116 | validation: 0.6545902673173444]
	TIME [epoch: 9.51 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6549583014688408		[learning rate: 0.0051623]
	Learning Rate: 0.00516229
	LOSS [training: 0.6549583014688408 | validation: 0.6941332326786139]
	TIME [epoch: 9.51 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6524402242883593		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.6524402242883593 | validation: 0.6877970955998858]
	TIME [epoch: 9.51 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.753511332344401		[learning rate: 0.0051373]
	Learning Rate: 0.00513732
	LOSS [training: 0.753511332344401 | validation: 0.668844921116402]
	TIME [epoch: 9.53 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5359816953559748		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.5359816953559748 | validation: 0.6692484000772335]
	TIME [epoch: 9.51 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7308732445724877		[learning rate: 0.0051125]
	Learning Rate: 0.00511248
	LOSS [training: 0.7308732445724877 | validation: 0.6141418178809904]
	TIME [epoch: 9.51 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8364279206090703		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.8364279206090703 | validation: 0.957546658576122]
	TIME [epoch: 9.51 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5591626534487366		[learning rate: 0.0050878]
	Learning Rate: 0.00508776
	LOSS [training: 0.5591626534487366 | validation: 0.3492928410778673]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.942268513203544		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.942268513203544 | validation: 1.4215560838808898]
	TIME [epoch: 9.52 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7761252654369594		[learning rate: 0.0050632]
	Learning Rate: 0.00506315
	LOSS [training: 0.7761252654369594 | validation: 0.5861036731432999]
	TIME [epoch: 9.52 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4281043476402336		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.4281043476402336 | validation: 0.4771693062493367]
	TIME [epoch: 9.54 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5779793719345439		[learning rate: 0.0050387]
	Learning Rate: 0.00503867
	LOSS [training: 0.5779793719345439 | validation: 0.5044392566489561]
	TIME [epoch: 9.52 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47049015617547274		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.47049015617547274 | validation: 0.7378294581607905]
	TIME [epoch: 9.52 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6203630642129305		[learning rate: 0.0050143]
	Learning Rate: 0.0050143
	LOSS [training: 0.6203630642129305 | validation: 0.8416711290107649]
	TIME [epoch: 9.51 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7301622707414125		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.7301622707414125 | validation: 0.6827203603672295]
	TIME [epoch: 9.53 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48673255816405947		[learning rate: 0.0049901]
	Learning Rate: 0.00499005
	LOSS [training: 0.48673255816405947 | validation: 0.5199034871753052]
	TIME [epoch: 9.52 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6031429779886538		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.6031429779886538 | validation: 0.47865233728979745]
	TIME [epoch: 9.51 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5231685194466611		[learning rate: 0.0049659]
	Learning Rate: 0.00496592
	LOSS [training: 0.5231685194466611 | validation: 0.5329868032549291]
	TIME [epoch: 9.51 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5129293686469024		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.5129293686469024 | validation: 0.5527342325222196]
	TIME [epoch: 9.53 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5205303459887952		[learning rate: 0.0049419]
	Learning Rate: 0.00494191
	LOSS [training: 0.5205303459887952 | validation: 0.4532937379506072]
	TIME [epoch: 9.5 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.510830364830037		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.510830364830037 | validation: 0.31966394942121507]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46703974023280176		[learning rate: 0.004918]
	Learning Rate: 0.00491801
	LOSS [training: 0.46703974023280176 | validation: 0.8954186030349811]
	TIME [epoch: 9.54 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7342654948699006		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.7342654948699006 | validation: 0.638556314104738]
	TIME [epoch: 9.51 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6397417438891038		[learning rate: 0.0048942]
	Learning Rate: 0.00489423
	LOSS [training: 0.6397417438891038 | validation: 0.5137705624048201]
	TIME [epoch: 9.5 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5089743351318512		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.5089743351318512 | validation: 0.6133648725452797]
	TIME [epoch: 9.51 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5352317850477307		[learning rate: 0.0048706]
	Learning Rate: 0.00487056
	LOSS [training: 0.5352317850477307 | validation: 0.5049960604277852]
	TIME [epoch: 9.53 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5199585269004929		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.5199585269004929 | validation: 0.6689400213181517]
	TIME [epoch: 9.51 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5716858033167675		[learning rate: 0.004847]
	Learning Rate: 0.00484701
	LOSS [training: 0.5716858033167675 | validation: 0.43967731026246526]
	TIME [epoch: 9.5 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5913773080231403		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.5913773080231403 | validation: 1.0868845013970756]
	TIME [epoch: 9.51 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7624954034477976		[learning rate: 0.0048236]
	Learning Rate: 0.00482357
	LOSS [training: 0.7624954034477976 | validation: 0.5458242060359314]
	TIME [epoch: 9.51 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4921215772769532		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.4921215772769532 | validation: 0.4112278505633258]
	TIME [epoch: 9.5 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6308228386301444		[learning rate: 0.0048002]
	Learning Rate: 0.00480024
	LOSS [training: 0.6308228386301444 | validation: 0.6463936222712127]
	TIME [epoch: 9.5 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49088040582305775		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.49088040582305775 | validation: 0.5646731052854636]
	TIME [epoch: 9.51 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6442904671821222		[learning rate: 0.004777]
	Learning Rate: 0.00477703
	LOSS [training: 0.6442904671821222 | validation: 0.5836731566630711]
	TIME [epoch: 9.5 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43270786148138934		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.43270786148138934 | validation: 0.38723295767891613]
	TIME [epoch: 9.5 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5996958188283321		[learning rate: 0.0047539]
	Learning Rate: 0.00475393
	LOSS [training: 0.5996958188283321 | validation: 0.66267767161742]
	TIME [epoch: 9.5 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.568374166957592		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.568374166957592 | validation: 0.9085149263597719]
	TIME [epoch: 9.52 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7915143762279133		[learning rate: 0.0047309]
	Learning Rate: 0.00473094
	LOSS [training: 0.7915143762279133 | validation: 0.3728551812626739]
	TIME [epoch: 9.51 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6800449602655755		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.6800449602655755 | validation: 1.2035521386688577]
	TIME [epoch: 9.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5926845934330631		[learning rate: 0.0047081]
	Learning Rate: 0.00470806
	LOSS [training: 0.5926845934330631 | validation: 0.6038858160824522]
	TIME [epoch: 9.51 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4914765842404905		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.4914765842404905 | validation: 0.33675561576775037]
	TIME [epoch: 9.51 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5798540119940543		[learning rate: 0.0046853]
	Learning Rate: 0.00468529
	LOSS [training: 0.5798540119940543 | validation: 0.7254946698198339]
	TIME [epoch: 9.5 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4974724532722029		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.4974724532722029 | validation: 0.41307297619095323]
	TIME [epoch: 9.5 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4702557992085725		[learning rate: 0.0046626]
	Learning Rate: 0.00466264
	LOSS [training: 0.4702557992085725 | validation: 0.5698653713698096]
	TIME [epoch: 9.52 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4714620582603021		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.4714620582603021 | validation: 0.37390564766604983]
	TIME [epoch: 9.51 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5518445926100284		[learning rate: 0.0046401]
	Learning Rate: 0.00464009
	LOSS [training: 0.5518445926100284 | validation: 0.8738071317020933]
	TIME [epoch: 9.5 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8258850295174851		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.8258850295174851 | validation: 0.429864421921859]
	TIME [epoch: 9.5 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293740729458276		[learning rate: 0.0046177]
	Learning Rate: 0.00461765
	LOSS [training: 0.5293740729458276 | validation: 0.5080231396982985]
	TIME [epoch: 9.52 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5954309290291461		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.5954309290291461 | validation: 0.31018906975064864]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_420.pth
	Model improved!!!
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5731409786175439		[learning rate: 0.0045953]
	Learning Rate: 0.00459532
	LOSS [training: 0.5731409786175439 | validation: 0.6212710565487974]
	TIME [epoch: 9.52 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5154273368773234		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.5154273368773234 | validation: 0.32631522625798676]
	TIME [epoch: 9.53 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5042716770111587		[learning rate: 0.0045731]
	Learning Rate: 0.0045731
	LOSS [training: 0.5042716770111587 | validation: 0.8459063616064001]
	TIME [epoch: 9.52 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5604332056494437		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.5604332056494437 | validation: 0.5261874518034786]
	TIME [epoch: 9.51 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5933572730560094		[learning rate: 0.004551]
	Learning Rate: 0.00455098
	LOSS [training: 0.5933572730560094 | validation: 0.6810636057463723]
	TIME [epoch: 9.51 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6960267597945535		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.6960267597945535 | validation: 0.823309303611016]
	TIME [epoch: 9.52 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4910155487037408		[learning rate: 0.004529]
	Learning Rate: 0.00452898
	LOSS [training: 0.4910155487037408 | validation: 0.4417648128391919]
	TIME [epoch: 9.51 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5469647874630309		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.5469647874630309 | validation: 0.6139600521337368]
	TIME [epoch: 9.52 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46141262130129795		[learning rate: 0.0045071]
	Learning Rate: 0.00450707
	LOSS [training: 0.46141262130129795 | validation: 0.5761098139996065]
	TIME [epoch: 9.51 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46449156483496684		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.46449156483496684 | validation: 0.4699957023080327]
	TIME [epoch: 9.52 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196746517564657		[learning rate: 0.0044853]
	Learning Rate: 0.00448528
	LOSS [training: 0.5196746517564657 | validation: 0.7295034974413926]
	TIME [epoch: 9.5 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5668426665472308		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.5668426665472308 | validation: 0.8583832704013091]
	TIME [epoch: 9.51 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6543737339664282		[learning rate: 0.0044636]
	Learning Rate: 0.00446359
	LOSS [training: 0.6543737339664282 | validation: 0.4317898412553008]
	TIME [epoch: 9.51 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.804018977247788		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.804018977247788 | validation: 0.4824602270504081]
	TIME [epoch: 9.51 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48038928631792766		[learning rate: 0.004442]
	Learning Rate: 0.004442
	LOSS [training: 0.48038928631792766 | validation: 0.7065894276264271]
	TIME [epoch: 9.51 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6115596964164755		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.6115596964164755 | validation: 0.4665810635914791]
	TIME [epoch: 9.52 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40470136393011175		[learning rate: 0.0044205]
	Learning Rate: 0.00442052
	LOSS [training: 0.40470136393011175 | validation: 0.7631017759275716]
	TIME [epoch: 9.52 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5378934819957099		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.5378934819957099 | validation: 0.6245949452357139]
	TIME [epoch: 9.51 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5413593862118414		[learning rate: 0.0043991]
	Learning Rate: 0.00439915
	LOSS [training: 0.5413593862118414 | validation: 0.4099768612038796]
	TIME [epoch: 9.51 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39837826316354763		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.39837826316354763 | validation: 0.4790813375931103]
	TIME [epoch: 9.5 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41595214471604114		[learning rate: 0.0043779]
	Learning Rate: 0.00437787
	LOSS [training: 0.41595214471604114 | validation: 0.875339065439396]
	TIME [epoch: 9.52 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.591503603764541		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.591503603764541 | validation: 0.520145145153481]
	TIME [epoch: 9.51 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45975344021521447		[learning rate: 0.0043567]
	Learning Rate: 0.0043567
	LOSS [training: 0.45975344021521447 | validation: 0.47849849405669864]
	TIME [epoch: 9.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46567239400693916		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.46567239400693916 | validation: 0.38762486852042155]
	TIME [epoch: 9.51 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6187409199968206		[learning rate: 0.0043356]
	Learning Rate: 0.00433563
	LOSS [training: 0.6187409199968206 | validation: 0.5017127061934272]
	TIME [epoch: 9.51 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6134170083935544		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.6134170083935544 | validation: 0.9518128235985833]
	TIME [epoch: 9.5 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5318847911965754		[learning rate: 0.0043147]
	Learning Rate: 0.00431467
	LOSS [training: 0.5318847911965754 | validation: 0.6408623242255493]
	TIME [epoch: 9.51 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48546283664299256		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.48546283664299256 | validation: 0.5178285592715389]
	TIME [epoch: 9.53 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4804926857044169		[learning rate: 0.0042938]
	Learning Rate: 0.0042938
	LOSS [training: 0.4804926857044169 | validation: 0.32404342067525405]
	TIME [epoch: 9.51 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4089662448023583		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.4089662448023583 | validation: 0.38975642509184716]
	TIME [epoch: 9.51 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4542135730997378		[learning rate: 0.004273]
	Learning Rate: 0.00427304
	LOSS [training: 0.4542135730997378 | validation: 0.7443675839209212]
	TIME [epoch: 9.51 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7115548321604994		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.7115548321604994 | validation: 0.3301477186704321]
	TIME [epoch: 9.52 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5086001574899208		[learning rate: 0.0042524]
	Learning Rate: 0.00425238
	LOSS [training: 0.5086001574899208 | validation: 0.7558050841148216]
	TIME [epoch: 9.51 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5961679943272344		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.5961679943272344 | validation: 0.4775963059332679]
	TIME [epoch: 9.51 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6225473632384622		[learning rate: 0.0042318]
	Learning Rate: 0.00423181
	LOSS [training: 0.6225473632384622 | validation: 0.3147844713415783]
	TIME [epoch: 9.52 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3423355322479876		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.3423355322479876 | validation: 0.3002794538852082]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_456.pth
	Model improved!!!
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38994692859334856		[learning rate: 0.0042113]
	Learning Rate: 0.00421135
	LOSS [training: 0.38994692859334856 | validation: 0.2725248778770938]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_457.pth
	Model improved!!!
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5146656738323123		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.5146656738323123 | validation: 0.5738288035688727]
	TIME [epoch: 9.52 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6470455586432262		[learning rate: 0.004191]
	Learning Rate: 0.00419098
	LOSS [training: 0.6470455586432262 | validation: 0.4703496892212677]
	TIME [epoch: 9.54 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275067814196023		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.5275067814196023 | validation: 0.478312820561648]
	TIME [epoch: 9.52 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6466370991976131		[learning rate: 0.0041707]
	Learning Rate: 0.00417071
	LOSS [training: 0.6466370991976131 | validation: 0.4196620270608136]
	TIME [epoch: 9.52 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6745177203328802		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.6745177203328802 | validation: 0.20993711735137852]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5022827190107786		[learning rate: 0.0041505]
	Learning Rate: 0.00415055
	LOSS [training: 0.5022827190107786 | validation: 0.7242776391138877]
	TIME [epoch: 9.54 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6175348643760211		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.6175348643760211 | validation: 0.5173748609847868]
	TIME [epoch: 9.51 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6456141521704136		[learning rate: 0.0041305]
	Learning Rate: 0.00413047
	LOSS [training: 0.6456141521704136 | validation: 0.7773449389312467]
	TIME [epoch: 9.52 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.521568178881559		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.521568178881559 | validation: 0.3646830678869229]
	TIME [epoch: 9.53 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43329965993817454		[learning rate: 0.0041105]
	Learning Rate: 0.0041105
	LOSS [training: 0.43329965993817454 | validation: 0.2812674892829621]
	TIME [epoch: 9.52 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3036728424356975		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.3036728424356975 | validation: 0.4055834035797567]
	TIME [epoch: 9.51 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49518343671775844		[learning rate: 0.0040906]
	Learning Rate: 0.00409062
	LOSS [training: 0.49518343671775844 | validation: 0.6035937881905767]
	TIME [epoch: 9.51 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.609542620717092		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.609542620717092 | validation: 0.43795271692160487]
	TIME [epoch: 9.52 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5378568961867702		[learning rate: 0.0040708]
	Learning Rate: 0.00407084
	LOSS [training: 0.5378568961867702 | validation: 0.3128329993120792]
	TIME [epoch: 9.52 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6321181385147566		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.6321181385147566 | validation: 0.48476962812658997]
	TIME [epoch: 9.52 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5671089383487755		[learning rate: 0.0040512]
	Learning Rate: 0.00405116
	LOSS [training: 0.5671089383487755 | validation: 0.7937556783101738]
	TIME [epoch: 9.52 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6030341021328409		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.6030341021328409 | validation: 0.6090134744849768]
	TIME [epoch: 9.52 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.025594543799748		[learning rate: 0.0040316]
	Learning Rate: 0.00403157
	LOSS [training: 1.025594543799748 | validation: 0.5555266672829865]
	TIME [epoch: 9.51 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39485263708341783		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.39485263708341783 | validation: 0.8830583891680753]
	TIME [epoch: 9.51 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48331773475751305		[learning rate: 0.0040121]
	Learning Rate: 0.00401207
	LOSS [training: 0.48331773475751305 | validation: 0.747674560412408]
	TIME [epoch: 9.53 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5254438447353842		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.5254438447353842 | validation: 1.5588000460695952]
	TIME [epoch: 9.51 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6683090290182409		[learning rate: 0.0039927]
	Learning Rate: 0.00399267
	LOSS [training: 0.6683090290182409 | validation: 0.39888111643745916]
	TIME [epoch: 9.52 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7802979390882502		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.7802979390882502 | validation: 0.701742137489731]
	TIME [epoch: 9.5 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6222224285773665		[learning rate: 0.0039734]
	Learning Rate: 0.00397336
	LOSS [training: 0.6222224285773665 | validation: 0.6820360338593682]
	TIME [epoch: 9.53 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6689904995216311		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.6689904995216311 | validation: 0.5811406747342476]
	TIME [epoch: 9.51 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6185795750625559		[learning rate: 0.0039541]
	Learning Rate: 0.00395415
	LOSS [training: 0.6185795750625559 | validation: 0.5157040262578607]
	TIME [epoch: 9.51 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6878540019480841		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.6878540019480841 | validation: 0.4525639113785049]
	TIME [epoch: 9.53 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5272479775044354		[learning rate: 0.003935]
	Learning Rate: 0.00393502
	LOSS [training: 0.5272479775044354 | validation: 0.38595010654488976]
	TIME [epoch: 9.52 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5318345435740015		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.5318345435740015 | validation: 0.3740479273233352]
	TIME [epoch: 9.51 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46596517236829377		[learning rate: 0.003916]
	Learning Rate: 0.00391599
	LOSS [training: 0.46596517236829377 | validation: 0.3514668830841302]
	TIME [epoch: 9.5 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6446028806283525		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.6446028806283525 | validation: 0.4993912025328261]
	TIME [epoch: 9.52 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3671341020346335		[learning rate: 0.0038971]
	Learning Rate: 0.00389706
	LOSS [training: 0.3671341020346335 | validation: 0.4361026554724964]
	TIME [epoch: 9.51 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33581768024468117		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.33581768024468117 | validation: 0.41587560460530726]
	TIME [epoch: 9.51 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35527314594001835		[learning rate: 0.0038782]
	Learning Rate: 0.00387821
	LOSS [training: 0.35527314594001835 | validation: 0.5021363522006069]
	TIME [epoch: 9.51 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43032667401021996		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.43032667401021996 | validation: 0.6194079178436779]
	TIME [epoch: 9.53 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5699536204462635		[learning rate: 0.0038595]
	Learning Rate: 0.00385946
	LOSS [training: 0.5699536204462635 | validation: 0.39324658762798126]
	TIME [epoch: 9.5 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4202739773741671		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.4202739773741671 | validation: 0.3784778570778552]
	TIME [epoch: 9.51 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4129916997130305		[learning rate: 0.0038408]
	Learning Rate: 0.00384079
	LOSS [training: 0.4129916997130305 | validation: 0.48141212551930934]
	TIME [epoch: 9.51 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41814179044121114		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.41814179044121114 | validation: 0.4230312112986763]
	TIME [epoch: 9.52 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45105789190996076		[learning rate: 0.0038222]
	Learning Rate: 0.00382222
	LOSS [training: 0.45105789190996076 | validation: 0.40373141918391964]
	TIME [epoch: 9.51 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.418645258664822		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.418645258664822 | validation: 0.43066440366553804]
	TIME [epoch: 9.51 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45670076641195223		[learning rate: 0.0038037]
	Learning Rate: 0.00380374
	LOSS [training: 0.45670076641195223 | validation: 0.33814250918693795]
	TIME [epoch: 9.52 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.542761591610199		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.542761591610199 | validation: 0.5298385686783176]
	TIME [epoch: 9.51 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43154050708641717		[learning rate: 0.0037853]
	Learning Rate: 0.00378534
	LOSS [training: 0.43154050708641717 | validation: 0.5816809157858519]
	TIME [epoch: 9.51 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36479863823140907		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.36479863823140907 | validation: 0.45787645377031155]
	TIME [epoch: 9.51 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5411879196893732		[learning rate: 0.003767]
	Learning Rate: 0.00376704
	LOSS [training: 0.5411879196893732 | validation: 0.7702186113960428]
	TIME [epoch: 9.53 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44083304817538427		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.44083304817538427 | validation: 0.4468659820753345]
	TIME [epoch: 9.51 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.378835656113454		[learning rate: 0.0037488]
	Learning Rate: 0.00374882
	LOSS [training: 0.378835656113454 | validation: 0.5419432982316421]
	TIME [epoch: 9.51 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49261068802078406		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.49261068802078406 | validation: 0.9175533725147443]
	TIME [epoch: 9.52 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5124341554882228		[learning rate: 0.0037307]
	Learning Rate: 0.00373069
	LOSS [training: 0.5124341554882228 | validation: 0.34250881161565083]
	TIME [epoch: 9.52 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4914165010142882		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.4914165010142882 | validation: 0.4055426485170095]
	TIME [epoch: 9.51 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4978038759965324		[learning rate: 0.0037127]
	Learning Rate: 0.00371265
	LOSS [training: 0.4978038759965324 | validation: 0.5320951263780991]
	TIME [epoch: 9.51 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46815880987188285		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.46815880987188285 | validation: 0.3357837076554817]
	TIME [epoch: 9.53 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39280281964117975		[learning rate: 0.0036947]
	Learning Rate: 0.0036947
	LOSS [training: 0.39280281964117975 | validation: 0.5271344120967862]
	TIME [epoch: 9.52 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5488295616079695		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.5488295616079695 | validation: 0.7005739957730361]
	TIME [epoch: 9.5 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44637822161337626		[learning rate: 0.0036768]
	Learning Rate: 0.00367683
	LOSS [training: 0.44637822161337626 | validation: 0.43656404842900953]
	TIME [epoch: 9.52 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.451695206570784		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.451695206570784 | validation: 0.39208981217173333]
	TIME [epoch: 9.52 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3303392700855645		[learning rate: 0.0036591]
	Learning Rate: 0.00365905
	LOSS [training: 0.3303392700855645 | validation: 0.3085859559450546]
	TIME [epoch: 9.51 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3604386201161133		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.3604386201161133 | validation: 0.455004683579613]
	TIME [epoch: 9.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41890108642060353		[learning rate: 0.0036414]
	Learning Rate: 0.00364136
	LOSS [training: 0.41890108642060353 | validation: 0.36032704859610043]
	TIME [epoch: 9.52 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37630875758871624		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.37630875758871624 | validation: 0.5823776844920644]
	TIME [epoch: 9.51 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6137421301035202		[learning rate: 0.0036237]
	Learning Rate: 0.00362375
	LOSS [training: 0.6137421301035202 | validation: 0.3862110565452717]
	TIME [epoch: 9.51 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46285392878554854		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.46285392878554854 | validation: 0.36866933785267336]
	TIME [epoch: 9.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7469790630052634		[learning rate: 0.0036062]
	Learning Rate: 0.00360622
	LOSS [training: 0.7469790630052634 | validation: 0.5458922322590151]
	TIME [epoch: 9.52 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9080912603523492		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.9080912603523492 | validation: 0.7977733645036343]
	TIME [epoch: 9.51 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9041141584017364		[learning rate: 0.0035888]
	Learning Rate: 0.00358878
	LOSS [training: 0.9041141584017364 | validation: 0.6277131794410371]
	TIME [epoch: 9.51 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7428957827414888		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.7428957827414888 | validation: 0.6776393023130513]
	TIME [epoch: 9.51 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8745074817701987		[learning rate: 0.0035714]
	Learning Rate: 0.00357143
	LOSS [training: 0.8745074817701987 | validation: 0.670976345591049]
	TIME [epoch: 9.53 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9406854045313068		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.9406854045313068 | validation: 0.5364614675633276]
	TIME [epoch: 9.51 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.670326447657238		[learning rate: 0.0035542]
	Learning Rate: 0.00355416
	LOSS [training: 0.670326447657238 | validation: 0.6114146686620009]
	TIME [epoch: 9.51 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7505385660058151		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.7505385660058151 | validation: 0.7156640806236646]
	TIME [epoch: 9.51 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6309398480482022		[learning rate: 0.003537]
	Learning Rate: 0.00353697
	LOSS [training: 0.6309398480482022 | validation: 0.29720094750410225]
	TIME [epoch: 9.52 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4908045938260227		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.4908045938260227 | validation: 0.3185022842203174]
	TIME [epoch: 9.5 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5541514375968082		[learning rate: 0.0035199]
	Learning Rate: 0.00351987
	LOSS [training: 0.5541514375968082 | validation: 0.5527381052180056]
	TIME [epoch: 9.51 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6062551564874967		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.6062551564874967 | validation: 0.6588391757829044]
	TIME [epoch: 9.52 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6172821444317484		[learning rate: 0.0035028]
	Learning Rate: 0.00350285
	LOSS [training: 0.6172821444317484 | validation: 0.6527999403648252]
	TIME [epoch: 9.51 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.604665728133574		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.604665728133574 | validation: 0.566403957065994]
	TIME [epoch: 9.51 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5074546225732903		[learning rate: 0.0034859]
	Learning Rate: 0.00348591
	LOSS [training: 0.5074546225732903 | validation: 0.5137843613168345]
	TIME [epoch: 9.51 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5867763924002803		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.5867763924002803 | validation: 0.4373602932251297]
	TIME [epoch: 9.52 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5085181393830053		[learning rate: 0.003469]
	Learning Rate: 0.00346905
	LOSS [training: 0.5085181393830053 | validation: 0.5271232303431034]
	TIME [epoch: 9.51 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5473355437447938		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.5473355437447938 | validation: 0.5831314579897919]
	TIME [epoch: 9.51 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6171757980250371		[learning rate: 0.0034523]
	Learning Rate: 0.00345227
	LOSS [training: 0.6171757980250371 | validation: 0.4766363746509392]
	TIME [epoch: 9.52 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5909721532739128		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.5909721532739128 | validation: 0.5876598605559623]
	TIME [epoch: 9.51 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5689604495675501		[learning rate: 0.0034356]
	Learning Rate: 0.00343558
	LOSS [training: 0.5689604495675501 | validation: 0.33224304225056545]
	TIME [epoch: 9.52 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6155129187670111		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.6155129187670111 | validation: 0.45979270716471404]
	TIME [epoch: 9.51 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7135249571656278		[learning rate: 0.003419]
	Learning Rate: 0.00341897
	LOSS [training: 0.7135249571656278 | validation: 0.7099047232911777]
	TIME [epoch: 9.53 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5540629151119305		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.5540629151119305 | validation: 0.49764485383986823]
	TIME [epoch: 9.52 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5275865770185424		[learning rate: 0.0034024]
	Learning Rate: 0.00340243
	LOSS [training: 0.5275865770185424 | validation: 0.7170465916081348]
	TIME [epoch: 9.52 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5431367500324211		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.5431367500324211 | validation: 0.6493039047012735]
	TIME [epoch: 9.51 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7081399854433219		[learning rate: 0.003386]
	Learning Rate: 0.00338598
	LOSS [training: 0.7081399854433219 | validation: 1.1575995992358532]
	TIME [epoch: 9.54 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7169816181596712		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.7169816181596712 | validation: 0.9301145724056076]
	TIME [epoch: 9.52 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7672516278710088		[learning rate: 0.0033696]
	Learning Rate: 0.0033696
	LOSS [training: 0.7672516278710088 | validation: 0.3928792944191601]
	TIME [epoch: 9.52 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38661245139681805		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.38661245139681805 | validation: 0.3226842839303541]
	TIME [epoch: 9.52 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41351839982367145		[learning rate: 0.0033533]
	Learning Rate: 0.00335331
	LOSS [training: 0.41351839982367145 | validation: 0.3885435451708763]
	TIME [epoch: 9.53 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5139626769512056		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.5139626769512056 | validation: 0.42198473699479716]
	TIME [epoch: 9.51 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4346026370556089		[learning rate: 0.0033371]
	Learning Rate: 0.00333709
	LOSS [training: 0.4346026370556089 | validation: 0.3488277774046291]
	TIME [epoch: 9.51 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38496505231239564		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.38496505231239564 | validation: 0.4278704255867903]
	TIME [epoch: 9.53 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5928120336799441		[learning rate: 0.003321]
	Learning Rate: 0.00332096
	LOSS [training: 0.5928120336799441 | validation: 0.7366942813026371]
	TIME [epoch: 9.51 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4815062813973894		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.4815062813973894 | validation: 0.4196914796329957]
	TIME [epoch: 9.5 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3435034788893378		[learning rate: 0.0033049]
	Learning Rate: 0.0033049
	LOSS [training: 0.3435034788893378 | validation: 0.40206789824988903]
	TIME [epoch: 9.51 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6619063064961751		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.6619063064961751 | validation: 0.8365565590779034]
	TIME [epoch: 9.53 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0757339454036063		[learning rate: 0.0032889]
	Learning Rate: 0.00328891
	LOSS [training: 1.0757339454036063 | validation: 0.7035157064917749]
	TIME [epoch: 9.51 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.681728531388608		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.681728531388608 | validation: 0.47525449702222383]
	TIME [epoch: 9.51 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.604461985744567		[learning rate: 0.003273]
	Learning Rate: 0.00327301
	LOSS [training: 0.604461985744567 | validation: 0.48353801586597145]
	TIME [epoch: 9.51 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5620054796084177		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.5620054796084177 | validation: 0.5789274063643621]
	TIME [epoch: 9.51 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5774334399192884		[learning rate: 0.0032572]
	Learning Rate: 0.00325718
	LOSS [training: 0.5774334399192884 | validation: 0.5228283001256532]
	TIME [epoch: 9.5 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5474407096866872		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.5474407096866872 | validation: 0.5144055190728081]
	TIME [epoch: 9.5 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5526154806222745		[learning rate: 0.0032414]
	Learning Rate: 0.00324143
	LOSS [training: 0.5526154806222745 | validation: 0.5058490427007684]
	TIME [epoch: 9.51 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7228018305340986		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.7228018305340986 | validation: 0.5832802517934202]
	TIME [epoch: 9.5 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5651923396962044		[learning rate: 0.0032258]
	Learning Rate: 0.00322576
	LOSS [training: 0.5651923396962044 | validation: 0.4206590043915597]
	TIME [epoch: 9.5 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.519485950799567		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.519485950799567 | validation: 0.5610792778620385]
	TIME [epoch: 9.5 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5237995262196259		[learning rate: 0.0032102]
	Learning Rate: 0.00321016
	LOSS [training: 0.5237995262196259 | validation: 0.8553335167715486]
	TIME [epoch: 9.52 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7204832845455608		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.7204832845455608 | validation: 0.44192978141767697]
	TIME [epoch: 9.5 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3995829612853437		[learning rate: 0.0031946]
	Learning Rate: 0.00319463
	LOSS [training: 0.3995829612853437 | validation: 0.5087576553143938]
	TIME [epoch: 9.5 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.441175772451835		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.441175772451835 | validation: 0.4519450276387325]
	TIME [epoch: 9.51 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4251862999827227		[learning rate: 0.0031792]
	Learning Rate: 0.00317918
	LOSS [training: 0.4251862999827227 | validation: 0.5890068078061308]
	TIME [epoch: 9.52 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4388182615573344		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.4388182615573344 | validation: 0.5115838511613712]
	TIME [epoch: 9.5 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5288015136018436		[learning rate: 0.0031638]
	Learning Rate: 0.00316381
	LOSS [training: 0.5288015136018436 | validation: 0.5947388541724865]
	TIME [epoch: 9.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4210729726080646		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.4210729726080646 | validation: 0.27651259611188134]
	TIME [epoch: 9.51 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4482013329797742		[learning rate: 0.0031485]
	Learning Rate: 0.00314851
	LOSS [training: 0.4482013329797742 | validation: 0.42454835299095245]
	TIME [epoch: 9.5 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5969767247685909		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.5969767247685909 | validation: 0.41811023899381494]
	TIME [epoch: 9.5 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3329556526625159		[learning rate: 0.0031333]
	Learning Rate: 0.00313329
	LOSS [training: 0.3329556526625159 | validation: 0.3624264265955026]
	TIME [epoch: 9.51 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29311439920900767		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.29311439920900767 | validation: 0.4912605325832296]
	TIME [epoch: 9.52 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3628867494997559		[learning rate: 0.0031181]
	Learning Rate: 0.00311813
	LOSS [training: 0.3628867494997559 | validation: 0.5427375940339897]
	TIME [epoch: 9.5 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3492894627344619		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.3492894627344619 | validation: 0.33745766084298295]
	TIME [epoch: 9.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3120407163533506		[learning rate: 0.0031031]
	Learning Rate: 0.00310305
	LOSS [training: 0.3120407163533506 | validation: 0.34908624060670135]
	TIME [epoch: 9.51 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322952260036699		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.5322952260036699 | validation: 0.4586659272920805]
	TIME [epoch: 9.51 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7255852270558867		[learning rate: 0.003088]
	Learning Rate: 0.00308805
	LOSS [training: 0.7255852270558867 | validation: 0.9020432355920641]
	TIME [epoch: 9.51 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6468016674251104		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.6468016674251104 | validation: 0.43299337715400044]
	TIME [epoch: 9.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5810957059638377		[learning rate: 0.0030731]
	Learning Rate: 0.00307312
	LOSS [training: 0.5810957059638377 | validation: 0.6062125360632649]
	TIME [epoch: 9.52 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39117945596838594		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.39117945596838594 | validation: 0.9175558079989646]
	TIME [epoch: 9.5 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.709862134335119		[learning rate: 0.0030583]
	Learning Rate: 0.00305825
	LOSS [training: 0.709862134335119 | validation: 0.4472751770976801]
	TIME [epoch: 9.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7841307425861744		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.7841307425861744 | validation: 0.5558504860096811]
	TIME [epoch: 9.5 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38362078470783434		[learning rate: 0.0030435]
	Learning Rate: 0.00304347
	LOSS [training: 0.38362078470783434 | validation: 0.2948326246106926]
	TIME [epoch: 9.52 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37714228982550296		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.37714228982550296 | validation: 0.40934297445183787]
	TIME [epoch: 9.5 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46271142061365056		[learning rate: 0.0030287]
	Learning Rate: 0.00302875
	LOSS [training: 0.46271142061365056 | validation: 0.32982927077657564]
	TIME [epoch: 9.51 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30838924098469966		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.30838924098469966 | validation: 0.3252784437923652]
	TIME [epoch: 9.51 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33008119746142717		[learning rate: 0.0030141]
	Learning Rate: 0.0030141
	LOSS [training: 0.33008119746142717 | validation: 0.30373227863358604]
	TIME [epoch: 9.51 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42818295093186237		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.42818295093186237 | validation: 1.0721064040755448]
	TIME [epoch: 9.5 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.684475456421483		[learning rate: 0.0029995]
	Learning Rate: 0.00299953
	LOSS [training: 0.684475456421483 | validation: 0.3662525093290077]
	TIME [epoch: 9.51 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43241618860504427		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.43241618860504427 | validation: 0.36574755706587864]
	TIME [epoch: 9.53 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3766273893449698		[learning rate: 0.002985]
	Learning Rate: 0.00298502
	LOSS [training: 0.3766273893449698 | validation: 0.31665936254028415]
	TIME [epoch: 9.51 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38573948986131634		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.38573948986131634 | validation: 0.4713039079886039]
	TIME [epoch: 9.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32987183092340255		[learning rate: 0.0029706]
	Learning Rate: 0.00297059
	LOSS [training: 0.32987183092340255 | validation: 0.40001734024191155]
	TIME [epoch: 9.51 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31842734589370053		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.31842734589370053 | validation: 0.6093597877994226]
	TIME [epoch: 9.52 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4257013273317984		[learning rate: 0.0029562]
	Learning Rate: 0.00295622
	LOSS [training: 0.4257013273317984 | validation: 0.4111232148014294]
	TIME [epoch: 9.51 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3142521163713777		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.3142521163713777 | validation: 0.3773440430377097]
	TIME [epoch: 9.51 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3238152467587107		[learning rate: 0.0029419]
	Learning Rate: 0.00294192
	LOSS [training: 0.3238152467587107 | validation: 0.33386245710941]
	TIME [epoch: 9.52 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30422822633391094		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.30422822633391094 | validation: 0.5922228995033413]
	TIME [epoch: 9.51 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5060810332837667		[learning rate: 0.0029277]
	Learning Rate: 0.0029277
	LOSS [training: 0.5060810332837667 | validation: 0.2527544314845426]
	TIME [epoch: 9.51 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3360550529464401		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.3360550529464401 | validation: 0.5864890259255179]
	TIME [epoch: 9.5 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3355802039147365		[learning rate: 0.0029135]
	Learning Rate: 0.00291354
	LOSS [training: 0.3355802039147365 | validation: 0.27645305496644496]
	TIME [epoch: 9.52 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43350683329578227		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.43350683329578227 | validation: 0.8595804491021118]
	TIME [epoch: 9.51 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6499929221662855		[learning rate: 0.0028995]
	Learning Rate: 0.00289945
	LOSS [training: 0.6499929221662855 | validation: 0.3609882865070258]
	TIME [epoch: 9.51 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3231623753449333		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.3231623753449333 | validation: 0.34978582134739816]
	TIME [epoch: 9.51 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34365607944851095		[learning rate: 0.0028854]
	Learning Rate: 0.00288543
	LOSS [training: 0.34365607944851095 | validation: 0.26462890477453505]
	TIME [epoch: 9.53 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2685249174569481		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.2685249174569481 | validation: 0.33129492993578197]
	TIME [epoch: 9.5 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2605164279585451		[learning rate: 0.0028715]
	Learning Rate: 0.00287148
	LOSS [training: 0.2605164279585451 | validation: 0.35059763556501167]
	TIME [epoch: 9.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39234795423734814		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.39234795423734814 | validation: 0.249975544283744]
	TIME [epoch: 9.51 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24453035307703433		[learning rate: 0.0028576]
	Learning Rate: 0.00285759
	LOSS [training: 0.24453035307703433 | validation: 0.879420911822393]
	TIME [epoch: 9.52 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43205643970295143		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.43205643970295143 | validation: 0.3735911926079972]
	TIME [epoch: 9.51 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.327699732644532		[learning rate: 0.0028438]
	Learning Rate: 0.00284377
	LOSS [training: 0.327699732644532 | validation: 0.27954987761843886]
	TIME [epoch: 9.51 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28498431130131285		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.28498431130131285 | validation: 0.26667659859823806]
	TIME [epoch: 9.52 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4276934215639356		[learning rate: 0.00283]
	Learning Rate: 0.00283002
	LOSS [training: 0.4276934215639356 | validation: 0.2926221677103442]
	TIME [epoch: 9.51 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36945049825270065		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.36945049825270065 | validation: 0.29091611129480965]
	TIME [epoch: 9.5 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29126181791204814		[learning rate: 0.0028163]
	Learning Rate: 0.00281633
	LOSS [training: 0.29126181791204814 | validation: 0.4387936551904603]
	TIME [epoch: 9.51 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7736521711368495		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.7736521711368495 | validation: 0.5105353431072022]
	TIME [epoch: 9.52 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3384748584086125		[learning rate: 0.0028027]
	Learning Rate: 0.00280272
	LOSS [training: 0.3384748584086125 | validation: 0.21268372994152096]
	TIME [epoch: 9.51 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2502393938092788		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.2502393938092788 | validation: 0.539100834679784]
	TIME [epoch: 9.5 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30185943328338316		[learning rate: 0.0027892]
	Learning Rate: 0.00278916
	LOSS [training: 0.30185943328338316 | validation: 0.22078973056662485]
	TIME [epoch: 9.52 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3484781331915564		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.3484781331915564 | validation: 0.17525652162245742]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_628.pth
	Model improved!!!
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19379597625954528		[learning rate: 0.0027757]
	Learning Rate: 0.00277567
	LOSS [training: 0.19379597625954528 | validation: 0.2751105800761802]
	TIME [epoch: 9.51 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.259434741980462		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.259434741980462 | validation: 0.31354981585917396]
	TIME [epoch: 9.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35710634368462085		[learning rate: 0.0027623]
	Learning Rate: 0.00276225
	LOSS [training: 0.35710634368462085 | validation: 0.16736302430240044]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_631.pth
	Model improved!!!
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.370867742236159		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.370867742236159 | validation: 0.8194980813101749]
	TIME [epoch: 9.51 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3400234499054503		[learning rate: 0.0027489]
	Learning Rate: 0.00274889
	LOSS [training: 0.3400234499054503 | validation: 0.24364675674916528]
	TIME [epoch: 9.5 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47701659876553626		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.47701659876553626 | validation: 0.3606922863673271]
	TIME [epoch: 9.5 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27119573969518457		[learning rate: 0.0027356]
	Learning Rate: 0.0027356
	LOSS [training: 0.27119573969518457 | validation: 0.2718459612827812]
	TIME [epoch: 9.52 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3382098369244539		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.3382098369244539 | validation: 0.300460942952746]
	TIME [epoch: 9.51 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28124683625201985		[learning rate: 0.0027224]
	Learning Rate: 0.00272237
	LOSS [training: 0.28124683625201985 | validation: 0.4332601127016952]
	TIME [epoch: 9.5 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5454738242221971		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.5454738242221971 | validation: 0.3461951005901663]
	TIME [epoch: 9.52 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35580643939732154		[learning rate: 0.0027092]
	Learning Rate: 0.00270921
	LOSS [training: 0.35580643939732154 | validation: 0.28128016509515896]
	TIME [epoch: 9.51 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3111512104843197		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.3111512104843197 | validation: 0.3940873083959231]
	TIME [epoch: 9.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22176358387429856		[learning rate: 0.0026961]
	Learning Rate: 0.00269611
	LOSS [training: 0.22176358387429856 | validation: 0.351225822347464]
	TIME [epoch: 9.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27008393836728406		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.27008393836728406 | validation: 0.27623743714524296]
	TIME [epoch: 9.52 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31577290020497817		[learning rate: 0.0026831]
	Learning Rate: 0.00268307
	LOSS [training: 0.31577290020497817 | validation: 0.4385284816051723]
	TIME [epoch: 9.51 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29006453020731804		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.29006453020731804 | validation: 0.2083485173301958]
	TIME [epoch: 9.5 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32628346998808083		[learning rate: 0.0026701]
	Learning Rate: 0.00267009
	LOSS [training: 0.32628346998808083 | validation: 0.532815187264276]
	TIME [epoch: 9.5 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37998234661993224		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.37998234661993224 | validation: 0.21026793175939282]
	TIME [epoch: 9.52 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2993645981309661		[learning rate: 0.0026572]
	Learning Rate: 0.00265718
	LOSS [training: 0.2993645981309661 | validation: 0.5387598016546206]
	TIME [epoch: 9.51 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4280594073243479		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.4280594073243479 | validation: 0.42148461370115614]
	TIME [epoch: 9.51 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.405932659217457		[learning rate: 0.0026443]
	Learning Rate: 0.00264433
	LOSS [training: 0.405932659217457 | validation: 0.29728413180754665]
	TIME [epoch: 9.52 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.299645849373828		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.299645849373828 | validation: 0.3008117367237019]
	TIME [epoch: 9.51 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2731052791455397		[learning rate: 0.0026315]
	Learning Rate: 0.00263154
	LOSS [training: 0.2731052791455397 | validation: 0.2190424248616867]
	TIME [epoch: 9.5 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24316895678825445		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.24316895678825445 | validation: 0.3748011070751304]
	TIME [epoch: 9.5 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31930082178492725		[learning rate: 0.0026188]
	Learning Rate: 0.00261882
	LOSS [training: 0.31930082178492725 | validation: 0.3907492611988723]
	TIME [epoch: 9.52 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2832621035211177		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.2832621035211177 | validation: 0.33763470575056653]
	TIME [epoch: 9.51 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30178054051542386		[learning rate: 0.0026062]
	Learning Rate: 0.00260615
	LOSS [training: 0.30178054051542386 | validation: 0.37515350622419513]
	TIME [epoch: 9.5 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3269419153765103		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.3269419153765103 | validation: 0.2855922326942806]
	TIME [epoch: 9.5 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32193677829358186		[learning rate: 0.0025936]
	Learning Rate: 0.00259355
	LOSS [training: 0.32193677829358186 | validation: 0.391490323553991]
	TIME [epoch: 9.52 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.366338172012996		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.366338172012996 | validation: 0.2758508470223799]
	TIME [epoch: 9.51 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21366563601099942		[learning rate: 0.002581]
	Learning Rate: 0.00258101
	LOSS [training: 0.21366563601099942 | validation: 0.29126134119227515]
	TIME [epoch: 9.5 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25155183028856204		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.25155183028856204 | validation: 0.5295491067062872]
	TIME [epoch: 9.52 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31170429652855364		[learning rate: 0.0025685]
	Learning Rate: 0.00256853
	LOSS [training: 0.31170429652855364 | validation: 0.38735304916568053]
	TIME [epoch: 9.51 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3638136437014039		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.3638136437014039 | validation: 0.35671480333490174]
	TIME [epoch: 9.51 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3299793109547979		[learning rate: 0.0025561]
	Learning Rate: 0.00255611
	LOSS [training: 0.3299793109547979 | validation: 0.37727176559095427]
	TIME [epoch: 9.5 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2840036487320693		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.2840036487320693 | validation: 0.35206925533429767]
	TIME [epoch: 9.52 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5285788559058797		[learning rate: 0.0025437]
	Learning Rate: 0.00254375
	LOSS [training: 0.5285788559058797 | validation: 0.24939377759698375]
	TIME [epoch: 9.51 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20601774741447745		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.20601774741447745 | validation: 0.23752251325667728]
	TIME [epoch: 9.51 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21799341696590546		[learning rate: 0.0025314]
	Learning Rate: 0.00253144
	LOSS [training: 0.21799341696590546 | validation: 0.1730156629935928]
	TIME [epoch: 9.51 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2501616107121488		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.2501616107121488 | validation: 0.2851068401354371]
	TIME [epoch: 9.52 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25173928068479523		[learning rate: 0.0025192]
	Learning Rate: 0.0025192
	LOSS [training: 0.25173928068479523 | validation: 0.8273514152353516]
	TIME [epoch: 9.5 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42955134185847144		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.42955134185847144 | validation: 0.37424575405491306]
	TIME [epoch: 9.5 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23598915198741696		[learning rate: 0.002507]
	Learning Rate: 0.00250702
	LOSS [training: 0.23598915198741696 | validation: 0.23727275772116987]
	TIME [epoch: 9.51 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27779772111683143		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.27779772111683143 | validation: 0.2718827275794962]
	TIME [epoch: 9.51 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1871712515697011		[learning rate: 0.0024949]
	Learning Rate: 0.0024949
	LOSS [training: 0.1871712515697011 | validation: 0.39849675672408397]
	TIME [epoch: 9.51 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5428639400551469		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.5428639400551469 | validation: 0.2799170853890264]
	TIME [epoch: 9.5 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22577977160057863		[learning rate: 0.0024828]
	Learning Rate: 0.00248283
	LOSS [training: 0.22577977160057863 | validation: 0.34834823189751585]
	TIME [epoch: 9.52 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29256761429040246		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.29256761429040246 | validation: 0.23577532615255303]
	TIME [epoch: 9.51 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2620376260956677		[learning rate: 0.0024708]
	Learning Rate: 0.00247083
	LOSS [training: 0.2620376260956677 | validation: 0.32885537111849256]
	TIME [epoch: 9.5 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2587572389460776		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.2587572389460776 | validation: 0.25144164389880663]
	TIME [epoch: 9.5 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.288025858516583		[learning rate: 0.0024589]
	Learning Rate: 0.00245888
	LOSS [training: 0.288025858516583 | validation: 0.49228433353849016]
	TIME [epoch: 9.52 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27857088795942225		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.27857088795942225 | validation: 0.24083566649728952]
	TIME [epoch: 9.51 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22334140309630568		[learning rate: 0.002447]
	Learning Rate: 0.00244699
	LOSS [training: 0.22334140309630568 | validation: 0.26355576945129616]
	TIME [epoch: 9.5 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28499737475958853		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.28499737475958853 | validation: 0.27117591598042085]
	TIME [epoch: 9.52 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23423113055593164		[learning rate: 0.0024352]
	Learning Rate: 0.00243515
	LOSS [training: 0.23423113055593164 | validation: 0.2567978574313375]
	TIME [epoch: 9.51 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2396342032700632		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.2396342032700632 | validation: 0.2149922932984378]
	TIME [epoch: 9.51 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24946945136208934		[learning rate: 0.0024234]
	Learning Rate: 0.00242338
	LOSS [training: 0.24946945136208934 | validation: 0.2783703894497578]
	TIME [epoch: 9.51 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29656585900743593		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.29656585900743593 | validation: 0.1917252603213504]
	TIME [epoch: 9.53 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26786538508523655		[learning rate: 0.0024117]
	Learning Rate: 0.00241166
	LOSS [training: 0.26786538508523655 | validation: 0.19367832233948817]
	TIME [epoch: 9.51 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.173192893224079		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.173192893224079 | validation: 0.18208545529567907]
	TIME [epoch: 9.5 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20077508360095422		[learning rate: 0.0024]
	Learning Rate: 0.0024
	LOSS [training: 0.20077508360095422 | validation: 0.2853023881483799]
	TIME [epoch: 9.52 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24575621139293716		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.24575621139293716 | validation: 0.23642735964659273]
	TIME [epoch: 9.52 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22176387751979482		[learning rate: 0.0023884]
	Learning Rate: 0.00238839
	LOSS [training: 0.22176387751979482 | validation: 0.30682681772095277]
	TIME [epoch: 9.5 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21485961773566858		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.21485961773566858 | validation: 0.2533727038054081]
	TIME [epoch: 9.5 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2607375762497934		[learning rate: 0.0023768]
	Learning Rate: 0.00237684
	LOSS [training: 0.2607375762497934 | validation: 0.23679214683569727]
	TIME [epoch: 9.52 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1823906920779267		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.1823906920779267 | validation: 0.2200197098012497]
	TIME [epoch: 9.51 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21441003798827246		[learning rate: 0.0023653]
	Learning Rate: 0.00236535
	LOSS [training: 0.21441003798827246 | validation: 0.8554292265156764]
	TIME [epoch: 9.5 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41405168052372704		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.41405168052372704 | validation: 0.46017069121100834]
	TIME [epoch: 9.51 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26872886739478574		[learning rate: 0.0023539]
	Learning Rate: 0.00235391
	LOSS [training: 0.26872886739478574 | validation: 0.30023292432614024]
	TIME [epoch: 9.53 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22951493660774655		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.22951493660774655 | validation: 0.20527777421868773]
	TIME [epoch: 9.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24413154595950023		[learning rate: 0.0023425]
	Learning Rate: 0.00234252
	LOSS [training: 0.24413154595950023 | validation: 0.3373811487391906]
	TIME [epoch: 9.51 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19414587460905114		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.19414587460905114 | validation: 0.2944457392953054]
	TIME [epoch: 9.51 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2264357234859673		[learning rate: 0.0023312]
	Learning Rate: 0.0023312
	LOSS [training: 0.2264357234859673 | validation: 0.328859684405723]
	TIME [epoch: 9.52 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17783370487291097		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.17783370487291097 | validation: 0.19165974887370799]
	TIME [epoch: 9.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20994044293317332		[learning rate: 0.0023199]
	Learning Rate: 0.00231992
	LOSS [training: 0.20994044293317332 | validation: 0.2543243131045494]
	TIME [epoch: 9.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2979757903112065		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.2979757903112065 | validation: 0.27740124894606766]
	TIME [epoch: 9.53 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24965751271793007		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.24965751271793007 | validation: 0.36196629039627765]
	TIME [epoch: 9.51 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22569269462721575		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.22569269462721575 | validation: 0.30231914586059205]
	TIME [epoch: 9.51 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2889777821377719		[learning rate: 0.0022975]
	Learning Rate: 0.00229754
	LOSS [training: 0.2889777821377719 | validation: 0.25401534751835053]
	TIME [epoch: 9.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22649677834049178		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.22649677834049178 | validation: 0.27808961828461476]
	TIME [epoch: 9.52 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17209793762503336		[learning rate: 0.0022864]
	Learning Rate: 0.00228643
	LOSS [training: 0.17209793762503336 | validation: 0.2201800856076258]
	TIME [epoch: 9.5 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2382183771872975		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.2382183771872975 | validation: 0.2322702990012485]
	TIME [epoch: 9.5 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24377179803371257		[learning rate: 0.0022754]
	Learning Rate: 0.00227537
	LOSS [training: 0.24377179803371257 | validation: 0.2778108166679911]
	TIME [epoch: 9.51 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32199301547047005		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.32199301547047005 | validation: 0.2985979409786696]
	TIME [epoch: 9.51 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3235996476078177		[learning rate: 0.0022644]
	Learning Rate: 0.00226437
	LOSS [training: 0.3235996476078177 | validation: 0.35422174382983196]
	TIME [epoch: 9.51 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2598141544803727		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.2598141544803727 | validation: 0.198413485499069]
	TIME [epoch: 9.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1919073266591755		[learning rate: 0.0022534]
	Learning Rate: 0.00225342
	LOSS [training: 0.1919073266591755 | validation: 0.19885217534640487]
	TIME [epoch: 9.52 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20307334535025467		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.20307334535025467 | validation: 0.18751994957425552]
	TIME [epoch: 9.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19735637672995762		[learning rate: 0.0022425]
	Learning Rate: 0.00224252
	LOSS [training: 0.19735637672995762 | validation: 0.31608994536787544]
	TIME [epoch: 9.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3147659825215926		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.3147659825215926 | validation: 0.42864342381930853]
	TIME [epoch: 9.51 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22890390884266867		[learning rate: 0.0022317]
	Learning Rate: 0.00223168
	LOSS [training: 0.22890390884266867 | validation: 0.4177483439986348]
	TIME [epoch: 9.52 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2894450698973294		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.2894450698973294 | validation: 0.15750661162828666]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_720.pth
	Model improved!!!
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21370993298738786		[learning rate: 0.0022209]
	Learning Rate: 0.00222089
	LOSS [training: 0.21370993298738786 | validation: 0.2053533198214175]
	TIME [epoch: 9.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18156640756322914		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.18156640756322914 | validation: 0.1860112712022548]
	TIME [epoch: 9.51 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17520381105487323		[learning rate: 0.0022101]
	Learning Rate: 0.00221015
	LOSS [training: 0.17520381105487323 | validation: 0.19099371599371956]
	TIME [epoch: 9.52 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17728690867407998		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.17728690867407998 | validation: 0.41199742249321786]
	TIME [epoch: 9.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3081272268459131		[learning rate: 0.0021995]
	Learning Rate: 0.00219946
	LOSS [training: 0.3081272268459131 | validation: 0.2781827398774467]
	TIME [epoch: 9.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2590474770459473		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.2590474770459473 | validation: 0.2877656323470401]
	TIME [epoch: 9.52 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24135515223118378		[learning rate: 0.0021888]
	Learning Rate: 0.00218882
	LOSS [training: 0.24135515223118378 | validation: 0.3397452186039847]
	TIME [epoch: 9.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3353543017665753		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.3353543017665753 | validation: 0.3658179480937055]
	TIME [epoch: 9.5 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156579834019008		[learning rate: 0.0021782]
	Learning Rate: 0.00217824
	LOSS [training: 0.3156579834019008 | validation: 0.4179697878095576]
	TIME [epoch: 9.51 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31977298933924153		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.31977298933924153 | validation: 0.28894921586209327]
	TIME [epoch: 9.52 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24344884359544466		[learning rate: 0.0021677]
	Learning Rate: 0.0021677
	LOSS [training: 0.24344884359544466 | validation: 0.3344052286632344]
	TIME [epoch: 9.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2581613638862306		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.2581613638862306 | validation: 0.3122732819233172]
	TIME [epoch: 9.5 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21804531691567278		[learning rate: 0.0021572]
	Learning Rate: 0.00215722
	LOSS [training: 0.21804531691567278 | validation: 0.21170085850891124]
	TIME [epoch: 9.51 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24360893478210058		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.24360893478210058 | validation: 0.24563781396115525]
	TIME [epoch: 9.51 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26743253197258454		[learning rate: 0.0021468]
	Learning Rate: 0.00214679
	LOSS [training: 0.26743253197258454 | validation: 0.17487399571877155]
	TIME [epoch: 9.51 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22704489982840353		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.22704489982840353 | validation: 0.19669321632954778]
	TIME [epoch: 9.51 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2156772042440457		[learning rate: 0.0021364]
	Learning Rate: 0.00213641
	LOSS [training: 0.2156772042440457 | validation: 0.17722132310529234]
	TIME [epoch: 9.51 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21782551683429863		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.21782551683429863 | validation: 0.35839460022757313]
	TIME [epoch: 9.51 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20907370754188861		[learning rate: 0.0021261]
	Learning Rate: 0.00212608
	LOSS [training: 0.20907370754188861 | validation: 0.471318387715468]
	TIME [epoch: 9.51 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36685822437792054		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.36685822437792054 | validation: 0.31415805098173677]
	TIME [epoch: 9.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27400561207008384		[learning rate: 0.0021158]
	Learning Rate: 0.0021158
	LOSS [training: 0.27400561207008384 | validation: 0.1634746953512376]
	TIME [epoch: 9.52 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1947103770949569		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.1947103770949569 | validation: 0.3735177643405605]
	TIME [epoch: 9.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21263498837600245		[learning rate: 0.0021056]
	Learning Rate: 0.00210556
	LOSS [training: 0.21263498837600245 | validation: 0.26946376062631433]
	TIME [epoch: 9.51 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2721358635951634		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.2721358635951634 | validation: 0.30033737437604535]
	TIME [epoch: 9.51 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23797114359563337		[learning rate: 0.0020954]
	Learning Rate: 0.00209538
	LOSS [training: 0.23797114359563337 | validation: 0.23313567875700839]
	TIME [epoch: 9.51 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16682449989484152		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.16682449989484152 | validation: 0.2377697929275805]
	TIME [epoch: 9.51 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2084121493095313		[learning rate: 0.0020852]
	Learning Rate: 0.00208525
	LOSS [training: 0.2084121493095313 | validation: 0.39134095632233845]
	TIME [epoch: 9.5 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3622733820786886		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.3622733820786886 | validation: 0.2152657362515322]
	TIME [epoch: 9.52 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23889178343319814		[learning rate: 0.0020752]
	Learning Rate: 0.00207517
	LOSS [training: 0.23889178343319814 | validation: 0.2590397041339814]
	TIME [epoch: 9.51 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23763822976733145		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.23763822976733145 | validation: 0.21901349034548667]
	TIME [epoch: 9.51 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27267837972650677		[learning rate: 0.0020651]
	Learning Rate: 0.00206513
	LOSS [training: 0.27267837972650677 | validation: 0.2544458317816275]
	TIME [epoch: 9.51 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32022628612419296		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.32022628612419296 | validation: 0.26932264655149046]
	TIME [epoch: 9.52 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24126070993682905		[learning rate: 0.0020551]
	Learning Rate: 0.00205514
	LOSS [training: 0.24126070993682905 | validation: 0.33706643760164384]
	TIME [epoch: 9.51 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27970199931082085		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.27970199931082085 | validation: 0.4142869048435549]
	TIME [epoch: 9.5 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3325294636018028		[learning rate: 0.0020452]
	Learning Rate: 0.0020452
	LOSS [training: 0.3325294636018028 | validation: 0.29884653798533484]
	TIME [epoch: 9.51 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22208832673988016		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.22208832673988016 | validation: 0.2470660448332996]
	TIME [epoch: 9.52 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19498881260108947		[learning rate: 0.0020353]
	Learning Rate: 0.00203531
	LOSS [training: 0.19498881260108947 | validation: 0.3022327911220897]
	TIME [epoch: 9.51 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26140431426136784		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.26140431426136784 | validation: 0.27661183598245215]
	TIME [epoch: 9.5 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24375709278320334		[learning rate: 0.0020255]
	Learning Rate: 0.00202547
	LOSS [training: 0.24375709278320334 | validation: 0.1933669233383244]
	TIME [epoch: 9.52 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18957505250908296		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.18957505250908296 | validation: 0.1818568387947358]
	TIME [epoch: 9.51 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21012886875980233		[learning rate: 0.0020157]
	Learning Rate: 0.00201568
	LOSS [training: 0.21012886875980233 | validation: 0.21154846025947127]
	TIME [epoch: 9.51 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25458314077626204		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.25458314077626204 | validation: 0.1624345934105171]
	TIME [epoch: 9.54 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1884552911968364		[learning rate: 0.0020059]
	Learning Rate: 0.00200593
	LOSS [training: 0.1884552911968364 | validation: 0.10241997033648716]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_763.pth
	Model improved!!!
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19782145916375565		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.19782145916375565 | validation: 0.2887135898290481]
	TIME [epoch: 9.51 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22288513675474864		[learning rate: 0.0019962]
	Learning Rate: 0.00199623
	LOSS [training: 0.22288513675474864 | validation: 0.19898564582049935]
	TIME [epoch: 9.51 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2303345053265753		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.2303345053265753 | validation: 0.2053470358369925]
	TIME [epoch: 9.52 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2781302157615642		[learning rate: 0.0019866]
	Learning Rate: 0.00198658
	LOSS [training: 0.2781302157615642 | validation: 0.16955633164355546]
	TIME [epoch: 9.51 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3134082259512141		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.3134082259512141 | validation: 0.1937861438687772]
	TIME [epoch: 9.51 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21562622847666701		[learning rate: 0.001977]
	Learning Rate: 0.00197697
	LOSS [training: 0.21562622847666701 | validation: 0.1547166921881265]
	TIME [epoch: 9.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21406025440658288		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.21406025440658288 | validation: 0.15116092343749388]
	TIME [epoch: 9.52 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2400063187576546		[learning rate: 0.0019674]
	Learning Rate: 0.00196741
	LOSS [training: 0.2400063187576546 | validation: 0.17570773963746988]
	TIME [epoch: 9.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21819448922992984		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.21819448922992984 | validation: 0.2715849924433076]
	TIME [epoch: 9.5 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24268200992491368		[learning rate: 0.0019579]
	Learning Rate: 0.0019579
	LOSS [training: 0.24268200992491368 | validation: 0.30197400906450783]
	TIME [epoch: 9.51 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4623321001967192		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.4623321001967192 | validation: 0.2917617623669596]
	TIME [epoch: 9.52 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34666947595534453		[learning rate: 0.0019484]
	Learning Rate: 0.00194843
	LOSS [training: 0.34666947595534453 | validation: 0.767572000047477]
	TIME [epoch: 9.51 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46210191565519293		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.46210191565519293 | validation: 0.3273706905302425]
	TIME [epoch: 9.51 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28190618720845034		[learning rate: 0.001939]
	Learning Rate: 0.00193901
	LOSS [training: 0.28190618720845034 | validation: 0.543223630042107]
	TIME [epoch: 9.52 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3976007728425592		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.3976007728425592 | validation: 0.2627051204182732]
	TIME [epoch: 9.51 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22310024039124077		[learning rate: 0.0019296]
	Learning Rate: 0.00192963
	LOSS [training: 0.22310024039124077 | validation: 0.21585540405608786]
	TIME [epoch: 9.51 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2446855359962749		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.2446855359962749 | validation: 0.24537003005542338]
	TIME [epoch: 9.5 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3558765771461485		[learning rate: 0.0019203]
	Learning Rate: 0.0019203
	LOSS [training: 0.3558765771461485 | validation: 0.24203597045302455]
	TIME [epoch: 9.52 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2823091252990282		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.2823091252990282 | validation: 0.3577332080172161]
	TIME [epoch: 9.51 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26455707058132216		[learning rate: 0.001911]
	Learning Rate: 0.00191101
	LOSS [training: 0.26455707058132216 | validation: 0.14185527839814469]
	TIME [epoch: 9.51 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14852383285229925		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.14852383285229925 | validation: 0.17667476271757665]
	TIME [epoch: 9.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14957660525280564		[learning rate: 0.0019018]
	Learning Rate: 0.00190177
	LOSS [training: 0.14957660525280564 | validation: 0.2999972252331069]
	TIME [epoch: 9.52 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4321884200350821		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.4321884200350821 | validation: 0.5691972141484877]
	TIME [epoch: 9.51 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3348665234200613		[learning rate: 0.0018926]
	Learning Rate: 0.00189257
	LOSS [training: 0.3348665234200613 | validation: 0.2968637156076602]
	TIME [epoch: 9.51 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30446359013002794		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.30446359013002794 | validation: 0.25525388478942956]
	TIME [epoch: 9.52 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.283038673680727		[learning rate: 0.0018834]
	Learning Rate: 0.00188342
	LOSS [training: 0.283038673680727 | validation: 0.21188441853859896]
	TIME [epoch: 9.5 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19789354558814382		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.19789354558814382 | validation: 0.3006997417847231]
	TIME [epoch: 9.5 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2216361191312401		[learning rate: 0.0018743]
	Learning Rate: 0.00187431
	LOSS [training: 0.2216361191312401 | validation: 0.2299923627324807]
	TIME [epoch: 9.51 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22742881469440537		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.22742881469440537 | validation: 0.2582311950674324]
	TIME [epoch: 9.52 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2790410438035735		[learning rate: 0.0018652]
	Learning Rate: 0.00186525
	LOSS [training: 0.2790410438035735 | validation: 0.20792964007721618]
	TIME [epoch: 9.51 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3102242108721705		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.3102242108721705 | validation: 0.32395796789242964]
	TIME [epoch: 9.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3244656273344227		[learning rate: 0.0018562]
	Learning Rate: 0.00185623
	LOSS [training: 0.3244656273344227 | validation: 0.14835607952744667]
	TIME [epoch: 9.5 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4100404593198178		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.4100404593198178 | validation: 0.6605845374822096]
	TIME [epoch: 9.52 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2510078450517189		[learning rate: 0.0018473]
	Learning Rate: 0.00184725
	LOSS [training: 0.2510078450517189 | validation: 0.20525443953632608]
	TIME [epoch: 9.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1978111710406664		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.1978111710406664 | validation: 0.1389533507607789]
	TIME [epoch: 9.5 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2259710219166184		[learning rate: 0.0018383]
	Learning Rate: 0.00183832
	LOSS [training: 0.2259710219166184 | validation: 0.14378080966407733]
	TIME [epoch: 9.52 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21562174949746865		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.21562174949746865 | validation: 0.22477535857756045]
	TIME [epoch: 9.51 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20603620035248654		[learning rate: 0.0018294]
	Learning Rate: 0.00182943
	LOSS [training: 0.20603620035248654 | validation: 0.17831329434224627]
	TIME [epoch: 9.51 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.192762385567088		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.192762385567088 | validation: 0.17467819047533145]
	TIME [epoch: 9.51 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19746283449900331		[learning rate: 0.0018206]
	Learning Rate: 0.00182058
	LOSS [training: 0.19746283449900331 | validation: 0.15509213700898622]
	TIME [epoch: 9.52 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1748577239580215		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.1748577239580215 | validation: 0.20709516406147987]
	TIME [epoch: 9.5 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1844029774251694		[learning rate: 0.0018118]
	Learning Rate: 0.00181178
	LOSS [training: 0.1844029774251694 | validation: 0.12193624182507229]
	TIME [epoch: 9.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15036602864445645		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.15036602864445645 | validation: 0.22591147183643767]
	TIME [epoch: 9.52 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22260628953333628		[learning rate: 0.001803]
	Learning Rate: 0.00180302
	LOSS [training: 0.22260628953333628 | validation: 0.24194243239731697]
	TIME [epoch: 9.52 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25625753772590415		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.25625753772590415 | validation: 0.22080552031940112]
	TIME [epoch: 9.51 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2030200638654978		[learning rate: 0.0017943]
	Learning Rate: 0.0017943
	LOSS [training: 0.2030200638654978 | validation: 0.2057107584462915]
	TIME [epoch: 9.51 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17988381623873476		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.17988381623873476 | validation: 0.22214820660875498]
	TIME [epoch: 9.53 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17779542996367625		[learning rate: 0.0017856]
	Learning Rate: 0.00178562
	LOSS [training: 0.17779542996367625 | validation: 0.14784125662451536]
	TIME [epoch: 9.52 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2103214467171861		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.2103214467171861 | validation: 0.14761703644031365]
	TIME [epoch: 9.51 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18766095666730803		[learning rate: 0.001777]
	Learning Rate: 0.00177699
	LOSS [training: 0.18766095666730803 | validation: 0.19407478897877056]
	TIME [epoch: 9.51 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27823243279977916		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.27823243279977916 | validation: 0.2062380499853296]
	TIME [epoch: 9.52 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1754142610980784		[learning rate: 0.0017684]
	Learning Rate: 0.00176839
	LOSS [training: 0.1754142610980784 | validation: 0.370236794297591]
	TIME [epoch: 9.51 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26458050868238125		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.26458050868238125 | validation: 0.16211140342773078]
	TIME [epoch: 9.51 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17863918653922395		[learning rate: 0.0017598]
	Learning Rate: 0.00175984
	LOSS [training: 0.17863918653922395 | validation: 0.20935849743741075]
	TIME [epoch: 9.51 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1443267488105057		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.1443267488105057 | validation: 0.1968649890193248]
	TIME [epoch: 9.52 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1500505948887858		[learning rate: 0.0017513]
	Learning Rate: 0.00175133
	LOSS [training: 0.1500505948887858 | validation: 0.25709635084331717]
	TIME [epoch: 9.5 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2395497667126269		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.2395497667126269 | validation: 0.3121506849775361]
	TIME [epoch: 9.51 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21395279455072624		[learning rate: 0.0017429]
	Learning Rate: 0.00174286
	LOSS [training: 0.21395279455072624 | validation: 0.5175854844221999]
	TIME [epoch: 9.52 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30685284007900193		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.30685284007900193 | validation: 0.1489517927644923]
	TIME [epoch: 9.51 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15694848360058947		[learning rate: 0.0017344]
	Learning Rate: 0.00173443
	LOSS [training: 0.15694848360058947 | validation: 0.20494840666041403]
	TIME [epoch: 9.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21377291898330988		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.21377291898330988 | validation: 0.13658630897682358]
	TIME [epoch: 9.51 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20960847240486435		[learning rate: 0.001726]
	Learning Rate: 0.00172605
	LOSS [training: 0.20960847240486435 | validation: 0.2939785178370121]
	TIME [epoch: 9.52 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2615669697772915		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.2615669697772915 | validation: 0.2605023244159917]
	TIME [epoch: 9.52 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2181239388171341		[learning rate: 0.0017177]
	Learning Rate: 0.0017177
	LOSS [training: 0.2181239388171341 | validation: 0.19810551367483237]
	TIME [epoch: 9.5 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29514715878114134		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.29514715878114134 | validation: 0.17841889687916138]
	TIME [epoch: 9.5 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18589332345962492		[learning rate: 0.0017094]
	Learning Rate: 0.00170939
	LOSS [training: 0.18589332345962492 | validation: 0.2098119423101011]
	TIME [epoch: 9.52 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28328896663720726		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.28328896663720726 | validation: 0.3060805798288452]
	TIME [epoch: 9.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2466947104991351		[learning rate: 0.0017011]
	Learning Rate: 0.00170113
	LOSS [training: 0.2466947104991351 | validation: 0.319986006029703]
	TIME [epoch: 9.51 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3262382920253019		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.3262382920253019 | validation: 0.2741496472151295]
	TIME [epoch: 9.52 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22703260091892385		[learning rate: 0.0016929]
	Learning Rate: 0.0016929
	LOSS [training: 0.22703260091892385 | validation: 0.2334187143513809]
	TIME [epoch: 9.5 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18151892385152296		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.18151892385152296 | validation: 0.16221833413201422]
	TIME [epoch: 9.5 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17203975914403072		[learning rate: 0.0016847]
	Learning Rate: 0.00168471
	LOSS [training: 0.17203975914403072 | validation: 0.17302238989361474]
	TIME [epoch: 9.51 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22976401250369372		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.22976401250369372 | validation: 0.15062543215821658]
	TIME [epoch: 9.52 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28535165612510427		[learning rate: 0.0016766]
	Learning Rate: 0.00167657
	LOSS [training: 0.28535165612510427 | validation: 0.16814838895312448]
	TIME [epoch: 9.5 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2620185540355821		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.2620185540355821 | validation: 0.24886347034109652]
	TIME [epoch: 9.5 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21811057998399547		[learning rate: 0.0016685]
	Learning Rate: 0.00166846
	LOSS [training: 0.21811057998399547 | validation: 0.19097193821771583]
	TIME [epoch: 9.5 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15778332828585762		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.15778332828585762 | validation: 0.14892330157518038]
	TIME [epoch: 9.51 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16689240207680328		[learning rate: 0.0016604]
	Learning Rate: 0.00166039
	LOSS [training: 0.16689240207680328 | validation: 0.24915717572566734]
	TIME [epoch: 9.5 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17461737932462373		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.17461737932462373 | validation: 0.19334238622381772]
	TIME [epoch: 9.5 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2138090081682357		[learning rate: 0.0016524]
	Learning Rate: 0.00165236
	LOSS [training: 0.2138090081682357 | validation: 0.1792125271603637]
	TIME [epoch: 9.51 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16467158838050594		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.16467158838050594 | validation: 0.21703142670186115]
	TIME [epoch: 9.51 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15727372948935447		[learning rate: 0.0016444]
	Learning Rate: 0.00164437
	LOSS [training: 0.15727372948935447 | validation: 0.14101188699529224]
	TIME [epoch: 9.49 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17618716819176375		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.17618716819176375 | validation: 0.2856539385641817]
	TIME [epoch: 9.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1668340439523756		[learning rate: 0.0016364]
	Learning Rate: 0.00163642
	LOSS [training: 0.1668340439523756 | validation: 0.19049724771267998]
	TIME [epoch: 9.51 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17642060225171335		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.17642060225171335 | validation: 0.19677415479091223]
	TIME [epoch: 9.5 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22132460482607078		[learning rate: 0.0016285]
	Learning Rate: 0.00162851
	LOSS [training: 0.22132460482607078 | validation: 0.16064089173837143]
	TIME [epoch: 9.49 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24289875547513953		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.24289875547513953 | validation: 0.17374870066563808]
	TIME [epoch: 9.52 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22787588458105068		[learning rate: 0.0016206]
	Learning Rate: 0.00162063
	LOSS [training: 0.22787588458105068 | validation: 0.19713898620382847]
	TIME [epoch: 9.51 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1952317227750921		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.1952317227750921 | validation: 0.1807386167825268]
	TIME [epoch: 9.5 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1559457186354376		[learning rate: 0.0016128]
	Learning Rate: 0.00161279
	LOSS [training: 0.1559457186354376 | validation: 0.14943500973590904]
	TIME [epoch: 9.5 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14708477678563314		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.14708477678563314 | validation: 0.2625806920448527]
	TIME [epoch: 9.52 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16513161115775357		[learning rate: 0.001605]
	Learning Rate: 0.001605
	LOSS [training: 0.16513161115775357 | validation: 0.5615146066936787]
	TIME [epoch: 9.5 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2811949294491233		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.2811949294491233 | validation: 0.17305457515868775]
	TIME [epoch: 9.5 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2712884781933551		[learning rate: 0.0015972]
	Learning Rate: 0.00159723
	LOSS [training: 0.2712884781933551 | validation: 0.27913724601722273]
	TIME [epoch: 9.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2194175515845705		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.2194175515845705 | validation: 0.46559106316906723]
	TIME [epoch: 9.51 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5074905966677875		[learning rate: 0.0015895]
	Learning Rate: 0.00158951
	LOSS [training: 0.5074905966677875 | validation: 0.21895165418714385]
	TIME [epoch: 9.5 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2447349023833616		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.2447349023833616 | validation: 0.20885046439123692]
	TIME [epoch: 9.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2499188120046551		[learning rate: 0.0015818]
	Learning Rate: 0.00158182
	LOSS [training: 0.2499188120046551 | validation: 0.12446416985181079]
	TIME [epoch: 9.51 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15706272448218403		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.15706272448218403 | validation: 0.15411955865842697]
	TIME [epoch: 9.52 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17428639708373317		[learning rate: 0.0015742]
	Learning Rate: 0.00157417
	LOSS [training: 0.17428639708373317 | validation: 0.28080646499447187]
	TIME [epoch: 9.5 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21672460336212057		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.21672460336212057 | validation: 0.15941906834567315]
	TIME [epoch: 9.5 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20737745616122155		[learning rate: 0.0015666]
	Learning Rate: 0.00156656
	LOSS [training: 0.20737745616122155 | validation: 0.2675939162516826]
	TIME [epoch: 9.52 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17082535356477407		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.17082535356477407 | validation: 0.25799040752265645]
	TIME [epoch: 9.5 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2544577336133706		[learning rate: 0.001559]
	Learning Rate: 0.00155899
	LOSS [training: 0.2544577336133706 | validation: 0.2209652191794999]
	TIME [epoch: 9.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22609618482826072		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.22609618482826072 | validation: 0.269206543718958]
	TIME [epoch: 9.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.192508646280644		[learning rate: 0.0015514]
	Learning Rate: 0.00155145
	LOSS [training: 0.192508646280644 | validation: 0.19874324175920766]
	TIME [epoch: 9.52 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15878502030739466		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.15878502030739466 | validation: 0.5814628142450662]
	TIME [epoch: 9.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3320594498359879		[learning rate: 0.0015439]
	Learning Rate: 0.00154394
	LOSS [training: 0.3320594498359879 | validation: 0.11648548931638651]
	TIME [epoch: 9.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15452626990768403		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.15452626990768403 | validation: 0.21568244589152052]
	TIME [epoch: 9.51 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1803656977487209		[learning rate: 0.0015365]
	Learning Rate: 0.00153648
	LOSS [training: 0.1803656977487209 | validation: 0.17282347195770328]
	TIME [epoch: 9.51 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16960348516615606		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.16960348516615606 | validation: 0.1981280194770093]
	TIME [epoch: 9.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1965828703539078		[learning rate: 0.001529]
	Learning Rate: 0.00152905
	LOSS [training: 0.1965828703539078 | validation: 0.14031416180298675]
	TIME [epoch: 9.5 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1865756234972356		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.1865756234972356 | validation: 0.19063811460798338]
	TIME [epoch: 9.51 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26459648608321357		[learning rate: 0.0015217]
	Learning Rate: 0.00152165
	LOSS [training: 0.26459648608321357 | validation: 0.11188426171094167]
	TIME [epoch: 9.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16984489134873154		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.16984489134873154 | validation: 0.17852392286660948]
	TIME [epoch: 9.49 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21645384589615527		[learning rate: 0.0015143]
	Learning Rate: 0.00151429
	LOSS [training: 0.21645384589615527 | validation: 0.13196912734453212]
	TIME [epoch: 9.5 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12000982701354528		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.12000982701354528 | validation: 0.15205190834562643]
	TIME [epoch: 9.52 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13275981306141768		[learning rate: 0.001507]
	Learning Rate: 0.00150697
	LOSS [training: 0.13275981306141768 | validation: 0.335666266553008]
	TIME [epoch: 9.5 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5553803551155582		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.5553803551155582 | validation: 0.3560196925699124]
	TIME [epoch: 9.5 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20683430779734602		[learning rate: 0.0014997]
	Learning Rate: 0.00149968
	LOSS [training: 0.20683430779734602 | validation: 0.14667514975549342]
	TIME [epoch: 9.51 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13443521561000765		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.13443521561000765 | validation: 0.16065466976193196]
	TIME [epoch: 9.5 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16647690762266906		[learning rate: 0.0014924]
	Learning Rate: 0.00149243
	LOSS [training: 0.16647690762266906 | validation: 0.13593422226764024]
	TIME [epoch: 9.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11801247536699744		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.11801247536699744 | validation: 0.20272296757431973]
	TIME [epoch: 9.5 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24318349165796294		[learning rate: 0.0014852]
	Learning Rate: 0.00148522
	LOSS [training: 0.24318349165796294 | validation: 0.1462642517960241]
	TIME [epoch: 9.52 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14205633493567518		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.14205633493567518 | validation: 0.12634658784950287]
	TIME [epoch: 9.51 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17222326051652204		[learning rate: 0.001478]
	Learning Rate: 0.00147803
	LOSS [training: 0.17222326051652204 | validation: 0.1334239046781203]
	TIME [epoch: 9.5 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17201533563235727		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.17201533563235727 | validation: 0.19502900314547716]
	TIME [epoch: 9.5 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29488041073963045		[learning rate: 0.0014709]
	Learning Rate: 0.00147089
	LOSS [training: 0.29488041073963045 | validation: 0.16612356034723993]
	TIME [epoch: 9.51 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1379977404055389		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.1379977404055389 | validation: 0.17519373631260202]
	TIME [epoch: 9.51 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24982180963523862		[learning rate: 0.0014638]
	Learning Rate: 0.00146377
	LOSS [training: 0.24982180963523862 | validation: 0.16248211092492398]
	TIME [epoch: 9.5 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14427009673020166		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.14427009673020166 | validation: 0.2136176389462028]
	TIME [epoch: 9.51 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15830556660573425		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.15830556660573425 | validation: 0.1631095541915436]
	TIME [epoch: 9.51 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1591350150425784		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.1591350150425784 | validation: 0.24385993275303755]
	TIME [epoch: 9.5 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16480084822587857		[learning rate: 0.0014497]
	Learning Rate: 0.00144965
	LOSS [training: 0.16480084822587857 | validation: 0.1798088113747335]
	TIME [epoch: 9.5 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12428660470091572		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.12428660470091572 | validation: 0.2368784350811918]
	TIME [epoch: 9.52 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15745369273508578		[learning rate: 0.0014426]
	Learning Rate: 0.00144264
	LOSS [training: 0.15745369273508578 | validation: 0.2664713401037112]
	TIME [epoch: 9.51 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17665209319653943		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.17665209319653943 | validation: 0.1988979897200092]
	TIME [epoch: 9.5 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18865478826692217		[learning rate: 0.0014357]
	Learning Rate: 0.00143566
	LOSS [training: 0.18865478826692217 | validation: 0.22219317391734345]
	TIME [epoch: 9.5 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.299629912377376		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.299629912377376 | validation: 0.25610097129647125]
	TIME [epoch: 9.52 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24851646627798923		[learning rate: 0.0014287]
	Learning Rate: 0.00142872
	LOSS [training: 0.24851646627798923 | validation: 0.24179368687808242]
	TIME [epoch: 9.5 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19594661882142667		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.19594661882142667 | validation: 0.17688008166447466]
	TIME [epoch: 9.5 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2657663032742065		[learning rate: 0.0014218]
	Learning Rate: 0.00142181
	LOSS [training: 0.2657663032742065 | validation: 0.18382900620814013]
	TIME [epoch: 9.51 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21167410685253749		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.21167410685253749 | validation: 0.19408788866316784]
	TIME [epoch: 9.51 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17796685874247553		[learning rate: 0.0014149]
	Learning Rate: 0.00141494
	LOSS [training: 0.17796685874247553 | validation: 0.2813079487433475]
	TIME [epoch: 9.5 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2516436536429221		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.2516436536429221 | validation: 0.2759993881853897]
	TIME [epoch: 9.51 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21847222358199656		[learning rate: 0.0014081]
	Learning Rate: 0.00140809
	LOSS [training: 0.21847222358199656 | validation: 0.19719515713162244]
	TIME [epoch: 9.52 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1449680383985978		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.1449680383985978 | validation: 0.17260419472580865]
	TIME [epoch: 9.51 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.169111045147506		[learning rate: 0.0014013]
	Learning Rate: 0.00140128
	LOSS [training: 0.169111045147506 | validation: 0.2585353268460468]
	TIME [epoch: 9.51 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1542525140968404		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.1542525140968404 | validation: 0.28035367134528116]
	TIME [epoch: 9.5 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19826937039208184		[learning rate: 0.0013945]
	Learning Rate: 0.00139451
	LOSS [training: 0.19826937039208184 | validation: 0.17003724237200502]
	TIME [epoch: 9.52 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16068865101741728		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.16068865101741728 | validation: 0.1342324851186728]
	TIME [epoch: 9.51 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475749538285277		[learning rate: 0.0013878]
	Learning Rate: 0.00138776
	LOSS [training: 0.1475749538285277 | validation: 0.22383920295116264]
	TIME [epoch: 9.51 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14145951986458666		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.14145951986458666 | validation: 0.30051507835711194]
	TIME [epoch: 9.51 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19100010179971488		[learning rate: 0.0013811]
	Learning Rate: 0.00138105
	LOSS [training: 0.19100010179971488 | validation: 0.266098330693026]
	TIME [epoch: 9.52 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17569601026601434		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.17569601026601434 | validation: 0.5682987925231613]
	TIME [epoch: 9.5 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2732100568239752		[learning rate: 0.0013744]
	Learning Rate: 0.00137437
	LOSS [training: 0.2732100568239752 | validation: 0.22348629309534537]
	TIME [epoch: 9.51 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18717213848108627		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.18717213848108627 | validation: 0.26487792263500537]
	TIME [epoch: 9.52 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19872790924621425		[learning rate: 0.0013677]
	Learning Rate: 0.00136773
	LOSS [training: 0.19872790924621425 | validation: 0.3880617240216607]
	TIME [epoch: 9.51 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23982249613991477		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.23982249613991477 | validation: 0.21817202688661347]
	TIME [epoch: 9.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19684959250979478		[learning rate: 0.0013611]
	Learning Rate: 0.00136111
	LOSS [training: 0.19684959250979478 | validation: 0.18070054040950478]
	TIME [epoch: 9.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.200246825359077		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.200246825359077 | validation: 0.23236936899288752]
	TIME [epoch: 9.52 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21936336782239613		[learning rate: 0.0013545]
	Learning Rate: 0.00135453
	LOSS [training: 0.21936336782239613 | validation: 0.22973621187045307]
	TIME [epoch: 9.51 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2346186348487243		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.2346186348487243 | validation: 0.3435060373058639]
	TIME [epoch: 9.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31265647920874956		[learning rate: 0.001348]
	Learning Rate: 0.00134798
	LOSS [training: 0.31265647920874956 | validation: 0.22833359605479606]
	TIME [epoch: 9.52 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21736918778052416		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.21736918778052416 | validation: 0.19733604490642428]
	TIME [epoch: 9.51 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15667211015612711		[learning rate: 0.0013415]
	Learning Rate: 0.00134146
	LOSS [training: 0.15667211015612711 | validation: 0.2013471942169443]
	TIME [epoch: 9.51 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14174582283172588		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.14174582283172588 | validation: 0.1293782874406932]
	TIME [epoch: 9.5 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14133615930133817		[learning rate: 0.001335]
	Learning Rate: 0.00133498
	LOSS [training: 0.14133615930133817 | validation: 0.20872733705413907]
	TIME [epoch: 9.52 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15935002314480926		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.15935002314480926 | validation: 0.19034424026902955]
	TIME [epoch: 9.51 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18354224471808184		[learning rate: 0.0013285]
	Learning Rate: 0.00132852
	LOSS [training: 0.18354224471808184 | validation: 0.2135668124990411]
	TIME [epoch: 9.5 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1839773313108947		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.1839773313108947 | validation: 0.1328891308553438]
	TIME [epoch: 9.5 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16794812903193268		[learning rate: 0.0013221]
	Learning Rate: 0.0013221
	LOSS [training: 0.16794812903193268 | validation: 0.1744408795279643]
	TIME [epoch: 9.53 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13560766463733778		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.13560766463733778 | validation: 0.16221371159508388]
	TIME [epoch: 9.5 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12131642212348812		[learning rate: 0.0013157]
	Learning Rate: 0.0013157
	LOSS [training: 0.12131642212348812 | validation: 0.16686355560012153]
	TIME [epoch: 9.51 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.193258866738559		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.193258866738559 | validation: 0.1280168490935321]
	TIME [epoch: 9.51 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1149627267467542		[learning rate: 0.0013093]
	Learning Rate: 0.00130934
	LOSS [training: 0.1149627267467542 | validation: 0.15179474022142284]
	TIME [epoch: 9.52 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14507621335150245		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.14507621335150245 | validation: 0.3411030995746441]
	TIME [epoch: 9.5 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1978685217927443		[learning rate: 0.001303]
	Learning Rate: 0.00130301
	LOSS [training: 0.1978685217927443 | validation: 0.176757289859745]
	TIME [epoch: 9.5 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17068495733279151		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.17068495733279151 | validation: 0.15513784218289778]
	TIME [epoch: 9.52 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.204387800918649		[learning rate: 0.0012967]
	Learning Rate: 0.00129671
	LOSS [training: 0.204387800918649 | validation: 0.24105433517942992]
	TIME [epoch: 9.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1572279737614912		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.1572279737614912 | validation: 0.3184659409973066]
	TIME [epoch: 9.5 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19661417090193872		[learning rate: 0.0012904]
	Learning Rate: 0.00129044
	LOSS [training: 0.19661417090193872 | validation: 0.19443151494067068]
	TIME [epoch: 9.51 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19514456116891593		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.19514456116891593 | validation: 0.34824408350623487]
	TIME [epoch: 9.52 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22585863142285284		[learning rate: 0.0012842]
	Learning Rate: 0.0012842
	LOSS [training: 0.22585863142285284 | validation: 0.20089843860952603]
	TIME [epoch: 9.51 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16704030086621433		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.16704030086621433 | validation: 0.14139838721187686]
	TIME [epoch: 9.5 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21527495481420136		[learning rate: 0.001278]
	Learning Rate: 0.00127799
	LOSS [training: 0.21527495481420136 | validation: 0.2584801210673286]
	TIME [epoch: 9.51 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1945450917513499		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.1945450917513499 | validation: 0.1492881206135322]
	TIME [epoch: 9.52 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17939257345146536		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.17939257345146536 | validation: 0.1113158899284097]
	TIME [epoch: 9.51 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1351408767970768		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.1351408767970768 | validation: 0.15552194401862512]
	TIME [epoch: 9.5 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1371652876593177		[learning rate: 0.0012657]
	Learning Rate: 0.00126566
	LOSS [training: 0.1371652876593177 | validation: 0.17085384617800004]
	TIME [epoch: 9.52 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17097692331068204		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.17097692331068204 | validation: 0.25058791781099354]
	TIME [epoch: 9.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562856275592283		[learning rate: 0.0012595]
	Learning Rate: 0.00125954
	LOSS [training: 0.1562856275592283 | validation: 0.1980168699230118]
	TIME [epoch: 9.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22574088965168224		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.22574088965168224 | validation: 0.2667810727735919]
	TIME [epoch: 9.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2140282489244524		[learning rate: 0.0012534]
	Learning Rate: 0.00125344
	LOSS [training: 0.2140282489244524 | validation: 0.30491509430545816]
	TIME [epoch: 9.53 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31381188869132154		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.31381188869132154 | validation: 0.3473312416325655]
	TIME [epoch: 9.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23977297176506038		[learning rate: 0.0012474]
	Learning Rate: 0.00124738
	LOSS [training: 0.23977297176506038 | validation: 0.3419930497984319]
	TIME [epoch: 9.5 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20522540180713414		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.20522540180713414 | validation: 0.23283126049149303]
	TIME [epoch: 9.51 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20702290643462046		[learning rate: 0.0012414]
	Learning Rate: 0.00124135
	LOSS [training: 0.20702290643462046 | validation: 0.13412496887953446]
	TIME [epoch: 9.52 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2199562465548872		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.2199562465548872 | validation: 0.18311171735266768]
	TIME [epoch: 9.51 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15912635107656142		[learning rate: 0.0012353]
	Learning Rate: 0.00123535
	LOSS [training: 0.15912635107656142 | validation: 0.13560353084285875]
	TIME [epoch: 9.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16998433763026224		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.16998433763026224 | validation: 0.1808502335166954]
	TIME [epoch: 9.52 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16447372022565312		[learning rate: 0.0012294]
	Learning Rate: 0.00122937
	LOSS [training: 0.16447372022565312 | validation: 0.2198839900737549]
	TIME [epoch: 9.51 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18080246204627343		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.18080246204627343 | validation: 0.15497485807971528]
	TIME [epoch: 9.5 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14830779128623192		[learning rate: 0.0012234]
	Learning Rate: 0.00122343
	LOSS [training: 0.14830779128623192 | validation: 0.14141058938958978]
	TIME [epoch: 9.5 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13266217786588913		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.13266217786588913 | validation: 0.13992311420146905]
	TIME [epoch: 9.52 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12006112096226182		[learning rate: 0.0012175]
	Learning Rate: 0.00121751
	LOSS [training: 0.12006112096226182 | validation: 0.14357453271859683]
	TIME [epoch: 9.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18291924765833797		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.18291924765833797 | validation: 0.3377420629988586]
	TIME [epoch: 9.51 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.240197595443096		[learning rate: 0.0012116]
	Learning Rate: 0.00121163
	LOSS [training: 0.240197595443096 | validation: 0.19444422626448038]
	TIME [epoch: 9.51 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1697869589438507		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.1697869589438507 | validation: 0.19752581057235907]
	TIME [epoch: 9.51 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15803978907396127		[learning rate: 0.0012058]
	Learning Rate: 0.00120577
	LOSS [training: 0.15803978907396127 | validation: 0.16289179282996707]
	TIME [epoch: 9.5 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13316954834914935		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.13316954834914935 | validation: 0.13681615807769995]
	TIME [epoch: 9.5 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18807291510421872		[learning rate: 0.0011999]
	Learning Rate: 0.00119994
	LOSS [training: 0.18807291510421872 | validation: 0.13649916282553118]
	TIME [epoch: 9.52 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12577552968515765		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.12577552968515765 | validation: 0.18277904541877513]
	TIME [epoch: 9.51 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20537974360421046		[learning rate: 0.0011941]
	Learning Rate: 0.00119413
	LOSS [training: 0.20537974360421046 | validation: 0.3379503803006671]
	TIME [epoch: 9.51 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2733813620031228		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.2733813620031228 | validation: 0.22445974125785223]
	TIME [epoch: 9.51 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.232613335869953		[learning rate: 0.0011884]
	Learning Rate: 0.00118836
	LOSS [training: 0.232613335869953 | validation: 0.2249318399557229]
	TIME [epoch: 9.53 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23185353262027694		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.23185353262027694 | validation: 0.2096318994402306]
	TIME [epoch: 9.51 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18970308863794766		[learning rate: 0.0011826]
	Learning Rate: 0.00118261
	LOSS [training: 0.18970308863794766 | validation: 0.25373590588535744]
	TIME [epoch: 9.5 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15355548759327386		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.15355548759327386 | validation: 0.1802766567883819]
	TIME [epoch: 9.52 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1752853886291408		[learning rate: 0.0011769]
	Learning Rate: 0.00117689
	LOSS [training: 0.1752853886291408 | validation: 0.29925732217211776]
	TIME [epoch: 9.51 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1943960806974397		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.1943960806974397 | validation: 0.23642632194833715]
	TIME [epoch: 9.51 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2796397845580042		[learning rate: 0.0011712]
	Learning Rate: 0.0011712
	LOSS [training: 0.2796397845580042 | validation: 0.14320455070014096]
	TIME [epoch: 9.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18600575740890082		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.18600575740890082 | validation: 0.1797974273038432]
	TIME [epoch: 9.52 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13009098361783375		[learning rate: 0.0011655]
	Learning Rate: 0.00116554
	LOSS [training: 0.13009098361783375 | validation: 0.33619144993960964]
	TIME [epoch: 9.51 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20358126824437583		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.20358126824437583 | validation: 0.1831519665729735]
	TIME [epoch: 9.51 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1452368157152797		[learning rate: 0.0011599]
	Learning Rate: 0.0011599
	LOSS [training: 0.1452368157152797 | validation: 0.24724282103117362]
	TIME [epoch: 9.51 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.217645922230081		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.217645922230081 | validation: 0.31788603104817303]
	TIME [epoch: 9.53 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19730664583032329		[learning rate: 0.0011543]
	Learning Rate: 0.00115429
	LOSS [training: 0.19730664583032329 | validation: 0.5308546191665683]
	TIME [epoch: 9.5 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33230561716232143		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.33230561716232143 | validation: 0.22814563002521468]
	TIME [epoch: 9.51 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18643459796165243		[learning rate: 0.0011487]
	Learning Rate: 0.00114871
	LOSS [training: 0.18643459796165243 | validation: 0.1818872622891562]
	TIME [epoch: 9.52 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14224624622211926		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.14224624622211926 | validation: 0.18387140597569812]
	TIME [epoch: 9.5 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18532078054365644		[learning rate: 0.0011432]
	Learning Rate: 0.00114316
	LOSS [training: 0.18532078054365644 | validation: 0.1727625403833794]
	TIME [epoch: 9.51 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12541176307066887		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.12541176307066887 | validation: 0.13230245729650597]
	TIME [epoch: 9.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15971367375840415		[learning rate: 0.0011376]
	Learning Rate: 0.00113763
	LOSS [training: 0.15971367375840415 | validation: 0.3143585234780831]
	TIME [epoch: 9.52 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19117338282085694		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.19117338282085694 | validation: 0.27800713067711263]
	TIME [epoch: 9.5 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21199848572619992		[learning rate: 0.0011321]
	Learning Rate: 0.00113213
	LOSS [training: 0.21199848572619992 | validation: 0.1889152883272627]
	TIME [epoch: 9.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16121430154140085		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.16121430154140085 | validation: 0.21122511652439221]
	TIME [epoch: 9.5 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2069280697976		[learning rate: 0.0011267]
	Learning Rate: 0.00112665
	LOSS [training: 0.2069280697976 | validation: 0.19687696560604084]
	TIME [epoch: 9.52 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23548821400932654		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.23548821400932654 | validation: 0.2734236158721727]
	TIME [epoch: 9.51 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2348195994578576		[learning rate: 0.0011212]
	Learning Rate: 0.0011212
	LOSS [training: 0.2348195994578576 | validation: 0.22922311784890576]
	TIME [epoch: 9.5 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21011886231740823		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.21011886231740823 | validation: 0.3251166077287729]
	TIME [epoch: 9.52 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24997704956379171		[learning rate: 0.0011158]
	Learning Rate: 0.00111578
	LOSS [training: 0.24997704956379171 | validation: 0.21876139479459553]
	TIME [epoch: 9.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16418484384607257		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.16418484384607257 | validation: 0.2359301165761716]
	TIME [epoch: 9.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16175481859621982		[learning rate: 0.0011104]
	Learning Rate: 0.00111039
	LOSS [training: 0.16175481859621982 | validation: 0.17734199636254958]
	TIME [epoch: 9.5 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17957894991976356		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.17957894991976356 | validation: 0.19518985017501503]
	TIME [epoch: 9.51 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19120618862747452		[learning rate: 0.001105]
	Learning Rate: 0.00110502
	LOSS [training: 0.19120618862747452 | validation: 0.2220842443862066]
	TIME [epoch: 9.51 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14868035480480477		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.14868035480480477 | validation: 0.1744586148092115]
	TIME [epoch: 9.51 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14528060388015224		[learning rate: 0.0010997]
	Learning Rate: 0.00109967
	LOSS [training: 0.14528060388015224 | validation: 0.15374808474882298]
	TIME [epoch: 9.5 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16449256556817668		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.16449256556817668 | validation: 0.25777848117208]
	TIME [epoch: 9.52 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1788830408521101		[learning rate: 0.0010944]
	Learning Rate: 0.00109435
	LOSS [training: 0.1788830408521101 | validation: 0.2668681328269855]
	TIME [epoch: 9.51 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23572576076664448		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.23572576076664448 | validation: 0.14139646476577802]
	TIME [epoch: 9.52 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18276332861024977		[learning rate: 0.0010891]
	Learning Rate: 0.00108906
	LOSS [training: 0.18276332861024977 | validation: 0.1631462502235601]
	TIME [epoch: 9.52 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537723280316455		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.1537723280316455 | validation: 0.16785979401693113]
	TIME [epoch: 9.51 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14334999639930676		[learning rate: 0.0010838]
	Learning Rate: 0.0010838
	LOSS [training: 0.14334999639930676 | validation: 0.1499821404731701]
	TIME [epoch: 9.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1578800040512326		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.1578800040512326 | validation: 0.1875618944688293]
	TIME [epoch: 9.5 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22007754812337468		[learning rate: 0.0010786]
	Learning Rate: 0.00107855
	LOSS [training: 0.22007754812337468 | validation: 0.18496591421936834]
	TIME [epoch: 9.53 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23675357813577716		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.23675357813577716 | validation: 0.17031139458584413]
	TIME [epoch: 9.51 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16498084217279183		[learning rate: 0.0010733]
	Learning Rate: 0.00107334
	LOSS [training: 0.16498084217279183 | validation: 0.36955327738058935]
	TIME [epoch: 9.51 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24474547554824527		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.24474547554824527 | validation: 0.14782055075560283]
	TIME [epoch: 9.51 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14215271776969574		[learning rate: 0.0010681]
	Learning Rate: 0.00106815
	LOSS [training: 0.14215271776969574 | validation: 0.1581677590869965]
	TIME [epoch: 9.53 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13766941961527385		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.13766941961527385 | validation: 0.15774117453370712]
	TIME [epoch: 9.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15808041334861384		[learning rate: 0.001063]
	Learning Rate: 0.00106298
	LOSS [training: 0.15808041334861384 | validation: 0.160756014238178]
	TIME [epoch: 9.51 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1892989257364524		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.1892989257364524 | validation: 0.19468467796253305]
	TIME [epoch: 9.53 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17610925963895666		[learning rate: 0.0010578]
	Learning Rate: 0.00105784
	LOSS [training: 0.17610925963895666 | validation: 0.19580603234747415]
	TIME [epoch: 9.51 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14283109515153772		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.14283109515153772 | validation: 0.15121448962453016]
	TIME [epoch: 9.5 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12559361509442646		[learning rate: 0.0010527]
	Learning Rate: 0.00105273
	LOSS [training: 0.12559361509442646 | validation: 0.12716510969017977]
	TIME [epoch: 9.5 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13949067370378132		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.13949067370378132 | validation: 0.19065349704463852]
	TIME [epoch: 9.52 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21843085800724954		[learning rate: 0.0010476]
	Learning Rate: 0.00104764
	LOSS [training: 0.21843085800724954 | validation: 0.31396592082052016]
	TIME [epoch: 9.5 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2228856648189423		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.2228856648189423 | validation: 0.3445890928162392]
	TIME [epoch: 9.51 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2165112870669197		[learning rate: 0.0010426]
	Learning Rate: 0.00104257
	LOSS [training: 0.2165112870669197 | validation: 0.19802893043897352]
	TIME [epoch: 9.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1954501110434773		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.1954501110434773 | validation: 0.19824904293822931]
	TIME [epoch: 9.52 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13426594652909912		[learning rate: 0.0010375]
	Learning Rate: 0.00103753
	LOSS [training: 0.13426594652909912 | validation: 0.18738784647875995]
	TIME [epoch: 9.51 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11318162816519953		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.11318162816519953 | validation: 0.12699662752753368]
	TIME [epoch: 9.5 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10570949081304792		[learning rate: 0.0010325]
	Learning Rate: 0.00103251
	LOSS [training: 0.10570949081304792 | validation: 0.1785240528036739]
	TIME [epoch: 9.51 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13876080854103537		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.13876080854103537 | validation: 0.12792214488228873]
	TIME [epoch: 9.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12109848294772889		[learning rate: 0.0010275]
	Learning Rate: 0.00102752
	LOSS [training: 0.12109848294772889 | validation: 0.17577109894368068]
	TIME [epoch: 9.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12785102290207775		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.12785102290207775 | validation: 0.11821881919289037]
	TIME [epoch: 9.5 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1446987245911725		[learning rate: 0.0010225]
	Learning Rate: 0.00102255
	LOSS [training: 0.1446987245911725 | validation: 0.24835955890048947]
	TIME [epoch: 9.52 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16767757027287095		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.16767757027287095 | validation: 0.1603916043441987]
	TIME [epoch: 9.51 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12992756756039697		[learning rate: 0.0010176]
	Learning Rate: 0.0010176
	LOSS [training: 0.12992756756039697 | validation: 0.18554678593676688]
	TIME [epoch: 9.5 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15560342105945701		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.15560342105945701 | validation: 0.2524660518500952]
	TIME [epoch: 9.51 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14041865441550216		[learning rate: 0.0010127]
	Learning Rate: 0.00101268
	LOSS [training: 0.14041865441550216 | validation: 0.09983074210083012]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1045.pth
	Model improved!!!
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1076728931375173		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.1076728931375173 | validation: 0.12868141461878982]
	TIME [epoch: 9.51 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1856785507852498		[learning rate: 0.0010078]
	Learning Rate: 0.00100779
	LOSS [training: 0.1856785507852498 | validation: 0.1484943275895825]
	TIME [epoch: 9.5 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15168851436182768		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.15168851436182768 | validation: 0.15881993996055255]
	TIME [epoch: 9.52 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13170202995598607		[learning rate: 0.0010029]
	Learning Rate: 0.00100291
	LOSS [training: 0.13170202995598607 | validation: 0.1041924204211659]
	TIME [epoch: 9.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10908196804356292		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.10908196804356292 | validation: 0.12825402142546452]
	TIME [epoch: 9.5 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12028241322782773		[learning rate: 0.00099806]
	Learning Rate: 0.000998063
	LOSS [training: 0.12028241322782773 | validation: 0.24641101124453016]
	TIME [epoch: 9.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12050792062639577		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.12050792062639577 | validation: 0.11943817018211013]
	TIME [epoch: 9.52 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10739304346879261		[learning rate: 0.00099324]
	Learning Rate: 0.000993237
	LOSS [training: 0.10739304346879261 | validation: 0.09436376771216255]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1053.pth
	Model improved!!!
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12965270911078192		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.12965270911078192 | validation: 0.1539882849819016]
	TIME [epoch: 9.51 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09592560562286154		[learning rate: 0.00098843]
	Learning Rate: 0.000988433
	LOSS [training: 0.09592560562286154 | validation: 0.1022048402687397]
	TIME [epoch: 9.51 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08997186407366732		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.08997186407366732 | validation: 0.1287718342378591]
	TIME [epoch: 9.52 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11277883268132097		[learning rate: 0.00098365]
	Learning Rate: 0.000983653
	LOSS [training: 0.11277883268132097 | validation: 0.13883521728968093]
	TIME [epoch: 9.5 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10252304682722868		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.10252304682722868 | validation: 0.128492748970693]
	TIME [epoch: 9.5 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12625443428679445		[learning rate: 0.0009789]
	Learning Rate: 0.000978897
	LOSS [training: 0.12625443428679445 | validation: 0.20628507050684186]
	TIME [epoch: 9.51 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13405658524950453		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.13405658524950453 | validation: 0.15481314154176656]
	TIME [epoch: 9.51 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15605758739361367		[learning rate: 0.00097416]
	Learning Rate: 0.000974163
	LOSS [training: 0.15605758739361367 | validation: 0.19714573640969388]
	TIME [epoch: 9.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13635545683253203		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.13635545683253203 | validation: 0.17013207927056218]
	TIME [epoch: 9.51 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14870429352096942		[learning rate: 0.00096945]
	Learning Rate: 0.000969452
	LOSS [training: 0.14870429352096942 | validation: 0.12505387954335828]
	TIME [epoch: 9.52 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11995619189800714		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.11995619189800714 | validation: 0.1234357572619326]
	TIME [epoch: 9.51 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13183798721846013		[learning rate: 0.00096476]
	Learning Rate: 0.000964764
	LOSS [training: 0.13183798721846013 | validation: 0.12861658450961685]
	TIME [epoch: 9.5 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1369241669811901		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.1369241669811901 | validation: 0.2091404951505873]
	TIME [epoch: 9.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12921243094618903		[learning rate: 0.0009601]
	Learning Rate: 0.000960098
	LOSS [training: 0.12921243094618903 | validation: 0.11989940272335599]
	TIME [epoch: 9.52 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14237059859641732		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.14237059859641732 | validation: 0.16787140634009604]
	TIME [epoch: 9.51 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2203335498199952		[learning rate: 0.00095546]
	Learning Rate: 0.000955456
	LOSS [training: 0.2203335498199952 | validation: 0.22771915935833545]
	TIME [epoch: 9.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18595038625970756		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.18595038625970756 | validation: 0.14918700036289564]
	TIME [epoch: 9.52 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12883697267775637		[learning rate: 0.00095084]
	Learning Rate: 0.000950835
	LOSS [training: 0.12883697267775637 | validation: 0.3262522562268456]
	TIME [epoch: 9.51 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20084563671802017		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.20084563671802017 | validation: 0.1920099645908354]
	TIME [epoch: 9.5 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1945473902169223		[learning rate: 0.00094624]
	Learning Rate: 0.000946237
	LOSS [training: 0.1945473902169223 | validation: 0.39615132793851154]
	TIME [epoch: 9.51 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18529054375000084		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.18529054375000084 | validation: 0.2446268092809443]
	TIME [epoch: 9.52 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1673872338387401		[learning rate: 0.00094166]
	Learning Rate: 0.000941661
	LOSS [training: 0.1673872338387401 | validation: 0.20431873448460386]
	TIME [epoch: 9.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14582701158178318		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.14582701158178318 | validation: 0.12515556529827337]
	TIME [epoch: 9.51 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1522946464026961		[learning rate: 0.00093711]
	Learning Rate: 0.000937108
	LOSS [training: 0.1522946464026961 | validation: 0.14160491129136216]
	TIME [epoch: 9.52 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10245279426947548		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.10245279426947548 | validation: 0.12834029619674772]
	TIME [epoch: 9.52 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11630815752808481		[learning rate: 0.00093258]
	Learning Rate: 0.000932576
	LOSS [training: 0.11630815752808481 | validation: 0.16725766802651762]
	TIME [epoch: 9.51 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11151602995150826		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.11151602995150826 | validation: 0.10805592826125095]
	TIME [epoch: 9.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09973648998711038		[learning rate: 0.00092807]
	Learning Rate: 0.000928066
	LOSS [training: 0.09973648998711038 | validation: 0.15879013932236183]
	TIME [epoch: 9.52 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16248038476215224		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.16248038476215224 | validation: 0.2867133238211262]
	TIME [epoch: 9.51 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26739765409088095		[learning rate: 0.00092358]
	Learning Rate: 0.000923578
	LOSS [training: 0.26739765409088095 | validation: 0.21077572217414933]
	TIME [epoch: 9.5 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20474098643271085		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.20474098643271085 | validation: 0.3833213187644902]
	TIME [epoch: 9.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17109518485480052		[learning rate: 0.00091911]
	Learning Rate: 0.000919112
	LOSS [training: 0.17109518485480052 | validation: 0.14509549403233402]
	TIME [epoch: 9.52 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1388289901097061		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.1388289901097061 | validation: 0.16295182528937027]
	TIME [epoch: 9.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1519345369981436		[learning rate: 0.00091467]
	Learning Rate: 0.000914667
	LOSS [training: 0.1519345369981436 | validation: 0.13688523563547977]
	TIME [epoch: 9.5 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1223914041057553		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.1223914041057553 | validation: 0.1984488721788049]
	TIME [epoch: 9.51 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14672572811834012		[learning rate: 0.00091024]
	Learning Rate: 0.000910244
	LOSS [training: 0.14672572811834012 | validation: 0.15114974292132144]
	TIME [epoch: 9.52 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1034536928575525		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.1034536928575525 | validation: 0.14690140350731987]
	TIME [epoch: 9.5 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13521552558415345		[learning rate: 0.00090584]
	Learning Rate: 0.000905843
	LOSS [training: 0.13521552558415345 | validation: 0.4097785840925288]
	TIME [epoch: 9.51 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24838436187427945		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.24838436187427945 | validation: 0.12642762110531083]
	TIME [epoch: 9.51 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11078477247985545		[learning rate: 0.00090146]
	Learning Rate: 0.000901462
	LOSS [training: 0.11078477247985545 | validation: 0.14382011778060202]
	TIME [epoch: 9.51 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14905250342904247		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.14905250342904247 | validation: 0.15610123570206613]
	TIME [epoch: 9.51 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14140216455024635		[learning rate: 0.0008971]
	Learning Rate: 0.000897103
	LOSS [training: 0.14140216455024635 | validation: 0.12966926326138872]
	TIME [epoch: 9.5 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1381561550940507		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.1381561550940507 | validation: 0.22306038897317643]
	TIME [epoch: 9.53 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1496018618041165		[learning rate: 0.00089276]
	Learning Rate: 0.000892764
	LOSS [training: 0.1496018618041165 | validation: 0.15690119470548677]
	TIME [epoch: 9.5 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16332117602277646		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.16332117602277646 | validation: 0.202204579520135]
	TIME [epoch: 9.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16162278074700062		[learning rate: 0.00088845]
	Learning Rate: 0.000888447
	LOSS [training: 0.16162278074700062 | validation: 0.19167662504682142]
	TIME [epoch: 9.52 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1403480122916597		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.1403480122916597 | validation: 0.1992973476777518]
	TIME [epoch: 9.51 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14122336583971618		[learning rate: 0.00088415]
	Learning Rate: 0.000884151
	LOSS [training: 0.14122336583971618 | validation: 0.16284749633563395]
	TIME [epoch: 9.5 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14701944257615146		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.14701944257615146 | validation: 0.1625011322496856]
	TIME [epoch: 9.5 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1375155413999977		[learning rate: 0.00087988]
	Learning Rate: 0.000879875
	LOSS [training: 0.1375155413999977 | validation: 0.14846095051038816]
	TIME [epoch: 9.52 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12459929464388816		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.12459929464388816 | validation: 0.16492752283674247]
	TIME [epoch: 9.51 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1424250231843657		[learning rate: 0.00087562]
	Learning Rate: 0.00087562
	LOSS [training: 0.1424250231843657 | validation: 0.21724172769254937]
	TIME [epoch: 9.5 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16414210038753604		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.16414210038753604 | validation: 0.15312940998433394]
	TIME [epoch: 9.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13347745927649626		[learning rate: 0.00087139]
	Learning Rate: 0.000871386
	LOSS [training: 0.13347745927649626 | validation: 0.18079002174564857]
	TIME [epoch: 9.52 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21488873108993722		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.21488873108993722 | validation: 0.20899982115335547]
	TIME [epoch: 9.5 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2229794116428275		[learning rate: 0.00086717]
	Learning Rate: 0.000867172
	LOSS [training: 0.2229794116428275 | validation: 0.2629381544530571]
	TIME [epoch: 9.51 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17130696168986895		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.17130696168986895 | validation: 0.26815531371878754]
	TIME [epoch: 9.52 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17780567392368876		[learning rate: 0.00086298]
	Learning Rate: 0.000862979
	LOSS [training: 0.17780567392368876 | validation: 0.22051473913173028]
	TIME [epoch: 9.51 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13188809181826802		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.13188809181826802 | validation: 0.16238966296337126]
	TIME [epoch: 9.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13621833881861062		[learning rate: 0.00085881]
	Learning Rate: 0.000858805
	LOSS [training: 0.13621833881861062 | validation: 0.2161424022440368]
	TIME [epoch: 9.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17551324016761782		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.17551324016761782 | validation: 0.16974579157951772]
	TIME [epoch: 9.52 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12339340893660782		[learning rate: 0.00085465]
	Learning Rate: 0.000854652
	LOSS [training: 0.12339340893660782 | validation: 0.17375415160766455]
	TIME [epoch: 9.51 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14586149809567983		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.14586149809567983 | validation: 0.16385052502806347]
	TIME [epoch: 9.5 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12918218318712088		[learning rate: 0.00085052]
	Learning Rate: 0.000850519
	LOSS [training: 0.12918218318712088 | validation: 0.2815620511336426]
	TIME [epoch: 9.51 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20669890236984828		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.20669890236984828 | validation: 0.19216219232991066]
	TIME [epoch: 9.52 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14564292327223843		[learning rate: 0.00084641]
	Learning Rate: 0.000846406
	LOSS [training: 0.14564292327223843 | validation: 0.16903336515501607]
	TIME [epoch: 9.51 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13450904805444558		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.13450904805444558 | validation: 0.2048980485240179]
	TIME [epoch: 9.51 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12872989649693928		[learning rate: 0.00084231]
	Learning Rate: 0.000842313
	LOSS [training: 0.12872989649693928 | validation: 0.14630503820526364]
	TIME [epoch: 9.52 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11490511731810922		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.11490511731810922 | validation: 0.16851973341989393]
	TIME [epoch: 9.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1633519546958822		[learning rate: 0.00083824]
	Learning Rate: 0.00083824
	LOSS [training: 0.1633519546958822 | validation: 0.27464333840176897]
	TIME [epoch: 9.5 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16378838600158602		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.16378838600158602 | validation: 0.20095414119879926]
	TIME [epoch: 9.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1974041679656614		[learning rate: 0.00083419]
	Learning Rate: 0.000834187
	LOSS [training: 0.1974041679656614 | validation: 0.19200605923654276]
	TIME [epoch: 9.52 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16853459133299975		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.16853459133299975 | validation: 0.18764281319960868]
	TIME [epoch: 9.51 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16105066340127583		[learning rate: 0.00083015]
	Learning Rate: 0.000830152
	LOSS [training: 0.16105066340127583 | validation: 0.2627435176093664]
	TIME [epoch: 9.51 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1672251733070231		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.1672251733070231 | validation: 0.14249143648377133]
	TIME [epoch: 9.51 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11608456261773961		[learning rate: 0.00082614]
	Learning Rate: 0.000826138
	LOSS [training: 0.11608456261773961 | validation: 0.20190598865480916]
	TIME [epoch: 9.52 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10491945256183799		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.10491945256183799 | validation: 0.11967926250410248]
	TIME [epoch: 9.5 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11664651317267896		[learning rate: 0.00082214]
	Learning Rate: 0.000822143
	LOSS [training: 0.11664651317267896 | validation: 0.21568939280107555]
	TIME [epoch: 9.51 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13185101871912935		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.13185101871912935 | validation: 0.16441637669146508]
	TIME [epoch: 9.52 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13034756833179267		[learning rate: 0.00081817]
	Learning Rate: 0.000818167
	LOSS [training: 0.13034756833179267 | validation: 0.17051243695706725]
	TIME [epoch: 9.51 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13579461352592137		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.13579461352592137 | validation: 0.16202954697140493]
	TIME [epoch: 9.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1947978846615375		[learning rate: 0.00081421]
	Learning Rate: 0.000814211
	LOSS [training: 0.1947978846615375 | validation: 0.14650705542869852]
	TIME [epoch: 9.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11822159500167526		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.11822159500167526 | validation: 0.1605899111205171]
	TIME [epoch: 9.52 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12147441554720476		[learning rate: 0.00081027]
	Learning Rate: 0.000810273
	LOSS [training: 0.12147441554720476 | validation: 0.13594845361336855]
	TIME [epoch: 9.51 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13225808611065107		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.13225808611065107 | validation: 0.17943130025822104]
	TIME [epoch: 9.5 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14249563037340887		[learning rate: 0.00080636]
	Learning Rate: 0.000806355
	LOSS [training: 0.14249563037340887 | validation: 0.2374287912138938]
	TIME [epoch: 9.51 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15588981443840544		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.15588981443840544 | validation: 0.23408315770266103]
	TIME [epoch: 9.52 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16344472807012508		[learning rate: 0.00080246]
	Learning Rate: 0.000802456
	LOSS [training: 0.16344472807012508 | validation: 0.1657103880021119]
	TIME [epoch: 9.51 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1703724985952394		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.1703724985952394 | validation: 0.23436185829399123]
	TIME [epoch: 9.5 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17315983151961226		[learning rate: 0.00079858]
	Learning Rate: 0.000798575
	LOSS [training: 0.17315983151961226 | validation: 0.16696248595288452]
	TIME [epoch: 9.52 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12686127062863192		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.12686127062863192 | validation: 0.16084119081598708]
	TIME [epoch: 9.5 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16194942374185484		[learning rate: 0.00079471]
	Learning Rate: 0.000794713
	LOSS [training: 0.16194942374185484 | validation: 0.2740500130559357]
	TIME [epoch: 9.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19472295075547202		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.19472295075547202 | validation: 0.16935599426092615]
	TIME [epoch: 9.5 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1274717053555729		[learning rate: 0.00079087]
	Learning Rate: 0.00079087
	LOSS [training: 0.1274717053555729 | validation: 0.14981171910155222]
	TIME [epoch: 9.52 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13371328452793355		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.13371328452793355 | validation: 0.14061557482633366]
	TIME [epoch: 9.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1274280103773631		[learning rate: 0.00078705]
	Learning Rate: 0.000787046
	LOSS [training: 0.1274280103773631 | validation: 0.24198681609404138]
	TIME [epoch: 9.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17380197716799717		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.17380197716799717 | validation: 0.17984454944960582]
	TIME [epoch: 9.5 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14169300843775842		[learning rate: 0.00078324]
	Learning Rate: 0.00078324
	LOSS [training: 0.14169300843775842 | validation: 0.18473551385763085]
	TIME [epoch: 9.53 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14452034374458195		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.14452034374458195 | validation: 0.15589402085069984]
	TIME [epoch: 9.51 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16008035484081645		[learning rate: 0.00077945]
	Learning Rate: 0.000779452
	LOSS [training: 0.16008035484081645 | validation: 0.1558738713431844]
	TIME [epoch: 9.51 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11243145521144134		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.11243145521144134 | validation: 0.1334197249255353]
	TIME [epoch: 9.51 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10608750889759193		[learning rate: 0.00077568]
	Learning Rate: 0.000775683
	LOSS [training: 0.10608750889759193 | validation: 0.14722987117001107]
	TIME [epoch: 9.51 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12392143468489665		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.12392143468489665 | validation: 0.16046572739664433]
	TIME [epoch: 9.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17362994741082288		[learning rate: 0.00077193]
	Learning Rate: 0.000771932
	LOSS [training: 0.17362994741082288 | validation: 0.2227774066853119]
	TIME [epoch: 9.5 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18053747597103353		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.18053747597103353 | validation: 0.08734809518257895]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1158.pth
	Model improved!!!
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0914228195055988		[learning rate: 0.0007682]
	Learning Rate: 0.000768199
	LOSS [training: 0.0914228195055988 | validation: 0.10415331804649804]
	TIME [epoch: 9.52 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08847417862798757		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.08847417862798757 | validation: 0.12916261052498598]
	TIME [epoch: 9.51 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23957370359728528		[learning rate: 0.00076448]
	Learning Rate: 0.000764484
	LOSS [training: 0.23957370359728528 | validation: 0.4580936547351451]
	TIME [epoch: 9.53 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2366749984753555		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.2366749984753555 | validation: 0.16554054748156816]
	TIME [epoch: 9.52 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0998636568168856		[learning rate: 0.00076079]
	Learning Rate: 0.000760787
	LOSS [training: 0.0998636568168856 | validation: 0.11230927149753392]
	TIME [epoch: 9.51 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09130821027493452		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.09130821027493452 | validation: 0.10840862580994881]
	TIME [epoch: 9.51 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11356995757830916		[learning rate: 0.00075711]
	Learning Rate: 0.000757108
	LOSS [training: 0.11356995757830916 | validation: 0.1516355511887174]
	TIME [epoch: 9.54 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11212970800765773		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.11212970800765773 | validation: 0.14311724731722825]
	TIME [epoch: 9.52 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583996546862337		[learning rate: 0.00075345]
	Learning Rate: 0.000753447
	LOSS [training: 0.1583996546862337 | validation: 0.2065370870276105]
	TIME [epoch: 9.52 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21322208110273166		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.21322208110273166 | validation: 0.1546704468878]
	TIME [epoch: 9.52 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13427548810336942		[learning rate: 0.0007498]
	Learning Rate: 0.000749803
	LOSS [training: 0.13427548810336942 | validation: 0.14030089958887396]
	TIME [epoch: 9.53 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11846413890533872		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.11846413890533872 | validation: 0.17189774539139943]
	TIME [epoch: 9.51 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12251875441388452		[learning rate: 0.00074618]
	Learning Rate: 0.000746177
	LOSS [training: 0.12251875441388452 | validation: 0.18455122400160456]
	TIME [epoch: 9.52 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1370025615541512		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.1370025615541512 | validation: 0.12849028379147218]
	TIME [epoch: 9.52 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14158566479320017		[learning rate: 0.00074257]
	Learning Rate: 0.000742569
	LOSS [training: 0.14158566479320017 | validation: 0.18729942371640995]
	TIME [epoch: 9.53 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15272500799221073		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.15272500799221073 | validation: 0.18046818865031042]
	TIME [epoch: 9.51 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15761962664027224		[learning rate: 0.00073898]
	Learning Rate: 0.000738978
	LOSS [training: 0.15761962664027224 | validation: 0.20982536174395364]
	TIME [epoch: 9.52 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1261829782674089		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.1261829782674089 | validation: 0.16422038902717995]
	TIME [epoch: 9.53 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2125128933837071		[learning rate: 0.0007354]
	Learning Rate: 0.000735405
	LOSS [training: 0.2125128933837071 | validation: 0.16660589233374004]
	TIME [epoch: 9.52 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11818971344746174		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.11818971344746174 | validation: 0.16841103397160076]
	TIME [epoch: 9.52 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10694827325065781		[learning rate: 0.00073185]
	Learning Rate: 0.000731848
	LOSS [training: 0.10694827325065781 | validation: 0.1405266451699092]
	TIME [epoch: 9.52 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14269639838226572		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.14269639838226572 | validation: 0.13576059616091624]
	TIME [epoch: 9.53 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1083941450539417		[learning rate: 0.00072831]
	Learning Rate: 0.000728309
	LOSS [training: 0.1083941450539417 | validation: 0.11546137058448258]
	TIME [epoch: 9.52 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1144544765331317		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.1144544765331317 | validation: 0.12332118306576291]
	TIME [epoch: 9.52 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11884320684866553		[learning rate: 0.00072479]
	Learning Rate: 0.000724787
	LOSS [training: 0.11884320684866553 | validation: 0.1658817010440987]
	TIME [epoch: 9.52 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15342651422519732		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.15342651422519732 | validation: 0.1516790416190562]
	TIME [epoch: 9.53 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12677037527540555		[learning rate: 0.00072128]
	Learning Rate: 0.000721282
	LOSS [training: 0.12677037527540555 | validation: 0.31020558160446565]
	TIME [epoch: 9.52 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16235093820036606		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.16235093820036606 | validation: 0.15036422876548827]
	TIME [epoch: 9.52 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11695202489250463		[learning rate: 0.00071779]
	Learning Rate: 0.000717794
	LOSS [training: 0.11695202489250463 | validation: 0.18212788528299864]
	TIME [epoch: 9.53 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10897378522703471		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.10897378522703471 | validation: 0.16713551966398782]
	TIME [epoch: 9.51 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12514629527220106		[learning rate: 0.00071432]
	Learning Rate: 0.000714323
	LOSS [training: 0.12514629527220106 | validation: 0.119970616389835]
	TIME [epoch: 9.51 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10239256837096658		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.10239256837096658 | validation: 0.11946976554662626]
	TIME [epoch: 9.52 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10187793821578224		[learning rate: 0.00071087]
	Learning Rate: 0.000710869
	LOSS [training: 0.10187793821578224 | validation: 0.127963059400612]
	TIME [epoch: 9.53 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1158452129029949		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.1158452129029949 | validation: 0.11095976873511161]
	TIME [epoch: 9.51 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09740985067235246		[learning rate: 0.00070743]
	Learning Rate: 0.000707431
	LOSS [training: 0.09740985067235246 | validation: 0.10900551869439548]
	TIME [epoch: 9.51 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10294688989590554		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.10294688989590554 | validation: 0.12641277682300714]
	TIME [epoch: 9.53 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11220613649996825		[learning rate: 0.00070401]
	Learning Rate: 0.00070401
	LOSS [training: 0.11220613649996825 | validation: 0.1169344307116866]
	TIME [epoch: 9.52 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1319483315444227		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.1319483315444227 | validation: 0.12408187635633622]
	TIME [epoch: 9.51 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1283428316661849		[learning rate: 0.00070061]
	Learning Rate: 0.000700606
	LOSS [training: 0.1283428316661849 | validation: 0.16735322808412625]
	TIME [epoch: 9.51 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09707676400361352		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.09707676400361352 | validation: 0.10360444540753669]
	TIME [epoch: 9.53 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1223592335000793		[learning rate: 0.00069722]
	Learning Rate: 0.000697218
	LOSS [training: 0.1223592335000793 | validation: 0.093820525390509]
	TIME [epoch: 9.51 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08192052269498715		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.08192052269498715 | validation: 0.13339484629942072]
	TIME [epoch: 9.52 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07392945974964202		[learning rate: 0.00069385]
	Learning Rate: 0.000693846
	LOSS [training: 0.07392945974964202 | validation: 0.14054426892765565]
	TIME [epoch: 9.51 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08751433493655437		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.08751433493655437 | validation: 0.1558549852859555]
	TIME [epoch: 9.54 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1019435929798667		[learning rate: 0.00069049]
	Learning Rate: 0.000690491
	LOSS [training: 0.1019435929798667 | validation: 0.14851198652714798]
	TIME [epoch: 9.52 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10007576209303574		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.10007576209303574 | validation: 0.1453699701584172]
	TIME [epoch: 9.52 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10989171095041843		[learning rate: 0.00068715]
	Learning Rate: 0.000687152
	LOSS [training: 0.10989171095041843 | validation: 0.12245333311394387]
	TIME [epoch: 9.53 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10126277021131551		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.10126277021131551 | validation: 0.10046140552507513]
	TIME [epoch: 9.52 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0812936900279492		[learning rate: 0.00068383]
	Learning Rate: 0.000683829
	LOSS [training: 0.0812936900279492 | validation: 0.11306669760475098]
	TIME [epoch: 9.51 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0848738144294057		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.0848738144294057 | validation: 0.0863205775455702]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1208.pth
	Model improved!!!
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11318323757565078		[learning rate: 0.00068052]
	Learning Rate: 0.000680522
	LOSS [training: 0.11318323757565078 | validation: 0.19643937095851619]
	TIME [epoch: 9.53 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10338296722134625		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.10338296722134625 | validation: 0.16380065629579846]
	TIME [epoch: 9.51 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07891431260998047		[learning rate: 0.00067723]
	Learning Rate: 0.000677231
	LOSS [training: 0.07891431260998047 | validation: 0.13346295712911663]
	TIME [epoch: 9.5 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09319684490316751		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.09319684490316751 | validation: 0.17401676476945324]
	TIME [epoch: 9.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18647470712163883		[learning rate: 0.00067396]
	Learning Rate: 0.000673956
	LOSS [training: 0.18647470712163883 | validation: 0.1386786176419469]
	TIME [epoch: 9.52 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09791754072419392		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.09791754072419392 | validation: 0.10683033977541687]
	TIME [epoch: 9.51 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08011680496131277		[learning rate: 0.0006707]
	Learning Rate: 0.000670697
	LOSS [training: 0.08011680496131277 | validation: 0.10961949947435688]
	TIME [epoch: 9.51 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08734636650325228		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.08734636650325228 | validation: 0.12091838248511357]
	TIME [epoch: 9.52 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12786653562083622		[learning rate: 0.00066745]
	Learning Rate: 0.000667454
	LOSS [training: 0.12786653562083622 | validation: 0.18047543032056687]
	TIME [epoch: 9.51 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13160376856590555		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.13160376856590555 | validation: 0.1565380627453113]
	TIME [epoch: 9.51 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09406906015544407		[learning rate: 0.00066423]
	Learning Rate: 0.000664226
	LOSS [training: 0.09406906015544407 | validation: 0.12369568005028699]
	TIME [epoch: 9.51 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1061480609662927		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.1061480609662927 | validation: 0.19036042963426603]
	TIME [epoch: 9.52 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15105107948694613		[learning rate: 0.00066101]
	Learning Rate: 0.000661014
	LOSS [training: 0.15105107948694613 | validation: 0.10278260668170922]
	TIME [epoch: 9.51 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09509041147394928		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.09509041147394928 | validation: 0.10766452456467387]
	TIME [epoch: 9.51 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08001106957236719		[learning rate: 0.00065782]
	Learning Rate: 0.000657817
	LOSS [training: 0.08001106957236719 | validation: 0.193855494084665]
	TIME [epoch: 9.51 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12436050371859217		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.12436050371859217 | validation: 0.1379401553569778]
	TIME [epoch: 9.53 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10325713428042937		[learning rate: 0.00065464]
	Learning Rate: 0.000654636
	LOSS [training: 0.10325713428042937 | validation: 0.11912075063316195]
	TIME [epoch: 9.51 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09255552990496982		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.09255552990496982 | validation: 0.12861718992008123]
	TIME [epoch: 9.51 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09470057783603003		[learning rate: 0.00065147]
	Learning Rate: 0.000651471
	LOSS [training: 0.09470057783603003 | validation: 0.10117029112240042]
	TIME [epoch: 9.53 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11099568771927246		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.11099568771927246 | validation: 0.15750734987818915]
	TIME [epoch: 9.51 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0915349728096527		[learning rate: 0.00064832]
	Learning Rate: 0.00064832
	LOSS [training: 0.0915349728096527 | validation: 0.11418343906759885]
	TIME [epoch: 9.51 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12064088633366674		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.12064088633366674 | validation: 0.1021462257535482]
	TIME [epoch: 9.5 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07743383041932543		[learning rate: 0.00064519]
	Learning Rate: 0.000645185
	LOSS [training: 0.07743383041932543 | validation: 0.1184104950817629]
	TIME [epoch: 9.52 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09711802037754838		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.09711802037754838 | validation: 0.17844114380182072]
	TIME [epoch: 9.51 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10958116597307159		[learning rate: 0.00064206]
	Learning Rate: 0.000642065
	LOSS [training: 0.10958116597307159 | validation: 0.13987378479490412]
	TIME [epoch: 9.51 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13051975578846153		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.13051975578846153 | validation: 0.1385460998138691]
	TIME [epoch: 9.52 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10582213993398763		[learning rate: 0.00063896]
	Learning Rate: 0.00063896
	LOSS [training: 0.10582213993398763 | validation: 0.17119380913542423]
	TIME [epoch: 9.52 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12103658994271091		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.12103658994271091 | validation: 0.1344773942222608]
	TIME [epoch: 9.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12700905753667957		[learning rate: 0.00063587]
	Learning Rate: 0.00063587
	LOSS [training: 0.12700905753667957 | validation: 0.11728576724331446]
	TIME [epoch: 9.5 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10677285751226315		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.10677285751226315 | validation: 0.12804023517242957]
	TIME [epoch: 9.52 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10186550077535647		[learning rate: 0.0006328]
	Learning Rate: 0.000632795
	LOSS [training: 0.10186550077535647 | validation: 0.14437112204829256]
	TIME [epoch: 9.51 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10122034404405515		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.10122034404405515 | validation: 0.13394058756787106]
	TIME [epoch: 9.51 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09102053302896349		[learning rate: 0.00062974]
	Learning Rate: 0.000629735
	LOSS [training: 0.09102053302896349 | validation: 0.10694109035047036]
	TIME [epoch: 9.51 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0865613871057374		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.0865613871057374 | validation: 0.17326700148643326]
	TIME [epoch: 9.52 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10093616259542985		[learning rate: 0.00062669]
	Learning Rate: 0.00062669
	LOSS [training: 0.10093616259542985 | validation: 0.10743734183681075]
	TIME [epoch: 9.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08075857654392715		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.08075857654392715 | validation: 0.130474220696824]
	TIME [epoch: 9.5 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13112697680546093		[learning rate: 0.00062366]
	Learning Rate: 0.000623659
	LOSS [training: 0.13112697680546093 | validation: 0.11607685407974179]
	TIME [epoch: 9.52 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11089142935799731		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.11089142935799731 | validation: 0.10091178530883685]
	TIME [epoch: 9.52 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11288262299959047		[learning rate: 0.00062064]
	Learning Rate: 0.000620643
	LOSS [training: 0.11288262299959047 | validation: 0.11734293282071946]
	TIME [epoch: 9.51 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0904499841512379		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.0904499841512379 | validation: 0.2540035264429257]
	TIME [epoch: 9.5 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12874039846571908		[learning rate: 0.00061764]
	Learning Rate: 0.000617642
	LOSS [training: 0.12874039846571908 | validation: 0.0868019248791654]
	TIME [epoch: 9.52 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0972474478253906		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.0972474478253906 | validation: 0.149776479227685]
	TIME [epoch: 9.51 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08390874304416027		[learning rate: 0.00061466]
	Learning Rate: 0.000614655
	LOSS [training: 0.08390874304416027 | validation: 0.08140354621108946]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1251.pth
	Model improved!!!
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07633441823364387		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.07633441823364387 | validation: 0.12404070415616686]
	TIME [epoch: 9.51 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09457435326559446		[learning rate: 0.00061168]
	Learning Rate: 0.000611683
	LOSS [training: 0.09457435326559446 | validation: 0.10406215308407368]
	TIME [epoch: 9.52 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08867328349423954		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.08867328349423954 | validation: 0.09623819487810024]
	TIME [epoch: 9.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08542132571520619		[learning rate: 0.00060872]
	Learning Rate: 0.000608725
	LOSS [training: 0.08542132571520619 | validation: 0.10936110153500632]
	TIME [epoch: 9.5 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1004571327171854		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.1004571327171854 | validation: 0.13382596374281655]
	TIME [epoch: 9.51 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12775684319214506		[learning rate: 0.00060578]
	Learning Rate: 0.000605781
	LOSS [training: 0.12775684319214506 | validation: 0.08994320153015613]
	TIME [epoch: 9.51 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09539588134017125		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.09539588134017125 | validation: 0.10873627165011673]
	TIME [epoch: 9.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1065036283145852		[learning rate: 0.00060285]
	Learning Rate: 0.000602852
	LOSS [training: 0.1065036283145852 | validation: 0.0867147122365099]
	TIME [epoch: 9.5 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08677253815057724		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.08677253815057724 | validation: 0.15427795499614141]
	TIME [epoch: 9.52 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11372228595802744		[learning rate: 0.00059994]
	Learning Rate: 0.000599936
	LOSS [training: 0.11372228595802744 | validation: 0.11812291371832516]
	TIME [epoch: 9.5 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08517231224292703		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.08517231224292703 | validation: 0.10587203462678194]
	TIME [epoch: 9.5 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09502388132116171		[learning rate: 0.00059704]
	Learning Rate: 0.000597035
	LOSS [training: 0.09502388132116171 | validation: 0.14777795558670043]
	TIME [epoch: 9.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10193222688005106		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.10193222688005106 | validation: 0.11635532331882767]
	TIME [epoch: 9.52 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0920339401883167		[learning rate: 0.00059415]
	Learning Rate: 0.000594148
	LOSS [training: 0.0920339401883167 | validation: 0.12837598634450484]
	TIME [epoch: 9.51 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10171050217070725		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.10171050217070725 | validation: 0.17740356187951872]
	TIME [epoch: 9.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11197631829400992		[learning rate: 0.00059128]
	Learning Rate: 0.000591275
	LOSS [training: 0.11197631829400992 | validation: 0.10918062984446394]
	TIME [epoch: 9.52 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0933422552134405		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.0933422552134405 | validation: 0.1103573808587362]
	TIME [epoch: 9.51 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10151296598292014		[learning rate: 0.00058842]
	Learning Rate: 0.000588416
	LOSS [training: 0.10151296598292014 | validation: 0.14406092057770237]
	TIME [epoch: 9.5 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10781633784538511		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.10781633784538511 | validation: 0.09821524928313854]
	TIME [epoch: 9.5 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09398850503983731		[learning rate: 0.00058557]
	Learning Rate: 0.00058557
	LOSS [training: 0.09398850503983731 | validation: 0.11332744789466624]
	TIME [epoch: 9.52 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14489602483766367		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.14489602483766367 | validation: 0.16997556482144657]
	TIME [epoch: 9.51 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1260009528606682		[learning rate: 0.00058274]
	Learning Rate: 0.000582738
	LOSS [training: 0.1260009528606682 | validation: 0.09746751139581437]
	TIME [epoch: 9.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0915238531510906		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.0915238531510906 | validation: 0.10751802932776841]
	TIME [epoch: 9.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11645635192932154		[learning rate: 0.00057992]
	Learning Rate: 0.00057992
	LOSS [training: 0.11645635192932154 | validation: 0.11031942951306974]
	TIME [epoch: 9.52 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10950386240470525		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.10950386240470525 | validation: 0.12863377000569542]
	TIME [epoch: 9.5 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09099930600572488		[learning rate: 0.00057712]
	Learning Rate: 0.000577116
	LOSS [training: 0.09099930600572488 | validation: 0.1385363530465746]
	TIME [epoch: 9.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.111822308413522		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.111822308413522 | validation: 0.08450090919251245]
	TIME [epoch: 9.51 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0742896024387319		[learning rate: 0.00057433]
	Learning Rate: 0.000574325
	LOSS [training: 0.0742896024387319 | validation: 0.10689971775210813]
	TIME [epoch: 9.52 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0787711476311127		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.0787711476311127 | validation: 0.10211653060085255]
	TIME [epoch: 9.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08530595044184115		[learning rate: 0.00057155]
	Learning Rate: 0.000571548
	LOSS [training: 0.08530595044184115 | validation: 0.11594771036487753]
	TIME [epoch: 9.5 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11346381681689129		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.11346381681689129 | validation: 0.13265336122872368]
	TIME [epoch: 9.52 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10105124607192402		[learning rate: 0.00056878]
	Learning Rate: 0.000568784
	LOSS [training: 0.10105124607192402 | validation: 0.06972406584902804]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1283.pth
	Model improved!!!
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0809071481097362		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.0809071481097362 | validation: 0.09151015560008173]
	TIME [epoch: 9.51 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08015675707168439		[learning rate: 0.00056603]
	Learning Rate: 0.000566033
	LOSS [training: 0.08015675707168439 | validation: 0.09491606227401699]
	TIME [epoch: 9.51 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09642047630278008		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.09642047630278008 | validation: 0.07727631947326535]
	TIME [epoch: 9.51 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07689731425691598		[learning rate: 0.0005633]
	Learning Rate: 0.000563296
	LOSS [training: 0.07689731425691598 | validation: 0.10270786491783206]
	TIME [epoch: 9.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08442261668842202		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.08442261668842202 | validation: 0.09027511354454754]
	TIME [epoch: 9.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09200720961544555		[learning rate: 0.00056057]
	Learning Rate: 0.000560572
	LOSS [training: 0.09200720961544555 | validation: 0.11052077983057985]
	TIME [epoch: 9.52 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08160169060595727		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.08160169060595727 | validation: 0.08578958019533253]
	TIME [epoch: 9.51 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08686347783616867		[learning rate: 0.00055786]
	Learning Rate: 0.000557861
	LOSS [training: 0.08686347783616867 | validation: 0.1062085286435093]
	TIME [epoch: 9.5 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11319898405343812		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.11319898405343812 | validation: 0.1187467533365799]
	TIME [epoch: 9.51 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07447316119938985		[learning rate: 0.00055516]
	Learning Rate: 0.000555164
	LOSS [training: 0.07447316119938985 | validation: 0.07945144760434623]
	TIME [epoch: 9.51 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08439127940580135		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.08439127940580135 | validation: 0.12536793655528894]
	TIME [epoch: 9.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09674178086963443		[learning rate: 0.00055248]
	Learning Rate: 0.000552479
	LOSS [training: 0.09674178086963443 | validation: 0.09002024212245598]
	TIME [epoch: 9.5 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07527950042524945		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.07527950042524945 | validation: 0.0994608247278628]
	TIME [epoch: 9.51 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08857823733008297		[learning rate: 0.00054981]
	Learning Rate: 0.000549807
	LOSS [training: 0.08857823733008297 | validation: 0.11458790653621169]
	TIME [epoch: 9.52 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09263428026263486		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.09263428026263486 | validation: 0.09689153874197018]
	TIME [epoch: 9.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08914853505151576		[learning rate: 0.00054715]
	Learning Rate: 0.000547149
	LOSS [training: 0.08914853505151576 | validation: 0.10533939356863899]
	TIME [epoch: 9.5 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12389510312927757		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.12389510312927757 | validation: 0.10589543169856609]
	TIME [epoch: 9.53 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10694079706729112		[learning rate: 0.0005445]
	Learning Rate: 0.000544503
	LOSS [training: 0.10694079706729112 | validation: 0.08566488489675467]
	TIME [epoch: 9.51 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07227072519948352		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.07227072519948352 | validation: 0.12522020750180435]
	TIME [epoch: 9.51 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09748265199625614		[learning rate: 0.00054187]
	Learning Rate: 0.000541869
	LOSS [training: 0.09748265199625614 | validation: 0.1336284228360284]
	TIME [epoch: 9.51 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09655431902540838		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.09655431902540838 | validation: 0.1792509452746367]
	TIME [epoch: 9.53 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10918222651571068		[learning rate: 0.00053925]
	Learning Rate: 0.000539249
	LOSS [training: 0.10918222651571068 | validation: 0.15016095421788053]
	TIME [epoch: 9.51 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08910191426139624		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.08910191426139624 | validation: 0.11615833730619564]
	TIME [epoch: 9.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08175695121898398		[learning rate: 0.00053664]
	Learning Rate: 0.000536641
	LOSS [training: 0.08175695121898398 | validation: 0.09953289035276458]
	TIME [epoch: 9.5 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09864294163055871		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.09864294163055871 | validation: 0.12188066898944015]
	TIME [epoch: 9.51 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08146811464945151		[learning rate: 0.00053405]
	Learning Rate: 0.000534046
	LOSS [training: 0.08146811464945151 | validation: 0.15404184300054627]
	TIME [epoch: 9.51 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11247875507153386		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.11247875507153386 | validation: 0.14947552281161236]
	TIME [epoch: 9.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11258473550473816		[learning rate: 0.00053146]
	Learning Rate: 0.000531464
	LOSS [training: 0.11258473550473816 | validation: 0.1210309853044077]
	TIME [epoch: 9.52 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07589040021355756		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.07589040021355756 | validation: 0.06833459426898274]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1312.pth
	Model improved!!!
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0590950507420616		[learning rate: 0.00052889]
	Learning Rate: 0.000528894
	LOSS [training: 0.0590950507420616 | validation: 0.09134338987018456]
	TIME [epoch: 9.5 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06740732306465011		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.06740732306465011 | validation: 0.07991878138113769]
	TIME [epoch: 9.5 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07648231943076847		[learning rate: 0.00052634]
	Learning Rate: 0.000526336
	LOSS [training: 0.07648231943076847 | validation: 0.1443617881583176]
	TIME [epoch: 9.52 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12430176316509176		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.12430176316509176 | validation: 0.09854116749659143]
	TIME [epoch: 9.51 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06865398690945476		[learning rate: 0.00052379]
	Learning Rate: 0.000523791
	LOSS [training: 0.06865398690945476 | validation: 0.10371464056525305]
	TIME [epoch: 9.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11236990351464667		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.11236990351464667 | validation: 0.10215096222123986]
	TIME [epoch: 9.51 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08341821098181497		[learning rate: 0.00052126]
	Learning Rate: 0.000521258
	LOSS [training: 0.08341821098181497 | validation: 0.12136459062722058]
	TIME [epoch: 9.51 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08658546663398911		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.08658546663398911 | validation: 0.1038585192566154]
	TIME [epoch: 9.5 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09162871445630753		[learning rate: 0.00051874]
	Learning Rate: 0.000518737
	LOSS [training: 0.09162871445630753 | validation: 0.10524073105309115]
	TIME [epoch: 9.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07394347344544802		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.07394347344544802 | validation: 0.08969923094715618]
	TIME [epoch: 9.52 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09700601955412105		[learning rate: 0.00051623]
	Learning Rate: 0.000516229
	LOSS [training: 0.09700601955412105 | validation: 0.12932510377448916]
	TIME [epoch: 9.5 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07973224562387775		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.07973224562387775 | validation: 0.15451473167429758]
	TIME [epoch: 9.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10120564169369954		[learning rate: 0.00051373]
	Learning Rate: 0.000513732
	LOSS [training: 0.10120564169369954 | validation: 0.211604565384823]
	TIME [epoch: 9.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14050675309382027		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.14050675309382027 | validation: 0.10976297098400942]
	TIME [epoch: 9.52 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09031570490234422		[learning rate: 0.00051125]
	Learning Rate: 0.000511248
	LOSS [training: 0.09031570490234422 | validation: 0.1312973396589673]
	TIME [epoch: 9.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09072001074365887		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.09072001074365887 | validation: 0.14497642540970918]
	TIME [epoch: 9.5 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0926883814726562		[learning rate: 0.00050878]
	Learning Rate: 0.000508776
	LOSS [training: 0.0926883814726562 | validation: 0.11758016623145412]
	TIME [epoch: 9.51 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12443149960479985		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.12443149960479985 | validation: 0.1290835393848517]
	TIME [epoch: 9.51 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12595802229546865		[learning rate: 0.00050632]
	Learning Rate: 0.000506315
	LOSS [training: 0.12595802229546865 | validation: 0.07450360902279378]
	TIME [epoch: 9.5 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09332707963428652		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.09332707963428652 | validation: 0.08246973876277622]
	TIME [epoch: 9.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10465040721136232		[learning rate: 0.00050387]
	Learning Rate: 0.000503867
	LOSS [training: 0.10465040721136232 | validation: 0.1420996847427803]
	TIME [epoch: 9.51 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10831511021934237		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.10831511021934237 | validation: 0.11863202049483952]
	TIME [epoch: 9.51 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09568019726282774		[learning rate: 0.00050143]
	Learning Rate: 0.00050143
	LOSS [training: 0.09568019726282774 | validation: 0.09984643121187403]
	TIME [epoch: 9.5 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08950744948052858		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.08950744948052858 | validation: 0.15656215707369092]
	TIME [epoch: 9.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11653922089970266		[learning rate: 0.00049901]
	Learning Rate: 0.000499005
	LOSS [training: 0.11653922089970266 | validation: 0.08769624811821629]
	TIME [epoch: 9.52 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08132213262018172		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.08132213262018172 | validation: 0.1056221288461276]
	TIME [epoch: 9.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0763853359136093		[learning rate: 0.00049659]
	Learning Rate: 0.000496592
	LOSS [training: 0.0763853359136093 | validation: 0.10326134402580486]
	TIME [epoch: 9.51 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09159691709388071		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.09159691709388071 | validation: 0.11855115670541277]
	TIME [epoch: 9.51 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08365218929409221		[learning rate: 0.00049419]
	Learning Rate: 0.000494191
	LOSS [training: 0.08365218929409221 | validation: 0.12098260792420153]
	TIME [epoch: 9.51 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12864789923256095		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.12864789923256095 | validation: 0.14146093626728604]
	TIME [epoch: 9.49 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10661699537038813		[learning rate: 0.0004918]
	Learning Rate: 0.000491801
	LOSS [training: 0.10661699537038813 | validation: 0.12409471101158516]
	TIME [epoch: 9.51 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1070713895528042		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.1070713895528042 | validation: 0.13387529024243575]
	TIME [epoch: 9.52 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08879755352584201		[learning rate: 0.00048942]
	Learning Rate: 0.000489423
	LOSS [training: 0.08879755352584201 | validation: 0.12685396759886863]
	TIME [epoch: 9.5 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.109984320031118		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.109984320031118 | validation: 0.10895500357729108]
	TIME [epoch: 9.51 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11199965904362626		[learning rate: 0.00048706]
	Learning Rate: 0.000487056
	LOSS [training: 0.11199965904362626 | validation: 0.12680994408954901]
	TIME [epoch: 9.5 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08449805163542842		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.08449805163542842 | validation: 0.1639658375027348]
	TIME [epoch: 9.52 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07235212561452453		[learning rate: 0.0004847]
	Learning Rate: 0.000484701
	LOSS [training: 0.07235212561452453 | validation: 0.10333227420896338]
	TIME [epoch: 9.5 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09416143045894974		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.09416143045894974 | validation: 0.1342762623931488]
	TIME [epoch: 9.49 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0986676156455993		[learning rate: 0.00048236]
	Learning Rate: 0.000482357
	LOSS [training: 0.0986676156455993 | validation: 0.10525746708636327]
	TIME [epoch: 9.51 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09009364217017388		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.09009364217017388 | validation: 0.13384244866478187]
	TIME [epoch: 9.51 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10483179744696		[learning rate: 0.00048002]
	Learning Rate: 0.000480024
	LOSS [training: 0.10483179744696 | validation: 0.15163639719144428]
	TIME [epoch: 9.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09086116377661538		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.09086116377661538 | validation: 0.10094232482372427]
	TIME [epoch: 9.5 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07950998027813214		[learning rate: 0.0004777]
	Learning Rate: 0.000477703
	LOSS [training: 0.07950998027813214 | validation: 0.1193569945292755]
	TIME [epoch: 9.51 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0653956597738014		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.0653956597738014 | validation: 0.12674550693085132]
	TIME [epoch: 9.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08081876666055972		[learning rate: 0.00047539]
	Learning Rate: 0.000475393
	LOSS [training: 0.08081876666055972 | validation: 0.10716859466301187]
	TIME [epoch: 9.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08337416936786357		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.08337416936786357 | validation: 0.1005647112228543]
	TIME [epoch: 9.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07726822141791037		[learning rate: 0.00047309]
	Learning Rate: 0.000473094
	LOSS [training: 0.07726822141791037 | validation: 0.10657447365266493]
	TIME [epoch: 9.51 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1054589925472548		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.1054589925472548 | validation: 0.11001819941826758]
	TIME [epoch: 9.49 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0911793006642968		[learning rate: 0.00047081]
	Learning Rate: 0.000470806
	LOSS [training: 0.0911793006642968 | validation: 0.09728336847763226]
	TIME [epoch: 9.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07878973579075924		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.07878973579075924 | validation: 0.11155179379901674]
	TIME [epoch: 9.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11245248558507295		[learning rate: 0.00046853]
	Learning Rate: 0.000468529
	LOSS [training: 0.11245248558507295 | validation: 0.10767242468564357]
	TIME [epoch: 9.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0859874315525524		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.0859874315525524 | validation: 0.12360117559463621]
	TIME [epoch: 9.51 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08264163744463793		[learning rate: 0.00046626]
	Learning Rate: 0.000466264
	LOSS [training: 0.08264163744463793 | validation: 0.09258541847785522]
	TIME [epoch: 9.5 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07385145882756335		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.07385145882756335 | validation: 0.08643040475771432]
	TIME [epoch: 9.52 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08274724808985841		[learning rate: 0.00046401]
	Learning Rate: 0.000464009
	LOSS [training: 0.08274724808985841 | validation: 0.08113763738591086]
	TIME [epoch: 9.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09623561337719039		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.09623561337719039 | validation: 0.1298064263866628]
	TIME [epoch: 9.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11324075593214881		[learning rate: 0.00046177]
	Learning Rate: 0.000461765
	LOSS [training: 0.11324075593214881 | validation: 0.12086255085892222]
	TIME [epoch: 9.49 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10477555688535774		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.10477555688535774 | validation: 0.09762159596579718]
	TIME [epoch: 9.51 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06548462159306598		[learning rate: 0.00045953]
	Learning Rate: 0.000459532
	LOSS [training: 0.06548462159306598 | validation: 0.1031828416471408]
	TIME [epoch: 9.5 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08200678729341127		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.08200678729341127 | validation: 0.12778214875440408]
	TIME [epoch: 9.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08852088804949806		[learning rate: 0.00045731]
	Learning Rate: 0.00045731
	LOSS [training: 0.08852088804949806 | validation: 0.1047225048058087]
	TIME [epoch: 9.51 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09796051406011734		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.09796051406011734 | validation: 0.12248981381771647]
	TIME [epoch: 9.51 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11429394818047253		[learning rate: 0.0004551]
	Learning Rate: 0.000455098
	LOSS [training: 0.11429394818047253 | validation: 0.11938762573188764]
	TIME [epoch: 9.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0909990006330572		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.0909990006330572 | validation: 0.10500471979029705]
	TIME [epoch: 9.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06865930122040291		[learning rate: 0.0004529]
	Learning Rate: 0.000452898
	LOSS [training: 0.06865930122040291 | validation: 0.08012583501397995]
	TIME [epoch: 9.52 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08346553782072147		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.08346553782072147 | validation: 0.13684582826249478]
	TIME [epoch: 9.51 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0877092954610278		[learning rate: 0.00045071]
	Learning Rate: 0.000450708
	LOSS [training: 0.0877092954610278 | validation: 0.08961091176985402]
	TIME [epoch: 9.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06320967162205046		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.06320967162205046 | validation: 0.07631998181898833]
	TIME [epoch: 9.5 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08078618295905476		[learning rate: 0.00044853]
	Learning Rate: 0.000448528
	LOSS [training: 0.08078618295905476 | validation: 0.09245942747371647]
	TIME [epoch: 9.53 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07631896793841993		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.07631896793841993 | validation: 0.10303075099609837]
	TIME [epoch: 9.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07389272409058738		[learning rate: 0.00044636]
	Learning Rate: 0.000446359
	LOSS [training: 0.07389272409058738 | validation: 0.10489602800099565]
	TIME [epoch: 9.5 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07567818709018634		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.07567818709018634 | validation: 0.0929467256822686]
	TIME [epoch: 9.51 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08386434463362893		[learning rate: 0.0004442]
	Learning Rate: 0.0004442
	LOSS [training: 0.08386434463362893 | validation: 0.1283587857155191]
	TIME [epoch: 9.51 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11138883615997179		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.11138883615997179 | validation: 0.1433012579018166]
	TIME [epoch: 9.5 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09230687297015619		[learning rate: 0.00044205]
	Learning Rate: 0.000442052
	LOSS [training: 0.09230687297015619 | validation: 0.09708410045842789]
	TIME [epoch: 9.5 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06805030435409251		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.06805030435409251 | validation: 0.12224069250922347]
	TIME [epoch: 9.52 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06452238769364131		[learning rate: 0.00043991]
	Learning Rate: 0.000439915
	LOSS [training: 0.06452238769364131 | validation: 0.1047904860850373]
	TIME [epoch: 9.51 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07969416025703117		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.07969416025703117 | validation: 0.12276502567375958]
	TIME [epoch: 9.5 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12705657537481113		[learning rate: 0.00043779]
	Learning Rate: 0.000437787
	LOSS [training: 0.12705657537481113 | validation: 0.15165219444880254]
	TIME [epoch: 9.51 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09342915124577236		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.09342915124577236 | validation: 0.09538066018541727]
	TIME [epoch: 9.52 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07859493863578312		[learning rate: 0.00043567]
	Learning Rate: 0.00043567
	LOSS [training: 0.07859493863578312 | validation: 0.10366084882048596]
	TIME [epoch: 9.5 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06894851203789512		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.06894851203789512 | validation: 0.08817801535910451]
	TIME [epoch: 9.5 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07025665008717763		[learning rate: 0.00043356]
	Learning Rate: 0.000433563
	LOSS [training: 0.07025665008717763 | validation: 0.11558481845326235]
	TIME [epoch: 9.51 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07658129754764731		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.07658129754764731 | validation: 0.08647063111613243]
	TIME [epoch: 9.51 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062132751782221815		[learning rate: 0.00043147]
	Learning Rate: 0.000431467
	LOSS [training: 0.062132751782221815 | validation: 0.09888298845416298]
	TIME [epoch: 9.51 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07210536349752833		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.07210536349752833 | validation: 0.10437272032168181]
	TIME [epoch: 9.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07403603972438268		[learning rate: 0.00042938]
	Learning Rate: 0.00042938
	LOSS [training: 0.07403603972438268 | validation: 0.1192875915833097]
	TIME [epoch: 9.51 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08195545633456841		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.08195545633456841 | validation: 0.10741480332279679]
	TIME [epoch: 9.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11121645422836104		[learning rate: 0.0004273]
	Learning Rate: 0.000427304
	LOSS [training: 0.11121645422836104 | validation: 0.11999298408308082]
	TIME [epoch: 9.5 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06950631345862086		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.06950631345862086 | validation: 0.0845775686275446]
	TIME [epoch: 9.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06591196994474387		[learning rate: 0.00042524]
	Learning Rate: 0.000425238
	LOSS [training: 0.06591196994474387 | validation: 0.12717831976142385]
	TIME [epoch: 9.52 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07737762971569014		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.07737762971569014 | validation: 0.09802247017359383]
	TIME [epoch: 9.51 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09301906756726937		[learning rate: 0.00042318]
	Learning Rate: 0.000423181
	LOSS [training: 0.09301906756726937 | validation: 0.11649574611801793]
	TIME [epoch: 9.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10136038577617004		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.10136038577617004 | validation: 0.13952857724085538]
	TIME [epoch: 9.52 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07959452743610938		[learning rate: 0.00042113]
	Learning Rate: 0.000421135
	LOSS [training: 0.07959452743610938 | validation: 0.12898919237699516]
	TIME [epoch: 9.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08139237559577236		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.08139237559577236 | validation: 0.09263697541191399]
	TIME [epoch: 9.52 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06724610853343713		[learning rate: 0.0004191]
	Learning Rate: 0.000419098
	LOSS [training: 0.06724610853343713 | validation: 0.10842507131059648]
	TIME [epoch: 9.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08137827158452939		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.08137827158452939 | validation: 0.10006334889708102]
	TIME [epoch: 9.51 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09113710011500212		[learning rate: 0.00041707]
	Learning Rate: 0.000417072
	LOSS [training: 0.09113710011500212 | validation: 0.11994396272698726]
	TIME [epoch: 9.51 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08963427461643327		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.08963427461643327 | validation: 0.08838192701534832]
	TIME [epoch: 9.49 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06089779034829838		[learning rate: 0.00041505]
	Learning Rate: 0.000415055
	LOSS [training: 0.06089779034829838 | validation: 0.0816693178184433]
	TIME [epoch: 9.5 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08754148457880394		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.08754148457880394 | validation: 0.10171439328731222]
	TIME [epoch: 9.51 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08265504956063915		[learning rate: 0.00041305]
	Learning Rate: 0.000413048
	LOSS [training: 0.08265504956063915 | validation: 0.0978387735923943]
	TIME [epoch: 9.5 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07331199367168768		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.07331199367168768 | validation: 0.08361939568310071]
	TIME [epoch: 9.5 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08794668175253446		[learning rate: 0.00041105]
	Learning Rate: 0.00041105
	LOSS [training: 0.08794668175253446 | validation: 0.11409870453497621]
	TIME [epoch: 9.52 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09992817284668047		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.09992817284668047 | validation: 0.0808198307695465]
	TIME [epoch: 9.51 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07764057691668805		[learning rate: 0.00040906]
	Learning Rate: 0.000409062
	LOSS [training: 0.07764057691668805 | validation: 0.12329742966921661]
	TIME [epoch: 9.5 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09996237089022701		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.09996237089022701 | validation: 0.08294991171813909]
	TIME [epoch: 9.51 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09217186657195554		[learning rate: 0.00040708]
	Learning Rate: 0.000407084
	LOSS [training: 0.09217186657195554 | validation: 0.07957234712342683]
	TIME [epoch: 9.51 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07812905690295673		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.07812905690295673 | validation: 0.09233536486355712]
	TIME [epoch: 9.51 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10534207174559014		[learning rate: 0.00040512]
	Learning Rate: 0.000405116
	LOSS [training: 0.10534207174559014 | validation: 0.1677274809070836]
	TIME [epoch: 9.5 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1272792355220059		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.1272792355220059 | validation: 0.15355786876403468]
	TIME [epoch: 9.51 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10043624089560972		[learning rate: 0.00040316]
	Learning Rate: 0.000403157
	LOSS [training: 0.10043624089560972 | validation: 0.10127289383397496]
	TIME [epoch: 9.52 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06670454739227871		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.06670454739227871 | validation: 0.07092547964016004]
	TIME [epoch: 9.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06793486194345927		[learning rate: 0.00040121]
	Learning Rate: 0.000401207
	LOSS [training: 0.06793486194345927 | validation: 0.10203756086608035]
	TIME [epoch: 9.5 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06485632823126035		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.06485632823126035 | validation: 0.0894860497348974]
	TIME [epoch: 9.52 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08888786937424722		[learning rate: 0.00039927]
	Learning Rate: 0.000399267
	LOSS [training: 0.08888786937424722 | validation: 0.14142055716596416]
	TIME [epoch: 9.5 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0801190554605118		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.0801190554605118 | validation: 0.07995203316098877]
	TIME [epoch: 9.51 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061103980089946844		[learning rate: 0.00039734]
	Learning Rate: 0.000397336
	LOSS [training: 0.061103980089946844 | validation: 0.09864767149514027]
	TIME [epoch: 9.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07244543709098392		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.07244543709098392 | validation: 0.10473270849568934]
	TIME [epoch: 9.52 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07604131216121017		[learning rate: 0.00039541]
	Learning Rate: 0.000395415
	LOSS [training: 0.07604131216121017 | validation: 0.10852238082321236]
	TIME [epoch: 9.51 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07848849164164566		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.07848849164164566 | validation: 0.09054441826035375]
	TIME [epoch: 9.51 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07596535029308094		[learning rate: 0.0003935]
	Learning Rate: 0.000393502
	LOSS [training: 0.07596535029308094 | validation: 0.1501662397409174]
	TIME [epoch: 9.5 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08688368573763366		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.08688368573763366 | validation: 0.1097441726475896]
	TIME [epoch: 9.52 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07199074672568857		[learning rate: 0.0003916]
	Learning Rate: 0.000391599
	LOSS [training: 0.07199074672568857 | validation: 0.10274112555212778]
	TIME [epoch: 9.5 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1046220610863565		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.1046220610863565 | validation: 0.1587043560588326]
	TIME [epoch: 9.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11057464747886112		[learning rate: 0.00038971]
	Learning Rate: 0.000389706
	LOSS [training: 0.11057464747886112 | validation: 0.150558203710012]
	TIME [epoch: 9.52 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08361534373141316		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.08361534373141316 | validation: 0.10059290891744439]
	TIME [epoch: 9.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0680033596453675		[learning rate: 0.00038782]
	Learning Rate: 0.000387821
	LOSS [training: 0.0680033596453675 | validation: 0.11025428441171624]
	TIME [epoch: 9.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06870372342521605		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.06870372342521605 | validation: 0.11568314090995083]
	TIME [epoch: 9.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09213336232398894		[learning rate: 0.00038595]
	Learning Rate: 0.000385946
	LOSS [training: 0.09213336232398894 | validation: 0.14527525185105464]
	TIME [epoch: 9.52 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08779488577584862		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.08779488577584862 | validation: 0.12260849152614749]
	TIME [epoch: 9.49 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08052677019749939		[learning rate: 0.00038408]
	Learning Rate: 0.000384079
	LOSS [training: 0.08052677019749939 | validation: 0.11479654527571857]
	TIME [epoch: 9.5 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07212228196134329		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.07212228196134329 | validation: 0.1033240291431238]
	TIME [epoch: 9.51 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09403434982916713		[learning rate: 0.00038222]
	Learning Rate: 0.000382222
	LOSS [training: 0.09403434982916713 | validation: 0.12418550757409587]
	TIME [epoch: 9.51 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08642119114621186		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.08642119114621186 | validation: 0.10619189768864243]
	TIME [epoch: 9.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08816003044189294		[learning rate: 0.00038037]
	Learning Rate: 0.000380374
	LOSS [training: 0.08816003044189294 | validation: 0.11716639454772027]
	TIME [epoch: 9.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07504656843024485		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.07504656843024485 | validation: 0.12793222303107074]
	TIME [epoch: 9.52 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08568254265721985		[learning rate: 0.00037853]
	Learning Rate: 0.000378534
	LOSS [training: 0.08568254265721985 | validation: 0.11683348766289468]
	TIME [epoch: 9.5 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.076184310992096		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.076184310992096 | validation: 0.09395976574560028]
	TIME [epoch: 9.5 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07365673703440659		[learning rate: 0.0003767]
	Learning Rate: 0.000376704
	LOSS [training: 0.07365673703440659 | validation: 0.11061931196655872]
	TIME [epoch: 9.5 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07189039563826546		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.07189039563826546 | validation: 0.11034416496340273]
	TIME [epoch: 9.52 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07760090945360157		[learning rate: 0.00037488]
	Learning Rate: 0.000374882
	LOSS [training: 0.07760090945360157 | validation: 0.0825396883768908]
	TIME [epoch: 9.51 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0766547697071435		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.0766547697071435 | validation: 0.09012325653470518]
	TIME [epoch: 9.51 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07241612257013483		[learning rate: 0.00037307]
	Learning Rate: 0.000373069
	LOSS [training: 0.07241612257013483 | validation: 0.08873808327833778]
	TIME [epoch: 9.5 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061874533080462715		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.061874533080462715 | validation: 0.09750149724391176]
	TIME [epoch: 9.51 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06830775452994998		[learning rate: 0.00037127]
	Learning Rate: 0.000371265
	LOSS [training: 0.06830775452994998 | validation: 0.09990949164309544]
	TIME [epoch: 9.51 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07128676948713779		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.07128676948713779 | validation: 0.10943210727371401]
	TIME [epoch: 9.51 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07356321466857609		[learning rate: 0.00036947]
	Learning Rate: 0.00036947
	LOSS [training: 0.07356321466857609 | validation: 0.09303799418368197]
	TIME [epoch: 9.53 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07280994351995242		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.07280994351995242 | validation: 0.0991716117318114]
	TIME [epoch: 9.51 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0686113661054942		[learning rate: 0.00036768]
	Learning Rate: 0.000367683
	LOSS [training: 0.0686113661054942 | validation: 0.09298289456290873]
	TIME [epoch: 9.51 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06988553027183513		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.06988553027183513 | validation: 0.11756015276872067]
	TIME [epoch: 9.51 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07332194352892064		[learning rate: 0.00036591]
	Learning Rate: 0.000365905
	LOSS [training: 0.07332194352892064 | validation: 0.10983101944429596]
	TIME [epoch: 9.52 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06481114545852366		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.06481114545852366 | validation: 0.10622224005596374]
	TIME [epoch: 9.52 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07587312882250284		[learning rate: 0.00036414]
	Learning Rate: 0.000364136
	LOSS [training: 0.07587312882250284 | validation: 0.08704325826069258]
	TIME [epoch: 9.51 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06467153790609637		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.06467153790609637 | validation: 0.0902936319745342]
	TIME [epoch: 9.52 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06740948833884074		[learning rate: 0.00036237]
	Learning Rate: 0.000362375
	LOSS [training: 0.06740948833884074 | validation: 0.097219564690745]
	TIME [epoch: 9.52 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062245653018296064		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.062245653018296064 | validation: 0.062021357621776706]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1470.pth
	Model improved!!!
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08313914343767634		[learning rate: 0.00036062]
	Learning Rate: 0.000360622
	LOSS [training: 0.08313914343767634 | validation: 0.08540275692192083]
	TIME [epoch: 9.52 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07791326001016942		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.07791326001016942 | validation: 0.10202448122993601]
	TIME [epoch: 9.54 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06268958112081328		[learning rate: 0.00035888]
	Learning Rate: 0.000358878
	LOSS [training: 0.06268958112081328 | validation: 0.07716162689257862]
	TIME [epoch: 9.52 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05724970970484938		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.05724970970484938 | validation: 0.12234132544774493]
	TIME [epoch: 9.52 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07901679507429228		[learning rate: 0.00035714]
	Learning Rate: 0.000357143
	LOSS [training: 0.07901679507429228 | validation: 0.07841520865024967]
	TIME [epoch: 9.52 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08878748935275159		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.08878748935275159 | validation: 0.11730867471999849]
	TIME [epoch: 9.54 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07690578294203756		[learning rate: 0.00035542]
	Learning Rate: 0.000355416
	LOSS [training: 0.07690578294203756 | validation: 0.07906730017684029]
	TIME [epoch: 9.52 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06467015719532328		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.06467015719532328 | validation: 0.09906629976238594]
	TIME [epoch: 9.52 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0704980751416664		[learning rate: 0.0003537]
	Learning Rate: 0.000353697
	LOSS [training: 0.0704980751416664 | validation: 0.12500009149037314]
	TIME [epoch: 9.54 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07340823265259758		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.07340823265259758 | validation: 0.110829428300266]
	TIME [epoch: 9.53 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06619090310811913		[learning rate: 0.00035199]
	Learning Rate: 0.000351987
	LOSS [training: 0.06619090310811913 | validation: 0.11656447471077559]
	TIME [epoch: 9.52 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07541663033783487		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.07541663033783487 | validation: 0.09921279747514516]
	TIME [epoch: 9.51 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07424338243048312		[learning rate: 0.00035028]
	Learning Rate: 0.000350285
	LOSS [training: 0.07424338243048312 | validation: 0.08741988252665708]
	TIME [epoch: 9.54 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0901504192220546		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.0901504192220546 | validation: 0.13443561205655105]
	TIME [epoch: 9.52 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09154143704843647		[learning rate: 0.00034859]
	Learning Rate: 0.000348591
	LOSS [training: 0.09154143704843647 | validation: 0.0806647128530192]
	TIME [epoch: 9.52 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06223220905396748		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.06223220905396748 | validation: 0.07378848198960598]
	TIME [epoch: 9.52 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06478753258205243		[learning rate: 0.0003469]
	Learning Rate: 0.000346905
	LOSS [training: 0.06478753258205243 | validation: 0.1022445147878421]
	TIME [epoch: 9.53 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07827664545602893		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.07827664545602893 | validation: 0.08188103027957518]
	TIME [epoch: 9.52 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0745143424269897		[learning rate: 0.00034523]
	Learning Rate: 0.000345227
	LOSS [training: 0.0745143424269897 | validation: 0.08007386416058541]
	TIME [epoch: 9.52 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05738966823246736		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.05738966823246736 | validation: 0.09374583200808094]
	TIME [epoch: 9.53 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06719966291556505		[learning rate: 0.00034356]
	Learning Rate: 0.000343558
	LOSS [training: 0.06719966291556505 | validation: 0.10598798684267]
	TIME [epoch: 9.52 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07220223133121724		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.07220223133121724 | validation: 0.09874017115129771]
	TIME [epoch: 9.52 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06138960425533655		[learning rate: 0.0003419]
	Learning Rate: 0.000341897
	LOSS [training: 0.06138960425533655 | validation: 0.08526873829841548]
	TIME [epoch: 9.52 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0681430741703983		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.0681430741703983 | validation: 0.10787564437507192]
	TIME [epoch: 9.53 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07061650528672854		[learning rate: 0.00034024]
	Learning Rate: 0.000340243
	LOSS [training: 0.07061650528672854 | validation: 0.09916988307755159]
	TIME [epoch: 9.52 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06842776023057294		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.06842776023057294 | validation: 0.10285704034138923]
	TIME [epoch: 9.51 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07090891184466099		[learning rate: 0.0003386]
	Learning Rate: 0.000338598
	LOSS [training: 0.07090891184466099 | validation: 0.12145296362403478]
	TIME [epoch: 9.52 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06850232464564204		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.06850232464564204 | validation: 0.0865408192082101]
	TIME [epoch: 9.54 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06743846654033009		[learning rate: 0.00033696]
	Learning Rate: 0.00033696
	LOSS [training: 0.06743846654033009 | validation: 0.10126929498364572]
	TIME [epoch: 9.52 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0641246876371005		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.0641246876371005 | validation: 0.08815154811695637]
	TIME [epoch: 9.51 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06496422996791053		[learning rate: 0.00033533]
	Learning Rate: 0.000335331
	LOSS [training: 0.06496422996791053 | validation: 0.09755319073919543]
	TIME [epoch: 9.53 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09080661583680807		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.09080661583680807 | validation: 0.09886852651840461]
	TIME [epoch: 9.52 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06965138516079392		[learning rate: 0.00033371]
	Learning Rate: 0.000333709
	LOSS [training: 0.06965138516079392 | validation: 0.11381763403142367]
	TIME [epoch: 9.52 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07230257102598306		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.07230257102598306 | validation: 0.07969350896415199]
	TIME [epoch: 9.52 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06148294194211569		[learning rate: 0.0003321]
	Learning Rate: 0.000332096
	LOSS [training: 0.06148294194211569 | validation: 0.0930302645265506]
	TIME [epoch: 9.54 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06827505012373533		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.06827505012373533 | validation: 0.09003937412944224]
	TIME [epoch: 9.52 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08737743127955373		[learning rate: 0.00033049]
	Learning Rate: 0.00033049
	LOSS [training: 0.08737743127955373 | validation: 0.12987987654820987]
	TIME [epoch: 9.52 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07771477807873989		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.07771477807873989 | validation: 0.07448182900147486]
	TIME [epoch: 9.52 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05559056994879604		[learning rate: 0.00032889]
	Learning Rate: 0.000328891
	LOSS [training: 0.05559056994879604 | validation: 0.07465935475031545]
	TIME [epoch: 9.53 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058411726765010774		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.058411726765010774 | validation: 0.07560319936400972]
	TIME [epoch: 9.52 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059430731690395075		[learning rate: 0.0003273]
	Learning Rate: 0.000327301
	LOSS [training: 0.059430731690395075 | validation: 0.11092641738356993]
	TIME [epoch: 9.52 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05846256342201321		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.05846256342201321 | validation: 0.08504463433498576]
	TIME [epoch: 9.53 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07351040440037429		[learning rate: 0.00032572]
	Learning Rate: 0.000325718
	LOSS [training: 0.07351040440037429 | validation: 0.0977315819102814]
	TIME [epoch: 9.52 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07212330623799186		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.07212330623799186 | validation: 0.06716294289256022]
	TIME [epoch: 9.52 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06944956205231792		[learning rate: 0.00032414]
	Learning Rate: 0.000324143
	LOSS [training: 0.06944956205231792 | validation: 0.07944165793617908]
	TIME [epoch: 9.53 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06827274833161856		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.06827274833161856 | validation: 0.08175426409425962]
	TIME [epoch: 9.54 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0760086598324194		[learning rate: 0.00032258]
	Learning Rate: 0.000322576
	LOSS [training: 0.0760086598324194 | validation: 0.0869725662102472]
	TIME [epoch: 9.52 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06293314225646388		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.06293314225646388 | validation: 0.07127582937309437]
	TIME [epoch: 9.51 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06717634526500647		[learning rate: 0.00032102]
	Learning Rate: 0.000321016
	LOSS [training: 0.06717634526500647 | validation: 0.10855727859424236]
	TIME [epoch: 9.52 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07896693000391575		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.07896693000391575 | validation: 0.108654519289479]
	TIME [epoch: 9.51 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06207018695858961		[learning rate: 0.00031946]
	Learning Rate: 0.000319463
	LOSS [training: 0.06207018695858961 | validation: 0.09621278320327069]
	TIME [epoch: 9.51 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09107375160541287		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.09107375160541287 | validation: 0.08322431302665803]
	TIME [epoch: 9.51 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08179223013190069		[learning rate: 0.00031792]
	Learning Rate: 0.000317918
	LOSS [training: 0.08179223013190069 | validation: 0.10378749348102838]
	TIME [epoch: 9.53 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0711558982788484		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.0711558982788484 | validation: 0.09312548558066172]
	TIME [epoch: 9.51 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07579058014016954		[learning rate: 0.00031638]
	Learning Rate: 0.000316381
	LOSS [training: 0.07579058014016954 | validation: 0.0787200464693454]
	TIME [epoch: 9.52 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06132872308090827		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.06132872308090827 | validation: 0.09751189943463835]
	TIME [epoch: 9.51 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06981456850507156		[learning rate: 0.00031485]
	Learning Rate: 0.000314851
	LOSS [training: 0.06981456850507156 | validation: 0.10664312954459025]
	TIME [epoch: 9.54 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06849169266346843		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.06849169266346843 | validation: 0.07140480048000031]
	TIME [epoch: 9.52 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05883622094598312		[learning rate: 0.00031333]
	Learning Rate: 0.000313329
	LOSS [training: 0.05883622094598312 | validation: 0.11161902075583942]
	TIME [epoch: 9.53 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0643401669437945		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.0643401669437945 | validation: 0.07724883019658121]
	TIME [epoch: 9.53 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05909568273467188		[learning rate: 0.00031181]
	Learning Rate: 0.000311813
	LOSS [training: 0.05909568273467188 | validation: 0.08421148515800696]
	TIME [epoch: 9.53 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0649639091104805		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.0649639091104805 | validation: 0.08884576685092432]
	TIME [epoch: 9.51 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0698668188636662		[learning rate: 0.00031031]
	Learning Rate: 0.000310305
	LOSS [training: 0.0698668188636662 | validation: 0.07767321411304677]
	TIME [epoch: 9.52 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07086366104667957		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.07086366104667957 | validation: 0.08623654928269697]
	TIME [epoch: 9.53 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0718247184485788		[learning rate: 0.0003088]
	Learning Rate: 0.000308805
	LOSS [training: 0.0718247184485788 | validation: 0.1418029933004284]
	TIME [epoch: 9.52 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1178638248259302		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.1178638248259302 | validation: 0.15018443647287186]
	TIME [epoch: 9.51 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07291399655555195		[learning rate: 0.00030731]
	Learning Rate: 0.000307312
	LOSS [training: 0.07291399655555195 | validation: 0.11360190669414952]
	TIME [epoch: 9.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06825070431184213		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.06825070431184213 | validation: 0.10106209745668178]
	TIME [epoch: 9.52 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06833604965510484		[learning rate: 0.00030583]
	Learning Rate: 0.000305826
	LOSS [training: 0.06833604965510484 | validation: 0.08873876637109988]
	TIME [epoch: 9.51 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06658757995661392		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.06658757995661392 | validation: 0.10954944255478502]
	TIME [epoch: 9.52 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0647995660335198		[learning rate: 0.00030435]
	Learning Rate: 0.000304347
	LOSS [training: 0.0647995660335198 | validation: 0.08289340955433135]
	TIME [epoch: 9.53 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05974824584843702		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.05974824584843702 | validation: 0.08937610585177075]
	TIME [epoch: 9.54 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06488872493196297		[learning rate: 0.00030287]
	Learning Rate: 0.000302875
	LOSS [training: 0.06488872493196297 | validation: 0.09228464511006823]
	TIME [epoch: 9.52 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06606081851037134		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.06606081851037134 | validation: 0.06449053939520553]
	TIME [epoch: 9.52 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07056327088231164		[learning rate: 0.00030141]
	Learning Rate: 0.00030141
	LOSS [training: 0.07056327088231164 | validation: 0.08971377935413558]
	TIME [epoch: 9.53 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07137110327509628		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.07137110327509628 | validation: 0.0820986768511648]
	TIME [epoch: 9.52 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06289302327032083		[learning rate: 0.00029995]
	Learning Rate: 0.000299953
	LOSS [training: 0.06289302327032083 | validation: 0.08356195470860904]
	TIME [epoch: 9.52 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055587474543095025		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.055587474543095025 | validation: 0.08749554213938528]
	TIME [epoch: 9.51 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06373396676063157		[learning rate: 0.0002985]
	Learning Rate: 0.000298502
	LOSS [training: 0.06373396676063157 | validation: 0.09428390555170274]
	TIME [epoch: 9.51 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07004959024904873		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.07004959024904873 | validation: 0.1027397597323256]
	TIME [epoch: 9.51 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07440777549781441		[learning rate: 0.00029706]
	Learning Rate: 0.000297059
	LOSS [training: 0.07440777549781441 | validation: 0.15126932965601506]
	TIME [epoch: 9.52 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06823792239545713		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.06823792239545713 | validation: 0.09248000153849169]
	TIME [epoch: 9.53 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07272925746097789		[learning rate: 0.00029562]
	Learning Rate: 0.000295622
	LOSS [training: 0.07272925746097789 | validation: 0.08914575664057474]
	TIME [epoch: 9.53 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0656901217894279		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.0656901217894279 | validation: 0.08014715244004289]
	TIME [epoch: 9.52 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05890040758931155		[learning rate: 0.00029419]
	Learning Rate: 0.000294193
	LOSS [training: 0.05890040758931155 | validation: 0.08212281841449176]
	TIME [epoch: 9.52 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06528334000145178		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.06528334000145178 | validation: 0.1203757515243643]
	TIME [epoch: 9.54 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08076010913400862		[learning rate: 0.00029277]
	Learning Rate: 0.00029277
	LOSS [training: 0.08076010913400862 | validation: 0.06844011929506666]
	TIME [epoch: 9.52 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06363028238784357		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.06363028238784357 | validation: 0.05989119321458298]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1558.pth
	Model improved!!!
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060132817082396706		[learning rate: 0.00029135]
	Learning Rate: 0.000291354
	LOSS [training: 0.060132817082396706 | validation: 0.08682682760855158]
	TIME [epoch: 9.52 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0685639238652576		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.0685639238652576 | validation: 0.0855769116674282]
	TIME [epoch: 9.52 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06911273280923018		[learning rate: 0.00028995]
	Learning Rate: 0.000289945
	LOSS [training: 0.06911273280923018 | validation: 0.0803424012834993]
	TIME [epoch: 9.51 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0602167466937788		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.0602167466937788 | validation: 0.08764146832951694]
	TIME [epoch: 9.51 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06945405830398159		[learning rate: 0.00028854]
	Learning Rate: 0.000288543
	LOSS [training: 0.06945405830398159 | validation: 0.11660264249146436]
	TIME [epoch: 9.51 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09636638175293986		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.09636638175293986 | validation: 0.1379827485166558]
	TIME [epoch: 9.51 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10798656274035492		[learning rate: 0.00028715]
	Learning Rate: 0.000287148
	LOSS [training: 0.10798656274035492 | validation: 0.1480694113690197]
	TIME [epoch: 9.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08447301660829802		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.08447301660829802 | validation: 0.14094323316054844]
	TIME [epoch: 9.51 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0979768921932623		[learning rate: 0.00028576]
	Learning Rate: 0.000285759
	LOSS [training: 0.0979768921932623 | validation: 0.1090900821366013]
	TIME [epoch: 9.53 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07829169328540646		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.07829169328540646 | validation: 0.1320654234933194]
	TIME [epoch: 9.51 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08588610084527884		[learning rate: 0.00028438]
	Learning Rate: 0.000284377
	LOSS [training: 0.08588610084527884 | validation: 0.12399725256883168]
	TIME [epoch: 9.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08793354175121418		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.08793354175121418 | validation: 0.1442696070192413]
	TIME [epoch: 9.51 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11510221972528747		[learning rate: 0.000283]
	Learning Rate: 0.000283002
	LOSS [training: 0.11510221972528747 | validation: 0.1371822188695169]
	TIME [epoch: 9.51 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08298275556576078		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.08298275556576078 | validation: 0.15392211173481596]
	TIME [epoch: 9.51 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10848333704116694		[learning rate: 0.00028163]
	Learning Rate: 0.000281633
	LOSS [training: 0.10848333704116694 | validation: 0.15491072625412927]
	TIME [epoch: 9.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09789477458493098		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.09789477458493098 | validation: 0.13549030401092568]
	TIME [epoch: 9.53 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0810885723181669		[learning rate: 0.00028027]
	Learning Rate: 0.000280272
	LOSS [training: 0.0810885723181669 | validation: 0.10070694804062726]
	TIME [epoch: 9.51 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07829239227176077		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.07829239227176077 | validation: 0.10587277446507959]
	TIME [epoch: 9.5 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07707171033908569		[learning rate: 0.00027892]
	Learning Rate: 0.000278916
	LOSS [training: 0.07707171033908569 | validation: 0.13397682808447503]
	TIME [epoch: 9.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09753445832057059		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.09753445832057059 | validation: 0.15698941027938126]
	TIME [epoch: 9.53 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09280318424568909		[learning rate: 0.00027757]
	Learning Rate: 0.000277567
	LOSS [training: 0.09280318424568909 | validation: 0.10300738165906609]
	TIME [epoch: 9.52 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07913609217769765		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.07913609217769765 | validation: 0.11144282270524718]
	TIME [epoch: 9.52 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0706718492692978		[learning rate: 0.00027623]
	Learning Rate: 0.000276225
	LOSS [training: 0.0706718492692978 | validation: 0.09742354331706288]
	TIME [epoch: 9.51 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07035209728798017		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.07035209728798017 | validation: 0.08574774719384522]
	TIME [epoch: 9.53 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0724727124203682		[learning rate: 0.00027489]
	Learning Rate: 0.000274889
	LOSS [training: 0.0724727124203682 | validation: 0.14500687324893283]
	TIME [epoch: 9.51 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0871682184634551		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.0871682184634551 | validation: 0.10693072622620939]
	TIME [epoch: 9.51 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07328941334809634		[learning rate: 0.00027356]
	Learning Rate: 0.00027356
	LOSS [training: 0.07328941334809634 | validation: 0.10129209707665938]
	TIME [epoch: 9.52 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07939081699457903		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.07939081699457903 | validation: 0.1059795271058713]
	TIME [epoch: 9.51 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07536091087041177		[learning rate: 0.00027224]
	Learning Rate: 0.000272237
	LOSS [training: 0.07536091087041177 | validation: 0.12715089351278308]
	TIME [epoch: 9.51 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0899826788397585		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.0899826788397585 | validation: 0.11874196083563902]
	TIME [epoch: 9.5 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07161535393442665		[learning rate: 0.00027092]
	Learning Rate: 0.000270921
	LOSS [training: 0.07161535393442665 | validation: 0.10608052494901184]
	TIME [epoch: 9.53 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0724051012771786		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.0724051012771786 | validation: 0.08218483663596668]
	TIME [epoch: 9.51 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05607022915590628		[learning rate: 0.00026961]
	Learning Rate: 0.000269611
	LOSS [training: 0.05607022915590628 | validation: 0.09860300912850395]
	TIME [epoch: 9.52 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07267557069704134		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.07267557069704134 | validation: 0.11151539749266355]
	TIME [epoch: 9.53 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0806328587255022		[learning rate: 0.00026831]
	Learning Rate: 0.000268307
	LOSS [training: 0.0806328587255022 | validation: 0.1312468500909525]
	TIME [epoch: 9.53 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0898671039472356		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.0898671039472356 | validation: 0.10186352433369006]
	TIME [epoch: 9.51 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06935785760095708		[learning rate: 0.00026701]
	Learning Rate: 0.000267009
	LOSS [training: 0.06935785760095708 | validation: 0.10929954706606473]
	TIME [epoch: 9.51 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07880787870711434		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.07880787870711434 | validation: 0.11410024035612247]
	TIME [epoch: 9.53 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07219545407146968		[learning rate: 0.00026572]
	Learning Rate: 0.000265718
	LOSS [training: 0.07219545407146968 | validation: 0.07959747645904298]
	TIME [epoch: 9.52 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06298450435458042		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.06298450435458042 | validation: 0.0871216928835567]
	TIME [epoch: 9.51 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06426610659554935		[learning rate: 0.00026443]
	Learning Rate: 0.000264433
	LOSS [training: 0.06426610659554935 | validation: 0.09360745710827718]
	TIME [epoch: 9.5 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07289402865883234		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.07289402865883234 | validation: 0.1048217306645537]
	TIME [epoch: 9.53 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0675397727787639		[learning rate: 0.00026315]
	Learning Rate: 0.000263154
	LOSS [training: 0.0675397727787639 | validation: 0.08022990860756973]
	TIME [epoch: 9.52 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06853007194716303		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.06853007194716303 | validation: 0.1135399985342041]
	TIME [epoch: 9.5 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06793511828715051		[learning rate: 0.00026188]
	Learning Rate: 0.000261882
	LOSS [training: 0.06793511828715051 | validation: 0.11350149796648357]
	TIME [epoch: 9.51 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06442198611593918		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.06442198611593918 | validation: 0.0887237450849319]
	TIME [epoch: 9.53 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06583174695467503		[learning rate: 0.00026062]
	Learning Rate: 0.000260615
	LOSS [training: 0.06583174695467503 | validation: 0.0834928944452491]
	TIME [epoch: 9.52 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06796230767174907		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.06796230767174907 | validation: 0.07808403861476447]
	TIME [epoch: 9.51 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06427652656042804		[learning rate: 0.00025936]
	Learning Rate: 0.000259355
	LOSS [training: 0.06427652656042804 | validation: 0.08025413096755088]
	TIME [epoch: 9.53 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061092445834063445		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.061092445834063445 | validation: 0.09169075750269685]
	TIME [epoch: 9.52 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07093451655485186		[learning rate: 0.0002581]
	Learning Rate: 0.000258101
	LOSS [training: 0.07093451655485186 | validation: 0.08095626794113127]
	TIME [epoch: 9.51 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05895055238757072		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.05895055238757072 | validation: 0.09952801407694105]
	TIME [epoch: 9.51 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06096244407272118		[learning rate: 0.00025685]
	Learning Rate: 0.000256853
	LOSS [training: 0.06096244407272118 | validation: 0.08971119387286196]
	TIME [epoch: 9.52 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06511306680782099		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.06511306680782099 | validation: 0.09284541072518959]
	TIME [epoch: 9.51 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09163818603683334		[learning rate: 0.00025561]
	Learning Rate: 0.000255611
	LOSS [training: 0.09163818603683334 | validation: 0.10155271074260214]
	TIME [epoch: 9.51 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0831580668915808		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.0831580668915808 | validation: 0.0935240863954864]
	TIME [epoch: 9.52 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08933148436535818		[learning rate: 0.00025437]
	Learning Rate: 0.000254375
	LOSS [training: 0.08933148436535818 | validation: 0.13350039258928864]
	TIME [epoch: 9.52 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08711972930787817		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.08711972930787817 | validation: 0.07945344680818028]
	TIME [epoch: 9.52 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0649309298740035		[learning rate: 0.00025314]
	Learning Rate: 0.000253144
	LOSS [training: 0.0649309298740035 | validation: 0.10065791280091287]
	TIME [epoch: 9.52 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0800992321784317		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.0800992321784317 | validation: 0.11632640999472414]
	TIME [epoch: 9.53 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06829150376426693		[learning rate: 0.00025192]
	Learning Rate: 0.00025192
	LOSS [training: 0.06829150376426693 | validation: 0.08834224108706139]
	TIME [epoch: 9.52 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06421535775487798		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.06421535775487798 | validation: 0.07014586107460609]
	TIME [epoch: 9.51 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06058342473427629		[learning rate: 0.0002507]
	Learning Rate: 0.000250702
	LOSS [training: 0.06058342473427629 | validation: 0.07675817032380597]
	TIME [epoch: 9.51 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059333890711542124		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.059333890711542124 | validation: 0.06047848322253569]
	TIME [epoch: 9.54 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05491237621539239		[learning rate: 0.00024949]
	Learning Rate: 0.00024949
	LOSS [training: 0.05491237621539239 | validation: 0.06637216442623181]
	TIME [epoch: 9.51 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.077572552032807		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.077572552032807 | validation: 0.10211785755931199]
	TIME [epoch: 9.52 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08022044136706773		[learning rate: 0.00024828]
	Learning Rate: 0.000248283
	LOSS [training: 0.08022044136706773 | validation: 0.1167398289212634]
	TIME [epoch: 9.52 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08044188941280235		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.08044188941280235 | validation: 0.10477681708726656]
	TIME [epoch: 9.53 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06433729269870082		[learning rate: 0.00024708]
	Learning Rate: 0.000247083
	LOSS [training: 0.06433729269870082 | validation: 0.0823257997913489]
	TIME [epoch: 9.51 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0684909114595395		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.0684909114595395 | validation: 0.10098613422344879]
	TIME [epoch: 9.51 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06602508115707298		[learning rate: 0.00024589]
	Learning Rate: 0.000245888
	LOSS [training: 0.06602508115707298 | validation: 0.07545779732246338]
	TIME [epoch: 9.53 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07968950606997494		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.07968950606997494 | validation: 0.08326107315707719]
	TIME [epoch: 9.52 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06751368244450733		[learning rate: 0.0002447]
	Learning Rate: 0.000244699
	LOSS [training: 0.06751368244450733 | validation: 0.08432895879540254]
	TIME [epoch: 9.51 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06388476457662014		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.06388476457662014 | validation: 0.08359353588202684]
	TIME [epoch: 9.51 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06153809947353765		[learning rate: 0.00024352]
	Learning Rate: 0.000243515
	LOSS [training: 0.06153809947353765 | validation: 0.09134048938576164]
	TIME [epoch: 9.53 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06098634365299056		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.06098634365299056 | validation: 0.09219146378912871]
	TIME [epoch: 9.51 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06494082132874177		[learning rate: 0.00024234]
	Learning Rate: 0.000242338
	LOSS [training: 0.06494082132874177 | validation: 0.07274123462567365]
	TIME [epoch: 9.51 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06038656179626434		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.06038656179626434 | validation: 0.08404799754421528]
	TIME [epoch: 9.52 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05984220888730196		[learning rate: 0.00024117]
	Learning Rate: 0.000241166
	LOSS [training: 0.05984220888730196 | validation: 0.07899070580737282]
	TIME [epoch: 9.51 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06421129091872711		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.06421129091872711 | validation: 0.08805395326527851]
	TIME [epoch: 9.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05963360723716271		[learning rate: 0.00024]
	Learning Rate: 0.00024
	LOSS [training: 0.05963360723716271 | validation: 0.08218397008596033]
	TIME [epoch: 9.51 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06495025969179828		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.06495025969179828 | validation: 0.08668527127125467]
	TIME [epoch: 9.53 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06821482572354884		[learning rate: 0.00023884]
	Learning Rate: 0.000238839
	LOSS [training: 0.06821482572354884 | validation: 0.09783362863704899]
	TIME [epoch: 9.52 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0580386109049833		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.0580386109049833 | validation: 0.08961602369976891]
	TIME [epoch: 9.51 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06274499748827715		[learning rate: 0.00023768]
	Learning Rate: 0.000237684
	LOSS [training: 0.06274499748827715 | validation: 0.09586178462698744]
	TIME [epoch: 9.52 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05847774665403018		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.05847774665403018 | validation: 0.07242974569068196]
	TIME [epoch: 9.54 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05394609442694276		[learning rate: 0.00023653]
	Learning Rate: 0.000236535
	LOSS [training: 0.05394609442694276 | validation: 0.07357333604455514]
	TIME [epoch: 9.51 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05777958784698448		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.05777958784698448 | validation: 0.11711908115596106]
	TIME [epoch: 9.51 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07649824389734194		[learning rate: 0.00023539]
	Learning Rate: 0.000235391
	LOSS [training: 0.07649824389734194 | validation: 0.09383700759626618]
	TIME [epoch: 9.53 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06620516261667998		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.06620516261667998 | validation: 0.08306529890065395]
	TIME [epoch: 9.51 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09432577171437657		[learning rate: 0.00023425]
	Learning Rate: 0.000234252
	LOSS [training: 0.09432577171437657 | validation: 0.09786586227798401]
	TIME [epoch: 9.52 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06352104691830532		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.06352104691830532 | validation: 0.07588248644588236]
	TIME [epoch: 9.51 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06193219821186936		[learning rate: 0.00023312]
	Learning Rate: 0.00023312
	LOSS [training: 0.06193219821186936 | validation: 0.08595884875781104]
	TIME [epoch: 9.53 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0657387950357321		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.0657387950357321 | validation: 0.08231465470991495]
	TIME [epoch: 9.51 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06289000145417262		[learning rate: 0.00023199]
	Learning Rate: 0.000231992
	LOSS [training: 0.06289000145417262 | validation: 0.09555903034607123]
	TIME [epoch: 9.52 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058450533296376936		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.058450533296376936 | validation: 0.060172448237066516]
	TIME [epoch: 9.52 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06627881038106817		[learning rate: 0.00023087]
	Learning Rate: 0.00023087
	LOSS [training: 0.06627881038106817 | validation: 0.09376062520474499]
	TIME [epoch: 9.54 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06483502755630151		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.06483502755630151 | validation: 0.10770855023218368]
	TIME [epoch: 9.52 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061432064708186476		[learning rate: 0.00022975]
	Learning Rate: 0.000229754
	LOSS [training: 0.061432064708186476 | validation: 0.09196674291688099]
	TIME [epoch: 9.51 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06464746587268157		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.06464746587268157 | validation: 0.07723603749484698]
	TIME [epoch: 9.53 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054174912522447535		[learning rate: 0.00022864]
	Learning Rate: 0.000228643
	LOSS [training: 0.054174912522447535 | validation: 0.10506781111014815]
	TIME [epoch: 9.51 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05782622037303202		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.05782622037303202 | validation: 0.06132666350446536]
	TIME [epoch: 9.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06710195533825702		[learning rate: 0.00022754]
	Learning Rate: 0.000227537
	LOSS [training: 0.06710195533825702 | validation: 0.12777220728914984]
	TIME [epoch: 9.5 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0746145618355758		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.0746145618355758 | validation: 0.09884224504900599]
	TIME [epoch: 9.52 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056930903152291226		[learning rate: 0.00022644]
	Learning Rate: 0.000226437
	LOSS [training: 0.056930903152291226 | validation: 0.10087236354087857]
	TIME [epoch: 9.51 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06095861309561913		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.06095861309561913 | validation: 0.07913736699119506]
	TIME [epoch: 9.51 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06465714944308891		[learning rate: 0.00022534]
	Learning Rate: 0.000225342
	LOSS [training: 0.06465714944308891 | validation: 0.06348833831741234]
	TIME [epoch: 9.5 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05937261877210007		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.05937261877210007 | validation: 0.0911683920987482]
	TIME [epoch: 9.52 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05890448528329574		[learning rate: 0.00022425]
	Learning Rate: 0.000224252
	LOSS [training: 0.05890448528329574 | validation: 0.10210973448863729]
	TIME [epoch: 9.51 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06525015995106884		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.06525015995106884 | validation: 0.10121344162634127]
	TIME [epoch: 9.51 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07074629230536103		[learning rate: 0.00022317]
	Learning Rate: 0.000223168
	LOSS [training: 0.07074629230536103 | validation: 0.0728238733109939]
	TIME [epoch: 9.52 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06877197488659297		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.06877197488659297 | validation: 0.12165072963893113]
	TIME [epoch: 9.51 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06753454081430534		[learning rate: 0.00022209]
	Learning Rate: 0.000222089
	LOSS [training: 0.06753454081430534 | validation: 0.09017199653084453]
	TIME [epoch: 9.51 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0714451348209256		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.0714451348209256 | validation: 0.09769095478208019]
	TIME [epoch: 9.5 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06766627351826437		[learning rate: 0.00022101]
	Learning Rate: 0.000221015
	LOSS [training: 0.06766627351826437 | validation: 0.08350860716097121]
	TIME [epoch: 9.52 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05858565330118658		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.05858565330118658 | validation: 0.07268909537533041]
	TIME [epoch: 9.51 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06477813720985849		[learning rate: 0.00021995]
	Learning Rate: 0.000219946
	LOSS [training: 0.06477813720985849 | validation: 0.079661333770577]
	TIME [epoch: 9.5 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05946264500345263		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.05946264500345263 | validation: 0.0929158671402066]
	TIME [epoch: 9.5 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06964241211296365		[learning rate: 0.00021888]
	Learning Rate: 0.000218882
	LOSS [training: 0.06964241211296365 | validation: 0.08330822561681096]
	TIME [epoch: 9.52 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059746278700951505		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.059746278700951505 | validation: 0.06449816835576773]
	TIME [epoch: 9.51 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06333247276069984		[learning rate: 0.00021782]
	Learning Rate: 0.000217824
	LOSS [training: 0.06333247276069984 | validation: 0.10248806810571641]
	TIME [epoch: 9.5 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06030172800912368		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.06030172800912368 | validation: 0.07434860615070629]
	TIME [epoch: 9.52 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05423366002543576		[learning rate: 0.00021677]
	Learning Rate: 0.00021677
	LOSS [training: 0.05423366002543576 | validation: 0.07704230503409033]
	TIME [epoch: 9.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054807348422937975		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.054807348422937975 | validation: 0.0682954906536755]
	TIME [epoch: 9.51 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051249861060158365		[learning rate: 0.00021572]
	Learning Rate: 0.000215722
	LOSS [training: 0.051249861060158365 | validation: 0.0702996783688187]
	TIME [epoch: 9.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05420404190001478		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.05420404190001478 | validation: 0.07234025107362466]
	TIME [epoch: 9.53 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04538431187574979		[learning rate: 0.00021468]
	Learning Rate: 0.000214679
	LOSS [training: 0.04538431187574979 | validation: 0.07910444116412423]
	TIME [epoch: 9.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059824406596393244		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.059824406596393244 | validation: 0.08299938521236616]
	TIME [epoch: 9.5 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06064196197449313		[learning rate: 0.00021364]
	Learning Rate: 0.000213641
	LOSS [training: 0.06064196197449313 | validation: 0.09693722793971996]
	TIME [epoch: 9.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05652842040424248		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.05652842040424248 | validation: 0.09445756918661255]
	TIME [epoch: 9.52 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0524937808533289		[learning rate: 0.00021261]
	Learning Rate: 0.000212608
	LOSS [training: 0.0524937808533289 | validation: 0.09462239414849608]
	TIME [epoch: 9.5 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05492966765894068		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.05492966765894068 | validation: 0.09371312051345027]
	TIME [epoch: 9.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06363582294391266		[learning rate: 0.00021158]
	Learning Rate: 0.00021158
	LOSS [training: 0.06363582294391266 | validation: 0.07184588974430503]
	TIME [epoch: 9.52 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05455986898687459		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.05455986898687459 | validation: 0.07380964057031045]
	TIME [epoch: 9.52 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05993235184837831		[learning rate: 0.00021056]
	Learning Rate: 0.000210556
	LOSS [training: 0.05993235184837831 | validation: 0.07798877098449937]
	TIME [epoch: 9.5 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06596181272046689		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.06596181272046689 | validation: 0.08863429483326943]
	TIME [epoch: 9.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06102789939545357		[learning rate: 0.00020954]
	Learning Rate: 0.000209538
	LOSS [training: 0.06102789939545357 | validation: 0.08137097499136753]
	TIME [epoch: 9.52 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06220344646579884		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.06220344646579884 | validation: 0.08622082172787518]
	TIME [epoch: 9.5 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06472699070578651		[learning rate: 0.00020852]
	Learning Rate: 0.000208525
	LOSS [training: 0.06472699070578651 | validation: 0.08753334748795652]
	TIME [epoch: 9.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06129120769303513		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.06129120769303513 | validation: 0.07757941294839353]
	TIME [epoch: 9.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0633047937460636		[learning rate: 0.00020752]
	Learning Rate: 0.000207516
	LOSS [training: 0.0633047937460636 | validation: 0.08812244146373133]
	TIME [epoch: 9.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0825947527170983		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.0825947527170983 | validation: 0.09099372920513364]
	TIME [epoch: 9.49 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07651060241694699		[learning rate: 0.00020651]
	Learning Rate: 0.000206513
	LOSS [training: 0.07651060241694699 | validation: 0.08992577513719446]
	TIME [epoch: 9.49 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06335487797465694		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.06335487797465694 | validation: 0.09968487611324661]
	TIME [epoch: 9.52 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06323083378718529		[learning rate: 0.00020551]
	Learning Rate: 0.000205514
	LOSS [training: 0.06323083378718529 | validation: 0.07818800509266091]
	TIME [epoch: 9.51 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07686319575346601		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.07686319575346601 | validation: 0.08376025229339722]
	TIME [epoch: 9.51 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07081986202423216		[learning rate: 0.00020452]
	Learning Rate: 0.000204521
	LOSS [training: 0.07081986202423216 | validation: 0.09054456333161025]
	TIME [epoch: 9.51 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061600267804550926		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.061600267804550926 | validation: 0.0860301318393445]
	TIME [epoch: 9.52 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057863573109497454		[learning rate: 0.00020353]
	Learning Rate: 0.000203531
	LOSS [training: 0.057863573109497454 | validation: 0.0784453393781068]
	TIME [epoch: 9.49 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056171125003749746		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.056171125003749746 | validation: 0.09921243548449994]
	TIME [epoch: 9.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060986201962853225		[learning rate: 0.00020255]
	Learning Rate: 0.000202547
	LOSS [training: 0.060986201962853225 | validation: 0.09027045949788864]
	TIME [epoch: 9.51 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06682026642313275		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.06682026642313275 | validation: 0.1001398427879677]
	TIME [epoch: 9.52 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06259859150517767		[learning rate: 0.00020157]
	Learning Rate: 0.000201568
	LOSS [training: 0.06259859150517767 | validation: 0.0799114372097325]
	TIME [epoch: 9.51 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06556496277300983		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.06556496277300983 | validation: 0.08808045345708732]
	TIME [epoch: 9.52 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05921151811260962		[learning rate: 0.00020059]
	Learning Rate: 0.000200593
	LOSS [training: 0.05921151811260962 | validation: 0.08334041092198304]
	TIME [epoch: 9.51 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06362195344188559		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.06362195344188559 | validation: 0.11788396685583237]
	TIME [epoch: 9.5 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07016172254439354		[learning rate: 0.00019962]
	Learning Rate: 0.000199623
	LOSS [training: 0.07016172254439354 | validation: 0.09051173309085489]
	TIME [epoch: 9.49 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060718987694588646		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.060718987694588646 | validation: 0.09933460176594458]
	TIME [epoch: 9.51 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05890082638118126		[learning rate: 0.00019866]
	Learning Rate: 0.000198658
	LOSS [training: 0.05890082638118126 | validation: 0.07480958011765122]
	TIME [epoch: 9.53 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057077574111965866		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.057077574111965866 | validation: 0.08457013796983975]
	TIME [epoch: 9.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058960749091316676		[learning rate: 0.0001977]
	Learning Rate: 0.000197697
	LOSS [training: 0.058960749091316676 | validation: 0.0828214349309717]
	TIME [epoch: 9.51 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052051410687455946		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.052051410687455946 | validation: 0.08209942422768865]
	TIME [epoch: 9.52 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05626485586072229		[learning rate: 0.00019674]
	Learning Rate: 0.000196741
	LOSS [training: 0.05626485586072229 | validation: 0.0914937208769939]
	TIME [epoch: 9.5 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05948465006292973		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.05948465006292973 | validation: 0.08914074424909747]
	TIME [epoch: 9.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055116426567689135		[learning rate: 0.00019579]
	Learning Rate: 0.00019579
	LOSS [training: 0.055116426567689135 | validation: 0.07515317074565621]
	TIME [epoch: 9.49 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054811787795854494		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.054811787795854494 | validation: 0.10600583065811764]
	TIME [epoch: 9.52 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07224725491752396		[learning rate: 0.00019484]
	Learning Rate: 0.000194843
	LOSS [training: 0.07224725491752396 | validation: 0.10547347463627482]
	TIME [epoch: 9.5 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07489374251494993		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.07489374251494993 | validation: 0.08677918116882306]
	TIME [epoch: 9.51 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0781324985327035		[learning rate: 0.0001939]
	Learning Rate: 0.000193901
	LOSS [training: 0.0781324985327035 | validation: 0.0996282194194841]
	TIME [epoch: 9.5 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06112624752091826		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.06112624752091826 | validation: 0.08257461776466803]
	TIME [epoch: 9.52 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05322034273367041		[learning rate: 0.00019296]
	Learning Rate: 0.000192963
	LOSS [training: 0.05322034273367041 | validation: 0.08110215859445816]
	TIME [epoch: 9.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042990400037668554		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.042990400037668554 | validation: 0.06123268562014635]
	TIME [epoch: 9.51 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054765385651186126		[learning rate: 0.00019203]
	Learning Rate: 0.00019203
	LOSS [training: 0.054765385651186126 | validation: 0.07283038014840369]
	TIME [epoch: 9.5 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05468254759086137		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.05468254759086137 | validation: 0.09358451295551738]
	TIME [epoch: 9.51 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0739417945696014		[learning rate: 0.0001911]
	Learning Rate: 0.000191101
	LOSS [training: 0.0739417945696014 | validation: 0.07065672946163136]
	TIME [epoch: 9.5 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07054571126582913		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.07054571126582913 | validation: 0.07568316610609023]
	TIME [epoch: 9.5 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06222282711370693		[learning rate: 0.00019018]
	Learning Rate: 0.000190177
	LOSS [training: 0.06222282711370693 | validation: 0.09090098572254723]
	TIME [epoch: 9.51 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06563307036990491		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.06563307036990491 | validation: 0.09659661180796]
	TIME [epoch: 9.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06012758417452872		[learning rate: 0.00018926]
	Learning Rate: 0.000189257
	LOSS [training: 0.06012758417452872 | validation: 0.08244666370396429]
	TIME [epoch: 9.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0560355245550895		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.0560355245550895 | validation: 0.09673570440303016]
	TIME [epoch: 9.5 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06945119886791051		[learning rate: 0.00018834]
	Learning Rate: 0.000188342
	LOSS [training: 0.06945119886791051 | validation: 0.06301599569493614]
	TIME [epoch: 9.52 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05978288854114522		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.05978288854114522 | validation: 0.0862865488438456]
	TIME [epoch: 9.52 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06322475463327257		[learning rate: 0.00018743]
	Learning Rate: 0.000187431
	LOSS [training: 0.06322475463327257 | validation: 0.06727581075919735]
	TIME [epoch: 9.49 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05427543826918681		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.05427543826918681 | validation: 0.08186704694424421]
	TIME [epoch: 9.53 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05406494182778225		[learning rate: 0.00018652]
	Learning Rate: 0.000186525
	LOSS [training: 0.05406494182778225 | validation: 0.07786919224924044]
	TIME [epoch: 9.51 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05607379003672035		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.05607379003672035 | validation: 0.06733798218376252]
	TIME [epoch: 9.52 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06000460906423265		[learning rate: 0.00018562]
	Learning Rate: 0.000185623
	LOSS [training: 0.06000460906423265 | validation: 0.07792037074885562]
	TIME [epoch: 9.49 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06802415589104024		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.06802415589104024 | validation: 0.08795445222825109]
	TIME [epoch: 9.52 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0616085901090341		[learning rate: 0.00018473]
	Learning Rate: 0.000184725
	LOSS [training: 0.0616085901090341 | validation: 0.08111461600217687]
	TIME [epoch: 9.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057139044302010576		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.057139044302010576 | validation: 0.077301383252287]
	TIME [epoch: 9.5 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05572611884253964		[learning rate: 0.00018383]
	Learning Rate: 0.000183832
	LOSS [training: 0.05572611884253964 | validation: 0.07464706109092328]
	TIME [epoch: 9.51 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06138878056170116		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.06138878056170116 | validation: 0.07533401972637041]
	TIME [epoch: 9.52 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06469397162541039		[learning rate: 0.00018294]
	Learning Rate: 0.000182943
	LOSS [training: 0.06469397162541039 | validation: 0.07819482536200129]
	TIME [epoch: 9.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05347424998596486		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.05347424998596486 | validation: 0.08838072816295946]
	TIME [epoch: 9.51 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05895291888620898		[learning rate: 0.00018206]
	Learning Rate: 0.000182058
	LOSS [training: 0.05895291888620898 | validation: 0.0819826058895174]
	TIME [epoch: 9.52 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04426498457982056		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.04426498457982056 | validation: 0.07014216889508756]
	TIME [epoch: 9.52 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06090596937494441		[learning rate: 0.00018118]
	Learning Rate: 0.000181178
	LOSS [training: 0.06090596937494441 | validation: 0.07314645776748604]
	TIME [epoch: 9.5 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06034039645054606		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.06034039645054606 | validation: 0.0844523593956434]
	TIME [epoch: 9.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05537283512276418		[learning rate: 0.0001803]
	Learning Rate: 0.000180302
	LOSS [training: 0.05537283512276418 | validation: 0.07021375631614916]
	TIME [epoch: 9.51 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05885896373688741		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.05885896373688741 | validation: 0.07590103699981109]
	TIME [epoch: 9.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06416833690495635		[learning rate: 0.00017943]
	Learning Rate: 0.00017943
	LOSS [training: 0.06416833690495635 | validation: 0.06856675935865823]
	TIME [epoch: 9.5 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06345296876594074		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.06345296876594074 | validation: 0.10949769132144953]
	TIME [epoch: 9.5 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06817453642030738		[learning rate: 0.00017856]
	Learning Rate: 0.000178562
	LOSS [training: 0.06817453642030738 | validation: 0.1069961863015671]
	TIME [epoch: 9.52 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0776787071130313		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.0776787071130313 | validation: 0.08594520223207124]
	TIME [epoch: 9.5 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07656156064922134		[learning rate: 0.0001777]
	Learning Rate: 0.000177699
	LOSS [training: 0.07656156064922134 | validation: 0.08843093599025108]
	TIME [epoch: 9.51 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0661550996964296		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.0661550996964296 | validation: 0.06399533527957296]
	TIME [epoch: 9.53 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05876916672786185		[learning rate: 0.00017684]
	Learning Rate: 0.000176839
	LOSS [training: 0.05876916672786185 | validation: 0.06952701815453653]
	TIME [epoch: 9.51 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06905126020332439		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.06905126020332439 | validation: 0.07943965883808646]
	TIME [epoch: 9.51 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06324044047152576		[learning rate: 0.00017598]
	Learning Rate: 0.000175984
	LOSS [training: 0.06324044047152576 | validation: 0.06676300027216782]
	TIME [epoch: 9.52 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0589756721089314		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.0589756721089314 | validation: 0.08124411564067462]
	TIME [epoch: 9.53 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06091527192221642		[learning rate: 0.00017513]
	Learning Rate: 0.000175133
	LOSS [training: 0.06091527192221642 | validation: 0.06703085069349546]
	TIME [epoch: 9.51 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05145223906746823		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.05145223906746823 | validation: 0.09309142756873845]
	TIME [epoch: 9.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05482475657542217		[learning rate: 0.00017429]
	Learning Rate: 0.000174286
	LOSS [training: 0.05482475657542217 | validation: 0.09552353528897246]
	TIME [epoch: 9.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06343179809282774		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.06343179809282774 | validation: 0.08883099166602812]
	TIME [epoch: 9.52 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05391145040357516		[learning rate: 0.00017344]
	Learning Rate: 0.000173443
	LOSS [training: 0.05391145040357516 | validation: 0.09518300499111718]
	TIME [epoch: 9.5 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05668156835776709		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.05668156835776709 | validation: 0.0753622113018453]
	TIME [epoch: 9.5 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06500137398951773		[learning rate: 0.0001726]
	Learning Rate: 0.000172605
	LOSS [training: 0.06500137398951773 | validation: 0.08145243869311987]
	TIME [epoch: 9.53 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0662698550227447		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.0662698550227447 | validation: 0.08659862101371119]
	TIME [epoch: 9.52 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05969648251427251		[learning rate: 0.00017177]
	Learning Rate: 0.00017177
	LOSS [training: 0.05969648251427251 | validation: 0.09607331919989286]
	TIME [epoch: 9.51 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06006904533222261		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.06006904533222261 | validation: 0.08015197025112322]
	TIME [epoch: 9.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04476471943561624		[learning rate: 0.00017094]
	Learning Rate: 0.000170939
	LOSS [training: 0.04476471943561624 | validation: 0.08150666873429589]
	TIME [epoch: 9.51 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05322611972205639		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.05322611972205639 | validation: 0.08493960500051685]
	TIME [epoch: 9.51 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06240643983205503		[learning rate: 0.00017011]
	Learning Rate: 0.000170113
	LOSS [training: 0.06240643983205503 | validation: 0.09956990982052513]
	TIME [epoch: 9.5 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059685000430060656		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.059685000430060656 | validation: 0.10137503008872362]
	TIME [epoch: 9.51 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055764205353920446		[learning rate: 0.00016929]
	Learning Rate: 0.00016929
	LOSS [training: 0.055764205353920446 | validation: 0.08826777636603302]
	TIME [epoch: 9.52 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05336241969995338		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.05336241969995338 | validation: 0.06663444963426013]
	TIME [epoch: 9.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05480417424866487		[learning rate: 0.00016847]
	Learning Rate: 0.000168471
	LOSS [training: 0.05480417424866487 | validation: 0.08028301800963047]
	TIME [epoch: 9.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060139315481626		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.060139315481626 | validation: 0.07612492443162917]
	TIME [epoch: 9.52 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06033972339609063		[learning rate: 0.00016766]
	Learning Rate: 0.000167657
	LOSS [training: 0.06033972339609063 | validation: 0.08105368724251719]
	TIME [epoch: 9.5 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0459615891736689		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.0459615891736689 | validation: 0.07820290690160198]
	TIME [epoch: 9.51 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05698530718585294		[learning rate: 0.00016685]
	Learning Rate: 0.000166846
	LOSS [training: 0.05698530718585294 | validation: 0.08271493891234659]
	TIME [epoch: 9.52 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053657204460111164		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.053657204460111164 | validation: 0.08172710911465207]
	TIME [epoch: 9.52 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05719978217601242		[learning rate: 0.00016604]
	Learning Rate: 0.000166039
	LOSS [training: 0.05719978217601242 | validation: 0.08541276744798668]
	TIME [epoch: 9.51 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053658713591658594		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.053658713591658594 | validation: 0.08220833940748858]
	TIME [epoch: 9.51 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05443406608805275		[learning rate: 0.00016524]
	Learning Rate: 0.000165236
	LOSS [training: 0.05443406608805275 | validation: 0.086387900196609]
	TIME [epoch: 9.52 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05823268890840168		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.05823268890840168 | validation: 0.10811442738838112]
	TIME [epoch: 9.51 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06749497448130662		[learning rate: 0.00016444]
	Learning Rate: 0.000164437
	LOSS [training: 0.06749497448130662 | validation: 0.10842774803914583]
	TIME [epoch: 9.5 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06312471168678466		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.06312471168678466 | validation: 0.08943734374400855]
	TIME [epoch: 9.5 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0528938653610588		[learning rate: 0.00016364]
	Learning Rate: 0.000163642
	LOSS [training: 0.0528938653610588 | validation: 0.08035107616373764]
	TIME [epoch: 9.52 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05740189840661347		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.05740189840661347 | validation: 0.1021264327415128]
	TIME [epoch: 9.51 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06981917352103081		[learning rate: 0.00016285]
	Learning Rate: 0.000162851
	LOSS [training: 0.06981917352103081 | validation: 0.1086690018105974]
	TIME [epoch: 9.52 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07728251153927088		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.07728251153927088 | validation: 0.13393900650333776]
	TIME [epoch: 9.51 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07968139105132938		[learning rate: 0.00016206]
	Learning Rate: 0.000162063
	LOSS [training: 0.07968139105132938 | validation: 0.09472777830129689]
	TIME [epoch: 9.53 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06552984820290003		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.06552984820290003 | validation: 0.08456213981993393]
	TIME [epoch: 9.52 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05930169757726874		[learning rate: 0.00016128]
	Learning Rate: 0.000161279
	LOSS [training: 0.05930169757726874 | validation: 0.07668234489165203]
	TIME [epoch: 9.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060435245721508726		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.060435245721508726 | validation: 0.08856167165377939]
	TIME [epoch: 9.52 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05938048809378935		[learning rate: 0.0001605]
	Learning Rate: 0.000160499
	LOSS [training: 0.05938048809378935 | validation: 0.08929660757582315]
	TIME [epoch: 9.51 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05720051814667385		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.05720051814667385 | validation: 0.08625010868374161]
	TIME [epoch: 9.5 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057223228379442645		[learning rate: 0.00015972]
	Learning Rate: 0.000159723
	LOSS [training: 0.057223228379442645 | validation: 0.08282288615921975]
	TIME [epoch: 9.51 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06149753728578409		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.06149753728578409 | validation: 0.11801265798499097]
	TIME [epoch: 9.52 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0629310455561568		[learning rate: 0.00015895]
	Learning Rate: 0.000158951
	LOSS [training: 0.0629310455561568 | validation: 0.11291188019244672]
	TIME [epoch: 9.5 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06210411193341749		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.06210411193341749 | validation: 0.08977180657397088]
	TIME [epoch: 9.51 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06049363346638674		[learning rate: 0.00015818]
	Learning Rate: 0.000158182
	LOSS [training: 0.06049363346638674 | validation: 0.07419930418645855]
	TIME [epoch: 9.5 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05836976224951231		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.05836976224951231 | validation: 0.08116142290308868]
	TIME [epoch: 9.52 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05843008024327294		[learning rate: 0.00015742]
	Learning Rate: 0.000157417
	LOSS [training: 0.05843008024327294 | validation: 0.08720095090948067]
	TIME [epoch: 9.51 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05934145612637291		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.05934145612637291 | validation: 0.11155613680822668]
	TIME [epoch: 9.5 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06696697907071468		[learning rate: 0.00015666]
	Learning Rate: 0.000156656
	LOSS [training: 0.06696697907071468 | validation: 0.06213452041232891]
	TIME [epoch: 9.51 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05680503972093902		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.05680503972093902 | validation: 0.08844415413169145]
	TIME [epoch: 9.51 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056189289362060135		[learning rate: 0.0001559]
	Learning Rate: 0.000155899
	LOSS [training: 0.056189289362060135 | validation: 0.07898616519013167]
	TIME [epoch: 9.51 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05042307732139271		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.05042307732139271 | validation: 0.08083267788653396]
	TIME [epoch: 9.5 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058375933746336185		[learning rate: 0.00015514]
	Learning Rate: 0.000155145
	LOSS [training: 0.058375933746336185 | validation: 0.08097436358345345]
	TIME [epoch: 9.51 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056156126425249794		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.056156126425249794 | validation: 0.08927811181453917]
	TIME [epoch: 9.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06227164257618517		[learning rate: 0.00015439]
	Learning Rate: 0.000154394
	LOSS [training: 0.06227164257618517 | validation: 0.09329973390715153]
	TIME [epoch: 9.49 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06065984739964314		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.06065984739964314 | validation: 0.0766477944141154]
	TIME [epoch: 9.51 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052445302546056706		[learning rate: 0.00015365]
	Learning Rate: 0.000153648
	LOSS [training: 0.052445302546056706 | validation: 0.09085694325719931]
	TIME [epoch: 9.51 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0519569895605112		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.0519569895605112 | validation: 0.07976877561955241]
	TIME [epoch: 9.5 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04741383046970295		[learning rate: 0.0001529]
	Learning Rate: 0.000152905
	LOSS [training: 0.04741383046970295 | validation: 0.08469214577794318]
	TIME [epoch: 9.51 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04583431007851991		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.04583431007851991 | validation: 0.08260559352538444]
	TIME [epoch: 9.51 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04996304496249633		[learning rate: 0.00015217]
	Learning Rate: 0.000152165
	LOSS [training: 0.04996304496249633 | validation: 0.07468115043242468]
	TIME [epoch: 9.52 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052418479517464825		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.052418479517464825 | validation: 0.09872950071153362]
	TIME [epoch: 9.51 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0628880109664193		[learning rate: 0.00015143]
	Learning Rate: 0.00015143
	LOSS [training: 0.0628880109664193 | validation: 0.08555268318407017]
	TIME [epoch: 9.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05238503880226612		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.05238503880226612 | validation: 0.08660134625967127]
	TIME [epoch: 9.52 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057635438884814635		[learning rate: 0.0001507]
	Learning Rate: 0.000150697
	LOSS [training: 0.057635438884814635 | validation: 0.0812295274757699]
	TIME [epoch: 9.52 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05257150293598747		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.05257150293598747 | validation: 0.07315249597046002]
	TIME [epoch: 9.51 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057372042356148234		[learning rate: 0.00014997]
	Learning Rate: 0.000149968
	LOSS [training: 0.057372042356148234 | validation: 0.09894108711416873]
	TIME [epoch: 9.5 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0645590160882706		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.0645590160882706 | validation: 0.06122429722723505]
	TIME [epoch: 9.53 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05632931424538919		[learning rate: 0.00014924]
	Learning Rate: 0.000149243
	LOSS [training: 0.05632931424538919 | validation: 0.07440005237400463]
	TIME [epoch: 9.5 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04779931369965861		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.04779931369965861 | validation: 0.08304822361446842]
	TIME [epoch: 9.51 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0564144016855628		[learning rate: 0.00014852]
	Learning Rate: 0.000148522
	LOSS [training: 0.0564144016855628 | validation: 0.07257655846275693]
	TIME [epoch: 9.53 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05267228546065311		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.05267228546065311 | validation: 0.08388562940578079]
	TIME [epoch: 9.51 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060525534349827395		[learning rate: 0.0001478]
	Learning Rate: 0.000147803
	LOSS [training: 0.060525534349827395 | validation: 0.08402772967364616]
	TIME [epoch: 9.5 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06396374201754759		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.06396374201754759 | validation: 0.09596089173242847]
	TIME [epoch: 9.51 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055627901621678945		[learning rate: 0.00014709]
	Learning Rate: 0.000147089
	LOSS [training: 0.055627901621678945 | validation: 0.07028870115184571]
	TIME [epoch: 9.53 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04873320490322066		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.04873320490322066 | validation: 0.07596611357657791]
	TIME [epoch: 9.53 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053636491155459556		[learning rate: 0.00014638]
	Learning Rate: 0.000146377
	LOSS [training: 0.053636491155459556 | validation: 0.07242348320932221]
	TIME [epoch: 9.53 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055888893038720334		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.055888893038720334 | validation: 0.0697793780121017]
	TIME [epoch: 9.51 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05767083782642218		[learning rate: 0.00014567]
	Learning Rate: 0.000145669
	LOSS [training: 0.05767083782642218 | validation: 0.07732780031360903]
	TIME [epoch: 9.54 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048757356499147496		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.048757356499147496 | validation: 0.06434589727828137]
	TIME [epoch: 9.52 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0549868161505339		[learning rate: 0.00014497]
	Learning Rate: 0.000144965
	LOSS [training: 0.0549868161505339 | validation: 0.08408725907476114]
	TIME [epoch: 9.51 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051441787164745255		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.051441787164745255 | validation: 0.0975312560827455]
	TIME [epoch: 9.53 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06569795935063152		[learning rate: 0.00014426]
	Learning Rate: 0.000144264
	LOSS [training: 0.06569795935063152 | validation: 0.06628239148650936]
	TIME [epoch: 9.52 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058187982851449147		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.058187982851449147 | validation: 0.07742556785261961]
	TIME [epoch: 9.52 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05874654875071735		[learning rate: 0.00014357]
	Learning Rate: 0.000143566
	LOSS [training: 0.05874654875071735 | validation: 0.06853096274195558]
	TIME [epoch: 9.51 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05276136618397448		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.05276136618397448 | validation: 0.07524669926340424]
	TIME [epoch: 9.53 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054685069078231244		[learning rate: 0.00014287]
	Learning Rate: 0.000142872
	LOSS [training: 0.054685069078231244 | validation: 0.06754921492070019]
	TIME [epoch: 9.52 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053169246424645614		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.053169246424645614 | validation: 0.06443760911155433]
	TIME [epoch: 9.51 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0582136852956864		[learning rate: 0.00014218]
	Learning Rate: 0.000142181
	LOSS [training: 0.0582136852956864 | validation: 0.08478560569016391]
	TIME [epoch: 9.53 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05505105304233373		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.05505105304233373 | validation: 0.056416125685875895]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1856.pth
	Model improved!!!
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05298104618441616		[learning rate: 0.00014149]
	Learning Rate: 0.000141494
	LOSS [training: 0.05298104618441616 | validation: 0.08866557235312698]
	TIME [epoch: 9.53 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05233257329578896		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.05233257329578896 | validation: 0.07092662510379871]
	TIME [epoch: 9.51 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0475712395792721		[learning rate: 0.00014081]
	Learning Rate: 0.000140809
	LOSS [training: 0.0475712395792721 | validation: 0.07810843999424232]
	TIME [epoch: 9.53 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061070485614464945		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.061070485614464945 | validation: 0.0811682325423228]
	TIME [epoch: 9.52 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0530384727570663		[learning rate: 0.00014013]
	Learning Rate: 0.000140128
	LOSS [training: 0.0530384727570663 | validation: 0.10672822142568354]
	TIME [epoch: 9.51 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06942258405742685		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.06942258405742685 | validation: 0.07983310127727028]
	TIME [epoch: 9.52 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054340860455562356		[learning rate: 0.00013945]
	Learning Rate: 0.000139451
	LOSS [training: 0.054340860455562356 | validation: 0.0701932195829023]
	TIME [epoch: 9.53 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051617235919724926		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.051617235919724926 | validation: 0.08897290831890434]
	TIME [epoch: 9.51 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059435073345653		[learning rate: 0.00013878]
	Learning Rate: 0.000138776
	LOSS [training: 0.059435073345653 | validation: 0.07387245052021964]
	TIME [epoch: 9.51 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0493901478417114		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.0493901478417114 | validation: 0.05575695615941049]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1866.pth
	Model improved!!!
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05121120668085867		[learning rate: 0.00013811]
	Learning Rate: 0.000138105
	LOSS [training: 0.05121120668085867 | validation: 0.07384566278780443]
	TIME [epoch: 9.53 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05614283060651868		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.05614283060651868 | validation: 0.08679696039613129]
	TIME [epoch: 9.51 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05346068359635682		[learning rate: 0.00013744]
	Learning Rate: 0.000137437
	LOSS [training: 0.05346068359635682 | validation: 0.07716157189430221]
	TIME [epoch: 9.52 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051052691901664914		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.051052691901664914 | validation: 0.06651989012259239]
	TIME [epoch: 9.53 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04972331418231297		[learning rate: 0.00013677]
	Learning Rate: 0.000136773
	LOSS [training: 0.04972331418231297 | validation: 0.06974262435878521]
	TIME [epoch: 9.51 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045443072132674435		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.045443072132674435 | validation: 0.06377666378779522]
	TIME [epoch: 9.52 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050554101471443756		[learning rate: 0.00013611]
	Learning Rate: 0.000136111
	LOSS [training: 0.050554101471443756 | validation: 0.07069915079924428]
	TIME [epoch: 9.53 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045892517227274894		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.045892517227274894 | validation: 0.08649440828950915]
	TIME [epoch: 9.53 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04747889895975973		[learning rate: 0.00013545]
	Learning Rate: 0.000135453
	LOSS [training: 0.04747889895975973 | validation: 0.08223922806944417]
	TIME [epoch: 9.52 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05006664968072355		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.05006664968072355 | validation: 0.08859361389057187]
	TIME [epoch: 9.54 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04557489496623145		[learning rate: 0.0001348]
	Learning Rate: 0.000134798
	LOSS [training: 0.04557489496623145 | validation: 0.06938472493701488]
	TIME [epoch: 9.53 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06323809773559924		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.06323809773559924 | validation: 0.06650765227866924]
	TIME [epoch: 9.51 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.064314476699033		[learning rate: 0.00013415]
	Learning Rate: 0.000134146
	LOSS [training: 0.064314476699033 | validation: 0.1004801875112814]
	TIME [epoch: 9.52 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0679970465789137		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.0679970465789137 | validation: 0.0896657774677574]
	TIME [epoch: 9.52 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059156418210079685		[learning rate: 0.0001335]
	Learning Rate: 0.000133498
	LOSS [training: 0.059156418210079685 | validation: 0.08604077051097857]
	TIME [epoch: 9.53 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06231983245113447		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.06231983245113447 | validation: 0.09397617778164621]
	TIME [epoch: 9.52 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06306747310813263		[learning rate: 0.00013285]
	Learning Rate: 0.000132852
	LOSS [training: 0.06306747310813263 | validation: 0.08633622037289125]
	TIME [epoch: 9.51 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06270772501734208		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.06270772501734208 | validation: 0.09370828184522384]
	TIME [epoch: 9.53 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05183206266989211		[learning rate: 0.00013221]
	Learning Rate: 0.00013221
	LOSS [training: 0.05183206266989211 | validation: 0.08728725390995898]
	TIME [epoch: 9.51 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05145234321796025		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.05145234321796025 | validation: 0.0628175427903551]
	TIME [epoch: 9.51 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04833528229224999		[learning rate: 0.00013157]
	Learning Rate: 0.00013157
	LOSS [training: 0.04833528229224999 | validation: 0.08371460557484206]
	TIME [epoch: 9.52 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05421209583001961		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.05421209583001961 | validation: 0.07792952006418787]
	TIME [epoch: 9.52 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046892401971564364		[learning rate: 0.00013093]
	Learning Rate: 0.000130934
	LOSS [training: 0.046892401971564364 | validation: 0.08280941460192817]
	TIME [epoch: 9.51 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059791550197255836		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.059791550197255836 | validation: 0.07769377411557446]
	TIME [epoch: 9.51 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05515345250363303		[learning rate: 0.0001303]
	Learning Rate: 0.000130301
	LOSS [training: 0.05515345250363303 | validation: 0.06866189626634374]
	TIME [epoch: 9.52 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050080886086254474		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.050080886086254474 | validation: 0.07005003690134863]
	TIME [epoch: 9.52 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05387783684901147		[learning rate: 0.00012967]
	Learning Rate: 0.000129671
	LOSS [training: 0.05387783684901147 | validation: 0.09189202262726993]
	TIME [epoch: 9.52 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06484282234897905		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.06484282234897905 | validation: 0.06708514270568837]
	TIME [epoch: 9.53 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058004378528910064		[learning rate: 0.00012904]
	Learning Rate: 0.000129044
	LOSS [training: 0.058004378528910064 | validation: 0.08874854800553336]
	TIME [epoch: 9.52 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06009009719407865		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.06009009719407865 | validation: 0.0750384211703049]
	TIME [epoch: 9.51 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05083252148548138		[learning rate: 0.00012842]
	Learning Rate: 0.00012842
	LOSS [training: 0.05083252148548138 | validation: 0.07044846945550967]
	TIME [epoch: 9.51 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049377235718244414		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.049377235718244414 | validation: 0.0857293825872047]
	TIME [epoch: 9.53 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048693540345334664		[learning rate: 0.0001278]
	Learning Rate: 0.000127799
	LOSS [training: 0.048693540345334664 | validation: 0.06554535661313779]
	TIME [epoch: 9.51 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044905272764488136		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.044905272764488136 | validation: 0.08544394544549348]
	TIME [epoch: 9.51 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04687476847932014		[learning rate: 0.00012718]
	Learning Rate: 0.000127181
	LOSS [training: 0.04687476847932014 | validation: 0.06426407691374365]
	TIME [epoch: 9.52 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054541208868305234		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.054541208868305234 | validation: 0.08283230836545069]
	TIME [epoch: 9.52 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05546839256814316		[learning rate: 0.00012657]
	Learning Rate: 0.000126566
	LOSS [training: 0.05546839256814316 | validation: 0.08091149174148055]
	TIME [epoch: 9.51 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05598558669103506		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.05598558669103506 | validation: 0.07203457921472618]
	TIME [epoch: 9.51 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04949795804844734		[learning rate: 0.00012595]
	Learning Rate: 0.000125954
	LOSS [training: 0.04949795804844734 | validation: 0.065501235480197]
	TIME [epoch: 9.54 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05210377122645564		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.05210377122645564 | validation: 0.04133295709879981]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240219_183144/states/model_tr_study5_1906.pth
	Model improved!!!
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04548209329083834		[learning rate: 0.00012534]
	Learning Rate: 0.000125345
	LOSS [training: 0.04548209329083834 | validation: 0.07667796833582609]
	TIME [epoch: 9.52 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05109718842908793		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.05109718842908793 | validation: 0.06642481947324413]
	TIME [epoch: 9.53 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05648886552991571		[learning rate: 0.00012474]
	Learning Rate: 0.000124738
	LOSS [training: 0.05648886552991571 | validation: 0.07451464669267308]
	TIME [epoch: 9.52 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05819879830322304		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.05819879830322304 | validation: 0.08233454047948026]
	TIME [epoch: 9.5 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05937630818328306		[learning rate: 0.00012414]
	Learning Rate: 0.000124135
	LOSS [training: 0.05937630818328306 | validation: 0.10217574842074151]
	TIME [epoch: 9.51 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05596464646898998		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.05596464646898998 | validation: 0.0817729574552666]
	TIME [epoch: 9.52 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05205535541863452		[learning rate: 0.00012353]
	Learning Rate: 0.000123535
	LOSS [training: 0.05205535541863452 | validation: 0.07537375850089971]
	TIME [epoch: 9.51 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05740992472888514		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.05740992472888514 | validation: 0.061510603604763466]
	TIME [epoch: 9.5 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053543883161057015		[learning rate: 0.00012294]
	Learning Rate: 0.000122937
	LOSS [training: 0.053543883161057015 | validation: 0.09583674702314846]
	TIME [epoch: 9.52 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059775976205596146		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.059775976205596146 | validation: 0.07672803637381564]
	TIME [epoch: 9.51 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055947070229435625		[learning rate: 0.00012234]
	Learning Rate: 0.000122343
	LOSS [training: 0.055947070229435625 | validation: 0.08810384273030185]
	TIME [epoch: 9.51 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05238353522241118		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.05238353522241118 | validation: 0.06561530559570673]
	TIME [epoch: 9.51 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04836618825050449		[learning rate: 0.00012175]
	Learning Rate: 0.000121751
	LOSS [training: 0.04836618825050449 | validation: 0.08707599092254459]
	TIME [epoch: 9.53 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054218061776669726		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.054218061776669726 | validation: 0.06164941284434505]
	TIME [epoch: 9.51 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050292627551225655		[learning rate: 0.00012116]
	Learning Rate: 0.000121163
	LOSS [training: 0.050292627551225655 | validation: 0.08298161253528796]
	TIME [epoch: 9.51 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05201099014439549		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.05201099014439549 | validation: 0.08008839039876055]
	TIME [epoch: 9.52 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053647303433201565		[learning rate: 0.00012058]
	Learning Rate: 0.000120577
	LOSS [training: 0.053647303433201565 | validation: 0.06067881974883859]
	TIME [epoch: 9.51 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05445948252824		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.05445948252824 | validation: 0.07553963678131616]
	TIME [epoch: 9.51 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05061125611429185		[learning rate: 0.00011999]
	Learning Rate: 0.000119994
	LOSS [training: 0.05061125611429185 | validation: 0.06397021821348883]
	TIME [epoch: 9.51 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06305483920391106		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.06305483920391106 | validation: 0.07106295596742011]
	TIME [epoch: 9.52 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05017831801192929		[learning rate: 0.00011941]
	Learning Rate: 0.000119413
	LOSS [training: 0.05017831801192929 | validation: 0.06914800704378127]
	TIME [epoch: 9.51 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05257112543016816		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.05257112543016816 | validation: 0.0778895406599648]
	TIME [epoch: 9.51 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05116910093970304		[learning rate: 0.00011884]
	Learning Rate: 0.000118836
	LOSS [training: 0.05116910093970304 | validation: 0.08059814149522655]
	TIME [epoch: 9.53 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04563127775246317		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.04563127775246317 | validation: 0.07976598105083038]
	TIME [epoch: 9.51 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04812599413367123		[learning rate: 0.00011826]
	Learning Rate: 0.000118261
	LOSS [training: 0.04812599413367123 | validation: 0.08746729155735139]
	TIME [epoch: 9.52 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05349096853760092		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.05349096853760092 | validation: 0.07633225111112084]
	TIME [epoch: 9.51 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05011186242588038		[learning rate: 0.00011769]
	Learning Rate: 0.000117689
	LOSS [training: 0.05011186242588038 | validation: 0.08977860311576728]
	TIME [epoch: 9.53 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04811462006335225		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.04811462006335225 | validation: 0.07453573967795586]
	TIME [epoch: 9.51 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04800433231553215		[learning rate: 0.00011712]
	Learning Rate: 0.00011712
	LOSS [training: 0.04800433231553215 | validation: 0.08429185650352505]
	TIME [epoch: 9.51 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06948398174547933		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.06948398174547933 | validation: 0.08213755671946757]
	TIME [epoch: 9.53 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05492240165404118		[learning rate: 0.00011655]
	Learning Rate: 0.000116554
	LOSS [training: 0.05492240165404118 | validation: 0.05874371110005711]
	TIME [epoch: 9.52 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04861117518750064		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.04861117518750064 | validation: 0.06852722805858197]
	TIME [epoch: 9.51 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03813078629709405		[learning rate: 0.00011599]
	Learning Rate: 0.00011599
	LOSS [training: 0.03813078629709405 | validation: 0.08734062975370722]
	TIME [epoch: 9.52 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04967773485569319		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.04967773485569319 | validation: 0.07720405968483714]
	TIME [epoch: 9.52 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050396618047409004		[learning rate: 0.00011543]
	Learning Rate: 0.000115429
	LOSS [training: 0.050396618047409004 | validation: 0.0791655858117523]
	TIME [epoch: 9.51 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05415051669869446		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.05415051669869446 | validation: 0.06668105937002426]
	TIME [epoch: 9.51 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05100999401396413		[learning rate: 0.00011487]
	Learning Rate: 0.000114871
	LOSS [training: 0.05100999401396413 | validation: 0.05984392166084325]
	TIME [epoch: 9.53 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05337512752732228		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.05337512752732228 | validation: 0.08046285854174977]
	TIME [epoch: 9.52 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05377110831881001		[learning rate: 0.00011432]
	Learning Rate: 0.000114316
	LOSS [training: 0.05377110831881001 | validation: 0.06949069007284156]
	TIME [epoch: 9.51 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05086067668337131		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.05086067668337131 | validation: 0.08670953594131266]
	TIME [epoch: 9.52 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04973513337071264		[learning rate: 0.00011376]
	Learning Rate: 0.000113763
	LOSS [training: 0.04973513337071264 | validation: 0.05493432915264412]
	TIME [epoch: 9.52 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05448530759285354		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.05448530759285354 | validation: 0.06887458710286466]
	TIME [epoch: 9.51 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0568557199206398		[learning rate: 0.00011321]
	Learning Rate: 0.000113213
	LOSS [training: 0.0568557199206398 | validation: 0.09177408400827743]
	TIME [epoch: 9.51 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05001489928015764		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.05001489928015764 | validation: 0.07194597247591399]
	TIME [epoch: 9.52 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0487933728759681		[learning rate: 0.00011267]
	Learning Rate: 0.000112665
	LOSS [training: 0.0487933728759681 | validation: 0.07336101791952715]
	TIME [epoch: 9.51 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04741300768869391		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.04741300768869391 | validation: 0.06830323044967265]
	TIME [epoch: 9.51 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04467122638904959		[learning rate: 0.00011212]
	Learning Rate: 0.00011212
	LOSS [training: 0.04467122638904959 | validation: 0.07867998613066492]
	TIME [epoch: 9.51 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05004456597846631		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.05004456597846631 | validation: 0.08428237913047085]
	TIME [epoch: 9.52 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049593202126462024		[learning rate: 0.00011158]
	Learning Rate: 0.000111578
	LOSS [training: 0.049593202126462024 | validation: 0.07642162792716736]
	TIME [epoch: 9.51 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04661704936444329		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.04661704936444329 | validation: 0.07165556515936343]
	TIME [epoch: 9.52 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05100872475235681		[learning rate: 0.00011104]
	Learning Rate: 0.000111039
	LOSS [training: 0.05100872475235681 | validation: 0.07778204821138339]
	TIME [epoch: 9.53 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04637599722283478		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.04637599722283478 | validation: 0.08227357719217818]
	TIME [epoch: 9.51 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04797667761401508		[learning rate: 0.0001105]
	Learning Rate: 0.000110502
	LOSS [training: 0.04797667761401508 | validation: 0.07799099007806327]
	TIME [epoch: 9.51 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04512877298688906		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.04512877298688906 | validation: 0.08837456420216856]
	TIME [epoch: 9.53 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05445339420617675		[learning rate: 0.00010997]
	Learning Rate: 0.000109967
	LOSS [training: 0.05445339420617675 | validation: 0.06785296059738408]
	TIME [epoch: 9.51 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05314080469528657		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.05314080469528657 | validation: 0.09744015379793936]
	TIME [epoch: 9.51 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0514664285157981		[learning rate: 0.00010944]
	Learning Rate: 0.000109435
	LOSS [training: 0.0514664285157981 | validation: 0.07779383695421385]
	TIME [epoch: 9.51 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049745939155960636		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.049745939155960636 | validation: 0.06031459086694966]
	TIME [epoch: 9.52 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04441202999321943		[learning rate: 0.00010891]
	Learning Rate: 0.000108906
	LOSS [training: 0.04441202999321943 | validation: 0.07791859856348628]
	TIME [epoch: 9.51 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057806044385244726		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.057806044385244726 | validation: 0.07815256362192796]
	TIME [epoch: 9.51 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05352091251615183		[learning rate: 0.00010838]
	Learning Rate: 0.00010838
	LOSS [training: 0.05352091251615183 | validation: 0.06977834882850484]
	TIME [epoch: 9.52 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04585437067089436		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.04585437067089436 | validation: 0.08641025876512236]
	TIME [epoch: 9.51 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04872424060578372		[learning rate: 0.00010786]
	Learning Rate: 0.000107855
	LOSS [training: 0.04872424060578372 | validation: 0.07482588239654428]
	TIME [epoch: 9.51 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04933510882007259		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.04933510882007259 | validation: 0.08092359069403235]
	TIME [epoch: 9.51 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0586517084331223		[learning rate: 0.00010733]
	Learning Rate: 0.000107334
	LOSS [training: 0.0586517084331223 | validation: 0.07340159978309899]
	TIME [epoch: 9.53 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05432219287973752		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.05432219287973752 | validation: 0.08384134602420716]
	TIME [epoch: 9.51 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05278268307997056		[learning rate: 0.00010681]
	Learning Rate: 0.000106815
	LOSS [training: 0.05278268307997056 | validation: 0.09062412391546175]
	TIME [epoch: 9.51 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06298088769284832		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.06298088769284832 | validation: 0.10452827178151498]
	TIME [epoch: 9.53 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05226389861517251		[learning rate: 0.0001063]
	Learning Rate: 0.000106298
	LOSS [training: 0.05226389861517251 | validation: 0.07944253352161802]
	TIME [epoch: 9.51 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04758652807904795		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.04758652807904795 | validation: 0.06267048645135859]
	TIME [epoch: 9.51 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051679191061731675		[learning rate: 0.00010578]
	Learning Rate: 0.000105784
	LOSS [training: 0.051679191061731675 | validation: 0.0937474242240346]
	TIME [epoch: 9.51 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05347471651161874		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.05347471651161874 | validation: 0.07911091009476827]
	TIME [epoch: 9.52 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055941249437626836		[learning rate: 0.00010527]
	Learning Rate: 0.000105273
	LOSS [training: 0.055941249437626836 | validation: 0.07284049309479837]
	TIME [epoch: 9.51 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04151494693549036		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.04151494693549036 | validation: 0.07923859943712606]
	TIME [epoch: 9.51 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05051886880014418		[learning rate: 0.00010476]
	Learning Rate: 0.000104764
	LOSS [training: 0.05051886880014418 | validation: 0.08196854356992567]
	TIME [epoch: 9.53 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06714169355351476		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.06714169355351476 | validation: 0.08721143008489735]
	TIME [epoch: 9.52 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06352927342884496		[learning rate: 0.00010426]
	Learning Rate: 0.000104257
	LOSS [training: 0.06352927342884496 | validation: 0.0886168084353509]
	TIME [epoch: 9.51 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05077490469204362		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.05077490469204362 | validation: 0.055707039443059665]
	TIME [epoch: 9.51 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047127373080421316		[learning rate: 0.00010375]
	Learning Rate: 0.000103753
	LOSS [training: 0.047127373080421316 | validation: 0.05552195632972312]
	TIME [epoch: 9.53 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04727305866215128		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.04727305866215128 | validation: 0.07616798698101274]
	TIME [epoch: 9.52 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05173164786645842		[learning rate: 0.00010325]
	Learning Rate: 0.000103251
	LOSS [training: 0.05173164786645842 | validation: 0.07906416871773032]
	TIME [epoch: 9.51 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050996097486669265		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.050996097486669265 | validation: 0.10223528372185917]
	TIME [epoch: 9.52 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05886111020664915		[learning rate: 0.00010275]
	Learning Rate: 0.000102752
	LOSS [training: 0.05886111020664915 | validation: 0.09306408472154656]
	TIME [epoch: 9.51 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05346610808514964		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.05346610808514964 | validation: 0.08925885783296074]
	TIME [epoch: 9.52 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057315164510165606		[learning rate: 0.00010225]
	Learning Rate: 0.000102255
	LOSS [training: 0.057315164510165606 | validation: 0.10051045694363624]
	TIME [epoch: 9.51 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06358445894206807		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.06358445894206807 | validation: 0.09505798784849886]
	TIME [epoch: 9.53 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057618007911331356		[learning rate: 0.00010176]
	Learning Rate: 0.00010176
	LOSS [training: 0.057618007911331356 | validation: 0.09789962760289818]
	TIME [epoch: 9.51 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06345240971883045		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.06345240971883045 | validation: 0.07715821467132843]
	TIME [epoch: 9.52 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05842475480675561		[learning rate: 0.00010127]
	Learning Rate: 0.000101268
	LOSS [training: 0.05842475480675561 | validation: 0.08894611392522266]
	TIME [epoch: 9.53 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05433934853894449		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.05433934853894449 | validation: 0.08521123301767096]
	TIME [epoch: 9.51 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06148984026738612		[learning rate: 0.00010078]
	Learning Rate: 0.000100779
	LOSS [training: 0.06148984026738612 | validation: 0.08904736497240227]
	TIME [epoch: 9.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05368834059210623		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.05368834059210623 | validation: 0.07256585906250933]
	TIME [epoch: 9.52 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05768374096167258		[learning rate: 0.00010029]
	Learning Rate: 0.000100291
	LOSS [training: 0.05768374096167258 | validation: 0.06241774618037834]
	TIME [epoch: 9.52 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061259407448109995		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.061259407448109995 | validation: 0.08404572086861639]
	TIME [epoch: 9.51 sec]
Finished training in 19167.271 seconds.
