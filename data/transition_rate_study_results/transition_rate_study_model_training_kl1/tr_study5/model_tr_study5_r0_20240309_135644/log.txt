Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r0', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4049246816

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.487716824106514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.487716824106514 | validation: 10.795444711325917]
	TIME [epoch: 112 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.681497059769923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.681497059769923 | validation: 9.191721588032605]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.50804914504066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.50804914504066 | validation: 9.112611958075474]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.021646860632227		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.021646860632227 | validation: 7.992236690253324]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.210098792174169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.210098792174169 | validation: 7.426956488339682]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.545890279801588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.545890279801588 | validation: 6.578032374281065]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.463151292087783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.463151292087783 | validation: 6.030555304631816]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.927240174108623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.927240174108623 | validation: 6.051421705243056]
	TIME [epoch: 24.9 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.936207094202651		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.936207094202651 | validation: 5.824112960635782]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.943236266101127		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.943236266101127 | validation: 6.959744321184099]
	TIME [epoch: 25 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.002442389866751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.002442389866751 | validation: 5.720598715930046]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.538144625283292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.538144625283292 | validation: 5.718112948824557]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.450184248664027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.450184248664027 | validation: 5.657259337165764]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4559097201508955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4559097201508955 | validation: 5.77804833368665]
	TIME [epoch: 24.9 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.544391078005579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.544391078005579 | validation: 6.131848773968013]
	TIME [epoch: 25 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.59563861265222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.59563861265222 | validation: 5.713812835629511]
	TIME [epoch: 25 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5821534367891665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5821534367891665 | validation: 5.743168054143341]
	TIME [epoch: 24.9 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.531398722551341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.531398722551341 | validation: 5.721626628361544]
	TIME [epoch: 25 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.521991072702052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.521991072702052 | validation: 5.615694168077846]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.500282426341796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.500282426341796 | validation: 5.796328803608037]
	TIME [epoch: 24.9 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.525603812299751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.525603812299751 | validation: 5.796961129423689]
	TIME [epoch: 25 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.473381561645904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.473381561645904 | validation: 5.879620422021568]
	TIME [epoch: 24.9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.394865486112567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.394865486112567 | validation: 5.782170349648015]
	TIME [epoch: 25 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.401293612925859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.401293612925859 | validation: 5.645672886171028]
	TIME [epoch: 25 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3339686369711465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3339686369711465 | validation: 5.633557228357999]
	TIME [epoch: 24.9 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.403419351717927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.403419351717927 | validation: 5.635265669991506]
	TIME [epoch: 25 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.343335646107992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.343335646107992 | validation: 5.778202334265358]
	TIME [epoch: 25 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3374741465481375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3374741465481375 | validation: 5.466260023233393]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2779334966769005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2779334966769005 | validation: 5.741025150755397]
	TIME [epoch: 25 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.18746294996803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.18746294996803 | validation: 5.540045121253447]
	TIME [epoch: 24.9 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.183052537635968		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.183052537635968 | validation: 5.424359457476214]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.29848459985717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.29848459985717 | validation: 5.639429928352712]
	TIME [epoch: 25 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.183396880609682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.183396880609682 | validation: 5.542883341470856]
	TIME [epoch: 24.9 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.044597461257427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.044597461257427 | validation: 5.2998902010831195]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.860909032502519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.860909032502519 | validation: 6.949138624086687]
	TIME [epoch: 25 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.772024199861043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.772024199861043 | validation: 5.301621271829228]
	TIME [epoch: 24.9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.160172677498455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.160172677498455 | validation: 5.3415419918324645]
	TIME [epoch: 25 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9759382013778986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.9759382013778986 | validation: 5.501738251360498]
	TIME [epoch: 25 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.962848930225807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.962848930225807 | validation: 5.116687063656476]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.799007431806961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.799007431806961 | validation: 4.8380466766155505]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.751574549238503		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.751574549238503 | validation: 4.777162357608627]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.479663332512593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.479663332512593 | validation: 4.706321779678043]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.561740030138594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.561740030138594 | validation: 4.10256113493086]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.186508334487829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.186508334487829 | validation: 4.503238702146351]
	TIME [epoch: 25 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.235119791961355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.235119791961355 | validation: 3.904818123159121]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6987418263346874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6987418263346874 | validation: 5.2385095557411185]
	TIME [epoch: 25 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.432359619085673		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.432359619085673 | validation: 4.03286218379621]
	TIME [epoch: 25 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.327782872200917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.327782872200917 | validation: 5.827429476447073]
	TIME [epoch: 25 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.058392898826308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.058392898826308 | validation: 3.5561444151856993]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0410857872448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0410857872448 | validation: 7.252985797627002]
	TIME [epoch: 25 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.417462415006671		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 7.417462415006671 | validation: 6.320777185712955]
	TIME [epoch: 25 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.033374998570038		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 6.033374998570038 | validation: 4.87327085157594]
	TIME [epoch: 25 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6350881613894375		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 4.6350881613894375 | validation: 6.164806524423276]
	TIME [epoch: 25 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.010152260663473		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.010152260663473 | validation: 4.341424980904504]
	TIME [epoch: 25 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8726460273892385		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.8726460273892385 | validation: 4.763853746155173]
	TIME [epoch: 25 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.408779051810701		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.408779051810701 | validation: 5.120593028217481]
	TIME [epoch: 25 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.450766756061901		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 4.450766756061901 | validation: 5.036542311235758]
	TIME [epoch: 25 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9740608916848625		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 4.9740608916848625 | validation: 4.439315013314592]
	TIME [epoch: 25 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.989441410146725		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.989441410146725 | validation: 3.7832193718261524]
	TIME [epoch: 25 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39516996595441		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.39516996595441 | validation: 3.517512363654228]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.311951810308545		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.311951810308545 | validation: 3.0881501687471316]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0066071000970798		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 3.0066071000970798 | validation: 2.9824876944704943]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.271954941265561		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.271954941265561 | validation: 3.582149545469464]
	TIME [epoch: 25 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.118810360676797		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.118810360676797 | validation: 3.5144359141933843]
	TIME [epoch: 25 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4374038275296246		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.4374038275296246 | validation: 3.797333501765328]
	TIME [epoch: 25 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.002171779231865		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.002171779231865 | validation: 3.8039491046325664]
	TIME [epoch: 25 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.354655169558445		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.354655169558445 | validation: 3.2159197416735537]
	TIME [epoch: 25.1 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2908251071242183		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.2908251071242183 | validation: 3.2741013559344094]
	TIME [epoch: 25 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.393720257932504		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.393720257932504 | validation: 2.9386092162166655]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9564138450897555		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.9564138450897555 | validation: 3.2142648450302285]
	TIME [epoch: 25 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.744957570461831		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.744957570461831 | validation: 3.525939047685352]
	TIME [epoch: 25 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.915323010733167		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.915323010733167 | validation: 2.5488902663078425]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_72.pth
	Model improved!!!
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.803074217344182		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.803074217344182 | validation: 3.020778674918297]
	TIME [epoch: 25 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4288839186784745		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.4288839186784745 | validation: 4.412380412411836]
	TIME [epoch: 25 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2239351136357657		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.2239351136357657 | validation: 2.8343360388352528]
	TIME [epoch: 25 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2871269057242642		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.2871269057242642 | validation: 3.201798493066399]
	TIME [epoch: 25 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.834906540883543		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.834906540883543 | validation: 3.2046758005851315]
	TIME [epoch: 25 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6642167225124744		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.6642167225124744 | validation: 2.9324419456069024]
	TIME [epoch: 25 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.577093389306478		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.577093389306478 | validation: 2.35877903248302]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2333512034611296		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.2333512034611296 | validation: 2.6020499558617862]
	TIME [epoch: 25 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.53952612084655		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.53952612084655 | validation: 2.403812109540076]
	TIME [epoch: 25 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.232873954533025		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.232873954533025 | validation: 2.742571440185519]
	TIME [epoch: 25 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6172139506986665		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.6172139506986665 | validation: 2.4776257316337493]
	TIME [epoch: 25 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.220818484565098		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 5.220818484565098 | validation: 4.460061027011194]
	TIME [epoch: 25 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.80995589741105		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.80995589741105 | validation: 4.28560443433429]
	TIME [epoch: 25 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5882809405149514		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.5882809405149514 | validation: 2.8456157010961136]
	TIME [epoch: 25 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.571377795747731		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.571377795747731 | validation: 2.8176396980383487]
	TIME [epoch: 25 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3577239200645734		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.3577239200645734 | validation: 4.843819772238657]
	TIME [epoch: 25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.413601853173744		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.413601853173744 | validation: 2.6611192080525585]
	TIME [epoch: 25 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4670392585391068		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.4670392585391068 | validation: 3.6129840306952627]
	TIME [epoch: 25 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.037753477876797		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.037753477876797 | validation: 2.6767069940086525]
	TIME [epoch: 25 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.206269255088741		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.206269255088741 | validation: 7.537721598257535]
	TIME [epoch: 25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.015707184035149		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 5.015707184035149 | validation: 2.474824670029754]
	TIME [epoch: 25 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.817258079006679		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.817258079006679 | validation: 3.0871504401410044]
	TIME [epoch: 25 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5376662830272765		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.5376662830272765 | validation: 2.2723789467378968]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_95.pth
	Model improved!!!
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.110715532847455		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.110715532847455 | validation: 2.2613882909132164]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8281944128250296		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.8281944128250296 | validation: 2.575343301007298]
	TIME [epoch: 25 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1508293822034315		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.1508293822034315 | validation: 3.052718420774675]
	TIME [epoch: 25 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.672515871604483		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.672515871604483 | validation: 2.2109539015064876]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1217702330363983		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.1217702330363983 | validation: 2.345534395372615]
	TIME [epoch: 25 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1436360564066472		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.1436360564066472 | validation: 3.5763624199795845]
	TIME [epoch: 25 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.909936100604755		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.909936100604755 | validation: 2.051100612002227]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3039446913960906		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.3039446913960906 | validation: 1.7711197641806522]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.630895599281054		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.630895599281054 | validation: 2.615292683994837]
	TIME [epoch: 25 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0413538895176813		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.0413538895176813 | validation: 2.7167280955899025]
	TIME [epoch: 25 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1506482117664505		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.1506482117664505 | validation: 1.9704032840812187]
	TIME [epoch: 24.9 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.254551962609612		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.254551962609612 | validation: 1.8453648031675727]
	TIME [epoch: 25 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1494321016695355		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.1494321016695355 | validation: 1.7755911129199171]
	TIME [epoch: 25 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7693199505740127		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.7693199505740127 | validation: 1.9025581133407554]
	TIME [epoch: 24.9 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.00779297527034		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 5.00779297527034 | validation: 8.697755338644807]
	TIME [epoch: 25 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.9727453629730345		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 7.9727453629730345 | validation: 6.2565660242191345]
	TIME [epoch: 25 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.135211165643488		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 7.135211165643488 | validation: 6.39826931821185]
	TIME [epoch: 24.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.108867528757043		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 7.108867528757043 | validation: 6.292588370882503]
	TIME [epoch: 25 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.205646035431009		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 7.205646035431009 | validation: 6.6841044306956565]
	TIME [epoch: 25 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.591798384588786		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 8.591798384588786 | validation: 9.389191525020214]
	TIME [epoch: 24.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.584864795052422		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 8.584864795052422 | validation: 6.904902568183034]
	TIME [epoch: 25 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.605987825417365		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 5.605987825417365 | validation: 3.372646296555139]
	TIME [epoch: 25 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.886050942715512		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.886050942715512 | validation: 2.4707236742733656]
	TIME [epoch: 24.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0706771941254245		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.0706771941254245 | validation: 1.831493994593666]
	TIME [epoch: 25 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7091131332548315		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.7091131332548315 | validation: 1.9888008623399174]
	TIME [epoch: 25 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1125439891130995		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.1125439891130995 | validation: 1.8668017096923892]
	TIME [epoch: 24.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9244917107530168		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.9244917107530168 | validation: 1.8374511854627815]
	TIME [epoch: 25 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.143746840058684		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.143746840058684 | validation: 2.5415139761971868]
	TIME [epoch: 25 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.378089392131907		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.378089392131907 | validation: 2.7281522828834146]
	TIME [epoch: 24.9 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.275294215344357		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.275294215344357 | validation: 2.299782053391811]
	TIME [epoch: 25 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1050544784662724		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 2.1050544784662724 | validation: 2.259044599067679]
	TIME [epoch: 25 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8764878278288966		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.8764878278288966 | validation: 1.7594437812712813]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8012337945431212		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.8012337945431212 | validation: 1.3814094320467405]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8722281999371808		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.8722281999371808 | validation: 1.7065529610762462]
	TIME [epoch: 25 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7337628016701214		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.7337628016701214 | validation: 1.6736231715211847]
	TIME [epoch: 24.9 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8437329606291664		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.8437329606291664 | validation: 1.9029939150858852]
	TIME [epoch: 24.9 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5663604829003288		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.5663604829003288 | validation: 1.2971092554914447]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.35935475898199		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.35935475898199 | validation: 2.6854742411626518]
	TIME [epoch: 24.9 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.093089573260844		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 2.093089573260844 | validation: 1.3281186142982058]
	TIME [epoch: 25 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3075726345224716		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.3075726345224716 | validation: 1.343913698798479]
	TIME [epoch: 25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.544824899475609		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.544824899475609 | validation: 3.2565765768972628]
	TIME [epoch: 24.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1917007447659125		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 2.1917007447659125 | validation: 2.111720125641114]
	TIME [epoch: 25 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6936175918383658		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.6936175918383658 | validation: 1.540114782168638]
	TIME [epoch: 25 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.830318679912303		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.830318679912303 | validation: 1.5763424929917562]
	TIME [epoch: 25 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4316780147278554		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.4316780147278554 | validation: 1.8360822129228933]
	TIME [epoch: 24.9 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.920477396702931		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.920477396702931 | validation: 2.2382368819537932]
	TIME [epoch: 25 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9243733443993563		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.9243733443993563 | validation: 2.0586502644141076]
	TIME [epoch: 24.9 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.293986277359242		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.293986277359242 | validation: 2.4334162265798067]
	TIME [epoch: 25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0525892147114497		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.0525892147114497 | validation: 2.118174359066577]
	TIME [epoch: 24.9 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.112649424349031		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 2.112649424349031 | validation: 2.1443021271761906]
	TIME [epoch: 25 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9005134664669348		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.9005134664669348 | validation: 1.8328324087993992]
	TIME [epoch: 24.9 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6290129937225784		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.6290129937225784 | validation: 2.359644576387123]
	TIME [epoch: 25 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8176711706587745		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.8176711706587745 | validation: 2.5209164200463325]
	TIME [epoch: 24.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8831978247481087		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.8831978247481087 | validation: 1.6888714644973442]
	TIME [epoch: 24.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.509119681449978		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.509119681449978 | validation: 2.046050966198006]
	TIME [epoch: 24.9 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.561818236315302		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.561818236315302 | validation: 2.0928169678117157]
	TIME [epoch: 24.9 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5874962543693334		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.5874962543693334 | validation: 1.5394446445854704]
	TIME [epoch: 24.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.438860180447021		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.438860180447021 | validation: 1.201761718594539]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3582572651286742		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.3582572651286742 | validation: 1.7055144480291875]
	TIME [epoch: 24.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3266639755801042		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.3266639755801042 | validation: 1.142069468599796]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.24126942297691		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.24126942297691 | validation: 2.2548088964364785]
	TIME [epoch: 25 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9570842811524802		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.9570842811524802 | validation: 2.0303590870928168]
	TIME [epoch: 25 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.711248042289137		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.711248042289137 | validation: 3.5087427161077525]
	TIME [epoch: 24.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.384893943519015		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.384893943519015 | validation: 1.5144077042784048]
	TIME [epoch: 25 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.377457670775233		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.377457670775233 | validation: 3.058796317740869]
	TIME [epoch: 25 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.257826390756467		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.257826390756467 | validation: 1.5230129713703884]
	TIME [epoch: 25 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5148246220518888		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.5148246220518888 | validation: 2.4213970270048777]
	TIME [epoch: 25 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5941893544699137		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.5941893544699137 | validation: 2.912414616866481]
	TIME [epoch: 25 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.912063652425036		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.912063652425036 | validation: 1.5896468398083692]
	TIME [epoch: 25 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8068842105333998		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.8068842105333998 | validation: 1.943841166898966]
	TIME [epoch: 25 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.436759199243566		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.436759199243566 | validation: 2.844128136940259]
	TIME [epoch: 25 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7844097109784414		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.7844097109784414 | validation: 1.2664306265484504]
	TIME [epoch: 24.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.373883624622311		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.373883624622311 | validation: 1.2683906277613934]
	TIME [epoch: 25 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5305443410293942		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.5305443410293942 | validation: 1.1993363738319416]
	TIME [epoch: 25 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3895689573799659		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.3895689573799659 | validation: 2.19984283379633]
	TIME [epoch: 24.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4142886637798382		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.4142886637798382 | validation: 1.6319192747115683]
	TIME [epoch: 25 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8053548345592647		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 2.8053548345592647 | validation: 4.0125298681911215]
	TIME [epoch: 25 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450119457007181		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.450119457007181 | validation: 1.7004001635154464]
	TIME [epoch: 24.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.57553136356298		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.57553136356298 | validation: 1.1754725136533395]
	TIME [epoch: 25 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5177997396644058		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.5177997396644058 | validation: 1.913629410585494]
	TIME [epoch: 25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4646991177644408		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.4646991177644408 | validation: 1.7296476012881834]
	TIME [epoch: 25 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4628644220723566		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.4628644220723566 | validation: 1.0938332055435425]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.274453597912129		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.274453597912129 | validation: 1.2973531872081083]
	TIME [epoch: 25 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0947534341441205		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 2.0947534341441205 | validation: 3.0135679475440886]
	TIME [epoch: 24.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.058098387155547		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 2.058098387155547 | validation: 2.157007944613384]
	TIME [epoch: 25 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.136682780586586		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.136682780586586 | validation: 1.767431158282618]
	TIME [epoch: 25 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3500715925328368		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.3500715925328368 | validation: 1.7732131488028011]
	TIME [epoch: 24.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4636035078803662		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.4636035078803662 | validation: 3.7736384060990042]
	TIME [epoch: 25 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.20402909997569		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 2.20402909997569 | validation: 1.3234563597583024]
	TIME [epoch: 25 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0900070830312334		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 2.0900070830312334 | validation: 1.899285394968697]
	TIME [epoch: 25 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7067722446412432		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.7067722446412432 | validation: 1.5216757266772578]
	TIME [epoch: 25 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3955353474552006		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.3955353474552006 | validation: 2.154400585747682]
	TIME [epoch: 25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6357349668044634		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.6357349668044634 | validation: 1.4960357794312071]
	TIME [epoch: 25 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3175862550096762		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.3175862550096762 | validation: 1.4113717446980376]
	TIME [epoch: 25 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.599009017362972		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.599009017362972 | validation: 1.532535143520869]
	TIME [epoch: 25 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.433306753687457		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.433306753687457 | validation: 1.353485380627311]
	TIME [epoch: 25 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2436203663607563		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.2436203663607563 | validation: 1.1207187852274934]
	TIME [epoch: 25 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4083660108657818		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.4083660108657818 | validation: 1.761659405219587]
	TIME [epoch: 25 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4192267402296164		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.4192267402296164 | validation: 1.2415968255474625]
	TIME [epoch: 24.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2850238536729517		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.2850238536729517 | validation: 1.276177118277507]
	TIME [epoch: 25 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1442150755338776		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.1442150755338776 | validation: 1.180675959482298]
	TIME [epoch: 25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0628925581090838		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.0628925581090838 | validation: 2.213654918395333]
	TIME [epoch: 25 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5134565308329397		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.5134565308329397 | validation: 1.6044733637822293]
	TIME [epoch: 25 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5735644964554907		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.5735644964554907 | validation: 1.5652300160650132]
	TIME [epoch: 25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.437846068678646		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.437846068678646 | validation: 1.0397091079261218]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2806086310489988		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.2806086310489988 | validation: 1.320990838497966]
	TIME [epoch: 25 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7780308664816582		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.7780308664816582 | validation: 1.2369900970841285]
	TIME [epoch: 25 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2539690496053886		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.2539690496053886 | validation: 1.4608433530834135]
	TIME [epoch: 25 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3164161707077573		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.3164161707077573 | validation: 1.1593741790531735]
	TIME [epoch: 25 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3505460893715042		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.3505460893715042 | validation: 1.0223854299401491]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1689495973821695		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.1689495973821695 | validation: 1.0614928177130167]
	TIME [epoch: 24.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.150179605443581		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.150179605443581 | validation: 1.2294973628843928]
	TIME [epoch: 25 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1528069927948932		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.1528069927948932 | validation: 1.3906049371002118]
	TIME [epoch: 25.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.174234215886552		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.174234215886552 | validation: 1.2162706826604959]
	TIME [epoch: 25 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0289632767706522		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.0289632767706522 | validation: 1.9658766087403183]
	TIME [epoch: 25 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8030056785439896		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.8030056785439896 | validation: 1.7588180713592707]
	TIME [epoch: 25 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5582171776948075		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.5582171776948075 | validation: 1.0675740729165026]
	TIME [epoch: 25 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1517120764695903		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.1517120764695903 | validation: 0.9978552570718864]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_213.pth
	Model improved!!!
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2704392613598676		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.2704392613598676 | validation: 1.3603797219659512]
	TIME [epoch: 25 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1965628731642666		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.1965628731642666 | validation: 1.145682470195547]
	TIME [epoch: 25 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.194584633104256		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.194584633104256 | validation: 1.1365086071977575]
	TIME [epoch: 25 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.12741827505757		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.12741827505757 | validation: 1.872537461527495]
	TIME [epoch: 25 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.318142228400574		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.318142228400574 | validation: 2.0179799885331344]
	TIME [epoch: 25 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4864326565970885		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.4864326565970885 | validation: 1.6336195550566626]
	TIME [epoch: 25 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.195517562954495		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.195517562954495 | validation: 1.0571669230184777]
	TIME [epoch: 25.1 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.130300950103131		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.130300950103131 | validation: 2.267181535502572]
	TIME [epoch: 25 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4972861765771182		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.4972861765771182 | validation: 1.1589902339398963]
	TIME [epoch: 25 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7350718440365496		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.7350718440365496 | validation: 1.2666982354599403]
	TIME [epoch: 25 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4018806588871033		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.4018806588871033 | validation: 1.2466683919370072]
	TIME [epoch: 25 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1005724584771719		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.1005724584771719 | validation: 1.4296861343319645]
	TIME [epoch: 25 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3407303174773373		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.3407303174773373 | validation: 1.7156981706205716]
	TIME [epoch: 25 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2157184793385998		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.2157184793385998 | validation: 1.124846967836795]
	TIME [epoch: 25 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1105803237581418		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.1105803237581418 | validation: 1.3513754847084334]
	TIME [epoch: 25 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.487587601876113		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.487587601876113 | validation: 1.2503655444019068]
	TIME [epoch: 25 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.14680407278009		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 2.14680407278009 | validation: 1.877206478566261]
	TIME [epoch: 25 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8374226400054123		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.8374226400054123 | validation: 1.4489284717697621]
	TIME [epoch: 25 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3234538599232284		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.3234538599232284 | validation: 2.002141926123911]
	TIME [epoch: 25 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3518582566140398		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.3518582566140398 | validation: 1.2793702758142422]
	TIME [epoch: 25 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.15622802774547		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.15622802774547 | validation: 1.5901625719923473]
	TIME [epoch: 25 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3275978592444555		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.3275978592444555 | validation: 1.170355490819896]
	TIME [epoch: 25 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9719072815609828		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.9719072815609828 | validation: 1.6329056203025971]
	TIME [epoch: 25 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.301686639213728		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.301686639213728 | validation: 1.3144878410132868]
	TIME [epoch: 25 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2389207614081714		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.2389207614081714 | validation: 1.5516958802397156]
	TIME [epoch: 25 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.333342835570583		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.333342835570583 | validation: 1.2481408609695674]
	TIME [epoch: 25 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3230233729732594		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.3230233729732594 | validation: 5.211188942965413]
	TIME [epoch: 25 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.731546344506767		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.731546344506767 | validation: 1.5337371724995055]
	TIME [epoch: 25 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4994132717755497		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.4994132717755497 | validation: 1.927419762135784]
	TIME [epoch: 25 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7890437543811182		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.7890437543811182 | validation: 1.5030341478108518]
	TIME [epoch: 25 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3481654929544478		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.3481654929544478 | validation: 1.8905904965957672]
	TIME [epoch: 25 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7587374114980723		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.7587374114980723 | validation: 1.4023760729321086]
	TIME [epoch: 25 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3198424801406115		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.3198424801406115 | validation: 1.1413728506789758]
	TIME [epoch: 25 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0528982645228033		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.0528982645228033 | validation: 2.1383707955507307]
	TIME [epoch: 25 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2662353939099031		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.2662353939099031 | validation: 1.28392760120704]
	TIME [epoch: 25 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2703711272429767		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.2703711272429767 | validation: 1.3821075872589876]
	TIME [epoch: 25 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1281820108247418		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.1281820108247418 | validation: 1.0855446609773096]
	TIME [epoch: 25 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.41446271567574		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.41446271567574 | validation: 1.0976462407786682]
	TIME [epoch: 25 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0484441027185396		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.0484441027185396 | validation: 1.5827314090091835]
	TIME [epoch: 25 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.417666908243478		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.417666908243478 | validation: 1.3670598808754297]
	TIME [epoch: 25 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3367108009349726		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.3367108009349726 | validation: 0.9512984239644169]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.153006232536419		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.153006232536419 | validation: 1.1265677197469963]
	TIME [epoch: 25 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0312929438637828		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.0312929438637828 | validation: 0.9788990542278877]
	TIME [epoch: 25 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9871295928146788		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.9871295928146788 | validation: 1.0321028408509865]
	TIME [epoch: 25 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2835184707774048		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.2835184707774048 | validation: 0.9815464543950466]
	TIME [epoch: 25 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0607353378165623		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.0607353378165623 | validation: 1.4121412031776888]
	TIME [epoch: 25 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3352012292233868		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.3352012292233868 | validation: 1.0832246834102681]
	TIME [epoch: 25 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4136759290092835		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.4136759290092835 | validation: 0.9802355712394831]
	TIME [epoch: 25 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9157979638966313		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.9157979638966313 | validation: 0.9188671808607198]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_262.pth
	Model improved!!!
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8443003426217375		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.8443003426217375 | validation: 1.523224561993077]
	TIME [epoch: 25 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0646833865075853		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.0646833865075853 | validation: 0.9370543350779894]
	TIME [epoch: 25 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.146253330789011		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.146253330789011 | validation: 0.892138680932486]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_265.pth
	Model improved!!!
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0272085559767956		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.0272085559767956 | validation: 1.3435135679941335]
	TIME [epoch: 25 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9677334487996553		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.9677334487996553 | validation: 1.0558818600259239]
	TIME [epoch: 25 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8670216975754491		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.8670216975754491 | validation: 1.3797318244117427]
	TIME [epoch: 25 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0225751157743468		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.0225751157743468 | validation: 1.0645543840368872]
	TIME [epoch: 25 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8849034583542115		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.8849034583542115 | validation: 1.117317200910835]
	TIME [epoch: 25 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0786048703816458		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.0786048703816458 | validation: 2.918327750019516]
	TIME [epoch: 25 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6661283094316088		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.6661283094316088 | validation: 1.0419188287644223]
	TIME [epoch: 25 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2867886152850394		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.2867886152850394 | validation: 0.9423562076000203]
	TIME [epoch: 25 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.112797657041257		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.112797657041257 | validation: 1.0873901821268839]
	TIME [epoch: 25 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1159790920014396		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.1159790920014396 | validation: 1.836762451834629]
	TIME [epoch: 25 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1963312764027219		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.1963312764027219 | validation: 2.033543081525713]
	TIME [epoch: 25 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6644963410099318		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.6644963410099318 | validation: 1.3855038625779919]
	TIME [epoch: 25 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9840977458857636		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.9840977458857636 | validation: 0.9783032427679237]
	TIME [epoch: 25 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8275939790419905		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.8275939790419905 | validation: 1.0361534576573097]
	TIME [epoch: 25 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0191585632268683		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.0191585632268683 | validation: 1.2845195737906303]
	TIME [epoch: 25 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.178899073056245		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.178899073056245 | validation: 1.1311341901727203]
	TIME [epoch: 25 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3748395747253777		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.3748395747253777 | validation: 1.6835582625604448]
	TIME [epoch: 25 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2725952745651443		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.2725952745651443 | validation: 1.2230026365528794]
	TIME [epoch: 25 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8956542460822577		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.8956542460822577 | validation: 1.153727438896304]
	TIME [epoch: 25 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2948325068973796		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.2948325068973796 | validation: 0.9451368640912119]
	TIME [epoch: 25 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9452449263965284		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.9452449263965284 | validation: 0.9574093851108123]
	TIME [epoch: 25 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.085069899123181		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.085069899123181 | validation: 0.9538872463128826]
	TIME [epoch: 25 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8773351309076749		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.8773351309076749 | validation: 1.5342604723987314]
	TIME [epoch: 25 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5946346583238116		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.5946346583238116 | validation: 1.164218784190266]
	TIME [epoch: 25 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0317804692617318		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.0317804692617318 | validation: 0.9265283213753287]
	TIME [epoch: 25 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9461083069509716		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.9461083069509716 | validation: 1.3540285201417583]
	TIME [epoch: 25 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0624751766913005		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.0624751766913005 | validation: 0.8444429198561321]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8024887788968198		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.8024887788968198 | validation: 0.8973341309953131]
	TIME [epoch: 25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8545360337684569		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.8545360337684569 | validation: 0.9289907938351535]
	TIME [epoch: 25 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9910565331709418		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.9910565331709418 | validation: 1.1554155562237423]
	TIME [epoch: 25 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1252675517700534		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.1252675517700534 | validation: 1.2088588286179762]
	TIME [epoch: 25 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9661129545414042		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.9661129545414042 | validation: 0.8189217802928724]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_297.pth
	Model improved!!!
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8502791446626358		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.8502791446626358 | validation: 1.3834938654340283]
	TIME [epoch: 25 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8972943044197129		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.8972943044197129 | validation: 1.0097397592170692]
	TIME [epoch: 25 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1834849721474539		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.1834849721474539 | validation: 1.6804343939153648]
	TIME [epoch: 25 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6224748574170718		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.6224748574170718 | validation: 0.775425406435308]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_301.pth
	Model improved!!!
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9838147021577243		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.9838147021577243 | validation: 1.022454463517622]
	TIME [epoch: 25 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9326275015207013		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.9326275015207013 | validation: 1.7786219303106574]
	TIME [epoch: 25 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2384221865441702		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.2384221865441702 | validation: 1.0550547776652481]
	TIME [epoch: 24.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0660482275340055		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.0660482275340055 | validation: 1.1506998152935375]
	TIME [epoch: 25 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1705108724425584		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.1705108724425584 | validation: 1.396967956999797]
	TIME [epoch: 25 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.155993566116826		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.155993566116826 | validation: 1.4314874880760116]
	TIME [epoch: 24.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1830209292219716		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.1830209292219716 | validation: 2.096192315755936]
	TIME [epoch: 25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5878905601759277		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.5878905601759277 | validation: 1.6754842105874348]
	TIME [epoch: 25 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.100572607797508		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.100572607797508 | validation: 1.756726284342472]
	TIME [epoch: 24.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1871347862330097		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.1871347862330097 | validation: 1.847282196318019]
	TIME [epoch: 25 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.324351953483313		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.324351953483313 | validation: 1.1685884470451104]
	TIME [epoch: 25 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0842656039218914		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.0842656039218914 | validation: 1.010752463371077]
	TIME [epoch: 24.9 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.054047572765305		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.054047572765305 | validation: 2.0368023777833177]
	TIME [epoch: 25 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7454257037265701		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.7454257037265701 | validation: 1.2963639366147999]
	TIME [epoch: 25 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1425219236097994		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.1425219236097994 | validation: 1.0103178541739544]
	TIME [epoch: 25 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0418293237858305		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.0418293237858305 | validation: 1.1714335521284185]
	TIME [epoch: 25 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.005910402711808		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.005910402711808 | validation: 1.0675014601332504]
	TIME [epoch: 25 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.137247181078274		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.137247181078274 | validation: 1.2149872881157653]
	TIME [epoch: 25 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1139568636211914		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.1139568636211914 | validation: 0.9576779460190105]
	TIME [epoch: 25 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9578836454801627		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.9578836454801627 | validation: 0.9971107659857091]
	TIME [epoch: 25 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0791476700664038		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.0791476700664038 | validation: 0.8603455454396722]
	TIME [epoch: 25 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2475205405193013		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.2475205405193013 | validation: 0.9205461181402974]
	TIME [epoch: 25 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2001231330974105		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.2001231330974105 | validation: 1.0499731714637404]
	TIME [epoch: 25 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.263657445972245		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.263657445972245 | validation: 1.3287676657900607]
	TIME [epoch: 25 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.237626281794864		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.237626281794864 | validation: 1.5995557383315475]
	TIME [epoch: 25 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.282599858332242		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.282599858332242 | validation: 1.1792127717035041]
	TIME [epoch: 25 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.465268462716215		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.465268462716215 | validation: 1.503282989804913]
	TIME [epoch: 25 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2689307290285001		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.2689307290285001 | validation: 0.9516782435463012]
	TIME [epoch: 25 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031702713864688		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.031702713864688 | validation: 0.957314354370076]
	TIME [epoch: 25 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0712252625738392		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.0712252625738392 | validation: 1.1409502263831293]
	TIME [epoch: 25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8393814089492415		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.8393814089492415 | validation: 1.3148449003869465]
	TIME [epoch: 25 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.226765878806969		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.226765878806969 | validation: 1.2998157303907232]
	TIME [epoch: 25 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4434667598069337		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.4434667598069337 | validation: 1.3989655902316696]
	TIME [epoch: 24.9 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2220232316506194		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.2220232316506194 | validation: 1.0450205879785726]
	TIME [epoch: 25 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9189484298867967		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.9189484298867967 | validation: 0.9205727442336971]
	TIME [epoch: 25 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9704129435888151		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.9704129435888151 | validation: 0.9143316471345297]
	TIME [epoch: 25 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3726234207602017		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.3726234207602017 | validation: 1.6039878904331162]
	TIME [epoch: 25 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.459005935028769		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.459005935028769 | validation: 1.2682371207105434]
	TIME [epoch: 25 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0998517252845774		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.0998517252845774 | validation: 1.2444484580034207]
	TIME [epoch: 25 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2550683733830352		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.2550683733830352 | validation: 1.5882559622433785]
	TIME [epoch: 25 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1224859267649503		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.1224859267649503 | validation: 0.9303967725777118]
	TIME [epoch: 25 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8694376979923815		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.8694376979923815 | validation: 1.6174044204910303]
	TIME [epoch: 25 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0840793503245747		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.0840793503245747 | validation: 0.9658235609592148]
	TIME [epoch: 24.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9159275630455361		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.9159275630455361 | validation: 1.4337961924659217]
	TIME [epoch: 25 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2268359179052342		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 1.2268359179052342 | validation: 0.9512364822345396]
	TIME [epoch: 25 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8779398071812144		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.8779398071812144 | validation: 0.9468368379949017]
	TIME [epoch: 25 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0628147467291964		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.0628147467291964 | validation: 1.140552506431823]
	TIME [epoch: 25 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9049497978200789		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.9049497978200789 | validation: 0.9342701214052942]
	TIME [epoch: 24.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8600837075107571		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.8600837075107571 | validation: 0.9211549618312609]
	TIME [epoch: 25 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.03223533191444		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.03223533191444 | validation: 0.997143722966322]
	TIME [epoch: 25 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.866349695706901		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.866349695706901 | validation: 0.7002949167126841]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6768118962987851		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.6768118962987851 | validation: 1.2744938281881086]
	TIME [epoch: 24.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.220086134295705		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 1.220086134295705 | validation: 1.2007033765853778]
	TIME [epoch: 25 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9202289791678772		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.9202289791678772 | validation: 1.624928900912787]
	TIME [epoch: 25 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1032259217738396		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.1032259217738396 | validation: 0.9165186674822777]
	TIME [epoch: 24.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9363250140809734		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.9363250140809734 | validation: 0.9363573841837863]
	TIME [epoch: 25 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.792624919101226		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.792624919101226 | validation: 0.7623046253239059]
	TIME [epoch: 25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9275196742920644		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.9275196742920644 | validation: 0.9641316848795232]
	TIME [epoch: 24.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1079306449776254		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.1079306449776254 | validation: 0.7891229700931771]
	TIME [epoch: 25 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4376391450301176		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.4376391450301176 | validation: 1.137233994654025]
	TIME [epoch: 25 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0418643722308476		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.0418643722308476 | validation: 0.9612658601679358]
	TIME [epoch: 24.9 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9794495495664726		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.9794495495664726 | validation: 0.8465056479707685]
	TIME [epoch: 25 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282548887563018		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.7282548887563018 | validation: 0.8240461775504997]
	TIME [epoch: 25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8424288756134732		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.8424288756134732 | validation: 0.9106894632272685]
	TIME [epoch: 24.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2359377989945748		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.2359377989945748 | validation: 1.0356330285247153]
	TIME [epoch: 25 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9463370150764956		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.9463370150764956 | validation: 1.2883351400727696]
	TIME [epoch: 25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.165873389603398		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.165873389603398 | validation: 1.3085040708809776]
	TIME [epoch: 24.9 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161934224271711		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.161934224271711 | validation: 0.8902732953552519]
	TIME [epoch: 25 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.831265369418438		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.831265369418438 | validation: 0.8929612890344777]
	TIME [epoch: 25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0237051185382047		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.0237051185382047 | validation: 0.8971257333724912]
	TIME [epoch: 24.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2298110550526755		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.2298110550526755 | validation: 1.003658457544841]
	TIME [epoch: 25 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0366094768130272		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.0366094768130272 | validation: 0.9671744814794938]
	TIME [epoch: 25 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7697868279211884		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.7697868279211884 | validation: 1.0940180982563588]
	TIME [epoch: 24.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9546918754516786		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.9546918754516786 | validation: 0.9054177432209963]
	TIME [epoch: 25 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8808842251230011		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.8808842251230011 | validation: 0.7700625249103777]
	TIME [epoch: 25 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7399225317060572		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.7399225317060572 | validation: 0.970093365305219]
	TIME [epoch: 25 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8842432796401984		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.8842432796401984 | validation: 0.942330348962875]
	TIME [epoch: 25 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8076968287691377		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.8076968287691377 | validation: 1.2449757545601132]
	TIME [epoch: 25 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1031219541843733		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.1031219541843733 | validation: 1.2284315630315725]
	TIME [epoch: 25 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.256731603127109		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.256731603127109 | validation: 1.4738650168804768]
	TIME [epoch: 25 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1592726376291276		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.1592726376291276 | validation: 1.1848720499031395]
	TIME [epoch: 25 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9460356143532092		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.9460356143532092 | validation: 0.8916037275719347]
	TIME [epoch: 25 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8606014091594703		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.8606014091594703 | validation: 1.1726548012401352]
	TIME [epoch: 25 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8283804062635917		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.8283804062635917 | validation: 0.7368578728518029]
	TIME [epoch: 25 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7850146571881582		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.7850146571881582 | validation: 0.6901581529984726]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_386.pth
	Model improved!!!
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8165152096026032		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.8165152096026032 | validation: 1.0950847263177077]
	TIME [epoch: 25 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.205913479815159		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.205913479815159 | validation: 1.3533513500076884]
	TIME [epoch: 25 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8960737752585448		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.8960737752585448 | validation: 0.8561765645653076]
	TIME [epoch: 24.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.767401039916182		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.767401039916182 | validation: 0.9177312844066617]
	TIME [epoch: 25 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.24951356296087		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.24951356296087 | validation: 1.1358310001499967]
	TIME [epoch: 25 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9438417655732303		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.9438417655732303 | validation: 0.9875185970342933]
	TIME [epoch: 24.9 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.80690484671718		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.80690484671718 | validation: 1.6894095961244873]
	TIME [epoch: 25 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3169610997936094		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.3169610997936094 | validation: 1.192736322099488]
	TIME [epoch: 25 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2230021733986276		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.2230021733986276 | validation: 1.1271615244666402]
	TIME [epoch: 24.9 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8383606788555652		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.8383606788555652 | validation: 1.105683705841871]
	TIME [epoch: 25 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1555218776420262		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.1555218776420262 | validation: 0.7836615628438329]
	TIME [epoch: 25 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7612670453536957		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.7612670453536957 | validation: 1.1720929013389614]
	TIME [epoch: 24.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.881823486940288		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.881823486940288 | validation: 0.6480704184553447]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_399.pth
	Model improved!!!
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.92754497951468		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.92754497951468 | validation: 0.7874857173408597]
	TIME [epoch: 25.3 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7953012225021959		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.7953012225021959 | validation: 0.739451493250028]
	TIME [epoch: 25 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6970172021223476		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.6970172021223476 | validation: 0.7250960543177526]
	TIME [epoch: 25 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7937596386910913		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.7937596386910913 | validation: 0.9743410317051056]
	TIME [epoch: 25 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9306030825923466		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.9306030825923466 | validation: 2.4837781898546503]
	TIME [epoch: 25 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5278832222660448		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 1.5278832222660448 | validation: 1.1692967373888559]
	TIME [epoch: 25 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8770985173632897		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.8770985173632897 | validation: 0.6898920905077504]
	TIME [epoch: 25 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7754755040869004		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.7754755040869004 | validation: 0.7440738435148421]
	TIME [epoch: 25 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7477747140778372		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.7477747140778372 | validation: 0.7657951391243393]
	TIME [epoch: 25 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7330794047535666		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.7330794047535666 | validation: 0.8048587171403694]
	TIME [epoch: 25 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.743237053494519		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.743237053494519 | validation: 0.8352109775965829]
	TIME [epoch: 25 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9528504178174767		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.9528504178174767 | validation: 1.2967369551575467]
	TIME [epoch: 25 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2957406554398554		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.2957406554398554 | validation: 0.9826510377840905]
	TIME [epoch: 25 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8243586219828286		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.8243586219828286 | validation: 0.7837031583147098]
	TIME [epoch: 25 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7537605427641909		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.7537605427641909 | validation: 0.8985242270469367]
	TIME [epoch: 25 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708689307040824		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.7708689307040824 | validation: 0.7415636352832803]
	TIME [epoch: 25 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7440419409113701		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.7440419409113701 | validation: 0.8457040964404291]
	TIME [epoch: 25 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0636451312487205		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.0636451312487205 | validation: 2.2145989586041197]
	TIME [epoch: 25 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3449784586877385		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.3449784586877385 | validation: 0.7437323557502054]
	TIME [epoch: 25 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8001886794433267		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.8001886794433267 | validation: 0.7185416546021415]
	TIME [epoch: 25 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8498862339175558		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.8498862339175558 | validation: 0.796115406181363]
	TIME [epoch: 25 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7144119602616339		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.7144119602616339 | validation: 0.778914670014114]
	TIME [epoch: 25 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6401795429495206		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.6401795429495206 | validation: 0.8641005820273912]
	TIME [epoch: 25 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1950692926755688		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.1950692926755688 | validation: 0.9256688844820207]
	TIME [epoch: 25 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.755433224294703		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.755433224294703 | validation: 0.9710324258614699]
	TIME [epoch: 25 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8074365938047287		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.8074365938047287 | validation: 0.7104037967908046]
	TIME [epoch: 25 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7791935807868569		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.7791935807868569 | validation: 0.9044184613837877]
	TIME [epoch: 25 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9063379058339596		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.9063379058339596 | validation: 0.6919199386850557]
	TIME [epoch: 25 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7143075850385289		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.7143075850385289 | validation: 0.9413337317030666]
	TIME [epoch: 25 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8560245532108067		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.8560245532108067 | validation: 0.8548411663239445]
	TIME [epoch: 25 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7635112823571414		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.7635112823571414 | validation: 0.9604705070478269]
	TIME [epoch: 25 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7210661761175603		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.7210661761175603 | validation: 0.7975227483016042]
	TIME [epoch: 25 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7947776348168007		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.7947776348168007 | validation: 0.6637847789875445]
	TIME [epoch: 25 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0543347184923872		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.0543347184923872 | validation: 1.2284884816038177]
	TIME [epoch: 25 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7649850369120362		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.7649850369120362 | validation: 0.7421505869617332]
	TIME [epoch: 25 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6104032657882785		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.6104032657882785 | validation: 0.9356804362976232]
	TIME [epoch: 25 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263780585181818		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.7263780585181818 | validation: 0.8080407748106615]
	TIME [epoch: 25 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2240907393830212		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.2240907393830212 | validation: 1.1787937162431081]
	TIME [epoch: 25 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0705311485086824		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.0705311485086824 | validation: 0.8905306279477907]
	TIME [epoch: 25 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5172396616302128		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.5172396616302128 | validation: 1.0245073399651365]
	TIME [epoch: 25 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0613598916126086		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.0613598916126086 | validation: 0.8381180860666823]
	TIME [epoch: 25 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.750895375426655		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.750895375426655 | validation: 0.8738939401607526]
	TIME [epoch: 25 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7147123602171775		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.7147123602171775 | validation: 0.8918409076676239]
	TIME [epoch: 25 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0185800200265245		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 1.0185800200265245 | validation: 1.2186764414142848]
	TIME [epoch: 25 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9862959249456352		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.9862959249456352 | validation: 0.861884938911966]
	TIME [epoch: 25 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8534596262095477		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.8534596262095477 | validation: 0.6957788652617868]
	TIME [epoch: 25 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281458343551699		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.7281458343551699 | validation: 0.720571100528344]
	TIME [epoch: 25 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8855922187959324		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.8855922187959324 | validation: 0.9276094643149214]
	TIME [epoch: 25 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7744018448331224		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.7744018448331224 | validation: 0.7616664138594849]
	TIME [epoch: 25 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7495538841140277		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.7495538841140277 | validation: 0.650404773222538]
	TIME [epoch: 25 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7943023099569482		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.7943023099569482 | validation: 1.5705466756981503]
	TIME [epoch: 25 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.245382473787278		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.245382473787278 | validation: 0.8129148771047184]
	TIME [epoch: 25 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8469724849822227		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.8469724849822227 | validation: 0.6279841548551918]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_452.pth
	Model improved!!!
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4519593599641247		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.4519593599641247 | validation: 1.9746175674294757]
	TIME [epoch: 25 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2425467104601		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.2425467104601 | validation: 0.7052494131460199]
	TIME [epoch: 25 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7086716853510788		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.7086716853510788 | validation: 0.7118576575546766]
	TIME [epoch: 25 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6887502162054686		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.6887502162054686 | validation: 0.7322028610985888]
	TIME [epoch: 25 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8716514575938337		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.8716514575938337 | validation: 1.3733728027863998]
	TIME [epoch: 25 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1147597178733797		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.1147597178733797 | validation: 0.7679351966606203]
	TIME [epoch: 25 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7425164756103182		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.7425164756103182 | validation: 1.6368739741045155]
	TIME [epoch: 25 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1685993786913509		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.1685993786913509 | validation: 0.8035761341053149]
	TIME [epoch: 25 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.791445702287576		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.791445702287576 | validation: 0.7575508925188278]
	TIME [epoch: 25 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8327393368421683		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.8327393368421683 | validation: 1.108102442354008]
	TIME [epoch: 25 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.984908662224168		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.984908662224168 | validation: 0.9622926065632208]
	TIME [epoch: 25 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8805789461705278		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.8805789461705278 | validation: 0.8839605998959571]
	TIME [epoch: 25 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7826245965654449		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.7826245965654449 | validation: 0.7811316353096188]
	TIME [epoch: 25 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8393412105795157		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.8393412105795157 | validation: 0.7069207212434244]
	TIME [epoch: 25 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.676305387881895		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.676305387881895 | validation: 0.7897771935637371]
	TIME [epoch: 25 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697934436265842		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.6697934436265842 | validation: 1.0228459267752887]
	TIME [epoch: 25 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2780006607852634		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.2780006607852634 | validation: 1.1282658925940454]
	TIME [epoch: 25 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.808356641031145		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.808356641031145 | validation: 0.7429799777681493]
	TIME [epoch: 25 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6408174336689456		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6408174336689456 | validation: 0.8464744159132522]
	TIME [epoch: 25 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7984579167663226		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.7984579167663226 | validation: 0.7454635164798805]
	TIME [epoch: 25 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7000369282156578		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.7000369282156578 | validation: 0.8369530906158845]
	TIME [epoch: 25 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6559598113381595		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.6559598113381595 | validation: 0.760110334072875]
	TIME [epoch: 25 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7360433254921996		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.7360433254921996 | validation: 1.2185799056262634]
	TIME [epoch: 25 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8516302533876503		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.8516302533876503 | validation: 0.7302694245842127]
	TIME [epoch: 25 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6677323761015108		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.6677323761015108 | validation: 0.7971635988330726]
	TIME [epoch: 25 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7595947317443815		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.7595947317443815 | validation: 0.8596167114014139]
	TIME [epoch: 25 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8030420438546299		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.8030420438546299 | validation: 0.6974558123331518]
	TIME [epoch: 25 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7379009082707719		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.7379009082707719 | validation: 0.6885466006026547]
	TIME [epoch: 25 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7291775119951506		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.7291775119951506 | validation: 0.6753142787371853]
	TIME [epoch: 25 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6517442152456807		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.6517442152456807 | validation: 0.7711794317620932]
	TIME [epoch: 25 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7726045179114582		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.7726045179114582 | validation: 0.8646189307765931]
	TIME [epoch: 25 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8437878590880342		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.8437878590880342 | validation: 0.6741814278835484]
	TIME [epoch: 25 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5959790262119029		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.5959790262119029 | validation: 0.6127579375825569]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7531041205392888		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.7531041205392888 | validation: 0.9846648665025903]
	TIME [epoch: 25 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.693463068965705		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.693463068965705 | validation: 0.7715583069519497]
	TIME [epoch: 25 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8516539993882569		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.8516539993882569 | validation: 0.936223971244401]
	TIME [epoch: 25 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7339838722887281		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.7339838722887281 | validation: 0.9589529036809896]
	TIME [epoch: 25 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8466306439624993		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.8466306439624993 | validation: 0.9047537785889931]
	TIME [epoch: 25 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8478016310451738		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.8478016310451738 | validation: 0.7480968587610537]
	TIME [epoch: 25 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.931889949500349		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.931889949500349 | validation: 1.5382660897151872]
	TIME [epoch: 25 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1556597278342082		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.1556597278342082 | validation: 1.0936671065808463]
	TIME [epoch: 25 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.858008241030649		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.858008241030649 | validation: 1.07218705572585]
	TIME [epoch: 25 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9952046432114283		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.9952046432114283 | validation: 0.8581051598196908]
	TIME [epoch: 25 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6716157015340156		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.6716157015340156 | validation: 0.6650669160644929]
	TIME [epoch: 25 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685343939907139		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.685343939907139 | validation: 0.9009643852839474]
	TIME [epoch: 25 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.72763823804685		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.72763823804685 | validation: 2.853274030376166]
	TIME [epoch: 25 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5360457873840145		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 1.5360457873840145 | validation: 0.6533363014846748]
	TIME [epoch: 25 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563778669301007		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.6563778669301007 | validation: 0.7181096473870393]
	TIME [epoch: 25 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6221080402942537		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6221080402942537 | validation: 0.9332032981327438]
	TIME [epoch: 25 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8136692136226875		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.8136692136226875 | validation: 0.7281468023367411]
	TIME [epoch: 25 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6400187246579739		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.6400187246579739 | validation: 0.653029602006221]
	TIME [epoch: 25 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7167339935125219		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.7167339935125219 | validation: 1.3808965756695992]
	TIME [epoch: 25 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8652120213448424		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.8652120213448424 | validation: 0.8598079505141185]
	TIME [epoch: 25 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0446361856361972		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.0446361856361972 | validation: 0.8688742544299798]
	TIME [epoch: 25 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7376399874095346		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.7376399874095346 | validation: 1.032693940258763]
	TIME [epoch: 25 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7266865855680573		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.7266865855680573 | validation: 1.3681245495160335]
	TIME [epoch: 25 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8790332882535631		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.8790332882535631 | validation: 0.9168344267960213]
	TIME [epoch: 25 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9577344719370529		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.9577344719370529 | validation: 0.7954821218352194]
	TIME [epoch: 25 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0431312707823233		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 1.0431312707823233 | validation: 0.6168342725522404]
	TIME [epoch: 24.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9193665638153499		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.9193665638153499 | validation: 0.7082203642900352]
	TIME [epoch: 25 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6469657583013367		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.6469657583013367 | validation: 0.626739871103759]
	TIME [epoch: 25 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5937444825399562		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.5937444825399562 | validation: 0.6817750220934038]
	TIME [epoch: 25 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5873555402518837		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.5873555402518837 | validation: 0.6574132996099175]
	TIME [epoch: 25 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9232484082510948		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.9232484082510948 | validation: 1.1536384387354077]
	TIME [epoch: 25 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0364871453786728		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 1.0364871453786728 | validation: 0.7553477910667868]
	TIME [epoch: 24.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6544575450070258		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.6544575450070258 | validation: 1.0699423478320254]
	TIME [epoch: 25 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8829342818629198		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.8829342818629198 | validation: 1.249708720175156]
	TIME [epoch: 25 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8839767016616897		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.8839767016616897 | validation: 0.6602314090396685]
	TIME [epoch: 24.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.834514678106858		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.834514678106858 | validation: 0.9306654474011316]
	TIME [epoch: 25 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8018819985011653		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.8018819985011653 | validation: 0.7798318900816389]
	TIME [epoch: 25 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.703847254597118		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.703847254597118 | validation: 0.753450813087679]
	TIME [epoch: 24.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5961053394353886		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.5961053394353886 | validation: 0.6035024991021419]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_524.pth
	Model improved!!!
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5856741025120594		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.5856741025120594 | validation: 0.6609990584427082]
	TIME [epoch: 25 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6353851766832432		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.6353851766832432 | validation: 0.6793207523628506]
	TIME [epoch: 24.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8047733222827502		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.8047733222827502 | validation: 1.15552384710933]
	TIME [epoch: 25 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8671826822097158		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.8671826822097158 | validation: 1.0673457806539441]
	TIME [epoch: 25 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7702324748378215		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.7702324748378215 | validation: 0.7009599264856675]
	TIME [epoch: 25 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8886412328263305		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.8886412328263305 | validation: 1.0464108361993774]
	TIME [epoch: 25 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828611578552407		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.6828611578552407 | validation: 0.6727109412094185]
	TIME [epoch: 25 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7052889447902263		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.7052889447902263 | validation: 0.8982260776105573]
	TIME [epoch: 25 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.977732959552634		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.977732959552634 | validation: 0.6577219676911349]
	TIME [epoch: 25 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7836248546042144		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.7836248546042144 | validation: 1.1654641862072201]
	TIME [epoch: 25 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8068002011063453		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.8068002011063453 | validation: 1.1394783837942075]
	TIME [epoch: 24.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.741308515273453		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.741308515273453 | validation: 0.7030916404771728]
	TIME [epoch: 25 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.821989329865174		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.821989329865174 | validation: 0.7842599727433651]
	TIME [epoch: 25 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7042553157279406		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.7042553157279406 | validation: 0.8719297533860244]
	TIME [epoch: 24.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6663946214714732		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.6663946214714732 | validation: 0.6870218631906662]
	TIME [epoch: 25 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6784421465862256		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.6784421465862256 | validation: 0.7263698710651272]
	TIME [epoch: 25 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7958985043299615		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.7958985043299615 | validation: 0.6957471189023906]
	TIME [epoch: 24.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6458810448349303		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.6458810448349303 | validation: 0.7997675301339452]
	TIME [epoch: 24.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6445223948835869		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.6445223948835869 | validation: 0.6150173858584659]
	TIME [epoch: 25 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6498116967931917		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.6498116967931917 | validation: 2.716887833345553]
	TIME [epoch: 24.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4016187837299396		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 1.4016187837299396 | validation: 0.7763711647058255]
	TIME [epoch: 24.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6954030497720418		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.6954030497720418 | validation: 0.6818391954069405]
	TIME [epoch: 25 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931309595839172		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.6931309595839172 | validation: 0.8397240787661087]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7780385039494178		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.7780385039494178 | validation: 0.6748865434700971]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6747514713620175		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.6747514713620175 | validation: 0.7702360370250891]
	TIME [epoch: 25 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9109276201873303		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.9109276201873303 | validation: 0.8832345713911288]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7748480350906111		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.7748480350906111 | validation: 1.4540699979563514]
	TIME [epoch: 24.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0870736538655077		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 1.0870736538655077 | validation: 0.8493575298713582]
	TIME [epoch: 25 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7541571578875113		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.7541571578875113 | validation: 0.9453353522626208]
	TIME [epoch: 25 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9062282456708275		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.9062282456708275 | validation: 0.8188287644760778]
	TIME [epoch: 25 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6998912365565934		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.6998912365565934 | validation: 0.9321901672681097]
	TIME [epoch: 25 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7099282976969884		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.7099282976969884 | validation: 1.0600237172406224]
	TIME [epoch: 24.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9254758151389423		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.9254758151389423 | validation: 0.9244764685279482]
	TIME [epoch: 24.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7964001017829028		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.7964001017829028 | validation: 0.899819039895733]
	TIME [epoch: 25 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7847292146529811		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.7847292146529811 | validation: 1.009380604038586]
	TIME [epoch: 24.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8005688860970792		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.8005688860970792 | validation: 1.11671945490533]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7798998622254699		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.7798998622254699 | validation: 0.7289273728420992]
	TIME [epoch: 25 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301207439984918		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.6301207439984918 | validation: 0.7028179030486555]
	TIME [epoch: 24.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254776635886973		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.6254776635886973 | validation: 0.7054898447442193]
	TIME [epoch: 24.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6504611039759912		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.6504611039759912 | validation: 0.6402159898569376]
	TIME [epoch: 25 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6678342716394826		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.6678342716394826 | validation: 0.7370856059943628]
	TIME [epoch: 25 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7852651294884324		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.7852651294884324 | validation: 0.8249437776078488]
	TIME [epoch: 24.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7048512524724984		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.7048512524724984 | validation: 0.7210178554050924]
	TIME [epoch: 24.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.60148166486324		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.60148166486324 | validation: 0.862828416815543]
	TIME [epoch: 24.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272496252421923		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.7272496252421923 | validation: 1.0263045960496464]
	TIME [epoch: 24.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6522534771164605		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.6522534771164605 | validation: 0.6811302762768454]
	TIME [epoch: 25 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7146403331496164		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.7146403331496164 | validation: 1.3275165365530517]
	TIME [epoch: 24.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8838706464018403		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.8838706464018403 | validation: 0.8046539008049891]
	TIME [epoch: 25 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7428541097723846		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.7428541097723846 | validation: 1.3167416882594154]
	TIME [epoch: 25 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.157434637807618		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 2.157434637807618 | validation: 0.8288823468240638]
	TIME [epoch: 25 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7540877758635985		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.7540877758635985 | validation: 0.7002800017793022]
	TIME [epoch: 24.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.851049331048938		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.851049331048938 | validation: 0.8062040894578444]
	TIME [epoch: 24.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6895907009643321		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.6895907009643321 | validation: 0.7029878979285582]
	TIME [epoch: 24.9 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6009716395480722		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.6009716395480722 | validation: 0.5868448844076933]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_578.pth
	Model improved!!!
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.769696842079815		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.769696842079815 | validation: 0.595690383052809]
	TIME [epoch: 25 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6434327321883171		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.6434327321883171 | validation: 0.5570761219282259]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_580.pth
	Model improved!!!
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5740641285360109		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5740641285360109 | validation: 0.5512295274829123]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_581.pth
	Model improved!!!
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5493987474733716		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.5493987474733716 | validation: 0.7388217839421747]
	TIME [epoch: 25 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5424050895622021		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.5424050895622021 | validation: 0.6839531234660075]
	TIME [epoch: 25 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6422073856137318		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.6422073856137318 | validation: 0.6692500280905915]
	TIME [epoch: 24.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5516162851734597		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5516162851734597 | validation: 0.546485373492422]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6190669469881254		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.6190669469881254 | validation: 0.6101665315826201]
	TIME [epoch: 25 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5774210974984194		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.5774210974984194 | validation: 0.5339478149300014]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_587.pth
	Model improved!!!
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5335193937337934		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.5335193937337934 | validation: 0.7315485626583862]
	TIME [epoch: 25 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5806139701903439		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.5806139701903439 | validation: 0.6818475862316768]
	TIME [epoch: 25 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.536447982821826		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.536447982821826 | validation: 0.751059072643189]
	TIME [epoch: 25 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582297038339413		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.582297038339413 | validation: 0.6847618934000409]
	TIME [epoch: 25 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882846837341616		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.6882846837341616 | validation: 0.6164174122399864]
	TIME [epoch: 25 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5096656454386052		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.5096656454386052 | validation: 0.563743293752873]
	TIME [epoch: 24.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4964082592001179		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.4964082592001179 | validation: 0.6287694037826213]
	TIME [epoch: 25 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724855784197928		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.5724855784197928 | validation: 0.5724282749770154]
	TIME [epoch: 24.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48576806891440005		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.48576806891440005 | validation: 0.8381301223654433]
	TIME [epoch: 24.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5592152955923776		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.5592152955923776 | validation: 0.5836630040438356]
	TIME [epoch: 25 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45303306598743853		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.45303306598743853 | validation: 0.8570854446371332]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.078792440253521		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 1.078792440253521 | validation: 0.7259924025172518]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.746407918451536		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.746407918451536 | validation: 0.8615418299644358]
	TIME [epoch: 24.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6329184434804223		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.6329184434804223 | validation: 0.5363014306552903]
	TIME [epoch: 25 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.952998993191261		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.952998993191261 | validation: 2.0617164688949456]
	TIME [epoch: 24.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0030285200569802		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 1.0030285200569802 | validation: 0.603477808346245]
	TIME [epoch: 25 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572329390652899		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.572329390652899 | validation: 0.7908063527265696]
	TIME [epoch: 25 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6100465445887238		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.6100465445887238 | validation: 0.5469300916578684]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235233166334347		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.6235233166334347 | validation: 0.5568599512121443]
	TIME [epoch: 25 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5012419549328293		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.5012419549328293 | validation: 0.563630154691221]
	TIME [epoch: 24.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48871346976180297		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.48871346976180297 | validation: 0.645185832750865]
	TIME [epoch: 24.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891700000732535		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.4891700000732535 | validation: 0.5341762993514279]
	TIME [epoch: 25 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5583185023651567		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.5583185023651567 | validation: 0.6579038428559127]
	TIME [epoch: 25 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5754820057818798		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.5754820057818798 | validation: 0.5528338444785504]
	TIME [epoch: 24.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4722564295456998		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.4722564295456998 | validation: 0.6642939313062839]
	TIME [epoch: 25 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7373248110708206		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.7373248110708206 | validation: 0.7490890452502725]
	TIME [epoch: 25 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5878683376097484		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.5878683376097484 | validation: 0.722843481140283]
	TIME [epoch: 25 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6365097568096346		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.6365097568096346 | validation: 0.6918586637347582]
	TIME [epoch: 25 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5822796668470135		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5822796668470135 | validation: 0.5942789245693232]
	TIME [epoch: 25 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.493722652944672		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.493722652944672 | validation: 0.7880584725687652]
	TIME [epoch: 24.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5572376372364465		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.5572376372364465 | validation: 0.7769706759653192]
	TIME [epoch: 25 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6497214625755116		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.6497214625755116 | validation: 0.8773823465742843]
	TIME [epoch: 25 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6429741474794542		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.6429741474794542 | validation: 0.6200536835005471]
	TIME [epoch: 24.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5766781919801663		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.5766781919801663 | validation: 0.5342640801413622]
	TIME [epoch: 25 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5763483974597452		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.5763483974597452 | validation: 0.7784801287796669]
	TIME [epoch: 25 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8303137564316738		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.8303137564316738 | validation: 0.8141054226908697]
	TIME [epoch: 25 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6866016005588313		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.6866016005588313 | validation: 0.6981070744635808]
	TIME [epoch: 25 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6174882420542371		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.6174882420542371 | validation: 0.7311026904973045]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6847943499844295		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.6847943499844295 | validation: 0.6991170840989791]
	TIME [epoch: 24.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5673502086732112		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5673502086732112 | validation: 0.628768868198103]
	TIME [epoch: 24.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6039456345503915		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.6039456345503915 | validation: 0.7359822996352258]
	TIME [epoch: 25 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5556136467536223		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5556136467536223 | validation: 0.5854103505388605]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6814191168934102		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.6814191168934102 | validation: 0.5474975989364291]
	TIME [epoch: 25 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6733007181502567		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.6733007181502567 | validation: 0.5982687634868578]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5254183232365277		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.5254183232365277 | validation: 0.5541938181769498]
	TIME [epoch: 25 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082578192410663		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.5082578192410663 | validation: 0.6576661475844695]
	TIME [epoch: 25 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7060055498255262		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.7060055498255262 | validation: 0.9300400729557666]
	TIME [epoch: 25 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5791179531498256		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.5791179531498256 | validation: 0.5706333573006921]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082747339982492		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.5082747339982492 | validation: 0.5111152333620657]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_636.pth
	Model improved!!!
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644597716524705		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.5644597716524705 | validation: 0.7745881495523311]
	TIME [epoch: 25 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6124499817931588		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.6124499817931588 | validation: 0.7107328959022262]
	TIME [epoch: 24.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5308715007414833		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.5308715007414833 | validation: 0.5770352259169205]
	TIME [epoch: 25 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021984837214544		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.5021984837214544 | validation: 0.7236956218924877]
	TIME [epoch: 25 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.59857952700889		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.59857952700889 | validation: 0.6875085011639998]
	TIME [epoch: 25 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936573044780991		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.5936573044780991 | validation: 0.8613042229338126]
	TIME [epoch: 25 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5938765732340807		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.5938765732340807 | validation: 0.5972713072625828]
	TIME [epoch: 25 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5664455378238709		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.5664455378238709 | validation: 0.5269819593857298]
	TIME [epoch: 25 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4378156297976795		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.4378156297976795 | validation: 0.5006545423822603]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_645.pth
	Model improved!!!
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46249759580330874		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.46249759580330874 | validation: 0.6719345670392317]
	TIME [epoch: 25 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5967769788559347		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.5967769788559347 | validation: 0.5919139018510375]
	TIME [epoch: 25.2 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6793529345614812		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.6793529345614812 | validation: 0.8806241965200704]
	TIME [epoch: 24.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6471259950716699		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.6471259950716699 | validation: 0.5833699418394578]
	TIME [epoch: 24.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5638828845150287		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.5638828845150287 | validation: 0.5404772738588214]
	TIME [epoch: 24.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45210201880862233		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.45210201880862233 | validation: 0.5459897429913232]
	TIME [epoch: 24.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5248961934664805		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5248961934664805 | validation: 0.7308879773678669]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5095570248086547		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.5095570248086547 | validation: 0.5315135848191197]
	TIME [epoch: 24.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4669065093902858		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.4669065093902858 | validation: 0.6434196590249874]
	TIME [epoch: 24.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9164008540564221		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.9164008540564221 | validation: 1.206992331464468]
	TIME [epoch: 24.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712704033104395		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.712704033104395 | validation: 0.5196104050349654]
	TIME [epoch: 24.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44524980004116393		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.44524980004116393 | validation: 0.5949476082911306]
	TIME [epoch: 24.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5803869019476177		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.5803869019476177 | validation: 1.2670209364535974]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9318106599924372		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.9318106599924372 | validation: 0.6375309790433192]
	TIME [epoch: 24.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5475020368132649		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.5475020368132649 | validation: 0.6335612252563467]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4987182974342507		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.4987182974342507 | validation: 0.5132312146525865]
	TIME [epoch: 24.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5700977100847118		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5700977100847118 | validation: 0.6700982969039814]
	TIME [epoch: 24.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4922963319042493		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.4922963319042493 | validation: 0.5566529640722476]
	TIME [epoch: 24.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47356376315825394		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.47356376315825394 | validation: 0.5998575864505183]
	TIME [epoch: 24.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5357629252245356		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.5357629252245356 | validation: 0.6735099937915388]
	TIME [epoch: 24.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4964158133477169		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.4964158133477169 | validation: 0.5507508988924498]
	TIME [epoch: 24.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.492722113363763		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.492722113363763 | validation: 0.8305084722700897]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6821427379980206		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.6821427379980206 | validation: 0.6028096687377694]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5546789986975312		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.5546789986975312 | validation: 0.46053065523688774]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_669.pth
	Model improved!!!
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45002230138298355		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.45002230138298355 | validation: 0.49461089396638164]
	TIME [epoch: 24.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6547835628573311		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.6547835628573311 | validation: 0.744183897151797]
	TIME [epoch: 25 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6966129338885311		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.6966129338885311 | validation: 0.6163918281344352]
	TIME [epoch: 24.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6952255850118028		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.6952255850118028 | validation: 0.7161503769340394]
	TIME [epoch: 24.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.679013040393635		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.679013040393635 | validation: 0.6985452625116073]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5483466824140903		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.5483466824140903 | validation: 0.6198565371894175]
	TIME [epoch: 24.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5327530798834843		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.5327530798834843 | validation: 0.5633647976578585]
	TIME [epoch: 24.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5202524645762977		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.5202524645762977 | validation: 0.46608138443728975]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5903445555856766		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.5903445555856766 | validation: 0.6611945656702949]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6121404093984593		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.6121404093984593 | validation: 0.7103426980861037]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5743253979600255		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.5743253979600255 | validation: 0.6306429100788451]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5604006389056501		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.5604006389056501 | validation: 0.52349335671501]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47026570489170644		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.47026570489170644 | validation: 0.6098254646962991]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44896935986235864		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.44896935986235864 | validation: 0.45928336540913406]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.472790983132341		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.472790983132341 | validation: 1.304193270425021]
	TIME [epoch: 25 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.013081164786103		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 1.013081164786103 | validation: 0.7499808716384265]
	TIME [epoch: 25 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5094495177328183		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5094495177328183 | validation: 0.5169292928527883]
	TIME [epoch: 25 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45641848049052813		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.45641848049052813 | validation: 0.5112963648459448]
	TIME [epoch: 25 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5892869448397777		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.5892869448397777 | validation: 0.6208757087703033]
	TIME [epoch: 25 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5011876940041056		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.5011876940041056 | validation: 0.6528238384720128]
	TIME [epoch: 25 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.524386762044593		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.524386762044593 | validation: 0.718732739865465]
	TIME [epoch: 25 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5136973536610925		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.5136973536610925 | validation: 0.5431538816759409]
	TIME [epoch: 25 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5294793873639283		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.5294793873639283 | validation: 0.7925245836589716]
	TIME [epoch: 25 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7127723744726779		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.7127723744726779 | validation: 0.5617501496371005]
	TIME [epoch: 25 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4552372055253501		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.4552372055253501 | validation: 0.54980599754354]
	TIME [epoch: 25 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5157184855700334		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.5157184855700334 | validation: 0.701137409014413]
	TIME [epoch: 25 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5723782344995662		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.5723782344995662 | validation: 0.5617206365764977]
	TIME [epoch: 25 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.515274905903995		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.515274905903995 | validation: 0.5423094268739681]
	TIME [epoch: 25 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46640004491605913		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.46640004491605913 | validation: 0.5743012645082625]
	TIME [epoch: 25 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.505992537963786		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.505992537963786 | validation: 0.5798829691958093]
	TIME [epoch: 25 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44216071832218456		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.44216071832218456 | validation: 0.542129987010164]
	TIME [epoch: 25 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44012131441764607		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.44012131441764607 | validation: 0.6243592249052082]
	TIME [epoch: 25 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7376960001910492		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.7376960001910492 | validation: 0.5898868627770958]
	TIME [epoch: 25 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5237846565997223		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.5237846565997223 | validation: 0.45461609464639596]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_703.pth
	Model improved!!!
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44352462266308323		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.44352462266308323 | validation: 0.49605385748731423]
	TIME [epoch: 25 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5519461830952331		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.5519461830952331 | validation: 0.44495993978362663]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_705.pth
	Model improved!!!
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4047462992834617		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.4047462992834617 | validation: 0.4714074484736104]
	TIME [epoch: 24.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4068448914500866		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.4068448914500866 | validation: 0.4468444344976993]
	TIME [epoch: 25 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45339254127898165		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.45339254127898165 | validation: 0.5179072152377884]
	TIME [epoch: 24.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43182381341410886		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.43182381341410886 | validation: 0.5374933040439394]
	TIME [epoch: 25 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47034612115170965		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.47034612115170965 | validation: 0.5513935612229685]
	TIME [epoch: 25 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46126306025329505		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.46126306025329505 | validation: 0.5122865780318229]
	TIME [epoch: 25 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40775579865595546		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.40775579865595546 | validation: 0.5404185107628977]
	TIME [epoch: 25 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47470453974830484		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.47470453974830484 | validation: 0.5462452468921916]
	TIME [epoch: 25 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49041506189534		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.49041506189534 | validation: 0.48577071871670074]
	TIME [epoch: 24.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40850471977363356		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.40850471977363356 | validation: 0.47283333559547097]
	TIME [epoch: 25 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48371457877899204		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.48371457877899204 | validation: 0.5152704481193732]
	TIME [epoch: 25 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5230565322492399		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.5230565322492399 | validation: 0.5011995185816854]
	TIME [epoch: 25 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42261986826242376		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.42261986826242376 | validation: 0.4365893914311036]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_718.pth
	Model improved!!!
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41933006999229205		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.41933006999229205 | validation: 0.5935612462789225]
	TIME [epoch: 25 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5277644302970114		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.5277644302970114 | validation: 0.5212717757072098]
	TIME [epoch: 24.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4258752658128539		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.4258752658128539 | validation: 0.8187172414152639]
	TIME [epoch: 24.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.654978685643646		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.654978685643646 | validation: 0.5245620007363193]
	TIME [epoch: 25 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5111002884963164		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.5111002884963164 | validation: 0.6535236380682009]
	TIME [epoch: 24.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.532554027315932		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.532554027315932 | validation: 0.5824619657961129]
	TIME [epoch: 24.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6796845031925902		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.6796845031925902 | validation: 0.6501503944713912]
	TIME [epoch: 25 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.534736455320876		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.534736455320876 | validation: 0.4764400872167296]
	TIME [epoch: 24.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.424488502847314		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.424488502847314 | validation: 0.6020401445297011]
	TIME [epoch: 24.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44512774968494506		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.44512774968494506 | validation: 0.5291636449325298]
	TIME [epoch: 25 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43862313162129607		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.43862313162129607 | validation: 0.6471456453455354]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4513141422981087		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.4513141422981087 | validation: 0.4814809166006427]
	TIME [epoch: 24.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45841100855514283		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.45841100855514283 | validation: 0.49181135273227805]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42866827611647934		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.42866827611647934 | validation: 0.417422647068844]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_732.pth
	Model improved!!!
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4163538262193063		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.4163538262193063 | validation: 1.0618567920133961]
	TIME [epoch: 24.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7896891236471575		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.7896891236471575 | validation: 0.5435545579211755]
	TIME [epoch: 25 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49780568791211377		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.49780568791211377 | validation: 0.5537317473504969]
	TIME [epoch: 25 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542541628598662		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.542541628598662 | validation: 1.165687321279143]
	TIME [epoch: 24.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9587774084715348		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.9587774084715348 | validation: 0.5870639509959864]
	TIME [epoch: 25 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44693753354279353		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.44693753354279353 | validation: 0.518561156751568]
	TIME [epoch: 25 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41188142038163317		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.41188142038163317 | validation: 0.6292272605837392]
	TIME [epoch: 24.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4632912840919072		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.4632912840919072 | validation: 0.5443808125464554]
	TIME [epoch: 25 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40940620073218936		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.40940620073218936 | validation: 0.5303094841984871]
	TIME [epoch: 24.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4319258310539677		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.4319258310539677 | validation: 0.45240203387149797]
	TIME [epoch: 25 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667457395464249		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.3667457395464249 | validation: 0.5379421994019756]
	TIME [epoch: 25 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46493544800483155		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.46493544800483155 | validation: 0.4480144761372506]
	TIME [epoch: 24.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41714124570660127		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.41714124570660127 | validation: 0.4610308574554111]
	TIME [epoch: 24.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5322679446634297		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.5322679446634297 | validation: 0.5988021692178959]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5572327697031214		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.5572327697031214 | validation: 0.533552611421224]
	TIME [epoch: 24.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113189735542092		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.5113189735542092 | validation: 0.5668478997689697]
	TIME [epoch: 24.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4198086065554851		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.4198086065554851 | validation: 0.41383955692378754]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_749.pth
	Model improved!!!
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4074663299506356		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.4074663299506356 | validation: 0.46841807265325885]
	TIME [epoch: 25 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39893549374105897		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.39893549374105897 | validation: 0.4477028853683113]
	TIME [epoch: 25 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3717535456744031		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.3717535456744031 | validation: 0.4155232121853611]
	TIME [epoch: 25 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4302946213314704		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.4302946213314704 | validation: 0.6121751732177176]
	TIME [epoch: 25 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4133545565358016		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.4133545565358016 | validation: 0.5177418742449743]
	TIME [epoch: 25 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43312666569216385		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.43312666569216385 | validation: 0.5103282470554963]
	TIME [epoch: 25 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404693232398957		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.4404693232398957 | validation: 0.454684156753711]
	TIME [epoch: 25 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42431776316030734		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.42431776316030734 | validation: 0.45644887966583997]
	TIME [epoch: 24.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4440319595718859		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.4440319595718859 | validation: 0.47840782608666865]
	TIME [epoch: 25 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44905627719435537		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.44905627719435537 | validation: 0.6465306650714647]
	TIME [epoch: 25 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.528608770894853		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.528608770894853 | validation: 1.2903728424370535]
	TIME [epoch: 25 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8617955639613518		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.8617955639613518 | validation: 0.5269574086890978]
	TIME [epoch: 25 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5057150731744744		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.5057150731744744 | validation: 0.5612710062656977]
	TIME [epoch: 25 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4616558075112868		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.4616558075112868 | validation: 0.5182874220489903]
	TIME [epoch: 25 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49632497488834826		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.49632497488834826 | validation: 0.5770759392141427]
	TIME [epoch: 25 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.558843569017829		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.558843569017829 | validation: 0.5346842859801005]
	TIME [epoch: 25 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47475279811133175		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.47475279811133175 | validation: 0.5487033453912628]
	TIME [epoch: 25 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4549253479344664		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.4549253479344664 | validation: 0.5700114427563672]
	TIME [epoch: 25 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46654478674197625		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.46654478674197625 | validation: 0.5080877313888827]
	TIME [epoch: 25 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4748640368495828		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.4748640368495828 | validation: 0.3997417123657718]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_769.pth
	Model improved!!!
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41897925726105884		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.41897925726105884 | validation: 0.6001759708979516]
	TIME [epoch: 25 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44231643595470005		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.44231643595470005 | validation: 0.41519338703318975]
	TIME [epoch: 25 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5030591873525441		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.5030591873525441 | validation: 0.5278884094450023]
	TIME [epoch: 24.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46077366041756085		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.46077366041756085 | validation: 0.5430200929497826]
	TIME [epoch: 25 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4857763402362096		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.4857763402362096 | validation: 0.4791795890408337]
	TIME [epoch: 25 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4691070076451663		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.4691070076451663 | validation: 0.4745183916728469]
	TIME [epoch: 25 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37787210153446715		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.37787210153446715 | validation: 0.5732108882601052]
	TIME [epoch: 24.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4380855594006075		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.4380855594006075 | validation: 0.45587164711492195]
	TIME [epoch: 25 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39417246086906943		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.39417246086906943 | validation: 0.43335715529242747]
	TIME [epoch: 24.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47475555510609463		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.47475555510609463 | validation: 0.4732676505121596]
	TIME [epoch: 25 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4601012737171247		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.4601012737171247 | validation: 0.4394917803156642]
	TIME [epoch: 24.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38795558219988424		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.38795558219988424 | validation: 0.4485399482500091]
	TIME [epoch: 24.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3754132046896015		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.3754132046896015 | validation: 0.6497689978497797]
	TIME [epoch: 24.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5370552474132557		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.5370552474132557 | validation: 0.5246156306543793]
	TIME [epoch: 25 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556300866366573		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.4556300866366573 | validation: 0.5679068647527238]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.522272062890028		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.522272062890028 | validation: 0.4759727363898895]
	TIME [epoch: 25 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6425202595801234		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.6425202595801234 | validation: 0.759256917722073]
	TIME [epoch: 25 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5839644099538105		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.5839644099538105 | validation: 0.8825398590737641]
	TIME [epoch: 24.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5889209049574808		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.5889209049574808 | validation: 0.5699595517569996]
	TIME [epoch: 24.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5005464648760535		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.5005464648760535 | validation: 0.5008138894107993]
	TIME [epoch: 25 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4143723107660814		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.4143723107660814 | validation: 0.4752958784995191]
	TIME [epoch: 24.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3749748454581936		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.3749748454581936 | validation: 0.4904822464102817]
	TIME [epoch: 25 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4001954278728837		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.4001954278728837 | validation: 0.5090384287437875]
	TIME [epoch: 25 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.515439679291231		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.515439679291231 | validation: 0.7587237071309304]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5590644271801519		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.5590644271801519 | validation: 0.6397055279525666]
	TIME [epoch: 24.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4793039769334013		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.4793039769334013 | validation: 0.5306099609239364]
	TIME [epoch: 25 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4705010243577623		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.4705010243577623 | validation: 0.5052396464511528]
	TIME [epoch: 24.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38458265579438483		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.38458265579438483 | validation: 0.4172874913019859]
	TIME [epoch: 24.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36424204064843557		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.36424204064843557 | validation: 0.6237016817180703]
	TIME [epoch: 25 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3975691397854611		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.3975691397854611 | validation: 0.5201619376245644]
	TIME [epoch: 24.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40092262993975836		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.40092262993975836 | validation: 0.404410458967058]
	TIME [epoch: 24.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42374123179916146		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.42374123179916146 | validation: 0.5846096467200058]
	TIME [epoch: 25 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5523635368218927		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.5523635368218927 | validation: 0.6544154001310014]
	TIME [epoch: 24.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4980930918634921		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.4980930918634921 | validation: 0.5384260095854729]
	TIME [epoch: 25 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5295591014649708		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.5295591014649708 | validation: 0.7219830523967876]
	TIME [epoch: 24.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5235854634015125		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.5235854634015125 | validation: 0.5083832324923957]
	TIME [epoch: 24.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4843546868890366		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.4843546868890366 | validation: 0.5238843294093367]
	TIME [epoch: 24.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3986049268235746		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.3986049268235746 | validation: 0.46672480499113234]
	TIME [epoch: 24.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3625809291792817		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.3625809291792817 | validation: 0.6214238557371818]
	TIME [epoch: 24.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5785128435529021		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.5785128435529021 | validation: 0.591103301053164]
	TIME [epoch: 24.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47295216359630565		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.47295216359630565 | validation: 0.5111797381379181]
	TIME [epoch: 25 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44196609655641794		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.44196609655641794 | validation: 0.5378655173353957]
	TIME [epoch: 24.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.456458527849919		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.456458527849919 | validation: 0.49276066212306274]
	TIME [epoch: 24.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40515969927605233		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.40515969927605233 | validation: 0.47904484606668823]
	TIME [epoch: 25 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40289011997173574		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.40289011997173574 | validation: 0.44159043324030495]
	TIME [epoch: 24.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35640562837703904		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.35640562837703904 | validation: 0.41569765306220063]
	TIME [epoch: 24.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40296369347236044		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.40296369347236044 | validation: 0.5091418686561717]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4755054067566301		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.4755054067566301 | validation: 0.5972553563352639]
	TIME [epoch: 24.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5903075797999089		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.5903075797999089 | validation: 0.4700992200849629]
	TIME [epoch: 24.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39833049987441005		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.39833049987441005 | validation: 0.44490710994877425]
	TIME [epoch: 25 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46998425455403503		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.46998425455403503 | validation: 0.6707513096798072]
	TIME [epoch: 24.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4659391828534448		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.4659391828534448 | validation: 0.4043080740760908]
	TIME [epoch: 24.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632981672442467		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.3632981672442467 | validation: 0.4264027541979349]
	TIME [epoch: 25 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4221516629309275		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.4221516629309275 | validation: 0.6280948576505457]
	TIME [epoch: 24.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4049023783883097		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.4049023783883097 | validation: 0.3550897940816016]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_824.pth
	Model improved!!!
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3308677517768752		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.3308677517768752 | validation: 0.429618800763685]
	TIME [epoch: 25 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34218827595963297		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.34218827595963297 | validation: 0.4676847045825682]
	TIME [epoch: 25 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385988949796454		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.3385988949796454 | validation: 0.3756491330231721]
	TIME [epoch: 24.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3625808904579554		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.3625808904579554 | validation: 0.4570225013675308]
	TIME [epoch: 25 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36886191518453026		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.36886191518453026 | validation: 0.41714266457412913]
	TIME [epoch: 25 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3978984834989074		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.3978984834989074 | validation: 0.5442333045638623]
	TIME [epoch: 25 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37831561481391807		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.37831561481391807 | validation: 0.46447019770399095]
	TIME [epoch: 25 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35704447930279637		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.35704447930279637 | validation: 0.42738969886925376]
	TIME [epoch: 25 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3548253045028975		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.3548253045028975 | validation: 0.42247066014318796]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45264636671304287		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.45264636671304287 | validation: 0.4571640642958485]
	TIME [epoch: 25 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38072263018922664		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.38072263018922664 | validation: 0.5206237798996395]
	TIME [epoch: 24.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40008194821876164		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.40008194821876164 | validation: 0.5488956161909001]
	TIME [epoch: 24.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7351826060257565		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.7351826060257565 | validation: 0.6235366636175803]
	TIME [epoch: 24.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4679689880261013		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.4679689880261013 | validation: 0.42867654926036725]
	TIME [epoch: 25 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35279022220001044		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.35279022220001044 | validation: 0.4032557861911918]
	TIME [epoch: 24.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3573247095484001		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.3573247095484001 | validation: 0.47524978479032715]
	TIME [epoch: 25 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4396030781436253		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.4396030781436253 | validation: 0.5351817144164658]
	TIME [epoch: 25 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48486547607966307		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.48486547607966307 | validation: 0.6021988362890578]
	TIME [epoch: 24.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4973193980746691		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.4973193980746691 | validation: 0.5163265879145905]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4257777242518288		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.4257777242518288 | validation: 0.37939433554286767]
	TIME [epoch: 24.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.328569903008864		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.328569903008864 | validation: 0.3739818341551009]
	TIME [epoch: 24.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41244885593401487		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.41244885593401487 | validation: 0.4505948474910692]
	TIME [epoch: 25 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39580215686862874		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.39580215686862874 | validation: 0.40779748245552194]
	TIME [epoch: 24.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43242515944575355		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.43242515944575355 | validation: 0.5907849477417758]
	TIME [epoch: 24.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4934816551510918		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.4934816551510918 | validation: 0.4249180539736598]
	TIME [epoch: 25 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3385028405137991		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.3385028405137991 | validation: 0.40353115999468114]
	TIME [epoch: 25 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33472857386857946		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.33472857386857946 | validation: 0.39679920783798184]
	TIME [epoch: 24.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34302246487475474		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.34302246487475474 | validation: 0.4114259744260538]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32047215446179433		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.32047215446179433 | validation: 0.34788052989672225]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240309_135644/states/model_tr_study5_853.pth
	Model improved!!!
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3256804006796324		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.3256804006796324 | validation: 0.4798700211943451]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37164854932885827		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.37164854932885827 | validation: 0.5002758294013051]
	TIME [epoch: 25 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6127854380919217		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.6127854380919217 | validation: 0.650823699277806]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5501085954903602		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.5501085954903602 | validation: 0.5314975889401028]
	TIME [epoch: 24.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4119410538934062		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.4119410538934062 | validation: 0.4750977728141724]
	TIME [epoch: 24.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42725617453381065		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.42725617453381065 | validation: 0.510143180728764]
	TIME [epoch: 25 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247934025411366		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.5247934025411366 | validation: 0.6414789093427845]
	TIME [epoch: 24.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6367106544391997		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.6367106544391997 | validation: 0.5803071238121563]
	TIME [epoch: 25 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45933896478732306		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.45933896478732306 | validation: 0.5053910964640957]
	TIME [epoch: 25 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40822455727289536		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.40822455727289536 | validation: 0.5432304923478819]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4889200677642778		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.4889200677642778 | validation: 0.4377798400778191]
	TIME [epoch: 24.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5298166033587659		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.5298166033587659 | validation: 0.4983983969441742]
	TIME [epoch: 24.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4863461911484469		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.4863461911484469 | validation: 0.5086648876815525]
	TIME [epoch: 24.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569180721723201		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.4569180721723201 | validation: 0.41752702137364694]
	TIME [epoch: 24.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40226451570221416		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.40226451570221416 | validation: 0.3683853219944726]
	TIME [epoch: 24.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3479010867606402		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.3479010867606402 | validation: 0.7334694843378763]
	TIME [epoch: 24.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48160558769958184		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.48160558769958184 | validation: 0.42193355539806815]
	TIME [epoch: 24.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34803759541849677		[learning rate: 0.00054614]
