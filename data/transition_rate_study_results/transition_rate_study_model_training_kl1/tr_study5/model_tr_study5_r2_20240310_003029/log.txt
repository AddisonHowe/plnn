Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r2', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2996029599

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.578855996528784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.578855996528784 | validation: 9.8572666336771]
	TIME [epoch: 112 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.316289501612632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.316289501612632 | validation: 9.027525516533911]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.3491636221195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.3491636221195 | validation: 8.65833867666255]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.959565678236011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.959565678236011 | validation: 8.439610077208277]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.7641148355530785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.7641148355530785 | validation: 8.40836452199582]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.767325186919711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.767325186919711 | validation: 7.4837917430540575]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.33166202895888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.33166202895888 | validation: 7.193987987711696]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.96438031778383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.96438031778383 | validation: 6.859078578039124]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.59893253244984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.59893253244984 | validation: 6.572107629291322]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4688074525248656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4688074525248656 | validation: 6.443361984651242]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.216524256442738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.216524256442738 | validation: 6.1697520256678695]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.152485880910298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.152485880910298 | validation: 6.069085103540097]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.072024688895391		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.072024688895391 | validation: 6.129537628160997]
	TIME [epoch: 25 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.205743350647334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.205743350647334 | validation: 6.4866152568154645]
	TIME [epoch: 25 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.186007115176849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.186007115176849 | validation: 5.861590249708729]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.030962831987898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.030962831987898 | validation: 5.890148803260327]
	TIME [epoch: 25 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.931302057468039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.931302057468039 | validation: 5.745466289061767]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.838925558242824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.838925558242824 | validation: 6.691184537137835]
	TIME [epoch: 24.9 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.946746179723457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.946746179723457 | validation: 6.014749144781917]
	TIME [epoch: 25 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1331792159855345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1331792159855345 | validation: 6.032972916281165]
	TIME [epoch: 25 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0052751574580565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0052751574580565 | validation: 5.884194578730699]
	TIME [epoch: 25 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.909714116569715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.909714116569715 | validation: 5.759776297909818]
	TIME [epoch: 25 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.836103524305552		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.836103524305552 | validation: 5.781676321265711]
	TIME [epoch: 25 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.838143338074053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.838143338074053 | validation: 5.670815319200956]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7343697156398425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7343697156398425 | validation: 5.588843047862635]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7969731010120995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7969731010120995 | validation: 5.624904596628433]
	TIME [epoch: 25 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.668096271675312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.668096271675312 | validation: 5.650940754464386]
	TIME [epoch: 25 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7261800095088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7261800095088 | validation: 5.775381735146705]
	TIME [epoch: 25 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.935488736509654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.935488736509654 | validation: 5.6893592185952295]
	TIME [epoch: 25 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0249332720599345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0249332720599345 | validation: 5.735461545075566]
	TIME [epoch: 25 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8818128984799385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8818128984799385 | validation: 5.676061235045409]
	TIME [epoch: 25 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.770115345173802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.770115345173802 | validation: 5.58675446295676]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6702532762173385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6702532762173385 | validation: 5.538118843142495]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.279149633817271		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.279149633817271 | validation: 9.665782417689124]
	TIME [epoch: 24.9 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.177895686942675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.177895686942675 | validation: 5.940394785698872]
	TIME [epoch: 25 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1047827743664085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1047827743664085 | validation: 5.915595876132859]
	TIME [epoch: 25 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.002933661448344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.002933661448344 | validation: 5.751408348174827]
	TIME [epoch: 24.9 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7954048388656165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7954048388656165 | validation: 5.739856261566697]
	TIME [epoch: 25 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.882446399247633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.882446399247633 | validation: 5.7212622726801055]
	TIME [epoch: 25 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.81589675912276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.81589675912276 | validation: 5.6342810496543]
	TIME [epoch: 24.9 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.703435279901878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.703435279901878 | validation: 5.597426038783147]
	TIME [epoch: 25 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.848493545977472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.848493545977472 | validation: 5.609812057690062]
	TIME [epoch: 25 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7545207489138726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7545207489138726 | validation: 6.006937326119672]
	TIME [epoch: 25 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.910920367123717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.910920367123717 | validation: 5.794541752214029]
	TIME [epoch: 25 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.733128858583315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.733128858583315 | validation: 5.768992956162]
	TIME [epoch: 24.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.083869522563081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.083869522563081 | validation: 7.191697010101919]
	TIME [epoch: 25 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.00333834171345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.00333834171345 | validation: 5.480292534505382]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5790413239821035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5790413239821035 | validation: 5.4493306267318]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.489052268306505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.489052268306505 | validation: 5.367354002774143]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.493938204304872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.493938204304872 | validation: 5.912077048020207]
	TIME [epoch: 24.9 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.380423714257717		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 6.380423714257717 | validation: 6.036773174826571]
	TIME [epoch: 24.9 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.555443739239459		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.555443739239459 | validation: 5.817685282013799]
	TIME [epoch: 24.9 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.786830681575038		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.786830681575038 | validation: 6.389810467901108]
	TIME [epoch: 24.9 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.600567666409436		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 6.600567666409436 | validation: 6.47864157997963]
	TIME [epoch: 24.9 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.612385996825656		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.612385996825656 | validation: 5.607322913397352]
	TIME [epoch: 25 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.427055601694116		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 5.427055601694116 | validation: 5.425950526036554]
	TIME [epoch: 24.9 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.837709029281074		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.837709029281074 | validation: 6.297124343449066]
	TIME [epoch: 24.9 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.75144174906942		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.75144174906942 | validation: 5.449354687177776]
	TIME [epoch: 25 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.502575029975563		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.502575029975563 | validation: 5.5149388386517275]
	TIME [epoch: 25 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.433119303859855		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.433119303859855 | validation: 6.550261105813752]
	TIME [epoch: 24.9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.275884121385475		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 6.275884121385475 | validation: 5.696399806510099]
	TIME [epoch: 24.9 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.478321292305685		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 5.478321292305685 | validation: 5.36616334331753]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.31847724304697		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.31847724304697 | validation: 5.143012542114881]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.188840738324078		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.188840738324078 | validation: 5.139894503055636]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.12495473121421		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 5.12495473121421 | validation: 5.357667968873418]
	TIME [epoch: 24.9 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.34250812451414		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.34250812451414 | validation: 5.291620206795046]
	TIME [epoch: 24.9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.314351655411693		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 5.314351655411693 | validation: 5.672424355070772]
	TIME [epoch: 25 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.280204777990959		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 5.280204777990959 | validation: 5.287154588255724]
	TIME [epoch: 25 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.589204584478587		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 6.589204584478587 | validation: 9.332712798653858]
	TIME [epoch: 24.9 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.72090737063124		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 7.72090737063124 | validation: 5.408852036681459]
	TIME [epoch: 25 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1683822258299505		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 5.1683822258299505 | validation: 5.160480055943688]
	TIME [epoch: 25 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.016910380226963		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 6.016910380226963 | validation: 7.678516298447342]
	TIME [epoch: 24.9 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.601552288865554		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 6.601552288865554 | validation: 5.6332181164558435]
	TIME [epoch: 25 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.228183144197809		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 5.228183144197809 | validation: 5.103047335247356]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.29901396490483		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 5.29901396490483 | validation: 5.440038963615283]
	TIME [epoch: 24.9 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.348770928237056		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 5.348770928237056 | validation: 5.602288024200432]
	TIME [epoch: 25 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1991144891206815		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 5.1991144891206815 | validation: 5.093058738993896]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.136054079079256		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 5.136054079079256 | validation: 6.277901412527042]
	TIME [epoch: 24.9 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.222059915942924		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 6.222059915942924 | validation: 6.512948053287292]
	TIME [epoch: 25 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.581639443378086		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 5.581639443378086 | validation: 5.356132497290596]
	TIME [epoch: 24.9 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.352456636479358		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 5.352456636479358 | validation: 5.11695255336915]
	TIME [epoch: 25 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.972751541115553		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 4.972751541115553 | validation: 5.148217287546815]
	TIME [epoch: 25 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.335705693281531		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 5.335705693281531 | validation: 5.83191781936418]
	TIME [epoch: 25 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.840720550507504		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 5.840720550507504 | validation: 5.236634449940224]
	TIME [epoch: 25 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.02533224871159		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 5.02533224871159 | validation: 5.281839595022056]
	TIME [epoch: 25 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.693875602285276		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 5.693875602285276 | validation: 6.387549919624932]
	TIME [epoch: 25 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4709540651974455		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 5.4709540651974455 | validation: 5.19837915204602]
	TIME [epoch: 25 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.204815298360817		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 5.204815298360817 | validation: 5.165992045017458]
	TIME [epoch: 25 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.928113809049213		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 4.928113809049213 | validation: 5.032561435852283]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.920915934485921		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 4.920915934485921 | validation: 4.925377002652011]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.797341026126127		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.797341026126127 | validation: 4.830140845660306]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.86220732059755		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 4.86220732059755 | validation: 5.793303601360476]
	TIME [epoch: 25 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.386569387352472		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 5.386569387352472 | validation: 4.8357671219448815]
	TIME [epoch: 25 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.776539618749552		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.776539618749552 | validation: 4.806562070410331]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.62431627265387		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.62431627265387 | validation: 4.991033560162945]
	TIME [epoch: 25 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.660534313667103		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 4.660534313667103 | validation: 4.622789738882666]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.645759977002229		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.645759977002229 | validation: 5.187559217209084]
	TIME [epoch: 25 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1850848868737		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 6.1850848868737 | validation: 6.684794004811329]
	TIME [epoch: 25.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.777773734262248		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 5.777773734262248 | validation: 7.077561531073334]
	TIME [epoch: 25 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.7465875963033		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 6.7465875963033 | validation: 5.76128091441036]
	TIME [epoch: 25 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.1339146142907754		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 5.1339146142907754 | validation: 5.221550629683632]
	TIME [epoch: 25 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.932004145678193		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.932004145678193 | validation: 4.818537414246401]
	TIME [epoch: 25 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.834854612126177		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 4.834854612126177 | validation: 4.99028622807982]
	TIME [epoch: 25 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.638436100506392		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.638436100506392 | validation: 4.498192083100435]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.448442230425826		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 4.448442230425826 | validation: 4.464520951066032]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_105.pth
	Model improved!!!
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.323932567968807		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 4.323932567968807 | validation: 4.302490310976253]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.228653600099733		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 4.228653600099733 | validation: 4.809620207297187]
	TIME [epoch: 25 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.469802870291138		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.469802870291138 | validation: 4.380217464224486]
	TIME [epoch: 25 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.06501509571146		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.06501509571146 | validation: 4.124362528871833]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.137228277933632		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 4.137228277933632 | validation: 4.035969195988373]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7859465735535176		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 3.7859465735535176 | validation: 4.104145365415029]
	TIME [epoch: 25 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.781390248003538		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 4.781390248003538 | validation: 4.5067585722006935]
	TIME [epoch: 24.9 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9799596752861657		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.9799596752861657 | validation: 5.117740171044876]
	TIME [epoch: 25 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.673336859091183		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 5.673336859091183 | validation: 7.961025215630223]
	TIME [epoch: 25 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.696721762804894		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 7.696721762804894 | validation: 8.49811546947573]
	TIME [epoch: 24.9 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.342182232924777		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 7.342182232924777 | validation: 6.12210058973423]
	TIME [epoch: 25 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.13678657569546		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 5.13678657569546 | validation: 4.37213310212058]
	TIME [epoch: 25 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9624633472709356		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.9624633472709356 | validation: 3.9118258114938]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.665870847809667		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.665870847809667 | validation: 3.6413105116448437]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.495492842171819		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.495492842171819 | validation: 3.697502405253495]
	TIME [epoch: 25 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.488271308521162		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 4.488271308521162 | validation: 4.825658434803503]
	TIME [epoch: 24.9 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.26951780862872		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.26951780862872 | validation: 3.7827241672555263]
	TIME [epoch: 25 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.452634107561859		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.452634107561859 | validation: 3.397096642124373]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3374483972508258		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.3374483972508258 | validation: 3.184539002580557]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.553251653559527		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 4.553251653559527 | validation: 6.069884883299151]
	TIME [epoch: 25 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.062871587453878		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 4.062871587453878 | validation: 3.4080262526360934]
	TIME [epoch: 25 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2165877572219097		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.2165877572219097 | validation: 3.095385616344662]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.093974410003796		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 3.093974410003796 | validation: 3.0259220172460615]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2885716756135546		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 3.2885716756135546 | validation: 4.06486257983692]
	TIME [epoch: 25 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.245817107063078		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 3.245817107063078 | validation: 4.469724649716007]
	TIME [epoch: 25 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.039294498736309		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 4.039294498736309 | validation: 3.4094236174838257]
	TIME [epoch: 25 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.062049208311244		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.062049208311244 | validation: 3.942360513770647]
	TIME [epoch: 25 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.887037510822403		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 5.887037510822403 | validation: 7.034974041563881]
	TIME [epoch: 25 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.757130863318168		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 6.757130863318168 | validation: 8.096806653045016]
	TIME [epoch: 25 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.170961069930019		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 7.170961069930019 | validation: 7.420877771779097]
	TIME [epoch: 25 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.434566945763503		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 6.434566945763503 | validation: 6.369977188440832]
	TIME [epoch: 24.9 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6744933120055885		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 5.6744933120055885 | validation: 5.6392119957255185]
	TIME [epoch: 25 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5113461500592695		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 4.5113461500592695 | validation: 3.6756394991909973]
	TIME [epoch: 25 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1771230685650784		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.1771230685650784 | validation: 3.2378272287034084]
	TIME [epoch: 24.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.956193387811714		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 2.956193387811714 | validation: 2.875041886918099]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8509082976336773		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 2.8509082976336773 | validation: 2.8995172148133883]
	TIME [epoch: 25 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.912398448231614		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 2.912398448231614 | validation: 2.7530664493419614]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6107368227284877		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.6107368227284877 | validation: 3.261893925106828]
	TIME [epoch: 25 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.038406105252556		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 3.038406105252556 | validation: 2.933848688512486]
	TIME [epoch: 25 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5196337441304753		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.5196337441304753 | validation: 3.409738185648191]
	TIME [epoch: 24.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.844629201261819		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.844629201261819 | validation: 2.9001015669213706]
	TIME [epoch: 25 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5070645314899562		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.5070645314899562 | validation: 2.6172252841518917]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_147.pth
	Model improved!!!
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5051259346463404		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 2.5051259346463404 | validation: 2.5373000649062125]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_148.pth
	Model improved!!!
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0116036866461986		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.0116036866461986 | validation: 3.140329049640194]
	TIME [epoch: 24.9 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.746139634282527		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.746139634282527 | validation: 2.238197193796164]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_150.pth
	Model improved!!!
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.214863275598928		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.214863275598928 | validation: 2.188974992130708]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_151.pth
	Model improved!!!
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.235443373044033		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 2.235443373044033 | validation: 2.20557861790553]
	TIME [epoch: 24.9 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.243156429695664		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.243156429695664 | validation: 2.165010287789606]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_153.pth
	Model improved!!!
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.174689183675587		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.174689183675587 | validation: 2.954817261620281]
	TIME [epoch: 25 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.39416318178459		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.39416318178459 | validation: 3.0336965260260707]
	TIME [epoch: 24.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.296533761460981		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.296533761460981 | validation: 2.090625175948399]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_156.pth
	Model improved!!!
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.025717286325974		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.025717286325974 | validation: 1.92766671266182]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9636129269324463		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.9636129269324463 | validation: 2.1055406890692647]
	TIME [epoch: 24.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9774341322168816		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.9774341322168816 | validation: 1.9656395864472265]
	TIME [epoch: 25 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.984430600796224		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.984430600796224 | validation: 1.8083009365027634]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1910680181108506		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.1910680181108506 | validation: 2.9051528712134123]
	TIME [epoch: 24.9 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.604398923215862		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 2.604398923215862 | validation: 1.9712862054870623]
	TIME [epoch: 25 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0166959954924684		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 2.0166959954924684 | validation: 2.63967206856536]
	TIME [epoch: 25 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2625056366192386		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.2625056366192386 | validation: 2.6834017688105396]
	TIME [epoch: 24.9 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.285378639023475		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.285378639023475 | validation: 1.8636302932528275]
	TIME [epoch: 25 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9451177988167978		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.9451177988167978 | validation: 2.085171184757727]
	TIME [epoch: 25 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7987147879380347		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.7987147879380347 | validation: 1.9986755067130588]
	TIME [epoch: 24.9 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0829487118850736		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 2.0829487118850736 | validation: 3.557535941255785]
	TIME [epoch: 25 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4842798986788495		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 2.4842798986788495 | validation: 1.9184851218034675]
	TIME [epoch: 25 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8370179227804473		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.8370179227804473 | validation: 1.9173490431326974]
	TIME [epoch: 24.9 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9592556575738436		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.9592556575738436 | validation: 2.2364404004345593]
	TIME [epoch: 25 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.873554549237547		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.873554549237547 | validation: 1.8838633644890217]
	TIME [epoch: 24.9 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6058392287023917		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.6058392287023917 | validation: 2.0859048557571276]
	TIME [epoch: 24.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.170851975712023		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.170851975712023 | validation: 1.9230963998415929]
	TIME [epoch: 25 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.912091571128355		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.912091571128355 | validation: 2.2025916070397624]
	TIME [epoch: 25 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7423619174269693		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.7423619174269693 | validation: 2.147839160478541]
	TIME [epoch: 24.9 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8439652767526673		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.8439652767526673 | validation: 2.372627823171112]
	TIME [epoch: 25 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7849456901660856		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.7849456901660856 | validation: 1.5595978436343578]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_178.pth
	Model improved!!!
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6971063163917424		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.6971063163917424 | validation: 1.5783916260002382]
	TIME [epoch: 24.9 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5999542599030594		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.5999542599030594 | validation: 2.04995076214431]
	TIME [epoch: 25 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.654096372948136		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.654096372948136 | validation: 2.162242212705326]
	TIME [epoch: 25 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.691104706116488		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.691104706116488 | validation: 2.213579104465959]
	TIME [epoch: 24.9 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.647382205821718		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.647382205821718 | validation: 1.7223434938144635]
	TIME [epoch: 25 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7380533041431234		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.7380533041431234 | validation: 2.0038403042748123]
	TIME [epoch: 25 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.775012680176848		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.775012680176848 | validation: 1.4956895206546186]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6943350374143444		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.6943350374143444 | validation: 1.5293739940694124]
	TIME [epoch: 25 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4581181484044519		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.4581181484044519 | validation: 1.7745190835234588]
	TIME [epoch: 25 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6187877285135643		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.6187877285135643 | validation: 2.1358709818012005]
	TIME [epoch: 24.9 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6666844539700785		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.6666844539700785 | validation: 1.5063555699664586]
	TIME [epoch: 25 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5337878433746548		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.5337878433746548 | validation: 1.38812781309145]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_190.pth
	Model improved!!!
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5429211791126476		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.5429211791126476 | validation: 1.5107157392734296]
	TIME [epoch: 24.9 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6279420593621252		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.6279420593621252 | validation: 1.7561684237351518]
	TIME [epoch: 25 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5982499098639598		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.5982499098639598 | validation: 2.3543536266725598]
	TIME [epoch: 25 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.785559267814849		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.785559267814849 | validation: 3.402270024114226]
	TIME [epoch: 24.9 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1559447905367457		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.1559447905367457 | validation: 1.9338435494541961]
	TIME [epoch: 25 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0171496568827694		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 2.0171496568827694 | validation: 1.7120497008324744]
	TIME [epoch: 25 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.748774326722105		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.748774326722105 | validation: 2.4681209594385276]
	TIME [epoch: 24.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9131907080276498		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 1.9131907080276498 | validation: 2.8146617836577916]
	TIME [epoch: 25 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8645931575713521		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.8645931575713521 | validation: 1.7684589484808515]
	TIME [epoch: 25 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4180572678662515		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.4180572678662515 | validation: 1.7098354536495588]
	TIME [epoch: 24.9 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.135256128555603		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.135256128555603 | validation: 1.8961526921899055]
	TIME [epoch: 25 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9468998660732129		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.9468998660732129 | validation: 1.9035720981249744]
	TIME [epoch: 25 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6337344526309823		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.6337344526309823 | validation: 1.554076844478833]
	TIME [epoch: 24.9 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8562110710599757		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.8562110710599757 | validation: 2.3409894089101626]
	TIME [epoch: 24.9 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8653536241476434		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.8653536241476434 | validation: 1.509410572513375]
	TIME [epoch: 25 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4702276470089624		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.4702276470089624 | validation: 2.817747456787614]
	TIME [epoch: 24.9 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.138822486073746		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 2.138822486073746 | validation: 1.9034199911402112]
	TIME [epoch: 24.9 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5378888652204181		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.5378888652204181 | validation: 1.8199188569810496]
	TIME [epoch: 25 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6967560530405692		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.6967560530405692 | validation: 1.3295927039112798]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5929522773877722		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.5929522773877722 | validation: 1.5561670751247982]
	TIME [epoch: 24.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.432226319817489		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.432226319817489 | validation: 1.4302826868604177]
	TIME [epoch: 24.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0832991339507294		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.0832991339507294 | validation: 1.6986678522581866]
	TIME [epoch: 24.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3667903310202583		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 2.3667903310202583 | validation: 2.2512215604680668]
	TIME [epoch: 24.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8705780330731947		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.8705780330731947 | validation: 1.5904319741351116]
	TIME [epoch: 24.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0408346538330333		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 2.0408346538330333 | validation: 2.423583880810903]
	TIME [epoch: 24.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7948626543241801		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.7948626543241801 | validation: 1.3851407250032726]
	TIME [epoch: 24.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4557197102307309		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.4557197102307309 | validation: 1.5099621400908063]
	TIME [epoch: 25 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5517072871113455		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.5517072871113455 | validation: 2.0786267037278465]
	TIME [epoch: 24.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7916400327985438		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.7916400327985438 | validation: 4.267477994548285]
	TIME [epoch: 24.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.925064901635805		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 4.925064901635805 | validation: 4.174372797142783]
	TIME [epoch: 24.9 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1358094276709148		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 3.1358094276709148 | validation: 1.3545696415616089]
	TIME [epoch: 24.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4784049374025852		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.4784049374025852 | validation: 1.3876578413991465]
	TIME [epoch: 24.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4385395386730957		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.4385395386730957 | validation: 1.4559771225519504]
	TIME [epoch: 24.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.484622168126565		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 1.484622168126565 | validation: 1.2419000744881903]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6069040324793868		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.6069040324793868 | validation: 2.4730580766363426]
	TIME [epoch: 24.9 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.630650157208101		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.630650157208101 | validation: 1.2049037041816406]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4574352474329753		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.4574352474329753 | validation: 1.4247518504002334]
	TIME [epoch: 24.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.919650387778494		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.919650387778494 | validation: 2.748128453554875]
	TIME [epoch: 24.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7597265884214914		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 1.7597265884214914 | validation: 1.3686275171255124]
	TIME [epoch: 24.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8323189059209264		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.8323189059209264 | validation: 1.2644943452049167]
	TIME [epoch: 24.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.542223477538509		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.542223477538509 | validation: 2.368064273239548]
	TIME [epoch: 24.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.633093277975305		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.633093277975305 | validation: 1.2077001059649974]
	TIME [epoch: 24.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3259801607625723		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.3259801607625723 | validation: 1.3844390057515108]
	TIME [epoch: 24.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4562933114205816		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.4562933114205816 | validation: 1.778101375364794]
	TIME [epoch: 24.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6559051118584138		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.6559051118584138 | validation: 1.4564827013365902]
	TIME [epoch: 25 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9045152831326595		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.9045152831326595 | validation: 1.9189546631725787]
	TIME [epoch: 24.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4697335976659054		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.4697335976659054 | validation: 2.6849120320890814]
	TIME [epoch: 24.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9657991684017868		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.9657991684017868 | validation: 1.2126866633240652]
	TIME [epoch: 25 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3800093213694846		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.3800093213694846 | validation: 2.2027277228867717]
	TIME [epoch: 24.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1267557008051794		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 2.1267557008051794 | validation: 2.9974768143027517]
	TIME [epoch: 24.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8852360975657234		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.8852360975657234 | validation: 1.1550745117275971]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7378027977350614		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.7378027977350614 | validation: 1.5195004139182198]
	TIME [epoch: 24.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6575652639962188		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.6575652639962188 | validation: 1.459463002904847]
	TIME [epoch: 24.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6810294059054556		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.6810294059054556 | validation: 1.4632404743607992]
	TIME [epoch: 24.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4966549493383627		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.4966549493383627 | validation: 2.047326625424249]
	TIME [epoch: 24.9 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9590456597552597		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 1.9590456597552597 | validation: 1.7764590863443221]
	TIME [epoch: 24.9 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8278987661412278		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.8278987661412278 | validation: 1.7392741874590458]
	TIME [epoch: 24.9 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6102633443805119		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 1.6102633443805119 | validation: 1.994643227625812]
	TIME [epoch: 24.9 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.915328078227793		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.915328078227793 | validation: 1.2601970772099504]
	TIME [epoch: 24.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2200678445817013		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 2.2200678445817013 | validation: 2.162083775917544]
	TIME [epoch: 24.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.331183832731729		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 4.331183832731729 | validation: 7.40757270758488]
	TIME [epoch: 24.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.163715476640073		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 6.163715476640073 | validation: 6.878272085762677]
	TIME [epoch: 24.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.199956857339728		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 6.199956857339728 | validation: 6.805874305356617]
	TIME [epoch: 24.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.899265194709209		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 5.899265194709209 | validation: 6.672569438428425]
	TIME [epoch: 24.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.672833136936576		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 5.672833136936576 | validation: 6.591029035474381]
	TIME [epoch: 24.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.620329493267676		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 5.620329493267676 | validation: 6.553023579767551]
	TIME [epoch: 24.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.570700504073007		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 5.570700504073007 | validation: 6.581466685152584]
	TIME [epoch: 24.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.573969960064092		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 5.573969960064092 | validation: 6.485845356926764]
	TIME [epoch: 24.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.467948979106278		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 5.467948979106278 | validation: 6.529073637404482]
	TIME [epoch: 24.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.467588203514037		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 5.467588203514037 | validation: 6.796022117016994]
	TIME [epoch: 24.9 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.07275923952498		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 6.07275923952498 | validation: 7.156426350010759]
	TIME [epoch: 24.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.230890150114218		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 6.230890150114218 | validation: 7.010711361903527]
	TIME [epoch: 24.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.30464408809421		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 6.30464408809421 | validation: 7.040980041112922]
	TIME [epoch: 24.9 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.199891296984428		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 6.199891296984428 | validation: 7.036147286326539]
	TIME [epoch: 24.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.231578487399525		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 6.231578487399525 | validation: 7.031870018144911]
	TIME [epoch: 24.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.166665504417806		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 6.166665504417806 | validation: 7.093060167095828]
	TIME [epoch: 24.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.231691536673891		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 6.231691536673891 | validation: 7.0333651028888715]
	TIME [epoch: 24.9 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.223031697234477		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 6.223031697234477 | validation: 6.985821384119044]
	TIME [epoch: 24.9 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3496625589485705		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 6.3496625589485705 | validation: 7.2807094657498315]
	TIME [epoch: 24.9 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.263416682056843		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 6.263416682056843 | validation: 7.106282604623718]
	TIME [epoch: 24.9 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.2352082684231105		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 6.2352082684231105 | validation: 7.364597576084718]
	TIME [epoch: 24.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.323636277154846		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 6.323636277154846 | validation: 7.328135915176631]
	TIME [epoch: 24.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7841538475080085		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 5.7841538475080085 | validation: 6.530821001547256]
	TIME [epoch: 24.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.487187337596909		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 5.487187337596909 | validation: 6.676396402171324]
	TIME [epoch: 25 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.402372000433935		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 6.402372000433935 | validation: 7.845771420966419]
	TIME [epoch: 24.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.616940062541747		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 6.616940062541747 | validation: 7.538938346664707]
	TIME [epoch: 24.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.522366842202358		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 6.522366842202358 | validation: 7.553331531922563]
	TIME [epoch: 25 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.5691701927446795		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 6.5691701927446795 | validation: 7.734192914746684]
	TIME [epoch: 24.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.76585955335465		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 6.76585955335465 | validation: 7.523157015604269]
	TIME [epoch: 24.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.540166721383027		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 6.540166721383027 | validation: 7.58176113160087]
	TIME [epoch: 24.9 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.530110235778642		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 6.530110235778642 | validation: 7.536772445126799]
	TIME [epoch: 24.9 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.4929516228311766		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 6.4929516228311766 | validation: 7.507448525517112]
	TIME [epoch: 24.9 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.37982765002793		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 6.37982765002793 | validation: 6.684650135951967]
	TIME [epoch: 25 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.429315725143434		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 5.429315725143434 | validation: 6.6350314595366875]
	TIME [epoch: 24.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.494140343295612		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 5.494140343295612 | validation: 5.253183423169212]
	TIME [epoch: 24.9 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0038691802960376		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 4.0038691802960376 | validation: 4.5539671826743495]
	TIME [epoch: 25 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.60319016263985		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 3.60319016263985 | validation: 4.25940860321891]
	TIME [epoch: 24.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.207757549147233		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 3.207757549147233 | validation: 3.830988351082972]
	TIME [epoch: 24.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.46451509092382		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 3.46451509092382 | validation: 3.708065760480916]
	TIME [epoch: 25 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.799604524296995		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 2.799604524296995 | validation: 3.128488854005799]
	TIME [epoch: 25 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3943956140309313		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 2.3943956140309313 | validation: 2.778385653153933]
	TIME [epoch: 24.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.50652370082409		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 2.50652370082409 | validation: 3.11169993296832]
	TIME [epoch: 25 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1895676773257287		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 2.1895676773257287 | validation: 2.2239169891238113]
	TIME [epoch: 25 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9496583982163953		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 1.9496583982163953 | validation: 2.1396668291737835]
	TIME [epoch: 24.9 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9049960319997377		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.9049960319997377 | validation: 1.7360640472171052]
	TIME [epoch: 25 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8102810112485532		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.8102810112485532 | validation: 1.6418900974906359]
	TIME [epoch: 25 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6441412120053631		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.6441412120053631 | validation: 1.7236584747326809]
	TIME [epoch: 24.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9801726366194585		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.9801726366194585 | validation: 1.8166259180930058]
	TIME [epoch: 25 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.733532482605507		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 1.733532482605507 | validation: 2.181344436167254]
	TIME [epoch: 25 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7856397626028555		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.7856397626028555 | validation: 1.750226855848668]
	TIME [epoch: 24.9 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8636006227215955		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.8636006227215955 | validation: 1.7022816739921567]
	TIME [epoch: 25 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8421424106887043		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.8421424106887043 | validation: 1.52535065932762]
	TIME [epoch: 25 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.705521774903958		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.705521774903958 | validation: 1.587915873455118]
	TIME [epoch: 24.9 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5117186306759889		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.5117186306759889 | validation: 1.5983799109980357]
	TIME [epoch: 25 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9132949560840817		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.9132949560840817 | validation: 1.8092856059375482]
	TIME [epoch: 25 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6185947282917605		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.6185947282917605 | validation: 1.814342645933766]
	TIME [epoch: 24.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5390453082200657		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.5390453082200657 | validation: 1.721247021568452]
	TIME [epoch: 25 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1547831931704815		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 2.1547831931704815 | validation: 1.6777050747882476]
	TIME [epoch: 25 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5267676483899728		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.5267676483899728 | validation: 2.220688478284622]
	TIME [epoch: 24.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.066924024497818		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 2.066924024497818 | validation: 1.763046574548051]
	TIME [epoch: 25 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8360993722413594		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.8360993722413594 | validation: 2.1273636092206285]
	TIME [epoch: 25 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.74538437845641		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.74538437845641 | validation: 1.8123649003060944]
	TIME [epoch: 24.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.423442183030742		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 2.423442183030742 | validation: 6.1860788849905575]
	TIME [epoch: 25 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.931906366817693		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 3.931906366817693 | validation: 1.9197685121637758]
	TIME [epoch: 24.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.467365381206105		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 2.467365381206105 | validation: 1.8961768587097638]
	TIME [epoch: 24.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7829363439387529		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.7829363439387529 | validation: 1.821347235616127]
	TIME [epoch: 25 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6048717294110788		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.6048717294110788 | validation: 1.9970817619306918]
	TIME [epoch: 25 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6422370592796924		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.6422370592796924 | validation: 1.3747432677700215]
	TIME [epoch: 24.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.55927605677705		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.55927605677705 | validation: 1.411832868024907]
	TIME [epoch: 25 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5600123721351955		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.5600123721351955 | validation: 1.6162342979654478]
	TIME [epoch: 25 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.235947333016278		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 2.235947333016278 | validation: 3.49453111867702]
	TIME [epoch: 24.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.566210158889688		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 2.566210158889688 | validation: 4.609440212167985]
	TIME [epoch: 25 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3551418154462986		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 3.3551418154462986 | validation: 2.4872832039816384]
	TIME [epoch: 25 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.15440949827603		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 2.15440949827603 | validation: 2.0322181047725207]
	TIME [epoch: 24.9 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9213829872043593		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.9213829872043593 | validation: 2.1867519622241343]
	TIME [epoch: 25 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.030356586351845		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 2.030356586351845 | validation: 2.4263130083317885]
	TIME [epoch: 25 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.610077101714782		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 2.610077101714782 | validation: 4.460630732102906]
	TIME [epoch: 24.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0361450300100428		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 3.0361450300100428 | validation: 2.3916227437485365]
	TIME [epoch: 25 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.615917836842292		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 2.615917836842292 | validation: 2.0169114331070275]
	TIME [epoch: 25 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.991520992240122		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.991520992240122 | validation: 2.6072510132131335]
	TIME [epoch: 24.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0848418191017304		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 2.0848418191017304 | validation: 2.3175424833900333]
	TIME [epoch: 25 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0512017633458974		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 3.0512017633458974 | validation: 2.9303382438425625]
	TIME [epoch: 25 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3841337888443572		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 2.3841337888443572 | validation: 1.9778816940209891]
	TIME [epoch: 24.9 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9725401097510968		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.9725401097510968 | validation: 2.0666515291012177]
	TIME [epoch: 25 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8132274113966098		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.8132274113966098 | validation: 1.8988570537301694]
	TIME [epoch: 25 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6488789141810805		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.6488789141810805 | validation: 1.6723224718179364]
	TIME [epoch: 24.9 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.807880865268467		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.807880865268467 | validation: 1.6364555539583159]
	TIME [epoch: 25 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6127920973787115		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.6127920973787115 | validation: 1.8505360802791813]
	TIME [epoch: 25 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728582681959555		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.728582681959555 | validation: 1.487732447158885]
	TIME [epoch: 24.9 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6689376099576076		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.6689376099576076 | validation: 1.6085971614054262]
	TIME [epoch: 25 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8055003642658622		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.8055003642658622 | validation: 1.598037256951874]
	TIME [epoch: 25 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9862161633402144		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.9862161633402144 | validation: 1.7215447387901543]
	TIME [epoch: 24.9 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5671962413326335		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.5671962413326335 | validation: 1.56824839258236]
	TIME [epoch: 25 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8885034883792504		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.8885034883792504 | validation: 1.4411998160529331]
	TIME [epoch: 25 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0323870265422546		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 2.0323870265422546 | validation: 3.184553615776359]
	TIME [epoch: 24.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0783116980272975		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 3.0783116980272975 | validation: 3.6113137276134366]
	TIME [epoch: 25 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.954461649840698		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 2.954461649840698 | validation: 1.7978768458062058]
	TIME [epoch: 25 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8938071066133637		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.8938071066133637 | validation: 1.5388928142949518]
	TIME [epoch: 24.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7149385069075418		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.7149385069075418 | validation: 2.1574843943162496]
	TIME [epoch: 25 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.892529921511093		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.892529921511093 | validation: 1.7066348129056912]
	TIME [epoch: 25 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5865457296775751		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.5865457296775751 | validation: 1.4471364556239084]
	TIME [epoch: 24.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.511348089703573		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.511348089703573 | validation: 1.4528534932674666]
	TIME [epoch: 25 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4851998337429957		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.4851998337429957 | validation: 1.7629166655275719]
	TIME [epoch: 25 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1550197714525554		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 2.1550197714525554 | validation: 2.395062569404879]
	TIME [epoch: 24.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9583057227942193		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.9583057227942193 | validation: 1.467904896669088]
	TIME [epoch: 25 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7459895174314666		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.7459895174314666 | validation: 2.3120599960706807]
	TIME [epoch: 25 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.828721987027794		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.828721987027794 | validation: 1.4173564875994282]
	TIME [epoch: 24.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6315855020988737		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 1.6315855020988737 | validation: 1.4074649888570765]
	TIME [epoch: 25 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8819710320576433		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.8819710320576433 | validation: 1.592070379311872]
	TIME [epoch: 25 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.784975903688796		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.784975903688796 | validation: 2.1879233879567175]
	TIME [epoch: 24.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9966143609589273		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 1.9966143609589273 | validation: 1.7273135737301777]
	TIME [epoch: 25 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7340074826597964		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.7340074826597964 | validation: 1.4293261904864816]
	TIME [epoch: 25 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5643617973654491		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.5643617973654491 | validation: 1.9305283698308922]
	TIME [epoch: 24.9 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7761095981658872		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.7761095981658872 | validation: 2.576521085438111]
	TIME [epoch: 25 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1764826363584966		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 2.1764826363584966 | validation: 1.784881708186265]
	TIME [epoch: 24.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.551038162195978		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 1.551038162195978 | validation: 1.8851363405332011]
	TIME [epoch: 24.9 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.640737688772709		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.640737688772709 | validation: 2.1597754446731097]
	TIME [epoch: 25 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.947606930319838		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.947606930319838 | validation: 1.3970368879182349]
	TIME [epoch: 25 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6351690548198983		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 1.6351690548198983 | validation: 1.6016696995004185]
	TIME [epoch: 24.9 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7004089655134753		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.7004089655134753 | validation: 1.5719263973356143]
	TIME [epoch: 25 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.14684584089425		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 2.14684584089425 | validation: 1.7635953388826409]
	TIME [epoch: 24.9 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.562504433678984		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.562504433678984 | validation: 1.2308680784360602]
	TIME [epoch: 24.9 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4635496143174804		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.4635496143174804 | validation: 1.3484851961163296]
	TIME [epoch: 25 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5620090815139998		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.5620090815139998 | validation: 1.423246696815121]
	TIME [epoch: 24.9 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8072931184487206		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 1.8072931184487206 | validation: 2.2941757366570985]
	TIME [epoch: 24.9 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.721381660189497		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.721381660189497 | validation: 1.3556022742767744]
	TIME [epoch: 24.9 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.414034659761838		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 1.414034659761838 | validation: 1.4381157169822718]
	TIME [epoch: 24.9 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6769238534544888		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.6769238534544888 | validation: 2.8675228835319504]
	TIME [epoch: 24.9 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.203515407750414		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 4.203515407750414 | validation: 6.1520894894383265]
	TIME [epoch: 25 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.531993151169205		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 5.531993151169205 | validation: 6.778481025458527]
	TIME [epoch: 24.9 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.371315541655192		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 5.371315541655192 | validation: 2.6216429888556467]
	TIME [epoch: 24.9 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.711181129502815		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.711181129502815 | validation: 1.4521639811068736]
	TIME [epoch: 25 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.494258590124353		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.494258590124353 | validation: 1.538642524654136]
	TIME [epoch: 25 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5184312143734315		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 1.5184312143734315 | validation: 1.442471417433022]
	TIME [epoch: 24.9 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6213623744243275		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 1.6213623744243275 | validation: 1.2771252121779058]
	TIME [epoch: 24.9 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7306587684372094		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.7306587684372094 | validation: 2.8420409923560346]
	TIME [epoch: 24.9 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1612512780366564		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 2.1612512780366564 | validation: 1.3748348968402302]
	TIME [epoch: 24.9 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5606512340930514		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.5606512340930514 | validation: 2.0354576700125464]
	TIME [epoch: 24.9 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6259413226252561		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.6259413226252561 | validation: 1.7095954242041629]
	TIME [epoch: 24.9 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6061959310978378		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.6061959310978378 | validation: 1.4122188605133619]
	TIME [epoch: 24.9 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9303050340143237		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.9303050340143237 | validation: 1.7968397500482542]
	TIME [epoch: 24.9 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7429795235838887		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.7429795235838887 | validation: 1.379671321081412]
	TIME [epoch: 25 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3038486928620807		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.3038486928620807 | validation: 1.1488660143724143]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_393.pth
	Model improved!!!
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3296563229999339		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 1.3296563229999339 | validation: 1.5823966276695722]
	TIME [epoch: 24.9 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4090737043091273		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 1.4090737043091273 | validation: 1.134094547639279]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_395.pth
	Model improved!!!
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4348845201664489		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.4348845201664489 | validation: 1.3133361707634985]
	TIME [epoch: 24.9 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.246841584698847		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.246841584698847 | validation: 1.3114907922139971]
	TIME [epoch: 24.9 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3445852647411551		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.3445852647411551 | validation: 1.4942032429994507]
	TIME [epoch: 24.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2402763952195968		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.2402763952195968 | validation: 1.2948076965613244]
	TIME [epoch: 24.9 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4092079459171554		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.4092079459171554 | validation: 1.725607338999966]
	TIME [epoch: 24.9 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3902680241501053		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.3902680241501053 | validation: 1.185817174814055]
	TIME [epoch: 24.9 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3760107435237516		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 1.3760107435237516 | validation: 1.5145752158187389]
	TIME [epoch: 24.9 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4127556346022803		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.4127556346022803 | validation: 1.8878437700592599]
	TIME [epoch: 24.9 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6680501385291149		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.6680501385291149 | validation: 1.2579700596933987]
	TIME [epoch: 24.9 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1581784117915586		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 2.1581784117915586 | validation: 1.209582788254702]
	TIME [epoch: 24.9 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.260261695686382		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 1.260261695686382 | validation: 1.4281310928729398]
	TIME [epoch: 24.9 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3504470647952664		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.3504470647952664 | validation: 2.608814743022431]
	TIME [epoch: 24.9 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4996262659017818		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.4996262659017818 | validation: 1.5412717461484413]
	TIME [epoch: 24.9 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4182104466433807		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.4182104466433807 | validation: 1.0629552657121268]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_409.pth
	Model improved!!!
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0707118719744526		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.0707118719744526 | validation: 1.0262888353418242]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_410.pth
	Model improved!!!
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3911296213100648		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.3911296213100648 | validation: 1.5632460475527155]
	TIME [epoch: 24.9 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9331004635255495		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.9331004635255495 | validation: 1.4280773609129804]
	TIME [epoch: 24.9 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3228131354741746		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.3228131354741746 | validation: 1.6559113970079866]
	TIME [epoch: 24.9 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2494773340112735		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.2494773340112735 | validation: 1.2621157935664573]
	TIME [epoch: 24.9 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2024761566129012		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.2024761566129012 | validation: 0.9603223175942813]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_415.pth
	Model improved!!!
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.034506326783429		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 1.034506326783429 | validation: 1.2692989920608349]
	TIME [epoch: 25 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5509950940511552		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.5509950940511552 | validation: 2.0353691934652316]
	TIME [epoch: 24.9 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6827137668977312		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.6827137668977312 | validation: 1.1430878045487514]
	TIME [epoch: 24.9 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2513330238933034		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.2513330238933034 | validation: 1.2658816305250273]
	TIME [epoch: 24.9 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8408535439401088		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.8408535439401088 | validation: 1.2446891894678336]
	TIME [epoch: 24.9 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3291587624284542		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 1.3291587624284542 | validation: 1.2565990335543669]
	TIME [epoch: 24.9 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7190013558529438		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 1.7190013558529438 | validation: 1.0351092184998714]
	TIME [epoch: 24.9 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6850554150512407		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 1.6850554150512407 | validation: 2.4001424702623204]
	TIME [epoch: 24.9 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.519719686444277		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.519719686444277 | validation: 1.1054129081361066]
	TIME [epoch: 24.9 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4533867277652497		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 1.4533867277652497 | validation: 1.8612611887014043]
	TIME [epoch: 24.9 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4133319735808387		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.4133319735808387 | validation: 1.0993924772921821]
	TIME [epoch: 24.9 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1143235223419647		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 1.1143235223419647 | validation: 0.9916635753110135]
	TIME [epoch: 24.9 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0865861900316602		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 1.0865861900316602 | validation: 1.6586737220919474]
	TIME [epoch: 24.9 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5308174171570494		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 1.5308174171570494 | validation: 1.2705155409730138]
	TIME [epoch: 24.9 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3481378495317051		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.3481378495317051 | validation: 1.6782657027173338]
	TIME [epoch: 24.9 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.022926221497575		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 4.022926221497575 | validation: 4.435702942966272]
	TIME [epoch: 24.9 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.419905896541356		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 4.419905896541356 | validation: 2.2426066536980875]
	TIME [epoch: 24.9 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5699969914782763		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 1.5699969914782763 | validation: 1.1426719048957592]
	TIME [epoch: 24.9 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4188936045612053		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.4188936045612053 | validation: 1.9733612261278421]
	TIME [epoch: 24.9 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.29788506425925		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.29788506425925 | validation: 1.517835813972431]
	TIME [epoch: 24.9 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.244940634586614		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.244940634586614 | validation: 1.062110815416387]
	TIME [epoch: 24.9 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0897537816918792		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.0897537816918792 | validation: 1.8326954163573226]
	TIME [epoch: 24.9 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.387421469526999		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.387421469526999 | validation: 1.336048848271186]
	TIME [epoch: 24.9 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2048498027544667		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.2048498027544667 | validation: 2.498271682192563]
	TIME [epoch: 24.9 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5248254878963383		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.5248254878963383 | validation: 1.0534335714995042]
	TIME [epoch: 24.9 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0347314132532852		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.0347314132532852 | validation: 1.8012217416280032]
	TIME [epoch: 24.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.795393000396767		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 3.795393000396767 | validation: 5.443763659022454]
	TIME [epoch: 24.9 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.771300835180927		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 4.771300835180927 | validation: 5.8960290775049335]
	TIME [epoch: 24.9 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.558998877303539		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 5.558998877303539 | validation: 6.127249818586521]
	TIME [epoch: 24.9 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.388304319014063		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 4.388304319014063 | validation: 1.8431219432162413]
	TIME [epoch: 24.9 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3702754121625829		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.3702754121625829 | validation: 1.290992023574105]
	TIME [epoch: 24.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3520953290588154		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.3520953290588154 | validation: 1.2611073816460552]
	TIME [epoch: 24.9 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2226711833861503		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.2226711833861503 | validation: 1.1618713516740713]
	TIME [epoch: 24.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6591490029288374		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.6591490029288374 | validation: 1.0814324067390648]
	TIME [epoch: 25 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3925548875951315		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.3925548875951315 | validation: 1.177735802165299]
	TIME [epoch: 24.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1933488262046166		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 1.1933488262046166 | validation: 1.263061440813638]
	TIME [epoch: 24.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.240023287016243		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.240023287016243 | validation: 1.1749494540641399]
	TIME [epoch: 24.9 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1205046623135848		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.1205046623135848 | validation: 1.2360359951151363]
	TIME [epoch: 24.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1566674251037936		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.1566674251037936 | validation: 1.1290299987842922]
	TIME [epoch: 24.9 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2832586485521955		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 1.2832586485521955 | validation: 1.6833808773236036]
	TIME [epoch: 24.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2380916596298472		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 1.2380916596298472 | validation: 0.9759610693785643]
	TIME [epoch: 24.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3033827167086782		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 1.3033827167086782 | validation: 1.0937013427739275]
	TIME [epoch: 24.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0956966669958792		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 1.0956966669958792 | validation: 1.2510239984720428]
	TIME [epoch: 24.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9901710350128827		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.9901710350128827 | validation: 1.2440777140238526]
	TIME [epoch: 24.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.20842865725377		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.20842865725377 | validation: 0.8691996554120192]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_460.pth
	Model improved!!!
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9849247540445695		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.9849247540445695 | validation: 1.244007801498819]
	TIME [epoch: 24.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.140513624176911		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 1.140513624176911 | validation: 1.1104639322716432]
	TIME [epoch: 24.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0504515052597911		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 1.0504515052597911 | validation: 0.9349412394474561]
	TIME [epoch: 24.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.376277674491465		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 1.376277674491465 | validation: 0.9997038281974671]
	TIME [epoch: 24.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9777372082291024		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.9777372082291024 | validation: 1.0155176979843434]
	TIME [epoch: 24.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.013165382890269		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 1.013165382890269 | validation: 1.1116942565954788]
	TIME [epoch: 24.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0122213511516622		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 1.0122213511516622 | validation: 1.0982827050901545]
	TIME [epoch: 24.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0252624238515788		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 1.0252624238515788 | validation: 1.0523618048953933]
	TIME [epoch: 24.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13098026696631		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.13098026696631 | validation: 1.0021643349986864]
	TIME [epoch: 24.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0147661024930636		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 1.0147661024930636 | validation: 0.8624406269498845]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_470.pth
	Model improved!!!
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9789625731904437		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.9789625731904437 | validation: 2.1060179410156405]
	TIME [epoch: 24.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5083666201979662		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 1.5083666201979662 | validation: 1.3741770502259418]
	TIME [epoch: 24.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3270680907559018		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 1.3270680907559018 | validation: 1.0551087623425104]
	TIME [epoch: 24.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1466127108967124		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.1466127108967124 | validation: 1.2855078409748801]
	TIME [epoch: 24.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1503265664346638		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 1.1503265664346638 | validation: 0.9803430624366221]
	TIME [epoch: 24.9 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.901303523703057		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.901303523703057 | validation: 1.4798763274727502]
	TIME [epoch: 25 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.592978860332997		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.592978860332997 | validation: 1.3654418983686532]
	TIME [epoch: 24.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2867829592617328		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.2867829592617328 | validation: 1.167525256779656]
	TIME [epoch: 24.9 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0496768752980983		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 1.0496768752980983 | validation: 1.0687354544628134]
	TIME [epoch: 25 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3223020676937178		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 1.3223020676937178 | validation: 0.9444661843202437]
	TIME [epoch: 24.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9677110330422912		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.9677110330422912 | validation: 0.8846848395269608]
	TIME [epoch: 24.9 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8760828601914281		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.8760828601914281 | validation: 0.8512968958764552]
	TIME [epoch: 25 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.249575946727451		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 1.249575946727451 | validation: 1.5514069738572709]
	TIME [epoch: 24.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1113288220258002		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.1113288220258002 | validation: 1.0581598458016952]
	TIME [epoch: 24.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8760358496447628		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.8760358496447628 | validation: 0.8572953889968709]
	TIME [epoch: 24.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.869732768124599		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.869732768124599 | validation: 0.7687564754399384]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_486.pth
	Model improved!!!
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8785020227363718		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.8785020227363718 | validation: 2.349074659025245]
	TIME [epoch: 24.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.453439582538734		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 1.453439582538734 | validation: 0.8353956414807061]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0143673433118712		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 1.0143673433118712 | validation: 1.27149443115004]
	TIME [epoch: 24.9 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1019125185799166		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 1.1019125185799166 | validation: 1.181508737078067]
	TIME [epoch: 24.9 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0265220387391563		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 1.0265220387391563 | validation: 0.7693244054731092]
	TIME [epoch: 24.9 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0316351411978197		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.0316351411978197 | validation: 1.0898608350198027]
	TIME [epoch: 24.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0078975590369816		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 1.0078975590369816 | validation: 0.8204035888621186]
	TIME [epoch: 24.9 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8694700747434221		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.8694700747434221 | validation: 0.8114305813987087]
	TIME [epoch: 24.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0315022342534288		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 1.0315022342534288 | validation: 0.7959355110024814]
	TIME [epoch: 24.9 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8247030151428927		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.8247030151428927 | validation: 0.7850586953808838]
	TIME [epoch: 24.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8478244057346399		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.8478244057346399 | validation: 0.860549016610279]
	TIME [epoch: 24.9 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7962084117924969		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.7962084117924969 | validation: 1.1258065062638467]
	TIME [epoch: 24.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9603085748114146		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.9603085748114146 | validation: 1.0282530714120548]
	TIME [epoch: 24.9 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9752381760252954		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.9752381760252954 | validation: 1.1935106084290221]
	TIME [epoch: 24.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0548144010515847		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 1.0548144010515847 | validation: 1.408748438598522]
	TIME [epoch: 24.9 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6834556384873172		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 1.6834556384873172 | validation: 0.963112010523601]
	TIME [epoch: 24.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.578481200475956		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 1.578481200475956 | validation: 1.0223257433231265]
	TIME [epoch: 24.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9413796296239811		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.9413796296239811 | validation: 1.1934626065675367]
	TIME [epoch: 24.9 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.006009444546077		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 1.006009444546077 | validation: 0.7655030937468976]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_505.pth
	Model improved!!!
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7863542916883075		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.7863542916883075 | validation: 1.5266786044936027]
	TIME [epoch: 24.9 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0683247145151888		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.0683247145151888 | validation: 1.0557513543377832]
	TIME [epoch: 24.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4554288557077768		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 1.4554288557077768 | validation: 2.471196543286809]
	TIME [epoch: 24.9 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2472597346274532		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.2472597346274532 | validation: 0.7373704644478608]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_509.pth
	Model improved!!!
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8687906489557525		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.8687906489557525 | validation: 1.2786920048779318]
	TIME [epoch: 24.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9765254621745473		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.9765254621745473 | validation: 1.7308341491375865]
	TIME [epoch: 24.9 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1272031797093505		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.1272031797093505 | validation: 1.0880268989223063]
	TIME [epoch: 24.9 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7935323027733191		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.7935323027733191 | validation: 0.7241253551530005]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_513.pth
	Model improved!!!
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0688131364477316		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.0688131364477316 | validation: 1.7042967404235765]
	TIME [epoch: 24.9 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4240275913306437		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 1.4240275913306437 | validation: 1.0503212786658707]
	TIME [epoch: 24.9 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9346934381279095		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.9346934381279095 | validation: 1.0726261855477353]
	TIME [epoch: 24.9 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8974041136398019		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.8974041136398019 | validation: 0.8444840143235536]
	TIME [epoch: 24.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7793306668844572		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.7793306668844572 | validation: 1.233470487722922]
	TIME [epoch: 24.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9650460380674207		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.9650460380674207 | validation: 1.9091109575589462]
	TIME [epoch: 24.9 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3266601545152652		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 1.3266601545152652 | validation: 0.9801464762680873]
	TIME [epoch: 24.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8029597236729759		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.8029597236729759 | validation: 0.7214308670498661]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7322546694453658		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.7322546694453658 | validation: 1.0010683775855191]
	TIME [epoch: 24.9 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.936646542023835		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.936646542023835 | validation: 0.952015964029096]
	TIME [epoch: 24.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7833425281838006		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.7833425281838006 | validation: 1.2551599235445488]
	TIME [epoch: 24.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.988193807010612		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.988193807010612 | validation: 0.7382378774226115]
	TIME [epoch: 24.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7886420924919577		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.7886420924919577 | validation: 0.7241114056346496]
	TIME [epoch: 24.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7142507327154091		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.7142507327154091 | validation: 0.8577712473378998]
	TIME [epoch: 24.9 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9801726041179388		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.9801726041179388 | validation: 1.40256433826599]
	TIME [epoch: 24.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8849148778871855		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.8849148778871855 | validation: 0.6979601537819248]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234167857353987		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.7234167857353987 | validation: 0.7695202901135396]
	TIME [epoch: 24.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6941626117922931		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.6941626117922931 | validation: 1.0823199971919417]
	TIME [epoch: 24.9 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0910762589539889		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 1.0910762589539889 | validation: 0.7934550760821735]
	TIME [epoch: 24.9 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8647991375613528		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.8647991375613528 | validation: 0.9182158860424923]
	TIME [epoch: 24.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7304355593509582		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.7304355593509582 | validation: 0.72735300092719]
	TIME [epoch: 24.9 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9694860744796596		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.9694860744796596 | validation: 0.7657393703649288]
	TIME [epoch: 24.9 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8310294449148131		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.8310294449148131 | validation: 1.0186925899388068]
	TIME [epoch: 24.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8046821880554438		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.8046821880554438 | validation: 0.9281601292451543]
	TIME [epoch: 24.9 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7783607106647462		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.7783607106647462 | validation: 0.8186490561030428]
	TIME [epoch: 24.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8366878238163541		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.8366878238163541 | validation: 0.9647420983642454]
	TIME [epoch: 24.9 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8028535968434269		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.8028535968434269 | validation: 1.1593942082291127]
	TIME [epoch: 24.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8752355817252576		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.8752355817252576 | validation: 0.6374736822870232]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_541.pth
	Model improved!!!
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.005750271014683		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 1.005750271014683 | validation: 1.1460340910522324]
	TIME [epoch: 24.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0782569116044143		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 1.0782569116044143 | validation: 1.0445340360274442]
	TIME [epoch: 24.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8202701329140715		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.8202701329140715 | validation: 0.675534806253661]
	TIME [epoch: 24.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.96351674446407		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.96351674446407 | validation: 1.092039346431058]
	TIME [epoch: 24.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8870029524971248		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.8870029524971248 | validation: 1.0913015309797003]
	TIME [epoch: 24.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.940490982590834		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.940490982590834 | validation: 0.8838721307567974]
	TIME [epoch: 24.9 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8605552134571146		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.8605552134571146 | validation: 1.056588713429853]
	TIME [epoch: 24.9 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.406840090309291		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 1.406840090309291 | validation: 0.9465478019353049]
	TIME [epoch: 24.9 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.91707139020946		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.91707139020946 | validation: 1.2066441307674454]
	TIME [epoch: 24.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0015441854816634		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 1.0015441854816634 | validation: 0.6788105495135713]
	TIME [epoch: 24.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8450632114936987		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.8450632114936987 | validation: 0.6440878080320281]
	TIME [epoch: 24.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9866209788765252		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.9866209788765252 | validation: 1.612487509956011]
	TIME [epoch: 24.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3704712260193657		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 1.3704712260193657 | validation: 1.1341383900568853]
	TIME [epoch: 24.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.931053240386318		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.931053240386318 | validation: 0.8676688321649754]
	TIME [epoch: 24.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8902391492913804		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.8902391492913804 | validation: 0.6221487252405716]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9894969404563159		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.9894969404563159 | validation: 0.6369627026512942]
	TIME [epoch: 24.9 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1595733965169202		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 1.1595733965169202 | validation: 1.0969175729002019]
	TIME [epoch: 24.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1339512530437845		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.1339512530437845 | validation: 0.8278707457689173]
	TIME [epoch: 24.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229754357564255		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.7229754357564255 | validation: 0.7061850766833858]
	TIME [epoch: 24.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.739837795144241		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.739837795144241 | validation: 0.8187856935121258]
	TIME [epoch: 24.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7767041432009861		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.7767041432009861 | validation: 0.6401704079060159]
	TIME [epoch: 24.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9142076883820814		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.9142076883820814 | validation: 1.0481139957424825]
	TIME [epoch: 24.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239714213394916		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 1.239714213394916 | validation: 1.9587830478571442]
	TIME [epoch: 24.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0014523592303348		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 1.0014523592303348 | validation: 0.993658363349964]
	TIME [epoch: 24.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7576242903312943		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.7576242903312943 | validation: 0.7019080280722009]
	TIME [epoch: 24.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6742451656802506		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.6742451656802506 | validation: 1.0447384533161788]
	TIME [epoch: 24.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1184410698991722		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 1.1184410698991722 | validation: 1.0776086393370243]
	TIME [epoch: 24.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8430899230006504		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.8430899230006504 | validation: 0.9542084323694914]
	TIME [epoch: 24.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0351917892362505		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.0351917892362505 | validation: 1.1414527553912481]
	TIME [epoch: 24.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8030132357241521		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.8030132357241521 | validation: 0.6474534648400752]
	TIME [epoch: 24.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893042280552006		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.6893042280552006 | validation: 0.6254053653998247]
	TIME [epoch: 24.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0104296067987422		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 1.0104296067987422 | validation: 0.7058436288637432]
	TIME [epoch: 24.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7623411989292451		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.7623411989292451 | validation: 0.7876023033251273]
	TIME [epoch: 24.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7758857517035879		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.7758857517035879 | validation: 1.2046114519622075]
	TIME [epoch: 24.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9854843540610322		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.9854843540610322 | validation: 0.659913211765309]
	TIME [epoch: 24.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7822959510617654		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.7822959510617654 | validation: 0.5608863030600004]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5976713099933566		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5976713099933566 | validation: 0.8103969939111402]
	TIME [epoch: 24.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.729850532473945		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.729850532473945 | validation: 0.741013021609536]
	TIME [epoch: 24.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1015402972361663		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 1.1015402972361663 | validation: 0.9226057830910142]
	TIME [epoch: 24.9 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8911348078600838		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.8911348078600838 | validation: 0.9082833316035576]
	TIME [epoch: 24.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9377510957397501		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.9377510957397501 | validation: 0.8772217598829909]
	TIME [epoch: 24.9 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8820348732253316		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.8820348732253316 | validation: 0.670819520327374]
	TIME [epoch: 24.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9127650269389924		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.9127650269389924 | validation: 1.3351598855334277]
	TIME [epoch: 24.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9551290414604529		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.9551290414604529 | validation: 0.5676361593274344]
	TIME [epoch: 24.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9063877445598372		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.9063877445598372 | validation: 1.274747571425548]
	TIME [epoch: 24.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8396099905012142		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.8396099905012142 | validation: 0.6733756405201186]
	TIME [epoch: 24.9 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8057336397250456		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.8057336397250456 | validation: 1.526908025130267]
	TIME [epoch: 24.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8790183518125756		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.8790183518125756 | validation: 1.6987072322578451]
	TIME [epoch: 24.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3393797282935038		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 1.3393797282935038 | validation: 0.8605917883653235]
	TIME [epoch: 24.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9467216513678988		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.9467216513678988 | validation: 1.1873847769070542]
	TIME [epoch: 24.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8138353324739932		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.8138353324739932 | validation: 0.8904440388373149]
	TIME [epoch: 24.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7908192754505253		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.7908192754505253 | validation: 1.9215761014675012]
	TIME [epoch: 24.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9772184731794864		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.9772184731794864 | validation: 0.8774505544985485]
	TIME [epoch: 24.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7872083000552634		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.7872083000552634 | validation: 0.6849218777503785]
	TIME [epoch: 24.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9013096732070445		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.9013096732070445 | validation: 0.6854661654705881]
	TIME [epoch: 24.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9765200905256395		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.9765200905256395 | validation: 0.7187124597624989]
	TIME [epoch: 24.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.052893128818651		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.052893128818651 | validation: 0.755484056407003]
	TIME [epoch: 24.9 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7052584089963995		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.7052584089963995 | validation: 0.8251018217362556]
	TIME [epoch: 24.9 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7199191752612337		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.7199191752612337 | validation: 0.8671892455065703]
	TIME [epoch: 24.9 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8186520251496492		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.8186520251496492 | validation: 1.1871407392871027]
	TIME [epoch: 24.9 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9371122614079491		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.9371122614079491 | validation: 0.811255908097145]
	TIME [epoch: 24.9 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7830776195636637		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.7830776195636637 | validation: 1.19272152410815]
	TIME [epoch: 24.9 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8248666376086424		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.8248666376086424 | validation: 0.8549154465066968]
	TIME [epoch: 24.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.825213574079108		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.825213574079108 | validation: 0.8431911223586377]
	TIME [epoch: 24.9 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8818633726682934		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.8818633726682934 | validation: 0.7006757873330985]
	TIME [epoch: 24.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8595060810031004		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.8595060810031004 | validation: 0.7669872759831918]
	TIME [epoch: 24.9 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532822552387997		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.7532822552387997 | validation: 0.7482588131899816]
	TIME [epoch: 24.9 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8194320322538824		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.8194320322538824 | validation: 0.7798849579555379]
	TIME [epoch: 24.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8282694270143373		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.8282694270143373 | validation: 2.529743089097904]
	TIME [epoch: 24.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7831576920474221		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 1.7831576920474221 | validation: 0.8178771903019406]
	TIME [epoch: 24.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.710647284534261		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.710647284534261 | validation: 0.7132840816605446]
	TIME [epoch: 24.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694658036934331		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.694658036934331 | validation: 0.885324854103923]
	TIME [epoch: 24.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8842264348456491		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.8842264348456491 | validation: 2.0790383929289495]
	TIME [epoch: 24.9 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0514877412659465		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 1.0514877412659465 | validation: 1.1276829768091656]
	TIME [epoch: 24.9 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.766631397046014		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.766631397046014 | validation: 0.6583274704425771]
	TIME [epoch: 24.9 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.876583297542253		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.876583297542253 | validation: 1.2219379251742235]
	TIME [epoch: 24.9 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8577623198551186		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.8577623198551186 | validation: 0.6460663877339156]
	TIME [epoch: 24.9 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6315231177826567		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.6315231177826567 | validation: 0.8360321890462078]
	TIME [epoch: 24.9 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3658424854421944		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 1.3658424854421944 | validation: 0.6101701525018811]
	TIME [epoch: 24.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.885985779444084		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.885985779444084 | validation: 1.0345736535690886]
	TIME [epoch: 24.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0005412161496203		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 1.0005412161496203 | validation: 0.7868185719116076]
	TIME [epoch: 24.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8489636144003139		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.8489636144003139 | validation: 0.9649778831973774]
	TIME [epoch: 24.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7895557020564431		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.7895557020564431 | validation: 1.9137960429478096]
	TIME [epoch: 24.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0807681693145925		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 1.0807681693145925 | validation: 1.0491302509952898]
	TIME [epoch: 24.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7905197925460519		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.7905197925460519 | validation: 1.8337214129131958]
	TIME [epoch: 24.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6112203089163497		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 2.6112203089163497 | validation: 0.8241935274679556]
	TIME [epoch: 24.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6948064049427812		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.6948064049427812 | validation: 0.6098421120021318]
	TIME [epoch: 24.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7752857006311467		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.7752857006311467 | validation: 0.8802175667409552]
	TIME [epoch: 24.9 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6626128646322149		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.6626128646322149 | validation: 0.738671105700937]
	TIME [epoch: 24.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7273835034162094		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.7273835034162094 | validation: 1.6417794681512994]
	TIME [epoch: 24.9 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.148341698719679		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 2.148341698719679 | validation: 2.2016265209131056]
	TIME [epoch: 24.9 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9490118221900437		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.9490118221900437 | validation: 1.5352219134844922]
	TIME [epoch: 24.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1006030911661913		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 1.1006030911661913 | validation: 0.5799119551198999]
	TIME [epoch: 24.9 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6261212472361937		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.6261212472361937 | validation: 0.7190268509275677]
	TIME [epoch: 24.9 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6507576468978515		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.6507576468978515 | validation: 0.6670734605299822]
	TIME [epoch: 24.9 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7243065369548882		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.7243065369548882 | validation: 1.0300253995730821]
	TIME [epoch: 24.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8652298385808025		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.8652298385808025 | validation: 0.8832224924679264]
	TIME [epoch: 24.9 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.55963237797936		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 1.55963237797936 | validation: 1.615525285075147]
	TIME [epoch: 24.9 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0225387092108131		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 1.0225387092108131 | validation: 0.7227821248472407]
	TIME [epoch: 24.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8142806262369193		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.8142806262369193 | validation: 0.73061383693257]
	TIME [epoch: 24.9 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9211677729947999		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.9211677729947999 | validation: 0.8946269238625243]
	TIME [epoch: 24.9 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.786977314019811		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.786977314019811 | validation: 0.9670404167513897]
	TIME [epoch: 24.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.104011557619671		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 1.104011557619671 | validation: 0.8020443393737567]
	TIME [epoch: 24.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.77689306006361		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.77689306006361 | validation: 0.8869593448848215]
	TIME [epoch: 24.9 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7585125556245622		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.7585125556245622 | validation: 0.6909473192864696]
	TIME [epoch: 24.9 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980931664383787		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.6980931664383787 | validation: 0.9120214731682732]
	TIME [epoch: 24.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7738480748634546		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.7738480748634546 | validation: 0.8427396525426919]
	TIME [epoch: 24.9 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8273088583078643		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.8273088583078643 | validation: 1.101952945267764]
	TIME [epoch: 24.9 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.752446979011375		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.752446979011375 | validation: 0.6725919021163435]
	TIME [epoch: 24.9 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7913409561539315		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.7913409561539315 | validation: 0.5689827603783069]
	TIME [epoch: 24.9 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8021945098388095		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.8021945098388095 | validation: 0.8961737658984044]
	TIME [epoch: 24.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8689624647581402		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.8689624647581402 | validation: 0.7425411723362401]
	TIME [epoch: 24.9 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7644961173462693		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.7644961173462693 | validation: 0.6866010064986224]
	TIME [epoch: 24.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8046208480031717		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.8046208480031717 | validation: 0.7230021052755632]
	TIME [epoch: 24.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.743307849575073		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.743307849575073 | validation: 0.8482727405650359]
	TIME [epoch: 24.9 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6468146029243989		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.6468146029243989 | validation: 0.5540458837543011]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_657.pth
	Model improved!!!
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6873742568445426		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.6873742568445426 | validation: 0.6228168809390247]
	TIME [epoch: 24.9 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6125307921567036		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.6125307921567036 | validation: 1.6535415582032533]
	TIME [epoch: 24.9 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.993050371293734		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.993050371293734 | validation: 0.9764820820487597]
	TIME [epoch: 24.9 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7441189791587739		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.7441189791587739 | validation: 0.7386334933058367]
	TIME [epoch: 24.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7901774795043071		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.7901774795043071 | validation: 0.6752634110027665]
	TIME [epoch: 24.9 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979205624009821		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.6979205624009821 | validation: 0.7807282040008124]
	TIME [epoch: 24.9 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7046913953265056		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.7046913953265056 | validation: 0.8248948622560947]
	TIME [epoch: 24.9 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0812994399065479		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 1.0812994399065479 | validation: 0.5923245536828039]
	TIME [epoch: 24.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5934115555899901		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.5934115555899901 | validation: 0.7503493266604824]
	TIME [epoch: 24.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.977514756425761		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.977514756425761 | validation: 1.760134569347945]
	TIME [epoch: 24.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8727717321091578		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.8727717321091578 | validation: 1.4108120797226886]
	TIME [epoch: 24.9 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.014290373821466		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 1.014290373821466 | validation: 0.6618419194534017]
	TIME [epoch: 24.9 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6122879881973586		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.6122879881973586 | validation: 1.1917988006486249]
	TIME [epoch: 24.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4923271013266584		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 1.4923271013266584 | validation: 1.339851505847969]
	TIME [epoch: 24.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9614745118673739		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.9614745118673739 | validation: 1.2488835666989493]
	TIME [epoch: 24.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7658251240480874		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.7658251240480874 | validation: 0.5633141734559399]
	TIME [epoch: 24.9 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.601130995175388		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.601130995175388 | validation: 0.5694791869258635]
	TIME [epoch: 24.9 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5576233578106454		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.5576233578106454 | validation: 0.5467315533503329]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_675.pth
	Model improved!!!
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.602646067848943		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.602646067848943 | validation: 0.6595062365615758]
	TIME [epoch: 24.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6927328192798289		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.6927328192798289 | validation: 0.9793246103050771]
	TIME [epoch: 24.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7438996438810073		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.7438996438810073 | validation: 0.6191326160948114]
	TIME [epoch: 24.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6835849880127649		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.6835849880127649 | validation: 0.7024897015632218]
	TIME [epoch: 24.9 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8514291603010808		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.8514291603010808 | validation: 0.9106944352635997]
	TIME [epoch: 24.9 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8601386201148729		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.8601386201148729 | validation: 0.8561743463955921]
	TIME [epoch: 24.9 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684015412212246		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.684015412212246 | validation: 0.565825983383319]
	TIME [epoch: 24.9 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6304559485696887		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.6304559485696887 | validation: 0.9599181731026548]
	TIME [epoch: 24.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6606066211870125		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.6606066211870125 | validation: 0.6555597595464095]
	TIME [epoch: 24.9 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7733369391570764		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.7733369391570764 | validation: 2.6576080855798443]
	TIME [epoch: 24.9 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4484925118716392		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 1.4484925118716392 | validation: 0.5655994831820198]
	TIME [epoch: 24.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.837339164027046		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.837339164027046 | validation: 0.7501078558377015]
	TIME [epoch: 24.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6897388031553543		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.6897388031553543 | validation: 0.5785519527411268]
	TIME [epoch: 24.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6063077427709063		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.6063077427709063 | validation: 0.6884037959902325]
	TIME [epoch: 24.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6778907684050401		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.6778907684050401 | validation: 0.6605739097836505]
	TIME [epoch: 24.9 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3768685404854317		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 1.3768685404854317 | validation: 2.0971553947406547]
	TIME [epoch: 24.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9632253485841106		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.9632253485841106 | validation: 0.5892628626523951]
	TIME [epoch: 24.9 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6953883085849049		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.6953883085849049 | validation: 0.8961231141799973]
	TIME [epoch: 24.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9409481709261434		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.9409481709261434 | validation: 0.546778377100201]
	TIME [epoch: 24.9 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8307586583437332		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.8307586583437332 | validation: 1.230484022892262]
	TIME [epoch: 24.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8226806094992183		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.8226806094992183 | validation: 0.7214803884661134]
	TIME [epoch: 24.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7785588408506829		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.7785588408506829 | validation: 0.8745237081868842]
	TIME [epoch: 24.9 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7553476821099289		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.7553476821099289 | validation: 0.6509877258086306]
	TIME [epoch: 24.9 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6684326384227373		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.6684326384227373 | validation: 0.7226074465451154]
	TIME [epoch: 24.9 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7385153176389685		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.7385153176389685 | validation: 1.5588388039424923]
	TIME [epoch: 24.9 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.027522719845866		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 2.027522719845866 | validation: 0.8046636421375343]
	TIME [epoch: 24.9 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980067282953444		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.6980067282953444 | validation: 0.7632477848286077]
	TIME [epoch: 24.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7805113026494839		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.7805113026494839 | validation: 1.2333637991989723]
	TIME [epoch: 24.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7770042063982955		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.7770042063982955 | validation: 0.6711192896404079]
	TIME [epoch: 24.9 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267387950297555		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.6267387950297555 | validation: 0.6211275169462817]
	TIME [epoch: 24.9 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.674149543011685		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.674149543011685 | validation: 0.543166070089073]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_706.pth
	Model improved!!!
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5711525197400424		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.5711525197400424 | validation: 0.5057542164485264]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.834709155954539		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.834709155954539 | validation: 0.5855890558355628]
	TIME [epoch: 24.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6392295619103137		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.6392295619103137 | validation: 0.7910685896180025]
	TIME [epoch: 24.9 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5847590091854348		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5847590091854348 | validation: 0.5375759639016969]
	TIME [epoch: 24.9 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6074452155870064		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.6074452155870064 | validation: 0.696661110315391]
	TIME [epoch: 24.9 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6262615431131844		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.6262615431131844 | validation: 0.65527685000538]
	TIME [epoch: 24.9 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7564361054906086		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.7564361054906086 | validation: 0.6443803096519638]
	TIME [epoch: 24.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6646750196433009		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.6646750196433009 | validation: 1.184999178826156]
	TIME [epoch: 24.9 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8302574615757016		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.8302574615757016 | validation: 0.7944770023323534]
	TIME [epoch: 24.9 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.081997101722913		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 1.081997101722913 | validation: 0.532990787196282]
	TIME [epoch: 24.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5613037827894348		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.5613037827894348 | validation: 0.5939475933734485]
	TIME [epoch: 24.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6159805307570664		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.6159805307570664 | validation: 0.7272093870494664]
	TIME [epoch: 24.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8672915560261154		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.8672915560261154 | validation: 0.5826057535733709]
	TIME [epoch: 24.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6495894756322761		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.6495894756322761 | validation: 0.5360118781014487]
	TIME [epoch: 24.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6449746788682308		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.6449746788682308 | validation: 0.5629589315951116]
	TIME [epoch: 24.9 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9447569829108956		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.9447569829108956 | validation: 0.7520565506807293]
	TIME [epoch: 24.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7253322113342011		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.7253322113342011 | validation: 0.8515128874121899]
	TIME [epoch: 24.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968515730268722		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.6968515730268722 | validation: 0.5612017268162595]
	TIME [epoch: 24.9 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6304443386132815		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.6304443386132815 | validation: 0.49477378497740554]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.792554637569349		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.792554637569349 | validation: 0.5952566674560678]
	TIME [epoch: 24.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5655643191694324		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.5655643191694324 | validation: 0.46395901490865343]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_727.pth
	Model improved!!!
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5831937097155475		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.5831937097155475 | validation: 0.5657960606295386]
	TIME [epoch: 24.9 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6462145317703589		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.6462145317703589 | validation: 0.5242462687555252]
	TIME [epoch: 24.9 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5823491971118356		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.5823491971118356 | validation: 0.4830412990588651]
	TIME [epoch: 24.9 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5359463927548567		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.5359463927548567 | validation: 0.4813198604753366]
	TIME [epoch: 24.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5756986021714404		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.5756986021714404 | validation: 0.5444849976706138]
	TIME [epoch: 24.9 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5892608421515234		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.5892608421515234 | validation: 0.5420800306841954]
	TIME [epoch: 24.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8002128201817581		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.8002128201817581 | validation: 0.6646081465902606]
	TIME [epoch: 24.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7853551281142195		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.7853551281142195 | validation: 0.6444397701272601]
	TIME [epoch: 24.9 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6378947948551164		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.6378947948551164 | validation: 1.06784378529782]
	TIME [epoch: 24.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1657485003428667		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 1.1657485003428667 | validation: 2.2065359102337054]
	TIME [epoch: 24.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2881751157791412		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 1.2881751157791412 | validation: 0.5352974074157308]
	TIME [epoch: 24.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6555835064075054		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.6555835064075054 | validation: 0.5924598414756189]
	TIME [epoch: 24.9 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6151247740018142		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.6151247740018142 | validation: 0.6192790340915555]
	TIME [epoch: 24.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9347157652870233		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.9347157652870233 | validation: 1.3415339067427305]
	TIME [epoch: 24.9 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8138619118138931		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.8138619118138931 | validation: 0.9299380129902949]
	TIME [epoch: 24.9 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7768794177244782		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.7768794177244782 | validation: 1.356461419168837]
	TIME [epoch: 24.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4871267152697496		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 1.4871267152697496 | validation: 0.65027073986664]
	TIME [epoch: 24.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.763828466819399		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.763828466819399 | validation: 0.6658740766888153]
	TIME [epoch: 24.9 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6099703654351347		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.6099703654351347 | validation: 0.7367305514172253]
	TIME [epoch: 24.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6044335380176309		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.6044335380176309 | validation: 0.625486721396482]
	TIME [epoch: 24.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5401338617374115		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.5401338617374115 | validation: 0.6895006458694337]
	TIME [epoch: 24.9 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5837243992145791		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.5837243992145791 | validation: 0.6307699855251065]
	TIME [epoch: 24.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8240604934070865		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.8240604934070865 | validation: 0.7203030094217641]
	TIME [epoch: 24.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5685195106213943		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.5685195106213943 | validation: 0.5931597268645185]
	TIME [epoch: 24.9 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5482077271399746		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.5482077271399746 | validation: 0.5482010338418521]
	TIME [epoch: 24.9 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615241797598979		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.615241797598979 | validation: 0.8114948164293284]
	TIME [epoch: 24.9 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6733661048100392		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.6733661048100392 | validation: 0.6962376450272945]
	TIME [epoch: 24.9 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6392795911580692		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.6392795911580692 | validation: 0.5962218790801727]
	TIME [epoch: 24.9 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5605472268649447		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.5605472268649447 | validation: 0.5025129312711428]
	TIME [epoch: 24.9 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5667516147698668		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.5667516147698668 | validation: 0.9122742898886443]
	TIME [epoch: 24.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6520358005011722		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.6520358005011722 | validation: 0.9378951976227293]
	TIME [epoch: 24.9 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7318252859348527		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.7318252859348527 | validation: 0.6106484389203524]
	TIME [epoch: 24.9 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.545359307687751		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.545359307687751 | validation: 0.6573676848230735]
	TIME [epoch: 24.9 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5805672625082501		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.5805672625082501 | validation: 0.5185931294772553]
	TIME [epoch: 24.9 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49067945825204373		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.49067945825204373 | validation: 0.5479637862655172]
	TIME [epoch: 24.9 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6147740891123759		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.6147740891123759 | validation: 0.6030128438873646]
	TIME [epoch: 24.9 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6146944779264956		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.6146944779264956 | validation: 0.5028996748549998]
	TIME [epoch: 24.9 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5056860491155961		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.5056860491155961 | validation: 0.7666261239337012]
	TIME [epoch: 24.9 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5689310825103674		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.5689310825103674 | validation: 0.796151423619993]
	TIME [epoch: 24.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8320455439677119		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.8320455439677119 | validation: 0.5479274604941867]
	TIME [epoch: 24.9 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5001981587471642		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.5001981587471642 | validation: 0.5156288695708642]
	TIME [epoch: 24.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6443869275384446		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.6443869275384446 | validation: 0.6290102345223013]
	TIME [epoch: 24.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7642030846045137		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.7642030846045137 | validation: 0.7436509537998207]
	TIME [epoch: 24.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6128388294353843		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.6128388294353843 | validation: 0.6421491186160787]
	TIME [epoch: 24.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5693102954319499		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.5693102954319499 | validation: 0.5806544922504955]
	TIME [epoch: 24.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5391386811947738		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.5391386811947738 | validation: 0.6682845731630205]
	TIME [epoch: 24.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5738731002942956		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.5738731002942956 | validation: 0.5215643874724277]
	TIME [epoch: 24.9 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6393800355329373		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.6393800355329373 | validation: 0.5278903028960094]
	TIME [epoch: 24.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6973578196772932		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.6973578196772932 | validation: 1.021647782936398]
	TIME [epoch: 24.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8068598914795395		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.8068598914795395 | validation: 0.5910341971915338]
	TIME [epoch: 24.9 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5826525608230648		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.5826525608230648 | validation: 0.566003119811813]
	TIME [epoch: 24.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5183209483559217		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.5183209483559217 | validation: 0.49905843797146243]
	TIME [epoch: 24.9 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5708532703043043		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.5708532703043043 | validation: 0.6438174560040202]
	TIME [epoch: 24.9 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5608882252997798		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.5608882252997798 | validation: 0.5513717721122956]
	TIME [epoch: 24.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5315856783897074		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.5315856783897074 | validation: 0.59660533366576]
	TIME [epoch: 24.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893927051312424		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.5893927051312424 | validation: 0.5718312225298741]
	TIME [epoch: 24.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5257397373005133		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.5257397373005133 | validation: 0.8968697869950295]
	TIME [epoch: 24.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7043289146891833		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.7043289146891833 | validation: 0.568240757532289]
	TIME [epoch: 24.9 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893369461801085		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.5893369461801085 | validation: 0.5967717446182992]
	TIME [epoch: 24.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5559009062588038		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.5559009062588038 | validation: 0.5061004835113032]
	TIME [epoch: 24.9 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5842998693833366		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.5842998693833366 | validation: 0.8332365522202335]
	TIME [epoch: 24.9 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1648854832372026		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 1.1648854832372026 | validation: 2.3708024829249004]
	TIME [epoch: 24.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2813631954647497		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 1.2813631954647497 | validation: 0.5273349267287872]
	TIME [epoch: 24.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6163918929758089		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.6163918929758089 | validation: 0.5403467067727137]
	TIME [epoch: 24.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6108450963098966		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.6108450963098966 | validation: 0.7655088639586122]
	TIME [epoch: 24.9 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6488330162146327		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.6488330162146327 | validation: 0.5802893013249716]
	TIME [epoch: 24.9 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5315101378162934		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.5315101378162934 | validation: 0.6534673833105117]
	TIME [epoch: 24.9 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6736384531249305		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.6736384531249305 | validation: 0.7212675495174997]
	TIME [epoch: 24.9 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7613487838421126		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.7613487838421126 | validation: 0.6898732248458742]
	TIME [epoch: 24.9 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5763584865734994		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.5763584865734994 | validation: 0.5348432608472815]
	TIME [epoch: 24.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49539549620118717		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.49539549620118717 | validation: 0.5063117138752559]
	TIME [epoch: 24.9 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6055687405859607		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.6055687405859607 | validation: 0.6465509654238887]
	TIME [epoch: 24.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6280016377612696		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.6280016377612696 | validation: 1.0841689314555094]
	TIME [epoch: 24.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6998071677827784		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.6998071677827784 | validation: 0.5058798532262698]
	TIME [epoch: 24.9 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6352811627076168		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.6352811627076168 | validation: 0.7447124832038616]
	TIME [epoch: 24.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.716136775429314		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.716136775429314 | validation: 0.5419097629108685]
	TIME [epoch: 24.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499193696028812		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.5499193696028812 | validation: 0.5764925055686656]
	TIME [epoch: 24.9 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5259995845525185		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.5259995845525185 | validation: 0.6872060256478383]
	TIME [epoch: 24.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6492573620601281		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.6492573620601281 | validation: 0.48729932236237916]
	TIME [epoch: 24.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5139836478706511		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.5139836478706511 | validation: 1.1018647195445173]
	TIME [epoch: 24.9 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7912612575957223		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.7912612575957223 | validation: 0.6842213967683294]
	TIME [epoch: 24.9 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5778192555836121		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.5778192555836121 | validation: 0.5456327734948889]
	TIME [epoch: 24.9 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6600068321145329		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.6600068321145329 | validation: 1.1130196616774541]
	TIME [epoch: 24.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8241025720846464		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.8241025720846464 | validation: 0.546608597149913]
	TIME [epoch: 24.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6875153604750142		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.6875153604750142 | validation: 0.6551097066134821]
	TIME [epoch: 24.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6204440328304222		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.6204440328304222 | validation: 1.50647893055456]
	TIME [epoch: 24.9 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.50106120099559		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 1.50106120099559 | validation: 1.593612102838049]
	TIME [epoch: 24.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9681456594021283		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.9681456594021283 | validation: 0.5515238460452173]
	TIME [epoch: 24.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5054090264894223		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.5054090264894223 | validation: 0.6876767554883328]
	TIME [epoch: 24.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5556704046518708		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.5556704046518708 | validation: 0.513767407451642]
	TIME [epoch: 24.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4945880241409705		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4945880241409705 | validation: 0.4888468251339325]
	TIME [epoch: 24.9 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6091437535434026		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.6091437535434026 | validation: 0.7155147513602879]
	TIME [epoch: 24.9 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5409027341741892		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.5409027341741892 | validation: 0.5811046399113035]
	TIME [epoch: 24.9 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5262947310985426		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.5262947310985426 | validation: 0.5626756179060936]
	TIME [epoch: 24.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6351866017695776		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.6351866017695776 | validation: 0.6441386706864219]
	TIME [epoch: 24.9 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5702058083336644		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.5702058083336644 | validation: 0.548730425960094]
	TIME [epoch: 24.9 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.534027701316159		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.534027701316159 | validation: 0.48460672991873494]
	TIME [epoch: 24.9 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4968219782125811		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.4968219782125811 | validation: 0.6228715161257738]
	TIME [epoch: 24.9 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5110577155316558		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.5110577155316558 | validation: 0.4752134747730514]
	TIME [epoch: 24.9 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077105303221991		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.5077105303221991 | validation: 0.580692050633244]
	TIME [epoch: 24.9 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7828240351465309		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.7828240351465309 | validation: 0.6592761390478282]
	TIME [epoch: 24.9 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5109685895644595		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.5109685895644595 | validation: 0.5012195563282836]
	TIME [epoch: 24.9 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5068708379205552		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.5068708379205552 | validation: 0.654838839459929]
	TIME [epoch: 24.9 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6327122833762044		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.6327122833762044 | validation: 0.45623957210567784]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_831.pth
	Model improved!!!
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5366516500406143		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.5366516500406143 | validation: 0.5652474156892922]
	TIME [epoch: 24.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5116436545968283		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.5116436545968283 | validation: 0.5059357802084348]
	TIME [epoch: 24.9 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4852941691885602		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.4852941691885602 | validation: 0.5958986866318209]
	TIME [epoch: 24.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5387545941128472		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.5387545941128472 | validation: 0.6739863546877318]
	TIME [epoch: 24.9 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5306373079665655		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.5306373079665655 | validation: 0.6301379633712932]
	TIME [epoch: 24.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6392703776134486		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.6392703776134486 | validation: 0.4977680385466]
	TIME [epoch: 24.9 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082429360279992		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.5082429360279992 | validation: 0.46628105942261633]
	TIME [epoch: 24.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4921766275539776		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.4921766275539776 | validation: 0.7151435959528215]
	TIME [epoch: 24.9 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6025269998378122		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.6025269998378122 | validation: 0.47168145776300163]
	TIME [epoch: 24.9 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6572900735534503		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.6572900735534503 | validation: 1.0012861843751464]
	TIME [epoch: 24.9 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4760724987499896		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 1.4760724987499896 | validation: 1.5021976910443247]
	TIME [epoch: 24.9 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8323371120508849		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.8323371120508849 | validation: 0.49420386288224905]
	TIME [epoch: 24.9 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5355559962196319		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.5355559962196319 | validation: 0.5579794556567641]
	TIME [epoch: 24.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6482981840502607		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.6482981840502607 | validation: 1.4743492287295288]
	TIME [epoch: 24.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0079994156943388		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 1.0079994156943388 | validation: 0.6442809439073125]
	TIME [epoch: 24.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6044950508101998		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.6044950508101998 | validation: 0.5598101307791861]
	TIME [epoch: 24.9 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5554897119701176		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.5554897119701176 | validation: 0.5967977036908116]
	TIME [epoch: 24.9 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5627785984986596		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.5627785984986596 | validation: 0.5085197556886472]
	TIME [epoch: 24.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5171049157419825		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.5171049157419825 | validation: 0.7661822762934684]
	TIME [epoch: 24.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5678569118066488		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.5678569118066488 | validation: 0.4922125694917468]
	TIME [epoch: 24.9 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4703732276292354		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.4703732276292354 | validation: 0.5667682569629074]
	TIME [epoch: 24.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5303368843365528		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.5303368843365528 | validation: 0.5266538494642309]
	TIME [epoch: 24.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5565436433242468		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.5565436433242468 | validation: 0.7989025544617713]
	TIME [epoch: 24.9 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6017078295730616		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.6017078295730616 | validation: 0.5108238751863652]
	TIME [epoch: 24.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224113050873858		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.5224113050873858 | validation: 0.5813626682039582]
	TIME [epoch: 24.9 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5093933470368734		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.5093933470368734 | validation: 0.58896643243389]
	TIME [epoch: 24.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5651502950787317		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.5651502950787317 | validation: 0.7145495406478375]
	TIME [epoch: 24.9 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5914094194781105		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.5914094194781105 | validation: 0.5170506369668056]
	TIME [epoch: 24.9 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5059448019903665		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.5059448019903665 | validation: 0.5066486088200418]
	TIME [epoch: 24.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236404690291765		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.5236404690291765 | validation: 0.5027193830067946]
	TIME [epoch: 24.9 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5164654996282365		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.5164654996282365 | validation: 0.5535250837159521]
	TIME [epoch: 24.9 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5965276148364672		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.5965276148364672 | validation: 1.2355385273498465]
	TIME [epoch: 24.9 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8212125083655296		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.8212125083655296 | validation: 0.5431590822854386]
	TIME [epoch: 24.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5674254881330318		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.5674254881330318 | validation: 0.6704524921670675]
	TIME [epoch: 24.9 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5470727957537184		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.5470727957537184 | validation: 0.5856992977302401]
	TIME [epoch: 24.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6480575144727085		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.6480575144727085 | validation: 0.765904511894596]
	TIME [epoch: 24.9 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5875180867871111		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.5875180867871111 | validation: 0.4947315014927986]
	TIME [epoch: 24.9 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5731808003627876		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.5731808003627876 | validation: 0.5603760497798348]
	TIME [epoch: 24.9 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6026002440836452		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.6026002440836452 | validation: 0.9956474790820644]
	TIME [epoch: 24.9 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7597250128309974		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.7597250128309974 | validation: 0.5362041380086334]
	TIME [epoch: 24.9 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5267143569916469		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.5267143569916469 | validation: 0.5209445976706567]
	TIME [epoch: 24.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5299068604165348		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.5299068604165348 | validation: 0.7140527301321729]
	TIME [epoch: 24.9 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5517000449839241		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.5517000449839241 | validation: 0.6095473464151221]
	TIME [epoch: 24.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5698852775472478		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.5698852775472478 | validation: 0.6720254763973579]
	TIME [epoch: 24.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5462723496673254		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.5462723496673254 | validation: 0.6510557814842973]
	TIME [epoch: 24.9 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.548064189804165		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.548064189804165 | validation: 0.5539641565040008]
	TIME [epoch: 24.9 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5732347193925766		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.5732347193925766 | validation: 0.5288278451983056]
	TIME [epoch: 24.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5056746659224036		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.5056746659224036 | validation: 0.5295081773322456]
	TIME [epoch: 24.9 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5717321426402715		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.5717321426402715 | validation: 0.6241519087083541]
	TIME [epoch: 24.9 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5680740083868131		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.5680740083868131 | validation: 0.4702672897266787]
	TIME [epoch: 24.9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.575183581320396		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.575183581320396 | validation: 1.2845107601115775]
	TIME [epoch: 24.9 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8591050633297359		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.8591050633297359 | validation: 0.5443401404371945]
	TIME [epoch: 24.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5876475896482929		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.5876475896482929 | validation: 0.6808473347664766]
	TIME [epoch: 24.9 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5548570973924788		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.5548570973924788 | validation: 0.5334775524410017]
	TIME [epoch: 24.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48301431084403557		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.48301431084403557 | validation: 0.7280672722219296]
	TIME [epoch: 24.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8891880658243918		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.8891880658243918 | validation: 1.054169106108646]
	TIME [epoch: 24.9 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8848231913260746		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.8848231913260746 | validation: 0.8517841430145418]
	TIME [epoch: 24.9 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8298439001145856		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.8298439001145856 | validation: 0.9121525033515604]
	TIME [epoch: 24.9 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6438955924098412		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.6438955924098412 | validation: 0.5609122377572677]
	TIME [epoch: 24.9 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.578455639825993		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.578455639825993 | validation: 0.5216939827988283]
	TIME [epoch: 24.9 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.597188801468109		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.597188801468109 | validation: 0.8005226013111826]
	TIME [epoch: 24.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.675182685719854		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.675182685719854 | validation: 0.5861325469283903]
	TIME [epoch: 24.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5091566835719218		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.5091566835719218 | validation: 0.52583868218397]
	TIME [epoch: 24.9 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46420781942457906		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.46420781942457906 | validation: 0.46956425214731623]
	TIME [epoch: 24.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4554577920706421		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.4554577920706421 | validation: 0.5029716674094437]
	TIME [epoch: 24.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4481070016999163		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.4481070016999163 | validation: 0.593322716705874]
	TIME [epoch: 24.9 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6422174810608179		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.6422174810608179 | validation: 0.6325179136181637]
	TIME [epoch: 24.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5458335912859358		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.5458335912859358 | validation: 0.5241420479595561]
	TIME [epoch: 24.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4761413509042751		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.4761413509042751 | validation: 0.47064477542957334]
	TIME [epoch: 24.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4717664375565519		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.4717664375565519 | validation: 0.4611702076896076]
	TIME [epoch: 24.9 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49235080457225333		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.49235080457225333 | validation: 0.8333099190093743]
	TIME [epoch: 24.9 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5929747669464135		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.5929747669464135 | validation: 0.6483307175163244]
	TIME [epoch: 24.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.786602524909155		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.786602524909155 | validation: 0.684337995886003]
	TIME [epoch: 24.9 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5296318225862583		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.5296318225862583 | validation: 1.0461565048342791]
	TIME [epoch: 24.9 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7938754647685026		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.7938754647685026 | validation: 0.5179757611655507]
	TIME [epoch: 24.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4666489290365026		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.4666489290365026 | validation: 0.495217516286452]
	TIME [epoch: 24.9 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4648198666200076		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.4648198666200076 | validation: 0.5424864115644026]
	TIME [epoch: 24.9 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5191226069702488		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.5191226069702488 | validation: 0.9599836262529075]
	TIME [epoch: 24.9 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6647096799337521		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.6647096799337521 | validation: 0.5523870749394363]
	TIME [epoch: 24.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5984502442043271		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.5984502442043271 | validation: 0.5380383660617198]
	TIME [epoch: 24.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4765343747189101		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.4765343747189101 | validation: 0.497292991931122]
	TIME [epoch: 24.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5651223757822146		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.5651223757822146 | validation: 0.5863026622644613]
	TIME [epoch: 24.9 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5345055642386902		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.5345055642386902 | validation: 0.4929029909723521]
	TIME [epoch: 24.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4744446161462298		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.4744446161462298 | validation: 0.5426109901641023]
	TIME [epoch: 24.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5103530521996139		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.5103530521996139 | validation: 0.7600238071195174]
	TIME [epoch: 24.9 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5897498732666595		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.5897498732666595 | validation: 0.5560998008453433]
	TIME [epoch: 24.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7617825959151199		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.7617825959151199 | validation: 0.6822673909320693]
	TIME [epoch: 24.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5329051433621279		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.5329051433621279 | validation: 0.5458497285354812]
	TIME [epoch: 24.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6744105724871197		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.6744105724871197 | validation: 0.876865103197971]
	TIME [epoch: 24.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7116318145340117		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.7116318145340117 | validation: 0.5764778475841535]
	TIME [epoch: 24.9 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.460035409810806		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.460035409810806 | validation: 0.5335147018418064]
	TIME [epoch: 24.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4733377004999802		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.4733377004999802 | validation: 0.4722062363975813]
	TIME [epoch: 24.9 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43779863796958457		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.43779863796958457 | validation: 0.4589262927955748]
	TIME [epoch: 24.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4563025877383293		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.4563025877383293 | validation: 0.457360893245489]
	TIME [epoch: 24.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4657976314251143		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.4657976314251143 | validation: 0.5075515210828764]
	TIME [epoch: 24.9 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4677454011528656		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.4677454011528656 | validation: 0.6699924759387696]
	TIME [epoch: 24.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5894377224614813		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.5894377224614813 | validation: 0.5677519620541074]
	TIME [epoch: 24.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5719851441346713		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.5719851441346713 | validation: 0.587624667136617]
	TIME [epoch: 24.9 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6237266052907664		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.6237266052907664 | validation: 0.5667561436861561]
	TIME [epoch: 24.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5569059317620422		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.5569059317620422 | validation: 0.5652640115853227]
	TIME [epoch: 24.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5642775381795851		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.5642775381795851 | validation: 0.5733893298405943]
	TIME [epoch: 24.9 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5553883433804443		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.5553883433804443 | validation: 0.5154491475007624]
	TIME [epoch: 24.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5554742339539124		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.5554742339539124 | validation: 0.5120213790747252]
	TIME [epoch: 24.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5333737116559101		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.5333737116559101 | validation: 0.527836752525102]
	TIME [epoch: 24.9 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48352410002646623		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.48352410002646623 | validation: 0.4737293380768506]
	TIME [epoch: 24.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4906659555770788		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.4906659555770788 | validation: 0.6665805764248366]
	TIME [epoch: 24.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5878854897732475		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.5878854897732475 | validation: 0.6005612118118012]
	TIME [epoch: 24.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5190482972374847		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.5190482972374847 | validation: 0.5296425216069423]
	TIME [epoch: 24.9 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.527264976367066		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.527264976367066 | validation: 0.504768220451867]
	TIME [epoch: 24.9 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4571260292271253		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.4571260292271253 | validation: 0.4858694166302533]
	TIME [epoch: 24.9 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45463989347428674		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.45463989347428674 | validation: 0.491220196895988]
	TIME [epoch: 24.9 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4529583884053009		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.4529583884053009 | validation: 0.4194152975608414]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_943.pth
	Model improved!!!
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44590617966354495		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.44590617966354495 | validation: 0.42686223256150146]
	TIME [epoch: 24.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4383078731828326		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.4383078731828326 | validation: 0.4728127070927557]
	TIME [epoch: 24.9 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4766037412795456		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.4766037412795456 | validation: 0.4494450713279224]
	TIME [epoch: 24.9 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47574959612160495		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.47574959612160495 | validation: 0.4404697727347206]
	TIME [epoch: 24.9 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4417386900175612		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.4417386900175612 | validation: 0.4602983812327818]
	TIME [epoch: 24.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45987141491768746		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.45987141491768746 | validation: 0.43946694251337326]
	TIME [epoch: 24.9 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326348019432442		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.4326348019432442 | validation: 0.4510049837580667]
	TIME [epoch: 24.9 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4489114424959409		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.4489114424959409 | validation: 0.4495907565464826]
	TIME [epoch: 24.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46679390360253015		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.46679390360253015 | validation: 0.6153707992948969]
	TIME [epoch: 24.9 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6032759423011098		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.6032759423011098 | validation: 0.433516132375781]
	TIME [epoch: 24.9 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47055683139751714		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.47055683139751714 | validation: 0.4657875612096719]
	TIME [epoch: 24.9 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45282201460282673		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.45282201460282673 | validation: 0.403057836004095]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_955.pth
	Model improved!!!
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261524236152213		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.5261524236152213 | validation: 0.7849273826595813]
	TIME [epoch: 24.9 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877580260205158		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.6877580260205158 | validation: 0.5509960551000325]
	TIME [epoch: 24.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49716687249345354		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.49716687249345354 | validation: 0.42779553964721645]
	TIME [epoch: 24.9 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6724195156599335		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.6724195156599335 | validation: 0.6488625483744552]
	TIME [epoch: 24.9 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.589674168080593		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.589674168080593 | validation: 0.5355504516778257]
	TIME [epoch: 24.9 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45184310900129315		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.45184310900129315 | validation: 0.42398892406473837]
	TIME [epoch: 24.9 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43743087633575095		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.43743087633575095 | validation: 0.4211828774539589]
	TIME [epoch: 24.9 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4275316673777076		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.4275316673777076 | validation: 0.5263814730139088]
	TIME [epoch: 24.9 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107521916527514		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.5107521916527514 | validation: 0.40967508934243896]
	TIME [epoch: 24.9 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43633449243712485		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.43633449243712485 | validation: 0.4399436427703054]
	TIME [epoch: 24.9 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5722780088040686		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.5722780088040686 | validation: 0.6724219699085775]
	TIME [epoch: 24.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47373398123444127		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.47373398123444127 | validation: 0.5085289291807361]
	TIME [epoch: 24.9 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6076693881488129		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.6076693881488129 | validation: 0.5670653084510942]
	TIME [epoch: 24.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4774242934764314		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.4774242934764314 | validation: 0.4583912246340634]
	TIME [epoch: 24.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4568258103509153		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.4568258103509153 | validation: 0.6132975619822361]
	TIME [epoch: 24.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46383043700712456		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.46383043700712456 | validation: 0.49434908379034903]
	TIME [epoch: 24.9 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46431118555522566		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.46431118555522566 | validation: 0.49497197063991194]
	TIME [epoch: 24.9 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4650576186757728		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.4650576186757728 | validation: 0.4970956428669423]
	TIME [epoch: 24.9 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46636521480899595		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.46636521480899595 | validation: 0.5371296854593699]
	TIME [epoch: 24.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5345061551629682		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.5345061551629682 | validation: 0.6008864701350071]
	TIME [epoch: 24.9 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5174070826908357		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.5174070826908357 | validation: 0.4652635237311793]
	TIME [epoch: 24.9 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4739917774852229		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.4739917774852229 | validation: 0.5137560064443754]
	TIME [epoch: 24.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5394873663799102		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.5394873663799102 | validation: 0.7176806341553433]
	TIME [epoch: 24.9 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6735020452665851		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.6735020452665851 | validation: 0.6559308788137831]
	TIME [epoch: 24.9 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5768486828076818		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.5768486828076818 | validation: 0.6260603590698327]
	TIME [epoch: 24.9 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5328247526667803		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.5328247526667803 | validation: 0.4511451160777705]
	TIME [epoch: 24.9 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4573415638699203		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.4573415638699203 | validation: 0.5250375060277008]
	TIME [epoch: 24.9 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4543883502503929		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.4543883502503929 | validation: 0.5458712412438798]
	TIME [epoch: 24.9 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5120588276426377		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.5120588276426377 | validation: 0.41848397627401]
	TIME [epoch: 24.9 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4178000661312149		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.4178000661312149 | validation: 0.4731762825427552]
	TIME [epoch: 24.9 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5186492602774136		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.5186492602774136 | validation: 0.4036948703405255]
	TIME [epoch: 24.9 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4371961292864622		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.4371961292864622 | validation: 0.4462518921314016]
	TIME [epoch: 24.9 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45582593070931043		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.45582593070931043 | validation: 0.5515413320033778]
	TIME [epoch: 24.9 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572165631150571		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.572165631150571 | validation: 0.5360738734691929]
	TIME [epoch: 24.9 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4648566496367963		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.4648566496367963 | validation: 0.4178297506391777]
	TIME [epoch: 24.9 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42877983596884167		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.42877983596884167 | validation: 0.49811149358932555]
	TIME [epoch: 24.9 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5678721844883317		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.5678721844883317 | validation: 0.642567820294255]
	TIME [epoch: 24.9 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4819607271435671		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.4819607271435671 | validation: 0.4573039740574086]
	TIME [epoch: 24.9 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4353401925256235		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.4353401925256235 | validation: 0.4071081185025248]
	TIME [epoch: 24.9 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45588056786910297		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.45588056786910297 | validation: 0.60677840681782]
	TIME [epoch: 24.9 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5119213137010841		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.5119213137010841 | validation: 0.5622749637645446]
	TIME [epoch: 24.9 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5003301997033582		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.5003301997033582 | validation: 0.451991404687803]
	TIME [epoch: 24.9 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5020669663693477		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.5020669663693477 | validation: 0.4122942365166759]
	TIME [epoch: 24.9 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44359593415232623		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.44359593415232623 | validation: 0.5089682924047613]
	TIME [epoch: 24.9 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5649237607950762		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.5649237607950762 | validation: 0.5302556930492829]
	TIME [epoch: 24.9 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45281814824928		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.45281814824928 | validation: 0.5633308430951202]
	TIME [epoch: 24.9 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.503814709978665		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.503814709978665 | validation: 0.4208584221018042]
	TIME [epoch: 24.9 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47709558676473934		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.47709558676473934 | validation: 0.5207777822577728]
	TIME [epoch: 24.9 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4632019278847319		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.4632019278847319 | validation: 0.4889084797372219]
	TIME [epoch: 24.9 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48812302436700383		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.48812302436700383 | validation: 0.44201206094845624]
	TIME [epoch: 24.9 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45868277154236703		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.45868277154236703 | validation: 0.6534056915130191]
	TIME [epoch: 24.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5892423796824223		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.5892423796824223 | validation: 0.7412271190426586]
	TIME [epoch: 24.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5503464988316116		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.5503464988316116 | validation: 0.5417570926127787]
	TIME [epoch: 24.9 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5334816892461834		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.5334816892461834 | validation: 0.5043076054671058]
	TIME [epoch: 24.9 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4292598735577167		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.4292598735577167 | validation: 0.46476343353815863]
	TIME [epoch: 24.9 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5145976569052368		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.5145976569052368 | validation: 0.4675120962416536]
	TIME [epoch: 24.9 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5059380756364024		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.5059380756364024 | validation: 0.6779715869305308]
	TIME [epoch: 24.9 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5656274620576184		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.5656274620576184 | validation: 0.45076934268205754]
	TIME [epoch: 24.9 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638589754624213		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.4638589754624213 | validation: 0.4513132234436048]
	TIME [epoch: 24.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44003219015011		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.44003219015011 | validation: 0.6035190215334635]
	TIME [epoch: 24.9 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5771233838606031		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.5771233838606031 | validation: 0.5933618971708556]
	TIME [epoch: 24.9 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4961514822159046		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.4961514822159046 | validation: 0.47557032263635185]
	TIME [epoch: 24.9 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43207757211644016		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.43207757211644016 | validation: 0.44936490851147814]
	TIME [epoch: 24.9 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5490081711114588		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.5490081711114588 | validation: 0.798101614507384]
	TIME [epoch: 24.9 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6259389706973002		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.6259389706973002 | validation: 0.5056047051121542]
	TIME [epoch: 24.9 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4484049194600607		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.4484049194600607 | validation: 0.5707182095243218]
	TIME [epoch: 24.9 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4585174257592255		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.4585174257592255 | validation: 0.5316539507036631]
	TIME [epoch: 24.9 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4978552849013239		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.4978552849013239 | validation: 0.5122765890288992]
	TIME [epoch: 24.9 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44398688749523296		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.44398688749523296 | validation: 0.497240576742622]
	TIME [epoch: 24.9 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4310898751856371		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.4310898751856371 | validation: 0.6232967261551314]
	TIME [epoch: 24.9 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540730867182158		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.5540730867182158 | validation: 0.597040500030751]
	TIME [epoch: 24.9 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.658832014796104		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.658832014796104 | validation: 0.679905284101804]
	TIME [epoch: 24.9 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5623911399419731		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.5623911399419731 | validation: 0.5177220406338447]
	TIME [epoch: 24.9 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5222231585424226		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.5222231585424226 | validation: 0.4716298050452696]
	TIME [epoch: 24.9 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4516762461802158		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.4516762461802158 | validation: 0.4750266985661344]
	TIME [epoch: 24.9 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.475783039258411		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.475783039258411 | validation: 0.44716554806198466]
	TIME [epoch: 24.9 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4624543689265587		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.4624543689265587 | validation: 0.4804197178570518]
	TIME [epoch: 24.9 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4434315998465335		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.4434315998465335 | validation: 0.5288795990748583]
	TIME [epoch: 24.9 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44132001647301855		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.44132001647301855 | validation: 0.428224936344958]
	TIME [epoch: 24.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45374196052849824		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.45374196052849824 | validation: 0.5934835791906805]
	TIME [epoch: 24.9 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8027518674128211		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.8027518674128211 | validation: 0.88832123191908]
	TIME [epoch: 24.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6172869382587092		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.6172869382587092 | validation: 0.46216640162117]
	TIME [epoch: 24.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4462028517785197		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.4462028517785197 | validation: 0.4418590585283856]
	TIME [epoch: 24.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4242869124339347		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.4242869124339347 | validation: 0.4166291033360494]
	TIME [epoch: 24.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4661945135590252		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.4661945135590252 | validation: 0.7170540942994884]
	TIME [epoch: 24.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.541220441414328		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.541220441414328 | validation: 0.4815356494862475]
	TIME [epoch: 24.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021370707600736		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.5021370707600736 | validation: 0.4550426030662797]
	TIME [epoch: 24.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5365270107545312		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.5365270107545312 | validation: 0.5876620656224198]
	TIME [epoch: 24.9 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5044563276234568		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.5044563276234568 | validation: 0.5064984129624664]
	TIME [epoch: 24.9 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4785933888884686		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.4785933888884686 | validation: 0.7958472247483716]
	TIME [epoch: 24.9 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8351380425196643		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.8351380425196643 | validation: 0.5986141972663603]
	TIME [epoch: 24.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5232407053191768		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.5232407053191768 | validation: 0.4524140323474586]
	TIME [epoch: 24.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4303825400671223		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.4303825400671223 | validation: 0.4646663478474398]
	TIME [epoch: 24.9 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5077656830945079		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.5077656830945079 | validation: 0.4626031250207814]
	TIME [epoch: 24.9 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45522112844595986		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.45522112844595986 | validation: 0.45057528400703833]
	TIME [epoch: 24.9 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43383547524179245		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.43383547524179245 | validation: 0.5386057676484166]
	TIME [epoch: 24.9 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5442000271242353		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.5442000271242353 | validation: 0.6503367118243242]
	TIME [epoch: 24.9 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5382052609309196		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.5382052609309196 | validation: 0.458663704104753]
	TIME [epoch: 24.9 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4781739677065089		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.4781739677065089 | validation: 0.45391800576266617]
	TIME [epoch: 24.9 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.428476378360235		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.428476378360235 | validation: 0.43338100564507614]
	TIME [epoch: 24.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4296170948643486		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.4296170948643486 | validation: 0.48108373323184583]
	TIME [epoch: 24.9 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42193507383089823		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.42193507383089823 | validation: 0.47000647358088643]
	TIME [epoch: 24.9 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071438698728464		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.5071438698728464 | validation: 0.43348583740796826]
	TIME [epoch: 24.9 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472833770818294		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.4472833770818294 | validation: 0.5033021077873385]
	TIME [epoch: 24.9 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4748403807956124		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.4748403807956124 | validation: 0.4625350909306647]
	TIME [epoch: 24.9 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4289910328273457		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.4289910328273457 | validation: 0.3997367909243308]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_1061.pth
	Model improved!!!
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4222053688082129		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.4222053688082129 | validation: 0.582046449190224]
	TIME [epoch: 24.9 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49589589859667127		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.49589589859667127 | validation: 0.42211008287911045]
	TIME [epoch: 24.9 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4207671010687483		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.4207671010687483 | validation: 0.4563635908063426]
	TIME [epoch: 24.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.537232986822294		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.537232986822294 | validation: 0.5213751951662942]
	TIME [epoch: 24.9 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4371468867180034		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.4371468867180034 | validation: 0.4604056177049792]
	TIME [epoch: 24.9 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.467790818531757		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.467790818531757 | validation: 0.4114955779708014]
	TIME [epoch: 24.9 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41004423749575225		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.41004423749575225 | validation: 0.43005261960537866]
	TIME [epoch: 24.9 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4709366280293499		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.4709366280293499 | validation: 0.44868284887950316]
	TIME [epoch: 24.9 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4741885495009365		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.4741885495009365 | validation: 0.6349124061227326]
	TIME [epoch: 24.9 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49894884500616654		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.49894884500616654 | validation: 0.48923996175813134]
	TIME [epoch: 24.9 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4705514743355723		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.4705514743355723 | validation: 0.5160007083273382]
	TIME [epoch: 24.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6061424123340882		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.6061424123340882 | validation: 0.7106170298554699]
	TIME [epoch: 24.9 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5288375147196211		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.5288375147196211 | validation: 0.47597916710113697]
	TIME [epoch: 24.9 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46723837343979224		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.46723837343979224 | validation: 0.4770874985355323]
	TIME [epoch: 24.9 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4841702395877436		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.4841702395877436 | validation: 0.5576529054983489]
	TIME [epoch: 24.9 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5108149443173925		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.5108149443173925 | validation: 0.5119238061047363]
	TIME [epoch: 24.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5170703581212198		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.5170703581212198 | validation: 0.47530809956716213]
	TIME [epoch: 24.9 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687066820019913		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.4687066820019913 | validation: 0.4800900335950274]
	TIME [epoch: 24.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4633784350418502		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.4633784350418502 | validation: 0.46503928872817385]
	TIME [epoch: 24.9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45380592978536405		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.45380592978536405 | validation: 0.4770500485649537]
	TIME [epoch: 24.9 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44813530878443697		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.44813530878443697 | validation: 0.5528665034718524]
	TIME [epoch: 24.9 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5584696477082305		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.5584696477082305 | validation: 0.5230588085976767]
	TIME [epoch: 24.9 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4704171066389592		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.4704171066389592 | validation: 0.5254889521998056]
	TIME [epoch: 24.9 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44270932773638455		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.44270932773638455 | validation: 0.4334787292075214]
	TIME [epoch: 25 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41368176663139133		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.41368176663139133 | validation: 0.449154397649124]
	TIME [epoch: 24.9 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4108285167875127		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.4108285167875127 | validation: 0.41827709761811255]
	TIME [epoch: 24.9 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43508505945737563		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.43508505945737563 | validation: 0.42603085638074223]
	TIME [epoch: 24.9 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.413516270793311		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.413516270793311 | validation: 0.4334350003749089]
	TIME [epoch: 24.9 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4659685849720233		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.4659685849720233 | validation: 0.5238967614288894]
	TIME [epoch: 24.9 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43598484129617565		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.43598484129617565 | validation: 0.48291175237830736]
	TIME [epoch: 24.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45880317837613993		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.45880317837613993 | validation: 0.41616757431957646]
	TIME [epoch: 24.9 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42094395626336734		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.42094395626336734 | validation: 0.4378126974147037]
	TIME [epoch: 24.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43189344923945394		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.43189344923945394 | validation: 0.4843167175677073]
	TIME [epoch: 24.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4988969946880775		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.4988969946880775 | validation: 0.45860449548845994]
	TIME [epoch: 24.9 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47870286640564924		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.47870286640564924 | validation: 0.489453915255582]
	TIME [epoch: 24.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4281396827131481		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.4281396827131481 | validation: 0.4546048770762429]
	TIME [epoch: 24.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4100515074798905		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.4100515074798905 | validation: 0.4083404910240794]
	TIME [epoch: 24.9 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4237119944314049		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.4237119944314049 | validation: 0.4503280759426251]
	TIME [epoch: 24.9 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4154090953575716		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.4154090953575716 | validation: 0.46375024321853386]
	TIME [epoch: 24.9 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46702658565363586		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.46702658565363586 | validation: 0.41633603608017355]
	TIME [epoch: 24.9 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3930771166898468		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.3930771166898468 | validation: 0.4304640755897309]
	TIME [epoch: 24.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4478686008851565		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.4478686008851565 | validation: 0.4572864928713393]
	TIME [epoch: 24.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43514986907708153		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.43514986907708153 | validation: 0.4392771211661047]
	TIME [epoch: 24.9 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4477729481263834		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.4477729481263834 | validation: 0.44990456282088376]
	TIME [epoch: 24.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.452154042461973		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.452154042461973 | validation: 0.5305575955276255]
	TIME [epoch: 24.9 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49941867129021955		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.49941867129021955 | validation: 0.6601725209786177]
	TIME [epoch: 24.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5679004803534695		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.5679004803534695 | validation: 0.428899461409463]
	TIME [epoch: 24.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.441932760255067		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.441932760255067 | validation: 0.5306233642248425]
	TIME [epoch: 24.9 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4678042173910502		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.4678042173910502 | validation: 0.44003640149591844]
	TIME [epoch: 24.9 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43735332281679196		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.43735332281679196 | validation: 0.41829297971861695]
	TIME [epoch: 24.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.428657323237012		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.428657323237012 | validation: 0.4064885964697372]
	TIME [epoch: 24.9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4039518245847084		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.4039518245847084 | validation: 0.4091390655690421]
	TIME [epoch: 24.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3984494568153881		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.3984494568153881 | validation: 0.40719919362698337]
	TIME [epoch: 24.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4216035289333865		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.4216035289333865 | validation: 0.5326122036109793]
	TIME [epoch: 24.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46642694668557194		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.46642694668557194 | validation: 0.4303512850326041]
	TIME [epoch: 24.9 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4857538831322755		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.4857538831322755 | validation: 0.7026017171863904]
	TIME [epoch: 24.9 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5680929629922481		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.5680929629922481 | validation: 0.44045373951492073]
	TIME [epoch: 24.9 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4262172612549826		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.4262172612549826 | validation: 0.42832883919513876]
	TIME [epoch: 24.9 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4272948816255275		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.4272948816255275 | validation: 0.4135455299687577]
	TIME [epoch: 24.9 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3975030995325009		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.3975030995325009 | validation: 0.42859805149936203]
	TIME [epoch: 24.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43520927375128354		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.43520927375128354 | validation: 0.4466204230332221]
	TIME [epoch: 24.9 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4586989812925455		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.4586989812925455 | validation: 0.5122775728621395]
	TIME [epoch: 24.9 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4490915673335173		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.4490915673335173 | validation: 0.42958431058487667]
	TIME [epoch: 24.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4640474689662083		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.4640474689662083 | validation: 0.44841357632944007]
	TIME [epoch: 24.9 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4577608164884264		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.4577608164884264 | validation: 0.4252246947085946]
	TIME [epoch: 24.9 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4074878985586391		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.4074878985586391 | validation: 0.46279535058129706]
	TIME [epoch: 24.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4414056528930133		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.4414056528930133 | validation: 0.4909522107136048]
	TIME [epoch: 24.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4124573573679359		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.4124573573679359 | validation: 0.4159658336352681]
	TIME [epoch: 24.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4150653281853164		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.4150653281853164 | validation: 0.41894935304208675]
	TIME [epoch: 24.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42453574721137743		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.42453574721137743 | validation: 0.42888206951358315]
	TIME [epoch: 24.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3981251474669875		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.3981251474669875 | validation: 0.41155387360503926]
	TIME [epoch: 24.9 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4242758749607007		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.4242758749607007 | validation: 0.4269149742663801]
	TIME [epoch: 24.9 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4066394398947241		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.4066394398947241 | validation: 0.4276817156925582]
	TIME [epoch: 24.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42728513931402207		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.42728513931402207 | validation: 0.49526887470893716]
	TIME [epoch: 24.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4526978526753004		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.4526978526753004 | validation: 0.5721880472092068]
	TIME [epoch: 24.9 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5926041014651302		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.5926041014651302 | validation: 0.6136269094931115]
	TIME [epoch: 24.9 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5543629948473007		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.5543629948473007 | validation: 0.5325486942100871]
	TIME [epoch: 24.9 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5489550582821492		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.5489550582821492 | validation: 0.5337873816835794]
	TIME [epoch: 24.9 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4599353523987595		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.4599353523987595 | validation: 0.4098457339064659]
	TIME [epoch: 24.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5003291254199151		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.5003291254199151 | validation: 0.5065854180310544]
	TIME [epoch: 24.9 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4791076918682239		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.4791076918682239 | validation: 0.46184747876717785]
	TIME [epoch: 24.9 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4357335703239601		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.4357335703239601 | validation: 0.4094641166453497]
	TIME [epoch: 24.9 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4036477181458844		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.4036477181458844 | validation: 0.39209628867834784]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_1144.pth
	Model improved!!!
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4010479601574578		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.4010479601574578 | validation: 0.39298576189509965]
	TIME [epoch: 24.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40111645500646914		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.40111645500646914 | validation: 0.38477866367320046]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_1146.pth
	Model improved!!!
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41358653718425475		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.41358653718425475 | validation: 0.40017826056830913]
	TIME [epoch: 24.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4120193899705077		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.4120193899705077 | validation: 0.39298604452482566]
	TIME [epoch: 24.9 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4115381255078434		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.4115381255078434 | validation: 0.44013804681159785]
	TIME [epoch: 24.9 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47021200495837023		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.47021200495837023 | validation: 0.5251383993967604]
	TIME [epoch: 24.9 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4947561186567559		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.4947561186567559 | validation: 0.43733248462495916]
	TIME [epoch: 24.9 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43872201183487175		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.43872201183487175 | validation: 0.412123063830868]
	TIME [epoch: 24.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39720494607707346		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.39720494607707346 | validation: 0.3899659480394395]
	TIME [epoch: 24.9 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4335538212426657		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.4335538212426657 | validation: 0.6727616260629852]
	TIME [epoch: 24.9 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5658678719571886		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.5658678719571886 | validation: 0.4766743989353969]
	TIME [epoch: 24.9 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404887467390177		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.4404887467390177 | validation: 0.39130229902902225]
	TIME [epoch: 24.9 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.388185377853996		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.388185377853996 | validation: 0.4484025774521352]
	TIME [epoch: 24.9 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41028421309859187		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.41028421309859187 | validation: 0.49406795848848334]
	TIME [epoch: 24.9 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45903654352021694		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.45903654352021694 | validation: 0.5052346573010611]
	TIME [epoch: 24.9 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4312121314054744		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.4312121314054744 | validation: 0.42367973070821247]
	TIME [epoch: 24.9 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42745989252092104		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.42745989252092104 | validation: 0.45487375681482006]
	TIME [epoch: 24.9 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4464041542935081		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.4464041542935081 | validation: 0.43939660752731596]
	TIME [epoch: 24.9 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4375039611095315		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.4375039611095315 | validation: 0.4204876169885652]
	TIME [epoch: 24.9 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40497207808495905		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.40497207808495905 | validation: 0.411012583742791]
	TIME [epoch: 24.9 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41854157559699495		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.41854157559699495 | validation: 0.4273809806042438]
	TIME [epoch: 24.9 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44918369518255824		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.44918369518255824 | validation: 0.4595294290725116]
	TIME [epoch: 24.9 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44373242661797535		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.44373242661797535 | validation: 0.4075685327412751]
	TIME [epoch: 24.9 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41448082573549627		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.41448082573549627 | validation: 0.40185681657367694]
	TIME [epoch: 24.9 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3894063261433227		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.3894063261433227 | validation: 0.39658467548328163]
	TIME [epoch: 24.9 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41636626670775617		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.41636626670775617 | validation: 0.4465664956220479]
	TIME [epoch: 24.9 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4122328822753703		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.4122328822753703 | validation: 0.4019747528282753]
	TIME [epoch: 24.9 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3972338930394346		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.3972338930394346 | validation: 0.4818874319018396]
	TIME [epoch: 24.9 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4325584697198617		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.4325584697198617 | validation: 0.41597161269792815]
	TIME [epoch: 24.9 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40170843832486436		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.40170843832486436 | validation: 0.4048683882822359]
	TIME [epoch: 24.9 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3910488854767397		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.3910488854767397 | validation: 0.42888334940540745]
	TIME [epoch: 24.9 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4379092141381545		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.4379092141381545 | validation: 0.40272013369111165]
	TIME [epoch: 24.9 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40319473093647173		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.40319473093647173 | validation: 0.536973020397787]
	TIME [epoch: 24.9 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5367481011062036		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.5367481011062036 | validation: 0.7741600338431289]
	TIME [epoch: 24.9 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6076566568734114		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.6076566568734114 | validation: 0.506737779883532]
	TIME [epoch: 24.9 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4234285597967165		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.4234285597967165 | validation: 0.40313720146134413]
	TIME [epoch: 24.9 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38897325018619977		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.38897325018619977 | validation: 0.4158220826071202]
	TIME [epoch: 24.9 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976804646482084		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.3976804646482084 | validation: 0.4547527930825785]
	TIME [epoch: 24.9 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41282947299505296		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.41282947299505296 | validation: 0.42770479482061574]
	TIME [epoch: 24.9 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42219641211439546		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.42219641211439546 | validation: 0.45009027456566897]
	TIME [epoch: 24.9 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40929180190652786		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.40929180190652786 | validation: 0.4240710224101327]
	TIME [epoch: 24.9 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4058419669678115		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.4058419669678115 | validation: 0.41284611596574344]
	TIME [epoch: 24.9 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4044054423149288		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.4044054423149288 | validation: 0.4273963463662325]
	TIME [epoch: 24.9 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3903459794600882		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.3903459794600882 | validation: 0.40776615221475243]
	TIME [epoch: 24.9 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4009225388798896		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.4009225388798896 | validation: 0.4279619273123961]
	TIME [epoch: 24.9 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060454785240447		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.4060454785240447 | validation: 0.41078527703596607]
	TIME [epoch: 24.9 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.432499839543408		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.432499839543408 | validation: 0.4064227483534588]
	TIME [epoch: 24.9 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40350141506173653		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.40350141506173653 | validation: 0.38180431014631255]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_1192.pth
	Model improved!!!
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40229233096555905		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.40229233096555905 | validation: 0.504759647785465]
	TIME [epoch: 24.9 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49710082773933484		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.49710082773933484 | validation: 0.4260524187248173]
	TIME [epoch: 24.9 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41670580710093963		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.41670580710093963 | validation: 0.4154527297084236]
	TIME [epoch: 24.9 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4272592281260877		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.4272592281260877 | validation: 0.48234920351293353]
	TIME [epoch: 24.9 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4324199734939418		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.4324199734939418 | validation: 0.39637610086242225]
	TIME [epoch: 24.9 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38829912595452437		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.38829912595452437 | validation: 0.4055407533177843]
	TIME [epoch: 24.9 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.406478261264877		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.406478261264877 | validation: 0.5106852904673977]
	TIME [epoch: 24.9 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.474439185978888		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.474439185978888 | validation: 0.5175622491254237]
	TIME [epoch: 24.9 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42272277062369723		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.42272277062369723 | validation: 0.44917866883570445]
	TIME [epoch: 24.9 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4583938033565944		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.4583938033565944 | validation: 0.625776778105885]
	TIME [epoch: 24.9 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5087702831410795		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.5087702831410795 | validation: 0.44087389203520794]
	TIME [epoch: 24.9 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.412960881387073		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.412960881387073 | validation: 0.4287749916174238]
	TIME [epoch: 24.9 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3918207382345398		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.3918207382345398 | validation: 0.4234338423895163]
	TIME [epoch: 24.9 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3944730685661242		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.3944730685661242 | validation: 0.4086580291972045]
	TIME [epoch: 24.9 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3951290072380809		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.3951290072380809 | validation: 0.39704813248881493]
	TIME [epoch: 24.9 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4127055344857565		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.4127055344857565 | validation: 0.45568607323296195]
	TIME [epoch: 24.9 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4560267864308327		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.4560267864308327 | validation: 0.4370025450988612]
	TIME [epoch: 24.9 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4085397232654365		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.4085397232654365 | validation: 0.4025628722847581]
	TIME [epoch: 24.9 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37784911954622946		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.37784911954622946 | validation: 0.3965035433297571]
	TIME [epoch: 24.9 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38083566183080303		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.38083566183080303 | validation: 0.39723314738877735]
	TIME [epoch: 24.9 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37773639105226725		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.37773639105226725 | validation: 0.4107138206959662]
	TIME [epoch: 24.9 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43195950135476835		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.43195950135476835 | validation: 0.496457901511547]
	TIME [epoch: 24.9 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42810375622641006		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.42810375622641006 | validation: 0.4273426997086152]
	TIME [epoch: 24.9 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43892193343891117		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.43892193343891117 | validation: 0.48218781096879215]
	TIME [epoch: 24.9 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4271612752793762		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.4271612752793762 | validation: 0.4692351179549483]
	TIME [epoch: 24.9 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42713980029486637		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.42713980029486637 | validation: 0.4992924327587896]
	TIME [epoch: 24.9 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4137845635380769		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.4137845635380769 | validation: 0.3862048708968806]
	TIME [epoch: 24.9 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38144105281066654		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.38144105281066654 | validation: 0.4117937371776011]
	TIME [epoch: 24.9 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3941418188071937		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.3941418188071937 | validation: 0.4057006415271712]
	TIME [epoch: 24.9 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39171743058239517		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.39171743058239517 | validation: 0.4314829531698131]
	TIME [epoch: 24.9 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39513325705511365		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.39513325705511365 | validation: 0.39914707193275856]
	TIME [epoch: 24.9 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41939768661003596		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.41939768661003596 | validation: 0.43883232207912537]
	TIME [epoch: 24.9 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42651289255825364		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.42651289255825364 | validation: 0.4122558676801799]
	TIME [epoch: 24.9 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42571062534815923		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.42571062534815923 | validation: 0.4593113033249877]
	TIME [epoch: 24.9 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42709451883588223		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.42709451883588223 | validation: 0.4449411776736221]
	TIME [epoch: 24.9 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40113764129447976		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.40113764129447976 | validation: 0.4136556020399683]
	TIME [epoch: 24.9 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3920370931082781		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.3920370931082781 | validation: 0.39387599367325515]
	TIME [epoch: 24.9 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.400012363481423		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.400012363481423 | validation: 0.3952093045621841]
	TIME [epoch: 24.9 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40176316200895595		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.40176316200895595 | validation: 0.3961646800427286]
	TIME [epoch: 24.9 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44689474098872284		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.44689474098872284 | validation: 0.46340479999613265]
	TIME [epoch: 24.9 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43599733074542457		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.43599733074542457 | validation: 0.4233827797367245]
	TIME [epoch: 24.9 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39472276457847255		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.39472276457847255 | validation: 0.38230560495602506]
	TIME [epoch: 24.9 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38879941993795164		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.38879941993795164 | validation: 0.378613997138864]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r2_20240310_003029/states/model_tr_study5_1235.pth
	Model improved!!!
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3869582454607431		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.3869582454607431 | validation: 0.43497766387033265]
	TIME [epoch: 24.9 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4781720030651784		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.4781720030651784 | validation: 0.6564722658802257]
	TIME [epoch: 24.9 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6719600753255963		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.6719600753255963 | validation: 0.771698376406878]
	TIME [epoch: 24.9 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6603011442926907		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.6603011442926907 | validation: 0.5946667519642851]
	TIME [epoch: 24.9 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4491387925233378		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.4491387925233378 | validation: 0.4094624219810403]
	TIME [epoch: 24.9 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3837686751621301		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.3837686751621301 | validation: 0.40179867975970057]
	TIME [epoch: 24.9 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3970331338647257		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.3970331338647257 | validation: 0.4101907251653191]
	TIME [epoch: 24.9 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4070057405425128		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.4070057405425128 | validation: 0.3857222894271724]
	TIME [epoch: 24.9 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820975257414884		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.3820975257414884 | validation: 0.40085337961781065]
	TIME [epoch: 24.9 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3931647171104821		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.3931647171104821 | validation: 0.44943120317113816]
	TIME [epoch: 24.9 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4967333920542125		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.4967333920542125 | validation: 0.45135934474364975]
	TIME [epoch: 24.9 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41606008211241735		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.41606008211241735 | validation: 0.4001954782909073]
	TIME [epoch: 24.9 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3883118162260238		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.3883118162260238 | validation: 0.4192012965856432]
	TIME [epoch: 24.9 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39461817401681454		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.39461817401681454 | validation: 0.41054206787548175]
	TIME [epoch: 24.9 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.394458860772795		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.394458860772795 | validation: 0.40097194901752164]
	TIME [epoch: 24.9 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3906249904785206		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.3906249904785206 | validation: 0.45728614942888457]
	TIME [epoch: 24.9 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41221913811983657		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.41221913811983657 | validation: 0.3800115241907554]
	TIME [epoch: 24.9 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.378174722877574		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.378174722877574 | validation: 0.3857046435338182]
	TIME [epoch: 24.9 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.391762035231738		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.391762035231738 | validation: 0.4452906587685398]
	TIME [epoch: 24.9 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40508693794744066		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.40508693794744066 | validation: 0.3973295028253675]
	TIME [epoch: 24.9 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38908844391248876		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.38908844391248876 | validation: 0.38359740249532226]
	TIME [epoch: 24.9 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37499304656339943		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.37499304656339943 | validation: 0.4061697417681809]
	TIME [epoch: 24.9 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39929966673062106		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.39929966673062106 | validation: 0.3854054487827645]
	TIME [epoch: 24.9 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37447678361295245		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.37447678361295245 | validation: 0.3859467811809855]
	TIME [epoch: 24.9 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40934185831772973		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.40934185831772973 | validation: 0.5517952605976119]
	TIME [epoch: 24.9 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45329298174485577		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.45329298174485577 | validation: 0.4025571560718966]
	TIME [epoch: 24.9 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40049247872879745		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.40049247872879745 | validation: 0.4138436957334362]
	TIME [epoch: 24.9 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4171771816847954		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.4171771816847954 | validation: 0.3857836841067537]
	TIME [epoch: 24.9 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3757149438174353		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.3757149438174353 | validation: 0.38348726739478994]
	TIME [epoch: 24.9 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389402275902234		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.389402275902234 | validation: 0.4723760271795352]
	TIME [epoch: 24.9 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5422302479940442		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.5422302479940442 | validation: 0.5976491358565453]
	TIME [epoch: 24.9 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5395260750587119		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.5395260750587119 | validation: 0.5672755797814418]
	TIME [epoch: 24.9 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5159358940609549		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.5159358940609549 | validation: 0.5082368386048622]
	TIME [epoch: 24.9 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43868299821347545		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.43868299821347545 | validation: 0.49721148892358635]
	TIME [epoch: 24.9 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43200875621361273		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.43200875621361273 | validation: 0.4180550219803367]
	TIME [epoch: 24.9 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4090446509467695		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.4090446509467695 | validation: 0.4102036937659506]
	TIME [epoch: 24.9 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39042769472807787		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.39042769472807787 | validation: 0.399499878339292]
	TIME [epoch: 24.9 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3904372696202041		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.3904372696202041 | validation: 0.3840840229942004]
	TIME [epoch: 24.9 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40226593340701144		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.40226593340701144 | validation: 0.4344805675421112]
	TIME [epoch: 24.9 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4042110926283341		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.4042110926283341 | validation: 0.43369103559494354]
	TIME [epoch: 24.9 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367726032380997		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.4367726032380997 | validation: 0.43305237954375214]
	TIME [epoch: 24.9 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.441193717965064		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.441193717965064 | validation: 0.5292427544383348]
	TIME [epoch: 24.9 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5479999949027212		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.5479999949027212 | validation: 0.6252049858825118]
	TIME [epoch: 24.9 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5544747424838408		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.5544747424838408 | validation: 0.5267031852982175]
	TIME [epoch: 24.9 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4781578638230545		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.4781578638230545 | validation: 0.4779439469158644]
	TIME [epoch: 24.9 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4426802076566801		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.4426802076566801 | validation: 0.4402866042678346]
	TIME [epoch: 24.9 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42319267541870764		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.42319267541870764 | validation: 0.41869600495574444]
	TIME [epoch: 24.9 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39041312856730803		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.39041312856730803 | validation: 0.4199084708794517]
	TIME [epoch: 24.9 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3972658853460459		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.3972658853460459 | validation: 0.41861739292622796]
	TIME [epoch: 24.9 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3857507928554563		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.3857507928554563 | validation: 0.40288795147064804]
	TIME [epoch: 24.9 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39131196272715424		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.39131196272715424 | validation: 0.39951411463842895]
	TIME [epoch: 24.9 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3866087872398042		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.3866087872398042 | validation: 0.4263090345362343]
	TIME [epoch: 24.9 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41086955292597405		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.41086955292597405 | validation: 0.5203198620336151]
	TIME [epoch: 24.9 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46576836204875716		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.46576836204875716 | validation: 0.5921428909380134]
	TIME [epoch: 24.9 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5174343984649074		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.5174343984649074 | validation: 0.5080117108200508]
	TIME [epoch: 24.9 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4324956063913555		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.4324956063913555 | validation: 0.5549523775404435]
	TIME [epoch: 24.9 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4964856330002287		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.4964856330002287 | validation: 0.5223118330426975]
	TIME [epoch: 24.9 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4551167639003323		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.4551167639003323 | validation: 0.48005700241466626]
	TIME [epoch: 24.9 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4098226982887395		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.4098226982887395 | validation: 0.41086323497379185]
	TIME [epoch: 24.9 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3903773088547605		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.3903773088547605 | validation: 0.40088776050178027]
	TIME [epoch: 24.9 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38723039902912243		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.38723039902912243 | validation: 0.41842580012741504]
	TIME [epoch: 24.9 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3859827946900414		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.3859827946900414 | validation: 0.526674064033131]
	TIME [epoch: 24.9 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4434007254795201		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.4434007254795201 | validation: 0.4791147689186526]
	TIME [epoch: 24.9 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4644575459345399		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.4644575459345399 | validation: 0.5971791957804627]
	TIME [epoch: 24.9 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47435034159851946		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.47435034159851946 | validation: 0.4432920019291191]
	TIME [epoch: 24.9 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4048161783569336		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.4048161783569336 | validation: 0.3982446962479761]
	TIME [epoch: 24.9 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39886117491835904		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.39886117491835904 | validation: 0.40665689652539255]
	TIME [epoch: 24.9 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39140403890129044		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.39140403890129044 | validation: 0.40124094124756954]
	TIME [epoch: 24.9 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39406090374083313		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.39406090374083313 | validation: 0.4128912852146759]
	TIME [epoch: 24.9 sec]
EPOCH 1305/2000:
	Training over batches...
