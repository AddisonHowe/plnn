Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r5', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3482869664

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 11.682993057543491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.682993057543491 | validation: 11.118916671118965]
	TIME [epoch: 54.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.799778506467167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.799778506467167 | validation: 11.589044903216973]
	TIME [epoch: 9.84 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.990035708419308		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.990035708419308 | validation: 10.51028264563577]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 10.06987337662971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.06987337662971 | validation: 10.114481759106043]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.818719917997493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.818719917997493 | validation: 9.512130124269213]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.50710450321133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.50710450321133 | validation: 8.823729945172294]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.126841320204264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.126841320204264 | validation: 9.337561780816666]
	TIME [epoch: 9.8 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.749760483426256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.749760483426256 | validation: 8.449334779255466]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.514967769754084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.514967769754084 | validation: 9.261936447611228]
	TIME [epoch: 9.8 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.934070442303039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.934070442303039 | validation: 8.00543040316628]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.047488054532508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.047488054532508 | validation: 8.624858184941523]
	TIME [epoch: 9.81 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.814291287411441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.814291287411441 | validation: 7.392946458139331]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.390276042886951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.390276042886951 | validation: 7.380884961280424]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.525248254662931		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.525248254662931 | validation: 7.049750644383936]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.25999781841019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.25999781841019 | validation: 7.023754066423112]
	TIME [epoch: 9.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.1077536687867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1077536687867 | validation: 6.895528195221609]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.092949884506412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.092949884506412 | validation: 7.185001370235471]
	TIME [epoch: 9.81 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.480490786153554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.480490786153554 | validation: 6.7589799196831635]
	TIME [epoch: 9.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.006559368029348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.006559368029348 | validation: 6.865693516402765]
	TIME [epoch: 9.82 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.87173238990049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.87173238990049 | validation: 6.518936307018646]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.090805788720694		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.090805788720694 | validation: 6.826096853127388]
	TIME [epoch: 9.82 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.04112666685278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.04112666685278 | validation: 6.327261811683974]
	TIME [epoch: 9.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.0043301686041275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0043301686041275 | validation: 6.5307442315246265]
	TIME [epoch: 9.81 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.7970904490586905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7970904490586905 | validation: 6.442758785219414]
	TIME [epoch: 9.81 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.287157654256092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.287157654256092 | validation: 6.348207347265871]
	TIME [epoch: 9.83 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.6377215257397735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6377215257397735 | validation: 6.525288172485207]
	TIME [epoch: 9.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.493634928642183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.493634928642183 | validation: 6.650855616124866]
	TIME [epoch: 9.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.876057883937722		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.876057883937722 | validation: 6.406732332040225]
	TIME [epoch: 9.81 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5720387092646195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5720387092646195 | validation: 6.302577792514342]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.550065344999755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.550065344999755 | validation: 6.846390869340561]
	TIME [epoch: 9.81 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.634637720458744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.634637720458744 | validation: 6.567763186475753]
	TIME [epoch: 9.81 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.726617866964421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.726617866964421 | validation: 6.173126517527054]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.542411210389441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.542411210389441 | validation: 6.01288942367831]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.465065497497556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.465065497497556 | validation: 6.339874706014609]
	TIME [epoch: 9.82 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.266272053812882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.266272053812882 | validation: 6.090396694516898]
	TIME [epoch: 9.82 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.009900109314071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.009900109314071 | validation: 6.25698567679472]
	TIME [epoch: 9.84 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.261560241457527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.261560241457527 | validation: 6.116465840436308]
	TIME [epoch: 9.81 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.5001291889056985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5001291889056985 | validation: 6.0061994216924655]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.185944375485551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.185944375485551 | validation: 5.508822142105819]
	TIME [epoch: 9.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.280619160913695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.280619160913695 | validation: 4.585546379845621]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.532807156887211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.532807156887211 | validation: 4.561078474757915]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.905157395022182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.905157395022182 | validation: 5.042860448701521]
	TIME [epoch: 9.81 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.726573413348811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.726573413348811 | validation: 5.761406599831883]
	TIME [epoch: 9.82 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.533991561390065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.533991561390065 | validation: 4.729779923066521]
	TIME [epoch: 9.81 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.402249450227131		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.402249450227131 | validation: 5.173069226396978]
	TIME [epoch: 9.81 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.955504456843235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.955504456843235 | validation: 4.047385920656567]
	TIME [epoch: 9.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.608573751047967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.608573751047967 | validation: 4.720842812953056]
	TIME [epoch: 9.81 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.361188106282913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.361188106282913 | validation: 4.965096525489301]
	TIME [epoch: 9.81 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5591204657877125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5591204657877125 | validation: 5.834682972667699]
	TIME [epoch: 9.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.822677459843122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.822677459843122 | validation: 4.170822818980274]
	TIME [epoch: 9.85 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.356483698366522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.356483698366522 | validation: 5.659387723351649]
	TIME [epoch: 9.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.496584109751259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.496584109751259 | validation: 6.738289313912755]
	TIME [epoch: 9.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.477666580691212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.477666580691212 | validation: 7.269097372768365]
	TIME [epoch: 9.81 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.87422140972876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.87422140972876 | validation: 6.294563623389957]
	TIME [epoch: 9.81 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.465833119588515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.465833119588515 | validation: 5.536804590536491]
	TIME [epoch: 9.79 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8403290836148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8403290836148 | validation: 4.444116448555461]
	TIME [epoch: 9.81 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.131461099941115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.131461099941115 | validation: 3.819683395250864]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9944734688013357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9944734688013357 | validation: 4.608542747549053]
	TIME [epoch: 9.81 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.8662026948134125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8662026948134125 | validation: 6.51933549965455]
	TIME [epoch: 9.81 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.18100628686973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.18100628686973 | validation: 4.5967094976921405]
	TIME [epoch: 9.82 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.169842259376292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.169842259376292 | validation: 4.307216596782357]
	TIME [epoch: 9.81 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.257348995536466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.257348995536466 | validation: 4.540933850158413]
	TIME [epoch: 9.81 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4732209009351065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4732209009351065 | validation: 4.433807621963788]
	TIME [epoch: 9.81 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.038594094052203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.038594094052203 | validation: 3.613478368074205]
	TIME [epoch: 9.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.721065834277473		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.721065834277473 | validation: 6.737924365019653]
	TIME [epoch: 9.81 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.774761458845195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.774761458845195 | validation: 4.2903621752264085]
	TIME [epoch: 9.81 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.352661054048875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.352661054048875 | validation: 5.1270606979723725]
	TIME [epoch: 9.82 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.452904168683955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.452904168683955 | validation: 4.733364594659206]
	TIME [epoch: 9.81 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.497145418574207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.497145418574207 | validation: 4.97678524968205]
	TIME [epoch: 9.81 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.315737088953007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.315737088953007 | validation: 5.566873108471425]
	TIME [epoch: 9.81 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.268707291382935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.268707291382935 | validation: 5.036364765438698]
	TIME [epoch: 9.82 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.8352307261203595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8352307261203595 | validation: 5.78097387730935]
	TIME [epoch: 9.81 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.762933745963786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.762933745963786 | validation: 4.255703139323063]
	TIME [epoch: 9.8 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.548172422899148		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.548172422899148 | validation: 4.2179375386379245]
	TIME [epoch: 9.82 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.930948035055411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.930948035055411 | validation: 4.165732140932482]
	TIME [epoch: 9.81 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.398411222243243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.398411222243243 | validation: 4.468815790839638]
	TIME [epoch: 9.81 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1464789288442345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1464789288442345 | validation: 3.9847565349058147]
	TIME [epoch: 9.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3712872500477635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3712872500477635 | validation: 4.809283597323891]
	TIME [epoch: 9.83 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.294730845270775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.294730845270775 | validation: 4.262896249621699]
	TIME [epoch: 9.81 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.279724290460729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.279724290460729 | validation: 4.189309865578084]
	TIME [epoch: 9.81 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.411809429087715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.411809429087715 | validation: 5.064026975991145]
	TIME [epoch: 9.81 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.146649395928845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.146649395928845 | validation: 3.991550116081328]
	TIME [epoch: 9.83 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.012518930144146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.012518930144146 | validation: 3.6962015857980304]
	TIME [epoch: 9.81 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8335806725424733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8335806725424733 | validation: 4.842519730982742]
	TIME [epoch: 9.81 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.378904661123343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.378904661123343 | validation: 5.0241338070940165]
	TIME [epoch: 9.83 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9741021437263546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9741021437263546 | validation: 3.329579089121162]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.258607898070419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.258607898070419 | validation: 4.3843114960996905]
	TIME [epoch: 9.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.6427218326289745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6427218326289745 | validation: 4.0529629400100236]
	TIME [epoch: 9.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.171248079997303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.171248079997303 | validation: 4.179127281686241]
	TIME [epoch: 9.82 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8672025295660646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8672025295660646 | validation: 6.8839093748544125]
	TIME [epoch: 9.79 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.771221365366179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.771221365366179 | validation: 4.20479234316456]
	TIME [epoch: 9.81 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.236672929884861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.236672929884861 | validation: 5.368545587556233]
	TIME [epoch: 9.81 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.436605945878374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.436605945878374 | validation: 4.627779906377575]
	TIME [epoch: 9.81 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.871921121086478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.871921121086478 | validation: 6.549952080056346]
	TIME [epoch: 9.8 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.693410926039575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.693410926039575 | validation: 5.000523362847127]
	TIME [epoch: 9.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.414933071095339		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.414933071095339 | validation: 4.126816964034099]
	TIME [epoch: 9.82 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.190876558549151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.190876558549151 | validation: 4.281430659952277]
	TIME [epoch: 9.81 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.165761522392495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.165761522392495 | validation: 3.708662488946164]
	TIME [epoch: 9.81 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.660763440038013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.660763440038013 | validation: 3.70834774335245]
	TIME [epoch: 9.81 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.622405436488657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.622405436488657 | validation: 5.1999638259348755]
	TIME [epoch: 9.81 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.2626355488270775		[learning rate: 0.0099806]
	Learning Rate: 0.00998063
	LOSS [training: 4.2626355488270775 | validation: 4.683060156974226]
	TIME [epoch: 9.81 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.253953861524672		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 4.253953861524672 | validation: 4.961004059507989]
	TIME [epoch: 9.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.887576510985786		[learning rate: 0.0099324]
	Learning Rate: 0.00993236
	LOSS [training: 5.887576510985786 | validation: 5.2722016023165645]
	TIME [epoch: 9.82 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.7138442955440105		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 4.7138442955440105 | validation: 3.8199444469966592]
	TIME [epoch: 9.81 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.747805453291178		[learning rate: 0.0098843]
	Learning Rate: 0.00988433
	LOSS [training: 4.747805453291178 | validation: 8.402775312789686]
	TIME [epoch: 9.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.78965238447157		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 4.78965238447157 | validation: 4.021746761472196]
	TIME [epoch: 9.81 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.482758766960051		[learning rate: 0.0098365]
	Learning Rate: 0.00983653
	LOSS [training: 4.482758766960051 | validation: 5.847422376727935]
	TIME [epoch: 9.81 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.386505729664945		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 5.386505729664945 | validation: 4.967785149567024]
	TIME [epoch: 9.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.409586025407583		[learning rate: 0.009789]
	Learning Rate: 0.00978897
	LOSS [training: 4.409586025407583 | validation: 4.772581765227853]
	TIME [epoch: 9.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.862578648844645		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 3.862578648844645 | validation: 3.969615586812669]
	TIME [epoch: 9.82 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.561134093987804		[learning rate: 0.0097416]
	Learning Rate: 0.00974163
	LOSS [training: 4.561134093987804 | validation: 5.282163470308124]
	TIME [epoch: 9.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.592393801600593		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 6.592393801600593 | validation: 6.138993792310311]
	TIME [epoch: 9.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.804007788735904		[learning rate: 0.0096945]
	Learning Rate: 0.00969452
	LOSS [training: 5.804007788735904 | validation: 5.483901710437308]
	TIME [epoch: 9.81 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.309390260069936		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 5.309390260069936 | validation: 5.389085359785124]
	TIME [epoch: 9.82 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.189637737469964		[learning rate: 0.0096476]
	Learning Rate: 0.00964764
	LOSS [training: 5.189637737469964 | validation: 5.474635260718208]
	TIME [epoch: 9.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.842842351430828		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 5.842842351430828 | validation: 6.228561824692581]
	TIME [epoch: 9.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.509699574387403		[learning rate: 0.009601]
	Learning Rate: 0.00960098
	LOSS [training: 5.509699574387403 | validation: 6.513086944460541]
	TIME [epoch: 9.81 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.760529235814792		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 7.760529235814792 | validation: 6.958330683124061]
	TIME [epoch: 9.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.254138639275715		[learning rate: 0.0095546]
	Learning Rate: 0.00955456
	LOSS [training: 5.254138639275715 | validation: 5.630179515373133]
	TIME [epoch: 9.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.6551988177703665		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 4.6551988177703665 | validation: 5.5847804125904945]
	TIME [epoch: 9.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.99668243653303		[learning rate: 0.0095084]
	Learning Rate: 0.00950835
	LOSS [training: 4.99668243653303 | validation: 5.735597312679363]
	TIME [epoch: 9.82 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.338922384003331		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 6.338922384003331 | validation: 6.343951740908074]
	TIME [epoch: 9.81 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.105886631956155		[learning rate: 0.0094624]
	Learning Rate: 0.00946237
	LOSS [training: 5.105886631956155 | validation: 5.306141231359056]
	TIME [epoch: 9.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.306890143743145		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 5.306890143743145 | validation: 4.2892230971936]
	TIME [epoch: 9.82 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.407219422237079		[learning rate: 0.0094166]
	Learning Rate: 0.00941661
	LOSS [training: 4.407219422237079 | validation: 4.3058825660407924]
	TIME [epoch: 9.81 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.925217502156747		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 3.925217502156747 | validation: 4.269628883596009]
	TIME [epoch: 9.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.49489366604396		[learning rate: 0.0093711]
	Learning Rate: 0.00937108
	LOSS [training: 4.49489366604396 | validation: 6.060468694209186]
	TIME [epoch: 9.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.206657447368534		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 6.206657447368534 | validation: 6.145208266520069]
	TIME [epoch: 9.82 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.951337149879166		[learning rate: 0.0093258]
	Learning Rate: 0.00932576
	LOSS [training: 5.951337149879166 | validation: 7.0965957434677955]
	TIME [epoch: 9.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.163548292067654		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 7.163548292067654 | validation: 6.623977581779404]
	TIME [epoch: 9.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.049272473075168		[learning rate: 0.0092807]
	Learning Rate: 0.00928066
	LOSS [training: 6.049272473075168 | validation: 4.583244441188243]
	TIME [epoch: 9.82 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.152204712408366		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 4.152204712408366 | validation: 5.491352395008242]
	TIME [epoch: 9.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.732879823097062		[learning rate: 0.0092358]
	Learning Rate: 0.00923578
	LOSS [training: 4.732879823097062 | validation: 3.6877932563221987]
	TIME [epoch: 9.81 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.722947915901309		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 4.722947915901309 | validation: 6.427717300642987]
	TIME [epoch: 9.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.732357729610723		[learning rate: 0.0091911]
	Learning Rate: 0.00919112
	LOSS [training: 5.732357729610723 | validation: 5.575634456126545]
	TIME [epoch: 9.82 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.417250597251104		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 5.417250597251104 | validation: 5.122020179717904]
	TIME [epoch: 9.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.619869084274889		[learning rate: 0.0091467]
	Learning Rate: 0.00914667
	LOSS [training: 4.619869084274889 | validation: 4.326397246938637]
	TIME [epoch: 9.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9556557807884		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 3.9556557807884 | validation: 4.202126543997938]
	TIME [epoch: 9.82 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.04308575531567		[learning rate: 0.0091024]
	Learning Rate: 0.00910244
	LOSS [training: 4.04308575531567 | validation: 3.779491328223392]
	TIME [epoch: 9.81 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.047457930050951		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 4.047457930050951 | validation: 4.415925836638847]
	TIME [epoch: 9.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.117771718762482		[learning rate: 0.0090584]
	Learning Rate: 0.00905842
	LOSS [training: 4.117771718762482 | validation: 3.492137893652404]
	TIME [epoch: 9.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4400656800671654		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 3.4400656800671654 | validation: 3.0545344733281827]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_142.pth
	Model improved!!!
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0573113785933423		[learning rate: 0.0090146]
	Learning Rate: 0.00901462
	LOSS [training: 3.0573113785933423 | validation: 3.7792886025509826]
	TIME [epoch: 9.83 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5622252984449867		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 3.5622252984449867 | validation: 3.282246904571879]
	TIME [epoch: 9.82 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3872742543616168		[learning rate: 0.008971]
	Learning Rate: 0.00897103
	LOSS [training: 3.3872742543616168 | validation: 3.261067643759225]
	TIME [epoch: 9.83 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4360554366411336		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 3.4360554366411336 | validation: 3.5181132053486706]
	TIME [epoch: 9.83 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2740742107110767		[learning rate: 0.0089276]
	Learning Rate: 0.00892764
	LOSS [training: 3.2740742107110767 | validation: 3.4323615691677465]
	TIME [epoch: 9.82 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4760969006169424		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 3.4760969006169424 | validation: 3.2269253827933513]
	TIME [epoch: 9.82 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8867934516494054		[learning rate: 0.0088845]
	Learning Rate: 0.00888447
	LOSS [training: 2.8867934516494054 | validation: 2.7325908870996796]
	TIME [epoch: 9.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.080613087740541		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 3.080613087740541 | validation: 2.791268172755839]
	TIME [epoch: 9.82 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2755127264099095		[learning rate: 0.0088415]
	Learning Rate: 0.00884151
	LOSS [training: 3.2755127264099095 | validation: 2.736006841875042]
	TIME [epoch: 9.82 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6676258338629144		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 2.6676258338629144 | validation: 2.6454005420887574]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1935779780659876		[learning rate: 0.0087988]
	Learning Rate: 0.00879875
	LOSS [training: 3.1935779780659876 | validation: 3.0993895519994874]
	TIME [epoch: 9.83 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.916325338595748		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 2.916325338595748 | validation: 2.6264025527544472]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7258027491276953		[learning rate: 0.0087562]
	Learning Rate: 0.0087562
	LOSS [training: 2.7258027491276953 | validation: 2.639280787403862]
	TIME [epoch: 9.81 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9346769683693608		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 2.9346769683693608 | validation: 3.1052425756457507]
	TIME [epoch: 9.82 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6011588288945413		[learning rate: 0.0087139]
	Learning Rate: 0.00871386
	LOSS [training: 2.6011588288945413 | validation: 3.454586010047777]
	TIME [epoch: 9.81 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8815054796388884		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 2.8815054796388884 | validation: 4.099450731036099]
	TIME [epoch: 9.81 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6910958555979403		[learning rate: 0.0086717]
	Learning Rate: 0.00867172
	LOSS [training: 2.6910958555979403 | validation: 2.8647512448356474]
	TIME [epoch: 9.82 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5687466559707848		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 2.5687466559707848 | validation: 2.1473592499856915]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_160.pth
	Model improved!!!
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.218176649117579		[learning rate: 0.0086298]
	Learning Rate: 0.00862979
	LOSS [training: 2.218176649117579 | validation: 2.364435623608485]
	TIME [epoch: 9.81 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2938254204552875		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 2.2938254204552875 | validation: 2.2338878180742117]
	TIME [epoch: 9.81 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2863685468503996		[learning rate: 0.0085881]
	Learning Rate: 0.00858805
	LOSS [training: 2.2863685468503996 | validation: 5.3431746585781115]
	TIME [epoch: 9.83 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.264448336449057		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 3.264448336449057 | validation: 2.499912869677003]
	TIME [epoch: 9.81 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3588121783615117		[learning rate: 0.0085465]
	Learning Rate: 0.00854652
	LOSS [training: 2.3588121783615117 | validation: 2.351220830091494]
	TIME [epoch: 9.81 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9088327355348738		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 2.9088327355348738 | validation: 2.806821010194982]
	TIME [epoch: 9.81 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.456518884894523		[learning rate: 0.0085052]
	Learning Rate: 0.00850519
	LOSS [training: 2.456518884894523 | validation: 2.369932326813772]
	TIME [epoch: 9.82 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2154323555294293		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 2.2154323555294293 | validation: 2.5316381297912773]
	TIME [epoch: 9.81 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6816178717232275		[learning rate: 0.0084641]
	Learning Rate: 0.00846406
	LOSS [training: 2.6816178717232275 | validation: 3.5035430271958297]
	TIME [epoch: 9.81 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4720239389355108		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 2.4720239389355108 | validation: 2.426104419124394]
	TIME [epoch: 9.82 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.377767281975818		[learning rate: 0.0084231]
	Learning Rate: 0.00842313
	LOSS [training: 2.377767281975818 | validation: 2.166060375117269]
	TIME [epoch: 9.81 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7255946975781122		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 2.7255946975781122 | validation: 2.6046313742095304]
	TIME [epoch: 9.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.517032175353354		[learning rate: 0.0083824]
	Learning Rate: 0.0083824
	LOSS [training: 2.517032175353354 | validation: 3.064646854039653]
	TIME [epoch: 9.81 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4566286954317027		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 2.4566286954317027 | validation: 3.03602718760851]
	TIME [epoch: 9.82 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.386339831434783		[learning rate: 0.0083419]
	Learning Rate: 0.00834186
	LOSS [training: 2.386339831434783 | validation: 2.594852457029872]
	TIME [epoch: 9.81 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.352542911563936		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 3.352542911563936 | validation: 2.3138940491054503]
	TIME [epoch: 9.81 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5180439736183082		[learning rate: 0.0083015]
	Learning Rate: 0.00830153
	LOSS [training: 2.5180439736183082 | validation: 2.7470631234436786]
	TIME [epoch: 9.82 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.239280420626957		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 2.239280420626957 | validation: 2.262163679427448]
	TIME [epoch: 9.81 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2443391965026147		[learning rate: 0.0082614]
	Learning Rate: 0.00826138
	LOSS [training: 2.2443391965026147 | validation: 2.433804910109472]
	TIME [epoch: 9.81 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3388190453663165		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 2.3388190453663165 | validation: 2.700351749752362]
	TIME [epoch: 9.81 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.38991836361718		[learning rate: 0.0082214]
	Learning Rate: 0.00822143
	LOSS [training: 2.38991836361718 | validation: 3.2042112057271073]
	TIME [epoch: 9.83 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.289586519330048		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 2.289586519330048 | validation: 2.1393905480842657]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.251162627167596		[learning rate: 0.0081817]
	Learning Rate: 0.00818167
	LOSS [training: 2.251162627167596 | validation: 2.458209116416168]
	TIME [epoch: 9.81 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0895842003435865		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 2.0895842003435865 | validation: 2.382268211122574]
	TIME [epoch: 9.82 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9213106515059235		[learning rate: 0.0081421]
	Learning Rate: 0.00814211
	LOSS [training: 1.9213106515059235 | validation: 2.059578048283704]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.800638855059233		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.800638855059233 | validation: 1.8676947393976093]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4000946337601285		[learning rate: 0.0081027]
	Learning Rate: 0.00810273
	LOSS [training: 2.4000946337601285 | validation: 3.4819860215411076]
	TIME [epoch: 9.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5287157199180283		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 2.5287157199180283 | validation: 2.427241603586231]
	TIME [epoch: 9.81 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4975674450717458		[learning rate: 0.0080636]
	Learning Rate: 0.00806355
	LOSS [training: 2.4975674450717458 | validation: 3.234523346696578]
	TIME [epoch: 9.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.335393843861714		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 2.335393843861714 | validation: 2.489064645426563]
	TIME [epoch: 9.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3235980836873713		[learning rate: 0.0080246]
	Learning Rate: 0.00802456
	LOSS [training: 2.3235980836873713 | validation: 1.9317832020655312]
	TIME [epoch: 9.82 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.015110594908321		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 2.015110594908321 | validation: 3.0810889931692027]
	TIME [epoch: 9.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5319058557847334		[learning rate: 0.0079858]
	Learning Rate: 0.00798575
	LOSS [training: 2.5319058557847334 | validation: 2.6950505603692285]
	TIME [epoch: 9.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.129061408114525		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 2.129061408114525 | validation: 1.7039925697761238]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1278964709330466		[learning rate: 0.0079471]
	Learning Rate: 0.00794713
	LOSS [training: 2.1278964709330466 | validation: 1.826554633907203]
	TIME [epoch: 9.82 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8896630091282405		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.8896630091282405 | validation: 2.184045664745586]
	TIME [epoch: 9.79 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8472360779274222		[learning rate: 0.0079087]
	Learning Rate: 0.0079087
	LOSS [training: 1.8472360779274222 | validation: 2.0046561033115378]
	TIME [epoch: 9.79 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8646263388469457		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 1.8646263388469457 | validation: 1.724421167209161]
	TIME [epoch: 9.82 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1904184982791746		[learning rate: 0.0078705]
	Learning Rate: 0.00787046
	LOSS [training: 2.1904184982791746 | validation: 2.5249664461179133]
	TIME [epoch: 9.79 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9636369325675147		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.9636369325675147 | validation: 1.8981532532129646]
	TIME [epoch: 9.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0060758529487344		[learning rate: 0.0078324]
	Learning Rate: 0.0078324
	LOSS [training: 2.0060758529487344 | validation: 1.6376309406015832]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7771710300815056		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 1.7771710300815056 | validation: 1.7637207587805594]
	TIME [epoch: 9.84 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7803957658861116		[learning rate: 0.0077945]
	Learning Rate: 0.00779452
	LOSS [training: 1.7803957658861116 | validation: 1.95627900172134]
	TIME [epoch: 9.82 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.771227946890931		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.771227946890931 | validation: 1.5952133587905422]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2689372031341586		[learning rate: 0.0077568]
	Learning Rate: 0.00775683
	LOSS [training: 2.2689372031341586 | validation: 2.8502976648397476]
	TIME [epoch: 9.84 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9996855535890443		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.9996855535890443 | validation: 1.6475142411966328]
	TIME [epoch: 9.82 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6141387543505405		[learning rate: 0.0077193]
	Learning Rate: 0.00771932
	LOSS [training: 1.6141387543505405 | validation: 2.051248065244804]
	TIME [epoch: 9.81 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9925963042653092		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 1.9925963042653092 | validation: 2.214036070775312]
	TIME [epoch: 9.81 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9777705627098041		[learning rate: 0.007682]
	Learning Rate: 0.00768199
	LOSS [training: 1.9777705627098041 | validation: 2.086571216226275]
	TIME [epoch: 9.84 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.007684654356555		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 2.007684654356555 | validation: 2.649852521937573]
	TIME [epoch: 9.82 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.325267171387377		[learning rate: 0.0076448]
	Learning Rate: 0.00764484
	LOSS [training: 2.325267171387377 | validation: 2.1243385617616917]
	TIME [epoch: 9.81 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.064406276622786		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 2.064406276622786 | validation: 2.6733746065724846]
	TIME [epoch: 9.83 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8821082747884528		[learning rate: 0.0076079]
	Learning Rate: 0.00760787
	LOSS [training: 1.8821082747884528 | validation: 2.165660386254277]
	TIME [epoch: 9.83 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6330967892776524		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 1.6330967892776524 | validation: 2.1118175381476734]
	TIME [epoch: 9.82 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.767634987281004		[learning rate: 0.0075711]
	Learning Rate: 0.00757108
	LOSS [training: 1.767634987281004 | validation: 1.712517967689888]
	TIME [epoch: 9.82 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8876998756673196		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 1.8876998756673196 | validation: 1.6417520629379134]
	TIME [epoch: 9.84 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5205612793185292		[learning rate: 0.0075345]
	Learning Rate: 0.00753447
	LOSS [training: 1.5205612793185292 | validation: 2.0195009713844874]
	TIME [epoch: 9.82 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6459102368074454		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 1.6459102368074454 | validation: 2.888067511990799]
	TIME [epoch: 9.81 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9839804144139088		[learning rate: 0.007498]
	Learning Rate: 0.00749803
	LOSS [training: 1.9839804144139088 | validation: 1.8699560317737765]
	TIME [epoch: 9.82 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7489539617209189		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.7489539617209189 | validation: 3.0351889009708306]
	TIME [epoch: 9.83 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.494447588595644		[learning rate: 0.0074618]
	Learning Rate: 0.00746177
	LOSS [training: 2.494447588595644 | validation: 1.9822100053898402]
	TIME [epoch: 9.81 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9233737632905357		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 1.9233737632905357 | validation: 2.7862871557493456]
	TIME [epoch: 9.82 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9701506202132197		[learning rate: 0.0074257]
	Learning Rate: 0.00742569
	LOSS [training: 1.9701506202132197 | validation: 1.763774193689871]
	TIME [epoch: 9.84 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7168479064925257		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 1.7168479064925257 | validation: 1.9399432875082807]
	TIME [epoch: 9.82 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7152439275994797		[learning rate: 0.0073898]
	Learning Rate: 0.00738978
	LOSS [training: 1.7152439275994797 | validation: 2.018473347920149]
	TIME [epoch: 9.82 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0657099037705984		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 2.0657099037705984 | validation: 2.523551899905381]
	TIME [epoch: 9.82 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.202267006408621		[learning rate: 0.007354]
	Learning Rate: 0.00735405
	LOSS [training: 2.202267006408621 | validation: 1.3345169439880642]
	TIME [epoch: 9.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8031343841039131		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 1.8031343841039131 | validation: 2.656369143952079]
	TIME [epoch: 9.81 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.669298796076657		[learning rate: 0.0073185]
	Learning Rate: 0.00731848
	LOSS [training: 1.669298796076657 | validation: 1.480053988243338]
	TIME [epoch: 9.81 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5312958568165191		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.5312958568165191 | validation: 1.6998755767619644]
	TIME [epoch: 9.84 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6459274161929567		[learning rate: 0.0072831]
	Learning Rate: 0.00728309
	LOSS [training: 1.6459274161929567 | validation: 1.5831208782158106]
	TIME [epoch: 9.81 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6101185398120847		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 1.6101185398120847 | validation: 2.6677637334282647]
	TIME [epoch: 9.81 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9350541985400573		[learning rate: 0.0072479]
	Learning Rate: 0.00724787
	LOSS [training: 2.9350541985400573 | validation: 2.059593943577053]
	TIME [epoch: 9.81 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.919205936016833		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.919205936016833 | validation: 1.4754063127343024]
	TIME [epoch: 9.83 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6113532436462354		[learning rate: 0.0072128]
	Learning Rate: 0.00721282
	LOSS [training: 1.6113532436462354 | validation: 1.571785006412227]
	TIME [epoch: 9.81 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.877126362200834		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 1.877126362200834 | validation: 2.868372612813573]
	TIME [epoch: 9.81 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8695497880998526		[learning rate: 0.0071779]
	Learning Rate: 0.00717794
	LOSS [training: 1.8695497880998526 | validation: 1.7708090201935915]
	TIME [epoch: 9.83 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.619268623668201		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 1.619268623668201 | validation: 1.6610478320235331]
	TIME [epoch: 9.81 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.643298666935128		[learning rate: 0.0071432]
	Learning Rate: 0.00714323
	LOSS [training: 1.643298666935128 | validation: 2.4646415947134246]
	TIME [epoch: 9.81 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6569848633760167		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 1.6569848633760167 | validation: 1.4357037856788355]
	TIME [epoch: 9.81 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5222020971094639		[learning rate: 0.0071087]
	Learning Rate: 0.00710869
	LOSS [training: 1.5222020971094639 | validation: 1.3704020743573835]
	TIME [epoch: 9.82 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4399812074971021		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 1.4399812074971021 | validation: 1.6133405688235385]
	TIME [epoch: 9.81 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6257437276590323		[learning rate: 0.0070743]
	Learning Rate: 0.00707431
	LOSS [training: 1.6257437276590323 | validation: 1.3552922450331797]
	TIME [epoch: 9.8 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3542973903821278		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 1.3542973903821278 | validation: 1.3770186255912085]
	TIME [epoch: 9.83 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4186058447343652		[learning rate: 0.0070401]
	Learning Rate: 0.0070401
	LOSS [training: 1.4186058447343652 | validation: 1.1793332071411182]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_245.pth
	Model improved!!!
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2729765693464692		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.2729765693464692 | validation: 1.1703809993644922]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_246.pth
	Model improved!!!
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5220036269805128		[learning rate: 0.0070061]
	Learning Rate: 0.00700606
	LOSS [training: 1.5220036269805128 | validation: 1.9589933900498955]
	TIME [epoch: 9.81 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5639418575871558		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 1.5639418575871558 | validation: 1.5221044886057085]
	TIME [epoch: 9.83 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6059416830796622		[learning rate: 0.0069722]
	Learning Rate: 0.00697218
	LOSS [training: 1.6059416830796622 | validation: 2.1940836725846737]
	TIME [epoch: 9.81 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6141932434330655		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.6141932434330655 | validation: 1.634633844439871]
	TIME [epoch: 9.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4099397329572785		[learning rate: 0.0069385]
	Learning Rate: 0.00693846
	LOSS [training: 1.4099397329572785 | validation: 1.3991615976246856]
	TIME [epoch: 9.82 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3458646322507042		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 1.3458646322507042 | validation: 1.3699718634541966]
	TIME [epoch: 9.81 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6987065152214516		[learning rate: 0.0069049]
	Learning Rate: 0.00690491
	LOSS [training: 1.6987065152214516 | validation: 1.958311754222921]
	TIME [epoch: 9.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6388593034924075		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 1.6388593034924075 | validation: 1.575222458800219]
	TIME [epoch: 9.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.520448520223232		[learning rate: 0.0068715]
	Learning Rate: 0.00687152
	LOSS [training: 1.520448520223232 | validation: 1.3686212499933217]
	TIME [epoch: 9.82 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3078127499158743		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 1.3078127499158743 | validation: 2.0837712813679232]
	TIME [epoch: 9.81 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7718558989039384		[learning rate: 0.0068383]
	Learning Rate: 0.00683829
	LOSS [training: 1.7718558989039384 | validation: 1.3602111948945617]
	TIME [epoch: 9.81 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3827245735186804		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 1.3827245735186804 | validation: 1.908363690890355]
	TIME [epoch: 9.82 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.45639258982544		[learning rate: 0.0068052]
	Learning Rate: 0.00680522
	LOSS [training: 1.45639258982544 | validation: 1.30357830786408]
	TIME [epoch: 9.82 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2365842570553105		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.2365842570553105 | validation: 1.599615496707214]
	TIME [epoch: 9.81 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2615802159283347		[learning rate: 0.0067723]
	Learning Rate: 0.00677231
	LOSS [training: 1.2615802159283347 | validation: 1.1614263574077182]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_261.pth
	Model improved!!!
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.883851752168276		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 1.883851752168276 | validation: 1.5877436099070517]
	TIME [epoch: 9.83 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7194355908474346		[learning rate: 0.0067396]
	Learning Rate: 0.00673956
	LOSS [training: 1.7194355908474346 | validation: 1.6039230548439225]
	TIME [epoch: 9.81 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1902843785277173		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 1.1902843785277173 | validation: 1.5579661408733432]
	TIME [epoch: 9.82 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5786810542973162		[learning rate: 0.006707]
	Learning Rate: 0.00670697
	LOSS [training: 1.5786810542973162 | validation: 1.8082687288620378]
	TIME [epoch: 9.83 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.690276428629062		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 1.690276428629062 | validation: 1.6549305471868576]
	TIME [epoch: 9.83 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2533414681615374		[learning rate: 0.0066745]
	Learning Rate: 0.00667454
	LOSS [training: 1.2533414681615374 | validation: 1.19757941019964]
	TIME [epoch: 9.81 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1791352061228009		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 1.1791352061228009 | validation: 1.350328871334001]
	TIME [epoch: 9.81 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.285541677170298		[learning rate: 0.0066423]
	Learning Rate: 0.00664226
	LOSS [training: 1.285541677170298 | validation: 1.1635248965399891]
	TIME [epoch: 9.82 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2160596254428742		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 1.2160596254428742 | validation: 1.5807139396279335]
	TIME [epoch: 9.82 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.393828996786053		[learning rate: 0.0066101]
	Learning Rate: 0.00661014
	LOSS [training: 2.393828996786053 | validation: 2.0588524768578544]
	TIME [epoch: 9.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8299288919276198		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 1.8299288919276198 | validation: 1.9681992744266585]
	TIME [epoch: 9.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7243087732143834		[learning rate: 0.0065782]
	Learning Rate: 0.00657817
	LOSS [training: 1.7243087732143834 | validation: 1.5094766930509846]
	TIME [epoch: 9.82 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4183353251767825		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 1.4183353251767825 | validation: 1.7007951209999237]
	TIME [epoch: 9.81 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.522730897721157		[learning rate: 0.0065464]
	Learning Rate: 0.00654636
	LOSS [training: 1.522730897721157 | validation: 1.6987640558468382]
	TIME [epoch: 9.81 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.432768374716819		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.432768374716819 | validation: 1.2283071331930662]
	TIME [epoch: 9.83 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2156029908675061		[learning rate: 0.0065147]
	Learning Rate: 0.0065147
	LOSS [training: 1.2156029908675061 | validation: 1.0572949222263401]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_277.pth
	Model improved!!!
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.217657656722174		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 1.217657656722174 | validation: 1.4871023771989187]
	TIME [epoch: 9.81 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3085420499248528		[learning rate: 0.0064832]
	Learning Rate: 0.0064832
	LOSS [training: 1.3085420499248528 | validation: 1.7800318153805825]
	TIME [epoch: 9.81 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.766530096619118		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 1.766530096619118 | validation: 1.266070635489685]
	TIME [epoch: 9.82 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2216877561901645		[learning rate: 0.0064518]
	Learning Rate: 0.00645185
	LOSS [training: 1.2216877561901645 | validation: 1.1423587186793662]
	TIME [epoch: 9.81 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6033781030515613		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 1.6033781030515613 | validation: 1.3648372244374607]
	TIME [epoch: 9.81 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3448197705022986		[learning rate: 0.0064206]
	Learning Rate: 0.00642065
	LOSS [training: 1.3448197705022986 | validation: 1.8383132806362448]
	TIME [epoch: 9.83 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5832325846777722		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.5832325846777722 | validation: 2.5317308634187725]
	TIME [epoch: 9.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4324447228373756		[learning rate: 0.0063896]
	Learning Rate: 0.0063896
	LOSS [training: 1.4324447228373756 | validation: 1.3252420844592467]
	TIME [epoch: 9.81 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.331707702405423		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 1.331707702405423 | validation: 1.480578179700757]
	TIME [epoch: 9.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.336360994453703		[learning rate: 0.0063587]
	Learning Rate: 0.0063587
	LOSS [training: 1.336360994453703 | validation: 1.3171531839943027]
	TIME [epoch: 9.82 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2764300404431785		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 1.2764300404431785 | validation: 1.329546328965921]
	TIME [epoch: 9.81 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.234558993926776		[learning rate: 0.006328]
	Learning Rate: 0.00632795
	LOSS [training: 1.234558993926776 | validation: 1.3119220997788916]
	TIME [epoch: 9.81 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3853396404273082		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 1.3853396404273082 | validation: 2.093144314444087]
	TIME [epoch: 9.83 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.776879528048185		[learning rate: 0.0062974]
	Learning Rate: 0.00629735
	LOSS [training: 1.776879528048185 | validation: 1.6935325055403372]
	TIME [epoch: 9.81 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5308324779865952		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 1.5308324779865952 | validation: 1.4970531432609926]
	TIME [epoch: 9.81 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1692648426718875		[learning rate: 0.0062669]
	Learning Rate: 0.0062669
	LOSS [training: 1.1692648426718875 | validation: 1.4509807785112048]
	TIME [epoch: 9.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5306688462353717		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 1.5306688462353717 | validation: 1.811384918041501]
	TIME [epoch: 9.82 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.488794364255345		[learning rate: 0.0062366]
	Learning Rate: 0.00623659
	LOSS [training: 1.488794364255345 | validation: 1.1355585324727604]
	TIME [epoch: 9.81 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.190719877610035		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.190719877610035 | validation: 1.5419064518996894]
	TIME [epoch: 9.81 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1310439532608059		[learning rate: 0.0062064]
	Learning Rate: 0.00620643
	LOSS [training: 1.1310439532608059 | validation: 1.3028322889702832]
	TIME [epoch: 9.81 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.099828784540597		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 1.099828784540597 | validation: 1.5148489949588355]
	TIME [epoch: 9.82 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3352069975755925		[learning rate: 0.0061764]
	Learning Rate: 0.00617642
	LOSS [training: 1.3352069975755925 | validation: 1.067582962046673]
	TIME [epoch: 9.81 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1565663203728445		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 1.1565663203728445 | validation: 1.5694328775158317]
	TIME [epoch: 9.81 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1978269678321147		[learning rate: 0.0061466]
	Learning Rate: 0.00614655
	LOSS [training: 1.1978269678321147 | validation: 1.192160417787358]
	TIME [epoch: 9.83 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2054661392447295		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 1.2054661392447295 | validation: 1.2805088599304952]
	TIME [epoch: 9.81 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1391882862740226		[learning rate: 0.0061168]
	Learning Rate: 0.00611683
	LOSS [training: 1.1391882862740226 | validation: 1.1817040574524245]
	TIME [epoch: 9.81 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3418248988685837		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 1.3418248988685837 | validation: 1.9611142786020772]
	TIME [epoch: 9.82 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2064811926521035		[learning rate: 0.0060872]
	Learning Rate: 0.00608725
	LOSS [training: 1.2064811926521035 | validation: 0.9934571240557702]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_305.pth
	Model improved!!!
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0960172971806617		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 1.0960172971806617 | validation: 1.041179516253502]
	TIME [epoch: 9.81 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1295607487522152		[learning rate: 0.0060578]
	Learning Rate: 0.00605781
	LOSS [training: 1.1295607487522152 | validation: 0.9694449247308009]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.045992893778669		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 1.045992893778669 | validation: 1.6168743712202451]
	TIME [epoch: 9.84 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3894589994372288		[learning rate: 0.0060285]
	Learning Rate: 0.00602852
	LOSS [training: 1.3894589994372288 | validation: 1.2673696866192088]
	TIME [epoch: 9.82 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2147611647876766		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 1.2147611647876766 | validation: 1.1156895791656227]
	TIME [epoch: 9.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0566700699638754		[learning rate: 0.0059994]
	Learning Rate: 0.00599936
	LOSS [training: 1.0566700699638754 | validation: 1.0436715141238642]
	TIME [epoch: 9.81 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0782371331906677		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.0782371331906677 | validation: 1.492121265521088]
	TIME [epoch: 9.81 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1377946820632214		[learning rate: 0.0059704]
	Learning Rate: 0.00597035
	LOSS [training: 1.1377946820632214 | validation: 1.0194585869807349]
	TIME [epoch: 9.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7573994225291063		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 1.7573994225291063 | validation: 2.907646184697845]
	TIME [epoch: 9.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.19557560495		[learning rate: 0.0059415]
	Learning Rate: 0.00594148
	LOSS [training: 2.19557560495 | validation: 2.1667824637464026]
	TIME [epoch: 9.82 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7181171530011405		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 1.7181171530011405 | validation: 1.5677757806968096]
	TIME [epoch: 9.81 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4680288249217976		[learning rate: 0.0059127]
	Learning Rate: 0.00591275
	LOSS [training: 1.4680288249217976 | validation: 1.4351514389648135]
	TIME [epoch: 9.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3002015860817018		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 1.3002015860817018 | validation: 1.2766446216878695]
	TIME [epoch: 9.81 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2506394898490203		[learning rate: 0.0058842]
	Learning Rate: 0.00588416
	LOSS [training: 1.2506394898490203 | validation: 1.583034568605463]
	TIME [epoch: 9.82 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3733196775880487		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 1.3733196775880487 | validation: 1.2670588528780582]
	TIME [epoch: 9.79 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1311622149349556		[learning rate: 0.0058557]
	Learning Rate: 0.0058557
	LOSS [training: 1.1311622149349556 | validation: 1.0751668205323646]
	TIME [epoch: 9.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0677154928129051		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 1.0677154928129051 | validation: 1.7280078767831415]
	TIME [epoch: 9.83 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.194614243091902		[learning rate: 0.0058274]
	Learning Rate: 0.00582738
	LOSS [training: 1.194614243091902 | validation: 1.274013871647001]
	TIME [epoch: 9.81 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9837181304564677		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.9837181304564677 | validation: 1.875372578764623]
	TIME [epoch: 9.81 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0345478989258248		[learning rate: 0.0057992]
	Learning Rate: 0.0057992
	LOSS [training: 1.0345478989258248 | validation: 1.4658908494368024]
	TIME [epoch: 9.79 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2289062388847518		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 1.2289062388847518 | validation: 1.2394821906974867]
	TIME [epoch: 9.82 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.353277061240305		[learning rate: 0.0057712]
	Learning Rate: 0.00577116
	LOSS [training: 1.353277061240305 | validation: 2.401964431236049]
	TIME [epoch: 9.79 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6385841798738656		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 1.6385841798738656 | validation: 0.9386412027953063]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5431490871284386		[learning rate: 0.0057433]
	Learning Rate: 0.00574325
	LOSS [training: 1.5431490871284386 | validation: 1.1704817918813897]
	TIME [epoch: 9.82 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.325364180766675		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 1.325364180766675 | validation: 1.6469022940955989]
	TIME [epoch: 9.81 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3910898058830936		[learning rate: 0.0057155]
	Learning Rate: 0.00571548
	LOSS [training: 1.3910898058830936 | validation: 1.2610252181311836]
	TIME [epoch: 9.79 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.077696304025752		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 1.077696304025752 | validation: 1.3735835707985808]
	TIME [epoch: 9.81 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3034354538464306		[learning rate: 0.0056878]
	Learning Rate: 0.00568784
	LOSS [training: 1.3034354538464306 | validation: 1.5414577874171256]
	TIME [epoch: 9.81 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.097926964941173		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 1.097926964941173 | validation: 0.8103621737674985]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_334.pth
	Model improved!!!
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.963422000197028		[learning rate: 0.0056603]
	Learning Rate: 0.00566033
	LOSS [training: 0.963422000197028 | validation: 1.3432521937035704]
	TIME [epoch: 9.81 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3324969461118867		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 1.3324969461118867 | validation: 1.105168599046787]
	TIME [epoch: 9.82 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.91968481011409		[learning rate: 0.005633]
	Learning Rate: 0.00563296
	LOSS [training: 0.91968481011409 | validation: 1.9561947839771485]
	TIME [epoch: 9.82 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3578430789693818		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 1.3578430789693818 | validation: 1.3735107853637687]
	TIME [epoch: 9.81 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0178769970708832		[learning rate: 0.0056057]
	Learning Rate: 0.00560572
	LOSS [training: 1.0178769970708832 | validation: 0.9912966119181934]
	TIME [epoch: 9.81 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1498301896065062		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 1.1498301896065062 | validation: 1.0451818977057685]
	TIME [epoch: 9.83 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1976749215779612		[learning rate: 0.0055786]
	Learning Rate: 0.00557861
	LOSS [training: 1.1976749215779612 | validation: 1.56324388381877]
	TIME [epoch: 9.81 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6620455061411845		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 1.6620455061411845 | validation: 3.0064304420718044]
	TIME [epoch: 9.81 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0123433924564895		[learning rate: 0.0055516]
	Learning Rate: 0.00555164
	LOSS [training: 2.0123433924564895 | validation: 1.039747226875706]
	TIME [epoch: 9.83 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.902970731811071		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 1.902970731811071 | validation: 1.6744826713567198]
	TIME [epoch: 9.81 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6443134592388102		[learning rate: 0.0055248]
	Learning Rate: 0.00552479
	LOSS [training: 1.6443134592388102 | validation: 1.2435874666302906]
	TIME [epoch: 9.81 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.278426822763682		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 1.278426822763682 | validation: 0.8082893214415515]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_346.pth
	Model improved!!!
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9433185160902571		[learning rate: 0.0054981]
	Learning Rate: 0.00549807
	LOSS [training: 0.9433185160902571 | validation: 1.257675651065945]
	TIME [epoch: 9.83 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9848850610625437		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.9848850610625437 | validation: 1.0231165390930415]
	TIME [epoch: 9.81 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8171045471732018		[learning rate: 0.0054715]
	Learning Rate: 0.00547149
	LOSS [training: 0.8171045471732018 | validation: 1.4376835828336891]
	TIME [epoch: 9.81 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.908700425436758		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.908700425436758 | validation: 1.8345230993181643]
	TIME [epoch: 9.83 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.121509213701733		[learning rate: 0.005445]
	Learning Rate: 0.00544503
	LOSS [training: 1.121509213701733 | validation: 0.9932131485381809]
	TIME [epoch: 9.81 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8048230476782454		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.8048230476782454 | validation: 0.9433938719584543]
	TIME [epoch: 9.81 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0962474238201583		[learning rate: 0.0054187]
	Learning Rate: 0.0054187
	LOSS [training: 1.0962474238201583 | validation: 1.2632743910352664]
	TIME [epoch: 9.81 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0752350928149823		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 1.0752350928149823 | validation: 1.659596498059081]
	TIME [epoch: 9.83 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1490758516201185		[learning rate: 0.0053925]
	Learning Rate: 0.00539249
	LOSS [training: 1.1490758516201185 | validation: 1.5489103463483773]
	TIME [epoch: 9.81 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3986047954001724		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 1.3986047954001724 | validation: 3.1305133109658834]
	TIME [epoch: 9.81 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7363589298480655		[learning rate: 0.0053664]
	Learning Rate: 0.00536641
	LOSS [training: 1.7363589298480655 | validation: 0.8686146953561118]
	TIME [epoch: 9.82 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0620047284221563		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 1.0620047284221563 | validation: 0.7283762263705705]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_358.pth
	Model improved!!!
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.014129363764994		[learning rate: 0.0053405]
	Learning Rate: 0.00534046
	LOSS [training: 1.014129363764994 | validation: 0.8978536679861295]
	TIME [epoch: 9.81 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9526524646262955		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.9526524646262955 | validation: 1.7592639314745555]
	TIME [epoch: 9.81 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.209285225488114		[learning rate: 0.0053146]
	Learning Rate: 0.00531464
	LOSS [training: 1.209285225488114 | validation: 0.8704693336641338]
	TIME [epoch: 9.82 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.909609532593133		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.909609532593133 | validation: 2.0973338072425243]
	TIME [epoch: 9.81 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.127371768541889		[learning rate: 0.0052889]
	Learning Rate: 0.00528894
	LOSS [training: 2.127371768541889 | validation: 1.644514926011968]
	TIME [epoch: 9.81 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2751706535430214		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 1.2751706535430214 | validation: 0.9786680703603345]
	TIME [epoch: 9.81 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9650480881770627		[learning rate: 0.0052634]
	Learning Rate: 0.00526336
	LOSS [training: 0.9650480881770627 | validation: 2.060002242900497]
	TIME [epoch: 9.81 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2940926844832106		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 1.2940926844832106 | validation: 1.166973610590975]
	TIME [epoch: 9.81 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9279130893334526		[learning rate: 0.0052379]
	Learning Rate: 0.00523791
	LOSS [training: 0.9279130893334526 | validation: 1.0502049803172004]
	TIME [epoch: 9.81 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9107681353055384		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.9107681353055384 | validation: 1.0409484240616482]
	TIME [epoch: 9.82 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9140936872423726		[learning rate: 0.0052126]
	Learning Rate: 0.00521258
	LOSS [training: 0.9140936872423726 | validation: 1.6266691275749987]
	TIME [epoch: 9.81 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8986696139988212		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.8986696139988212 | validation: 0.8361554085084637]
	TIME [epoch: 9.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7900904123381596		[learning rate: 0.0051874]
	Learning Rate: 0.00518737
	LOSS [training: 0.7900904123381596 | validation: 1.6585252113510016]
	TIME [epoch: 9.81 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5512141816949248		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 1.5512141816949248 | validation: 1.251173893538616]
	TIME [epoch: 9.82 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0708109484583264		[learning rate: 0.0051623]
	Learning Rate: 0.00516229
	LOSS [training: 1.0708109484583264 | validation: 0.9140299285422611]
	TIME [epoch: 9.81 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0805082565616004		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 1.0805082565616004 | validation: 1.0843691180418942]
	TIME [epoch: 9.81 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1243406129293387		[learning rate: 0.0051373]
	Learning Rate: 0.00513732
	LOSS [training: 1.1243406129293387 | validation: 0.8982865684291107]
	TIME [epoch: 9.82 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0648692780673452		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 1.0648692780673452 | validation: 0.8591813260464484]
	TIME [epoch: 9.81 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0657671989460078		[learning rate: 0.0051125]
	Learning Rate: 0.00511248
	LOSS [training: 1.0657671989460078 | validation: 1.9326331226960622]
	TIME [epoch: 9.81 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.636251512139498		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 1.636251512139498 | validation: 1.8826456464402168]
	TIME [epoch: 9.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6130236703181158		[learning rate: 0.0050878]
	Learning Rate: 0.00508776
	LOSS [training: 1.6130236703181158 | validation: 1.9678639789472443]
	TIME [epoch: 9.83 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.651486379846141		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 1.651486379846141 | validation: 1.9540924736199827]
	TIME [epoch: 9.81 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3922461473703278		[learning rate: 0.0050632]
	Learning Rate: 0.00506315
	LOSS [training: 1.3922461473703278 | validation: 1.6927587454386632]
	TIME [epoch: 9.81 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4579021123892137		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 1.4579021123892137 | validation: 1.0608377085138552]
	TIME [epoch: 9.82 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.041754833702679		[learning rate: 0.0050387]
	Learning Rate: 0.00503867
	LOSS [training: 1.041754833702679 | validation: 1.0249871810434446]
	TIME [epoch: 9.81 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0033718202853925		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 1.0033718202853925 | validation: 1.1745261760534673]
	TIME [epoch: 9.81 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2315817993221443		[learning rate: 0.0050143]
	Learning Rate: 0.0050143
	LOSS [training: 1.2315817993221443 | validation: 0.9928216195271332]
	TIME [epoch: 9.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0539006139006346		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 1.0539006139006346 | validation: 1.4332152311399577]
	TIME [epoch: 9.82 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0323958048664537		[learning rate: 0.0049901]
	Learning Rate: 0.00499005
	LOSS [training: 1.0323958048664537 | validation: 0.9770298694507327]
	TIME [epoch: 9.81 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9913303060690815		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.9913303060690815 | validation: 1.2750447198030703]
	TIME [epoch: 9.81 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9823068779540552		[learning rate: 0.0049659]
	Learning Rate: 0.00496592
	LOSS [training: 0.9823068779540552 | validation: 1.4508860622679791]
	TIME [epoch: 9.82 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.915712109480522		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.915712109480522 | validation: 1.1595543678013318]
	TIME [epoch: 9.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9658735632182152		[learning rate: 0.0049419]
	Learning Rate: 0.00494191
	LOSS [training: 0.9658735632182152 | validation: 0.9397059696299529]
	TIME [epoch: 9.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8339291025114554		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.8339291025114554 | validation: 1.7918312459125252]
	TIME [epoch: 9.81 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1599232985225374		[learning rate: 0.004918]
	Learning Rate: 0.00491801
	LOSS [training: 1.1599232985225374 | validation: 0.7680838347066876]
	TIME [epoch: 9.82 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8355435554657147		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.8355435554657147 | validation: 0.9153659278072386]
	TIME [epoch: 9.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.116764889489113		[learning rate: 0.0048942]
	Learning Rate: 0.00489423
	LOSS [training: 1.116764889489113 | validation: 1.0313487682925324]
	TIME [epoch: 9.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.241815631923917		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 1.241815631923917 | validation: 1.0217930255257477]
	TIME [epoch: 9.81 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2231465714710885		[learning rate: 0.0048706]
	Learning Rate: 0.00487056
	LOSS [training: 1.2231465714710885 | validation: 1.9933808137893123]
	TIME [epoch: 9.81 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2252545737704519		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 1.2252545737704519 | validation: 0.9299066500821666]
	TIME [epoch: 9.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9579102415026808		[learning rate: 0.004847]
	Learning Rate: 0.00484701
	LOSS [training: 0.9579102415026808 | validation: 1.416881411783178]
	TIME [epoch: 9.81 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9456290797369608		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.9456290797369608 | validation: 1.281723587443902]
	TIME [epoch: 9.82 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1164251636425504		[learning rate: 0.0048236]
	Learning Rate: 0.00482357
	LOSS [training: 1.1164251636425504 | validation: 1.262153810408368]
	TIME [epoch: 9.81 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0381943377654346		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 1.0381943377654346 | validation: 1.0936629056093292]
	TIME [epoch: 9.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8126795658936597		[learning rate: 0.0048002]
	Learning Rate: 0.00480024
	LOSS [training: 0.8126795658936597 | validation: 1.227826335370533]
	TIME [epoch: 9.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2847679862247647		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 1.2847679862247647 | validation: 1.0172692913543444]
	TIME [epoch: 9.82 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.205534308152594		[learning rate: 0.004777]
	Learning Rate: 0.00477703
	LOSS [training: 1.205534308152594 | validation: 1.004307939837023]
	TIME [epoch: 9.81 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6904310087972537		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.6904310087972537 | validation: 1.0237503226393871]
	TIME [epoch: 9.81 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9529652345527084		[learning rate: 0.0047539]
	Learning Rate: 0.00475393
	LOSS [training: 0.9529652345527084 | validation: 1.1818307290464005]
	TIME [epoch: 9.82 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.047024002419981		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 1.047024002419981 | validation: 1.2766574507589667]
	TIME [epoch: 9.81 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9817677151684754		[learning rate: 0.0047309]
	Learning Rate: 0.00473094
	LOSS [training: 0.9817677151684754 | validation: 1.1423931633414726]
	TIME [epoch: 9.81 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9473451138153957		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.9473451138153957 | validation: 0.5936254709854104]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_410.pth
	Model improved!!!
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9615286232867071		[learning rate: 0.0047081]
	Learning Rate: 0.00470806
	LOSS [training: 0.9615286232867071 | validation: 1.072280640637436]
	TIME [epoch: 9.82 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8945073101361742		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.8945073101361742 | validation: 0.7410638422925812]
	TIME [epoch: 9.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9706135634478332		[learning rate: 0.0046853]
	Learning Rate: 0.00468529
	LOSS [training: 0.9706135634478332 | validation: 0.7335526625078609]
	TIME [epoch: 9.81 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0241683642459962		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 1.0241683642459962 | validation: 0.6680542560423052]
	TIME [epoch: 9.82 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8632599928408803		[learning rate: 0.0046626]
	Learning Rate: 0.00466264
	LOSS [training: 0.8632599928408803 | validation: 0.8033222103378116]
	TIME [epoch: 9.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7740017052288766		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.7740017052288766 | validation: 0.661660750944799]
	TIME [epoch: 9.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8127569785863237		[learning rate: 0.0046401]
	Learning Rate: 0.00464009
	LOSS [training: 0.8127569785863237 | validation: 0.9093117512061634]
	TIME [epoch: 9.81 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7783477837447184		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.7783477837447184 | validation: 0.8257212324559816]
	TIME [epoch: 9.82 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8929319960947314		[learning rate: 0.0046177]
	Learning Rate: 0.00461765
	LOSS [training: 0.8929319960947314 | validation: 0.812559145780478]
	TIME [epoch: 9.79 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8486092387516078		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.8486092387516078 | validation: 1.957933801658976]
	TIME [epoch: 9.78 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3736743595235616		[learning rate: 0.0045953]
	Learning Rate: 0.00459532
	LOSS [training: 1.3736743595235616 | validation: 0.9112231897555103]
	TIME [epoch: 9.81 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6674596825881214		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 1.6674596825881214 | validation: 0.5984447618094284]
	TIME [epoch: 9.81 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8892313029870849		[learning rate: 0.0045731]
	Learning Rate: 0.0045731
	LOSS [training: 0.8892313029870849 | validation: 0.6544686051325768]
	TIME [epoch: 9.81 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7539244746519844		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.7539244746519844 | validation: 0.7179255888952925]
	TIME [epoch: 9.79 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8756092089102381		[learning rate: 0.004551]
	Learning Rate: 0.00455098
	LOSS [training: 0.8756092089102381 | validation: 0.8199890187949904]
	TIME [epoch: 9.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7587181615594684		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.7587181615594684 | validation: 0.8729835252302729]
	TIME [epoch: 9.81 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7080101299481711		[learning rate: 0.004529]
	Learning Rate: 0.00452898
	LOSS [training: 0.7080101299481711 | validation: 0.7451887971490412]
	TIME [epoch: 9.79 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6894556332150191		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.6894556332150191 | validation: 0.8204704751506887]
	TIME [epoch: 9.81 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5860589187611025		[learning rate: 0.0045071]
	Learning Rate: 0.00450707
	LOSS [training: 0.5860589187611025 | validation: 0.6024763026493468]
	TIME [epoch: 9.81 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7188933402060668		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.7188933402060668 | validation: 1.545301034182823]
	TIME [epoch: 9.78 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5326672910086656		[learning rate: 0.0044853]
	Learning Rate: 0.00448528
	LOSS [training: 1.5326672910086656 | validation: 0.8907115560875656]
	TIME [epoch: 9.81 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8890776173020306		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.8890776173020306 | validation: 1.5213754620029654]
	TIME [epoch: 9.82 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1386455697114333		[learning rate: 0.0044636]
	Learning Rate: 0.00446359
	LOSS [training: 1.1386455697114333 | validation: 1.109344919678723]
	TIME [epoch: 9.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7321465213228252		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.7321465213228252 | validation: 0.6078872879556476]
	TIME [epoch: 9.79 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1779481994783763		[learning rate: 0.004442]
	Learning Rate: 0.004442
	LOSS [training: 1.1779481994783763 | validation: 0.57245401270384]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_435.pth
	Model improved!!!
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8636029249679353		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.8636029249679353 | validation: 1.2280017529696527]
	TIME [epoch: 9.81 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8131876024609597		[learning rate: 0.0044205]
	Learning Rate: 0.00442052
	LOSS [training: 0.8131876024609597 | validation: 0.8440562091079997]
	TIME [epoch: 9.79 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7749034418017174		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.7749034418017174 | validation: 0.7974689454360823]
	TIME [epoch: 9.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0134057833522618		[learning rate: 0.0043991]
	Learning Rate: 0.00439915
	LOSS [training: 1.0134057833522618 | validation: 1.5552192551015669]
	TIME [epoch: 9.81 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8057469746715678		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.8057469746715678 | validation: 0.9152463846566957]
	TIME [epoch: 9.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9224465231869943		[learning rate: 0.0043779]
	Learning Rate: 0.00437787
	LOSS [training: 0.9224465231869943 | validation: 0.553205899022369]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_441.pth
	Model improved!!!
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5776671117427221		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.5776671117427221 | validation: 0.9740513900859558]
	TIME [epoch: 9.81 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6050794299573165		[learning rate: 0.0043567]
	Learning Rate: 0.0043567
	LOSS [training: 0.6050794299573165 | validation: 0.7482720668906151]
	TIME [epoch: 9.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3262088726789143		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 2.3262088726789143 | validation: 1.1203299193925782]
	TIME [epoch: 9.79 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7227471730345748		[learning rate: 0.0043356]
	Learning Rate: 0.00433563
	LOSS [training: 0.7227471730345748 | validation: 0.6825112441934246]
	TIME [epoch: 9.79 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6970484543759021		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.6970484543759021 | validation: 1.3950296636857449]
	TIME [epoch: 9.81 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7510658628735691		[learning rate: 0.0043147]
	Learning Rate: 0.00431467
	LOSS [training: 0.7510658628735691 | validation: 0.7269655697717139]
	TIME [epoch: 9.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6309319488731877		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.6309319488731877 | validation: 0.8398837292931907]
	TIME [epoch: 9.79 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7554659166177033		[learning rate: 0.0042938]
	Learning Rate: 0.0042938
	LOSS [training: 0.7554659166177033 | validation: 1.1902250926306988]
	TIME [epoch: 9.79 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8371721401422189		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.8371721401422189 | validation: 0.8426400007799053]
	TIME [epoch: 9.82 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6378934214453842		[learning rate: 0.004273]
	Learning Rate: 0.00427304
	LOSS [training: 0.6378934214453842 | validation: 0.7755925270100831]
	TIME [epoch: 9.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9472236312656819		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.9472236312656819 | validation: 0.7776204157028263]
	TIME [epoch: 9.79 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6657316682733049		[learning rate: 0.0042524]
	Learning Rate: 0.00425238
	LOSS [training: 0.6657316682733049 | validation: 1.2126213325498123]
	TIME [epoch: 9.81 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7893980557175365		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.7893980557175365 | validation: 0.6742474277711705]
	TIME [epoch: 9.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6996053497039502		[learning rate: 0.0042318]
	Learning Rate: 0.00423181
	LOSS [training: 0.6996053497039502 | validation: 1.0391375007432138]
	TIME [epoch: 9.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6825478264171646		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.6825478264171646 | validation: 1.0160542591069652]
	TIME [epoch: 9.79 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.568310263368908		[learning rate: 0.0042113]
	Learning Rate: 0.00421135
	LOSS [training: 0.568310263368908 | validation: 0.7825702754667182]
	TIME [epoch: 9.82 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7308082557247182		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.7308082557247182 | validation: 1.1065416342264276]
	TIME [epoch: 9.8 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.643520032394963		[learning rate: 0.004191]
	Learning Rate: 0.00419098
	LOSS [training: 0.643520032394963 | validation: 0.6592861849723023]
	TIME [epoch: 9.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5848383218168328		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.5848383218168328 | validation: 1.178984178539014]
	TIME [epoch: 9.81 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.882933314656564		[learning rate: 0.0041707]
	Learning Rate: 0.00417071
	LOSS [training: 0.882933314656564 | validation: 1.2136383840126492]
	TIME [epoch: 9.8 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8631419645941854		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.8631419645941854 | validation: 0.8883484822472218]
	TIME [epoch: 9.79 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9559999334105734		[learning rate: 0.0041505]
	Learning Rate: 0.00415055
	LOSS [training: 0.9559999334105734 | validation: 0.6655788391323573]
	TIME [epoch: 9.79 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8721869020486291		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.8721869020486291 | validation: 1.0269234496619033]
	TIME [epoch: 9.81 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5747410480014503		[learning rate: 0.0041305]
	Learning Rate: 0.00413047
	LOSS [training: 0.5747410480014503 | validation: 0.9442260897307284]
	TIME [epoch: 9.8 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.608729184154536		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.608729184154536 | validation: 0.505569780050087]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_466.pth
	Model improved!!!
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5610612131629568		[learning rate: 0.0041105]
	Learning Rate: 0.0041105
	LOSS [training: 0.5610612131629568 | validation: 0.9174897818750678]
	TIME [epoch: 9.82 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6795404371740524		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.6795404371740524 | validation: 1.673849224847582]
	TIME [epoch: 9.79 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.107886566082892		[learning rate: 0.0040906]
	Learning Rate: 0.00409062
	LOSS [training: 1.107886566082892 | validation: 1.4865531645448107]
	TIME [epoch: 9.79 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9963328150648568		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.9963328150648568 | validation: 1.103034194696674]
	TIME [epoch: 9.79 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6390910268915999		[learning rate: 0.0040708]
	Learning Rate: 0.00407084
	LOSS [training: 0.6390910268915999 | validation: 0.6396080709766578]
	TIME [epoch: 9.8 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6177804456429362		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.6177804456429362 | validation: 0.6123594586775915]
	TIME [epoch: 9.79 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5701794040713225		[learning rate: 0.0040512]
	Learning Rate: 0.00405116
	LOSS [training: 0.5701794040713225 | validation: 0.5945110865806261]
	TIME [epoch: 9.79 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8575518364850192		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.8575518364850192 | validation: 0.5009653958265382]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_474.pth
	Model improved!!!
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4913687152578203		[learning rate: 0.0040316]
	Learning Rate: 0.00403157
	LOSS [training: 0.4913687152578203 | validation: 0.7725192188756974]
	TIME [epoch: 9.81 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7876081131071168		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.7876081131071168 | validation: 1.0346002421572236]
	TIME [epoch: 9.79 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7166828542547907		[learning rate: 0.0040121]
	Learning Rate: 0.00401207
	LOSS [training: 0.7166828542547907 | validation: 0.5483612173135505]
	TIME [epoch: 9.8 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6430285677991685		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.6430285677991685 | validation: 0.4952587468377675]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5315005819181732		[learning rate: 0.0039927]
	Learning Rate: 0.00399267
	LOSS [training: 0.5315005819181732 | validation: 0.5309109335909028]
	TIME [epoch: 9.81 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5258150898903688		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.5258150898903688 | validation: 1.0009497010719117]
	TIME [epoch: 9.79 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5652289406752053		[learning rate: 0.0039734]
	Learning Rate: 0.00397336
	LOSS [training: 0.5652289406752053 | validation: 0.46663562004021436]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_481.pth
	Model improved!!!
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4665316965658916		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.4665316965658916 | validation: 0.4621028045633596]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5356846543890426		[learning rate: 0.0039541]
	Learning Rate: 0.00395415
	LOSS [training: 0.5356846543890426 | validation: 1.1004950190814862]
	TIME [epoch: 9.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8038392768541017		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.8038392768541017 | validation: 0.8370420373054849]
	TIME [epoch: 9.81 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.740665132551987		[learning rate: 0.003935]
	Learning Rate: 0.00393502
	LOSS [training: 0.740665132551987 | validation: 0.6050372016173665]
	TIME [epoch: 9.83 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7762074699565329		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.7762074699565329 | validation: 0.7223565697624289]
	TIME [epoch: 9.81 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7384352868582723		[learning rate: 0.003916]
	Learning Rate: 0.00391599
	LOSS [training: 0.7384352868582723 | validation: 0.5932904495203848]
	TIME [epoch: 9.81 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5306297512664717		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.5306297512664717 | validation: 0.9344756902556057]
	TIME [epoch: 9.81 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5908040001612809		[learning rate: 0.0038971]
	Learning Rate: 0.00389706
	LOSS [training: 0.5908040001612809 | validation: 0.44249603105186597]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_489.pth
	Model improved!!!
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.31491147761327		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 2.31491147761327 | validation: 5.0052803543873905]
	TIME [epoch: 9.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.074306039645752		[learning rate: 0.0038782]
	Learning Rate: 0.00387821
	LOSS [training: 5.074306039645752 | validation: 3.453864049800563]
	TIME [epoch: 9.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.59532316896401		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 4.59532316896401 | validation: 4.296214209516781]
	TIME [epoch: 9.82 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.684698753267001		[learning rate: 0.0038595]
	Learning Rate: 0.00385946
	LOSS [training: 4.684698753267001 | validation: 3.2116533946370387]
	TIME [epoch: 9.8 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.473703979909443		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 4.473703979909443 | validation: 3.315458345180244]
	TIME [epoch: 9.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3168502521680265		[learning rate: 0.0038408]
	Learning Rate: 0.00384079
	LOSS [training: 4.3168502521680265 | validation: 3.761255310632187]
	TIME [epoch: 9.81 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.44927678391992		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 4.44927678391992 | validation: 2.9855332921911386]
	TIME [epoch: 9.81 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.016756650791667		[learning rate: 0.0038222]
	Learning Rate: 0.00382222
	LOSS [training: 4.016756650791667 | validation: 2.7090203494738994]
	TIME [epoch: 9.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.491373383381019		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 3.491373383381019 | validation: 1.1332448577714194]
	TIME [epoch: 9.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7557956409573364		[learning rate: 0.0038037]
	Learning Rate: 0.00380374
	LOSS [training: 0.7557956409573364 | validation: 0.6856327357858044]
	TIME [epoch: 9.82 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7748460142024939		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.7748460142024939 | validation: 0.8126538820027347]
	TIME [epoch: 9.81 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6743745421859688		[learning rate: 0.0037853]
	Learning Rate: 0.00378534
	LOSS [training: 0.6743745421859688 | validation: 0.8104610084043228]
	TIME [epoch: 9.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8172333536216378		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.8172333536216378 | validation: 0.7770757753194328]
	TIME [epoch: 9.81 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6011166279277277		[learning rate: 0.003767]
	Learning Rate: 0.00376704
	LOSS [training: 0.6011166279277277 | validation: 0.8009905766797377]
	TIME [epoch: 9.81 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6364504947460119		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.6364504947460119 | validation: 0.622874514085605]
	TIME [epoch: 9.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.988677891081093		[learning rate: 0.0037488]
	Learning Rate: 0.00374882
	LOSS [training: 0.988677891081093 | validation: 0.9150344994633723]
	TIME [epoch: 9.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7615465573707783		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.7615465573707783 | validation: 0.7960528596769214]
	TIME [epoch: 9.82 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.566462686233018		[learning rate: 0.0037307]
	Learning Rate: 0.00373069
	LOSS [training: 0.566462686233018 | validation: 0.5440803018213098]
	TIME [epoch: 9.81 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7036894528699733		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.7036894528699733 | validation: 0.8256721482902739]
	TIME [epoch: 9.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5924899584989363		[learning rate: 0.0037127]
	Learning Rate: 0.00371265
	LOSS [training: 0.5924899584989363 | validation: 0.35031543496078427]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_509.pth
	Model improved!!!
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6606683916791388		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.6606683916791388 | validation: 0.7657494288464034]
	TIME [epoch: 9.83 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7545347885738697		[learning rate: 0.0036947]
	Learning Rate: 0.0036947
	LOSS [training: 0.7545347885738697 | validation: 0.5545209432114353]
	TIME [epoch: 9.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6478707986044541		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.6478707986044541 | validation: 0.6649608211951958]
	TIME [epoch: 9.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4892901832380197		[learning rate: 0.0036768]
	Learning Rate: 0.00367683
	LOSS [training: 0.4892901832380197 | validation: 0.49064784404961037]
	TIME [epoch: 9.82 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6884212637031785		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.6884212637031785 | validation: 0.625149388984865]
	TIME [epoch: 9.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4984415285240365		[learning rate: 0.0036591]
	Learning Rate: 0.00365905
	LOSS [training: 0.4984415285240365 | validation: 0.7244761121060609]
	TIME [epoch: 9.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6943932619833014		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.6943932619833014 | validation: 0.9844672393167574]
	TIME [epoch: 9.81 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5725343597282037		[learning rate: 0.0036414]
	Learning Rate: 0.00364136
	LOSS [training: 0.5725343597282037 | validation: 1.2106845385975211]
	TIME [epoch: 9.82 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5677358838445834		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.5677358838445834 | validation: 1.048384455775262]
	TIME [epoch: 9.81 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8094691597153802		[learning rate: 0.0036237]
	Learning Rate: 0.00362375
	LOSS [training: 0.8094691597153802 | validation: 0.815300754588954]
	TIME [epoch: 9.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4796286441216514		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.4796286441216514 | validation: 0.6847246574951897]
	TIME [epoch: 9.82 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5528302582044986		[learning rate: 0.0036062]
	Learning Rate: 0.00360622
	LOSS [training: 0.5528302582044986 | validation: 1.1501095059767503]
	TIME [epoch: 9.8 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6333357049166972		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.6333357049166972 | validation: 0.40576096311015847]
	TIME [epoch: 9.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4291534099472325		[learning rate: 0.0035888]
	Learning Rate: 0.00358878
	LOSS [training: 0.4291534099472325 | validation: 0.729983914988547]
	TIME [epoch: 9.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49837051334161064		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.49837051334161064 | validation: 0.5180841298939441]
	TIME [epoch: 9.82 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5298609602509298		[learning rate: 0.0035714]
	Learning Rate: 0.00357143
	LOSS [training: 0.5298609602509298 | validation: 0.447117994244733]
	TIME [epoch: 9.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47491966611765113		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.47491966611765113 | validation: 0.6387809560609246]
	TIME [epoch: 9.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6584646125434375		[learning rate: 0.0035542]
	Learning Rate: 0.00355416
	LOSS [training: 0.6584646125434375 | validation: 0.4482517804430759]
	TIME [epoch: 9.81 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.53982499680623		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.53982499680623 | validation: 0.5860895333235423]
	TIME [epoch: 9.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.474728141319544		[learning rate: 0.003537]
	Learning Rate: 0.00353697
	LOSS [training: 0.474728141319544 | validation: 0.4054759324999334]
	TIME [epoch: 9.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5924361582935085		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.5924361582935085 | validation: 0.46496486186992086]
	TIME [epoch: 9.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8140730836952107		[learning rate: 0.0035199]
	Learning Rate: 0.00351987
	LOSS [training: 0.8140730836952107 | validation: 0.7990533408896073]
	TIME [epoch: 9.81 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6409956047270489		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.6409956047270489 | validation: 0.737821272689771]
	TIME [epoch: 9.79 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5277881675812214		[learning rate: 0.0035028]
	Learning Rate: 0.00350285
	LOSS [training: 0.5277881675812214 | validation: 0.3281720725947243]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4124146068570057		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.4124146068570057 | validation: 0.6825218137097098]
	TIME [epoch: 9.79 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38472363958986233		[learning rate: 0.0034859]
	Learning Rate: 0.00348591
	LOSS [training: 0.38472363958986233 | validation: 0.4073093586993376]
	TIME [epoch: 9.79 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4698423338403921		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.4698423338403921 | validation: 0.5754331966103335]
	TIME [epoch: 9.79 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7260406019010344		[learning rate: 0.003469]
	Learning Rate: 0.00346905
	LOSS [training: 0.7260406019010344 | validation: 0.6280937011431822]
	TIME [epoch: 9.78 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7306774411907939		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.7306774411907939 | validation: 0.7235403482145384]
	TIME [epoch: 9.82 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6140137487477489		[learning rate: 0.0034523]
	Learning Rate: 0.00345227
	LOSS [training: 0.6140137487477489 | validation: 0.4909478489137885]
	TIME [epoch: 9.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5431182720553291		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.5431182720553291 | validation: 0.3783182769451088]
	TIME [epoch: 9.79 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4093747061376051		[learning rate: 0.0034356]
	Learning Rate: 0.00343558
	LOSS [training: 0.4093747061376051 | validation: 0.47426142391766646]
	TIME [epoch: 9.79 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4002229911441878		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.4002229911441878 | validation: 0.2992477308549659]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_542.pth
	Model improved!!!
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48891735602992786		[learning rate: 0.003419]
	Learning Rate: 0.00341897
	LOSS [training: 0.48891735602992786 | validation: 0.47559144372951057]
	TIME [epoch: 9.79 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7644222429040763		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.7644222429040763 | validation: 1.7173683031682814]
	TIME [epoch: 9.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0611271350362312		[learning rate: 0.0034024]
	Learning Rate: 0.00340243
	LOSS [training: 1.0611271350362312 | validation: 0.773825697702945]
	TIME [epoch: 9.82 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6072854787338466		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.6072854787338466 | validation: 0.8859190287438841]
	TIME [epoch: 9.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9839991384622732		[learning rate: 0.003386]
	Learning Rate: 0.00338598
	LOSS [training: 0.9839991384622732 | validation: 0.5112497450829617]
	TIME [epoch: 9.79 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5541892057204485		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.5541892057204485 | validation: 1.0995345182933889]
	TIME [epoch: 9.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6016772647172622		[learning rate: 0.0033696]
	Learning Rate: 0.0033696
	LOSS [training: 0.6016772647172622 | validation: 0.5068390682592575]
	TIME [epoch: 9.81 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37284498208096695		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.37284498208096695 | validation: 0.5422672620122087]
	TIME [epoch: 9.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8418021161052781		[learning rate: 0.0033533]
	Learning Rate: 0.00335331
	LOSS [training: 0.8418021161052781 | validation: 0.5321031341962352]
	TIME [epoch: 9.79 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6647071989107107		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.6647071989107107 | validation: 0.6462772663809896]
	TIME [epoch: 9.82 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5194841931895499		[learning rate: 0.0033371]
	Learning Rate: 0.00333709
	LOSS [training: 0.5194841931895499 | validation: 1.025029799792191]
	TIME [epoch: 9.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8171193173012916		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.8171193173012916 | validation: 0.8204169917608316]
	TIME [epoch: 9.79 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5310827956154565		[learning rate: 0.003321]
	Learning Rate: 0.00332096
	LOSS [training: 0.5310827956154565 | validation: 0.3549639525644935]
	TIME [epoch: 9.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4669988642973526		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.4669988642973526 | validation: 0.5280270056416825]
	TIME [epoch: 9.81 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.518762743506628		[learning rate: 0.0033049]
	Learning Rate: 0.0033049
	LOSS [training: 0.518762743506628 | validation: 0.4928625166150174]
	TIME [epoch: 9.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5526846495481152		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.5526846495481152 | validation: 1.3415745940165076]
	TIME [epoch: 9.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0944843136596831		[learning rate: 0.0032889]
	Learning Rate: 0.00328891
	LOSS [training: 1.0944843136596831 | validation: 0.4134186641086496]
	TIME [epoch: 9.81 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5399361107724843		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.5399361107724843 | validation: 0.39973445076538905]
	TIME [epoch: 9.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42086357771981875		[learning rate: 0.003273]
	Learning Rate: 0.00327301
	LOSS [training: 0.42086357771981875 | validation: 0.4301837633399724]
	TIME [epoch: 9.79 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4479589723548133		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.4479589723548133 | validation: 0.325897212770835]
	TIME [epoch: 9.79 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4642138692073198		[learning rate: 0.0032572]
	Learning Rate: 0.00325718
	LOSS [training: 0.4642138692073198 | validation: 0.9082377802710078]
	TIME [epoch: 9.81 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7029610318521253		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.7029610318521253 | validation: 0.9815072868714291]
	TIME [epoch: 9.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6927942793445195		[learning rate: 0.0032414]
	Learning Rate: 0.00324143
	LOSS [training: 0.6927942793445195 | validation: 0.6107503437519577]
	TIME [epoch: 9.79 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4581489391218792		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.4581489391218792 | validation: 0.36438841325358906]
	TIME [epoch: 9.82 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5446858885391914		[learning rate: 0.0032258]
	Learning Rate: 0.00322576
	LOSS [training: 1.5446858885391914 | validation: 0.6154080029865558]
	TIME [epoch: 9.79 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5963813783443372		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.5963813783443372 | validation: 0.3821050680778933]
	TIME [epoch: 9.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44248478940597763		[learning rate: 0.0032102]
	Learning Rate: 0.00321016
	LOSS [training: 0.44248478940597763 | validation: 0.32156696505589355]
	TIME [epoch: 9.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5340843253323443		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.5340843253323443 | validation: 0.8117062443965583]
	TIME [epoch: 9.81 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5682963975523461		[learning rate: 0.0031946]
	Learning Rate: 0.00319463
	LOSS [training: 0.5682963975523461 | validation: 0.42502225688550466]
	TIME [epoch: 9.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46398314005066776		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.46398314005066776 | validation: 0.5045142389827005]
	TIME [epoch: 9.79 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46087867292636464		[learning rate: 0.0031792]
	Learning Rate: 0.00317918
	LOSS [training: 0.46087867292636464 | validation: 0.4358537478544124]
	TIME [epoch: 9.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5600687283291537		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.5600687283291537 | validation: 0.4603502518737218]
	TIME [epoch: 9.81 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5592000692802891		[learning rate: 0.0031638]
	Learning Rate: 0.00316381
	LOSS [training: 0.5592000692802891 | validation: 0.7383655984583635]
	TIME [epoch: 9.79 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4068892057304989		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.4068892057304989 | validation: 0.4448969016717827]
	TIME [epoch: 9.79 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4383740341912777		[learning rate: 0.0031485]
	Learning Rate: 0.00314851
	LOSS [training: 0.4383740341912777 | validation: 0.6333384350218891]
	TIME [epoch: 9.82 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5719435355256985		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.5719435355256985 | validation: 0.4691302810048931]
	TIME [epoch: 9.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4075963076820666		[learning rate: 0.0031333]
	Learning Rate: 0.00313329
	LOSS [training: 0.4075963076820666 | validation: 0.6591970985105416]
	TIME [epoch: 9.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5018499293966071		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.5018499293966071 | validation: 0.45276295798335725]
	TIME [epoch: 9.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4742771627151943		[learning rate: 0.0031181]
	Learning Rate: 0.00311813
	LOSS [training: 0.4742771627151943 | validation: 0.47900953234900984]
	TIME [epoch: 9.82 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35808365251106056		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.35808365251106056 | validation: 0.6181077654917033]
	TIME [epoch: 9.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4758832263563673		[learning rate: 0.0031031]
	Learning Rate: 0.00310305
	LOSS [training: 0.4758832263563673 | validation: 0.38480858909845256]
	TIME [epoch: 9.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5860380114891361		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.5860380114891361 | validation: 0.321308392615813]
	TIME [epoch: 9.82 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3832024099961768		[learning rate: 0.003088]
	Learning Rate: 0.00308805
	LOSS [training: 0.3832024099961768 | validation: 0.24013365756834718]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_585.pth
	Model improved!!!
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5094201757688328		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.5094201757688328 | validation: 0.3292153750635673]
	TIME [epoch: 9.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39139391109742716		[learning rate: 0.0030731]
	Learning Rate: 0.00307312
	LOSS [training: 0.39139391109742716 | validation: 0.31350254071640127]
	TIME [epoch: 9.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4206419265576626		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.4206419265576626 | validation: 0.5203339547564824]
	TIME [epoch: 9.83 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4042860887494594		[learning rate: 0.0030583]
	Learning Rate: 0.00305825
	LOSS [training: 0.4042860887494594 | validation: 0.6664629620713128]
	TIME [epoch: 9.81 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.552078158607996		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.552078158607996 | validation: 0.33224857250092255]
	TIME [epoch: 9.81 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49488968868032135		[learning rate: 0.0030435]
	Learning Rate: 0.00304347
	LOSS [training: 0.49488968868032135 | validation: 0.397167818540126]
	TIME [epoch: 9.82 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4251752793217972		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.4251752793217972 | validation: 0.32508527415483224]
	TIME [epoch: 9.79 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3734381370738779		[learning rate: 0.0030287]
	Learning Rate: 0.00302875
	LOSS [training: 0.3734381370738779 | validation: 0.4883532338479087]
	TIME [epoch: 9.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7368078254692702		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.7368078254692702 | validation: 0.3047551829522949]
	TIME [epoch: 9.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3675718408570009		[learning rate: 0.0030141]
	Learning Rate: 0.0030141
	LOSS [training: 0.3675718408570009 | validation: 0.41533716333775533]
	TIME [epoch: 9.81 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4029232494910035		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.4029232494910035 | validation: 0.7048248288907607]
	TIME [epoch: 9.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8228021759390838		[learning rate: 0.0029995]
	Learning Rate: 0.00299953
	LOSS [training: 0.8228021759390838 | validation: 0.7524711781904398]
	TIME [epoch: 9.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5214449368618508		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.5214449368618508 | validation: 1.296166703736157]
	TIME [epoch: 9.82 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6808258700612112		[learning rate: 0.002985]
	Learning Rate: 0.00298502
	LOSS [training: 0.6808258700612112 | validation: 0.5396947420410135]
	TIME [epoch: 9.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4690779007982432		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.4690779007982432 | validation: 0.5638404737697262]
	TIME [epoch: 9.79 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5224471703993301		[learning rate: 0.0029706]
	Learning Rate: 0.00297059
	LOSS [training: 0.5224471703993301 | validation: 0.43101984806316995]
	TIME [epoch: 9.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49956941821586975		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.49956941821586975 | validation: 0.3312597177635939]
	TIME [epoch: 9.81 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34689174096133985		[learning rate: 0.0029562]
	Learning Rate: 0.00295622
	LOSS [training: 0.34689174096133985 | validation: 0.4796590947007313]
	TIME [epoch: 9.78 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6485704412369443		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.6485704412369443 | validation: 1.2758186673309602]
	TIME [epoch: 9.79 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.970515969869673		[learning rate: 0.0029419]
	Learning Rate: 0.00294192
	LOSS [training: 0.970515969869673 | validation: 0.7165271141613542]
	TIME [epoch: 9.79 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5823832776979998		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.5823832776979998 | validation: 0.28741195645799794]
	TIME [epoch: 9.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4350176994204114		[learning rate: 0.0029277]
	Learning Rate: 0.0029277
	LOSS [training: 0.4350176994204114 | validation: 0.3687198922562644]
	TIME [epoch: 9.79 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5840755345240785		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.5840755345240785 | validation: 0.4742675682212271]
	TIME [epoch: 9.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4747896191041104		[learning rate: 0.0029135]
	Learning Rate: 0.00291354
	LOSS [training: 0.4747896191041104 | validation: 0.47125801712554266]
	TIME [epoch: 9.82 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2947656985397424		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.2947656985397424 | validation: 0.3166816806701618]
	TIME [epoch: 9.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34684805168135		[learning rate: 0.0028995]
	Learning Rate: 0.00289945
	LOSS [training: 0.34684805168135 | validation: 0.5609605549803149]
	TIME [epoch: 9.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4047456171444576		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.4047456171444576 | validation: 0.7594887108567481]
	TIME [epoch: 9.81 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4876570276428255		[learning rate: 0.0028854]
	Learning Rate: 0.00288543
	LOSS [training: 0.4876570276428255 | validation: 0.5031858270346388]
	TIME [epoch: 9.81 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3871754659686997		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.3871754659686997 | validation: 0.3815478038472263]
	TIME [epoch: 9.79 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3075862777484605		[learning rate: 0.0028715]
	Learning Rate: 0.00287148
	LOSS [training: 0.3075862777484605 | validation: 0.6943494527787653]
	TIME [epoch: 9.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5158625021704035		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.5158625021704035 | validation: 0.6896818099795142]
	TIME [epoch: 9.82 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4020790709513341		[learning rate: 0.0028576]
	Learning Rate: 0.00285759
	LOSS [training: 0.4020790709513341 | validation: 0.6146489766089536]
	TIME [epoch: 9.79 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.365653326611738		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.365653326611738 | validation: 0.39454715117388084]
	TIME [epoch: 9.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.660065714627096		[learning rate: 0.0028438]
	Learning Rate: 0.00284377
	LOSS [training: 0.660065714627096 | validation: 0.4604693517776699]
	TIME [epoch: 9.79 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4058186852124531		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.4058186852124531 | validation: 0.47554680399069765]
	TIME [epoch: 9.81 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4183030961354799		[learning rate: 0.00283]
	Learning Rate: 0.00283002
	LOSS [training: 0.4183030961354799 | validation: 0.5223501063501732]
	TIME [epoch: 9.79 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.474656456565528		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.474656456565528 | validation: 0.5625895664548506]
	TIME [epoch: 9.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41820475844047894		[learning rate: 0.0028163]
	Learning Rate: 0.00281633
	LOSS [training: 0.41820475844047894 | validation: 0.6971872083416065]
	TIME [epoch: 9.81 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4560303158791375		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.4560303158791375 | validation: 0.7768481875652553]
	TIME [epoch: 9.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6817277045589014		[learning rate: 0.0028027]
	Learning Rate: 0.00280272
	LOSS [training: 0.6817277045589014 | validation: 0.7439089712719817]
	TIME [epoch: 9.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6644805275596786		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.6644805275596786 | validation: 0.420732871451385]
	TIME [epoch: 9.77 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4705463334649325		[learning rate: 0.0027892]
	Learning Rate: 0.00278916
	LOSS [training: 0.4705463334649325 | validation: 0.4201907586449055]
	TIME [epoch: 9.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.400979977328078		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.400979977328078 | validation: 0.4720685966488803]
	TIME [epoch: 9.79 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4261706010181965		[learning rate: 0.0027757]
	Learning Rate: 0.00277567
	LOSS [training: 0.4261706010181965 | validation: 0.9300039795276114]
	TIME [epoch: 9.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6399771815084803		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.6399771815084803 | validation: 0.4282391391555067]
	TIME [epoch: 9.81 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4374724353838964		[learning rate: 0.0027623]
	Learning Rate: 0.00276225
	LOSS [training: 0.4374724353838964 | validation: 0.4711105384041821]
	TIME [epoch: 9.79 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2873428958905019		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.2873428958905019 | validation: 0.3264327394724565]
	TIME [epoch: 9.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33905047362095553		[learning rate: 0.0027489]
	Learning Rate: 0.00274889
	LOSS [training: 0.33905047362095553 | validation: 0.3524540987066635]
	TIME [epoch: 9.78 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35726409725704034		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.35726409725704034 | validation: 0.22768672365703307]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36131105011771936		[learning rate: 0.0027356]
	Learning Rate: 0.0027356
	LOSS [training: 0.36131105011771936 | validation: 1.0539966668384246]
	TIME [epoch: 9.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6284176859907051		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.6284176859907051 | validation: 0.2846887121265083]
	TIME [epoch: 9.78 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4608548373302238		[learning rate: 0.0027224]
	Learning Rate: 0.00272237
	LOSS [training: 0.4608548373302238 | validation: 0.42309005487975937]
	TIME [epoch: 9.81 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4590795721350223		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.4590795721350223 | validation: 0.6070603229246766]
	TIME [epoch: 9.8 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34388910724506105		[learning rate: 0.0027092]
	Learning Rate: 0.00270921
	LOSS [training: 0.34388910724506105 | validation: 0.4298242591982613]
	TIME [epoch: 9.79 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5025425383375627		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.5025425383375627 | validation: 0.38665106660274534]
	TIME [epoch: 9.78 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44213323390913556		[learning rate: 0.0026961]
	Learning Rate: 0.00269611
	LOSS [training: 0.44213323390913556 | validation: 0.5028954954704739]
	TIME [epoch: 9.81 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45215816603971526		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.45215816603971526 | validation: 0.4791774407311962]
	TIME [epoch: 9.79 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4286126060344634		[learning rate: 0.0026831]
	Learning Rate: 0.00268307
	LOSS [training: 0.4286126060344634 | validation: 0.319062892218369]
	TIME [epoch: 9.79 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7278796002854893		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.7278796002854893 | validation: 0.39756775580669607]
	TIME [epoch: 9.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3492331481246089		[learning rate: 0.0026701]
	Learning Rate: 0.00267009
	LOSS [training: 0.3492331481246089 | validation: 0.3367444057293957]
	TIME [epoch: 9.8 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4719181835710053		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.4719181835710053 | validation: 0.4423053935003629]
	TIME [epoch: 9.8 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5026744167814741		[learning rate: 0.0026572]
	Learning Rate: 0.00265718
	LOSS [training: 0.5026744167814741 | validation: 0.43556512805175407]
	TIME [epoch: 9.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41030735612432584		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.41030735612432584 | validation: 0.2994175375591341]
	TIME [epoch: 9.81 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36983293278372115		[learning rate: 0.0026443]
	Learning Rate: 0.00264433
	LOSS [training: 0.36983293278372115 | validation: 0.6332928738122514]
	TIME [epoch: 9.78 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3508817960434103		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.3508817960434103 | validation: 0.3735457018435666]
	TIME [epoch: 9.79 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5560857000229893		[learning rate: 0.0026315]
	Learning Rate: 0.00263154
	LOSS [training: 0.5560857000229893 | validation: 0.28998785950954925]
	TIME [epoch: 9.78 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5704361550070984		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.5704361550070984 | validation: 0.4191661114856053]
	TIME [epoch: 9.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4029745990782036		[learning rate: 0.0026188]
	Learning Rate: 0.00261882
	LOSS [training: 0.4029745990782036 | validation: 0.368420565568766]
	TIME [epoch: 9.79 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3922949596336743		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.3922949596336743 | validation: 0.3405254968417276]
	TIME [epoch: 9.78 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3130766633520795		[learning rate: 0.0026062]
	Learning Rate: 0.00260615
	LOSS [training: 0.3130766633520795 | validation: 0.5640668440518006]
	TIME [epoch: 9.81 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3217800137891426		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.3217800137891426 | validation: 0.41358259282616827]
	TIME [epoch: 9.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43351513632118027		[learning rate: 0.0025936]
	Learning Rate: 0.00259355
	LOSS [training: 0.43351513632118027 | validation: 0.30837974679048336]
	TIME [epoch: 9.79 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3892206302628308		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.3892206302628308 | validation: 0.1955088428110223]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_658.pth
	Model improved!!!
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4343679524306931		[learning rate: 0.002581]
	Learning Rate: 0.00258101
	LOSS [training: 0.4343679524306931 | validation: 0.8836056773617742]
	TIME [epoch: 9.82 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7193419062320628		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.7193419062320628 | validation: 0.46185533844491305]
	TIME [epoch: 9.79 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5368417969477488		[learning rate: 0.0025685]
	Learning Rate: 0.00256853
	LOSS [training: 0.5368417969477488 | validation: 0.9024924716816747]
	TIME [epoch: 9.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0799860248242406		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 1.0799860248242406 | validation: 0.4536752753272464]
	TIME [epoch: 9.82 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.625216978576719		[learning rate: 0.0025561]
	Learning Rate: 0.00255611
	LOSS [training: 0.625216978576719 | validation: 0.6558940955555927]
	TIME [epoch: 9.79 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9353102095338102		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.9353102095338102 | validation: 0.7410986614651838]
	TIME [epoch: 9.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6363944178202064		[learning rate: 0.0025437]
	Learning Rate: 0.00254375
	LOSS [training: 0.6363944178202064 | validation: 0.9010582651006209]
	TIME [epoch: 9.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.626310711002693		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.626310711002693 | validation: 0.4258888945912571]
	TIME [epoch: 9.82 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5112734651727343		[learning rate: 0.0025314]
	Learning Rate: 0.00253144
	LOSS [training: 0.5112734651727343 | validation: 0.685088018492279]
	TIME [epoch: 9.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.578276846919603		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.578276846919603 | validation: 0.5067434445726524]
	TIME [epoch: 9.78 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4147620842694203		[learning rate: 0.0025192]
	Learning Rate: 0.0025192
	LOSS [training: 0.4147620842694203 | validation: 0.441318541966453]
	TIME [epoch: 9.81 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4175425798155642		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.4175425798155642 | validation: 0.31666993042428987]
	TIME [epoch: 9.81 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5431473751318381		[learning rate: 0.002507]
	Learning Rate: 0.00250702
	LOSS [training: 0.5431473751318381 | validation: 0.49251667449462233]
	TIME [epoch: 9.78 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4570795735577489		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.4570795735577489 | validation: 0.25478816827571155]
	TIME [epoch: 9.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35715016821999546		[learning rate: 0.0024949]
	Learning Rate: 0.0024949
	LOSS [training: 0.35715016821999546 | validation: 0.41743729848577177]
	TIME [epoch: 9.81 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5181246748148464		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.5181246748148464 | validation: 0.6891902339463672]
	TIME [epoch: 9.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45213392708688865		[learning rate: 0.0024828]
	Learning Rate: 0.00248283
	LOSS [training: 0.45213392708688865 | validation: 0.4311959486530768]
	TIME [epoch: 9.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3587036891401964		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.3587036891401964 | validation: 0.34703100253138025]
	TIME [epoch: 9.82 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3762656415718402		[learning rate: 0.0024708]
	Learning Rate: 0.00247083
	LOSS [training: 0.3762656415718402 | validation: 0.4594580074485243]
	TIME [epoch: 9.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5779114433380308		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.5779114433380308 | validation: 0.3706316689083245]
	TIME [epoch: 9.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4644079674546783		[learning rate: 0.0024589]
	Learning Rate: 0.00245888
	LOSS [training: 0.4644079674546783 | validation: 0.3792092893276648]
	TIME [epoch: 9.81 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4093425946331302		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.4093425946331302 | validation: 0.2391446330016963]
	TIME [epoch: 9.83 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2746652467225542		[learning rate: 0.002447]
	Learning Rate: 0.00244699
	LOSS [training: 0.2746652467225542 | validation: 0.4335766569962951]
	TIME [epoch: 9.79 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35307988713327776		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.35307988713327776 | validation: 0.34143895589333484]
	TIME [epoch: 9.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5233109010072365		[learning rate: 0.0024352]
	Learning Rate: 0.00243515
	LOSS [training: 0.5233109010072365 | validation: 1.0970534251815491]
	TIME [epoch: 9.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8185007417638672		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.8185007417638672 | validation: 0.3420116901271097]
	TIME [epoch: 9.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.318358006857377		[learning rate: 0.0024234]
	Learning Rate: 0.00242338
	LOSS [training: 0.318358006857377 | validation: 0.2515350144979423]
	TIME [epoch: 9.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3482180480411902		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.3482180480411902 | validation: 0.6447251888221587]
	TIME [epoch: 9.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5107238554324949		[learning rate: 0.0024117]
	Learning Rate: 0.00241166
	LOSS [training: 0.5107238554324949 | validation: 0.582906080665615]
	TIME [epoch: 9.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.466120839955322		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.466120839955322 | validation: 0.33406870738424266]
	TIME [epoch: 9.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49181854421391336		[learning rate: 0.0024]
	Learning Rate: 0.0024
	LOSS [training: 0.49181854421391336 | validation: 0.5104405289944609]
	TIME [epoch: 9.79 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44268994736427114		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.44268994736427114 | validation: 0.4763000597753613]
	TIME [epoch: 9.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49605683698431047		[learning rate: 0.0023884]
	Learning Rate: 0.00238839
	LOSS [training: 0.49605683698431047 | validation: 0.49312509065603666]
	TIME [epoch: 9.81 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46261921181020416		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.46261921181020416 | validation: 0.6561632555079605]
	TIME [epoch: 9.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5458323202760664		[learning rate: 0.0023768]
	Learning Rate: 0.00237684
	LOSS [training: 0.5458323202760664 | validation: 0.5608005732085741]
	TIME [epoch: 9.79 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5095688645176374		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.5095688645176374 | validation: 0.4312289412476932]
	TIME [epoch: 9.81 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5005752254623486		[learning rate: 0.0023653]
	Learning Rate: 0.00236535
	LOSS [training: 0.5005752254623486 | validation: 0.6200395054144355]
	TIME [epoch: 9.8 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.568816540337216		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.568816540337216 | validation: 0.45662345117250236]
	TIME [epoch: 9.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7122578201256288		[learning rate: 0.0023539]
	Learning Rate: 0.00235391
	LOSS [training: 0.7122578201256288 | validation: 1.0433654339771767]
	TIME [epoch: 9.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6794536457690292		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.6794536457690292 | validation: 0.4899394245149316]
	TIME [epoch: 9.81 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4578785225317052		[learning rate: 0.0023425]
	Learning Rate: 0.00234252
	LOSS [training: 0.4578785225317052 | validation: 0.6442961007710604]
	TIME [epoch: 9.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4248473544451944		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.4248473544451944 | validation: 0.37487281998845534]
	TIME [epoch: 9.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38722269093811346		[learning rate: 0.0023312]
	Learning Rate: 0.0023312
	LOSS [training: 0.38722269093811346 | validation: 1.1048897443322336]
	TIME [epoch: 9.81 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7076952075375826		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.7076952075375826 | validation: 0.3713421977815748]
	TIME [epoch: 9.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38725258780945626		[learning rate: 0.0023199]
	Learning Rate: 0.00231992
	LOSS [training: 0.38725258780945626 | validation: 0.7434833648124817]
	TIME [epoch: 9.79 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5105776028873809		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.5105776028873809 | validation: 0.3410843428961522]
	TIME [epoch: 9.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3729822248421685		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.3729822248421685 | validation: 0.43779137022926023]
	TIME [epoch: 9.82 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.604411686783697		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.604411686783697 | validation: 0.761444011543129]
	TIME [epoch: 9.81 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.644898674271484		[learning rate: 0.0022975]
	Learning Rate: 0.00229754
	LOSS [training: 0.644898674271484 | validation: 0.4378193464761039]
	TIME [epoch: 9.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5653980653019027		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.5653980653019027 | validation: 0.32687392864496395]
	TIME [epoch: 9.81 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34390297541887194		[learning rate: 0.0022864]
	Learning Rate: 0.00228643
	LOSS [training: 0.34390297541887194 | validation: 0.47129213656551844]
	TIME [epoch: 9.79 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8872544230557782		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.8872544230557782 | validation: 0.48454597987667514]
	TIME [epoch: 9.79 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4494545286859005		[learning rate: 0.0022754]
	Learning Rate: 0.00227537
	LOSS [training: 0.4494545286859005 | validation: 0.5444179841705581]
	TIME [epoch: 9.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4401120722095405		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.4401120722095405 | validation: 0.4170351971522828]
	TIME [epoch: 9.82 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3231854867610055		[learning rate: 0.0022644]
	Learning Rate: 0.00226437
	LOSS [training: 0.3231854867610055 | validation: 0.7680068822243223]
	TIME [epoch: 9.79 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5371187010422757		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.5371187010422757 | validation: 0.3535587964122076]
	TIME [epoch: 9.81 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38044721066624165		[learning rate: 0.0022534]
	Learning Rate: 0.00225342
	LOSS [training: 0.38044721066624165 | validation: 0.4503190557687623]
	TIME [epoch: 9.81 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8171650480304748		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.8171650480304748 | validation: 1.0478096005679982]
	TIME [epoch: 9.81 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47851186467432616		[learning rate: 0.0022425]
	Learning Rate: 0.00224252
	LOSS [training: 0.47851186467432616 | validation: 0.31203275247804413]
	TIME [epoch: 9.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6310773519591353		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.6310773519591353 | validation: 0.9802074951483002]
	TIME [epoch: 9.79 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6076336996761894		[learning rate: 0.0022317]
	Learning Rate: 0.00223168
	LOSS [training: 0.6076336996761894 | validation: 0.2650006478648064]
	TIME [epoch: 9.81 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37455516735805433		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.37455516735805433 | validation: 0.2935685623716727]
	TIME [epoch: 9.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3592841417381297		[learning rate: 0.0022209]
	Learning Rate: 0.00222089
	LOSS [training: 0.3592841417381297 | validation: 0.7296528244415303]
	TIME [epoch: 9.79 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41462002328495606		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.41462002328495606 | validation: 0.4249686046990314]
	TIME [epoch: 9.81 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3638755209655316		[learning rate: 0.0022101]
	Learning Rate: 0.00221015
	LOSS [training: 0.3638755209655316 | validation: 0.3997613194308576]
	TIME [epoch: 9.81 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3565064648829036		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.3565064648829036 | validation: 0.5002865303197623]
	TIME [epoch: 9.81 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5059628395463139		[learning rate: 0.0021995]
	Learning Rate: 0.00219946
	LOSS [training: 0.5059628395463139 | validation: 0.7401726806406659]
	TIME [epoch: 9.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5260191195542752		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.5260191195542752 | validation: 0.5235466052597252]
	TIME [epoch: 9.82 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4076638438304495		[learning rate: 0.0021888]
	Learning Rate: 0.00218882
	LOSS [training: 0.4076638438304495 | validation: 0.27345757755163064]
	TIME [epoch: 9.81 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41560741921010746		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.41560741921010746 | validation: 0.8927619952145728]
	TIME [epoch: 9.79 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5784936109326363		[learning rate: 0.0021782]
	Learning Rate: 0.00217824
	LOSS [training: 0.5784936109326363 | validation: 1.0849529207626285]
	TIME [epoch: 9.81 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6950697286890357		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.6950697286890357 | validation: 0.32397967726348237]
	TIME [epoch: 9.81 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35788995405225466		[learning rate: 0.0021677]
	Learning Rate: 0.0021677
	LOSS [training: 0.35788995405225466 | validation: 0.4233427353894284]
	TIME [epoch: 9.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4419910195552452		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.4419910195552452 | validation: 0.3938437779392719]
	TIME [epoch: 9.8 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4053888525092114		[learning rate: 0.0021572]
	Learning Rate: 0.00215722
	LOSS [training: 0.4053888525092114 | validation: 0.281298307458301]
	TIME [epoch: 9.83 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6278459196831534		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.6278459196831534 | validation: 0.5572702342025595]
	TIME [epoch: 9.8 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5073933686102923		[learning rate: 0.0021468]
	Learning Rate: 0.00214679
	LOSS [training: 0.5073933686102923 | validation: 0.4320919474468765]
	TIME [epoch: 9.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3931401300279737		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.3931401300279737 | validation: 0.9806696170331095]
	TIME [epoch: 9.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5402124658855139		[learning rate: 0.0021364]
	Learning Rate: 0.00213641
	LOSS [training: 0.5402124658855139 | validation: 0.21277337115216327]
	TIME [epoch: 9.82 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3742191995233556		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.3742191995233556 | validation: 0.5271241610175686]
	TIME [epoch: 9.79 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4274919077601673		[learning rate: 0.0021261]
	Learning Rate: 0.00212608
	LOSS [training: 0.4274919077601673 | validation: 1.0762075129089974]
	TIME [epoch: 9.78 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.660822771840944		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.660822771840944 | validation: 0.4786257215940439]
	TIME [epoch: 9.8 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47370254738211476		[learning rate: 0.0021158]
	Learning Rate: 0.0021158
	LOSS [training: 0.47370254738211476 | validation: 0.4121534952954275]
	TIME [epoch: 9.8 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42432540576749433		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.42432540576749433 | validation: 0.41046359946868044]
	TIME [epoch: 9.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32667679250635284		[learning rate: 0.0021056]
	Learning Rate: 0.00210556
	LOSS [training: 0.32667679250635284 | validation: 0.3546347263431817]
	TIME [epoch: 9.79 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29510781572618644		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.29510781572618644 | validation: 0.5481245320875957]
	TIME [epoch: 9.81 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31874408780738467		[learning rate: 0.0020954]
	Learning Rate: 0.00209538
	LOSS [training: 0.31874408780738467 | validation: 0.3537240844081315]
	TIME [epoch: 9.79 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42576290578868914		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.42576290578868914 | validation: 0.38979060660895687]
	TIME [epoch: 9.79 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5748357189243887		[learning rate: 0.0020852]
	Learning Rate: 0.00208525
	LOSS [training: 0.5748357189243887 | validation: 0.436320213246635]
	TIME [epoch: 9.81 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4685639540695078		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.4685639540695078 | validation: 0.33412809450813896]
	TIME [epoch: 9.79 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5687098931092714		[learning rate: 0.0020752]
	Learning Rate: 0.00207517
	LOSS [training: 0.5687098931092714 | validation: 0.5381219909064118]
	TIME [epoch: 9.82 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3890388833159565		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.3890388833159565 | validation: 0.3265197489000603]
	TIME [epoch: 9.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43892785530494083		[learning rate: 0.0020651]
	Learning Rate: 0.00206513
	LOSS [training: 0.43892785530494083 | validation: 0.462211409096583]
	TIME [epoch: 9.82 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48195113113880506		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.48195113113880506 | validation: 1.1254367561522158]
	TIME [epoch: 9.81 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5025046352244512		[learning rate: 0.0020551]
	Learning Rate: 0.00205514
	LOSS [training: 0.5025046352244512 | validation: 0.3480292256630751]
	TIME [epoch: 9.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3778972151080319		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.3778972151080319 | validation: 0.3424953578733714]
	TIME [epoch: 9.81 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41159350615526674		[learning rate: 0.0020452]
	Learning Rate: 0.0020452
	LOSS [training: 0.41159350615526674 | validation: 0.46600063096240635]
	TIME [epoch: 9.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3949790408110288		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.3949790408110288 | validation: 0.44502923543753115]
	TIME [epoch: 9.79 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35225201214483326		[learning rate: 0.0020353]
	Learning Rate: 0.00203531
	LOSS [training: 0.35225201214483326 | validation: 0.36593437855546496]
	TIME [epoch: 9.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3701715428323074		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.3701715428323074 | validation: 0.45455448956268785]
	TIME [epoch: 9.81 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4465002193933511		[learning rate: 0.0020255]
	Learning Rate: 0.00202547
	LOSS [training: 0.4465002193933511 | validation: 0.5688328177289195]
	TIME [epoch: 9.79 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4225079953054717		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.4225079953054717 | validation: 0.48678578838985276]
	TIME [epoch: 9.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32007187404871873		[learning rate: 0.0020157]
	Learning Rate: 0.00201568
	LOSS [training: 0.32007187404871873 | validation: 0.39830639301993515]
	TIME [epoch: 9.79 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36070748925607105		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.36070748925607105 | validation: 0.3277822654642463]
	TIME [epoch: 9.82 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3091897690405737		[learning rate: 0.0020059]
	Learning Rate: 0.00200593
	LOSS [training: 0.3091897690405737 | validation: 0.5182139277319421]
	TIME [epoch: 9.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5637979625960524		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.5637979625960524 | validation: 0.4788425393591257]
	TIME [epoch: 9.81 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3845580053100984		[learning rate: 0.0019962]
	Learning Rate: 0.00199623
	LOSS [training: 0.3845580053100984 | validation: 0.40761108205203966]
	TIME [epoch: 9.82 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.384921887205096		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.384921887205096 | validation: 0.2682496092278215]
	TIME [epoch: 9.79 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36998931567411986		[learning rate: 0.0019866]
	Learning Rate: 0.00198658
	LOSS [training: 0.36998931567411986 | validation: 0.4574235993969626]
	TIME [epoch: 9.78 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.315590750855664		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.315590750855664 | validation: 0.3298394102498257]
	TIME [epoch: 9.79 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077342313101215		[learning rate: 0.001977]
	Learning Rate: 0.00197697
	LOSS [training: 0.3077342313101215 | validation: 0.4684310672979007]
	TIME [epoch: 9.82 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37711659041947254		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.37711659041947254 | validation: 0.23246601324051544]
	TIME [epoch: 9.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32746121053151517		[learning rate: 0.0019674]
	Learning Rate: 0.00196741
	LOSS [training: 0.32746121053151517 | validation: 0.6428125447494587]
	TIME [epoch: 9.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7270702191969354		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.7270702191969354 | validation: 0.33846074993806613]
	TIME [epoch: 9.82 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47960348698295246		[learning rate: 0.0019579]
	Learning Rate: 0.0019579
	LOSS [training: 0.47960348698295246 | validation: 0.6588894413161229]
	TIME [epoch: 9.81 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3779672121615859		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.3779672121615859 | validation: 0.2961924794337615]
	TIME [epoch: 9.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4765383353574122		[learning rate: 0.0019484]
	Learning Rate: 0.00194843
	LOSS [training: 0.4765383353574122 | validation: 0.30408546743257553]
	TIME [epoch: 9.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3315625139242749		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.3315625139242749 | validation: 0.376474092029912]
	TIME [epoch: 9.82 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5329057808376605		[learning rate: 0.001939]
	Learning Rate: 0.00193901
	LOSS [training: 0.5329057808376605 | validation: 0.576416349681783]
	TIME [epoch: 9.79 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43959991830021783		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.43959991830021783 | validation: 0.33274719970577893]
	TIME [epoch: 9.81 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3887869328743969		[learning rate: 0.0019296]
	Learning Rate: 0.00192963
	LOSS [training: 0.3887869328743969 | validation: 0.4238375726647094]
	TIME [epoch: 9.81 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38038797907155636		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.38038797907155636 | validation: 0.4745016782926824]
	TIME [epoch: 9.81 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3298023494175668		[learning rate: 0.0019203]
	Learning Rate: 0.0019203
	LOSS [training: 0.3298023494175668 | validation: 0.43770202739621794]
	TIME [epoch: 9.81 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3557574953682024		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.3557574953682024 | validation: 0.453785802426126]
	TIME [epoch: 9.79 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26764924362671505		[learning rate: 0.001911]
	Learning Rate: 0.00191101
	LOSS [training: 0.26764924362671505 | validation: 0.624433082732645]
	TIME [epoch: 9.83 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4502371937328391		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.4502371937328391 | validation: 0.38082141323146973]
	TIME [epoch: 9.79 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3425796785740556		[learning rate: 0.0019018]
	Learning Rate: 0.00190177
	LOSS [training: 0.3425796785740556 | validation: 0.366068819895709]
	TIME [epoch: 9.79 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3932738691261409		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.3932738691261409 | validation: 0.5850518159628162]
	TIME [epoch: 9.81 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38864759831637014		[learning rate: 0.0018926]
	Learning Rate: 0.00189257
	LOSS [training: 0.38864759831637014 | validation: 0.5032057135617298]
	TIME [epoch: 9.81 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36718613153465274		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.36718613153465274 | validation: 0.4066996746849268]
	TIME [epoch: 9.79 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30431399137929926		[learning rate: 0.0018834]
	Learning Rate: 0.00188342
	LOSS [training: 0.30431399137929926 | validation: 0.19934417100802357]
	TIME [epoch: 9.79 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27770135155982795		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.27770135155982795 | validation: 0.49376446056675405]
	TIME [epoch: 9.82 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3197467075413022		[learning rate: 0.0018743]
	Learning Rate: 0.00187431
	LOSS [training: 0.3197467075413022 | validation: 0.46862440450575704]
	TIME [epoch: 9.81 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31666400972518927		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.31666400972518927 | validation: 0.5945725900755677]
	TIME [epoch: 9.79 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5045684122022818		[learning rate: 0.0018652]
	Learning Rate: 0.00186525
	LOSS [training: 0.5045684122022818 | validation: 0.32302127046123474]
	TIME [epoch: 9.81 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34470752062403376		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.34470752062403376 | validation: 0.40242662402373625]
	TIME [epoch: 9.79 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36682557806326777		[learning rate: 0.0018562]
	Learning Rate: 0.00185623
	LOSS [training: 0.36682557806326777 | validation: 0.4240377619311469]
	TIME [epoch: 9.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5283151505822009		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.5283151505822009 | validation: 0.6362010968355528]
	TIME [epoch: 9.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49465716859320175		[learning rate: 0.0018473]
	Learning Rate: 0.00184725
	LOSS [training: 0.49465716859320175 | validation: 0.47446269394729657]
	TIME [epoch: 9.81 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4353099519068101		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.4353099519068101 | validation: 0.3934256416063306]
	TIME [epoch: 9.81 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32914359045874203		[learning rate: 0.0018383]
	Learning Rate: 0.00183832
	LOSS [training: 0.32914359045874203 | validation: 0.33127090937857145]
	TIME [epoch: 9.79 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25618622526961243		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.25618622526961243 | validation: 0.5246996857537178]
	TIME [epoch: 9.79 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32200558363251186		[learning rate: 0.0018294]
	Learning Rate: 0.00182943
	LOSS [training: 0.32200558363251186 | validation: 0.27751909389507795]
	TIME [epoch: 9.81 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2605070328753807		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.2605070328753807 | validation: 0.28473721293559556]
	TIME [epoch: 9.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27864408592720713		[learning rate: 0.0018206]
	Learning Rate: 0.00182058
	LOSS [training: 0.27864408592720713 | validation: 0.2789767084748214]
	TIME [epoch: 9.79 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37209571365581995		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.37209571365581995 | validation: 0.3957057571642541]
	TIME [epoch: 9.81 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.323847118218347		[learning rate: 0.0018118]
	Learning Rate: 0.00181178
	LOSS [training: 0.323847118218347 | validation: 0.2859682508814639]
	TIME [epoch: 9.79 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40860995550223017		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.40860995550223017 | validation: 0.3315070937179291]
	TIME [epoch: 9.79 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32384011957404557		[learning rate: 0.001803]
	Learning Rate: 0.00180302
	LOSS [training: 0.32384011957404557 | validation: 0.33011343547398964]
	TIME [epoch: 9.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2638434294230293		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.2638434294230293 | validation: 0.23135914295150012]
	TIME [epoch: 9.82 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2299483484569028		[learning rate: 0.0017943]
	Learning Rate: 0.0017943
	LOSS [training: 0.2299483484569028 | validation: 0.27736732669307096]
	TIME [epoch: 9.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2695701641131626		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.2695701641131626 | validation: 0.3260091359882227]
	TIME [epoch: 9.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2705846494602877		[learning rate: 0.0017856]
	Learning Rate: 0.00178562
	LOSS [training: 0.2705846494602877 | validation: 0.34181420285044767]
	TIME [epoch: 9.81 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27730378781356496		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.27730378781356496 | validation: 0.3044187029805256]
	TIME [epoch: 9.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39225403908706585		[learning rate: 0.001777]
	Learning Rate: 0.00177699
	LOSS [training: 0.39225403908706585 | validation: 0.36189938214049167]
	TIME [epoch: 9.78 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24513454761905779		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.24513454761905779 | validation: 0.3506878694861815]
	TIME [epoch: 9.79 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30023480390061447		[learning rate: 0.0017684]
	Learning Rate: 0.00176839
	LOSS [training: 0.30023480390061447 | validation: 0.2413766798283595]
	TIME [epoch: 9.82 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2693924080286032		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.2693924080286032 | validation: 0.22044463023207697]
	TIME [epoch: 9.79 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2642171348900961		[learning rate: 0.0017598]
	Learning Rate: 0.00175984
	LOSS [training: 0.2642171348900961 | validation: 0.4722913609683057]
	TIME [epoch: 9.79 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.336477780801009		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.336477780801009 | validation: 0.33813141463367813]
	TIME [epoch: 9.8 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2564528122152596		[learning rate: 0.0017513]
	Learning Rate: 0.00175133
	LOSS [training: 0.2564528122152596 | validation: 0.2559326845833848]
	TIME [epoch: 9.8 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28861297208385217		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.28861297208385217 | validation: 0.4771883320888135]
	TIME [epoch: 9.79 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2718405968602663		[learning rate: 0.0017429]
	Learning Rate: 0.00174286
	LOSS [training: 0.2718405968602663 | validation: 0.5736251700174212]
	TIME [epoch: 9.79 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26543604999759457		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.26543604999759457 | validation: 0.32351027161219537]
	TIME [epoch: 9.8 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.256413614860271		[learning rate: 0.0017344]
	Learning Rate: 0.00173443
	LOSS [training: 0.256413614860271 | validation: 0.3258489907555513]
	TIME [epoch: 9.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2828549353143495		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.2828549353143495 | validation: 0.33076928644523207]
	TIME [epoch: 9.79 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.280683718598912		[learning rate: 0.001726]
	Learning Rate: 0.00172605
	LOSS [training: 0.280683718598912 | validation: 0.5346054377988484]
	TIME [epoch: 9.81 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34128977420944434		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.34128977420944434 | validation: 0.3068751681599157]
	TIME [epoch: 9.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2716345408418356		[learning rate: 0.0017177]
	Learning Rate: 0.0017177
	LOSS [training: 0.2716345408418356 | validation: 0.4548981010707688]
	TIME [epoch: 9.79 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28288903588584985		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.28288903588584985 | validation: 0.22691458114808086]
	TIME [epoch: 9.79 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22211262893441058		[learning rate: 0.0017094]
	Learning Rate: 0.00170939
	LOSS [training: 0.22211262893441058 | validation: 0.5400016248481738]
	TIME [epoch: 9.83 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4773531390710021		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.4773531390710021 | validation: 0.36682445773420264]
	TIME [epoch: 9.81 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36839520529789355		[learning rate: 0.0017011]
	Learning Rate: 0.00170113
	LOSS [training: 0.36839520529789355 | validation: 0.31152113111716856]
	TIME [epoch: 9.81 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3490875971591789		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.3490875971591789 | validation: 0.39619006670548423]
	TIME [epoch: 9.8 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4534934477411296		[learning rate: 0.0016929]
	Learning Rate: 0.0016929
	LOSS [training: 0.4534934477411296 | validation: 0.3169883755215189]
	TIME [epoch: 9.82 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3553629226219994		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.3553629226219994 | validation: 0.2909153933420798]
	TIME [epoch: 9.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2658881567667179		[learning rate: 0.0016847]
	Learning Rate: 0.00168471
	LOSS [training: 0.2658881567667179 | validation: 0.31692784108018346]
	TIME [epoch: 9.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22366181536589247		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.22366181536589247 | validation: 0.3433808698976745]
	TIME [epoch: 9.82 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27553604496928236		[learning rate: 0.0016766]
	Learning Rate: 0.00167657
	LOSS [training: 0.27553604496928236 | validation: 0.2337765051197341]
	TIME [epoch: 9.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33950044947735425		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.33950044947735425 | validation: 0.22804618397996115]
	TIME [epoch: 9.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5197009705583209		[learning rate: 0.0016685]
	Learning Rate: 0.00166846
	LOSS [training: 0.5197009705583209 | validation: 0.8044442646972522]
	TIME [epoch: 9.81 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5883257351446012		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.5883257351446012 | validation: 0.31648576477904866]
	TIME [epoch: 9.81 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31362274326817985		[learning rate: 0.0016604]
	Learning Rate: 0.00166039
	LOSS [training: 0.31362274326817985 | validation: 0.5006456348812075]
	TIME [epoch: 9.81 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3952240983026222		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.3952240983026222 | validation: 0.18460330005202166]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_842.pth
	Model improved!!!
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2891575401222567		[learning rate: 0.0016524]
	Learning Rate: 0.00165236
	LOSS [training: 0.2891575401222567 | validation: 0.20051097137956794]
	TIME [epoch: 9.83 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22963788377525352		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.22963788377525352 | validation: 0.2711702468776208]
	TIME [epoch: 9.81 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2699594339827029		[learning rate: 0.0016444]
	Learning Rate: 0.00164437
	LOSS [training: 0.2699594339827029 | validation: 0.32833820840208416]
	TIME [epoch: 9.81 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26987036161901473		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.26987036161901473 | validation: 0.1822823469813654]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_846.pth
	Model improved!!!
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26835772459483553		[learning rate: 0.0016364]
	Learning Rate: 0.00163642
	LOSS [training: 0.26835772459483553 | validation: 0.19769931087895554]
	TIME [epoch: 9.83 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27494196639386503		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.27494196639386503 | validation: 0.5239177840664242]
	TIME [epoch: 9.81 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3626372733416224		[learning rate: 0.0016285]
	Learning Rate: 0.00162851
	LOSS [training: 0.3626372733416224 | validation: 0.2769555155043375]
	TIME [epoch: 9.81 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22702339367163607		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.22702339367163607 | validation: 0.22026054814908805]
	TIME [epoch: 9.82 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21956424129209617		[learning rate: 0.0016206]
	Learning Rate: 0.00162063
	LOSS [training: 0.21956424129209617 | validation: 0.1880970073584944]
	TIME [epoch: 9.81 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3060553303165842		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.3060553303165842 | validation: 0.3548738754898591]
	TIME [epoch: 9.81 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29744965120072614		[learning rate: 0.0016128]
	Learning Rate: 0.00161279
	LOSS [training: 0.29744965120072614 | validation: 0.47703388441531885]
	TIME [epoch: 9.81 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28433182358057907		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.28433182358057907 | validation: 0.3317449628218144]
	TIME [epoch: 9.83 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2280882656804874		[learning rate: 0.001605]
	Learning Rate: 0.001605
	LOSS [training: 0.2280882656804874 | validation: 0.2212211221116619]
	TIME [epoch: 9.81 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19394384772932333		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.19394384772932333 | validation: 0.24185228672872774]
	TIME [epoch: 9.81 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2555191577765456		[learning rate: 0.0015972]
	Learning Rate: 0.00159723
	LOSS [training: 0.2555191577765456 | validation: 0.2717425671272261]
	TIME [epoch: 9.83 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25684655434186554		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.25684655434186554 | validation: 0.3846062162335486]
	TIME [epoch: 9.82 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3472048389177393		[learning rate: 0.0015895]
	Learning Rate: 0.00158951
	LOSS [training: 0.3472048389177393 | validation: 0.345874791078919]
	TIME [epoch: 9.81 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3027016418693194		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.3027016418693194 | validation: 0.3234901685294434]
	TIME [epoch: 9.81 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21673576574520995		[learning rate: 0.0015818]
	Learning Rate: 0.00158182
	LOSS [training: 0.21673576574520995 | validation: 0.3403989161902581]
	TIME [epoch: 9.83 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27604237105936014		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.27604237105936014 | validation: 0.31106548198683354]
	TIME [epoch: 9.82 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25413769698383476		[learning rate: 0.0015742]
	Learning Rate: 0.00157417
	LOSS [training: 0.25413769698383476 | validation: 0.2794237022666487]
	TIME [epoch: 9.81 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24452578323195495		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.24452578323195495 | validation: 0.36777710044852074]
	TIME [epoch: 9.82 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3003222265395		[learning rate: 0.0015666]
	Learning Rate: 0.00156656
	LOSS [training: 0.3003222265395 | validation: 0.40812929826232525]
	TIME [epoch: 9.82 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3603764552426508		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.3603764552426508 | validation: 0.3804435834009318]
	TIME [epoch: 9.81 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24215205851800095		[learning rate: 0.001559]
	Learning Rate: 0.00155899
	LOSS [training: 0.24215205851800095 | validation: 0.40862731565492993]
	TIME [epoch: 9.81 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36287087414001984		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.36287087414001984 | validation: 0.23174187337805408]
	TIME [epoch: 9.83 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2734322711389917		[learning rate: 0.0015514]
	Learning Rate: 0.00155145
	LOSS [training: 0.2734322711389917 | validation: 0.37382542498343996]
	TIME [epoch: 9.81 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34507236277544057		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.34507236277544057 | validation: 0.3909492592302799]
	TIME [epoch: 9.81 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2834827346591964		[learning rate: 0.0015439]
	Learning Rate: 0.00154394
	LOSS [training: 0.2834827346591964 | validation: 0.32227348136155926]
	TIME [epoch: 9.82 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.566846515473333		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.566846515473333 | validation: 0.36784685845474613]
	TIME [epoch: 9.82 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26030126929708		[learning rate: 0.0015365]
	Learning Rate: 0.00153648
	LOSS [training: 0.26030126929708 | validation: 0.2192225296619474]
	TIME [epoch: 9.81 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3283429331252309		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.3283429331252309 | validation: 0.455643982285565]
	TIME [epoch: 9.81 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23402883632795582		[learning rate: 0.001529]
	Learning Rate: 0.00152905
	LOSS [training: 0.23402883632795582 | validation: 0.2579132356782835]
	TIME [epoch: 9.82 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3071575417595128		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.3071575417595128 | validation: 0.21558679566605896]
	TIME [epoch: 9.81 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19694585904726442		[learning rate: 0.0015217]
	Learning Rate: 0.00152165
	LOSS [training: 0.19694585904726442 | validation: 0.45373371652799566]
	TIME [epoch: 9.81 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3706431173403912		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.3706431173403912 | validation: 0.2767005890004912]
	TIME [epoch: 9.81 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.294771647899626		[learning rate: 0.0015143]
	Learning Rate: 0.00151429
	LOSS [training: 0.294771647899626 | validation: 0.29312598527065586]
	TIME [epoch: 9.82 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22449630877598045		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.22449630877598045 | validation: 0.30545392762956736]
	TIME [epoch: 9.81 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2275775372560555		[learning rate: 0.001507]
	Learning Rate: 0.00150697
	LOSS [training: 0.2275775372560555 | validation: 0.2789105442492934]
	TIME [epoch: 9.81 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42318844274778666		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.42318844274778666 | validation: 0.2631707178633918]
	TIME [epoch: 9.83 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31418656899070463		[learning rate: 0.0014997]
	Learning Rate: 0.00149968
	LOSS [training: 0.31418656899070463 | validation: 0.1945994163313619]
	TIME [epoch: 9.82 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25155107280146877		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.25155107280146877 | validation: 0.45947263561034674]
	TIME [epoch: 9.81 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4097866882565581		[learning rate: 0.0014924]
	Learning Rate: 0.00149243
	LOSS [training: 0.4097866882565581 | validation: 0.2911614585560107]
	TIME [epoch: 9.81 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2613467552494984		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.2613467552494984 | validation: 0.28299961091147907]
	TIME [epoch: 9.83 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24156231648558202		[learning rate: 0.0014852]
	Learning Rate: 0.00148522
	LOSS [training: 0.24156231648558202 | validation: 0.15918913647256858]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_887.pth
	Model improved!!!
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2100834505935671		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.2100834505935671 | validation: 0.24796405773199023]
	TIME [epoch: 9.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3850693070810337		[learning rate: 0.001478]
	Learning Rate: 0.00147803
	LOSS [training: 0.3850693070810337 | validation: 0.2802005237298059]
	TIME [epoch: 9.83 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25150639754004706		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.25150639754004706 | validation: 0.23137853479796577]
	TIME [epoch: 9.81 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2522402884598437		[learning rate: 0.0014709]
	Learning Rate: 0.00147089
	LOSS [training: 0.2522402884598437 | validation: 0.23327977180770446]
	TIME [epoch: 9.81 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1698724320752089		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.1698724320752089 | validation: 0.22369051726154127]
	TIME [epoch: 9.81 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4250131865539692		[learning rate: 0.0014638]
	Learning Rate: 0.00146377
	LOSS [training: 0.4250131865539692 | validation: 0.4112567314552788]
	TIME [epoch: 9.83 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3058413011302873		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.3058413011302873 | validation: 0.3011447414292049]
	TIME [epoch: 9.81 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2140375176830609		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.2140375176830609 | validation: 0.2495157561102481]
	TIME [epoch: 9.81 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23015566511426672		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.23015566511426672 | validation: 0.47286055156715373]
	TIME [epoch: 9.82 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2597836317459107		[learning rate: 0.0014497]
	Learning Rate: 0.00144965
	LOSS [training: 0.2597836317459107 | validation: 0.33596326366923346]
	TIME [epoch: 9.81 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35423938145886275		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.35423938145886275 | validation: 0.3580791639872494]
	TIME [epoch: 9.81 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32856928592220813		[learning rate: 0.0014426]
	Learning Rate: 0.00144264
	LOSS [training: 0.32856928592220813 | validation: 0.2977953148576114]
	TIME [epoch: 9.81 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2223971396787888		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.2223971396787888 | validation: 0.23234879230661215]
	TIME [epoch: 9.82 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25078814283408646		[learning rate: 0.0014357]
	Learning Rate: 0.00143566
	LOSS [training: 0.25078814283408646 | validation: 0.18717601884107854]
	TIME [epoch: 9.81 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20320515685418034		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.20320515685418034 | validation: 0.2278227186510784]
	TIME [epoch: 9.81 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21059570584900394		[learning rate: 0.0014287]
	Learning Rate: 0.00142872
	LOSS [training: 0.21059570584900394 | validation: 0.3622922232549179]
	TIME [epoch: 9.83 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26939437344636447		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.26939437344636447 | validation: 0.3462344231381694]
	TIME [epoch: 9.81 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23216188775951302		[learning rate: 0.0014218]
	Learning Rate: 0.00142181
	LOSS [training: 0.23216188775951302 | validation: 0.39965194788238195]
	TIME [epoch: 9.81 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24271246327797255		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.24271246327797255 | validation: 0.3424181406419787]
	TIME [epoch: 9.8 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20228917147477626		[learning rate: 0.0014149]
	Learning Rate: 0.00141494
	LOSS [training: 0.20228917147477626 | validation: 0.4728554152078212]
	TIME [epoch: 9.83 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3333359013343237		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.3333359013343237 | validation: 0.2611461327583672]
	TIME [epoch: 9.81 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1861696268706241		[learning rate: 0.0014081]
	Learning Rate: 0.00140809
	LOSS [training: 0.1861696268706241 | validation: 0.2780504410339299]
	TIME [epoch: 9.81 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27098712787532786		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.27098712787532786 | validation: 0.21747350961281384]
	TIME [epoch: 9.81 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19670457163166233		[learning rate: 0.0014013]
	Learning Rate: 0.00140128
	LOSS [training: 0.19670457163166233 | validation: 0.41877211002071923]
	TIME [epoch: 9.82 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4190770360560589		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.4190770360560589 | validation: 0.30779167476429964]
	TIME [epoch: 9.81 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2626807572700719		[learning rate: 0.0013945]
	Learning Rate: 0.00139451
	LOSS [training: 0.2626807572700719 | validation: 0.32036488957864123]
	TIME [epoch: 9.81 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3752281935845409		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.3752281935845409 | validation: 0.299345848835309]
	TIME [epoch: 9.82 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26452565398118444		[learning rate: 0.0013878]
	Learning Rate: 0.00138776
	LOSS [training: 0.26452565398118444 | validation: 0.3493297306557072]
	TIME [epoch: 9.81 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2508341303753418		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.2508341303753418 | validation: 0.274395262067324]
	TIME [epoch: 9.81 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2794655263654531		[learning rate: 0.0013811]
	Learning Rate: 0.00138105
	LOSS [training: 0.2794655263654531 | validation: 0.1700892889916748]
	TIME [epoch: 9.82 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2678869446197988		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.2678869446197988 | validation: 0.4723345128028102]
	TIME [epoch: 9.82 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.365938125042365		[learning rate: 0.0013744]
	Learning Rate: 0.00137437
	LOSS [training: 0.365938125042365 | validation: 0.4296498994713669]
	TIME [epoch: 9.81 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3596837816043891		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.3596837816043891 | validation: 0.2800633327718267]
	TIME [epoch: 9.8 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2617481756690766		[learning rate: 0.0013677]
	Learning Rate: 0.00136773
	LOSS [training: 0.2617481756690766 | validation: 0.26053385372519694]
	TIME [epoch: 9.82 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24486618853670122		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.24486618853670122 | validation: 0.32228298223568147]
	TIME [epoch: 9.81 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33456109743027923		[learning rate: 0.0013611]
	Learning Rate: 0.00136111
	LOSS [training: 0.33456109743027923 | validation: 0.18330595886509166]
	TIME [epoch: 9.81 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3002411988770345		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.3002411988770345 | validation: 0.3329888722071968]
	TIME [epoch: 9.8 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3101962802309444		[learning rate: 0.0013545]
	Learning Rate: 0.00135453
	LOSS [training: 0.3101962802309444 | validation: 0.3319044286147587]
	TIME [epoch: 9.83 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2578238175857658		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.2578238175857658 | validation: 0.18850163638304857]
	TIME [epoch: 9.81 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3521836047691087		[learning rate: 0.001348]
	Learning Rate: 0.00134798
	LOSS [training: 0.3521836047691087 | validation: 0.5721205574564633]
	TIME [epoch: 9.81 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48039692454511485		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.48039692454511485 | validation: 0.3730741197102177]
	TIME [epoch: 9.82 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077029483197623		[learning rate: 0.0013415]
	Learning Rate: 0.00134146
	LOSS [training: 0.3077029483197623 | validation: 0.5523780467077566]
	TIME [epoch: 9.81 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37829492349435545		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.37829492349435545 | validation: 0.23994655424711525]
	TIME [epoch: 9.81 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21861180344476433		[learning rate: 0.001335]
	Learning Rate: 0.00133498
	LOSS [training: 0.21861180344476433 | validation: 0.5700701479015181]
	TIME [epoch: 9.8 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44546701057076205		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.44546701057076205 | validation: 0.316367026920523]
	TIME [epoch: 9.83 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2445881307304442		[learning rate: 0.0013285]
	Learning Rate: 0.00132852
	LOSS [training: 0.2445881307304442 | validation: 0.21408557898485947]
	TIME [epoch: 9.81 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27932954154167716		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.27932954154167716 | validation: 0.2237675930334579]
	TIME [epoch: 9.81 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20503652206013845		[learning rate: 0.0013221]
	Learning Rate: 0.0013221
	LOSS [training: 0.20503652206013845 | validation: 0.2749508067921678]
	TIME [epoch: 9.82 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2781444148596758		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.2781444148596758 | validation: 0.25230489686013186]
	TIME [epoch: 9.81 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38481680322421574		[learning rate: 0.0013157]
	Learning Rate: 0.0013157
	LOSS [training: 0.38481680322421574 | validation: 0.36685600512309563]
	TIME [epoch: 9.81 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2735446237311228		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.2735446237311228 | validation: 0.2485300150878335]
	TIME [epoch: 9.8 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2902023200505586		[learning rate: 0.0013093]
	Learning Rate: 0.00130934
	LOSS [training: 0.2902023200505586 | validation: 0.20365612219180917]
	TIME [epoch: 9.82 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20095082958002478		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.20095082958002478 | validation: 0.198250893173254]
	TIME [epoch: 9.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2253066381925958		[learning rate: 0.001303]
	Learning Rate: 0.00130301
	LOSS [training: 0.2253066381925958 | validation: 0.45346240842186597]
	TIME [epoch: 9.81 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41566882388824355		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.41566882388824355 | validation: 0.4023528747304925]
	TIME [epoch: 9.82 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29454240143934907		[learning rate: 0.0012967]
	Learning Rate: 0.00129671
	LOSS [training: 0.29454240143934907 | validation: 0.34826377427789135]
	TIME [epoch: 9.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21718634708342482		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.21718634708342482 | validation: 0.19661559333159098]
	TIME [epoch: 9.8 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19644795412863386		[learning rate: 0.0012904]
	Learning Rate: 0.00129044
	LOSS [training: 0.19644795412863386 | validation: 0.22457247753897774]
	TIME [epoch: 9.8 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2277947958298346		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.2277947958298346 | validation: 0.2826927894456895]
	TIME [epoch: 9.82 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3274787362604858		[learning rate: 0.0012842]
	Learning Rate: 0.0012842
	LOSS [training: 0.3274787362604858 | validation: 0.26216643205039075]
	TIME [epoch: 9.8 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3626666493444056		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.3626666493444056 | validation: 0.34397932787481905]
	TIME [epoch: 9.81 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2700490818972167		[learning rate: 0.001278]
	Learning Rate: 0.00127799
	LOSS [training: 0.2700490818972167 | validation: 0.2397904826120476]
	TIME [epoch: 9.81 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2588103769246849		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.2588103769246849 | validation: 0.18928106111930096]
	TIME [epoch: 9.82 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30040634456904325		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.30040634456904325 | validation: 0.33202330955103576]
	TIME [epoch: 9.81 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2556972858813882		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.2556972858813882 | validation: 0.38352307340926045]
	TIME [epoch: 9.8 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3023075349532759		[learning rate: 0.0012657]
	Learning Rate: 0.00126566
	LOSS [training: 0.3023075349532759 | validation: 0.23264689697258478]
	TIME [epoch: 9.83 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25562146720159395		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.25562146720159395 | validation: 0.48078074123362796]
	TIME [epoch: 9.81 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3917550790656572		[learning rate: 0.0012595]
	Learning Rate: 0.00125954
	LOSS [training: 0.3917550790656572 | validation: 0.2518036636132123]
	TIME [epoch: 9.81 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22591688334297505		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.22591688334297505 | validation: 0.22447106351843296]
	TIME [epoch: 9.82 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22658929635228361		[learning rate: 0.0012534]
	Learning Rate: 0.00125344
	LOSS [training: 0.22658929635228361 | validation: 0.21549365619138414]
	TIME [epoch: 9.81 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2984752517585175		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.2984752517585175 | validation: 0.2747268270414313]
	TIME [epoch: 9.8 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26472131235713814		[learning rate: 0.0012474]
	Learning Rate: 0.00124738
	LOSS [training: 0.26472131235713814 | validation: 0.22248783034199413]
	TIME [epoch: 9.8 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20499500014116462		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.20499500014116462 | validation: 0.14498494784826854]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_960.pth
	Model improved!!!
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27711396071741623		[learning rate: 0.0012414]
	Learning Rate: 0.00124135
	LOSS [training: 0.27711396071741623 | validation: 0.19708358892970182]
	TIME [epoch: 9.81 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22848316913090536		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.22848316913090536 | validation: 0.16837153229777094]
	TIME [epoch: 9.81 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26175706160841505		[learning rate: 0.0012353]
	Learning Rate: 0.00123535
	LOSS [training: 0.26175706160841505 | validation: 0.23620469148520798]
	TIME [epoch: 9.81 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2748225379138761		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.2748225379138761 | validation: 0.1497934568628132]
	TIME [epoch: 9.82 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19643535741215098		[learning rate: 0.0012294]
	Learning Rate: 0.00122937
	LOSS [training: 0.19643535741215098 | validation: 0.1629678074349964]
	TIME [epoch: 9.81 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20334876511523134		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.20334876511523134 | validation: 0.18637182879967384]
	TIME [epoch: 9.8 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3050745852080207		[learning rate: 0.0012234]
	Learning Rate: 0.00122343
	LOSS [training: 0.3050745852080207 | validation: 0.21276852674639352]
	TIME [epoch: 9.82 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2262569855277584		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.2262569855277584 | validation: 0.17287864848129972]
	TIME [epoch: 9.81 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18212784717210592		[learning rate: 0.0012175]
	Learning Rate: 0.00121751
	LOSS [training: 0.18212784717210592 | validation: 0.1893521107984881]
	TIME [epoch: 9.81 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18514251069232263		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.18514251069232263 | validation: 0.22376405930095275]
	TIME [epoch: 9.81 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26913094734902987		[learning rate: 0.0012116]
	Learning Rate: 0.00121163
	LOSS [training: 0.26913094734902987 | validation: 0.2405003133023663]
	TIME [epoch: 9.82 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2723030298037411		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.2723030298037411 | validation: 0.3150769231854221]
	TIME [epoch: 9.81 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19859053231145612		[learning rate: 0.0012058]
	Learning Rate: 0.00120577
	LOSS [training: 0.19859053231145612 | validation: 0.2662389188497988]
	TIME [epoch: 9.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2563851151869539		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.2563851151869539 | validation: 0.16850268929155132]
	TIME [epoch: 9.82 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21448748012465635		[learning rate: 0.0011999]
	Learning Rate: 0.00119994
	LOSS [training: 0.21448748012465635 | validation: 0.21473524552542253]
	TIME [epoch: 9.81 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3665575337422214		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.3665575337422214 | validation: 0.38683049553473636]
	TIME [epoch: 9.81 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3301798006946495		[learning rate: 0.0011941]
	Learning Rate: 0.00119413
	LOSS [training: 0.3301798006946495 | validation: 0.4609651832896228]
	TIME [epoch: 9.8 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38011185529727504		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.38011185529727504 | validation: 0.5832680446203256]
	TIME [epoch: 9.82 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6128120013414831		[learning rate: 0.0011884]
	Learning Rate: 0.00118836
	LOSS [training: 0.6128120013414831 | validation: 0.30599359140696086]
	TIME [epoch: 9.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.337446861019265		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.337446861019265 | validation: 0.23390476386515943]
	TIME [epoch: 9.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1925050160875627		[learning rate: 0.0011826]
	Learning Rate: 0.00118261
	LOSS [training: 0.1925050160875627 | validation: 0.15128514257426312]
	TIME [epoch: 9.82 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31226792925403385		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.31226792925403385 | validation: 0.32301272144633003]
	TIME [epoch: 9.81 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2193109515118153		[learning rate: 0.0011769]
	Learning Rate: 0.00117689
	LOSS [training: 0.2193109515118153 | validation: 0.1678943028161283]
	TIME [epoch: 9.81 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21631596420055893		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.21631596420055893 | validation: 0.404286423864572]
	TIME [epoch: 9.8 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35281809360123295		[learning rate: 0.0011712]
	Learning Rate: 0.0011712
	LOSS [training: 0.35281809360123295 | validation: 0.2117758640009215]
	TIME [epoch: 9.82 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26129820214748745		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.26129820214748745 | validation: 0.27406758218451366]
	TIME [epoch: 9.8 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22405338529692648		[learning rate: 0.0011655]
	Learning Rate: 0.00116554
	LOSS [training: 0.22405338529692648 | validation: 0.20126700076705903]
	TIME [epoch: 9.8 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20052186958685767		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.20052186958685767 | validation: 0.16403021495957204]
	TIME [epoch: 9.8 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17486578510317824		[learning rate: 0.0011599]
	Learning Rate: 0.0011599
	LOSS [training: 0.17486578510317824 | validation: 0.26867534505722235]
	TIME [epoch: 9.81 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35119693215651304		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.35119693215651304 | validation: 0.1352582086359048]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_990.pth
	Model improved!!!
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32215113005346885		[learning rate: 0.0011543]
	Learning Rate: 0.00115429
	LOSS [training: 0.32215113005346885 | validation: 0.2028316267852216]
	TIME [epoch: 9.81 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3030012291022754		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.3030012291022754 | validation: 0.14790163863648784]
	TIME [epoch: 9.82 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27483285754748027		[learning rate: 0.0011487]
	Learning Rate: 0.00114871
	LOSS [training: 0.27483285754748027 | validation: 0.30381700295510516]
	TIME [epoch: 9.81 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40621275350915675		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.40621275350915675 | validation: 0.3296403666268325]
	TIME [epoch: 9.8 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30916900781974854		[learning rate: 0.0011432]
	Learning Rate: 0.00114316
	LOSS [training: 0.30916900781974854 | validation: 0.42683713437619747]
	TIME [epoch: 9.81 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37276650170046133		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.37276650170046133 | validation: 0.17705984012152867]
	TIME [epoch: 9.81 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23786530966074454		[learning rate: 0.0011376]
	Learning Rate: 0.00113763
	LOSS [training: 0.23786530966074454 | validation: 0.3148031546786779]
	TIME [epoch: 9.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3067014441790409		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.3067014441790409 | validation: 0.33456974823899105]
	TIME [epoch: 9.8 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27102718460248487		[learning rate: 0.0011321]
	Learning Rate: 0.00113213
	LOSS [training: 0.27102718460248487 | validation: 0.22416471630288662]
	TIME [epoch: 9.82 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33718234255072554		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.33718234255072554 | validation: 0.1925104478149241]
	TIME [epoch: 9.81 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2936903770626433		[learning rate: 0.0011267]
	Learning Rate: 0.00112665
	LOSS [training: 0.2936903770626433 | validation: 0.2489945734592736]
	TIME [epoch: 9.8 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45043294006763557		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.45043294006763557 | validation: 0.1918702447966397]
	TIME [epoch: 9.81 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22329754669764784		[learning rate: 0.0011212]
	Learning Rate: 0.0011212
	LOSS [training: 0.22329754669764784 | validation: 0.20152165804980904]
	TIME [epoch: 9.81 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23339965991669215		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.23339965991669215 | validation: 0.3312555160630191]
	TIME [epoch: 9.8 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25224718982283767		[learning rate: 0.0011158]
	Learning Rate: 0.00111578
	LOSS [training: 0.25224718982283767 | validation: 0.195045501957093]
	TIME [epoch: 9.81 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20806472589267427		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.20806472589267427 | validation: 0.1876803712316112]
	TIME [epoch: 9.82 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2093478584967941		[learning rate: 0.0011104]
	Learning Rate: 0.00111039
	LOSS [training: 0.2093478584967941 | validation: 0.2932907678028713]
	TIME [epoch: 9.81 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2643684373665067		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.2643684373665067 | validation: 0.420636280005627]
	TIME [epoch: 9.8 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22956277820609433		[learning rate: 0.001105]
	Learning Rate: 0.00110502
	LOSS [training: 0.22956277820609433 | validation: 0.1982386696374762]
	TIME [epoch: 9.81 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1695337741558522		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.1695337741558522 | validation: 0.16279306024441784]
	TIME [epoch: 9.82 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18662647508485697		[learning rate: 0.0010997]
	Learning Rate: 0.00109967
	LOSS [training: 0.18662647508485697 | validation: 0.19068804042612436]
	TIME [epoch: 9.81 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19890274957430715		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.19890274957430715 | validation: 0.5917220010111346]
	TIME [epoch: 9.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36914342542015194		[learning rate: 0.0010944]
	Learning Rate: 0.00109435
	LOSS [training: 0.36914342542015194 | validation: 0.30706958656332844]
	TIME [epoch: 9.82 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2492208499511764		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.2492208499511764 | validation: 0.37336987707719216]
	TIME [epoch: 9.81 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24430464510662048		[learning rate: 0.0010891]
	Learning Rate: 0.00108906
	LOSS [training: 0.24430464510662048 | validation: 0.2441022951677108]
	TIME [epoch: 9.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22204478972825842		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.22204478972825842 | validation: 0.254090591368422]
	TIME [epoch: 9.81 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24144924053754444		[learning rate: 0.0010838]
	Learning Rate: 0.0010838
	LOSS [training: 0.24144924053754444 | validation: 0.43177118147729915]
	TIME [epoch: 9.82 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34285867476688614		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.34285867476688614 | validation: 0.813193329217107]
	TIME [epoch: 9.81 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3624549547636019		[learning rate: 0.0010786]
	Learning Rate: 0.00107855
	LOSS [training: 0.3624549547636019 | validation: 0.22539991913350207]
	TIME [epoch: 9.81 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3166712739612409		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.3166712739612409 | validation: 0.3140282024423094]
	TIME [epoch: 9.82 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23964854982875416		[learning rate: 0.0010733]
	Learning Rate: 0.00107334
	LOSS [training: 0.23964854982875416 | validation: 0.20571833826587183]
	TIME [epoch: 9.8 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27962821505951563		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.27962821505951563 | validation: 0.31028343678408205]
	TIME [epoch: 9.81 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20187583555373187		[learning rate: 0.0010681]
	Learning Rate: 0.00106815
	LOSS [training: 0.20187583555373187 | validation: 0.24719209776629247]
	TIME [epoch: 9.8 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23581795956733304		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.23581795956733304 | validation: 0.2290094027655114]
	TIME [epoch: 9.82 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23592467059925873		[learning rate: 0.001063]
	Learning Rate: 0.00106298
	LOSS [training: 0.23592467059925873 | validation: 0.23381667338050632]
	TIME [epoch: 9.8 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26346815347938063		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.26346815347938063 | validation: 0.2357673530131347]
	TIME [epoch: 9.81 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26196315546714055		[learning rate: 0.0010578]
	Learning Rate: 0.00105784
	LOSS [training: 0.26196315546714055 | validation: 0.31179671085988125]
	TIME [epoch: 9.82 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2021656352637562		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.2021656352637562 | validation: 0.20056231389738244]
	TIME [epoch: 9.8 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41669211600332823		[learning rate: 0.0010527]
	Learning Rate: 0.00105273
	LOSS [training: 0.41669211600332823 | validation: 0.2537237346786526]
	TIME [epoch: 9.81 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23010183347704682		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.23010183347704682 | validation: 0.20477118343297002]
	TIME [epoch: 9.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16714922051268535		[learning rate: 0.0010476]
	Learning Rate: 0.00104764
	LOSS [training: 0.16714922051268535 | validation: 0.16808642447091843]
	TIME [epoch: 9.83 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19152286141002797		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.19152286141002797 | validation: 0.17211973375086942]
	TIME [epoch: 9.81 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21333544496368306		[learning rate: 0.0010426]
	Learning Rate: 0.00104257
	LOSS [training: 0.21333544496368306 | validation: 0.30143732524590816]
	TIME [epoch: 9.8 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23325795371260843		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.23325795371260843 | validation: 0.5029377457576455]
	TIME [epoch: 9.82 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3512921502908953		[learning rate: 0.0010375]
	Learning Rate: 0.00103753
	LOSS [training: 0.3512921502908953 | validation: 0.3100230377813354]
	TIME [epoch: 9.82 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23059554782130118		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.23059554782130118 | validation: 0.21562728442970105]
	TIME [epoch: 9.8 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23274581790213214		[learning rate: 0.0010325]
	Learning Rate: 0.00103251
	LOSS [training: 0.23274581790213214 | validation: 0.3220660113248158]
	TIME [epoch: 9.8 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3739782085907052		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.3739782085907052 | validation: 0.36347615542229206]
	TIME [epoch: 9.82 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25493553180226924		[learning rate: 0.0010275]
	Learning Rate: 0.00102752
	LOSS [training: 0.25493553180226924 | validation: 0.2555205795639795]
	TIME [epoch: 9.81 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.298144838183078		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.298144838183078 | validation: 0.26776005279350146]
	TIME [epoch: 9.8 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3091045104271898		[learning rate: 0.0010225]
	Learning Rate: 0.00102255
	LOSS [training: 0.3091045104271898 | validation: 0.5571766599449827]
	TIME [epoch: 9.81 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3523301287905044		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.3523301287905044 | validation: 0.23606454879739291]
	TIME [epoch: 9.81 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1541273371639769		[learning rate: 0.0010176]
	Learning Rate: 0.0010176
	LOSS [training: 0.1541273371639769 | validation: 0.21682809027627195]
	TIME [epoch: 9.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18330819610087062		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.18330819610087062 | validation: 0.24876009884787]
	TIME [epoch: 9.81 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18055016819255312		[learning rate: 0.0010127]
	Learning Rate: 0.00101268
	LOSS [training: 0.18055016819255312 | validation: 0.2439746279911136]
	TIME [epoch: 9.82 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17771809502574676		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.17771809502574676 | validation: 0.19213802589132747]
	TIME [epoch: 9.81 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14190123093780288		[learning rate: 0.0010078]
	Learning Rate: 0.00100779
	LOSS [training: 0.14190123093780288 | validation: 0.23936165745584653]
	TIME [epoch: 9.8 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.211758463922825		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.211758463922825 | validation: 0.17685796906127774]
	TIME [epoch: 9.81 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1628221860366349		[learning rate: 0.0010029]
	Learning Rate: 0.00100291
	LOSS [training: 0.1628221860366349 | validation: 0.26112404560652397]
	TIME [epoch: 9.83 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2742013869678485		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.2742013869678485 | validation: 0.3866181284839687]
	TIME [epoch: 9.81 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21855439086561185		[learning rate: 0.00099806]
	Learning Rate: 0.000998063
	LOSS [training: 0.21855439086561185 | validation: 0.29042582430918396]
	TIME [epoch: 9.8 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.224885597411624		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.224885597411624 | validation: 0.22829373401901645]
	TIME [epoch: 9.82 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38813676066428465		[learning rate: 0.00099324]
	Learning Rate: 0.000993237
	LOSS [training: 0.38813676066428465 | validation: 0.1675940327213128]
	TIME [epoch: 9.81 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17738809920100723		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.17738809920100723 | validation: 0.17785824616454146]
	TIME [epoch: 9.81 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1670012754078841		[learning rate: 0.00098843]
	Learning Rate: 0.000988433
	LOSS [training: 0.1670012754078841 | validation: 0.1584180382859453]
	TIME [epoch: 9.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15977153432600058		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.15977153432600058 | validation: 0.18988047178431963]
	TIME [epoch: 9.83 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21164755922346928		[learning rate: 0.00098365]
	Learning Rate: 0.000983653
	LOSS [training: 0.21164755922346928 | validation: 0.3138470065572091]
	TIME [epoch: 9.8 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2748501318165211		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.2748501318165211 | validation: 0.2352508604597089]
	TIME [epoch: 9.81 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17728218349530028		[learning rate: 0.0009789]
	Learning Rate: 0.000978897
	LOSS [training: 0.17728218349530028 | validation: 0.22705812021266084]
	TIME [epoch: 9.82 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17952968740744962		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.17952968740744962 | validation: 0.29162665008637173]
	TIME [epoch: 9.81 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24270685077120158		[learning rate: 0.00097416]
	Learning Rate: 0.000974163
	LOSS [training: 0.24270685077120158 | validation: 0.30536357509941026]
	TIME [epoch: 9.81 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26693138732715377		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.26693138732715377 | validation: 0.4293759662780444]
	TIME [epoch: 9.81 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30548660334959754		[learning rate: 0.00096945]
	Learning Rate: 0.000969452
	LOSS [training: 0.30548660334959754 | validation: 0.4845929343729287]
	TIME [epoch: 9.82 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2908497288961511		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.2908497288961511 | validation: 0.33393583079946254]
	TIME [epoch: 9.8 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2919750177465189		[learning rate: 0.00096476]
	Learning Rate: 0.000964764
	LOSS [training: 0.2919750177465189 | validation: 0.17693592868242675]
	TIME [epoch: 9.8 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19850745111495793		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.19850745111495793 | validation: 0.16109519963991725]
	TIME [epoch: 9.83 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16565702820813127		[learning rate: 0.0009601]
	Learning Rate: 0.000960098
	LOSS [training: 0.16565702820813127 | validation: 0.2672906867911724]
	TIME [epoch: 9.81 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21348864031720968		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.21348864031720968 | validation: 0.1681741654081281]
	TIME [epoch: 9.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24752157543593195		[learning rate: 0.00095546]
	Learning Rate: 0.000955456
	LOSS [training: 0.24752157543593195 | validation: 0.453247605133744]
	TIME [epoch: 9.81 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23541776103897166		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.23541776103897166 | validation: 0.16634556992023877]
	TIME [epoch: 9.83 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.125988971301694		[learning rate: 0.00095084]
	Learning Rate: 0.000950835
	LOSS [training: 0.125988971301694 | validation: 0.12631716114502406]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1071.pth
	Model improved!!!
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21706938166171033		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.21706938166171033 | validation: 0.3714742326234466]
	TIME [epoch: 9.8 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44955978622893333		[learning rate: 0.00094624]
	Learning Rate: 0.000946237
	LOSS [training: 0.44955978622893333 | validation: 0.35811619518213783]
	TIME [epoch: 9.81 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29360426644777604		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.29360426644777604 | validation: 0.25293824091198003]
	TIME [epoch: 9.81 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.239439532572871		[learning rate: 0.00094166]
	Learning Rate: 0.000941661
	LOSS [training: 0.239439532572871 | validation: 0.1816827339057373]
	TIME [epoch: 9.8 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26758655212558097		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.26758655212558097 | validation: 0.23645490401273483]
	TIME [epoch: 9.79 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16602490595128058		[learning rate: 0.00093711]
	Learning Rate: 0.000937108
	LOSS [training: 0.16602490595128058 | validation: 0.2056102501534138]
	TIME [epoch: 9.82 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13476517917583017		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.13476517917583017 | validation: 0.16647806815108904]
	TIME [epoch: 9.8 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13541268770993492		[learning rate: 0.00093258]
	Learning Rate: 0.000932576
	LOSS [training: 0.13541268770993492 | validation: 0.1570528095475621]
	TIME [epoch: 9.79 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1800442135339993		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.1800442135339993 | validation: 0.17260577920744935]
	TIME [epoch: 9.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1684171783085046		[learning rate: 0.00092807]
	Learning Rate: 0.000928066
	LOSS [training: 0.1684171783085046 | validation: 0.28662814296759714]
	TIME [epoch: 9.81 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.348617285230309		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.348617285230309 | validation: 0.42959324350950506]
	TIME [epoch: 9.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26635412461110486		[learning rate: 0.00092358]
	Learning Rate: 0.000923578
	LOSS [training: 0.26635412461110486 | validation: 0.1397506989309043]
	TIME [epoch: 9.79 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1706046998236155		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.1706046998236155 | validation: 0.2268732948317437]
	TIME [epoch: 9.81 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30770560226329774		[learning rate: 0.00091911]
	Learning Rate: 0.000919112
	LOSS [training: 0.30770560226329774 | validation: 0.2585928593122858]
	TIME [epoch: 9.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18975103804380672		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.18975103804380672 | validation: 0.22735903223577025]
	TIME [epoch: 9.79 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676707487809686		[learning rate: 0.00091467]
	Learning Rate: 0.000914667
	LOSS [training: 0.1676707487809686 | validation: 0.13366824768719618]
	TIME [epoch: 9.8 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2322862174885048		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.2322862174885048 | validation: 0.17919050913465803]
	TIME [epoch: 9.81 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21962589814279015		[learning rate: 0.00091024]
	Learning Rate: 0.000910244
	LOSS [training: 0.21962589814279015 | validation: 0.23715009038057652]
	TIME [epoch: 9.79 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18687551346553405		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.18687551346553405 | validation: 0.15887625077907155]
	TIME [epoch: 9.79 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1734998047265833		[learning rate: 0.00090584]
	Learning Rate: 0.000905843
	LOSS [training: 0.1734998047265833 | validation: 0.2268515284175834]
	TIME [epoch: 9.81 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3164160957644365		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.3164160957644365 | validation: 0.26956958751452326]
	TIME [epoch: 9.79 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1534505045486264		[learning rate: 0.00090146]
	Learning Rate: 0.000901462
	LOSS [training: 0.1534505045486264 | validation: 0.26362615386145477]
	TIME [epoch: 9.8 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22961008328193738		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.22961008328193738 | validation: 0.32482205965793937]
	TIME [epoch: 9.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.245552779439537		[learning rate: 0.0008971]
	Learning Rate: 0.000897103
	LOSS [training: 0.245552779439537 | validation: 0.24626300885944208]
	TIME [epoch: 9.82 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1390335876777778		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.1390335876777778 | validation: 0.25164665677530706]
	TIME [epoch: 9.79 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19060510967721705		[learning rate: 0.00089276]
	Learning Rate: 0.000892764
	LOSS [training: 0.19060510967721705 | validation: 0.2662539632576508]
	TIME [epoch: 9.8 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16755576464243652		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.16755576464243652 | validation: 0.25033186198738216]
	TIME [epoch: 9.82 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14732279945773694		[learning rate: 0.00088845]
	Learning Rate: 0.000888447
	LOSS [training: 0.14732279945773694 | validation: 0.20479182766276702]
	TIME [epoch: 9.81 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13556775342255378		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.13556775342255378 | validation: 0.21001739317382978]
	TIME [epoch: 9.8 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23004510176675227		[learning rate: 0.00088415]
	Learning Rate: 0.000884151
	LOSS [training: 0.23004510176675227 | validation: 0.2776738731765589]
	TIME [epoch: 9.8 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18532587406413673		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.18532587406413673 | validation: 0.21141825528000752]
	TIME [epoch: 9.82 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18367355440452976		[learning rate: 0.00087988]
	Learning Rate: 0.000879875
	LOSS [training: 0.18367355440452976 | validation: 0.14925916175930157]
	TIME [epoch: 9.8 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15385597628043704		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.15385597628043704 | validation: 0.1519219016855351]
	TIME [epoch: 9.79 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15120068482250829		[learning rate: 0.00087562]
	Learning Rate: 0.00087562
	LOSS [training: 0.15120068482250829 | validation: 0.2078785623734712]
	TIME [epoch: 9.82 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1721337307668111		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.1721337307668111 | validation: 0.2536826731636793]
	TIME [epoch: 9.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23024716488292354		[learning rate: 0.00087139]
	Learning Rate: 0.000871386
	LOSS [training: 0.23024716488292354 | validation: 0.19292980226052836]
	TIME [epoch: 9.79 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.193646814814132		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.193646814814132 | validation: 0.20217351102892714]
	TIME [epoch: 9.79 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1921425929106276		[learning rate: 0.00086717]
	Learning Rate: 0.000867172
	LOSS [training: 0.1921425929106276 | validation: 0.1854359380008917]
	TIME [epoch: 9.82 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17008449760279584		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.17008449760279584 | validation: 0.25172294128849637]
	TIME [epoch: 9.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18483861325702522		[learning rate: 0.00086298]
	Learning Rate: 0.000862979
	LOSS [training: 0.18483861325702522 | validation: 0.2120709813552567]
	TIME [epoch: 9.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16717284910260194		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.16717284910260194 | validation: 0.30977587077767543]
	TIME [epoch: 9.81 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2944845054889127		[learning rate: 0.00085881]
	Learning Rate: 0.000858805
	LOSS [training: 0.2944845054889127 | validation: 0.3141057123346364]
	TIME [epoch: 9.81 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2042060393402924		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.2042060393402924 | validation: 0.3189219350573256]
	TIME [epoch: 9.79 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30724274968246845		[learning rate: 0.00085465]
	Learning Rate: 0.000854652
	LOSS [training: 0.30724274968246845 | validation: 0.2579229846606802]
	TIME [epoch: 9.8 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18843058197998003		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.18843058197998003 | validation: 0.2185111095744283]
	TIME [epoch: 9.81 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24201829260137747		[learning rate: 0.00085052]
	Learning Rate: 0.000850519
	LOSS [training: 0.24201829260137747 | validation: 0.3056292999118038]
	TIME [epoch: 9.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23944579252559053		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.23944579252559053 | validation: 0.11966466944247336]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1118.pth
	Model improved!!!
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1439141117427659		[learning rate: 0.00084641]
	Learning Rate: 0.000846406
	LOSS [training: 0.1439141117427659 | validation: 0.1491320268711091]
	TIME [epoch: 9.81 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19430078651204757		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.19430078651204757 | validation: 0.11046024671015751]
	TIME [epoch: 9.82 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1120.pth
	Model improved!!!
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1604122456133096		[learning rate: 0.00084231]
	Learning Rate: 0.000842313
	LOSS [training: 0.1604122456133096 | validation: 0.22519814778276206]
	TIME [epoch: 9.8 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16853290132515286		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.16853290132515286 | validation: 0.22260316444411912]
	TIME [epoch: 9.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15307497135949263		[learning rate: 0.00083824]
	Learning Rate: 0.00083824
	LOSS [training: 0.15307497135949263 | validation: 0.2199669044705412]
	TIME [epoch: 9.81 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1833999387907111		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.1833999387907111 | validation: 0.19726952656336352]
	TIME [epoch: 9.81 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19837173052240525		[learning rate: 0.00083419]
	Learning Rate: 0.000834187
	LOSS [training: 0.19837173052240525 | validation: 0.27674420650122933]
	TIME [epoch: 9.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1851457323402836		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.1851457323402836 | validation: 0.19708076898591118]
	TIME [epoch: 9.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19580078121433336		[learning rate: 0.00083015]
	Learning Rate: 0.000830152
	LOSS [training: 0.19580078121433336 | validation: 0.18450990135163484]
	TIME [epoch: 9.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18104665800525224		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.18104665800525224 | validation: 0.18609436227028334]
	TIME [epoch: 9.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.174569597374104		[learning rate: 0.00082614]
	Learning Rate: 0.000826138
	LOSS [training: 0.174569597374104 | validation: 0.31594338291047835]
	TIME [epoch: 9.79 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18527708800265336		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.18527708800265336 | validation: 0.17096475868069216]
	TIME [epoch: 9.81 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1388935951874558		[learning rate: 0.00082214]
	Learning Rate: 0.000822143
	LOSS [training: 0.1388935951874558 | validation: 0.24754438471723952]
	TIME [epoch: 9.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1879360706725957		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.1879360706725957 | validation: 0.14332033898023036]
	TIME [epoch: 9.8 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13789905460539237		[learning rate: 0.00081817]
	Learning Rate: 0.000818167
	LOSS [training: 0.13789905460539237 | validation: 0.18984485155979236]
	TIME [epoch: 9.79 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22233713124672855		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.22233713124672855 | validation: 0.4985495487014016]
	TIME [epoch: 9.81 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4949273224820724		[learning rate: 0.00081421]
	Learning Rate: 0.000814211
	LOSS [training: 0.4949273224820724 | validation: 0.20290943380067666]
	TIME [epoch: 9.8 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2057722517676032		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.2057722517676032 | validation: 0.2858970057477058]
	TIME [epoch: 9.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18631788188109275		[learning rate: 0.00081027]
	Learning Rate: 0.000810273
	LOSS [training: 0.18631788188109275 | validation: 0.1459512797490684]
	TIME [epoch: 9.82 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1387343228080893		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.1387343228080893 | validation: 0.1834990885350027]
	TIME [epoch: 9.81 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18533880574742537		[learning rate: 0.00080636]
	Learning Rate: 0.000806355
	LOSS [training: 0.18533880574742537 | validation: 0.2693958848966144]
	TIME [epoch: 9.79 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1745784170346587		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.1745784170346587 | validation: 0.26785762048755624]
	TIME [epoch: 9.79 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19928293566243857		[learning rate: 0.00080246]
	Learning Rate: 0.000802456
	LOSS [training: 0.19928293566243857 | validation: 0.15512898105708858]
	TIME [epoch: 9.82 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1705728167301719		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.1705728167301719 | validation: 0.2589542808197973]
	TIME [epoch: 9.81 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1819008618916986		[learning rate: 0.00079858]
	Learning Rate: 0.000798575
	LOSS [training: 0.1819008618916986 | validation: 0.3261915011963205]
	TIME [epoch: 9.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20147964470128082		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.20147964470128082 | validation: 0.17542330024487918]
	TIME [epoch: 9.82 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16913014238401014		[learning rate: 0.00079471]
	Learning Rate: 0.000794713
	LOSS [training: 0.16913014238401014 | validation: 0.20217689663346097]
	TIME [epoch: 9.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20588266031282115		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.20588266031282115 | validation: 0.19956703624954186]
	TIME [epoch: 9.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16204991318321443		[learning rate: 0.00079087]
	Learning Rate: 0.00079087
	LOSS [training: 0.16204991318321443 | validation: 0.1880122071228649]
	TIME [epoch: 9.79 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20905758673708416		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.20905758673708416 | validation: 0.2791811218496053]
	TIME [epoch: 9.82 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22864931832158897		[learning rate: 0.00078705]
	Learning Rate: 0.000787046
	LOSS [training: 0.22864931832158897 | validation: 0.1724613917478834]
	TIME [epoch: 9.79 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14882117228572442		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.14882117228572442 | validation: 0.18086624116852476]
	TIME [epoch: 9.8 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13625184620433142		[learning rate: 0.00078324]
	Learning Rate: 0.00078324
	LOSS [training: 0.13625184620433142 | validation: 0.19394778054172054]
	TIME [epoch: 9.81 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12954605937695102		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.12954605937695102 | validation: 0.21835491437710056]
	TIME [epoch: 9.79 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1360262349058901		[learning rate: 0.00077945]
	Learning Rate: 0.000779452
	LOSS [training: 0.1360262349058901 | validation: 0.15062545328309163]
	TIME [epoch: 9.79 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14271550851469006		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.14271550851469006 | validation: 0.19294487493258863]
	TIME [epoch: 9.78 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13831168713630146		[learning rate: 0.00077568]
	Learning Rate: 0.000775683
	LOSS [training: 0.13831168713630146 | validation: 0.14928954124086613]
	TIME [epoch: 9.82 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1403702193308049		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.1403702193308049 | validation: 0.18054566012529658]
	TIME [epoch: 9.79 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15109884375688235		[learning rate: 0.00077193]
	Learning Rate: 0.000771932
	LOSS [training: 0.15109884375688235 | validation: 0.27671538206862883]
	TIME [epoch: 9.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18031711199965866		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.18031711199965866 | validation: 0.19884773334351813]
	TIME [epoch: 9.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14475447257422663		[learning rate: 0.0007682]
	Learning Rate: 0.000768199
	LOSS [training: 0.14475447257422663 | validation: 0.20164543481410388]
	TIME [epoch: 9.8 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1296276895796402		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.1296276895796402 | validation: 0.1788852352205137]
	TIME [epoch: 9.78 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1457611006506215		[learning rate: 0.00076448]
	Learning Rate: 0.000764484
	LOSS [training: 0.1457611006506215 | validation: 0.19311955994234795]
	TIME [epoch: 9.79 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14700229644006133		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.14700229644006133 | validation: 0.19218132681522634]
	TIME [epoch: 9.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15451523584527244		[learning rate: 0.00076079]
	Learning Rate: 0.000760787
	LOSS [training: 0.15451523584527244 | validation: 0.30090693242105615]
	TIME [epoch: 9.79 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24617044845229405		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.24617044845229405 | validation: 0.4268021924851931]
	TIME [epoch: 9.79 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26681999456369054		[learning rate: 0.00075711]
	Learning Rate: 0.000757108
	LOSS [training: 0.26681999456369054 | validation: 0.37168506359621295]
	TIME [epoch: 9.79 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.230654756204476		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.230654756204476 | validation: 0.20285681636306513]
	TIME [epoch: 9.81 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14297774864051574		[learning rate: 0.00075345]
	Learning Rate: 0.000753447
	LOSS [training: 0.14297774864051574 | validation: 0.21631631628544093]
	TIME [epoch: 9.79 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19287258701446958		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.19287258701446958 | validation: 0.2827133941592345]
	TIME [epoch: 9.79 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18281862428260548		[learning rate: 0.0007498]
	Learning Rate: 0.000749803
	LOSS [training: 0.18281862428260548 | validation: 0.20258869862447756]
	TIME [epoch: 9.81 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1650391928124669		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.1650391928124669 | validation: 0.21911061018125824]
	TIME [epoch: 9.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16771777577458796		[learning rate: 0.00074618]
	Learning Rate: 0.000746177
	LOSS [training: 0.16771777577458796 | validation: 0.21729706200644572]
	TIME [epoch: 9.8 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14854128704685002		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.14854128704685002 | validation: 0.15113088483304496]
	TIME [epoch: 9.79 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15879393627185415		[learning rate: 0.00074257]
	Learning Rate: 0.000742569
	LOSS [training: 0.15879393627185415 | validation: 0.28815385149938233]
	TIME [epoch: 9.82 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2877512145007098		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.2877512145007098 | validation: 0.13424132432643926]
	TIME [epoch: 9.8 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14038256713601688		[learning rate: 0.00073898]
	Learning Rate: 0.000738978
	LOSS [training: 0.14038256713601688 | validation: 0.13955194077527178]
	TIME [epoch: 9.79 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1488653549564168		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.1488653549564168 | validation: 0.2137229029142641]
	TIME [epoch: 9.8 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15086782429433626		[learning rate: 0.0007354]
	Learning Rate: 0.000735405
	LOSS [training: 0.15086782429433626 | validation: 0.239706140762093]
	TIME [epoch: 9.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15575505219183156		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.15575505219183156 | validation: 0.2624727833942282]
	TIME [epoch: 9.79 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17929173688941052		[learning rate: 0.00073185]
	Learning Rate: 0.000731848
	LOSS [training: 0.17929173688941052 | validation: 0.3144776076385822]
	TIME [epoch: 9.79 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17631540525923955		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.17631540525923955 | validation: 0.14701648625529945]
	TIME [epoch: 9.81 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15791860975124822		[learning rate: 0.00072831]
	Learning Rate: 0.000728309
	LOSS [training: 0.15791860975124822 | validation: 0.14474069959823072]
	TIME [epoch: 9.79 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13455188890296327		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.13455188890296327 | validation: 0.15461030887017363]
	TIME [epoch: 9.79 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1596117149392306		[learning rate: 0.00072479]
	Learning Rate: 0.000724787
	LOSS [training: 0.1596117149392306 | validation: 0.24393194599424842]
	TIME [epoch: 9.81 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1753308055826694		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.1753308055826694 | validation: 0.18474351318083668]
	TIME [epoch: 9.79 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14485230417174905		[learning rate: 0.00072128]
	Learning Rate: 0.000721282
	LOSS [training: 0.14485230417174905 | validation: 0.1678557478829093]
	TIME [epoch: 9.79 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2149113566098153		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.2149113566098153 | validation: 0.18849954956360843]
	TIME [epoch: 9.79 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15717962394449153		[learning rate: 0.00071779]
	Learning Rate: 0.000717794
	LOSS [training: 0.15717962394449153 | validation: 0.31592605045362004]
	TIME [epoch: 9.8 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2148762011040742		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.2148762011040742 | validation: 0.1814058424968887]
	TIME [epoch: 9.79 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537183455816305		[learning rate: 0.00071432]
	Learning Rate: 0.000714323
	LOSS [training: 0.1537183455816305 | validation: 0.11758201137802093]
	TIME [epoch: 9.79 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1449680489166513		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.1449680489166513 | validation: 0.1422250662305326]
	TIME [epoch: 9.81 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14628170510653535		[learning rate: 0.00071087]
	Learning Rate: 0.000710869
	LOSS [training: 0.14628170510653535 | validation: 0.14922902784830883]
	TIME [epoch: 9.8 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13773113985905844		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.13773113985905844 | validation: 0.12196012361427588]
	TIME [epoch: 9.8 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14129278822597505		[learning rate: 0.00070743]
	Learning Rate: 0.000707431
	LOSS [training: 0.14129278822597505 | validation: 0.22068059097725162]
	TIME [epoch: 9.78 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12917576219319304		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.12917576219319304 | validation: 0.20678919032998624]
	TIME [epoch: 9.8 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20963008805038977		[learning rate: 0.00070401]
	Learning Rate: 0.00070401
	LOSS [training: 0.20963008805038977 | validation: 0.19288031995952692]
	TIME [epoch: 9.8 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15824475785920683		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.15824475785920683 | validation: 0.16339656296214522]
	TIME [epoch: 9.8 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11236718826579553		[learning rate: 0.00070061]
	Learning Rate: 0.000700606
	LOSS [training: 0.11236718826579553 | validation: 0.17379846319787637]
	TIME [epoch: 9.79 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1759971406057		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.1759971406057 | validation: 0.20174413571838018]
	TIME [epoch: 9.8 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20989334961133607		[learning rate: 0.00069722]
	Learning Rate: 0.000697218
	LOSS [training: 0.20989334961133607 | validation: 0.210560549483382]
	TIME [epoch: 9.79 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1323843228145111		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.1323843228145111 | validation: 0.14127452295347662]
	TIME [epoch: 9.79 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18229533184754912		[learning rate: 0.00069385]
	Learning Rate: 0.000693846
	LOSS [training: 0.18229533184754912 | validation: 0.23881630205634508]
	TIME [epoch: 9.81 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20253944843434218		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.20253944843434218 | validation: 0.22408282340351357]
	TIME [epoch: 9.79 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1909045494739581		[learning rate: 0.00069049]
	Learning Rate: 0.000690491
	LOSS [training: 0.1909045494739581 | validation: 0.29032611051165075]
	TIME [epoch: 9.8 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18540646260579335		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.18540646260579335 | validation: 0.22153636487466444]
	TIME [epoch: 9.79 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17311315477765166		[learning rate: 0.00068715]
	Learning Rate: 0.000687152
	LOSS [training: 0.17311315477765166 | validation: 0.18681789925872902]
	TIME [epoch: 9.8 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14824859797025983		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.14824859797025983 | validation: 0.12943717256636708]
	TIME [epoch: 9.79 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11246003791880854		[learning rate: 0.00068383]
	Learning Rate: 0.000683829
	LOSS [training: 0.11246003791880854 | validation: 0.19241464369573147]
	TIME [epoch: 9.79 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17913677635031064		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.17913677635031064 | validation: 0.10941917541148989]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1208.pth
	Model improved!!!
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10950345664451563		[learning rate: 0.00068052]
	Learning Rate: 0.000680522
	LOSS [training: 0.10950345664451563 | validation: 0.13511453823211425]
	TIME [epoch: 9.79 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15420387447228304		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.15420387447228304 | validation: 0.18425442819808788]
	TIME [epoch: 9.79 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24984346949456754		[learning rate: 0.00067723]
	Learning Rate: 0.000677231
	LOSS [training: 0.24984346949456754 | validation: 0.4129755507960424]
	TIME [epoch: 9.79 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3041379354206064		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.3041379354206064 | validation: 0.35852361946267935]
	TIME [epoch: 9.8 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20955763257575458		[learning rate: 0.00067396]
	Learning Rate: 0.000673956
	LOSS [training: 0.20955763257575458 | validation: 0.21794441068430637]
	TIME [epoch: 9.79 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14733987220095765		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.14733987220095765 | validation: 0.20159270790427986]
	TIME [epoch: 9.78 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.210157582038829		[learning rate: 0.0006707]
	Learning Rate: 0.000670697
	LOSS [training: 0.210157582038829 | validation: 0.18909602740224318]
	TIME [epoch: 9.81 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15519291536527044		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.15519291536527044 | validation: 0.2661434562981399]
	TIME [epoch: 9.79 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18040386784426424		[learning rate: 0.00066745]
	Learning Rate: 0.000667454
	LOSS [training: 0.18040386784426424 | validation: 0.16487418110151056]
	TIME [epoch: 9.79 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14095522576956002		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.14095522576956002 | validation: 0.1809110998444728]
	TIME [epoch: 9.77 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.114705244983026		[learning rate: 0.00066423]
	Learning Rate: 0.000664226
	LOSS [training: 0.114705244983026 | validation: 0.1521021901428594]
	TIME [epoch: 9.8 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14207443039325168		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.14207443039325168 | validation: 0.17132788388877912]
	TIME [epoch: 9.78 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12729058067848295		[learning rate: 0.00066101]
	Learning Rate: 0.000661014
	LOSS [training: 0.12729058067848295 | validation: 0.18936608354249493]
	TIME [epoch: 9.79 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15906376865020178		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.15906376865020178 | validation: 0.2628355861713856]
	TIME [epoch: 9.8 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2126024721710907		[learning rate: 0.00065782]
	Learning Rate: 0.000657817
	LOSS [training: 0.2126024721710907 | validation: 0.38777167712743577]
	TIME [epoch: 9.78 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20754380602676545		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.20754380602676545 | validation: 0.23984762512546412]
	TIME [epoch: 9.77 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17202858076076236		[learning rate: 0.00065464]
	Learning Rate: 0.000654636
	LOSS [training: 0.17202858076076236 | validation: 0.15461167947953247]
	TIME [epoch: 9.77 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1374089311161954		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.1374089311161954 | validation: 0.1921741722295554]
	TIME [epoch: 9.79 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1435570807173691		[learning rate: 0.00065147]
	Learning Rate: 0.000651471
	LOSS [training: 0.1435570807173691 | validation: 0.20870578479711077]
	TIME [epoch: 9.79 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18138788048123217		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.18138788048123217 | validation: 0.32238815057459996]
	TIME [epoch: 9.78 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.205962357417054		[learning rate: 0.00064832]
	Learning Rate: 0.00064832
	LOSS [training: 0.205962357417054 | validation: 0.21680483197804104]
	TIME [epoch: 9.8 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12046448253808069		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.12046448253808069 | validation: 0.17962385821621332]
	TIME [epoch: 9.78 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1642962067891152		[learning rate: 0.00064519]
	Learning Rate: 0.000645185
	LOSS [training: 0.1642962067891152 | validation: 0.23713301982232068]
	TIME [epoch: 9.78 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41472371794635415		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.41472371794635415 | validation: 0.22890335742484758]
	TIME [epoch: 9.78 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2249832801024903		[learning rate: 0.00064206]
	Learning Rate: 0.000642065
	LOSS [training: 0.2249832801024903 | validation: 0.18271168121969666]
	TIME [epoch: 9.8 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16720350932636194		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.16720350932636194 | validation: 0.18520258228332678]
	TIME [epoch: 9.79 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16836372297605412		[learning rate: 0.00063896]
	Learning Rate: 0.00063896
	LOSS [training: 0.16836372297605412 | validation: 0.30397172225589136]
	TIME [epoch: 9.78 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14474419108933595		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.14474419108933595 | validation: 0.19453078571911256]
	TIME [epoch: 9.8 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1083453500616836		[learning rate: 0.00063587]
	Learning Rate: 0.00063587
	LOSS [training: 0.1083453500616836 | validation: 0.19832204417557475]
	TIME [epoch: 9.79 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15948545417176363		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.15948545417176363 | validation: 0.24954211930363407]
	TIME [epoch: 9.79 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1400982717426437		[learning rate: 0.0006328]
	Learning Rate: 0.000632795
	LOSS [training: 0.1400982717426437 | validation: 0.20026363763805896]
	TIME [epoch: 9.78 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14138205825523745		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.14138205825523745 | validation: 0.1883477814240253]
	TIME [epoch: 9.79 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16407025652521473		[learning rate: 0.00062974]
	Learning Rate: 0.000629735
	LOSS [training: 0.16407025652521473 | validation: 0.2522963406952491]
	TIME [epoch: 9.78 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1350639915527533		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.1350639915527533 | validation: 0.21324675263342927]
	TIME [epoch: 9.78 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11249354079035996		[learning rate: 0.00062669]
	Learning Rate: 0.00062669
	LOSS [training: 0.11249354079035996 | validation: 0.1955691329755773]
	TIME [epoch: 9.79 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1259892121655575		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.1259892121655575 | validation: 0.1862126129287379]
	TIME [epoch: 9.81 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13541456061662022		[learning rate: 0.00062366]
	Learning Rate: 0.000623659
	LOSS [training: 0.13541456061662022 | validation: 0.20967372111869256]
	TIME [epoch: 9.78 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.145229925101842		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.145229925101842 | validation: 0.2359515962767816]
	TIME [epoch: 9.79 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1321609306281258		[learning rate: 0.00062064]
	Learning Rate: 0.000620643
	LOSS [training: 0.1321609306281258 | validation: 0.14466496504021487]
	TIME [epoch: 9.8 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13437424186968966		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.13437424186968966 | validation: 0.4185397248603117]
	TIME [epoch: 9.77 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2552871752588442		[learning rate: 0.00061764]
	Learning Rate: 0.000617642
	LOSS [training: 0.2552871752588442 | validation: 0.17503998591602013]
	TIME [epoch: 9.79 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12195264142177478		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.12195264142177478 | validation: 0.1585025811262784]
	TIME [epoch: 9.79 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15386885285459395		[learning rate: 0.00061466]
	Learning Rate: 0.000614655
	LOSS [training: 0.15386885285459395 | validation: 0.16433054404036468]
	TIME [epoch: 9.8 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17435211039544346		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.17435211039544346 | validation: 0.14977826717959758]
	TIME [epoch: 9.79 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16045181910060552		[learning rate: 0.00061168]
	Learning Rate: 0.000611683
	LOSS [training: 0.16045181910060552 | validation: 0.16864420568148614]
	TIME [epoch: 9.79 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1191814445099166		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.1191814445099166 | validation: 0.18111083190550037]
	TIME [epoch: 9.81 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11192509956178123		[learning rate: 0.00060872]
	Learning Rate: 0.000608725
	LOSS [training: 0.11192509956178123 | validation: 0.2162827169193131]
	TIME [epoch: 9.79 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17720675597051969		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.17720675597051969 | validation: 0.13542555918574542]
	TIME [epoch: 9.79 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17139577243465604		[learning rate: 0.00060578]
	Learning Rate: 0.000605781
	LOSS [training: 0.17139577243465604 | validation: 0.16052716363277142]
	TIME [epoch: 9.79 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12267599846965942		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.12267599846965942 | validation: 0.1923911443400878]
	TIME [epoch: 9.8 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17917283574698936		[learning rate: 0.00060285]
	Learning Rate: 0.000602852
	LOSS [training: 0.17917283574698936 | validation: 0.17901302371526817]
	TIME [epoch: 9.78 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14785736465362898		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.14785736465362898 | validation: 0.2655471625990573]
	TIME [epoch: 9.79 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16198332984053526		[learning rate: 0.00059994]
	Learning Rate: 0.000599936
	LOSS [training: 0.16198332984053526 | validation: 0.1540560643386178]
	TIME [epoch: 9.79 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14324669444934773		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.14324669444934773 | validation: 0.32381455258399544]
	TIME [epoch: 9.79 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22908974259366005		[learning rate: 0.00059704]
	Learning Rate: 0.000597035
	LOSS [training: 0.22908974259366005 | validation: 0.16465635692049652]
	TIME [epoch: 9.79 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11268952414736981		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.11268952414736981 | validation: 0.11044936909310694]
	TIME [epoch: 9.79 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11001811520539857		[learning rate: 0.00059415]
	Learning Rate: 0.000594148
	LOSS [training: 0.11001811520539857 | validation: 0.11557071083486978]
	TIME [epoch: 9.78 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10768465157619378		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.10768465157619378 | validation: 0.13619124392695237]
	TIME [epoch: 9.79 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10488763005365329		[learning rate: 0.00059128]
	Learning Rate: 0.000591275
	LOSS [training: 0.10488763005365329 | validation: 0.15114584115335297]
	TIME [epoch: 9.79 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1388932922721628		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.1388932922721628 | validation: 0.1681331768775366]
	TIME [epoch: 9.79 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516200858805292		[learning rate: 0.00058842]
	Learning Rate: 0.000588416
	LOSS [training: 0.1516200858805292 | validation: 0.21432099863372536]
	TIME [epoch: 9.78 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13692656021166993		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.13692656021166993 | validation: 0.16591002017650178]
	TIME [epoch: 9.79 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16745107814497096		[learning rate: 0.00058557]
	Learning Rate: 0.00058557
	LOSS [training: 0.16745107814497096 | validation: 0.1534947723125272]
	TIME [epoch: 9.78 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15133679753828227		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.15133679753828227 | validation: 0.1886537060458443]
	TIME [epoch: 9.81 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13195334506774206		[learning rate: 0.00058274]
	Learning Rate: 0.000582738
	LOSS [training: 0.13195334506774206 | validation: 0.2679467549633021]
	TIME [epoch: 9.8 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18036648394800428		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.18036648394800428 | validation: 0.15874169538470376]
	TIME [epoch: 9.78 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19008194937357636		[learning rate: 0.00057992]
	Learning Rate: 0.00057992
	LOSS [training: 0.19008194937357636 | validation: 0.1747143000335436]
	TIME [epoch: 9.79 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13042231580236405		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.13042231580236405 | validation: 0.1400369987259166]
	TIME [epoch: 9.81 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12158611932892109		[learning rate: 0.00057712]
	Learning Rate: 0.000577116
	LOSS [training: 0.12158611932892109 | validation: 0.1807483790107129]
	TIME [epoch: 9.78 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19367838548168814		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.19367838548168814 | validation: 0.23437288317334656]
	TIME [epoch: 9.78 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15337396461789737		[learning rate: 0.00057433]
	Learning Rate: 0.000574325
	LOSS [training: 0.15337396461789737 | validation: 0.1686788556468308]
	TIME [epoch: 9.8 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1111183859160626		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.1111183859160626 | validation: 0.17702370312129795]
	TIME [epoch: 9.77 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13058853643769122		[learning rate: 0.00057155]
	Learning Rate: 0.000571548
	LOSS [training: 0.13058853643769122 | validation: 0.1789771974177564]
	TIME [epoch: 9.79 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.203893890360743		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.203893890360743 | validation: 0.1502233080591491]
	TIME [epoch: 9.79 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13661249768888512		[learning rate: 0.00056878]
	Learning Rate: 0.000568784
	LOSS [training: 0.13661249768888512 | validation: 0.16785641745737423]
	TIME [epoch: 9.81 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11724707105597824		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.11724707105597824 | validation: 0.17867277647373805]
	TIME [epoch: 9.79 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1721796167898944		[learning rate: 0.00056603]
	Learning Rate: 0.000566033
	LOSS [training: 0.1721796167898944 | validation: 0.17532369325238623]
	TIME [epoch: 9.78 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14411650440152415		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.14411650440152415 | validation: 0.301574650832371]
	TIME [epoch: 9.8 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17978460580293476		[learning rate: 0.0005633]
	Learning Rate: 0.000563296
	LOSS [training: 0.17978460580293476 | validation: 0.14544070581092977]
	TIME [epoch: 9.79 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11611523625071943		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.11611523625071943 | validation: 0.15002644081977]
	TIME [epoch: 9.79 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13845798036302517		[learning rate: 0.00056057]
	Learning Rate: 0.000560572
	LOSS [training: 0.13845798036302517 | validation: 0.11878815425207905]
	TIME [epoch: 9.79 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1317578930535152		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.1317578930535152 | validation: 0.2648015389178218]
	TIME [epoch: 9.81 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1940931050596189		[learning rate: 0.00055786]
	Learning Rate: 0.000557861
	LOSS [training: 0.1940931050596189 | validation: 0.1768258836923104]
	TIME [epoch: 9.8 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11030086846994673		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.11030086846994673 | validation: 0.17246213598438628]
	TIME [epoch: 9.79 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1214734969266201		[learning rate: 0.00055516]
	Learning Rate: 0.000555164
	LOSS [training: 0.1214734969266201 | validation: 0.11637570664143089]
	TIME [epoch: 9.8 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10643186128979254		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.10643186128979254 | validation: 0.1529184276478204]
	TIME [epoch: 9.8 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14909618068844116		[learning rate: 0.00055248]
	Learning Rate: 0.000552479
	LOSS [training: 0.14909618068844116 | validation: 0.14362823932060287]
	TIME [epoch: 9.8 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2387441363704963		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.2387441363704963 | validation: 0.18515795403165947]
	TIME [epoch: 9.8 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19086052614729948		[learning rate: 0.00054981]
	Learning Rate: 0.000549807
	LOSS [training: 0.19086052614729948 | validation: 0.22024315359801067]
	TIME [epoch: 9.81 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15536326491198876		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.15536326491198876 | validation: 0.17086957399618805]
	TIME [epoch: 9.79 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18457590526719678		[learning rate: 0.00054715]
	Learning Rate: 0.000547149
	LOSS [training: 0.18457590526719678 | validation: 0.1847380172784913]
	TIME [epoch: 9.79 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17596110968991355		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.17596110968991355 | validation: 0.13969279074161198]
	TIME [epoch: 9.8 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1753208470026917		[learning rate: 0.0005445]
	Learning Rate: 0.000544503
	LOSS [training: 0.1753208470026917 | validation: 0.19092053185732077]
	TIME [epoch: 9.8 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1848398850354811		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.1848398850354811 | validation: 0.12707880048726528]
	TIME [epoch: 9.79 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14670844409395742		[learning rate: 0.00054187]
	Learning Rate: 0.000541869
	LOSS [training: 0.14670844409395742 | validation: 0.1951215386645889]
	TIME [epoch: 9.79 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1661078185116483		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.1661078185116483 | validation: 0.1542041058056166]
	TIME [epoch: 9.82 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18831138570026784		[learning rate: 0.00053925]
	Learning Rate: 0.000539249
	LOSS [training: 0.18831138570026784 | validation: 0.12037513205598042]
	TIME [epoch: 9.8 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13871514409497399		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.13871514409497399 | validation: 0.10599990295052529]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1306.pth
	Model improved!!!
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1438504841165155		[learning rate: 0.00053664]
	Learning Rate: 0.000536641
	LOSS [training: 0.1438504841165155 | validation: 0.1381721500705542]
	TIME [epoch: 9.82 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15347570673504135		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.15347570673504135 | validation: 0.15454877541550102]
	TIME [epoch: 9.79 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14756922471930842		[learning rate: 0.00053405]
	Learning Rate: 0.000534046
	LOSS [training: 0.14756922471930842 | validation: 0.19394151689924635]
	TIME [epoch: 9.78 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19422135356641285		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.19422135356641285 | validation: 0.1685905655499384]
	TIME [epoch: 9.78 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13858030972115046		[learning rate: 0.00053146]
	Learning Rate: 0.000531464
	LOSS [training: 0.13858030972115046 | validation: 0.12233160161743023]
	TIME [epoch: 9.8 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1724066311363102		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.1724066311363102 | validation: 0.14814226220832458]
	TIME [epoch: 9.79 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1797581393143499		[learning rate: 0.00052889]
	Learning Rate: 0.000528894
	LOSS [training: 0.1797581393143499 | validation: 0.24723891830261224]
	TIME [epoch: 9.78 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21701111317749144		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.21701111317749144 | validation: 0.1959794526124766]
	TIME [epoch: 9.79 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12739075239265518		[learning rate: 0.00052634]
	Learning Rate: 0.000526336
	LOSS [training: 0.12739075239265518 | validation: 0.13342676606257522]
	TIME [epoch: 9.79 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14276670139914657		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.14276670139914657 | validation: 0.20166481153762233]
	TIME [epoch: 9.78 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1752337894074381		[learning rate: 0.00052379]
	Learning Rate: 0.000523791
	LOSS [training: 0.1752337894074381 | validation: 0.21992508024448362]
	TIME [epoch: 9.78 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1593086631518965		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.1593086631518965 | validation: 0.19456761715166768]
	TIME [epoch: 9.81 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12441773652684548		[learning rate: 0.00052126]
	Learning Rate: 0.000521258
	LOSS [training: 0.12441773652684548 | validation: 0.16068622619343872]
	TIME [epoch: 9.78 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10424744293109756		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.10424744293109756 | validation: 0.13088637003221748]
	TIME [epoch: 9.79 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1502818844573141		[learning rate: 0.00051874]
	Learning Rate: 0.000518737
	LOSS [training: 0.1502818844573141 | validation: 0.243383383203621]
	TIME [epoch: 9.8 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17078319954700244		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.17078319954700244 | validation: 0.16005099595596614]
	TIME [epoch: 9.79 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13533538720896024		[learning rate: 0.00051623]
	Learning Rate: 0.000516229
	LOSS [training: 0.13533538720896024 | validation: 0.16837943894082927]
	TIME [epoch: 9.78 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512530079417369		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.1512530079417369 | validation: 0.16717440063804476]
	TIME [epoch: 9.78 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13074471316420064		[learning rate: 0.00051373]
	Learning Rate: 0.000513732
	LOSS [training: 0.13074471316420064 | validation: 0.1567869223226967]
	TIME [epoch: 9.8 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19828806432304225		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.19828806432304225 | validation: 0.23118422678270867]
	TIME [epoch: 9.78 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1656265017355079		[learning rate: 0.00051125]
	Learning Rate: 0.000511248
	LOSS [training: 0.1656265017355079 | validation: 0.132366037319267]
	TIME [epoch: 9.78 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12216637246669566		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.12216637246669566 | validation: 0.1610311963821458]
	TIME [epoch: 9.8 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10921727684800815		[learning rate: 0.00050878]
	Learning Rate: 0.000508776
	LOSS [training: 0.10921727684800815 | validation: 0.14201440026076792]
	TIME [epoch: 9.78 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1205470546645658		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.1205470546645658 | validation: 0.1620773108165799]
	TIME [epoch: 9.79 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13739096488088426		[learning rate: 0.00050632]
	Learning Rate: 0.000506315
	LOSS [training: 0.13739096488088426 | validation: 0.21547000298606742]
	TIME [epoch: 9.79 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14505544666889086		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.14505544666889086 | validation: 0.14630387664940578]
	TIME [epoch: 9.79 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1562040568588107		[learning rate: 0.00050387]
	Learning Rate: 0.000503867
	LOSS [training: 0.1562040568588107 | validation: 0.19875619125747157]
	TIME [epoch: 9.78 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15695223172206388		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.15695223172206388 | validation: 0.21001733104796827]
	TIME [epoch: 9.78 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15636406933876562		[learning rate: 0.00050143]
	Learning Rate: 0.00050143
	LOSS [training: 0.15636406933876562 | validation: 0.16522038141089168]
	TIME [epoch: 9.79 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14428825697970643		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.14428825697970643 | validation: 0.18194963987735296]
	TIME [epoch: 9.78 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12924274385027873		[learning rate: 0.00049901]
	Learning Rate: 0.000499005
	LOSS [training: 0.12924274385027873 | validation: 0.14308195954402309]
	TIME [epoch: 9.78 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11571335404939227		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.11571335404939227 | validation: 0.13939252972919738]
	TIME [epoch: 9.8 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17444423206927495		[learning rate: 0.00049659]
	Learning Rate: 0.000496592
	LOSS [training: 0.17444423206927495 | validation: 0.1772380105988755]
	TIME [epoch: 9.78 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14619896461053583		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.14619896461053583 | validation: 0.2371257978638088]
	TIME [epoch: 9.78 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15216010222194518		[learning rate: 0.00049419]
	Learning Rate: 0.000494191
	LOSS [training: 0.15216010222194518 | validation: 0.13799223477626618]
	TIME [epoch: 9.77 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12893937306121342		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.12893937306121342 | validation: 0.14128228277686808]
	TIME [epoch: 9.8 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11335094108009533		[learning rate: 0.0004918]
	Learning Rate: 0.000491801
	LOSS [training: 0.11335094108009533 | validation: 0.13118825797967051]
	TIME [epoch: 9.78 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10022198416274604		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.10022198416274604 | validation: 0.1141209751627297]
	TIME [epoch: 9.79 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15982342828061305		[learning rate: 0.00048942]
	Learning Rate: 0.000489423
	LOSS [training: 0.15982342828061305 | validation: 0.1653891148417442]
	TIME [epoch: 9.8 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14099306041130233		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.14099306041130233 | validation: 0.12882741268654047]
	TIME [epoch: 9.79 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1756892398265658		[learning rate: 0.00048706]
	Learning Rate: 0.000487056
	LOSS [training: 0.1756892398265658 | validation: 0.1255179741873511]
	TIME [epoch: 9.78 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1412621038239136		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.1412621038239136 | validation: 0.1939339964685898]
	TIME [epoch: 9.79 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18972676634186336		[learning rate: 0.0004847]
	Learning Rate: 0.000484701
	LOSS [training: 0.18972676634186336 | validation: 0.16950240892604135]
	TIME [epoch: 9.78 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15718568988509898		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.15718568988509898 | validation: 0.17447497287068323]
	TIME [epoch: 9.78 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13328727326358888		[learning rate: 0.00048236]
	Learning Rate: 0.000482357
	LOSS [training: 0.13328727326358888 | validation: 0.17884294888908378]
	TIME [epoch: 9.78 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1554448131190769		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.1554448131190769 | validation: 0.2637338088832037]
	TIME [epoch: 9.81 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24529128913651585		[learning rate: 0.00048002]
	Learning Rate: 0.000480024
	LOSS [training: 0.24529128913651585 | validation: 0.1834223875143209]
	TIME [epoch: 9.78 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18564877870226057		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.18564877870226057 | validation: 0.16114311807936252]
	TIME [epoch: 9.78 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13700846130107014		[learning rate: 0.0004777]
	Learning Rate: 0.000477703
	LOSS [training: 0.13700846130107014 | validation: 0.15732264964521667]
	TIME [epoch: 9.79 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13232056413174165		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.13232056413174165 | validation: 0.14663376127664385]
	TIME [epoch: 9.79 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13995458191709215		[learning rate: 0.00047539]
	Learning Rate: 0.000475393
	LOSS [training: 0.13995458191709215 | validation: 0.23621091619278808]
	TIME [epoch: 9.78 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20938463071147434		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.20938463071147434 | validation: 0.34636853166881665]
	TIME [epoch: 9.8 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2612787945201748		[learning rate: 0.00047309]
	Learning Rate: 0.000473094
	LOSS [training: 0.2612787945201748 | validation: 0.18632570131385046]
	TIME [epoch: 9.79 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1587233785110563		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.1587233785110563 | validation: 0.21848912714914534]
	TIME [epoch: 9.78 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15778190006124357		[learning rate: 0.00047081]
	Learning Rate: 0.000470806
	LOSS [training: 0.15778190006124357 | validation: 0.18824963274421222]
	TIME [epoch: 9.78 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15332052461460263		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.15332052461460263 | validation: 0.16640160398819961]
	TIME [epoch: 9.8 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15148696521997368		[learning rate: 0.00046853]
	Learning Rate: 0.000468529
	LOSS [training: 0.15148696521997368 | validation: 0.2555993894967839]
	TIME [epoch: 9.8 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15340231401223442		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.15340231401223442 | validation: 0.1705014312729547]
	TIME [epoch: 9.8 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15373104919181874		[learning rate: 0.00046626]
	Learning Rate: 0.000466264
	LOSS [training: 0.15373104919181874 | validation: 0.15907687506412566]
	TIME [epoch: 9.8 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12163362722646065		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.12163362722646065 | validation: 0.21393133539691472]
	TIME [epoch: 9.79 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1327518291762036		[learning rate: 0.00046401]
	Learning Rate: 0.000464009
	LOSS [training: 0.1327518291762036 | validation: 0.1355760943308416]
	TIME [epoch: 9.79 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1253989422438709		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.1253989422438709 | validation: 0.14722363550240553]
	TIME [epoch: 9.8 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10936906690332496		[learning rate: 0.00046177]
	Learning Rate: 0.000461765
	LOSS [training: 0.10936906690332496 | validation: 0.13396976739756875]
	TIME [epoch: 9.81 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12049083723465374		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.12049083723465374 | validation: 0.14076020332272676]
	TIME [epoch: 9.78 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11470476520593312		[learning rate: 0.00045953]
	Learning Rate: 0.000459532
	LOSS [training: 0.11470476520593312 | validation: 0.1839052851813333]
	TIME [epoch: 9.79 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11322706155280975		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.11322706155280975 | validation: 0.12929554598825416]
	TIME [epoch: 9.81 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12009267972568513		[learning rate: 0.00045731]
	Learning Rate: 0.00045731
	LOSS [training: 0.12009267972568513 | validation: 0.16111648432161327]
	TIME [epoch: 9.78 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1775323934071822		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.1775323934071822 | validation: 0.17506598906918217]
	TIME [epoch: 9.8 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14740201769022707		[learning rate: 0.0004551]
	Learning Rate: 0.000455098
	LOSS [training: 0.14740201769022707 | validation: 0.1559284487054464]
	TIME [epoch: 9.81 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1206652893226505		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.1206652893226505 | validation: 0.2239577968145318]
	TIME [epoch: 9.81 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.198988420403241		[learning rate: 0.0004529]
	Learning Rate: 0.000452898
	LOSS [training: 0.198988420403241 | validation: 0.1954718291955636]
	TIME [epoch: 9.79 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1234122257523637		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.1234122257523637 | validation: 0.18612707469715475]
	TIME [epoch: 9.78 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13326608837421086		[learning rate: 0.00045071]
	Learning Rate: 0.000450708
	LOSS [training: 0.13326608837421086 | validation: 0.16616363261000552]
	TIME [epoch: 9.81 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10357895890798778		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.10357895890798778 | validation: 0.19457218110317023]
	TIME [epoch: 9.78 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18693399348138698		[learning rate: 0.00044853]
	Learning Rate: 0.000448528
	LOSS [training: 0.18693399348138698 | validation: 0.21183063837813115]
	TIME [epoch: 9.79 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.210067484462719		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.210067484462719 | validation: 0.20625179893739604]
	TIME [epoch: 9.81 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14066046689563444		[learning rate: 0.00044636]
	Learning Rate: 0.000446359
	LOSS [training: 0.14066046689563444 | validation: 0.15751048543830518]
	TIME [epoch: 9.79 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1486215628362587		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.1486215628362587 | validation: 0.17875504558018718]
	TIME [epoch: 9.8 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2002684424096593		[learning rate: 0.0004442]
	Learning Rate: 0.0004442
	LOSS [training: 0.2002684424096593 | validation: 0.2388634566893465]
	TIME [epoch: 9.8 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22213566372287677		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.22213566372287677 | validation: 0.20711234917634244]
	TIME [epoch: 9.81 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25232718488996103		[learning rate: 0.00044205]
	Learning Rate: 0.000442052
	LOSS [training: 0.25232718488996103 | validation: 0.31800327686202706]
	TIME [epoch: 9.79 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3217452387634101		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.3217452387634101 | validation: 0.19579591733823315]
	TIME [epoch: 9.8 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2397611264061768		[learning rate: 0.00043991]
	Learning Rate: 0.000439915
	LOSS [training: 0.2397611264061768 | validation: 0.2039766237564165]
	TIME [epoch: 9.82 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26019127765450734		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.26019127765450734 | validation: 0.19540375781331945]
	TIME [epoch: 9.79 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19975664769959203		[learning rate: 0.00043779]
	Learning Rate: 0.000437787
	LOSS [training: 0.19975664769959203 | validation: 0.21475571546893066]
	TIME [epoch: 9.8 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17023475906344854		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.17023475906344854 | validation: 0.14499954613067076]
	TIME [epoch: 9.81 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17954388219584017		[learning rate: 0.00043567]
	Learning Rate: 0.00043567
	LOSS [training: 0.17954388219584017 | validation: 0.18928523560871757]
	TIME [epoch: 9.79 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15051883696639087		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.15051883696639087 | validation: 0.14479823295582336]
	TIME [epoch: 9.79 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18242081544402666		[learning rate: 0.00043356]
	Learning Rate: 0.000433563
	LOSS [training: 0.18242081544402666 | validation: 0.15574760979269747]
	TIME [epoch: 9.79 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1658445242858438		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.1658445242858438 | validation: 0.16130873437425072]
	TIME [epoch: 9.8 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18235339954206436		[learning rate: 0.00043147]
	Learning Rate: 0.000431467
	LOSS [training: 0.18235339954206436 | validation: 0.17732066835477084]
	TIME [epoch: 9.79 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14612677527651385		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.14612677527651385 | validation: 0.14474844341818244]
	TIME [epoch: 9.79 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16228921481899422		[learning rate: 0.00042938]
	Learning Rate: 0.00042938
	LOSS [training: 0.16228921481899422 | validation: 0.21154529132211317]
	TIME [epoch: 9.81 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16248405834980031		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.16248405834980031 | validation: 0.1725646912664025]
	TIME [epoch: 9.8 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12959636182777773		[learning rate: 0.0004273]
	Learning Rate: 0.000427304
	LOSS [training: 0.12959636182777773 | validation: 0.16774117896462237]
	TIME [epoch: 9.78 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12493201394136869		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.12493201394136869 | validation: 0.19541114763025497]
	TIME [epoch: 9.81 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1366132394601292		[learning rate: 0.00042524]
	Learning Rate: 0.000425238
	LOSS [training: 0.1366132394601292 | validation: 0.16825294876537647]
	TIME [epoch: 9.78 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17623181370281404		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.17623181370281404 | validation: 0.18512034086864795]
	TIME [epoch: 9.8 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17000095495609535		[learning rate: 0.00042318]
	Learning Rate: 0.000423181
	LOSS [training: 0.17000095495609535 | validation: 0.22028438770251554]
	TIME [epoch: 9.8 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11541657589094638		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.11541657589094638 | validation: 0.17813665848295848]
	TIME [epoch: 9.82 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14635910620330086		[learning rate: 0.00042113]
	Learning Rate: 0.000421135
	LOSS [training: 0.14635910620330086 | validation: 0.2013777824325461]
	TIME [epoch: 9.79 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14082975713710222		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.14082975713710222 | validation: 0.2022409540448142]
	TIME [epoch: 9.79 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1727981292507247		[learning rate: 0.0004191]
	Learning Rate: 0.000419098
	LOSS [training: 0.1727981292507247 | validation: 0.16627124706990246]
	TIME [epoch: 9.8 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11687014910548162		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.11687014910548162 | validation: 0.12912001197226602]
	TIME [epoch: 9.8 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11898420820798891		[learning rate: 0.00041707]
	Learning Rate: 0.000417072
	LOSS [training: 0.11898420820798891 | validation: 0.13467154362712777]
	TIME [epoch: 9.79 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18959265358350122		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.18959265358350122 | validation: 0.28069586498464133]
	TIME [epoch: 9.79 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19118595933433175		[learning rate: 0.00041505]
	Learning Rate: 0.000415055
	LOSS [training: 0.19118595933433175 | validation: 0.16257506059051133]
	TIME [epoch: 9.8 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.196313748307638		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.196313748307638 | validation: 0.2518267413711417]
	TIME [epoch: 9.8 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19587052621592407		[learning rate: 0.00041305]
	Learning Rate: 0.000413048
	LOSS [training: 0.19587052621592407 | validation: 0.2227125801262033]
	TIME [epoch: 9.79 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19468058996440446		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.19468058996440446 | validation: 0.25652044578223354]
	TIME [epoch: 9.82 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16612622470747568		[learning rate: 0.00041105]
	Learning Rate: 0.00041105
	LOSS [training: 0.16612622470747568 | validation: 0.22591739555685458]
	TIME [epoch: 9.79 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16214698841384625		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.16214698841384625 | validation: 0.2240620925218714]
	TIME [epoch: 9.79 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15240833031706164		[learning rate: 0.00040906]
	Learning Rate: 0.000409062
	LOSS [training: 0.15240833031706164 | validation: 0.1699267168438305]
	TIME [epoch: 9.8 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12293020065200906		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.12293020065200906 | validation: 0.1592220245402758]
	TIME [epoch: 9.79 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13400360124300664		[learning rate: 0.00040708]
	Learning Rate: 0.000407084
	LOSS [training: 0.13400360124300664 | validation: 0.1907881580433483]
	TIME [epoch: 9.78 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11452474602917091		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.11452474602917091 | validation: 0.17358074544664936]
	TIME [epoch: 9.79 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13058438724863106		[learning rate: 0.00040512]
	Learning Rate: 0.000405116
	LOSS [training: 0.13058438724863106 | validation: 0.1660852869055671]
	TIME [epoch: 9.81 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13697339605019826		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.13697339605019826 | validation: 0.19452680437047798]
	TIME [epoch: 9.79 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12112582613616822		[learning rate: 0.00040316]
	Learning Rate: 0.000403157
	LOSS [training: 0.12112582613616822 | validation: 0.16803910331072705]
	TIME [epoch: 9.79 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11393979290450976		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.11393979290450976 | validation: 0.14180835442356216]
	TIME [epoch: 9.81 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11454508158417034		[learning rate: 0.00040121]
	Learning Rate: 0.000401207
	LOSS [training: 0.11454508158417034 | validation: 0.15851173136401772]
	TIME [epoch: 9.79 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10276413382040639		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.10276413382040639 | validation: 0.17817587440070484]
	TIME [epoch: 9.79 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12670405016749137		[learning rate: 0.00039927]
	Learning Rate: 0.000399267
	LOSS [training: 0.12670405016749137 | validation: 0.13879339244525313]
	TIME [epoch: 9.81 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10217459356369382		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.10217459356369382 | validation: 0.16899818538473121]
	TIME [epoch: 9.79 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11763685067605556		[learning rate: 0.00039734]
	Learning Rate: 0.000397336
	LOSS [training: 0.11763685067605556 | validation: 0.17738437543026422]
	TIME [epoch: 9.79 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12434740542421488		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.12434740542421488 | validation: 0.14880613471994278]
	TIME [epoch: 9.8 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1081399415177757		[learning rate: 0.00039541]
	Learning Rate: 0.000395415
	LOSS [training: 0.1081399415177757 | validation: 0.13571758709411894]
	TIME [epoch: 9.81 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1162851838929206		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.1162851838929206 | validation: 0.15426442461575365]
	TIME [epoch: 9.8 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14362266990357556		[learning rate: 0.0003935]
	Learning Rate: 0.000393502
	LOSS [training: 0.14362266990357556 | validation: 0.171535573308582]
	TIME [epoch: 9.79 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10975498129417757		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.10975498129417757 | validation: 0.1764184454802873]
	TIME [epoch: 9.8 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11100168429992488		[learning rate: 0.0003916]
	Learning Rate: 0.000391599
	LOSS [training: 0.11100168429992488 | validation: 0.1602193760377177]
	TIME [epoch: 9.79 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11433156688340011		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.11433156688340011 | validation: 0.2523569405119942]
	TIME [epoch: 9.79 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15939531544448568		[learning rate: 0.00038971]
	Learning Rate: 0.000389706
	LOSS [training: 0.15939531544448568 | validation: 0.16963525675513638]
	TIME [epoch: 9.8 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14798688767786367		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.14798688767786367 | validation: 0.13675749576272453]
	TIME [epoch: 9.8 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12806599642171845		[learning rate: 0.00038782]
	Learning Rate: 0.000387821
	LOSS [training: 0.12806599642171845 | validation: 0.15141476918124927]
	TIME [epoch: 9.79 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11502923192386498		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.11502923192386498 | validation: 0.17380487652711477]
	TIME [epoch: 9.79 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12130577039310483		[learning rate: 0.00038595]
	Learning Rate: 0.000385946
	LOSS [training: 0.12130577039310483 | validation: 0.15560624451673244]
	TIME [epoch: 9.81 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14029632458855673		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.14029632458855673 | validation: 0.14736094593467328]
	TIME [epoch: 9.8 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10133769427228626		[learning rate: 0.00038408]
	Learning Rate: 0.000384079
	LOSS [training: 0.10133769427228626 | validation: 0.1544523902491805]
	TIME [epoch: 9.78 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11754544004704462		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.11754544004704462 | validation: 0.210359941452162]
	TIME [epoch: 9.81 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12352157474921525		[learning rate: 0.00038222]
	Learning Rate: 0.000382222
	LOSS [training: 0.12352157474921525 | validation: 0.180634748110188]
	TIME [epoch: 9.8 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12759062260386164		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.12759062260386164 | validation: 0.16105179180014298]
	TIME [epoch: 9.8 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10069927965396816		[learning rate: 0.00038037]
	Learning Rate: 0.000380374
	LOSS [training: 0.10069927965396816 | validation: 0.1327709336507811]
	TIME [epoch: 9.8 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08562373569052441		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.08562373569052441 | validation: 0.19142612233273973]
	TIME [epoch: 9.8 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1368960406384173		[learning rate: 0.00037853]
	Learning Rate: 0.000378534
	LOSS [training: 0.1368960406384173 | validation: 0.1473444441584166]
	TIME [epoch: 9.78 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12433672661958242		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.12433672661958242 | validation: 0.13390921936543987]
	TIME [epoch: 9.8 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11265811846907518		[learning rate: 0.0003767]
	Learning Rate: 0.000376704
	LOSS [training: 0.11265811846907518 | validation: 0.19233720364272877]
	TIME [epoch: 9.8 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11048337389862987		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.11048337389862987 | validation: 0.14267923378934425]
	TIME [epoch: 9.79 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10035099525102087		[learning rate: 0.00037488]
	Learning Rate: 0.000374882
	LOSS [training: 0.10035099525102087 | validation: 0.14912227554652416]
	TIME [epoch: 9.78 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09893378799166658		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.09893378799166658 | validation: 0.19604478827344732]
	TIME [epoch: 9.8 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14349573205136362		[learning rate: 0.00037307]
	Learning Rate: 0.000373069
	LOSS [training: 0.14349573205136362 | validation: 0.1435004193416244]
	TIME [epoch: 9.79 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10002366390239607		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.10002366390239607 | validation: 0.17656832298050756]
	TIME [epoch: 9.81 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09636368329638437		[learning rate: 0.00037127]
	Learning Rate: 0.000371265
	LOSS [training: 0.09636368329638437 | validation: 0.12335419658348842]
	TIME [epoch: 9.8 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09888576595368115		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.09888576595368115 | validation: 0.19414761599215286]
	TIME [epoch: 9.81 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11837938179894118		[learning rate: 0.00036947]
	Learning Rate: 0.00036947
	LOSS [training: 0.11837938179894118 | validation: 0.19133208881634836]
	TIME [epoch: 9.79 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12625851164913943		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.12625851164913943 | validation: 0.15388788538347867]
	TIME [epoch: 9.79 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09760447971699157		[learning rate: 0.00036768]
	Learning Rate: 0.000367683
	LOSS [training: 0.09760447971699157 | validation: 0.15674282319918276]
	TIME [epoch: 9.81 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10804223506399946		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.10804223506399946 | validation: 0.15078771481988526]
	TIME [epoch: 9.81 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09842210076436228		[learning rate: 0.00036591]
	Learning Rate: 0.000365905
	LOSS [training: 0.09842210076436228 | validation: 0.14752035175182196]
	TIME [epoch: 9.79 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09792013756606692		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.09792013756606692 | validation: 0.1411787188154024]
	TIME [epoch: 9.8 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12358487352224405		[learning rate: 0.00036414]
	Learning Rate: 0.000364136
	LOSS [training: 0.12358487352224405 | validation: 0.20291368418161645]
	TIME [epoch: 9.79 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1190050404274279		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.1190050404274279 | validation: 0.22749777909980531]
	TIME [epoch: 9.79 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12413543956995188		[learning rate: 0.00036237]
	Learning Rate: 0.000362375
	LOSS [training: 0.12413543956995188 | validation: 0.1735574009707692]
	TIME [epoch: 9.79 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11313035395138182		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.11313035395138182 | validation: 0.16587669093337115]
	TIME [epoch: 9.81 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12374494742809075		[learning rate: 0.00036062]
	Learning Rate: 0.000360622
	LOSS [training: 0.12374494742809075 | validation: 0.1567657899732391]
	TIME [epoch: 9.79 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10803035059855655		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.10803035059855655 | validation: 0.11692157461337889]
	TIME [epoch: 9.8 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10386333881239104		[learning rate: 0.00035888]
	Learning Rate: 0.000358878
	LOSS [training: 0.10386333881239104 | validation: 0.13948175480829897]
	TIME [epoch: 9.81 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0987403716413975		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.0987403716413975 | validation: 0.14147934032531648]
	TIME [epoch: 9.8 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14077237913461182		[learning rate: 0.00035714]
	Learning Rate: 0.000357143
	LOSS [training: 0.14077237913461182 | validation: 0.17595628691803883]
	TIME [epoch: 9.81 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12806503566875946		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.12806503566875946 | validation: 0.1320458086629296]
	TIME [epoch: 9.81 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.102962305455585		[learning rate: 0.00035542]
	Learning Rate: 0.000355416
	LOSS [training: 0.102962305455585 | validation: 0.11623598632612375]
	TIME [epoch: 9.8 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10341469986808535		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.10341469986808535 | validation: 0.14457597740618433]
	TIME [epoch: 9.8 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11404944411748415		[learning rate: 0.0003537]
	Learning Rate: 0.000353697
	LOSS [training: 0.11404944411748415 | validation: 0.19267409170517455]
	TIME [epoch: 9.8 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13199270068368626		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.13199270068368626 | validation: 0.1416724305990704]
	TIME [epoch: 9.81 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10201209326255767		[learning rate: 0.00035199]
	Learning Rate: 0.000351987
	LOSS [training: 0.10201209326255767 | validation: 0.13446529846890332]
	TIME [epoch: 9.81 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10138619797603254		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.10138619797603254 | validation: 0.12871327361957402]
	TIME [epoch: 9.8 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11509963946991544		[learning rate: 0.00035028]
	Learning Rate: 0.000350285
	LOSS [training: 0.11509963946991544 | validation: 0.15672598501349208]
	TIME [epoch: 9.81 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.108852880219559		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.108852880219559 | validation: 0.15528747778577326]
	TIME [epoch: 9.8 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1019113310708579		[learning rate: 0.00034859]
	Learning Rate: 0.000348591
	LOSS [training: 0.1019113310708579 | validation: 0.16767128630451864]
	TIME [epoch: 9.79 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16350190740471351		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.16350190740471351 | validation: 0.15153740924525994]
	TIME [epoch: 9.8 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.126486425565846		[learning rate: 0.0003469]
	Learning Rate: 0.000346905
	LOSS [training: 0.126486425565846 | validation: 0.20529297687647127]
	TIME [epoch: 9.82 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13007332850642384		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.13007332850642384 | validation: 0.18625138646683462]
	TIME [epoch: 9.8 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13339489368553897		[learning rate: 0.00034523]
	Learning Rate: 0.000345227
	LOSS [training: 0.13339489368553897 | validation: 0.15394346395200764]
	TIME [epoch: 9.79 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14078043457535513		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.14078043457535513 | validation: 0.16720437722295728]
	TIME [epoch: 9.82 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13785660735910876		[learning rate: 0.00034356]
	Learning Rate: 0.000343558
	LOSS [training: 0.13785660735910876 | validation: 0.11444852129066843]
	TIME [epoch: 9.8 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12563767021192196		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.12563767021192196 | validation: 0.16598172083698565]
	TIME [epoch: 9.8 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11667699735410156		[learning rate: 0.0003419]
	Learning Rate: 0.000341897
	LOSS [training: 0.11667699735410156 | validation: 0.16041022455821335]
	TIME [epoch: 9.81 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14740533842423248		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.14740533842423248 | validation: 0.15653669843999576]
	TIME [epoch: 9.8 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13659960043708247		[learning rate: 0.00034024]
	Learning Rate: 0.000340243
	LOSS [training: 0.13659960043708247 | validation: 0.1567200887086776]
	TIME [epoch: 9.79 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14622152039106884		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.14622152039106884 | validation: 0.18155317893183237]
	TIME [epoch: 9.8 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1160345886053753		[learning rate: 0.0003386]
	Learning Rate: 0.000338598
	LOSS [training: 0.1160345886053753 | validation: 0.14455659946447877]
	TIME [epoch: 9.81 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1065033012115391		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.1065033012115391 | validation: 0.12284857737440544]
	TIME [epoch: 9.8 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09452286568908097		[learning rate: 0.00033696]
	Learning Rate: 0.00033696
	LOSS [training: 0.09452286568908097 | validation: 0.12170445359842594]
	TIME [epoch: 9.8 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10117341822037529		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.10117341822037529 | validation: 0.13390798784504107]
	TIME [epoch: 9.81 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11502655375978113		[learning rate: 0.00033533]
	Learning Rate: 0.000335331
	LOSS [training: 0.11502655375978113 | validation: 0.16273995202274766]
	TIME [epoch: 9.79 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12192345080390006		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.12192345080390006 | validation: 0.17494663257226348]
	TIME [epoch: 9.79 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17580286785908625		[learning rate: 0.00033371]
	Learning Rate: 0.000333709
	LOSS [training: 0.17580286785908625 | validation: 0.11487129140528522]
	TIME [epoch: 9.81 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11149929227143873		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.11149929227143873 | validation: 0.13494189821882124]
	TIME [epoch: 9.81 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09678550239047011		[learning rate: 0.0003321]
	Learning Rate: 0.000332096
	LOSS [training: 0.09678550239047011 | validation: 0.15083658277273077]
	TIME [epoch: 9.79 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09786007208947609		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.09786007208947609 | validation: 0.13825412639178158]
	TIME [epoch: 9.8 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14376245963935988		[learning rate: 0.00033049]
	Learning Rate: 0.00033049
	LOSS [training: 0.14376245963935988 | validation: 0.1589766270590649]
	TIME [epoch: 9.81 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10638998005359153		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.10638998005359153 | validation: 0.1377239522465455]
	TIME [epoch: 9.8 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13860735302545876		[learning rate: 0.00032889]
	Learning Rate: 0.000328891
	LOSS [training: 0.13860735302545876 | validation: 0.12786238983215406]
	TIME [epoch: 9.8 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10414748522619002		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.10414748522619002 | validation: 0.13733142153121405]
	TIME [epoch: 9.82 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11069108302194011		[learning rate: 0.0003273]
	Learning Rate: 0.000327301
	LOSS [training: 0.11069108302194011 | validation: 0.12431213288522486]
	TIME [epoch: 9.79 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10543864962821012		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.10543864962821012 | validation: 0.13151291099081922]
	TIME [epoch: 9.8 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11466515121434781		[learning rate: 0.00032572]
	Learning Rate: 0.000325718
	LOSS [training: 0.11466515121434781 | validation: 0.15597793921434142]
	TIME [epoch: 9.8 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1152444271150131		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.1152444271150131 | validation: 0.12489737257430662]
	TIME [epoch: 9.82 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10037880786795342		[learning rate: 0.00032414]
	Learning Rate: 0.000324143
	LOSS [training: 0.10037880786795342 | validation: 0.12497794644594486]
	TIME [epoch: 9.78 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09269813383803963		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.09269813383803963 | validation: 0.11283546709857455]
	TIME [epoch: 9.8 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10588695839370921		[learning rate: 0.00032258]
	Learning Rate: 0.000322576
	LOSS [training: 0.10588695839370921 | validation: 0.13647914891118518]
	TIME [epoch: 9.81 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09902387734855919		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.09902387734855919 | validation: 0.1464845247229177]
	TIME [epoch: 9.79 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11218009410790801		[learning rate: 0.00032102]
	Learning Rate: 0.000321016
	LOSS [training: 0.11218009410790801 | validation: 0.14410529772190528]
	TIME [epoch: 9.79 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10489657702301505		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.10489657702301505 | validation: 0.1487250445389545]
	TIME [epoch: 9.81 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09963009022977216		[learning rate: 0.00031946]
	Learning Rate: 0.000319463
	LOSS [training: 0.09963009022977216 | validation: 0.1513944629497586]
	TIME [epoch: 9.8 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.116024651428457		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.116024651428457 | validation: 0.16432398700766532]
	TIME [epoch: 9.79 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11809539950365892		[learning rate: 0.00031792]
	Learning Rate: 0.000317918
	LOSS [training: 0.11809539950365892 | validation: 0.12565757833831193]
	TIME [epoch: 9.79 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1225397009197006		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.1225397009197006 | validation: 0.17057379767093564]
	TIME [epoch: 9.81 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12366401892882832		[learning rate: 0.00031638]
	Learning Rate: 0.000316381
	LOSS [training: 0.12366401892882832 | validation: 0.1304389271445379]
	TIME [epoch: 9.79 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10417412993321695		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.10417412993321695 | validation: 0.17667437913392434]
	TIME [epoch: 9.8 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1421858742534903		[learning rate: 0.00031485]
	Learning Rate: 0.000314851
	LOSS [training: 0.1421858742534903 | validation: 0.1776176132594135]
	TIME [epoch: 9.82 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10683510589496589		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.10683510589496589 | validation: 0.14373323914217667]
	TIME [epoch: 9.8 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11174895388971559		[learning rate: 0.00031333]
	Learning Rate: 0.000313329
	LOSS [training: 0.11174895388971559 | validation: 0.1438632341256389]
	TIME [epoch: 9.79 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11465193867617347		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.11465193867617347 | validation: 0.1533306066336786]
	TIME [epoch: 9.8 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1050550314193727		[learning rate: 0.00031181]
	Learning Rate: 0.000311813
	LOSS [training: 0.1050550314193727 | validation: 0.12250099801976509]
	TIME [epoch: 9.79 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11331124128910575		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.11331124128910575 | validation: 0.13155544339735767]
	TIME [epoch: 9.79 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11249480980467168		[learning rate: 0.00031031]
	Learning Rate: 0.000310305
	LOSS [training: 0.11249480980467168 | validation: 0.16490240127931458]
	TIME [epoch: 9.79 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1276185042891677		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.1276185042891677 | validation: 0.12174071742142246]
	TIME [epoch: 9.82 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10773547962064962		[learning rate: 0.0003088]
	Learning Rate: 0.000308805
	LOSS [training: 0.10773547962064962 | validation: 0.11316874517796909]
	TIME [epoch: 9.79 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09437107814093426		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.09437107814093426 | validation: 0.10974553949514974]
	TIME [epoch: 9.79 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09646379932333138		[learning rate: 0.00030731]
	Learning Rate: 0.000307312
	LOSS [training: 0.09646379932333138 | validation: 0.13966149382485019]
	TIME [epoch: 9.81 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12681811782591657		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.12681811782591657 | validation: 0.139912621541356]
	TIME [epoch: 9.8 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13272560235346414		[learning rate: 0.00030583]
	Learning Rate: 0.000305826
	LOSS [training: 0.13272560235346414 | validation: 0.154255008860182]
	TIME [epoch: 9.8 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13967918712461916		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.13967918712461916 | validation: 0.14437413614071049]
	TIME [epoch: 9.81 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.109772725575992		[learning rate: 0.00030435]
	Learning Rate: 0.000304347
	LOSS [training: 0.109772725575992 | validation: 0.12832856872603915]
	TIME [epoch: 9.8 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09096933818565468		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.09096933818565468 | validation: 0.12431568950327332]
	TIME [epoch: 9.8 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11239556879460055		[learning rate: 0.00030287]
	Learning Rate: 0.000302875
	LOSS [training: 0.11239556879460055 | validation: 0.11975173094982036]
	TIME [epoch: 9.79 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10144018574185298		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.10144018574185298 | validation: 0.11525469927695109]
	TIME [epoch: 9.81 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10032759974264449		[learning rate: 0.00030141]
	Learning Rate: 0.00030141
	LOSS [training: 0.10032759974264449 | validation: 0.1270647329342466]
	TIME [epoch: 9.78 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1414000078723065		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.1414000078723065 | validation: 0.16741393431339238]
	TIME [epoch: 9.79 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1597711624882982		[learning rate: 0.00029995]
	Learning Rate: 0.000299953
	LOSS [training: 0.1597711624882982 | validation: 0.1482123066508138]
	TIME [epoch: 9.8 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17089452166318417		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.17089452166318417 | validation: 0.14101975137483394]
	TIME [epoch: 9.79 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13656379096929455		[learning rate: 0.0002985]
	Learning Rate: 0.000298502
	LOSS [training: 0.13656379096929455 | validation: 0.14526122538978534]
	TIME [epoch: 9.78 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11089747397929386		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.11089747397929386 | validation: 0.10887003977325645]
	TIME [epoch: 9.79 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0965570974325364		[learning rate: 0.00029706]
	Learning Rate: 0.000297059
	LOSS [training: 0.0965570974325364 | validation: 0.15842131112742774]
	TIME [epoch: 9.81 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11182841210076903		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.11182841210076903 | validation: 0.12895100778160512]
	TIME [epoch: 9.8 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10616045862325571		[learning rate: 0.00029562]
	Learning Rate: 0.000295622
	LOSS [training: 0.10616045862325571 | validation: 0.13237157143173756]
	TIME [epoch: 9.8 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13087477087816163		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.13087477087816163 | validation: 0.13743082678739582]
	TIME [epoch: 9.81 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12441905670067137		[learning rate: 0.00029419]
	Learning Rate: 0.000294193
	LOSS [training: 0.12441905670067137 | validation: 0.11250688716920804]
	TIME [epoch: 9.79 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1032581387989205		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.1032581387989205 | validation: 0.13755324569612956]
	TIME [epoch: 9.79 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10116816311442893		[learning rate: 0.00029277]
	Learning Rate: 0.00029277
	LOSS [training: 0.10116816311442893 | validation: 0.11766330349241447]
	TIME [epoch: 9.8 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14987905088003495		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.14987905088003495 | validation: 0.1534913320269148]
	TIME [epoch: 9.8 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14606854298852207		[learning rate: 0.00029135]
	Learning Rate: 0.000291354
	LOSS [training: 0.14606854298852207 | validation: 0.12630737966272937]
	TIME [epoch: 9.79 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12463708652358192		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.12463708652358192 | validation: 0.13997654261837858]
	TIME [epoch: 9.79 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13252449469517089		[learning rate: 0.00028995]
	Learning Rate: 0.000289945
	LOSS [training: 0.13252449469517089 | validation: 0.1805444020804274]
	TIME [epoch: 9.81 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11719081836023182		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.11719081836023182 | validation: 0.1682272438155056]
	TIME [epoch: 9.78 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12011533528151197		[learning rate: 0.00028854]
	Learning Rate: 0.000288543
	LOSS [training: 0.12011533528151197 | validation: 0.20868164121985147]
	TIME [epoch: 9.79 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.142158863680049		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.142158863680049 | validation: 0.12348953222227675]
	TIME [epoch: 9.82 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09390742446515819		[learning rate: 0.00028715]
	Learning Rate: 0.000287148
	LOSS [training: 0.09390742446515819 | validation: 0.13493443107373496]
	TIME [epoch: 9.79 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12874642727972513		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.12874642727972513 | validation: 0.1695050756568853]
	TIME [epoch: 9.78 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13454716542932554		[learning rate: 0.00028576]
	Learning Rate: 0.000285759
	LOSS [training: 0.13454716542932554 | validation: 0.14411923148391698]
	TIME [epoch: 9.8 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09609971986728935		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.09609971986728935 | validation: 0.17081667906747083]
	TIME [epoch: 9.8 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10023393675067616		[learning rate: 0.00028438]
	Learning Rate: 0.000284377
	LOSS [training: 0.10023393675067616 | validation: 0.16318184441214034]
	TIME [epoch: 9.78 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11366004873793775		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.11366004873793775 | validation: 0.12505778920947605]
	TIME [epoch: 9.79 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13180280733920885		[learning rate: 0.000283]
	Learning Rate: 0.000283002
	LOSS [training: 0.13180280733920885 | validation: 0.16721914600661109]
	TIME [epoch: 9.81 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12812449456066805		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.12812449456066805 | validation: 0.14511322689812745]
	TIME [epoch: 9.79 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11633164749303046		[learning rate: 0.00028163]
	Learning Rate: 0.000281633
	LOSS [training: 0.11633164749303046 | validation: 0.1457380272157845]
	TIME [epoch: 9.78 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1471424092979567		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.1471424092979567 | validation: 0.13476380734447357]
	TIME [epoch: 9.8 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11527635855348897		[learning rate: 0.00028027]
	Learning Rate: 0.000280272
	LOSS [training: 0.11527635855348897 | validation: 0.12311249517545016]
	TIME [epoch: 9.79 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11521184684751617		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.11521184684751617 | validation: 0.12458579707978804]
	TIME [epoch: 9.8 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10594636396030536		[learning rate: 0.00027892]
	Learning Rate: 0.000278916
	LOSS [training: 0.10594636396030536 | validation: 0.13433476152578636]
	TIME [epoch: 9.78 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12847283973298734		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.12847283973298734 | validation: 0.14147620790460796]
	TIME [epoch: 9.81 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1007736214597869		[learning rate: 0.00027757]
	Learning Rate: 0.000277567
	LOSS [training: 0.1007736214597869 | validation: 0.10408847192532887]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1579.pth
	Model improved!!!
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10003364345908963		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.10003364345908963 | validation: 0.11682447112933819]
	TIME [epoch: 9.79 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10421697917102753		[learning rate: 0.00027623]
	Learning Rate: 0.000276225
	LOSS [training: 0.10421697917102753 | validation: 0.1570385764415112]
	TIME [epoch: 9.8 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11154889044938503		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.11154889044938503 | validation: 0.1446468018911608]
	TIME [epoch: 9.78 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10205805550882419		[learning rate: 0.00027489]
	Learning Rate: 0.000274889
	LOSS [training: 0.10205805550882419 | validation: 0.13162431147959383]
	TIME [epoch: 9.78 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09617606892904648		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.09617606892904648 | validation: 0.12692954984009297]
	TIME [epoch: 9.81 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10538029110262923		[learning rate: 0.00027356]
	Learning Rate: 0.00027356
	LOSS [training: 0.10538029110262923 | validation: 0.14112714008241906]
	TIME [epoch: 9.78 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12323656308125255		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.12323656308125255 | validation: 0.14838517586007552]
	TIME [epoch: 9.8 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0955382280359141		[learning rate: 0.00027224]
	Learning Rate: 0.000272237
	LOSS [training: 0.0955382280359141 | validation: 0.12499775818050121]
	TIME [epoch: 9.78 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11110079578646168		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.11110079578646168 | validation: 0.12670509477492484]
	TIME [epoch: 9.81 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09904011105805963		[learning rate: 0.00027092]
	Learning Rate: 0.000270921
	LOSS [training: 0.09904011105805963 | validation: 0.121471772987796]
	TIME [epoch: 9.79 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09615182582108057		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.09615182582108057 | validation: 0.15031610677022067]
	TIME [epoch: 9.79 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11172386916885568		[learning rate: 0.00026961]
	Learning Rate: 0.000269611
	LOSS [training: 0.11172386916885568 | validation: 0.13415048247847505]
	TIME [epoch: 9.8 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10378564603780997		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.10378564603780997 | validation: 0.18197724702241488]
	TIME [epoch: 9.8 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10728223869315075		[learning rate: 0.00026831]
	Learning Rate: 0.000268307
	LOSS [training: 0.10728223869315075 | validation: 0.1488873620282572]
	TIME [epoch: 9.79 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10104161573978698		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.10104161573978698 | validation: 0.14811263834890664]
	TIME [epoch: 9.79 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12414155306940093		[learning rate: 0.00026701]
	Learning Rate: 0.000267009
	LOSS [training: 0.12414155306940093 | validation: 0.13534147441913916]
	TIME [epoch: 9.8 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11468173168591474		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.11468173168591474 | validation: 0.13812075626840328]
	TIME [epoch: 9.79 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10639741835286136		[learning rate: 0.00026572]
	Learning Rate: 0.000265718
	LOSS [training: 0.10639741835286136 | validation: 0.14019321370781035]
	TIME [epoch: 9.79 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10500981613631158		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.10500981613631158 | validation: 0.12621530744248338]
	TIME [epoch: 9.81 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10686451699055685		[learning rate: 0.00026443]
	Learning Rate: 0.000264433
	LOSS [training: 0.10686451699055685 | validation: 0.1578296499376297]
	TIME [epoch: 9.79 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10685095025460653		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.10685095025460653 | validation: 0.14013218819002426]
	TIME [epoch: 9.78 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11160337396195022		[learning rate: 0.00026315]
	Learning Rate: 0.000263154
	LOSS [training: 0.11160337396195022 | validation: 0.1537349739454758]
	TIME [epoch: 9.79 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11347275925533076		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.11347275925533076 | validation: 0.11353142211391282]
	TIME [epoch: 9.78 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09247652722194147		[learning rate: 0.00026188]
	Learning Rate: 0.000261882
	LOSS [training: 0.09247652722194147 | validation: 0.1266086967512615]
	TIME [epoch: 9.79 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11655819676076562		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.11655819676076562 | validation: 0.13974769693386166]
	TIME [epoch: 9.78 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0978902600541632		[learning rate: 0.00026062]
	Learning Rate: 0.000260615
	LOSS [training: 0.0978902600541632 | validation: 0.1350034994655503]
	TIME [epoch: 9.8 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09568382796187157		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.09568382796187157 | validation: 0.1583914367295661]
	TIME [epoch: 9.79 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10861877951932815		[learning rate: 0.00025936]
	Learning Rate: 0.000259355
	LOSS [training: 0.10861877951932815 | validation: 0.1656283692963236]
	TIME [epoch: 9.78 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09674409697639258		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.09674409697639258 | validation: 0.15452475181529454]
	TIME [epoch: 9.81 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1138788423552104		[learning rate: 0.0002581]
	Learning Rate: 0.000258101
	LOSS [training: 0.1138788423552104 | validation: 0.17299747188686806]
	TIME [epoch: 9.78 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10408050265915676		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.10408050265915676 | validation: 0.12632474006586375]
	TIME [epoch: 9.78 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09634777645134616		[learning rate: 0.00025685]
	Learning Rate: 0.000256853
	LOSS [training: 0.09634777645134616 | validation: 0.17179189565259623]
	TIME [epoch: 9.8 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11140310918805155		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.11140310918805155 | validation: 0.15134455730954038]
	TIME [epoch: 9.78 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10087550010605328		[learning rate: 0.00025561]
	Learning Rate: 0.000255611
	LOSS [training: 0.10087550010605328 | validation: 0.15230460433706486]
	TIME [epoch: 9.79 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0878293913648725		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.0878293913648725 | validation: 0.15911194837595666]
	TIME [epoch: 9.78 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09657785316449069		[learning rate: 0.00025437]
	Learning Rate: 0.000254375
	LOSS [training: 0.09657785316449069 | validation: 0.12780728713412778]
	TIME [epoch: 9.81 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10043762396919739		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.10043762396919739 | validation: 0.1322571119689911]
	TIME [epoch: 9.79 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10957877840789214		[learning rate: 0.00025314]
	Learning Rate: 0.000253144
	LOSS [training: 0.10957877840789214 | validation: 0.1040302650543795]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1617.pth
	Model improved!!!
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08968141419549919		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.08968141419549919 | validation: 0.12322029702231753]
	TIME [epoch: 9.82 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09510973483191565		[learning rate: 0.00025192]
	Learning Rate: 0.00025192
	LOSS [training: 0.09510973483191565 | validation: 0.16041520945784363]
	TIME [epoch: 9.79 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10069611690174177		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.10069611690174177 | validation: 0.12445304460781915]
	TIME [epoch: 9.78 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07480020069990312		[learning rate: 0.0002507]
	Learning Rate: 0.000250702
	LOSS [training: 0.07480020069990312 | validation: 0.13196439158442605]
	TIME [epoch: 9.79 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0974282096747378		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.0974282096747378 | validation: 0.13365937604520267]
	TIME [epoch: 9.79 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14542947422303532		[learning rate: 0.00024949]
	Learning Rate: 0.00024949
	LOSS [training: 0.14542947422303532 | validation: 0.13371910377303323]
	TIME [epoch: 9.79 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1092063040459706		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.1092063040459706 | validation: 0.113622828578421]
	TIME [epoch: 9.79 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08425943729891869		[learning rate: 0.00024828]
	Learning Rate: 0.000248283
	LOSS [training: 0.08425943729891869 | validation: 0.11088972574578915]
	TIME [epoch: 9.79 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09715023511770886		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.09715023511770886 | validation: 0.12893301112444408]
	TIME [epoch: 9.78 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10546778636530155		[learning rate: 0.00024708]
	Learning Rate: 0.000247083
	LOSS [training: 0.10546778636530155 | validation: 0.15280263374614173]
	TIME [epoch: 9.79 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09763388475465465		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.09763388475465465 | validation: 0.13405372917301328]
	TIME [epoch: 9.8 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09219400474417343		[learning rate: 0.00024589]
	Learning Rate: 0.000245888
	LOSS [training: 0.09219400474417343 | validation: 0.12282774287902815]
	TIME [epoch: 9.78 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10020950002307949		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.10020950002307949 | validation: 0.11005122665452532]
	TIME [epoch: 9.79 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09780113192396642		[learning rate: 0.0002447]
	Learning Rate: 0.000244699
	LOSS [training: 0.09780113192396642 | validation: 0.1270786311353743]
	TIME [epoch: 9.8 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09051593296859876		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.09051593296859876 | validation: 0.1376489781544998]
	TIME [epoch: 9.8 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08865272927790369		[learning rate: 0.00024352]
	Learning Rate: 0.000243515
	LOSS [training: 0.08865272927790369 | validation: 0.12979782988410274]
	TIME [epoch: 9.79 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09807862281768846		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.09807862281768846 | validation: 0.13155300162676262]
	TIME [epoch: 9.78 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17297862153079555		[learning rate: 0.00024234]
	Learning Rate: 0.000242338
	LOSS [training: 0.17297862153079555 | validation: 0.21779956342664655]
	TIME [epoch: 9.8 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15211648528413216		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.15211648528413216 | validation: 0.13643974673836615]
	TIME [epoch: 9.79 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10156415443544595		[learning rate: 0.00024117]
	Learning Rate: 0.000241166
	LOSS [training: 0.10156415443544595 | validation: 0.1572762629694952]
	TIME [epoch: 9.78 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1174708813988697		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.1174708813988697 | validation: 0.16220641855193008]
	TIME [epoch: 9.81 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09069589673052118		[learning rate: 0.00024]
	Learning Rate: 0.00024
	LOSS [training: 0.09069589673052118 | validation: 0.11554524726887484]
	TIME [epoch: 9.8 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09426132991440178		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.09426132991440178 | validation: 0.12999136961368343]
	TIME [epoch: 9.8 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09501178946626657		[learning rate: 0.00023884]
	Learning Rate: 0.000238839
	LOSS [training: 0.09501178946626657 | validation: 0.1667097408285833]
	TIME [epoch: 9.8 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09544805227659309		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.09544805227659309 | validation: 0.1480562442806139]
	TIME [epoch: 9.81 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09948269227372676		[learning rate: 0.00023768]
	Learning Rate: 0.000237684
	LOSS [training: 0.09948269227372676 | validation: 0.11237235322462916]
	TIME [epoch: 9.79 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09264291399556937		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.09264291399556937 | validation: 0.1542019558121327]
	TIME [epoch: 9.8 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09307892329784898		[learning rate: 0.00023653]
	Learning Rate: 0.000236535
	LOSS [training: 0.09307892329784898 | validation: 0.12758776798142735]
	TIME [epoch: 9.81 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10049825682619942		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.10049825682619942 | validation: 0.14934519264523408]
	TIME [epoch: 9.8 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1043149916619223		[learning rate: 0.00023539]
	Learning Rate: 0.000235391
	LOSS [training: 0.1043149916619223 | validation: 0.13610545699056217]
	TIME [epoch: 9.8 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09490626494838414		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.09490626494838414 | validation: 0.13915137874860925]
	TIME [epoch: 9.8 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1092788559991587		[learning rate: 0.00023425]
	Learning Rate: 0.000234252
	LOSS [training: 0.1092788559991587 | validation: 0.13460463801009753]
	TIME [epoch: 9.8 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08373960560021627		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.08373960560021627 | validation: 0.127868052202202]
	TIME [epoch: 9.79 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10233280846092536		[learning rate: 0.00023312]
	Learning Rate: 0.00023312
	LOSS [training: 0.10233280846092536 | validation: 0.1647810635549379]
	TIME [epoch: 9.79 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10991205742308803		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.10991205742308803 | validation: 0.11009194333903882]
	TIME [epoch: 9.82 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09118632251501614		[learning rate: 0.00023199]
	Learning Rate: 0.000231992
	LOSS [training: 0.09118632251501614 | validation: 0.12277990709921728]
	TIME [epoch: 9.8 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1519971877312162		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.1519971877312162 | validation: 0.1990323140179396]
	TIME [epoch: 9.79 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17865135542420452		[learning rate: 0.00023087]
	Learning Rate: 0.00023087
	LOSS [training: 0.17865135542420452 | validation: 0.10799251870505706]
	TIME [epoch: 9.8 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08759960363625599		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.08759960363625599 | validation: 0.11588893996068088]
	TIME [epoch: 9.81 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11586337689035413		[learning rate: 0.00022975]
	Learning Rate: 0.000229754
	LOSS [training: 0.11586337689035413 | validation: 0.14963005226178946]
	TIME [epoch: 9.79 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10484705262924428		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.10484705262924428 | validation: 0.15954277085494936]
	TIME [epoch: 9.8 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09778491602200695		[learning rate: 0.00022864]
	Learning Rate: 0.000228643
	LOSS [training: 0.09778491602200695 | validation: 0.151238740849815]
	TIME [epoch: 9.8 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09505425235578119		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.09505425235578119 | validation: 0.12645145060808316]
	TIME [epoch: 9.79 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09407296274108792		[learning rate: 0.00022754]
	Learning Rate: 0.000227537
	LOSS [training: 0.09407296274108792 | validation: 0.1345130290395814]
	TIME [epoch: 9.8 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09934725243459762		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.09934725243459762 | validation: 0.12090781032833003]
	TIME [epoch: 9.81 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11024961145598619		[learning rate: 0.00022644]
	Learning Rate: 0.000226437
	LOSS [training: 0.11024961145598619 | validation: 0.11716047920140216]
	TIME [epoch: 9.79 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09293535728260889		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.09293535728260889 | validation: 0.13054637765309063]
	TIME [epoch: 9.79 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09570196990239048		[learning rate: 0.00022534]
	Learning Rate: 0.000225342
	LOSS [training: 0.09570196990239048 | validation: 0.15878945371733144]
	TIME [epoch: 9.82 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10354992407179582		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.10354992407179582 | validation: 0.15636566418056488]
	TIME [epoch: 9.79 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08890175021700682		[learning rate: 0.00022425]
	Learning Rate: 0.000224252
	LOSS [training: 0.08890175021700682 | validation: 0.10923257223501592]
	TIME [epoch: 9.79 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09896833456382909		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.09896833456382909 | validation: 0.1577971491336215]
	TIME [epoch: 9.8 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10624009225198154		[learning rate: 0.00022317]
	Learning Rate: 0.000223168
	LOSS [training: 0.10624009225198154 | validation: 0.13904938787349994]
	TIME [epoch: 9.8 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09951665088727164		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.09951665088727164 | validation: 0.13997685540228064]
	TIME [epoch: 9.81 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09746537902806292		[learning rate: 0.00022209]
	Learning Rate: 0.000222089
	LOSS [training: 0.09746537902806292 | validation: 0.11884664534400793]
	TIME [epoch: 9.8 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10017743349507709		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.10017743349507709 | validation: 0.14133660224575206]
	TIME [epoch: 9.81 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13307606183763404		[learning rate: 0.00022101]
	Learning Rate: 0.000221015
	LOSS [training: 0.13307606183763404 | validation: 0.17364821562660634]
	TIME [epoch: 9.8 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12251434341257553		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.12251434341257553 | validation: 0.1803674739689559]
	TIME [epoch: 9.8 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14813276959249688		[learning rate: 0.00021995]
	Learning Rate: 0.000219946
	LOSS [training: 0.14813276959249688 | validation: 0.19326504076192014]
	TIME [epoch: 9.79 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11355230228231132		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.11355230228231132 | validation: 0.14578036265387068]
	TIME [epoch: 9.79 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12266847566325981		[learning rate: 0.00021888]
	Learning Rate: 0.000218882
	LOSS [training: 0.12266847566325981 | validation: 0.1592315875804308]
	TIME [epoch: 9.8 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.123273302923427		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.123273302923427 | validation: 0.18060861876135836]
	TIME [epoch: 9.8 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1224724895430094		[learning rate: 0.00021782]
	Learning Rate: 0.000217824
	LOSS [training: 0.1224724895430094 | validation: 0.16590313155432312]
	TIME [epoch: 9.82 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12642717052436422		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.12642717052436422 | validation: 0.18634493062327578]
	TIME [epoch: 9.8 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1393210595603712		[learning rate: 0.00021677]
	Learning Rate: 0.00021677
	LOSS [training: 0.1393210595603712 | validation: 0.17564490916922165]
	TIME [epoch: 9.8 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1414725951478466		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.1414725951478466 | validation: 0.17578406868476287]
	TIME [epoch: 9.81 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12379427960877235		[learning rate: 0.00021572]
	Learning Rate: 0.000215722
	LOSS [training: 0.12379427960877235 | validation: 0.14429590266818415]
	TIME [epoch: 9.8 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09944739838813801		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.09944739838813801 | validation: 0.14157410369877194]
	TIME [epoch: 9.79 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0962585370781602		[learning rate: 0.00021468]
	Learning Rate: 0.000214679
	LOSS [training: 0.0962585370781602 | validation: 0.1544267791347526]
	TIME [epoch: 9.8 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11979763627174896		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.11979763627174896 | validation: 0.16921328476399883]
	TIME [epoch: 9.8 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12703843391492275		[learning rate: 0.00021364]
	Learning Rate: 0.000213641
	LOSS [training: 0.12703843391492275 | validation: 0.16972272101946018]
	TIME [epoch: 9.78 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1138765488646241		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.1138765488646241 | validation: 0.15816601677547323]
	TIME [epoch: 9.79 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09212530736291483		[learning rate: 0.00021261]
	Learning Rate: 0.000212608
	LOSS [training: 0.09212530736291483 | validation: 0.12627469440041217]
	TIME [epoch: 9.81 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0915537697657877		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.0915537697657877 | validation: 0.11526429300821864]
	TIME [epoch: 9.79 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08391661641489391		[learning rate: 0.00021158]
	Learning Rate: 0.00021158
	LOSS [training: 0.08391661641489391 | validation: 0.12962368594448367]
	TIME [epoch: 9.79 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10155167603339896		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.10155167603339896 | validation: 0.13384456040559486]
	TIME [epoch: 9.8 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08660277521314827		[learning rate: 0.00021056]
	Learning Rate: 0.000210556
	LOSS [training: 0.08660277521314827 | validation: 0.12271669832764502]
	TIME [epoch: 9.8 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08689971326929459		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.08689971326929459 | validation: 0.1401795000217069]
	TIME [epoch: 9.8 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07234378859554166		[learning rate: 0.00020954]
	Learning Rate: 0.000209538
	LOSS [training: 0.07234378859554166 | validation: 0.14872450242812113]
	TIME [epoch: 9.81 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09464673121089506		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.09464673121089506 | validation: 0.18587766073714235]
	TIME [epoch: 9.81 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08964254340573878		[learning rate: 0.00020852]
	Learning Rate: 0.000208525
	LOSS [training: 0.08964254340573878 | validation: 0.1248620184894783]
	TIME [epoch: 9.78 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08048240463920195		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.08048240463920195 | validation: 0.12055389457109911]
	TIME [epoch: 9.79 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09054850008059571		[learning rate: 0.00020752]
	Learning Rate: 0.000207516
	LOSS [training: 0.09054850008059571 | validation: 0.12571307981261196]
	TIME [epoch: 9.82 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08688181458979191		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.08688181458979191 | validation: 0.11582257051500439]
	TIME [epoch: 9.78 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07988723319532451		[learning rate: 0.00020651]
	Learning Rate: 0.000206513
	LOSS [training: 0.07988723319532451 | validation: 0.13177112243134634]
	TIME [epoch: 9.79 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09056703254323356		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.09056703254323356 | validation: 0.11144531925767166]
	TIME [epoch: 9.81 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10879680433472841		[learning rate: 0.00020551]
	Learning Rate: 0.000205514
	LOSS [training: 0.10879680433472841 | validation: 0.12934311783401511]
	TIME [epoch: 9.79 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11649675755907793		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.11649675755907793 | validation: 0.11547892834113128]
	TIME [epoch: 9.79 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09475782457366182		[learning rate: 0.00020452]
	Learning Rate: 0.000204521
	LOSS [training: 0.09475782457366182 | validation: 0.09875030536534567]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1705.pth
	Model improved!!!
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08222698786641874		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.08222698786641874 | validation: 0.10832471570868142]
	TIME [epoch: 9.81 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10420419817530839		[learning rate: 0.00020353]
	Learning Rate: 0.000203531
	LOSS [training: 0.10420419817530839 | validation: 0.13210986601705402]
	TIME [epoch: 9.79 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10371842280415329		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.10371842280415329 | validation: 0.11306475191680086]
	TIME [epoch: 9.78 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09724117848485439		[learning rate: 0.00020255]
	Learning Rate: 0.000202547
	LOSS [training: 0.09724117848485439 | validation: 0.13346122083511314]
	TIME [epoch: 9.8 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08907942550576005		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.08907942550576005 | validation: 0.10784426207575776]
	TIME [epoch: 9.79 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09606514833810523		[learning rate: 0.00020157]
	Learning Rate: 0.000201568
	LOSS [training: 0.09606514833810523 | validation: 0.1761949550039402]
	TIME [epoch: 9.78 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12261316473555783		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.12261316473555783 | validation: 0.16069507754796072]
	TIME [epoch: 9.8 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10444596255633058		[learning rate: 0.00020059]
	Learning Rate: 0.000200593
	LOSS [training: 0.10444596255633058 | validation: 0.1312341673226777]
	TIME [epoch: 9.79 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08394233995725123		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.08394233995725123 | validation: 0.13818243097208235]
	TIME [epoch: 9.78 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0880744820301941		[learning rate: 0.00019962]
	Learning Rate: 0.000199623
	LOSS [training: 0.0880744820301941 | validation: 0.12883851040944463]
	TIME [epoch: 9.79 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09133792615665905		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.09133792615665905 | validation: 0.11022175512486004]
	TIME [epoch: 9.8 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08266253914299178		[learning rate: 0.00019866]
	Learning Rate: 0.000198658
	LOSS [training: 0.08266253914299178 | validation: 0.12843213799708295]
	TIME [epoch: 9.79 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11033742458459735		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.11033742458459735 | validation: 0.11216221895546113]
	TIME [epoch: 9.78 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08888690554941159		[learning rate: 0.0001977]
	Learning Rate: 0.000197697
	LOSS [training: 0.08888690554941159 | validation: 0.11733096879624677]
	TIME [epoch: 9.8 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10962376983895043		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.10962376983895043 | validation: 0.14359814905570215]
	TIME [epoch: 9.79 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11794523915667765		[learning rate: 0.00019674]
	Learning Rate: 0.000196741
	LOSS [training: 0.11794523915667765 | validation: 0.14256297890863107]
	TIME [epoch: 9.8 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12024480160299411		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.12024480160299411 | validation: 0.14209693156768044]
	TIME [epoch: 9.79 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09869203183374078		[learning rate: 0.00019579]
	Learning Rate: 0.00019579
	LOSS [training: 0.09869203183374078 | validation: 0.13132006334196028]
	TIME [epoch: 9.8 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08809223622972696		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.08809223622972696 | validation: 0.11604913052328948]
	TIME [epoch: 9.79 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10346385647355764		[learning rate: 0.00019484]
	Learning Rate: 0.000194843
	LOSS [training: 0.10346385647355764 | validation: 0.10962390733018876]
	TIME [epoch: 9.8 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08646136167017078		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.08646136167017078 | validation: 0.12644867794819215]
	TIME [epoch: 9.81 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08240222197491162		[learning rate: 0.0001939]
	Learning Rate: 0.000193901
	LOSS [training: 0.08240222197491162 | validation: 0.09860459872173806]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1727.pth
	Model improved!!!
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08960817218580688		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.08960817218580688 | validation: 0.10877701388725107]
	TIME [epoch: 9.8 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1140393708540246		[learning rate: 0.00019296]
	Learning Rate: 0.000192963
	LOSS [training: 0.1140393708540246 | validation: 0.13417355867842432]
	TIME [epoch: 9.8 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14090505979024517		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.14090505979024517 | validation: 0.1212565752942937]
	TIME [epoch: 9.79 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1069887795685813		[learning rate: 0.00019203]
	Learning Rate: 0.00019203
	LOSS [training: 0.1069887795685813 | validation: 0.11337438764934835]
	TIME [epoch: 9.8 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10672874592077881		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.10672874592077881 | validation: 0.10391635739013587]
	TIME [epoch: 9.8 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10216720548072503		[learning rate: 0.0001911]
	Learning Rate: 0.000191101
	LOSS [training: 0.10216720548072503 | validation: 0.13150518416009024]
	TIME [epoch: 9.8 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09545889313788855		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.09545889313788855 | validation: 0.11619375484639852]
	TIME [epoch: 9.78 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0861551860381909		[learning rate: 0.00019018]
	Learning Rate: 0.000190177
	LOSS [training: 0.0861551860381909 | validation: 0.11779398641156119]
	TIME [epoch: 9.77 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09682062588471609		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.09682062588471609 | validation: 0.11074520651258833]
	TIME [epoch: 9.81 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11273271250274515		[learning rate: 0.00018926]
	Learning Rate: 0.000189257
	LOSS [training: 0.11273271250274515 | validation: 0.10037614133778529]
	TIME [epoch: 9.79 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10446479759187355		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.10446479759187355 | validation: 0.12106822110436684]
	TIME [epoch: 9.79 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11346310494998271		[learning rate: 0.00018834]
	Learning Rate: 0.000188342
	LOSS [training: 0.11346310494998271 | validation: 0.12255692988457455]
	TIME [epoch: 9.8 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10112309516789261		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.10112309516789261 | validation: 0.12901059326594505]
	TIME [epoch: 9.79 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11365434367524471		[learning rate: 0.00018743]
	Learning Rate: 0.000187431
	LOSS [training: 0.11365434367524471 | validation: 0.16233770012381094]
	TIME [epoch: 9.78 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09919556340811735		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.09919556340811735 | validation: 0.14991339055818245]
	TIME [epoch: 9.78 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10316280366607286		[learning rate: 0.00018652]
	Learning Rate: 0.000186525
	LOSS [training: 0.10316280366607286 | validation: 0.13502340283418543]
	TIME [epoch: 9.8 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09553416050868573		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.09553416050868573 | validation: 0.14396194189342099]
	TIME [epoch: 9.79 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09998370668811477		[learning rate: 0.00018562]
	Learning Rate: 0.000185623
	LOSS [training: 0.09998370668811477 | validation: 0.12535357952331647]
	TIME [epoch: 9.8 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10024954642126012		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.10024954642126012 | validation: 0.12670482770359684]
	TIME [epoch: 9.8 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10420474105593847		[learning rate: 0.00018473]
	Learning Rate: 0.000184725
	LOSS [training: 0.10420474105593847 | validation: 0.1764307826301519]
	TIME [epoch: 9.78 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10379611682017789		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.10379611682017789 | validation: 0.1269337906828977]
	TIME [epoch: 9.78 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08368040456008832		[learning rate: 0.00018383]
	Learning Rate: 0.000183832
	LOSS [training: 0.08368040456008832 | validation: 0.1168021812683689]
	TIME [epoch: 9.79 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0877716024928191		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.0877716024928191 | validation: 0.13254723696855877]
	TIME [epoch: 9.79 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08960593101231737		[learning rate: 0.00018294]
	Learning Rate: 0.000182943
	LOSS [training: 0.08960593101231737 | validation: 0.1093119537368875]
	TIME [epoch: 9.79 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09096536385322898		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.09096536385322898 | validation: 0.119866615792554]
	TIME [epoch: 9.78 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08619434520009736		[learning rate: 0.00018206]
	Learning Rate: 0.000182058
	LOSS [training: 0.08619434520009736 | validation: 0.10022517077234298]
	TIME [epoch: 9.81 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07760460218123044		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.07760460218123044 | validation: 0.1100098086653204]
	TIME [epoch: 9.78 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07969044056996846		[learning rate: 0.00018118]
	Learning Rate: 0.000181178
	LOSS [training: 0.07969044056996846 | validation: 0.11176665900035991]
	TIME [epoch: 9.79 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09056838087311153		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.09056838087311153 | validation: 0.13597930541939082]
	TIME [epoch: 9.8 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0869744829707034		[learning rate: 0.0001803]
	Learning Rate: 0.000180302
	LOSS [training: 0.0869744829707034 | validation: 0.11740044031857369]
	TIME [epoch: 9.8 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08795726188875166		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.08795726188875166 | validation: 0.13321302582943712]
	TIME [epoch: 9.78 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10515265353397063		[learning rate: 0.00017943]
	Learning Rate: 0.00017943
	LOSS [training: 0.10515265353397063 | validation: 0.1361227579975601]
	TIME [epoch: 9.8 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1072809683922388		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.1072809683922388 | validation: 0.11953498400429094]
	TIME [epoch: 9.81 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10485662254666865		[learning rate: 0.00017856]
	Learning Rate: 0.000178562
	LOSS [training: 0.10485662254666865 | validation: 0.14341879460269635]
	TIME [epoch: 9.8 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08622472404929829		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.08622472404929829 | validation: 0.12137142113361246]
	TIME [epoch: 9.79 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09887591188755648		[learning rate: 0.0001777]
	Learning Rate: 0.000177699
	LOSS [training: 0.09887591188755648 | validation: 0.17872613999513817]
	TIME [epoch: 9.81 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11014807198474705		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.11014807198474705 | validation: 0.13650726237156927]
	TIME [epoch: 9.79 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10330225308689314		[learning rate: 0.00017684]
	Learning Rate: 0.000176839
	LOSS [training: 0.10330225308689314 | validation: 0.11787380621052336]
	TIME [epoch: 9.78 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09091048390833065		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.09091048390833065 | validation: 0.10874692442123944]
	TIME [epoch: 9.8 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11094906307442005		[learning rate: 0.00017598]
	Learning Rate: 0.000175984
	LOSS [training: 0.11094906307442005 | validation: 0.13528082607971756]
	TIME [epoch: 9.79 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09907378537927844		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.09907378537927844 | validation: 0.12561531340961535]
	TIME [epoch: 9.79 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09404548997711647		[learning rate: 0.00017513]
	Learning Rate: 0.000175133
	LOSS [training: 0.09404548997711647 | validation: 0.12235167290815659]
	TIME [epoch: 9.79 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10105072508336191		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.10105072508336191 | validation: 0.1561973459138075]
	TIME [epoch: 9.81 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1044930906897289		[learning rate: 0.00017429]
	Learning Rate: 0.000174286
	LOSS [training: 0.1044930906897289 | validation: 0.13993737430693645]
	TIME [epoch: 9.79 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09424038117972097		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.09424038117972097 | validation: 0.12477877162857647]
	TIME [epoch: 9.79 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09287870275958299		[learning rate: 0.00017344]
	Learning Rate: 0.000173443
	LOSS [training: 0.09287870275958299 | validation: 0.10754902103175805]
	TIME [epoch: 9.8 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07817407777375496		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.07817407777375496 | validation: 0.10930635513250804]
	TIME [epoch: 9.79 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08620059152701334		[learning rate: 0.0001726]
	Learning Rate: 0.000172605
	LOSS [training: 0.08620059152701334 | validation: 0.1273036618877828]
	TIME [epoch: 9.78 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08645943234951851		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.08645943234951851 | validation: 0.1252043853360329]
	TIME [epoch: 9.82 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09847237785667542		[learning rate: 0.00017177]
	Learning Rate: 0.00017177
	LOSS [training: 0.09847237785667542 | validation: 0.13586506072965188]
	TIME [epoch: 9.79 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09865874092736222		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.09865874092736222 | validation: 0.1267978961499213]
	TIME [epoch: 9.78 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08253328456199317		[learning rate: 0.00017094]
	Learning Rate: 0.000170939
	LOSS [training: 0.08253328456199317 | validation: 0.1268709902970045]
	TIME [epoch: 9.79 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0816466548362546		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.0816466548362546 | validation: 0.14189044674073042]
	TIME [epoch: 9.82 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09287320047692474		[learning rate: 0.00017011]
	Learning Rate: 0.000170113
	LOSS [training: 0.09287320047692474 | validation: 0.13689679202192637]
	TIME [epoch: 9.79 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10968335213339526		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.10968335213339526 | validation: 0.14625209575957626]
	TIME [epoch: 9.79 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08849283284684409		[learning rate: 0.00016929]
	Learning Rate: 0.00016929
	LOSS [training: 0.08849283284684409 | validation: 0.13404842884712198]
	TIME [epoch: 9.81 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08716450235588075		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.08716450235588075 | validation: 0.1374462218199072]
	TIME [epoch: 9.79 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0976363415328739		[learning rate: 0.00016847]
	Learning Rate: 0.000168471
	LOSS [training: 0.0976363415328739 | validation: 0.13377461483065536]
	TIME [epoch: 9.79 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09562373071751466		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.09562373071751466 | validation: 0.11530913936350272]
	TIME [epoch: 9.8 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0942875522063256		[learning rate: 0.00016766]
	Learning Rate: 0.000167657
	LOSS [training: 0.0942875522063256 | validation: 0.12165523003874622]
	TIME [epoch: 9.79 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08944185557420875		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.08944185557420875 | validation: 0.1346297683545414]
	TIME [epoch: 9.78 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09093889543210787		[learning rate: 0.00016685]
	Learning Rate: 0.000166846
	LOSS [training: 0.09093889543210787 | validation: 0.13459931981744752]
	TIME [epoch: 9.79 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09905270313138334		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.09905270313138334 | validation: 0.1465559951188243]
	TIME [epoch: 9.8 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10559217119873951		[learning rate: 0.00016604]
	Learning Rate: 0.000166039
	LOSS [training: 0.10559217119873951 | validation: 0.1393389632753868]
	TIME [epoch: 9.79 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09448854918697604		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.09448854918697604 | validation: 0.12705864855478596]
	TIME [epoch: 9.8 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1005775459073315		[learning rate: 0.00016524]
	Learning Rate: 0.000165236
	LOSS [training: 0.1005775459073315 | validation: 0.2099875693783956]
	TIME [epoch: 9.8 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11315455395389287		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.11315455395389287 | validation: 0.13879901255126673]
	TIME [epoch: 9.79 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0933406469130411		[learning rate: 0.00016444]
	Learning Rate: 0.000164437
	LOSS [training: 0.0933406469130411 | validation: 0.13026510922987544]
	TIME [epoch: 9.8 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09676555795062607		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.09676555795062607 | validation: 0.14972022608472854]
	TIME [epoch: 9.79 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10742818738467204		[learning rate: 0.00016364]
	Learning Rate: 0.000163642
	LOSS [training: 0.10742818738467204 | validation: 0.15502324910922624]
	TIME [epoch: 9.81 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10037275483146926		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.10037275483146926 | validation: 0.14645233338158659]
	TIME [epoch: 9.79 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10946635217729281		[learning rate: 0.00016285]
	Learning Rate: 0.000162851
	LOSS [training: 0.10946635217729281 | validation: 0.1643937188278074]
	TIME [epoch: 9.79 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11064833472669935		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.11064833472669935 | validation: 0.18682443556933728]
	TIME [epoch: 9.81 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11963712107814453		[learning rate: 0.00016206]
	Learning Rate: 0.000162063
	LOSS [training: 0.11963712107814453 | validation: 0.17395231907025355]
	TIME [epoch: 9.79 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09950637322099791		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.09950637322099791 | validation: 0.13109769487637934]
	TIME [epoch: 9.79 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09270833316422751		[learning rate: 0.00016128]
	Learning Rate: 0.000161279
	LOSS [training: 0.09270833316422751 | validation: 0.14113014557220083]
	TIME [epoch: 9.81 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08932917646162605		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.08932917646162605 | validation: 0.1412862666416333]
	TIME [epoch: 9.8 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0958849477396589		[learning rate: 0.0001605]
	Learning Rate: 0.000160499
	LOSS [training: 0.0958849477396589 | validation: 0.15427335017134192]
	TIME [epoch: 9.8 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13068277226655145		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.13068277226655145 | validation: 0.14055532355158362]
	TIME [epoch: 9.79 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10440695536795119		[learning rate: 0.00015972]
	Learning Rate: 0.000159723
	LOSS [training: 0.10440695536795119 | validation: 0.14153418187212424]
	TIME [epoch: 9.81 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11127079255779729		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.11127079255779729 | validation: 0.18264232949240922]
	TIME [epoch: 9.79 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11801035035806347		[learning rate: 0.00015895]
	Learning Rate: 0.000158951
	LOSS [training: 0.11801035035806347 | validation: 0.12490544808968433]
	TIME [epoch: 9.8 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09750621408969977		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.09750621408969977 | validation: 0.10946541710397659]
	TIME [epoch: 9.82 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09154886928428867		[learning rate: 0.00015818]
	Learning Rate: 0.000158182
	LOSS [training: 0.09154886928428867 | validation: 0.12702031832964383]
	TIME [epoch: 9.8 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08157458933092601		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.08157458933092601 | validation: 0.12055669433905215]
	TIME [epoch: 9.8 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08953363292355385		[learning rate: 0.00015742]
	Learning Rate: 0.000157417
	LOSS [training: 0.08953363292355385 | validation: 0.12857764325912055]
	TIME [epoch: 9.81 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10749101174445189		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.10749101174445189 | validation: 0.12553590425707303]
	TIME [epoch: 9.8 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0997047499270882		[learning rate: 0.00015666]
	Learning Rate: 0.000156656
	LOSS [training: 0.0997047499270882 | validation: 0.14185560585059923]
	TIME [epoch: 9.79 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09902119330559638		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.09902119330559638 | validation: 0.1406750740297002]
	TIME [epoch: 9.79 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09599594383334747		[learning rate: 0.0001559]
	Learning Rate: 0.000155899
	LOSS [training: 0.09599594383334747 | validation: 0.1552220236970651]
	TIME [epoch: 9.81 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1221308902646715		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.1221308902646715 | validation: 0.12376128411527011]
	TIME [epoch: 9.8 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0884322388977431		[learning rate: 0.00015514]
	Learning Rate: 0.000155145
	LOSS [training: 0.0884322388977431 | validation: 0.11632335222682479]
	TIME [epoch: 9.8 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08760643123949403		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.08760643123949403 | validation: 0.13718549378066514]
	TIME [epoch: 9.81 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08972308204166836		[learning rate: 0.00015439]
	Learning Rate: 0.000154394
	LOSS [training: 0.08972308204166836 | validation: 0.13068902912401323]
	TIME [epoch: 9.79 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09413397985595413		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.09413397985595413 | validation: 0.12274294109710004]
	TIME [epoch: 9.79 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08985632446207581		[learning rate: 0.00015365]
	Learning Rate: 0.000153648
	LOSS [training: 0.08985632446207581 | validation: 0.12390031641755307]
	TIME [epoch: 9.79 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08310158401936057		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.08310158401936057 | validation: 0.10683777899526024]
	TIME [epoch: 9.81 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08474382042805965		[learning rate: 0.0001529]
	Learning Rate: 0.000152905
	LOSS [training: 0.08474382042805965 | validation: 0.12942360516250215]
	TIME [epoch: 9.8 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0796862322851196		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.0796862322851196 | validation: 0.10744289404863182]
	TIME [epoch: 9.79 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08404598382342131		[learning rate: 0.00015217]
	Learning Rate: 0.000152165
	LOSS [training: 0.08404598382342131 | validation: 0.11759852301944372]
	TIME [epoch: 9.79 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08135854108806531		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.08135854108806531 | validation: 0.143376740681057]
	TIME [epoch: 9.78 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09915254082953885		[learning rate: 0.00015143]
	Learning Rate: 0.00015143
	LOSS [training: 0.09915254082953885 | validation: 0.1357531073395188]
	TIME [epoch: 9.78 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08989066166686219		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.08989066166686219 | validation: 0.1384549433576678]
	TIME [epoch: 9.8 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09516892475926483		[learning rate: 0.0001507]
	Learning Rate: 0.000150697
	LOSS [training: 0.09516892475926483 | validation: 0.11836695562910887]
	TIME [epoch: 9.81 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10163309869646639		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.10163309869646639 | validation: 0.13780381704521996]
	TIME [epoch: 9.8 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08863570796327247		[learning rate: 0.00014997]
	Learning Rate: 0.000149968
	LOSS [training: 0.08863570796327247 | validation: 0.10032900708456081]
	TIME [epoch: 9.79 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08914752478946546		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.08914752478946546 | validation: 0.11080711097141911]
	TIME [epoch: 9.81 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0920380878371363		[learning rate: 0.00014924]
	Learning Rate: 0.000149243
	LOSS [training: 0.0920380878371363 | validation: 0.10262911986896281]
	TIME [epoch: 9.78 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09075316484903097		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.09075316484903097 | validation: 0.13454093455236157]
	TIME [epoch: 9.78 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09539148800243578		[learning rate: 0.00014852]
	Learning Rate: 0.000148522
	LOSS [training: 0.09539148800243578 | validation: 0.12440272216983064]
	TIME [epoch: 9.8 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09750372788445852		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.09750372788445852 | validation: 0.12369720497145277]
	TIME [epoch: 9.8 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09199527397713052		[learning rate: 0.0001478]
	Learning Rate: 0.000147803
	LOSS [training: 0.09199527397713052 | validation: 0.11057162997080104]
	TIME [epoch: 9.8 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09614185305162935		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.09614185305162935 | validation: 0.14268798205423316]
	TIME [epoch: 9.8 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09237836208661232		[learning rate: 0.00014709]
	Learning Rate: 0.000147089
	LOSS [training: 0.09237836208661232 | validation: 0.1273894605312177]
	TIME [epoch: 9.81 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08622045153456513		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.08622045153456513 | validation: 0.12629050079198756]
	TIME [epoch: 9.79 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08444971331955123		[learning rate: 0.00014638]
	Learning Rate: 0.000146377
	LOSS [training: 0.08444971331955123 | validation: 0.112331697477892]
	TIME [epoch: 9.79 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08886472041831427		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.08886472041831427 | validation: 0.1128539232117781]
	TIME [epoch: 9.8 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08433429217533801		[learning rate: 0.00014567]
	Learning Rate: 0.000145669
	LOSS [training: 0.08433429217533801 | validation: 0.10002487219212114]
	TIME [epoch: 9.79 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0871804449453827		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.0871804449453827 | validation: 0.1135142568014674]
	TIME [epoch: 9.78 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08879843522530094		[learning rate: 0.00014497]
	Learning Rate: 0.000144965
	LOSS [training: 0.08879843522530094 | validation: 0.10540377929224118]
	TIME [epoch: 9.81 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08557306097930453		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.08557306097930453 | validation: 0.10657754351172952]
	TIME [epoch: 9.8 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08565182082824409		[learning rate: 0.00014426]
	Learning Rate: 0.000144264
	LOSS [training: 0.08565182082824409 | validation: 0.11751715625168899]
	TIME [epoch: 9.79 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0913231317719998		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.0913231317719998 | validation: 0.13602857683343061]
	TIME [epoch: 9.8 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09539689967779724		[learning rate: 0.00014357]
	Learning Rate: 0.000143566
	LOSS [training: 0.09539689967779724 | validation: 0.13457433331899607]
	TIME [epoch: 9.8 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0908013899920646		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.0908013899920646 | validation: 0.14005115592303213]
	TIME [epoch: 9.79 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08827071855153115		[learning rate: 0.00014287]
	Learning Rate: 0.000142872
	LOSS [training: 0.08827071855153115 | validation: 0.14101079429727156]
	TIME [epoch: 9.79 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09177927652614266		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.09177927652614266 | validation: 0.13951576625800308]
	TIME [epoch: 9.82 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08637336876131535		[learning rate: 0.00014218]
	Learning Rate: 0.000142181
	LOSS [training: 0.08637336876131535 | validation: 0.11004532610135222]
	TIME [epoch: 9.78 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08207338952698774		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.08207338952698774 | validation: 0.10954954614713731]
	TIME [epoch: 9.79 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08937799508034198		[learning rate: 0.00014149]
	Learning Rate: 0.000141494
	LOSS [training: 0.08937799508034198 | validation: 0.12612166846327838]
	TIME [epoch: 9.8 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09329320688429239		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.09329320688429239 | validation: 0.11283286486170291]
	TIME [epoch: 9.79 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09636185180322183		[learning rate: 0.00014081]
	Learning Rate: 0.000140809
	LOSS [training: 0.09636185180322183 | validation: 0.11973452292068366]
	TIME [epoch: 9.8 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11887341797763369		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.11887341797763369 | validation: 0.11758540914640687]
	TIME [epoch: 9.78 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10623893739369197		[learning rate: 0.00014013]
	Learning Rate: 0.000140128
	LOSS [training: 0.10623893739369197 | validation: 0.10823771178993113]
	TIME [epoch: 9.8 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08444171642845935		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.08444171642845935 | validation: 0.10916873120904946]
	TIME [epoch: 9.81 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08779386057888985		[learning rate: 0.00013945]
	Learning Rate: 0.000139451
	LOSS [training: 0.08779386057888985 | validation: 0.11114218263569876]
	TIME [epoch: 9.79 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07726719347098715		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.07726719347098715 | validation: 0.12567700208778845]
	TIME [epoch: 9.8 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07674944198636892		[learning rate: 0.00013878]
	Learning Rate: 0.000138776
	LOSS [training: 0.07674944198636892 | validation: 0.11344432899754049]
	TIME [epoch: 9.79 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0763938820740722		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.0763938820740722 | validation: 0.11766140964315604]
	TIME [epoch: 9.78 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08375970798251495		[learning rate: 0.00013811]
	Learning Rate: 0.000138105
	LOSS [training: 0.08375970798251495 | validation: 0.10506065002797858]
	TIME [epoch: 9.8 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08149528038231421		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.08149528038231421 | validation: 0.09763656257227867]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1868.pth
	Model improved!!!
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08601250204782385		[learning rate: 0.00013744]
	Learning Rate: 0.000137437
	LOSS [training: 0.08601250204782385 | validation: 0.1002062858106334]
	TIME [epoch: 9.8 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09400713771042796		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.09400713771042796 | validation: 0.10521380385521971]
	TIME [epoch: 9.8 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11964024629901995		[learning rate: 0.00013677]
	Learning Rate: 0.000136773
	LOSS [training: 0.11964024629901995 | validation: 0.1443533058689957]
	TIME [epoch: 9.81 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1291103088819149		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.1291103088819149 | validation: 0.11529042321225909]
	TIME [epoch: 9.8 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09901077744678595		[learning rate: 0.00013611]
	Learning Rate: 0.000136111
	LOSS [training: 0.09901077744678595 | validation: 0.11144639100630264]
	TIME [epoch: 9.79 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10306233247964806		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.10306233247964806 | validation: 0.1175357748180103]
	TIME [epoch: 9.81 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09080121123180276		[learning rate: 0.00013545]
	Learning Rate: 0.000135453
	LOSS [training: 0.09080121123180276 | validation: 0.13481869866188628]
	TIME [epoch: 9.8 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10030015777503538		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.10030015777503538 | validation: 0.13612838824790235]
	TIME [epoch: 9.8 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09252888514049781		[learning rate: 0.0001348]
	Learning Rate: 0.000134798
	LOSS [training: 0.09252888514049781 | validation: 0.12724777078160193]
	TIME [epoch: 9.8 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09494771686970944		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.09494771686970944 | validation: 0.14139057579325645]
	TIME [epoch: 9.8 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10292997592382487		[learning rate: 0.00013415]
	Learning Rate: 0.000134146
	LOSS [training: 0.10292997592382487 | validation: 0.12190288853104843]
	TIME [epoch: 9.79 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09262737178335856		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.09262737178335856 | validation: 0.11344313834340997]
	TIME [epoch: 9.79 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.086713152731094		[learning rate: 0.0001335]
	Learning Rate: 0.000133498
	LOSS [training: 0.086713152731094 | validation: 0.10879590347109332]
	TIME [epoch: 9.81 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09923301664925506		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.09923301664925506 | validation: 0.11692533855910782]
	TIME [epoch: 9.79 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09462780536933944		[learning rate: 0.00013285]
	Learning Rate: 0.000132852
	LOSS [training: 0.09462780536933944 | validation: 0.10557819942800134]
	TIME [epoch: 9.79 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09238114397914146		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.09238114397914146 | validation: 0.11019146688061962]
	TIME [epoch: 9.79 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1074266523741205		[learning rate: 0.00013221]
	Learning Rate: 0.00013221
	LOSS [training: 0.1074266523741205 | validation: 0.13301357379312406]
	TIME [epoch: 9.79 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09512721066571977		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.09512721066571977 | validation: 0.11808543592154244]
	TIME [epoch: 9.78 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0888959158705239		[learning rate: 0.00013157]
	Learning Rate: 0.00013157
	LOSS [training: 0.0888959158705239 | validation: 0.10160091508443714]
	TIME [epoch: 9.8 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09325525520665848		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.09325525520665848 | validation: 0.09725411618038463]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1888.pth
	Model improved!!!
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09483323579136879		[learning rate: 0.00013093]
	Learning Rate: 0.000130934
	LOSS [training: 0.09483323579136879 | validation: 0.10445366099802612]
	TIME [epoch: 9.79 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11511848573961499		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.11511848573961499 | validation: 0.09884010241479807]
	TIME [epoch: 9.79 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10143970476449711		[learning rate: 0.0001303]
	Learning Rate: 0.000130301
	LOSS [training: 0.10143970476449711 | validation: 0.09879642504010308]
	TIME [epoch: 9.81 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10786598468271494		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.10786598468271494 | validation: 0.11566367110196799]
	TIME [epoch: 9.79 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10855215466417907		[learning rate: 0.00012967]
	Learning Rate: 0.000129671
	LOSS [training: 0.10855215466417907 | validation: 0.10200306142104074]
	TIME [epoch: 9.8 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10506375238513217		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.10506375238513217 | validation: 0.11117842173615779]
	TIME [epoch: 9.81 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09682734321474255		[learning rate: 0.00012904]
	Learning Rate: 0.000129044
	LOSS [training: 0.09682734321474255 | validation: 0.11928685098705173]
	TIME [epoch: 9.8 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09424233706146484		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.09424233706146484 | validation: 0.11990918282554575]
	TIME [epoch: 9.78 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08860955903350629		[learning rate: 0.00012842]
	Learning Rate: 0.00012842
	LOSS [training: 0.08860955903350629 | validation: 0.1255631775216188]
	TIME [epoch: 9.79 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08935812911265133		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.08935812911265133 | validation: 0.09524562704274374]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1898.pth
	Model improved!!!
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0951189977580148		[learning rate: 0.0001278]
	Learning Rate: 0.000127799
	LOSS [training: 0.0951189977580148 | validation: 0.10153296139859812]
	TIME [epoch: 9.78 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09980308183158416		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.09980308183158416 | validation: 0.11395681015781292]
	TIME [epoch: 9.79 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08839069606604959		[learning rate: 0.00012718]
	Learning Rate: 0.000127181
	LOSS [training: 0.08839069606604959 | validation: 0.11600080968962116]
	TIME [epoch: 9.8 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10306006180080722		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.10306006180080722 | validation: 0.13494986935758913]
	TIME [epoch: 9.78 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10577128401020494		[learning rate: 0.00012657]
	Learning Rate: 0.000126566
	LOSS [training: 0.10577128401020494 | validation: 0.13438811811944487]
	TIME [epoch: 9.79 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10382059195598074		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.10382059195598074 | validation: 0.12118586966725954]
	TIME [epoch: 9.8 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1022762003857957		[learning rate: 0.00012595]
	Learning Rate: 0.000125954
	LOSS [training: 0.1022762003857957 | validation: 0.11575934645229208]
	TIME [epoch: 9.78 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10846123118055702		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.10846123118055702 | validation: 0.1177253151099925]
	TIME [epoch: 9.79 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1061151664166721		[learning rate: 0.00012534]
	Learning Rate: 0.000125345
	LOSS [training: 0.1061151664166721 | validation: 0.11303969108846461]
	TIME [epoch: 9.78 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11270477612016586		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.11270477612016586 | validation: 0.13290054957922018]
	TIME [epoch: 9.8 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0902781005498701		[learning rate: 0.00012474]
	Learning Rate: 0.000124738
	LOSS [training: 0.0902781005498701 | validation: 0.11742270428715382]
	TIME [epoch: 9.78 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09023145578746192		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.09023145578746192 | validation: 0.09752973886558358]
	TIME [epoch: 9.78 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09305420886445179		[learning rate: 0.00012414]
	Learning Rate: 0.000124135
	LOSS [training: 0.09305420886445179 | validation: 0.1151891761808693]
	TIME [epoch: 9.8 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10205649383900144		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.10205649383900144 | validation: 0.11304194568434259]
	TIME [epoch: 9.78 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10535760613666681		[learning rate: 0.00012353]
	Learning Rate: 0.000123535
	LOSS [training: 0.10535760613666681 | validation: 0.12301665607035073]
	TIME [epoch: 9.79 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12056989390471422		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.12056989390471422 | validation: 0.11533287995887587]
	TIME [epoch: 9.8 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10469068486112394		[learning rate: 0.00012294]
	Learning Rate: 0.000122937
	LOSS [training: 0.10469068486112394 | validation: 0.10668494218104968]
	TIME [epoch: 9.79 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09907475375595295		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.09907475375595295 | validation: 0.13899801467491435]
	TIME [epoch: 9.78 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10517098444334194		[learning rate: 0.00012234]
	Learning Rate: 0.000122343
	LOSS [training: 0.10517098444334194 | validation: 0.14890433476147175]
	TIME [epoch: 9.8 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1000505397338414		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.1000505397338414 | validation: 0.12023106040792556]
	TIME [epoch: 9.82 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10125813879280728		[learning rate: 0.00012175]
	Learning Rate: 0.000121751
	LOSS [training: 0.10125813879280728 | validation: 0.12852563445978576]
	TIME [epoch: 9.81 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08909092682725006		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.08909092682725006 | validation: 0.1478992407244223]
	TIME [epoch: 9.79 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09855027447279824		[learning rate: 0.00012116]
	Learning Rate: 0.000121163
	LOSS [training: 0.09855027447279824 | validation: 0.1296404496360837]
	TIME [epoch: 9.81 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0905123254346731		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.0905123254346731 | validation: 0.14964877020023998]
	TIME [epoch: 9.79 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08482930415956806		[learning rate: 0.00012058]
	Learning Rate: 0.000120577
	LOSS [training: 0.08482930415956806 | validation: 0.13393366358849557]
	TIME [epoch: 9.8 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09447067501610276		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.09447067501610276 | validation: 0.10256410522766995]
	TIME [epoch: 9.8 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08450275322648274		[learning rate: 0.00011999]
	Learning Rate: 0.000119994
	LOSS [training: 0.08450275322648274 | validation: 0.13740213950121194]
	TIME [epoch: 9.8 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09957025611310746		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.09957025611310746 | validation: 0.1380506136502506]
	TIME [epoch: 9.79 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10328520084427287		[learning rate: 0.00011941]
	Learning Rate: 0.000119413
	LOSS [training: 0.10328520084427287 | validation: 0.14682057561540146]
	TIME [epoch: 9.8 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0898011782474319		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.0898011782474319 | validation: 0.1338547635816711]
	TIME [epoch: 9.81 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08201664104116138		[learning rate: 0.00011884]
	Learning Rate: 0.000118836
	LOSS [training: 0.08201664104116138 | validation: 0.13002818103255906]
	TIME [epoch: 9.79 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08214256566065652		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.08214256566065652 | validation: 0.112147248492025]
	TIME [epoch: 9.79 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08378515023152637		[learning rate: 0.00011826]
	Learning Rate: 0.000118261
	LOSS [training: 0.08378515023152637 | validation: 0.10808280036091457]
	TIME [epoch: 9.81 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08017926412698079		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.08017926412698079 | validation: 0.13195733701383777]
	TIME [epoch: 9.8 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08089803941623067		[learning rate: 0.00011769]
	Learning Rate: 0.000117689
	LOSS [training: 0.08089803941623067 | validation: 0.13394374332043846]
	TIME [epoch: 9.8 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08539884409070161		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.08539884409070161 | validation: 0.11982718307852425]
	TIME [epoch: 9.79 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07939825762210229		[learning rate: 0.00011712]
	Learning Rate: 0.00011712
	LOSS [training: 0.07939825762210229 | validation: 0.13033329243758754]
	TIME [epoch: 9.81 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08064528995242679		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.08064528995242679 | validation: 0.1294798430360078]
	TIME [epoch: 9.79 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08658510776113368		[learning rate: 0.00011655]
	Learning Rate: 0.000116554
	LOSS [training: 0.08658510776113368 | validation: 0.11560404441493699]
	TIME [epoch: 9.79 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08926510872408641		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.08926510872408641 | validation: 0.11399601886560555]
	TIME [epoch: 9.81 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07673116339936586		[learning rate: 0.00011599]
	Learning Rate: 0.00011599
	LOSS [training: 0.07673116339936586 | validation: 0.10777651926954693]
	TIME [epoch: 9.79 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0792584963602279		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.0792584963602279 | validation: 0.11662726488130001]
	TIME [epoch: 9.79 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09086261709738457		[learning rate: 0.00011543]
	Learning Rate: 0.000115429
	LOSS [training: 0.09086261709738457 | validation: 0.1481162469855348]
	TIME [epoch: 9.81 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10459112703250133		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.10459112703250133 | validation: 0.10500285624935594]
	TIME [epoch: 9.81 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08604940117997038		[learning rate: 0.00011487]
	Learning Rate: 0.000114871
	LOSS [training: 0.08604940117997038 | validation: 0.113754940894087]
	TIME [epoch: 9.79 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08240356547853422		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.08240356547853422 | validation: 0.1091106489664652]
	TIME [epoch: 9.78 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10095733971112328		[learning rate: 0.00011432]
	Learning Rate: 0.000114316
	LOSS [training: 0.10095733971112328 | validation: 0.12518381895555428]
	TIME [epoch: 9.83 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09357328704618158		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.09357328704618158 | validation: 0.09147135198040086]
	TIME [epoch: 9.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r5_20240219_183144/states/model_tr_study5_1946.pth
	Model improved!!!
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08557757045761817		[learning rate: 0.00011376]
	Learning Rate: 0.000113763
	LOSS [training: 0.08557757045761817 | validation: 0.10953243867391571]
	TIME [epoch: 9.81 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08574482919899032		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.08574482919899032 | validation: 0.1218541089480308]
	TIME [epoch: 9.83 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08222562741852801		[learning rate: 0.00011321]
	Learning Rate: 0.000113213
	LOSS [training: 0.08222562741852801 | validation: 0.09609461929705558]
	TIME [epoch: 9.81 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0857579137597061		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.0857579137597061 | validation: 0.12155777577774156]
	TIME [epoch: 9.81 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08074580872430631		[learning rate: 0.00011267]
	Learning Rate: 0.000112665
	LOSS [training: 0.08074580872430631 | validation: 0.11320057616342201]
	TIME [epoch: 9.82 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08583566057287953		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.08583566057287953 | validation: 0.13198866004637863]
	TIME [epoch: 9.79 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07747258578669329		[learning rate: 0.00011212]
	Learning Rate: 0.00011212
	LOSS [training: 0.07747258578669329 | validation: 0.1227685083237072]
	TIME [epoch: 9.81 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08078471031706566		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.08078471031706566 | validation: 0.11769629035651909]
	TIME [epoch: 9.8 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0785331616200306		[learning rate: 0.00011158]
	Learning Rate: 0.000111578
	LOSS [training: 0.0785331616200306 | validation: 0.10548622360720673]
	TIME [epoch: 9.81 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08120745625090249		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.08120745625090249 | validation: 0.11109019809821741]
	TIME [epoch: 9.79 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07909413312609508		[learning rate: 0.00011104]
	Learning Rate: 0.000111039
	LOSS [training: 0.07909413312609508 | validation: 0.09956952801847962]
	TIME [epoch: 9.78 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0798149503178702		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.0798149503178702 | validation: 0.12785525294497133]
	TIME [epoch: 9.8 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08380096009553194		[learning rate: 0.0001105]
	Learning Rate: 0.000110502
	LOSS [training: 0.08380096009553194 | validation: 0.115074990383548]
	TIME [epoch: 9.79 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06891005884450793		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.06891005884450793 | validation: 0.1275029587469863]
	TIME [epoch: 9.79 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07903528098139176		[learning rate: 0.00010997]
	Learning Rate: 0.000109967
	LOSS [training: 0.07903528098139176 | validation: 0.13133459335158232]
	TIME [epoch: 9.8 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08607395159402834		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.08607395159402834 | validation: 0.14040071846656585]
	TIME [epoch: 9.8 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09091462809005106		[learning rate: 0.00010944]
	Learning Rate: 0.000109435
	LOSS [training: 0.09091462809005106 | validation: 0.14872713893854728]
	TIME [epoch: 9.79 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0923567924266386		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.0923567924266386 | validation: 0.11497240482890213]
	TIME [epoch: 9.79 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08423661035192309		[learning rate: 0.00010891]
	Learning Rate: 0.000108906
	LOSS [training: 0.08423661035192309 | validation: 0.12588868128356928]
	TIME [epoch: 9.8 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0827435380519443		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.0827435380519443 | validation: 0.11953150176583238]
	TIME [epoch: 9.79 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08723424478842953		[learning rate: 0.00010838]
	Learning Rate: 0.00010838
	LOSS [training: 0.08723424478842953 | validation: 0.11969846463707733]
	TIME [epoch: 9.79 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08711470785735906		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.08711470785735906 | validation: 0.11794292790647241]
	TIME [epoch: 9.8 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08486591034998836		[learning rate: 0.00010786]
	Learning Rate: 0.000107855
	LOSS [training: 0.08486591034998836 | validation: 0.12208588185593466]
	TIME [epoch: 9.79 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07852350990192605		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.07852350990192605 | validation: 0.12122034296563612]
	TIME [epoch: 9.79 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08233786818052535		[learning rate: 0.00010733]
	Learning Rate: 0.000107334
	LOSS [training: 0.08233786818052535 | validation: 0.10127543559322152]
	TIME [epoch: 9.8 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09571814759042994		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.09571814759042994 | validation: 0.1161821377062026]
	TIME [epoch: 9.8 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09359055344736175		[learning rate: 0.00010681]
	Learning Rate: 0.000106815
	LOSS [training: 0.09359055344736175 | validation: 0.1379210990673938]
	TIME [epoch: 9.78 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0931692913182391		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.0931692913182391 | validation: 0.11098611170279293]
	TIME [epoch: 9.79 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1029747639310538		[learning rate: 0.0001063]
	Learning Rate: 0.000106298
	LOSS [training: 0.1029747639310538 | validation: 0.15586077315279892]
	TIME [epoch: 9.8 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10654766771025348		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.10654766771025348 | validation: 0.14851748093389824]
	TIME [epoch: 9.79 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09443128799572474		[learning rate: 0.00010578]
	Learning Rate: 0.000105784
	LOSS [training: 0.09443128799572474 | validation: 0.14674652788560946]
	TIME [epoch: 9.78 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09612312155964545		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.09612312155964545 | validation: 0.13096154255728765]
	TIME [epoch: 9.81 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08512347349705301		[learning rate: 0.00010527]
	Learning Rate: 0.000105273
	LOSS [training: 0.08512347349705301 | validation: 0.1282592957806924]
	TIME [epoch: 9.79 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07729681719627257		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.07729681719627257 | validation: 0.11511600092674933]
	TIME [epoch: 9.79 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08985694505834507		[learning rate: 0.00010476]
	Learning Rate: 0.000104764
	LOSS [training: 0.08985694505834507 | validation: 0.12944154072175934]
	TIME [epoch: 9.78 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0790082193549927		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.0790082193549927 | validation: 0.12139985442968637]
	TIME [epoch: 9.8 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08205459795891562		[learning rate: 0.00010426]
	Learning Rate: 0.000104257
	LOSS [training: 0.08205459795891562 | validation: 0.11857171981370275]
	TIME [epoch: 9.79 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08099309721675965		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.08099309721675965 | validation: 0.13531690084520648]
	TIME [epoch: 9.79 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07893485515557833		[learning rate: 0.00010375]
	Learning Rate: 0.000103753
	LOSS [training: 0.07893485515557833 | validation: 0.14353793445267785]
	TIME [epoch: 9.8 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09367040334728494		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.09367040334728494 | validation: 0.11767041887595586]
	TIME [epoch: 9.79 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07901085613940569		[learning rate: 0.00010325]
	Learning Rate: 0.000103251
	LOSS [training: 0.07901085613940569 | validation: 0.12963358032825872]
	TIME [epoch: 9.79 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08610347255199914		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.08610347255199914 | validation: 0.1335647103531983]
	TIME [epoch: 9.79 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09597391659460759		[learning rate: 0.00010275]
	Learning Rate: 0.000102752
	LOSS [training: 0.09597391659460759 | validation: 0.1583612026630649]
	TIME [epoch: 9.8 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09025005267615978		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.09025005267615978 | validation: 0.1282384233890184]
	TIME [epoch: 9.79 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08496929512307787		[learning rate: 0.00010225]
	Learning Rate: 0.000102255
	LOSS [training: 0.08496929512307787 | validation: 0.10508803351200627]
	TIME [epoch: 9.79 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0826239072647014		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.0826239072647014 | validation: 0.1058560513598178]
	TIME [epoch: 9.8 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0893361970286896		[learning rate: 0.00010176]
	Learning Rate: 0.00010176
	LOSS [training: 0.0893361970286896 | validation: 0.10672730089643453]
	TIME [epoch: 9.79 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08722132349154789		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.08722132349154789 | validation: 0.10817250612830101]
	TIME [epoch: 9.8 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08200438947480622		[learning rate: 0.00010127]
	Learning Rate: 0.000101268
	LOSS [training: 0.08200438947480622 | validation: 0.13442189701213778]
	TIME [epoch: 9.82 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08858797249122867		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.08858797249122867 | validation: 0.12431468892779649]
	TIME [epoch: 9.79 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08616620949492408		[learning rate: 0.00010078]
	Learning Rate: 0.000100779
	LOSS [training: 0.08616620949492408 | validation: 0.1254028358086101]
	TIME [epoch: 9.8 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08620185931631967		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.08620185931631967 | validation: 0.11745476267722758]
	TIME [epoch: 9.8 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07641805751642139		[learning rate: 0.00010029]
	Learning Rate: 0.000100291
	LOSS [training: 0.07641805751642139 | validation: 0.12218781019324684]
	TIME [epoch: 9.81 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07877754139321788		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.07877754139321788 | validation: 0.11745502303847058]
	TIME [epoch: 9.8 sec]
Finished training in 19742.155 seconds.
