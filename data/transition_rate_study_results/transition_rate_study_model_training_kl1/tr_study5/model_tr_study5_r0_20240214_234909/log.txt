Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r0', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2404332600

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 5/5] avg loss: 10.864333655174903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.864333655174903 | validation: 11.14837845569471]
	TIME [epoch: 49.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 5/5] avg loss: 10.499947635730319		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.499947635730319 | validation: 10.98285310158679]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 5/5] avg loss: 9.55178933765818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.55178933765818 | validation: 10.559301440541713]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 5/5] avg loss: 9.170194609630016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.170194609630016 | validation: 10.025760014936834]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 5/5] avg loss: 8.5363132165764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.5363132165764 | validation: 9.938824274111955]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 5/5] avg loss: 8.29786502160194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.29786502160194 | validation: 10.618222418133815]
	TIME [epoch: 10.3 sec]
EPOCH 7/500:
	Training over batches...
		[batch 5/5] avg loss: 10.51643122677763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.51643122677763 | validation: 9.970830829431087]
	TIME [epoch: 10.3 sec]
EPOCH 8/500:
	Training over batches...
		[batch 5/5] avg loss: 7.876000277004584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.876000277004584 | validation: 9.848416659032198]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 5/5] avg loss: 7.763797371565414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.763797371565414 | validation: 8.864580778726278]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 5/5] avg loss: 7.061029238467917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.061029238467917 | validation: 9.117837343389207]
	TIME [epoch: 10.3 sec]
EPOCH 11/500:
	Training over batches...
		[batch 5/5] avg loss: 6.873380215872679		[learning rate: 0.0099625]
	Learning Rate: 0.00996248
	LOSS [training: 6.873380215872679 | validation: 9.34157599932593]
	TIME [epoch: 10.3 sec]
EPOCH 12/500:
	Training over batches...
		[batch 5/5] avg loss: 6.856537453300602		[learning rate: 0.0099158]
	Learning Rate: 0.00991577
	LOSS [training: 6.856537453300602 | validation: 8.393838955776435]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 5/5] avg loss: 6.798062835101066		[learning rate: 0.0098693]
	Learning Rate: 0.00986928
	LOSS [training: 6.798062835101066 | validation: 8.017214072794957]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 5/5] avg loss: 6.22814180826736		[learning rate: 0.009823]
	Learning Rate: 0.00982302
	LOSS [training: 6.22814180826736 | validation: 7.767191015984096]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 5/5] avg loss: 6.246248768753122		[learning rate: 0.009777]
	Learning Rate: 0.00977696
	LOSS [training: 6.246248768753122 | validation: 7.542932246851523]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 5/5] avg loss: 5.9921890332982		[learning rate: 0.0097311]
	Learning Rate: 0.00973113
	LOSS [training: 5.9921890332982 | validation: 7.379095742008154]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 5/5] avg loss: 5.925105432377332		[learning rate: 0.0096855]
	Learning Rate: 0.00968551
	LOSS [training: 5.925105432377332 | validation: 7.225578209935593]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 5/5] avg loss: 5.823301580708099		[learning rate: 0.0096401]
	Learning Rate: 0.0096401
	LOSS [training: 5.823301580708099 | validation: 7.556676316203047]
	TIME [epoch: 10.3 sec]
EPOCH 19/500:
	Training over batches...
		[batch 5/5] avg loss: 5.568624807579367		[learning rate: 0.0095949]
	Learning Rate: 0.00959491
	LOSS [training: 5.568624807579367 | validation: 7.456878918992518]
	TIME [epoch: 10.3 sec]
EPOCH 20/500:
	Training over batches...
		[batch 5/5] avg loss: 5.285503776578481		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 5.285503776578481 | validation: 6.587883819818667]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 5/5] avg loss: 5.261642885490181		[learning rate: 0.0095052]
	Learning Rate: 0.00950515
	LOSS [training: 5.261642885490181 | validation: 6.503401164209541]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 5/5] avg loss: 5.217581324793781		[learning rate: 0.0094606]
	Learning Rate: 0.00946059
	LOSS [training: 5.217581324793781 | validation: 7.191598248860769]
	TIME [epoch: 10.3 sec]
EPOCH 23/500:
	Training over batches...
		[batch 5/5] avg loss: 4.966050862819477		[learning rate: 0.0094162]
	Learning Rate: 0.00941624
	LOSS [training: 4.966050862819477 | validation: 6.368356687769049]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 5/5] avg loss: 5.0642025133131146		[learning rate: 0.0093721]
	Learning Rate: 0.0093721
	LOSS [training: 5.0642025133131146 | validation: 6.348543974625302]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 5/5] avg loss: 4.862893055029931		[learning rate: 0.0093282]
	Learning Rate: 0.00932816
	LOSS [training: 4.862893055029931 | validation: 7.4665906131350175]
	TIME [epoch: 10.3 sec]
EPOCH 26/500:
	Training over batches...
		[batch 5/5] avg loss: 4.910399282764542		[learning rate: 0.0092844]
	Learning Rate: 0.00928443
	LOSS [training: 4.910399282764542 | validation: 6.751525160010212]
	TIME [epoch: 10.3 sec]
EPOCH 27/500:
	Training over batches...
		[batch 5/5] avg loss: 4.900964785323211		[learning rate: 0.0092409]
	Learning Rate: 0.0092409
	LOSS [training: 4.900964785323211 | validation: 6.361954806737359]
	TIME [epoch: 10.3 sec]
EPOCH 28/500:
	Training over batches...
		[batch 5/5] avg loss: 5.1903488697406095		[learning rate: 0.0091976]
	Learning Rate: 0.00919758
	LOSS [training: 5.1903488697406095 | validation: 6.905107743526899]
	TIME [epoch: 10.3 sec]
EPOCH 29/500:
	Training over batches...
		[batch 5/5] avg loss: 4.770391555795892		[learning rate: 0.0091545]
	Learning Rate: 0.00915446
	LOSS [training: 4.770391555795892 | validation: 6.272890105999895]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 5/5] avg loss: 4.653460123777728		[learning rate: 0.0091115]
	Learning Rate: 0.00911154
	LOSS [training: 4.653460123777728 | validation: 6.829342545074016]
	TIME [epoch: 10.3 sec]
EPOCH 31/500:
	Training over batches...
		[batch 5/5] avg loss: 4.782224109402465		[learning rate: 0.0090688]
	Learning Rate: 0.00906882
	LOSS [training: 4.782224109402465 | validation: 6.277900314819572]
	TIME [epoch: 10.3 sec]
EPOCH 32/500:
	Training over batches...
		[batch 5/5] avg loss: 4.574984195089307		[learning rate: 0.0090263]
	Learning Rate: 0.00902631
	LOSS [training: 4.574984195089307 | validation: 6.1559146994187905]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 5/5] avg loss: 4.690077215389644		[learning rate: 0.008984]
	Learning Rate: 0.00898399
	LOSS [training: 4.690077215389644 | validation: 6.746474969533822]
	TIME [epoch: 10.3 sec]
EPOCH 34/500:
	Training over batches...
		[batch 5/5] avg loss: 4.656880362376632		[learning rate: 0.0089419]
	Learning Rate: 0.00894187
	LOSS [training: 4.656880362376632 | validation: 6.4271178271810445]
	TIME [epoch: 10.3 sec]
EPOCH 35/500:
	Training over batches...
		[batch 5/5] avg loss: 4.507336630079638		[learning rate: 0.0089]
	Learning Rate: 0.00889995
	LOSS [training: 4.507336630079638 | validation: 7.529701161581588]
	TIME [epoch: 10.3 sec]
EPOCH 36/500:
	Training over batches...
		[batch 5/5] avg loss: 4.718414508130278		[learning rate: 0.0088582]
	Learning Rate: 0.00885823
	LOSS [training: 4.718414508130278 | validation: 6.58687072217785]
	TIME [epoch: 10.3 sec]
EPOCH 37/500:
	Training over batches...
		[batch 5/5] avg loss: 4.634883771439637		[learning rate: 0.0088167]
	Learning Rate: 0.0088167
	LOSS [training: 4.634883771439637 | validation: 6.929523219598067]
	TIME [epoch: 10.3 sec]
EPOCH 38/500:
	Training over batches...
		[batch 5/5] avg loss: 4.701277308346479		[learning rate: 0.0087754]
	Learning Rate: 0.00877537
	LOSS [training: 4.701277308346479 | validation: 6.477995272615954]
	TIME [epoch: 10.3 sec]
EPOCH 39/500:
	Training over batches...
		[batch 5/5] avg loss: 4.628839689625988		[learning rate: 0.0087342]
	Learning Rate: 0.00873423
	LOSS [training: 4.628839689625988 | validation: 6.863735223312761]
	TIME [epoch: 10.3 sec]
EPOCH 40/500:
	Training over batches...
		[batch 5/5] avg loss: 4.948264735997835		[learning rate: 0.0086933]
	Learning Rate: 0.00869328
	LOSS [training: 4.948264735997835 | validation: 6.1427298418948935]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 5/5] avg loss: 4.4291313429396615		[learning rate: 0.0086525]
	Learning Rate: 0.00865253
	LOSS [training: 4.4291313429396615 | validation: 6.97551611031404]
	TIME [epoch: 10.3 sec]
EPOCH 42/500:
	Training over batches...
		[batch 5/5] avg loss: 4.5102123455293865		[learning rate: 0.008612]
	Learning Rate: 0.00861196
	LOSS [training: 4.5102123455293865 | validation: 6.195103727052943]
	TIME [epoch: 10.3 sec]
EPOCH 43/500:
	Training over batches...
		[batch 5/5] avg loss: 4.5724638108158775		[learning rate: 0.0085716]
	Learning Rate: 0.00857159
	LOSS [training: 4.5724638108158775 | validation: 6.038003556867867]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 5/5] avg loss: 4.332372895519463		[learning rate: 0.0085314]
	Learning Rate: 0.0085314
	LOSS [training: 4.332372895519463 | validation: 6.243160690724143]
	TIME [epoch: 10.3 sec]
EPOCH 45/500:
	Training over batches...
		[batch 5/5] avg loss: 4.437053743438815		[learning rate: 0.0084914]
	Learning Rate: 0.00849141
	LOSS [training: 4.437053743438815 | validation: 6.216002413892282]
	TIME [epoch: 10.3 sec]
EPOCH 46/500:
	Training over batches...
		[batch 5/5] avg loss: 4.382937901738247		[learning rate: 0.0084516]
	Learning Rate: 0.0084516
	LOSS [training: 4.382937901738247 | validation: 6.041211951872266]
	TIME [epoch: 10.3 sec]
EPOCH 47/500:
	Training over batches...
		[batch 5/5] avg loss: 4.389667150517695		[learning rate: 0.008412]
	Learning Rate: 0.00841197
	LOSS [training: 4.389667150517695 | validation: 6.248893848577195]
	TIME [epoch: 10.3 sec]
EPOCH 48/500:
	Training over batches...
		[batch 5/5] avg loss: 4.364546422110405		[learning rate: 0.0083725]
	Learning Rate: 0.00837254
	LOSS [training: 4.364546422110405 | validation: 6.191714716449967]
	TIME [epoch: 10.3 sec]
EPOCH 49/500:
	Training over batches...
		[batch 5/5] avg loss: 4.52288939023707		[learning rate: 0.0083333]
	Learning Rate: 0.00833329
	LOSS [training: 4.52288939023707 | validation: 5.943936742414271]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 5/5] avg loss: 4.174945835970684		[learning rate: 0.0082942]
	Learning Rate: 0.00829422
	LOSS [training: 4.174945835970684 | validation: 6.803972413981221]
	TIME [epoch: 10.3 sec]
EPOCH 51/500:
	Training over batches...
		[batch 5/5] avg loss: 4.619655545391195		[learning rate: 0.0082553]
	Learning Rate: 0.00825533
	LOSS [training: 4.619655545391195 | validation: 6.155913291806075]
	TIME [epoch: 10.3 sec]
EPOCH 52/500:
	Training over batches...
		[batch 5/5] avg loss: 4.383519553378217		[learning rate: 0.0082166]
	Learning Rate: 0.00821663
	LOSS [training: 4.383519553378217 | validation: 5.984698960925485]
	TIME [epoch: 10.3 sec]
EPOCH 53/500:
	Training over batches...
		[batch 5/5] avg loss: 4.180043258797541		[learning rate: 0.0081781]
	Learning Rate: 0.00817811
	LOSS [training: 4.180043258797541 | validation: 6.050813116028524]
	TIME [epoch: 10.3 sec]
EPOCH 54/500:
	Training over batches...
		[batch 5/5] avg loss: 4.197999909347191		[learning rate: 0.0081398]
	Learning Rate: 0.00813977
	LOSS [training: 4.197999909347191 | validation: 6.198734121557822]
	TIME [epoch: 10.3 sec]
EPOCH 55/500:
	Training over batches...
		[batch 5/5] avg loss: 4.281736101645167		[learning rate: 0.0081016]
	Learning Rate: 0.00810161
	LOSS [training: 4.281736101645167 | validation: 6.240367897391061]
	TIME [epoch: 10.3 sec]
EPOCH 56/500:
	Training over batches...
		[batch 5/5] avg loss: 4.174374729975114		[learning rate: 0.0080636]
	Learning Rate: 0.00806363
	LOSS [training: 4.174374729975114 | validation: 5.711657439635044]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 5/5] avg loss: 4.27534463674011		[learning rate: 0.0080258]
	Learning Rate: 0.00802583
	LOSS [training: 4.27534463674011 | validation: 5.83269610067701]
	TIME [epoch: 10.3 sec]
EPOCH 58/500:
	Training over batches...
		[batch 5/5] avg loss: 4.1400488132482325		[learning rate: 0.0079882]
	Learning Rate: 0.0079882
	LOSS [training: 4.1400488132482325 | validation: 5.659571505065753]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 5/5] avg loss: 4.410587809754821		[learning rate: 0.0079508]
	Learning Rate: 0.00795075
	LOSS [training: 4.410587809754821 | validation: 6.931624148109355]
	TIME [epoch: 10.3 sec]
EPOCH 60/500:
	Training over batches...
		[batch 5/5] avg loss: 5.557655804831578		[learning rate: 0.0079135]
	Learning Rate: 0.00791348
	LOSS [training: 5.557655804831578 | validation: 7.904624614222852]
	TIME [epoch: 10.3 sec]
EPOCH 61/500:
	Training over batches...
		[batch 5/5] avg loss: 5.542707099951261		[learning rate: 0.0078764]
	Learning Rate: 0.00787638
	LOSS [training: 5.542707099951261 | validation: 6.320539718644698]
	TIME [epoch: 10.3 sec]
EPOCH 62/500:
	Training over batches...
		[batch 5/5] avg loss: 4.571506385084896		[learning rate: 0.0078395]
	Learning Rate: 0.00783945
	LOSS [training: 4.571506385084896 | validation: 6.1318329570914445]
	TIME [epoch: 10.3 sec]
EPOCH 63/500:
	Training over batches...
		[batch 5/5] avg loss: 4.1030560710302755		[learning rate: 0.0078027]
	Learning Rate: 0.0078027
	LOSS [training: 4.1030560710302755 | validation: 5.785955880978016]
	TIME [epoch: 10.3 sec]
EPOCH 64/500:
	Training over batches...
		[batch 5/5] avg loss: 4.038597785698608		[learning rate: 0.0077661]
	Learning Rate: 0.00776612
	LOSS [training: 4.038597785698608 | validation: 6.163078739488741]
	TIME [epoch: 10.3 sec]
EPOCH 65/500:
	Training over batches...
		[batch 5/5] avg loss: 4.1221055701048055		[learning rate: 0.0077297]
	Learning Rate: 0.00772971
	LOSS [training: 4.1221055701048055 | validation: 5.696384394310441]
	TIME [epoch: 10.3 sec]
EPOCH 66/500:
	Training over batches...
		[batch 5/5] avg loss: 4.165029811591163		[learning rate: 0.0076935]
	Learning Rate: 0.00769347
	LOSS [training: 4.165029811591163 | validation: 5.797106299319755]
	TIME [epoch: 10.3 sec]
EPOCH 67/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9529556571428004		[learning rate: 0.0076574]
	Learning Rate: 0.0076574
	LOSS [training: 3.9529556571428004 | validation: 5.78616397472792]
	TIME [epoch: 10.3 sec]
EPOCH 68/500:
	Training over batches...
		[batch 5/5] avg loss: 4.10785153420547		[learning rate: 0.0076215]
	Learning Rate: 0.00762151
	LOSS [training: 4.10785153420547 | validation: 5.709455772565401]
	TIME [epoch: 10.3 sec]
EPOCH 69/500:
	Training over batches...
		[batch 5/5] avg loss: 4.891566947427376		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 4.891566947427376 | validation: 6.211785353762982]
	TIME [epoch: 10.3 sec]
EPOCH 70/500:
	Training over batches...
		[batch 5/5] avg loss: 4.68505833101003		[learning rate: 0.0075502]
	Learning Rate: 0.00755021
	LOSS [training: 4.68505833101003 | validation: 6.399726786734475]
	TIME [epoch: 10.3 sec]
EPOCH 71/500:
	Training over batches...
		[batch 5/5] avg loss: 4.444648447709906		[learning rate: 0.0075148]
	Learning Rate: 0.00751482
	LOSS [training: 4.444648447709906 | validation: 5.560205726556776]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 5/5] avg loss: 3.948734891703986		[learning rate: 0.0074796]
	Learning Rate: 0.00747959
	LOSS [training: 3.948734891703986 | validation: 5.679613435875957]
	TIME [epoch: 10.3 sec]
EPOCH 73/500:
	Training over batches...
		[batch 5/5] avg loss: 3.958146739408104		[learning rate: 0.0074445]
	Learning Rate: 0.00744452
	LOSS [training: 3.958146739408104 | validation: 5.802034453834445]
	TIME [epoch: 10.3 sec]
EPOCH 74/500:
	Training over batches...
		[batch 5/5] avg loss: 4.01026226849682		[learning rate: 0.0074096]
	Learning Rate: 0.00740962
	LOSS [training: 4.01026226849682 | validation: 5.887849727864863]
	TIME [epoch: 10.3 sec]
EPOCH 75/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8739888870011647		[learning rate: 0.0073749]
	Learning Rate: 0.00737488
	LOSS [training: 3.8739888870011647 | validation: 5.5266918535091865]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9774333207553867		[learning rate: 0.0073403]
	Learning Rate: 0.00734031
	LOSS [training: 3.9774333207553867 | validation: 5.683637546658133]
	TIME [epoch: 10.3 sec]
EPOCH 77/500:
	Training over batches...
		[batch 5/5] avg loss: 3.825646256010605		[learning rate: 0.0073059]
	Learning Rate: 0.00730589
	LOSS [training: 3.825646256010605 | validation: 5.519115591884468]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_77.pth
	Model improved!!!
EPOCH 78/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9747116554425146		[learning rate: 0.0072716]
	Learning Rate: 0.00727164
	LOSS [training: 3.9747116554425146 | validation: 6.213575702786418]
	TIME [epoch: 10.3 sec]
EPOCH 79/500:
	Training over batches...
		[batch 5/5] avg loss: 3.864218759672601		[learning rate: 0.0072376]
	Learning Rate: 0.00723755
	LOSS [training: 3.864218759672601 | validation: 5.484616763463682]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 5/5] avg loss: 3.881702867418921		[learning rate: 0.0072036]
	Learning Rate: 0.00720362
	LOSS [training: 3.881702867418921 | validation: 5.560918606171574]
	TIME [epoch: 10.3 sec]
EPOCH 81/500:
	Training over batches...
		[batch 5/5] avg loss: 3.80222359089469		[learning rate: 0.0071699]
	Learning Rate: 0.00716985
	LOSS [training: 3.80222359089469 | validation: 5.5415907534495705]
	TIME [epoch: 10.3 sec]
EPOCH 82/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9999899383382678		[learning rate: 0.0071362]
	Learning Rate: 0.00713624
	LOSS [training: 3.9999899383382678 | validation: 5.488399147591836]
	TIME [epoch: 10.3 sec]
EPOCH 83/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6903113810268353		[learning rate: 0.0071028]
	Learning Rate: 0.00710278
	LOSS [training: 3.6903113810268353 | validation: 5.596052399258863]
	TIME [epoch: 10.3 sec]
EPOCH 84/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6839685850911033		[learning rate: 0.0070695]
	Learning Rate: 0.00706948
	LOSS [training: 3.6839685850911033 | validation: 5.814483421408793]
	TIME [epoch: 10.3 sec]
EPOCH 85/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8987308468488435		[learning rate: 0.0070363]
	Learning Rate: 0.00703634
	LOSS [training: 3.8987308468488435 | validation: 5.770832293526737]
	TIME [epoch: 10.3 sec]
EPOCH 86/500:
	Training over batches...
		[batch 5/5] avg loss: 3.833456976805435		[learning rate: 0.0070034]
	Learning Rate: 0.00700335
	LOSS [training: 3.833456976805435 | validation: 5.528459456386436]
	TIME [epoch: 10.3 sec]
EPOCH 87/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6853432721104378		[learning rate: 0.0069705]
	Learning Rate: 0.00697052
	LOSS [training: 3.6853432721104378 | validation: 6.055927334678124]
	TIME [epoch: 10.3 sec]
EPOCH 88/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7992922869921784		[learning rate: 0.0069378]
	Learning Rate: 0.00693784
	LOSS [training: 3.7992922869921784 | validation: 5.735978720751807]
	TIME [epoch: 10.3 sec]
EPOCH 89/500:
	Training over batches...
		[batch 5/5] avg loss: 3.80172488880349		[learning rate: 0.0069053]
	Learning Rate: 0.00690532
	LOSS [training: 3.80172488880349 | validation: 5.446016578338409]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_89.pth
	Model improved!!!
EPOCH 90/500:
	Training over batches...
		[batch 5/5] avg loss: 4.217062544146325		[learning rate: 0.0068729]
	Learning Rate: 0.00687294
	LOSS [training: 4.217062544146325 | validation: 5.958975376892152]
	TIME [epoch: 10.3 sec]
EPOCH 91/500:
	Training over batches...
		[batch 5/5] avg loss: 4.208905096612821		[learning rate: 0.0068407]
	Learning Rate: 0.00684072
	LOSS [training: 4.208905096612821 | validation: 5.65897275211948]
	TIME [epoch: 10.3 sec]
EPOCH 92/500:
	Training over batches...
		[batch 5/5] avg loss: 3.979620314204432		[learning rate: 0.0068087]
	Learning Rate: 0.00680865
	LOSS [training: 3.979620314204432 | validation: 6.273824403019337]
	TIME [epoch: 10.3 sec]
EPOCH 93/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9459355834568592		[learning rate: 0.0067767]
	Learning Rate: 0.00677673
	LOSS [training: 3.9459355834568592 | validation: 5.946827440869932]
	TIME [epoch: 10.3 sec]
EPOCH 94/500:
	Training over batches...
		[batch 5/5] avg loss: 3.814695860328716		[learning rate: 0.006745]
	Learning Rate: 0.00674496
	LOSS [training: 3.814695860328716 | validation: 5.418697221948719]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_94.pth
	Model improved!!!
EPOCH 95/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6657615032328614		[learning rate: 0.0067133]
	Learning Rate: 0.00671334
	LOSS [training: 3.6657615032328614 | validation: 5.627116742396533]
	TIME [epoch: 10.3 sec]
EPOCH 96/500:
	Training over batches...
		[batch 5/5] avg loss: 3.854347947927824		[learning rate: 0.0066819]
	Learning Rate: 0.00668187
	LOSS [training: 3.854347947927824 | validation: 5.3903343037037645]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_96.pth
	Model improved!!!
EPOCH 97/500:
	Training over batches...
		[batch 5/5] avg loss: 3.596223843540286		[learning rate: 0.0066505]
	Learning Rate: 0.00665054
	LOSS [training: 3.596223843540286 | validation: 6.50141471881836]
	TIME [epoch: 10.3 sec]
EPOCH 98/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9091193851241632		[learning rate: 0.0066194]
	Learning Rate: 0.00661936
	LOSS [training: 3.9091193851241632 | validation: 5.368151790404367]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_98.pth
	Model improved!!!
EPOCH 99/500:
	Training over batches...
		[batch 5/5] avg loss: 3.739873976505348		[learning rate: 0.0065883]
	Learning Rate: 0.00658833
	LOSS [training: 3.739873976505348 | validation: 5.56180798813211]
	TIME [epoch: 10.3 sec]
EPOCH 100/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7200589885711204		[learning rate: 0.0065574]
	Learning Rate: 0.00655745
	LOSS [training: 3.7200589885711204 | validation: 5.357416586925406]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_100.pth
	Model improved!!!
EPOCH 101/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6229410403207027		[learning rate: 0.0065267]
	Learning Rate: 0.0065267
	LOSS [training: 3.6229410403207027 | validation: 5.308884945965153]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_101.pth
	Model improved!!!
EPOCH 102/500:
	Training over batches...
		[batch 5/5] avg loss: 3.701128106830356		[learning rate: 0.0064961]
	Learning Rate: 0.0064961
	LOSS [training: 3.701128106830356 | validation: 5.4809881169020676]
	TIME [epoch: 10.3 sec]
EPOCH 103/500:
	Training over batches...
		[batch 5/5] avg loss: 3.652756926694481		[learning rate: 0.0064657]
	Learning Rate: 0.00646565
	LOSS [training: 3.652756926694481 | validation: 5.5904100044327105]
	TIME [epoch: 10.3 sec]
EPOCH 104/500:
	Training over batches...
		[batch 5/5] avg loss: 4.032033402186283		[learning rate: 0.0064353]
	Learning Rate: 0.00643534
	LOSS [training: 4.032033402186283 | validation: 6.109983827798292]
	TIME [epoch: 10.3 sec]
EPOCH 105/500:
	Training over batches...
		[batch 5/5] avg loss: 3.877544624285066		[learning rate: 0.0064052]
	Learning Rate: 0.00640517
	LOSS [training: 3.877544624285066 | validation: 5.339318556292114]
	TIME [epoch: 10.3 sec]
EPOCH 106/500:
	Training over batches...
		[batch 5/5] avg loss: 3.764018250001439		[learning rate: 0.0063751]
	Learning Rate: 0.00637514
	LOSS [training: 3.764018250001439 | validation: 6.636730761446199]
	TIME [epoch: 10.3 sec]
EPOCH 107/500:
	Training over batches...
		[batch 5/5] avg loss: 3.95176201234233		[learning rate: 0.0063453]
	Learning Rate: 0.00634525
	LOSS [training: 3.95176201234233 | validation: 5.4565541581632075]
	TIME [epoch: 10.3 sec]
EPOCH 108/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8702516291453803		[learning rate: 0.0063155]
	Learning Rate: 0.00631551
	LOSS [training: 3.8702516291453803 | validation: 5.935581548746027]
	TIME [epoch: 10.3 sec]
EPOCH 109/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9430254288575		[learning rate: 0.0062859]
	Learning Rate: 0.0062859
	LOSS [training: 3.9430254288575 | validation: 5.704203185325322]
	TIME [epoch: 10.3 sec]
EPOCH 110/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9509420644877586		[learning rate: 0.0062564]
	Learning Rate: 0.00625643
	LOSS [training: 3.9509420644877586 | validation: 5.523556240113192]
	TIME [epoch: 10.3 sec]
EPOCH 111/500:
	Training over batches...
		[batch 5/5] avg loss: 3.824793488529381		[learning rate: 0.0062271]
	Learning Rate: 0.0062271
	LOSS [training: 3.824793488529381 | validation: 5.37372599303028]
	TIME [epoch: 10.3 sec]
EPOCH 112/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6935440401711737		[learning rate: 0.0061979]
	Learning Rate: 0.0061979
	LOSS [training: 3.6935440401711737 | validation: 5.234301114405865]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_112.pth
	Model improved!!!
EPOCH 113/500:
	Training over batches...
		[batch 5/5] avg loss: 3.464715514695242		[learning rate: 0.0061688]
	Learning Rate: 0.00616885
	LOSS [training: 3.464715514695242 | validation: 5.372904765793577]
	TIME [epoch: 10.3 sec]
EPOCH 114/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6149974362998565		[learning rate: 0.0061399]
	Learning Rate: 0.00613993
	LOSS [training: 3.6149974362998565 | validation: 5.516421670996388]
	TIME [epoch: 10.3 sec]
EPOCH 115/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6920839695702057		[learning rate: 0.0061111]
	Learning Rate: 0.00611114
	LOSS [training: 3.6920839695702057 | validation: 5.277532735437979]
	TIME [epoch: 10.3 sec]
EPOCH 116/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7935888710346313		[learning rate: 0.0060825]
	Learning Rate: 0.00608249
	LOSS [training: 3.7935888710346313 | validation: 5.484194603264832]
	TIME [epoch: 10.3 sec]
EPOCH 117/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6690759604887107		[learning rate: 0.006054]
	Learning Rate: 0.00605398
	LOSS [training: 3.6690759604887107 | validation: 5.410080674697217]
	TIME [epoch: 10.3 sec]
EPOCH 118/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5040872786808435		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 3.5040872786808435 | validation: 5.370648695864595]
	TIME [epoch: 10.3 sec]
EPOCH 119/500:
	Training over batches...
		[batch 5/5] avg loss: 3.513381035909729		[learning rate: 0.0059973]
	Learning Rate: 0.00599735
	LOSS [training: 3.513381035909729 | validation: 5.432442333470174]
	TIME [epoch: 10.3 sec]
EPOCH 120/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5970619211995007		[learning rate: 0.0059692]
	Learning Rate: 0.00596923
	LOSS [training: 3.5970619211995007 | validation: 5.246151223047392]
	TIME [epoch: 10.3 sec]
EPOCH 121/500:
	Training over batches...
		[batch 5/5] avg loss: 3.636953396654455		[learning rate: 0.0059412]
	Learning Rate: 0.00594125
	LOSS [training: 3.636953396654455 | validation: 5.340958727733116]
	TIME [epoch: 10.3 sec]
EPOCH 122/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5987502132600127		[learning rate: 0.0059134]
	Learning Rate: 0.00591339
	LOSS [training: 3.5987502132600127 | validation: 5.950929774152221]
	TIME [epoch: 10.3 sec]
EPOCH 123/500:
	Training over batches...
		[batch 5/5] avg loss: 4.027728600530841		[learning rate: 0.0058857]
	Learning Rate: 0.00588567
	LOSS [training: 4.027728600530841 | validation: 5.4744653568601835]
	TIME [epoch: 10.3 sec]
EPOCH 124/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6105432439579617		[learning rate: 0.0058581]
	Learning Rate: 0.00585808
	LOSS [training: 3.6105432439579617 | validation: 5.351697158742807]
	TIME [epoch: 10.3 sec]
EPOCH 125/500:
	Training over batches...
		[batch 5/5] avg loss: 3.39932115579188		[learning rate: 0.0058306]
	Learning Rate: 0.00583061
	LOSS [training: 3.39932115579188 | validation: 5.8179156838919655]
	TIME [epoch: 10.3 sec]
EPOCH 126/500:
	Training over batches...
		[batch 5/5] avg loss: 4.05100975829843		[learning rate: 0.0058033]
	Learning Rate: 0.00580328
	LOSS [training: 4.05100975829843 | validation: 5.240951266142733]
	TIME [epoch: 10.3 sec]
EPOCH 127/500:
	Training over batches...
		[batch 5/5] avg loss: 3.993711755809501		[learning rate: 0.0057761]
	Learning Rate: 0.00577607
	LOSS [training: 3.993711755809501 | validation: 5.4578606232454305]
	TIME [epoch: 10.3 sec]
EPOCH 128/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5542484087781103		[learning rate: 0.005749]
	Learning Rate: 0.00574899
	LOSS [training: 3.5542484087781103 | validation: 5.356113648947178]
	TIME [epoch: 10.3 sec]
EPOCH 129/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8826083273100425		[learning rate: 0.005722]
	Learning Rate: 0.00572204
	LOSS [training: 3.8826083273100425 | validation: 5.273893625320848]
	TIME [epoch: 10.3 sec]
EPOCH 130/500:
	Training over batches...
		[batch 5/5] avg loss: 3.428004321382145		[learning rate: 0.0056952]
	Learning Rate: 0.00569522
	LOSS [training: 3.428004321382145 | validation: 5.544457397467173]
	TIME [epoch: 10.3 sec]
EPOCH 131/500:
	Training over batches...
		[batch 5/5] avg loss: 3.456290894288587		[learning rate: 0.0056685]
	Learning Rate: 0.00566852
	LOSS [training: 3.456290894288587 | validation: 5.635749177045902]
	TIME [epoch: 10.3 sec]
EPOCH 132/500:
	Training over batches...
		[batch 5/5] avg loss: 3.621593327983804		[learning rate: 0.0056419]
	Learning Rate: 0.00564194
	LOSS [training: 3.621593327983804 | validation: 5.403135069449578]
	TIME [epoch: 10.3 sec]
EPOCH 133/500:
	Training over batches...
		[batch 5/5] avg loss: 3.465825773923617		[learning rate: 0.0056155]
	Learning Rate: 0.00561549
	LOSS [training: 3.465825773923617 | validation: 5.609338960297261]
	TIME [epoch: 10.3 sec]
EPOCH 134/500:
	Training over batches...
		[batch 5/5] avg loss: 3.657910432474322		[learning rate: 0.0055892]
	Learning Rate: 0.00558916
	LOSS [training: 3.657910432474322 | validation: 5.384969632089748]
	TIME [epoch: 10.3 sec]
EPOCH 135/500:
	Training over batches...
		[batch 5/5] avg loss: 3.567049134959769		[learning rate: 0.005563]
	Learning Rate: 0.00556296
	LOSS [training: 3.567049134959769 | validation: 5.756415056420399]
	TIME [epoch: 10.3 sec]
EPOCH 136/500:
	Training over batches...
		[batch 5/5] avg loss: 3.677514319414801		[learning rate: 0.0055369]
	Learning Rate: 0.00553688
	LOSS [training: 3.677514319414801 | validation: 5.211470765330825]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_136.pth
	Model improved!!!
EPOCH 137/500:
	Training over batches...
		[batch 5/5] avg loss: 3.602276378835301		[learning rate: 0.0055109]
	Learning Rate: 0.00551092
	LOSS [training: 3.602276378835301 | validation: 5.864609437030859]
	TIME [epoch: 10.3 sec]
EPOCH 138/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6221576744221293		[learning rate: 0.0054851]
	Learning Rate: 0.00548509
	LOSS [training: 3.6221576744221293 | validation: 5.240065635325711]
	TIME [epoch: 10.3 sec]
EPOCH 139/500:
	Training over batches...
		[batch 5/5] avg loss: 3.35991500237092		[learning rate: 0.0054594]
	Learning Rate: 0.00545937
	LOSS [training: 3.35991500237092 | validation: 5.394300107129545]
	TIME [epoch: 10.3 sec]
EPOCH 140/500:
	Training over batches...
		[batch 5/5] avg loss: 3.459706564839179		[learning rate: 0.0054338]
	Learning Rate: 0.00543378
	LOSS [training: 3.459706564839179 | validation: 6.062751840240985]
	TIME [epoch: 10.3 sec]
EPOCH 141/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7938707412657813		[learning rate: 0.0054083]
	Learning Rate: 0.00540831
	LOSS [training: 3.7938707412657813 | validation: 5.212944169841899]
	TIME [epoch: 10.3 sec]
EPOCH 142/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3171194513870907		[learning rate: 0.005383]
	Learning Rate: 0.00538295
	LOSS [training: 3.3171194513870907 | validation: 5.334838436811716]
	TIME [epoch: 10.3 sec]
EPOCH 143/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3740723179719225		[learning rate: 0.0053577]
	Learning Rate: 0.00535771
	LOSS [training: 3.3740723179719225 | validation: 5.409816321805647]
	TIME [epoch: 10.3 sec]
EPOCH 144/500:
	Training over batches...
		[batch 5/5] avg loss: 3.351570998188555		[learning rate: 0.0053326]
	Learning Rate: 0.0053326
	LOSS [training: 3.351570998188555 | validation: 5.0891548287852695]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_144.pth
	Model improved!!!
EPOCH 145/500:
	Training over batches...
		[batch 5/5] avg loss: 3.40691091409632		[learning rate: 0.0053076]
	Learning Rate: 0.0053076
	LOSS [training: 3.40691091409632 | validation: 5.439154283475725]
	TIME [epoch: 10.3 sec]
EPOCH 146/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4244662041358955		[learning rate: 0.0052827]
	Learning Rate: 0.00528271
	LOSS [training: 3.4244662041358955 | validation: 5.398471334646561]
	TIME [epoch: 10.3 sec]
EPOCH 147/500:
	Training over batches...
		[batch 5/5] avg loss: 3.493936051170297		[learning rate: 0.0052579]
	Learning Rate: 0.00525795
	LOSS [training: 3.493936051170297 | validation: 5.129874130428909]
	TIME [epoch: 10.3 sec]
EPOCH 148/500:
	Training over batches...
		[batch 5/5] avg loss: 3.477231487814854		[learning rate: 0.0052333]
	Learning Rate: 0.0052333
	LOSS [training: 3.477231487814854 | validation: 5.072543248620654]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_148.pth
	Model improved!!!
EPOCH 149/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5866226592406454		[learning rate: 0.0052088]
	Learning Rate: 0.00520876
	LOSS [training: 3.5866226592406454 | validation: 5.217749740789476]
	TIME [epoch: 10.3 sec]
EPOCH 150/500:
	Training over batches...
		[batch 5/5] avg loss: 3.403245077675318		[learning rate: 0.0051843]
	Learning Rate: 0.00518434
	LOSS [training: 3.403245077675318 | validation: 5.142023969211417]
	TIME [epoch: 10.3 sec]
EPOCH 151/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6781976308437505		[learning rate: 0.00516]
	Learning Rate: 0.00516004
	LOSS [training: 3.6781976308437505 | validation: 5.309817071387159]
	TIME [epoch: 10.3 sec]
EPOCH 152/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6149553793462887		[learning rate: 0.0051358]
	Learning Rate: 0.00513585
	LOSS [training: 3.6149553793462887 | validation: 5.14552727431116]
	TIME [epoch: 10.3 sec]
EPOCH 153/500:
	Training over batches...
		[batch 5/5] avg loss: 3.434271957560857		[learning rate: 0.0051118]
	Learning Rate: 0.00511177
	LOSS [training: 3.434271957560857 | validation: 5.274627589523631]
	TIME [epoch: 10.3 sec]
EPOCH 154/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4711106687428206		[learning rate: 0.0050878]
	Learning Rate: 0.00508781
	LOSS [training: 3.4711106687428206 | validation: 5.643043430207727]
	TIME [epoch: 10.3 sec]
EPOCH 155/500:
	Training over batches...
		[batch 5/5] avg loss: 3.544249926845148		[learning rate: 0.005064]
	Learning Rate: 0.00506395
	LOSS [training: 3.544249926845148 | validation: 5.339231813571819]
	TIME [epoch: 10.3 sec]
EPOCH 156/500:
	Training over batches...
		[batch 5/5] avg loss: 3.397682487903377		[learning rate: 0.0050402]
	Learning Rate: 0.00504021
	LOSS [training: 3.397682487903377 | validation: 5.066209771411494]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_156.pth
	Model improved!!!
EPOCH 157/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3435604671611103		[learning rate: 0.0050166]
	Learning Rate: 0.00501658
	LOSS [training: 3.3435604671611103 | validation: 5.161184914303113]
	TIME [epoch: 10.3 sec]
EPOCH 158/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4908400324848317		[learning rate: 0.0049931]
	Learning Rate: 0.00499307
	LOSS [training: 3.4908400324848317 | validation: 5.077310437200468]
	TIME [epoch: 10.3 sec]
EPOCH 159/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3524854878157706		[learning rate: 0.0049697]
	Learning Rate: 0.00496966
	LOSS [training: 3.3524854878157706 | validation: 5.134325611346157]
	TIME [epoch: 10.3 sec]
EPOCH 160/500:
	Training over batches...
		[batch 5/5] avg loss: 3.393920320546665		[learning rate: 0.0049464]
	Learning Rate: 0.00494636
	LOSS [training: 3.393920320546665 | validation: 5.258193874849952]
	TIME [epoch: 10.3 sec]
EPOCH 161/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3341916305375237		[learning rate: 0.0049232]
	Learning Rate: 0.00492317
	LOSS [training: 3.3341916305375237 | validation: 6.332316039546302]
	TIME [epoch: 10.3 sec]
EPOCH 162/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9367542032648615		[learning rate: 0.0049001]
	Learning Rate: 0.00490009
	LOSS [training: 3.9367542032648615 | validation: 5.111920250201027]
	TIME [epoch: 10.3 sec]
EPOCH 163/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4730911191431275		[learning rate: 0.0048771]
	Learning Rate: 0.00487712
	LOSS [training: 3.4730911191431275 | validation: 5.049738954826927]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_163.pth
	Model improved!!!
EPOCH 164/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3248931413227822		[learning rate: 0.0048543]
	Learning Rate: 0.00485425
	LOSS [training: 3.3248931413227822 | validation: 5.1242064852749705]
	TIME [epoch: 10.3 sec]
EPOCH 165/500:
	Training over batches...
		[batch 5/5] avg loss: 3.378726358276939		[learning rate: 0.0048315]
	Learning Rate: 0.0048315
	LOSS [training: 3.378726358276939 | validation: 5.306095376040826]
	TIME [epoch: 10.3 sec]
EPOCH 166/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4454092040870625		[learning rate: 0.0048088]
	Learning Rate: 0.00480885
	LOSS [training: 3.4454092040870625 | validation: 5.113254170773114]
	TIME [epoch: 10.3 sec]
EPOCH 167/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3670258087818326		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 3.3670258087818326 | validation: 5.098243809541669]
	TIME [epoch: 10.3 sec]
EPOCH 168/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4664189280159095		[learning rate: 0.0047639]
	Learning Rate: 0.00476386
	LOSS [training: 3.4664189280159095 | validation: 5.232979796135852]
	TIME [epoch: 10.3 sec]
EPOCH 169/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4444215867676355		[learning rate: 0.0047415]
	Learning Rate: 0.00474153
	LOSS [training: 3.4444215867676355 | validation: 5.26960937311207]
	TIME [epoch: 10.3 sec]
EPOCH 170/500:
	Training over batches...
		[batch 5/5] avg loss: 3.473971515869837		[learning rate: 0.0047193]
	Learning Rate: 0.0047193
	LOSS [training: 3.473971515869837 | validation: 5.693823645245056]
	TIME [epoch: 10.3 sec]
EPOCH 171/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4665925872655734		[learning rate: 0.0046972]
	Learning Rate: 0.00469718
	LOSS [training: 3.4665925872655734 | validation: 6.0877924500424925]
	TIME [epoch: 10.3 sec]
EPOCH 172/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3747725759870177		[learning rate: 0.0046752]
	Learning Rate: 0.00467515
	LOSS [training: 3.3747725759870177 | validation: 5.144967167114071]
	TIME [epoch: 10.3 sec]
EPOCH 173/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1840817605277847		[learning rate: 0.0046532]
	Learning Rate: 0.00465324
	LOSS [training: 3.1840817605277847 | validation: 5.244694460851219]
	TIME [epoch: 10.3 sec]
EPOCH 174/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2445233952874597		[learning rate: 0.0046314]
	Learning Rate: 0.00463142
	LOSS [training: 3.2445233952874597 | validation: 5.268900706239516]
	TIME [epoch: 10.3 sec]
EPOCH 175/500:
	Training over batches...
		[batch 5/5] avg loss: 3.342056089563605		[learning rate: 0.0046097]
	Learning Rate: 0.00460971
	LOSS [training: 3.342056089563605 | validation: 6.038558385384213]
	TIME [epoch: 10.3 sec]
EPOCH 176/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4751001258862217		[learning rate: 0.0045881]
	Learning Rate: 0.0045881
	LOSS [training: 3.4751001258862217 | validation: 5.148671071298318]
	TIME [epoch: 10.3 sec]
EPOCH 177/500:
	Training over batches...
		[batch 5/5] avg loss: 3.312718587788644		[learning rate: 0.0045666]
	Learning Rate: 0.00456659
	LOSS [training: 3.312718587788644 | validation: 5.22554676599633]
	TIME [epoch: 10.3 sec]
EPOCH 178/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2019873840699207		[learning rate: 0.0045452]
	Learning Rate: 0.00454518
	LOSS [training: 3.2019873840699207 | validation: 5.16408792114087]
	TIME [epoch: 10.3 sec]
EPOCH 179/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3416849628823306		[learning rate: 0.0045239]
	Learning Rate: 0.00452387
	LOSS [training: 3.3416849628823306 | validation: 5.250509939343694]
	TIME [epoch: 10.3 sec]
EPOCH 180/500:
	Training over batches...
		[batch 5/5] avg loss: 3.315609836797273		[learning rate: 0.0045027]
	Learning Rate: 0.00450266
	LOSS [training: 3.315609836797273 | validation: 5.379551952969532]
	TIME [epoch: 10.3 sec]
EPOCH 181/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5772528734584803		[learning rate: 0.0044816]
	Learning Rate: 0.00448155
	LOSS [training: 3.5772528734584803 | validation: 5.216663824884645]
	TIME [epoch: 10.3 sec]
EPOCH 182/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3961825177640406		[learning rate: 0.0044605]
	Learning Rate: 0.00446054
	LOSS [training: 3.3961825177640406 | validation: 5.049398083470052]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_182.pth
	Model improved!!!
EPOCH 183/500:
	Training over batches...
		[batch 5/5] avg loss: 3.25540380168487		[learning rate: 0.0044396]
	Learning Rate: 0.00443963
	LOSS [training: 3.25540380168487 | validation: 5.039834969156777]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_183.pth
	Model improved!!!
EPOCH 184/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2948882289660397		[learning rate: 0.0044188]
	Learning Rate: 0.00441882
	LOSS [training: 3.2948882289660397 | validation: 5.048922874242093]
	TIME [epoch: 10.3 sec]
EPOCH 185/500:
	Training over batches...
		[batch 5/5] avg loss: 3.381031638932972		[learning rate: 0.0043981]
	Learning Rate: 0.0043981
	LOSS [training: 3.381031638932972 | validation: 5.016557752164882]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_185.pth
	Model improved!!!
EPOCH 186/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2690729336205613		[learning rate: 0.0043775]
	Learning Rate: 0.00437748
	LOSS [training: 3.2690729336205613 | validation: 5.1541296297233785]
	TIME [epoch: 10.3 sec]
EPOCH 187/500:
	Training over batches...
		[batch 5/5] avg loss: 3.182326892885181		[learning rate: 0.004357]
	Learning Rate: 0.00435696
	LOSS [training: 3.182326892885181 | validation: 5.070364792522708]
	TIME [epoch: 10.3 sec]
EPOCH 188/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2540537145175557		[learning rate: 0.0043365]
	Learning Rate: 0.00433654
	LOSS [training: 3.2540537145175557 | validation: 5.481412315447506]
	TIME [epoch: 10.3 sec]
EPOCH 189/500:
	Training over batches...
		[batch 5/5] avg loss: 3.332593407041018		[learning rate: 0.0043162]
	Learning Rate: 0.0043162
	LOSS [training: 3.332593407041018 | validation: 5.063347662096115]
	TIME [epoch: 10.3 sec]
EPOCH 190/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2439260341597063		[learning rate: 0.004296]
	Learning Rate: 0.00429597
	LOSS [training: 3.2439260341597063 | validation: 5.031800475992115]
	TIME [epoch: 10.3 sec]
EPOCH 191/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2409638024765597		[learning rate: 0.0042758]
	Learning Rate: 0.00427583
	LOSS [training: 3.2409638024765597 | validation: 4.998484209520646]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_191.pth
	Model improved!!!
EPOCH 192/500:
	Training over batches...
		[batch 5/5] avg loss: 3.234870363730065		[learning rate: 0.0042558]
	Learning Rate: 0.00425578
	LOSS [training: 3.234870363730065 | validation: 5.148270334027071]
	TIME [epoch: 10.3 sec]
EPOCH 193/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1486578620396437		[learning rate: 0.0042358]
	Learning Rate: 0.00423583
	LOSS [training: 3.1486578620396437 | validation: 5.022313750226909]
	TIME [epoch: 10.3 sec]
EPOCH 194/500:
	Training over batches...
		[batch 5/5] avg loss: 3.173892685646602		[learning rate: 0.004216]
	Learning Rate: 0.00421597
	LOSS [training: 3.173892685646602 | validation: 5.224825083714686]
	TIME [epoch: 10.3 sec]
EPOCH 195/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2360130074283937		[learning rate: 0.0041962]
	Learning Rate: 0.00419621
	LOSS [training: 3.2360130074283937 | validation: 5.542865652103033]
	TIME [epoch: 10.3 sec]
EPOCH 196/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4169357122758464		[learning rate: 0.0041765]
	Learning Rate: 0.00417654
	LOSS [training: 3.4169357122758464 | validation: 5.461773636445407]
	TIME [epoch: 10.3 sec]
EPOCH 197/500:
	Training over batches...
		[batch 5/5] avg loss: 3.294958765860946		[learning rate: 0.004157]
	Learning Rate: 0.00415696
	LOSS [training: 3.294958765860946 | validation: 5.071565023304368]
	TIME [epoch: 10.3 sec]
EPOCH 198/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1152323715261607		[learning rate: 0.0041375]
	Learning Rate: 0.00413747
	LOSS [training: 3.1152323715261607 | validation: 5.704529110027551]
	TIME [epoch: 10.3 sec]
EPOCH 199/500:
	Training over batches...
		[batch 5/5] avg loss: 3.469078646504289		[learning rate: 0.0041181]
	Learning Rate: 0.00411807
	LOSS [training: 3.469078646504289 | validation: 4.914790233830249]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_199.pth
	Model improved!!!
EPOCH 200/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2711252616553494		[learning rate: 0.0040988]
	Learning Rate: 0.00409877
	LOSS [training: 3.2711252616553494 | validation: 5.015772392962595]
	TIME [epoch: 10.3 sec]
EPOCH 201/500:
	Training over batches...
		[batch 5/5] avg loss: 3.199777309027521		[learning rate: 0.0040795]
	Learning Rate: 0.00407955
	LOSS [training: 3.199777309027521 | validation: 5.113987915582864]
	TIME [epoch: 10.3 sec]
EPOCH 202/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2273455671079936		[learning rate: 0.0040604]
	Learning Rate: 0.00406042
	LOSS [training: 3.2273455671079936 | validation: 5.055378282305748]
	TIME [epoch: 10.3 sec]
EPOCH 203/500:
	Training over batches...
		[batch 5/5] avg loss: 3.163518158258735		[learning rate: 0.0040414]
	Learning Rate: 0.00404139
	LOSS [training: 3.163518158258735 | validation: 5.05907768917409]
	TIME [epoch: 10.3 sec]
EPOCH 204/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1771867266363167		[learning rate: 0.0040224]
	Learning Rate: 0.00402244
	LOSS [training: 3.1771867266363167 | validation: 5.331196028582358]
	TIME [epoch: 10.3 sec]
EPOCH 205/500:
	Training over batches...
		[batch 5/5] avg loss: 3.225010655711627		[learning rate: 0.0040036]
	Learning Rate: 0.00400358
	LOSS [training: 3.225010655711627 | validation: 4.900422549864189]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_205.pth
	Model improved!!!
EPOCH 206/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1191156438015164		[learning rate: 0.0039848]
	Learning Rate: 0.00398481
	LOSS [training: 3.1191156438015164 | validation: 5.061263405364725]
	TIME [epoch: 10.3 sec]
EPOCH 207/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3923315146019997		[learning rate: 0.0039661]
	Learning Rate: 0.00396613
	LOSS [training: 3.3923315146019997 | validation: 5.023264391344762]
	TIME [epoch: 10.3 sec]
EPOCH 208/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0455636923169207		[learning rate: 0.0039475]
	Learning Rate: 0.00394754
	LOSS [training: 3.0455636923169207 | validation: 4.99020206315587]
	TIME [epoch: 10.3 sec]
EPOCH 209/500:
	Training over batches...
		[batch 5/5] avg loss: 3.196414850510335		[learning rate: 0.003929]
	Learning Rate: 0.00392903
	LOSS [training: 3.196414850510335 | validation: 5.0275559721538325]
	TIME [epoch: 10.3 sec]
EPOCH 210/500:
	Training over batches...
		[batch 5/5] avg loss: 3.031318238887443		[learning rate: 0.0039106]
	Learning Rate: 0.00391061
	LOSS [training: 3.031318238887443 | validation: 4.961210592754148]
	TIME [epoch: 10.3 sec]
EPOCH 211/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1035987267211547		[learning rate: 0.0038923]
	Learning Rate: 0.00389228
	LOSS [training: 3.1035987267211547 | validation: 5.244220628487913]
	TIME [epoch: 10.3 sec]
EPOCH 212/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0624378654607596		[learning rate: 0.003874]
	Learning Rate: 0.00387403
	LOSS [training: 3.0624378654607596 | validation: 4.755961484559308]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_212.pth
	Model improved!!!
EPOCH 213/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0879983724120086		[learning rate: 0.0038559]
	Learning Rate: 0.00385587
	LOSS [training: 3.0879983724120086 | validation: 4.700818578485793]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_213.pth
	Model improved!!!
EPOCH 214/500:
	Training over batches...
		[batch 5/5] avg loss: 3.498988184058812		[learning rate: 0.0038378]
	Learning Rate: 0.00383779
	LOSS [training: 3.498988184058812 | validation: 4.880910895461754]
	TIME [epoch: 10.3 sec]
EPOCH 215/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0785085636717895		[learning rate: 0.0038198]
	Learning Rate: 0.0038198
	LOSS [training: 3.0785085636717895 | validation: 4.848691320465982]
	TIME [epoch: 10.3 sec]
EPOCH 216/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9032475905771653		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 2.9032475905771653 | validation: 4.258241147924492]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_216.pth
	Model improved!!!
EPOCH 217/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0177029167497063		[learning rate: 0.0037841]
	Learning Rate: 0.00378407
	LOSS [training: 3.0177029167497063 | validation: 4.371497706560652]
	TIME [epoch: 10.3 sec]
EPOCH 218/500:
	Training over batches...
		[batch 5/5] avg loss: 2.768253823652064		[learning rate: 0.0037663]
	Learning Rate: 0.00376633
	LOSS [training: 2.768253823652064 | validation: 4.151801238122789]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_218.pth
	Model improved!!!
EPOCH 219/500:
	Training over batches...
		[batch 5/5] avg loss: 2.589590207478274		[learning rate: 0.0037487]
	Learning Rate: 0.00374867
	LOSS [training: 2.589590207478274 | validation: 3.90901632838913]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_219.pth
	Model improved!!!
EPOCH 220/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4787799975897125		[learning rate: 0.0037311]
	Learning Rate: 0.0037311
	LOSS [training: 2.4787799975897125 | validation: 4.83181811147681]
	TIME [epoch: 10.3 sec]
EPOCH 221/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5506094486254116		[learning rate: 0.0037136]
	Learning Rate: 0.00371361
	LOSS [training: 2.5506094486254116 | validation: 3.586891413409546]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_221.pth
	Model improved!!!
EPOCH 222/500:
	Training over batches...
		[batch 5/5] avg loss: 2.048574652121315		[learning rate: 0.0036962]
	Learning Rate: 0.0036962
	LOSS [training: 2.048574652121315 | validation: 1.8490006912575074]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_222.pth
	Model improved!!!
EPOCH 223/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8238734345997538		[learning rate: 0.0036789]
	Learning Rate: 0.00367887
	LOSS [training: 1.8238734345997538 | validation: 1.7076635190661125]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_223.pth
	Model improved!!!
EPOCH 224/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2902379717091295		[learning rate: 0.0036616]
	Learning Rate: 0.00366162
	LOSS [training: 1.2902379717091295 | validation: 1.5166313585876616]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_224.pth
	Model improved!!!
EPOCH 225/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0812837036308405		[learning rate: 0.0036445]
	Learning Rate: 0.00364446
	LOSS [training: 1.0812837036308405 | validation: 1.2136702428996118]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_225.pth
	Model improved!!!
EPOCH 226/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3301758628737246		[learning rate: 0.0036274]
	Learning Rate: 0.00362737
	LOSS [training: 1.3301758628737246 | validation: 1.0336108627833065]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_226.pth
	Model improved!!!
EPOCH 227/500:
	Training over batches...
		[batch 5/5] avg loss: 1.190353317669311		[learning rate: 0.0036104]
	Learning Rate: 0.00361036
	LOSS [training: 1.190353317669311 | validation: 1.158613778877364]
	TIME [epoch: 10.3 sec]
EPOCH 228/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0504307942540536		[learning rate: 0.0035934]
	Learning Rate: 0.00359344
	LOSS [training: 1.0504307942540536 | validation: 0.9403708625796332]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_228.pth
	Model improved!!!
EPOCH 229/500:
	Training over batches...
		[batch 5/5] avg loss: 1.098719327904815		[learning rate: 0.0035766]
	Learning Rate: 0.00357659
	LOSS [training: 1.098719327904815 | validation: 1.2674426926988955]
	TIME [epoch: 10.3 sec]
EPOCH 230/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1074556407831397		[learning rate: 0.0035598]
	Learning Rate: 0.00355982
	LOSS [training: 2.1074556407831397 | validation: 2.0630907689261617]
	TIME [epoch: 10.3 sec]
EPOCH 231/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2265035136304672		[learning rate: 0.0035431]
	Learning Rate: 0.00354314
	LOSS [training: 1.2265035136304672 | validation: 0.979119989351933]
	TIME [epoch: 10.3 sec]
EPOCH 232/500:
	Training over batches...
		[batch 5/5] avg loss: 1.327385016081618		[learning rate: 0.0035265]
	Learning Rate: 0.00352652
	LOSS [training: 1.327385016081618 | validation: 2.026477364718578]
	TIME [epoch: 10.3 sec]
EPOCH 233/500:
	Training over batches...
		[batch 5/5] avg loss: 1.241528271014627		[learning rate: 0.00351]
	Learning Rate: 0.00350999
	LOSS [training: 1.241528271014627 | validation: 1.4774067507440842]
	TIME [epoch: 10.3 sec]
EPOCH 234/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0358904882384232		[learning rate: 0.0034935]
	Learning Rate: 0.00349354
	LOSS [training: 1.0358904882384232 | validation: 1.3878333630464033]
	TIME [epoch: 10.3 sec]
EPOCH 235/500:
	Training over batches...
		[batch 5/5] avg loss: 1.153499141368114		[learning rate: 0.0034772]
	Learning Rate: 0.00347716
	LOSS [training: 1.153499141368114 | validation: 1.1165531752878772]
	TIME [epoch: 10.3 sec]
EPOCH 236/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0278793817206782		[learning rate: 0.0034609]
	Learning Rate: 0.00346086
	LOSS [training: 1.0278793817206782 | validation: 1.4278377966691813]
	TIME [epoch: 10.3 sec]
EPOCH 237/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1632833022558864		[learning rate: 0.0034446]
	Learning Rate: 0.00344463
	LOSS [training: 1.1632833022558864 | validation: 1.0276946627551393]
	TIME [epoch: 10.3 sec]
EPOCH 238/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1700052792484827		[learning rate: 0.0034285]
	Learning Rate: 0.00342848
	LOSS [training: 1.1700052792484827 | validation: 2.7167312581974046]
	TIME [epoch: 10.3 sec]
EPOCH 239/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2266027650011615		[learning rate: 0.0034124]
	Learning Rate: 0.00341241
	LOSS [training: 1.2266027650011615 | validation: 0.9023892517776986]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_239.pth
	Model improved!!!
EPOCH 240/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1745416459444633		[learning rate: 0.0033964]
	Learning Rate: 0.00339641
	LOSS [training: 1.1745416459444633 | validation: 0.8873887248389312]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_240.pth
	Model improved!!!
EPOCH 241/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9893068249732655		[learning rate: 0.0033805]
	Learning Rate: 0.00338049
	LOSS [training: 0.9893068249732655 | validation: 1.320659497312057]
	TIME [epoch: 10.3 sec]
EPOCH 242/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9725005357406244		[learning rate: 0.0033646]
	Learning Rate: 0.00336464
	LOSS [training: 0.9725005357406244 | validation: 1.5494293616702965]
	TIME [epoch: 10.3 sec]
EPOCH 243/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2251108099595716		[learning rate: 0.0033489]
	Learning Rate: 0.00334887
	LOSS [training: 1.2251108099595716 | validation: 1.4154778141548345]
	TIME [epoch: 10.3 sec]
EPOCH 244/500:
	Training over batches...
		[batch 5/5] avg loss: 1.109744038493379		[learning rate: 0.0033332]
	Learning Rate: 0.00333317
	LOSS [training: 1.109744038493379 | validation: 1.1179792197475382]
	TIME [epoch: 10.3 sec]
EPOCH 245/500:
	Training over batches...
		[batch 5/5] avg loss: 1.094034739134401		[learning rate: 0.0033175]
	Learning Rate: 0.00331754
	LOSS [training: 1.094034739134401 | validation: 1.1224176281974314]
	TIME [epoch: 10.3 sec]
EPOCH 246/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5870898117335461		[learning rate: 0.003302]
	Learning Rate: 0.00330199
	LOSS [training: 1.5870898117335461 | validation: 2.0222600436041014]
	TIME [epoch: 10.3 sec]
EPOCH 247/500:
	Training over batches...
		[batch 5/5] avg loss: 1.30380701170322		[learning rate: 0.0032865]
	Learning Rate: 0.00328651
	LOSS [training: 1.30380701170322 | validation: 0.8123410052003593]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_247.pth
	Model improved!!!
EPOCH 248/500:
	Training over batches...
		[batch 5/5] avg loss: 1.131173103774209		[learning rate: 0.0032711]
	Learning Rate: 0.0032711
	LOSS [training: 1.131173103774209 | validation: 1.0898304185009846]
	TIME [epoch: 10.3 sec]
EPOCH 249/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0355430724297245		[learning rate: 0.0032558]
	Learning Rate: 0.00325576
	LOSS [training: 1.0355430724297245 | validation: 1.543384612561368]
	TIME [epoch: 10.3 sec]
EPOCH 250/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3497251018575842		[learning rate: 0.0032405]
	Learning Rate: 0.0032405
	LOSS [training: 1.3497251018575842 | validation: 1.2182586981132157]
	TIME [epoch: 10.3 sec]
EPOCH 251/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9155982636592398		[learning rate: 0.0032253]
	Learning Rate: 0.00322531
	LOSS [training: 0.9155982636592398 | validation: 0.9776592313612262]
	TIME [epoch: 10.3 sec]
EPOCH 252/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8173662293279815		[learning rate: 0.0032102]
	Learning Rate: 0.00321019
	LOSS [training: 0.8173662293279815 | validation: 1.7035493593946567]
	TIME [epoch: 10.3 sec]
EPOCH 253/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9242950773612586		[learning rate: 0.0031951]
	Learning Rate: 0.00319514
	LOSS [training: 0.9242950773612586 | validation: 0.9439368270411664]
	TIME [epoch: 10.3 sec]
EPOCH 254/500:
	Training over batches...
		[batch 5/5] avg loss: 1.085708508365888		[learning rate: 0.0031802]
	Learning Rate: 0.00318016
	LOSS [training: 1.085708508365888 | validation: 0.8133254777027338]
	TIME [epoch: 10.3 sec]
EPOCH 255/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8240271915025144		[learning rate: 0.0031653]
	Learning Rate: 0.00316525
	LOSS [training: 0.8240271915025144 | validation: 1.8536847832539882]
	TIME [epoch: 10.3 sec]
EPOCH 256/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1399333491369892		[learning rate: 0.0031504]
	Learning Rate: 0.00315041
	LOSS [training: 1.1399333491369892 | validation: 0.7806534498411847]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_256.pth
	Model improved!!!
EPOCH 257/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9045190658639948		[learning rate: 0.0031356]
	Learning Rate: 0.00313564
	LOSS [training: 0.9045190658639948 | validation: 1.3930038433916767]
	TIME [epoch: 10.3 sec]
EPOCH 258/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1036196499493627		[learning rate: 0.0031209]
	Learning Rate: 0.00312094
	LOSS [training: 1.1036196499493627 | validation: 1.0487847971955178]
	TIME [epoch: 10.3 sec]
EPOCH 259/500:
	Training over batches...
		[batch 5/5] avg loss: 1.142739396661709		[learning rate: 0.0031063]
	Learning Rate: 0.00310631
	LOSS [training: 1.142739396661709 | validation: 1.2236527406922018]
	TIME [epoch: 10.3 sec]
EPOCH 260/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0092764943243657		[learning rate: 0.0030917]
	Learning Rate: 0.00309175
	LOSS [training: 1.0092764943243657 | validation: 1.0458559402430105]
	TIME [epoch: 10.3 sec]
EPOCH 261/500:
	Training over batches...
		[batch 5/5] avg loss: 1.194435323812704		[learning rate: 0.0030773]
	Learning Rate: 0.00307725
	LOSS [training: 1.194435323812704 | validation: 0.6562475447665969]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_261.pth
	Model improved!!!
EPOCH 262/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8214362791216384		[learning rate: 0.0030628]
	Learning Rate: 0.00306283
	LOSS [training: 0.8214362791216384 | validation: 0.669968856293086]
	TIME [epoch: 10.3 sec]
EPOCH 263/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9169620697129485		[learning rate: 0.0030485]
	Learning Rate: 0.00304847
	LOSS [training: 0.9169620697129485 | validation: 0.8685836308558256]
	TIME [epoch: 10.3 sec]
EPOCH 264/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9417830379284909		[learning rate: 0.0030342]
	Learning Rate: 0.00303418
	LOSS [training: 0.9417830379284909 | validation: 1.1560845628470244]
	TIME [epoch: 10.3 sec]
EPOCH 265/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8409300454781354		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.8409300454781354 | validation: 1.398768350182612]
	TIME [epoch: 10.3 sec]
EPOCH 266/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4328228213437133		[learning rate: 0.0030058]
	Learning Rate: 0.00300579
	LOSS [training: 1.4328228213437133 | validation: 1.0319570365190815]
	TIME [epoch: 10.3 sec]
EPOCH 267/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0559285951601267		[learning rate: 0.0029917]
	Learning Rate: 0.0029917
	LOSS [training: 1.0559285951601267 | validation: 0.9720573915424706]
	TIME [epoch: 10.3 sec]
EPOCH 268/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9546381408762233		[learning rate: 0.0029777]
	Learning Rate: 0.00297768
	LOSS [training: 0.9546381408762233 | validation: 1.319399481502002]
	TIME [epoch: 10.3 sec]
EPOCH 269/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9781729008274909		[learning rate: 0.0029637]
	Learning Rate: 0.00296372
	LOSS [training: 0.9781729008274909 | validation: 0.835202472860184]
	TIME [epoch: 10.3 sec]
EPOCH 270/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9631201088318978		[learning rate: 0.0029498]
	Learning Rate: 0.00294982
	LOSS [training: 0.9631201088318978 | validation: 0.7859287575486887]
	TIME [epoch: 10.3 sec]
EPOCH 271/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0259017559959402		[learning rate: 0.002936]
	Learning Rate: 0.00293599
	LOSS [training: 1.0259017559959402 | validation: 0.640333733226896]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_271.pth
	Model improved!!!
EPOCH 272/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4158179628061913		[learning rate: 0.0029222]
	Learning Rate: 0.00292223
	LOSS [training: 1.4158179628061913 | validation: 0.8189402568290174]
	TIME [epoch: 10.3 sec]
EPOCH 273/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8004136148532291		[learning rate: 0.0029085]
	Learning Rate: 0.00290853
	LOSS [training: 0.8004136148532291 | validation: 1.344071238964244]
	TIME [epoch: 10.3 sec]
EPOCH 274/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9683999844542217		[learning rate: 0.0028949]
	Learning Rate: 0.00289489
	LOSS [training: 0.9683999844542217 | validation: 1.2610280940213785]
	TIME [epoch: 10.3 sec]
EPOCH 275/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9589107619070463		[learning rate: 0.0028813]
	Learning Rate: 0.00288132
	LOSS [training: 0.9589107619070463 | validation: 1.3993935372707478]
	TIME [epoch: 10.3 sec]
EPOCH 276/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0531243801362673		[learning rate: 0.0028678]
	Learning Rate: 0.00286781
	LOSS [training: 1.0531243801362673 | validation: 0.6650414675491748]
	TIME [epoch: 10.3 sec]
EPOCH 277/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3044633576909153		[learning rate: 0.0028544]
	Learning Rate: 0.00285437
	LOSS [training: 1.3044633576909153 | validation: 2.2680221198793014]
	TIME [epoch: 10.3 sec]
EPOCH 278/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6177374910703244		[learning rate: 0.002841]
	Learning Rate: 0.00284099
	LOSS [training: 1.6177374910703244 | validation: 1.1415977434819882]
	TIME [epoch: 10.3 sec]
EPOCH 279/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9059769645990935		[learning rate: 0.0028277]
	Learning Rate: 0.00282767
	LOSS [training: 0.9059769645990935 | validation: 0.6537208185942265]
	TIME [epoch: 10.3 sec]
EPOCH 280/500:
	Training over batches...
		[batch 5/5] avg loss: 1.096613047745474		[learning rate: 0.0028144]
	Learning Rate: 0.00281441
	LOSS [training: 1.096613047745474 | validation: 1.298708008685764]
	TIME [epoch: 10.3 sec]
EPOCH 281/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9387862713680928		[learning rate: 0.0028012]
	Learning Rate: 0.00280122
	LOSS [training: 0.9387862713680928 | validation: 0.6688428845303566]
	TIME [epoch: 10.3 sec]
EPOCH 282/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8346745978686378		[learning rate: 0.0027881]
	Learning Rate: 0.00278809
	LOSS [training: 0.8346745978686378 | validation: 1.6261153993735207]
	TIME [epoch: 10.3 sec]
EPOCH 283/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0112658008987958		[learning rate: 0.002775]
	Learning Rate: 0.00277501
	LOSS [training: 1.0112658008987958 | validation: 0.702122856711263]
	TIME [epoch: 10.3 sec]
EPOCH 284/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0673692239072874		[learning rate: 0.002762]
	Learning Rate: 0.002762
	LOSS [training: 1.0673692239072874 | validation: 1.3232286188148163]
	TIME [epoch: 10.3 sec]
EPOCH 285/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0648225224290493		[learning rate: 0.0027491]
	Learning Rate: 0.00274906
	LOSS [training: 1.0648225224290493 | validation: 1.1413975239064527]
	TIME [epoch: 10.3 sec]
EPOCH 286/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8529379120289734		[learning rate: 0.0027362]
	Learning Rate: 0.00273617
	LOSS [training: 0.8529379120289734 | validation: 1.010099371149579]
	TIME [epoch: 10.3 sec]
EPOCH 287/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9352910717200095		[learning rate: 0.0027233]
	Learning Rate: 0.00272334
	LOSS [training: 0.9352910717200095 | validation: 1.036604411835246]
	TIME [epoch: 10.3 sec]
EPOCH 288/500:
	Training over batches...
		[batch 5/5] avg loss: 1.230306386672572		[learning rate: 0.0027106]
	Learning Rate: 0.00271057
	LOSS [training: 1.230306386672572 | validation: 0.7681574503590072]
	TIME [epoch: 10.3 sec]
EPOCH 289/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9519840488017838		[learning rate: 0.0026979]
	Learning Rate: 0.00269787
	LOSS [training: 0.9519840488017838 | validation: 1.0685501779432471]
	TIME [epoch: 10.3 sec]
EPOCH 290/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4753215498130987		[learning rate: 0.0026852]
	Learning Rate: 0.00268522
	LOSS [training: 1.4753215498130987 | validation: 0.8270028234346748]
	TIME [epoch: 10.3 sec]
EPOCH 291/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8034070289187151		[learning rate: 0.0026726]
	Learning Rate: 0.00267263
	LOSS [training: 0.8034070289187151 | validation: 0.9868572768600044]
	TIME [epoch: 10.3 sec]
EPOCH 292/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9015640191739198		[learning rate: 0.0026601]
	Learning Rate: 0.0026601
	LOSS [training: 0.9015640191739198 | validation: 1.1913222330222153]
	TIME [epoch: 10.3 sec]
EPOCH 293/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9894115900061274		[learning rate: 0.0026476]
	Learning Rate: 0.00264763
	LOSS [training: 0.9894115900061274 | validation: 0.8754464842204029]
	TIME [epoch: 10.3 sec]
EPOCH 294/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0988195149007685		[learning rate: 0.0026352]
	Learning Rate: 0.00263522
	LOSS [training: 1.0988195149007685 | validation: 1.1834531575664606]
	TIME [epoch: 10.3 sec]
EPOCH 295/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9455852083024683		[learning rate: 0.0026229]
	Learning Rate: 0.00262286
	LOSS [training: 0.9455852083024683 | validation: 0.7788303377145112]
	TIME [epoch: 10.3 sec]
EPOCH 296/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8714512761672806		[learning rate: 0.0026106]
	Learning Rate: 0.00261057
	LOSS [training: 0.8714512761672806 | validation: 0.646245706427291]
	TIME [epoch: 10.3 sec]
EPOCH 297/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7346334530334502		[learning rate: 0.0025983]
	Learning Rate: 0.00259833
	LOSS [training: 0.7346334530334502 | validation: 0.9926685297224515]
	TIME [epoch: 10.3 sec]
EPOCH 298/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8105549472956284		[learning rate: 0.0025861]
	Learning Rate: 0.00258615
	LOSS [training: 0.8105549472956284 | validation: 0.7830947906041884]
	TIME [epoch: 10.3 sec]
EPOCH 299/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9585981650610508		[learning rate: 0.002574]
	Learning Rate: 0.00257402
	LOSS [training: 0.9585981650610508 | validation: 1.4722188622953374]
	TIME [epoch: 10.3 sec]
EPOCH 300/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9183269373190004		[learning rate: 0.002562]
	Learning Rate: 0.00256195
	LOSS [training: 0.9183269373190004 | validation: 0.6427586175145387]
	TIME [epoch: 10.3 sec]
EPOCH 301/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9405705542827366		[learning rate: 0.0025499]
	Learning Rate: 0.00254994
	LOSS [training: 0.9405705542827366 | validation: 0.9830056893234891]
	TIME [epoch: 10.3 sec]
EPOCH 302/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9935235643265774		[learning rate: 0.002538]
	Learning Rate: 0.00253799
	LOSS [training: 0.9935235643265774 | validation: 0.9332867201126105]
	TIME [epoch: 10.3 sec]
EPOCH 303/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8200862921199148		[learning rate: 0.0025261]
	Learning Rate: 0.00252609
	LOSS [training: 0.8200862921199148 | validation: 0.6227306289155573]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_303.pth
	Model improved!!!
EPOCH 304/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8034573525472407		[learning rate: 0.0025142]
	Learning Rate: 0.00251425
	LOSS [training: 0.8034573525472407 | validation: 0.7287772465333856]
	TIME [epoch: 10.3 sec]
EPOCH 305/500:
	Training over batches...
		[batch 5/5] avg loss: 0.880819498833144		[learning rate: 0.0025025]
	Learning Rate: 0.00250246
	LOSS [training: 0.880819498833144 | validation: 0.8291075531404726]
	TIME [epoch: 10.3 sec]
EPOCH 306/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8934196431499005		[learning rate: 0.0024907]
	Learning Rate: 0.00249073
	LOSS [training: 0.8934196431499005 | validation: 2.2706226064945576]
	TIME [epoch: 10.3 sec]
EPOCH 307/500:
	Training over batches...
		[batch 5/5] avg loss: 1.383894524435324		[learning rate: 0.0024791]
	Learning Rate: 0.00247905
	LOSS [training: 1.383894524435324 | validation: 0.6867670307559849]
	TIME [epoch: 10.3 sec]
EPOCH 308/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7891897446028423		[learning rate: 0.0024674]
	Learning Rate: 0.00246743
	LOSS [training: 0.7891897446028423 | validation: 0.8393503489821417]
	TIME [epoch: 10.3 sec]
EPOCH 309/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7993594944120122		[learning rate: 0.0024559]
	Learning Rate: 0.00245586
	LOSS [training: 0.7993594944120122 | validation: 1.1022215167488205]
	TIME [epoch: 10.3 sec]
EPOCH 310/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7672252963171313		[learning rate: 0.0024443]
	Learning Rate: 0.00244435
	LOSS [training: 0.7672252963171313 | validation: 0.6427116862142824]
	TIME [epoch: 10.3 sec]
EPOCH 311/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9454241764820024		[learning rate: 0.0024329]
	Learning Rate: 0.00243289
	LOSS [training: 0.9454241764820024 | validation: 0.8386703481584834]
	TIME [epoch: 10.3 sec]
EPOCH 312/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9364475673985295		[learning rate: 0.0024215]
	Learning Rate: 0.00242148
	LOSS [training: 0.9364475673985295 | validation: 0.6439635139890929]
	TIME [epoch: 10.3 sec]
EPOCH 313/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8349349993799983		[learning rate: 0.0024101]
	Learning Rate: 0.00241013
	LOSS [training: 0.8349349993799983 | validation: 0.845213467427389]
	TIME [epoch: 10.3 sec]
EPOCH 314/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8260546758212822		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.8260546758212822 | validation: 0.7068141593186215]
	TIME [epoch: 10.3 sec]
EPOCH 315/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8069996323495235		[learning rate: 0.0023876]
	Learning Rate: 0.00238759
	LOSS [training: 0.8069996323495235 | validation: 1.007463631077354]
	TIME [epoch: 10.3 sec]
EPOCH 316/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7831583801738835		[learning rate: 0.0023764]
	Learning Rate: 0.00237639
	LOSS [training: 0.7831583801738835 | validation: 0.677896642354859]
	TIME [epoch: 10.3 sec]
EPOCH 317/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0481472159112186		[learning rate: 0.0023653]
	Learning Rate: 0.00236525
	LOSS [training: 1.0481472159112186 | validation: 0.8180302047507505]
	TIME [epoch: 10.3 sec]
EPOCH 318/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9668539971293619		[learning rate: 0.0023542]
	Learning Rate: 0.00235416
	LOSS [training: 0.9668539971293619 | validation: 0.6456030095933466]
	TIME [epoch: 10.3 sec]
EPOCH 319/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8315866432909497		[learning rate: 0.0023431]
	Learning Rate: 0.00234313
	LOSS [training: 0.8315866432909497 | validation: 1.7617766648194402]
	TIME [epoch: 10.3 sec]
EPOCH 320/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9726414328105942		[learning rate: 0.0023321]
	Learning Rate: 0.00233214
	LOSS [training: 0.9726414328105942 | validation: 0.834265997903644]
	TIME [epoch: 10.3 sec]
EPOCH 321/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9868766937686946		[learning rate: 0.0023212]
	Learning Rate: 0.00232121
	LOSS [training: 0.9868766937686946 | validation: 0.6939355845340733]
	TIME [epoch: 10.3 sec]
EPOCH 322/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7091580945427707		[learning rate: 0.0023103]
	Learning Rate: 0.00231033
	LOSS [training: 0.7091580945427707 | validation: 0.5989457439972604]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_322.pth
	Model improved!!!
EPOCH 323/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9673248056598386		[learning rate: 0.0022995]
	Learning Rate: 0.0022995
	LOSS [training: 0.9673248056598386 | validation: 1.0787899331351014]
	TIME [epoch: 10.3 sec]
EPOCH 324/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0368245350171437		[learning rate: 0.0022887]
	Learning Rate: 0.00228872
	LOSS [training: 1.0368245350171437 | validation: 0.6689482349895778]
	TIME [epoch: 10.3 sec]
EPOCH 325/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0484410221686917		[learning rate: 0.002278]
	Learning Rate: 0.00227799
	LOSS [training: 1.0484410221686917 | validation: 1.1155421785922082]
	TIME [epoch: 10.3 sec]
EPOCH 326/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9127749911686867		[learning rate: 0.0022673]
	Learning Rate: 0.00226731
	LOSS [training: 0.9127749911686867 | validation: 0.8356742123782845]
	TIME [epoch: 10.3 sec]
EPOCH 327/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7266562621106349		[learning rate: 0.0022567]
	Learning Rate: 0.00225668
	LOSS [training: 0.7266562621106349 | validation: 0.7292969432197971]
	TIME [epoch: 10.3 sec]
EPOCH 328/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6726786877836239		[learning rate: 0.0022461]
	Learning Rate: 0.0022461
	LOSS [training: 0.6726786877836239 | validation: 0.5934731981992826]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_328.pth
	Model improved!!!
EPOCH 329/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8697072302114718		[learning rate: 0.0022356]
	Learning Rate: 0.00223557
	LOSS [training: 0.8697072302114718 | validation: 0.9181618254113493]
	TIME [epoch: 10.3 sec]
EPOCH 330/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6626381274940143		[learning rate: 0.0022251]
	Learning Rate: 0.00222509
	LOSS [training: 1.6626381274940143 | validation: 0.6552384017640231]
	TIME [epoch: 10.3 sec]
EPOCH 331/500:
	Training over batches...
		[batch 5/5] avg loss: 0.862391624052352		[learning rate: 0.0022147]
	Learning Rate: 0.00221466
	LOSS [training: 0.862391624052352 | validation: 0.5955596716499296]
	TIME [epoch: 10.3 sec]
EPOCH 332/500:
	Training over batches...
		[batch 5/5] avg loss: 1.030367644428945		[learning rate: 0.0022043]
	Learning Rate: 0.00220427
	LOSS [training: 1.030367644428945 | validation: 0.8258275320065692]
	TIME [epoch: 10.3 sec]
EPOCH 333/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8798836190190436		[learning rate: 0.0021939]
	Learning Rate: 0.00219394
	LOSS [training: 0.8798836190190436 | validation: 1.4091365485807505]
	TIME [epoch: 10.3 sec]
EPOCH 334/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8279914828035796		[learning rate: 0.0021837]
	Learning Rate: 0.00218365
	LOSS [training: 0.8279914828035796 | validation: 0.5616076670928177]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_334.pth
	Model improved!!!
EPOCH 335/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8423329618609052		[learning rate: 0.0021734]
	Learning Rate: 0.00217342
	LOSS [training: 0.8423329618609052 | validation: 1.0577965478624043]
	TIME [epoch: 10.3 sec]
EPOCH 336/500:
	Training over batches...
		[batch 5/5] avg loss: 0.782930168516358		[learning rate: 0.0021632]
	Learning Rate: 0.00216323
	LOSS [training: 0.782930168516358 | validation: 0.8192869063415303]
	TIME [epoch: 10.3 sec]
EPOCH 337/500:
	Training over batches...
		[batch 5/5] avg loss: 0.863222878429122		[learning rate: 0.0021531]
	Learning Rate: 0.00215309
	LOSS [training: 0.863222878429122 | validation: 0.8712376671397308]
	TIME [epoch: 10.3 sec]
EPOCH 338/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9645473192987126		[learning rate: 0.002143]
	Learning Rate: 0.00214299
	LOSS [training: 0.9645473192987126 | validation: 0.7472153284313012]
	TIME [epoch: 10.3 sec]
EPOCH 339/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8401556262487976		[learning rate: 0.0021329]
	Learning Rate: 0.00213294
	LOSS [training: 0.8401556262487976 | validation: 1.3949592235661232]
	TIME [epoch: 10.3 sec]
EPOCH 340/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8739899734922352		[learning rate: 0.0021229]
	Learning Rate: 0.00212294
	LOSS [training: 0.8739899734922352 | validation: 0.7438104548103047]
	TIME [epoch: 10.3 sec]
EPOCH 341/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7018057204008866		[learning rate: 0.002113]
	Learning Rate: 0.00211299
	LOSS [training: 0.7018057204008866 | validation: 0.673687647607252]
	TIME [epoch: 10.3 sec]
EPOCH 342/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8743546338008636		[learning rate: 0.0021031]
	Learning Rate: 0.00210309
	LOSS [training: 0.8743546338008636 | validation: 0.8402303311458832]
	TIME [epoch: 10.3 sec]
EPOCH 343/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7545683204128333		[learning rate: 0.0020932]
	Learning Rate: 0.00209323
	LOSS [training: 0.7545683204128333 | validation: 0.7003434901267669]
	TIME [epoch: 10.3 sec]
EPOCH 344/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7742320232336464		[learning rate: 0.0020834]
	Learning Rate: 0.00208341
	LOSS [training: 0.7742320232336464 | validation: 0.7785812064165777]
	TIME [epoch: 10.3 sec]
EPOCH 345/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7209397432711859		[learning rate: 0.0020736]
	Learning Rate: 0.00207365
	LOSS [training: 0.7209397432711859 | validation: 0.896866536482114]
	TIME [epoch: 10.3 sec]
EPOCH 346/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7293727255486938		[learning rate: 0.0020639]
	Learning Rate: 0.00206392
	LOSS [training: 0.7293727255486938 | validation: 0.6227508506511751]
	TIME [epoch: 10.3 sec]
EPOCH 347/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7295962159723124		[learning rate: 0.0020542]
	Learning Rate: 0.00205425
	LOSS [training: 0.7295962159723124 | validation: 0.6344013403055073]
	TIME [epoch: 10.3 sec]
EPOCH 348/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7284522421812787		[learning rate: 0.0020446]
	Learning Rate: 0.00204462
	LOSS [training: 0.7284522421812787 | validation: 0.5620466917960303]
	TIME [epoch: 10.3 sec]
EPOCH 349/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9107615608947501		[learning rate: 0.002035]
	Learning Rate: 0.00203503
	LOSS [training: 0.9107615608947501 | validation: 1.3504798537909772]
	TIME [epoch: 10.3 sec]
EPOCH 350/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8512763162608181		[learning rate: 0.0020255]
	Learning Rate: 0.00202549
	LOSS [training: 0.8512763162608181 | validation: 0.5124826934557067]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_350.pth
	Model improved!!!
EPOCH 351/500:
	Training over batches...
		[batch 5/5] avg loss: 0.71486560167425		[learning rate: 0.002016]
	Learning Rate: 0.002016
	LOSS [training: 0.71486560167425 | validation: 0.6338354879813208]
	TIME [epoch: 10.3 sec]
EPOCH 352/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6684414815960569		[learning rate: 0.0020065]
	Learning Rate: 0.00200655
	LOSS [training: 0.6684414815960569 | validation: 0.8311587743657889]
	TIME [epoch: 10.3 sec]
EPOCH 353/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8232338825342881		[learning rate: 0.0019971]
	Learning Rate: 0.00199714
	LOSS [training: 0.8232338825342881 | validation: 0.8980869499686481]
	TIME [epoch: 10.3 sec]
EPOCH 354/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0781699064204044		[learning rate: 0.0019878]
	Learning Rate: 0.00198778
	LOSS [training: 1.0781699064204044 | validation: 0.912470508587108]
	TIME [epoch: 10.3 sec]
EPOCH 355/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8174387482674236		[learning rate: 0.0019785]
	Learning Rate: 0.00197846
	LOSS [training: 0.8174387482674236 | validation: 0.7146341618472735]
	TIME [epoch: 10.3 sec]
EPOCH 356/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7294063288216843		[learning rate: 0.0019692]
	Learning Rate: 0.00196918
	LOSS [training: 0.7294063288216843 | validation: 0.6804852497338348]
	TIME [epoch: 10.3 sec]
EPOCH 357/500:
	Training over batches...
		[batch 5/5] avg loss: 0.77370072526843		[learning rate: 0.0019599]
	Learning Rate: 0.00195995
	LOSS [training: 0.77370072526843 | validation: 1.102620789506655]
	TIME [epoch: 10.3 sec]
EPOCH 358/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7961351385185141		[learning rate: 0.0019508]
	Learning Rate: 0.00195076
	LOSS [training: 0.7961351385185141 | validation: 0.6875746571512403]
	TIME [epoch: 10.3 sec]
EPOCH 359/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9035344199541498		[learning rate: 0.0019416]
	Learning Rate: 0.00194162
	LOSS [training: 0.9035344199541498 | validation: 0.5183247773526661]
	TIME [epoch: 10.3 sec]
EPOCH 360/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7059725202302637		[learning rate: 0.0019325]
	Learning Rate: 0.00193251
	LOSS [training: 0.7059725202302637 | validation: 0.9795957476922204]
	TIME [epoch: 10.3 sec]
EPOCH 361/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7679821115868697		[learning rate: 0.0019235]
	Learning Rate: 0.00192345
	LOSS [training: 0.7679821115868697 | validation: 0.7167958766444772]
	TIME [epoch: 10.3 sec]
EPOCH 362/500:
	Training over batches...
		[batch 5/5] avg loss: 0.695311130248534		[learning rate: 0.0019144]
	Learning Rate: 0.00191444
	LOSS [training: 0.695311130248534 | validation: 0.8850993148532319]
	TIME [epoch: 10.3 sec]
EPOCH 363/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7616483375767429		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.7616483375767429 | validation: 0.5735341954888724]
	TIME [epoch: 10.3 sec]
EPOCH 364/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6004037532970856		[learning rate: 0.0018965]
	Learning Rate: 0.00189653
	LOSS [training: 0.6004037532970856 | validation: 0.7394843221629467]
	TIME [epoch: 10.3 sec]
EPOCH 365/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6914991217951325		[learning rate: 0.0018876]
	Learning Rate: 0.00188764
	LOSS [training: 0.6914991217951325 | validation: 1.542447167260039]
	TIME [epoch: 10.3 sec]
EPOCH 366/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8979141115477092		[learning rate: 0.0018788]
	Learning Rate: 0.00187879
	LOSS [training: 0.8979141115477092 | validation: 0.6923640896605264]
	TIME [epoch: 10.3 sec]
EPOCH 367/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8806191631442667		[learning rate: 0.00187]
	Learning Rate: 0.00186998
	LOSS [training: 0.8806191631442667 | validation: 0.7459777385337799]
	TIME [epoch: 10.3 sec]
EPOCH 368/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7054083179037419		[learning rate: 0.0018612]
	Learning Rate: 0.00186121
	LOSS [training: 0.7054083179037419 | validation: 0.9803373314323907]
	TIME [epoch: 10.3 sec]
EPOCH 369/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7666787740116798		[learning rate: 0.0018525]
	Learning Rate: 0.00185249
	LOSS [training: 0.7666787740116798 | validation: 1.099309423050811]
	TIME [epoch: 10.3 sec]
EPOCH 370/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7318514608300006		[learning rate: 0.0018438]
	Learning Rate: 0.0018438
	LOSS [training: 0.7318514608300006 | validation: 1.1725702731390333]
	TIME [epoch: 10.3 sec]
EPOCH 371/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8520376086582621		[learning rate: 0.0018352]
	Learning Rate: 0.00183516
	LOSS [training: 0.8520376086582621 | validation: 0.6810623663118532]
	TIME [epoch: 10.3 sec]
EPOCH 372/500:
	Training over batches...
		[batch 5/5] avg loss: 0.733288287888875		[learning rate: 0.0018266]
	Learning Rate: 0.00182655
	LOSS [training: 0.733288287888875 | validation: 0.6515080803176436]
	TIME [epoch: 10.3 sec]
EPOCH 373/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6862489051512828		[learning rate: 0.001818]
	Learning Rate: 0.00181799
	LOSS [training: 0.6862489051512828 | validation: 0.6394711589846207]
	TIME [epoch: 10.3 sec]
EPOCH 374/500:
	Training over batches...
		[batch 5/5] avg loss: 0.761761115883773		[learning rate: 0.0018095]
	Learning Rate: 0.00180947
	LOSS [training: 0.761761115883773 | validation: 0.8354025891048136]
	TIME [epoch: 10.3 sec]
EPOCH 375/500:
	Training over batches...
		[batch 5/5] avg loss: 0.765482019678713		[learning rate: 0.001801]
	Learning Rate: 0.00180099
	LOSS [training: 0.765482019678713 | validation: 0.7016933147469989]
	TIME [epoch: 10.3 sec]
EPOCH 376/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6878954947132531		[learning rate: 0.0017925]
	Learning Rate: 0.00179254
	LOSS [training: 0.6878954947132531 | validation: 0.6538634617037886]
	TIME [epoch: 10.3 sec]
EPOCH 377/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6630194860100148		[learning rate: 0.0017841]
	Learning Rate: 0.00178414
	LOSS [training: 0.6630194860100148 | validation: 0.6263329500412729]
	TIME [epoch: 10.3 sec]
EPOCH 378/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6728886006539124		[learning rate: 0.0017758]
	Learning Rate: 0.00177577
	LOSS [training: 0.6728886006539124 | validation: 0.5804793818610275]
	TIME [epoch: 10.3 sec]
EPOCH 379/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7420605389981858		[learning rate: 0.0017674]
	Learning Rate: 0.00176745
	LOSS [training: 0.7420605389981858 | validation: 0.5680021994046187]
	TIME [epoch: 10.3 sec]
EPOCH 380/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1157917849381984		[learning rate: 0.0017592]
	Learning Rate: 0.00175916
	LOSS [training: 1.1157917849381984 | validation: 0.9340871931350314]
	TIME [epoch: 10.3 sec]
EPOCH 381/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6768086685987585		[learning rate: 0.0017509]
	Learning Rate: 0.00175092
	LOSS [training: 0.6768086685987585 | validation: 0.5813014887636483]
	TIME [epoch: 10.3 sec]
EPOCH 382/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6472469001919133		[learning rate: 0.0017427]
	Learning Rate: 0.00174271
	LOSS [training: 0.6472469001919133 | validation: 0.9066151515895602]
	TIME [epoch: 10.3 sec]
EPOCH 383/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8133180480915316		[learning rate: 0.0017345]
	Learning Rate: 0.00173454
	LOSS [training: 0.8133180480915316 | validation: 0.8100892681290958]
	TIME [epoch: 10.3 sec]
EPOCH 384/500:
	Training over batches...
		[batch 5/5] avg loss: 0.727958273174883		[learning rate: 0.0017264]
	Learning Rate: 0.00172641
	LOSS [training: 0.727958273174883 | validation: 0.6706522655778164]
	TIME [epoch: 10.3 sec]
EPOCH 385/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6072832940055499		[learning rate: 0.0017183]
	Learning Rate: 0.00171831
	LOSS [training: 0.6072832940055499 | validation: 0.7288905362831994]
	TIME [epoch: 10.3 sec]
EPOCH 386/500:
	Training over batches...
		[batch 5/5] avg loss: 0.749623097280989		[learning rate: 0.0017103]
	Learning Rate: 0.00171026
	LOSS [training: 0.749623097280989 | validation: 1.1577663267449034]
	TIME [epoch: 10.3 sec]
EPOCH 387/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8035090654371034		[learning rate: 0.0017022]
	Learning Rate: 0.00170224
	LOSS [training: 0.8035090654371034 | validation: 0.5753454189967373]
	TIME [epoch: 10.3 sec]
EPOCH 388/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6942827697550398		[learning rate: 0.0016943]
	Learning Rate: 0.00169426
	LOSS [training: 0.6942827697550398 | validation: 0.6721919961687542]
	TIME [epoch: 10.3 sec]
EPOCH 389/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7691180754344394		[learning rate: 0.0016863]
	Learning Rate: 0.00168632
	LOSS [training: 0.7691180754344394 | validation: 0.7003968336809476]
	TIME [epoch: 10.3 sec]
EPOCH 390/500:
	Training over batches...
		[batch 5/5] avg loss: 0.634063799122411		[learning rate: 0.0016784]
	Learning Rate: 0.00167841
	LOSS [training: 0.634063799122411 | validation: 0.5510862458310554]
	TIME [epoch: 10.3 sec]
EPOCH 391/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6118489749937197		[learning rate: 0.0016705]
	Learning Rate: 0.00167054
	LOSS [training: 0.6118489749937197 | validation: 0.6212891814061025]
	TIME [epoch: 10.3 sec]
EPOCH 392/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6769280478374039		[learning rate: 0.0016627]
	Learning Rate: 0.00166271
	LOSS [training: 0.6769280478374039 | validation: 0.5056107585774515]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_392.pth
	Model improved!!!
EPOCH 393/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6012635760831325		[learning rate: 0.0016549]
	Learning Rate: 0.00165491
	LOSS [training: 0.6012635760831325 | validation: 0.7943670504554368]
	TIME [epoch: 10.3 sec]
EPOCH 394/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7980060752058772		[learning rate: 0.0016472]
	Learning Rate: 0.00164716
	LOSS [training: 0.7980060752058772 | validation: 1.1705975350400037]
	TIME [epoch: 10.3 sec]
EPOCH 395/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8860885014732703		[learning rate: 0.0016394]
	Learning Rate: 0.00163943
	LOSS [training: 0.8860885014732703 | validation: 0.6056019291723321]
	TIME [epoch: 10.3 sec]
EPOCH 396/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7748166129535756		[learning rate: 0.0016317]
	Learning Rate: 0.00163175
	LOSS [training: 0.7748166129535756 | validation: 1.126617231064573]
	TIME [epoch: 10.3 sec]
EPOCH 397/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9450823341052059		[learning rate: 0.0016241]
	Learning Rate: 0.0016241
	LOSS [training: 0.9450823341052059 | validation: 0.6580000742327436]
	TIME [epoch: 10.3 sec]
EPOCH 398/500:
	Training over batches...
		[batch 5/5] avg loss: 0.850537687851461		[learning rate: 0.0016165]
	Learning Rate: 0.00161648
	LOSS [training: 0.850537687851461 | validation: 1.1115135300862335]
	TIME [epoch: 10.3 sec]
EPOCH 399/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6105246268933285		[learning rate: 0.0016089]
	Learning Rate: 0.00160891
	LOSS [training: 0.6105246268933285 | validation: 0.6283420117648054]
	TIME [epoch: 10.3 sec]
EPOCH 400/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7026844813521411		[learning rate: 0.0016014]
	Learning Rate: 0.00160136
	LOSS [training: 0.7026844813521411 | validation: 0.887269340384206]
	TIME [epoch: 10.3 sec]
EPOCH 401/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5845145991738538		[learning rate: 0.0015939]
	Learning Rate: 0.00159386
	LOSS [training: 0.5845145991738538 | validation: 0.6073302011525131]
	TIME [epoch: 10.3 sec]
EPOCH 402/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6075670238276506		[learning rate: 0.0015864]
	Learning Rate: 0.00158638
	LOSS [training: 0.6075670238276506 | validation: 0.6547617420986717]
	TIME [epoch: 10.3 sec]
EPOCH 403/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5770251347641869		[learning rate: 0.0015789]
	Learning Rate: 0.00157895
	LOSS [training: 0.5770251347641869 | validation: 0.5063746719119162]
	TIME [epoch: 10.3 sec]
EPOCH 404/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7202616441411871		[learning rate: 0.0015715]
	Learning Rate: 0.00157154
	LOSS [training: 0.7202616441411871 | validation: 0.8728808563741447]
	TIME [epoch: 10.3 sec]
EPOCH 405/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6271451704538957		[learning rate: 0.0015642]
	Learning Rate: 0.00156418
	LOSS [training: 0.6271451704538957 | validation: 0.5413796388945845]
	TIME [epoch: 10.3 sec]
EPOCH 406/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6364681086088322		[learning rate: 0.0015568]
	Learning Rate: 0.00155684
	LOSS [training: 0.6364681086088322 | validation: 0.592769334557123]
	TIME [epoch: 10.3 sec]
EPOCH 407/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6364529413076786		[learning rate: 0.0015495]
	Learning Rate: 0.00154954
	LOSS [training: 0.6364529413076786 | validation: 0.5793884950281328]
	TIME [epoch: 10.3 sec]
EPOCH 408/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6736256567875185		[learning rate: 0.0015423]
	Learning Rate: 0.00154228
	LOSS [training: 0.6736256567875185 | validation: 0.6618740424525978]
	TIME [epoch: 10.3 sec]
EPOCH 409/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7534990923849767		[learning rate: 0.001535]
	Learning Rate: 0.00153505
	LOSS [training: 0.7534990923849767 | validation: 0.6702188195575859]
	TIME [epoch: 10.3 sec]
EPOCH 410/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7788280545623979		[learning rate: 0.0015279]
	Learning Rate: 0.00152785
	LOSS [training: 0.7788280545623979 | validation: 0.8451499735646317]
	TIME [epoch: 10.3 sec]
EPOCH 411/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7783650076145433		[learning rate: 0.0015207]
	Learning Rate: 0.00152069
	LOSS [training: 0.7783650076145433 | validation: 0.7238218339126121]
	TIME [epoch: 10.3 sec]
EPOCH 412/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7082285621066272		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.7082285621066272 | validation: 0.7579232266034179]
	TIME [epoch: 10.3 sec]
EPOCH 413/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5502339340015947		[learning rate: 0.0015065]
	Learning Rate: 0.00150647
	LOSS [training: 0.5502339340015947 | validation: 0.5351147098998775]
	TIME [epoch: 10.3 sec]
EPOCH 414/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5376342762128198		[learning rate: 0.0014994]
	Learning Rate: 0.0014994
	LOSS [training: 0.5376342762128198 | validation: 0.5575811973530485]
	TIME [epoch: 10.3 sec]
EPOCH 415/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6171753531554689		[learning rate: 0.0014924]
	Learning Rate: 0.00149237
	LOSS [training: 0.6171753531554689 | validation: 0.5125986014349769]
	TIME [epoch: 10.3 sec]
EPOCH 416/500:
	Training over batches...
		[batch 5/5] avg loss: 0.542855769045805		[learning rate: 0.0014854]
	Learning Rate: 0.00148538
	LOSS [training: 0.542855769045805 | validation: 0.6740931872959423]
	TIME [epoch: 10.3 sec]
EPOCH 417/500:
	Training over batches...
		[batch 5/5] avg loss: 0.689105840154299		[learning rate: 0.0014784]
	Learning Rate: 0.00147841
	LOSS [training: 0.689105840154299 | validation: 0.5629948104355437]
	TIME [epoch: 10.3 sec]
EPOCH 418/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6126563471441229		[learning rate: 0.0014715]
	Learning Rate: 0.00147148
	LOSS [training: 0.6126563471441229 | validation: 0.6879188887909662]
	TIME [epoch: 10.3 sec]
EPOCH 419/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6335102412412155		[learning rate: 0.0014646]
	Learning Rate: 0.00146458
	LOSS [training: 0.6335102412412155 | validation: 0.4587419414332516]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_419.pth
	Model improved!!!
EPOCH 420/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6313661360296023		[learning rate: 0.0014577]
	Learning Rate: 0.00145772
	LOSS [training: 0.6313661360296023 | validation: 0.8124249276306209]
	TIME [epoch: 10.3 sec]
EPOCH 421/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5992412771678816		[learning rate: 0.0014509]
	Learning Rate: 0.00145088
	LOSS [training: 0.5992412771678816 | validation: 0.8141333389545728]
	TIME [epoch: 10.3 sec]
EPOCH 422/500:
	Training over batches...
		[batch 5/5] avg loss: 0.662365743632231		[learning rate: 0.0014441]
	Learning Rate: 0.00144408
	LOSS [training: 0.662365743632231 | validation: 0.9251000142121183]
	TIME [epoch: 10.3 sec]
EPOCH 423/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6334145856644126		[learning rate: 0.0014373]
	Learning Rate: 0.00143731
	LOSS [training: 0.6334145856644126 | validation: 0.6470871053291234]
	TIME [epoch: 10.3 sec]
EPOCH 424/500:
	Training over batches...
		[batch 5/5] avg loss: 0.63130267108848		[learning rate: 0.0014306]
	Learning Rate: 0.00143057
	LOSS [training: 0.63130267108848 | validation: 1.002945676970675]
	TIME [epoch: 10.3 sec]
EPOCH 425/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6723701133518609		[learning rate: 0.0014239]
	Learning Rate: 0.00142387
	LOSS [training: 0.6723701133518609 | validation: 0.6400956924582966]
	TIME [epoch: 10.3 sec]
EPOCH 426/500:
	Training over batches...
		[batch 5/5] avg loss: 0.605920108059179		[learning rate: 0.0014172]
	Learning Rate: 0.00141719
	LOSS [training: 0.605920108059179 | validation: 0.7474696724428838]
	TIME [epoch: 10.3 sec]
EPOCH 427/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5843032980905221		[learning rate: 0.0014105]
	Learning Rate: 0.00141055
	LOSS [training: 0.5843032980905221 | validation: 0.7186385784841497]
	TIME [epoch: 10.3 sec]
EPOCH 428/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5853135309624972		[learning rate: 0.0014039]
	Learning Rate: 0.00140393
	LOSS [training: 0.5853135309624972 | validation: 0.4659327644296659]
	TIME [epoch: 10.3 sec]
EPOCH 429/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5394557440334392		[learning rate: 0.0013974]
	Learning Rate: 0.00139735
	LOSS [training: 0.5394557440334392 | validation: 0.5005576658100814]
	TIME [epoch: 10.3 sec]
EPOCH 430/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6117514029289733		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.6117514029289733 | validation: 0.6867329134039339]
	TIME [epoch: 10.3 sec]
EPOCH 431/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5601791210116485		[learning rate: 0.0013843]
	Learning Rate: 0.00138428
	LOSS [training: 0.5601791210116485 | validation: 0.5162160887981293]
	TIME [epoch: 10.3 sec]
EPOCH 432/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5919033039996859		[learning rate: 0.0013778]
	Learning Rate: 0.00137779
	LOSS [training: 0.5919033039996859 | validation: 0.5342929948716868]
	TIME [epoch: 10.3 sec]
EPOCH 433/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7492591567768718		[learning rate: 0.0013713]
	Learning Rate: 0.00137133
	LOSS [training: 0.7492591567768718 | validation: 0.9836406648512651]
	TIME [epoch: 10.3 sec]
EPOCH 434/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6482175139871912		[learning rate: 0.0013649]
	Learning Rate: 0.0013649
	LOSS [training: 0.6482175139871912 | validation: 0.8206621144080813]
	TIME [epoch: 10.3 sec]
EPOCH 435/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8031274178606346		[learning rate: 0.0013585]
	Learning Rate: 0.0013585
	LOSS [training: 0.8031274178606346 | validation: 0.7886793588813632]
	TIME [epoch: 10.3 sec]
EPOCH 436/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5955846850359798		[learning rate: 0.0013521]
	Learning Rate: 0.00135214
	LOSS [training: 0.5955846850359798 | validation: 0.6117480110518728]
	TIME [epoch: 10.3 sec]
EPOCH 437/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5827141986010013		[learning rate: 0.0013458]
	Learning Rate: 0.0013458
	LOSS [training: 0.5827141986010013 | validation: 0.6997719085594364]
	TIME [epoch: 10.3 sec]
EPOCH 438/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7204342669316031		[learning rate: 0.0013395]
	Learning Rate: 0.00133949
	LOSS [training: 0.7204342669316031 | validation: 0.6878809901005525]
	TIME [epoch: 10.3 sec]
EPOCH 439/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6015752417188023		[learning rate: 0.0013332]
	Learning Rate: 0.00133321
	LOSS [training: 0.6015752417188023 | validation: 0.6630408764142731]
	TIME [epoch: 10.3 sec]
EPOCH 440/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5631781561092567		[learning rate: 0.001327]
	Learning Rate: 0.00132696
	LOSS [training: 0.5631781561092567 | validation: 0.642850850793832]
	TIME [epoch: 10.3 sec]
EPOCH 441/500:
	Training over batches...
		[batch 5/5] avg loss: 0.567127658240375		[learning rate: 0.0013207]
	Learning Rate: 0.00132074
	LOSS [training: 0.567127658240375 | validation: 0.5952582128762949]
	TIME [epoch: 10.3 sec]
EPOCH 442/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6208297710706849		[learning rate: 0.0013145]
	Learning Rate: 0.00131454
	LOSS [training: 0.6208297710706849 | validation: 0.7615516467721518]
	TIME [epoch: 10.3 sec]
EPOCH 443/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5428964868517576		[learning rate: 0.0013084]
	Learning Rate: 0.00130838
	LOSS [training: 0.5428964868517576 | validation: 0.9844241634598785]
	TIME [epoch: 10.3 sec]
EPOCH 444/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5584569077750337		[learning rate: 0.0013022]
	Learning Rate: 0.00130225
	LOSS [training: 0.5584569077750337 | validation: 0.8391635114032029]
	TIME [epoch: 10.3 sec]
EPOCH 445/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6387541701060999		[learning rate: 0.0012961]
	Learning Rate: 0.00129614
	LOSS [training: 0.6387541701060999 | validation: 0.5949074345872586]
	TIME [epoch: 10.3 sec]
EPOCH 446/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5808121075296201		[learning rate: 0.0012901]
	Learning Rate: 0.00129007
	LOSS [training: 0.5808121075296201 | validation: 0.6709260893319596]
	TIME [epoch: 10.3 sec]
EPOCH 447/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6013856126168381		[learning rate: 0.001284]
	Learning Rate: 0.00128402
	LOSS [training: 0.6013856126168381 | validation: 0.6029043773041507]
	TIME [epoch: 10.3 sec]
EPOCH 448/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6615900504935147		[learning rate: 0.001278]
	Learning Rate: 0.001278
	LOSS [training: 0.6615900504935147 | validation: 0.6807254583340655]
	TIME [epoch: 10.3 sec]
EPOCH 449/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7262567655130885		[learning rate: 0.001272]
	Learning Rate: 0.00127201
	LOSS [training: 0.7262567655130885 | validation: 0.6282677605650651]
	TIME [epoch: 10.3 sec]
EPOCH 450/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6581416973531933		[learning rate: 0.001266]
	Learning Rate: 0.00126604
	LOSS [training: 0.6581416973531933 | validation: 0.7421451865599156]
	TIME [epoch: 10.3 sec]
EPOCH 451/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6555959860415009		[learning rate: 0.0012601]
	Learning Rate: 0.00126011
	LOSS [training: 0.6555959860415009 | validation: 0.9186948353137879]
	TIME [epoch: 10.3 sec]
EPOCH 452/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6647276125752548		[learning rate: 0.0012542]
	Learning Rate: 0.0012542
	LOSS [training: 0.6647276125752548 | validation: 0.5796907047539402]
	TIME [epoch: 10.3 sec]
EPOCH 453/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6879364830527511		[learning rate: 0.0012483]
	Learning Rate: 0.00124832
	LOSS [training: 0.6879364830527511 | validation: 1.0860234442957044]
	TIME [epoch: 10.3 sec]
EPOCH 454/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6997824433610006		[learning rate: 0.0012425]
	Learning Rate: 0.00124247
	LOSS [training: 0.6997824433610006 | validation: 0.6626276068592662]
	TIME [epoch: 10.3 sec]
EPOCH 455/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5335766608728412		[learning rate: 0.0012366]
	Learning Rate: 0.00123664
	LOSS [training: 0.5335766608728412 | validation: 0.8636975770779856]
	TIME [epoch: 10.3 sec]
EPOCH 456/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6518125204863775		[learning rate: 0.0012308]
	Learning Rate: 0.00123085
	LOSS [training: 0.6518125204863775 | validation: 0.5172584387484116]
	TIME [epoch: 10.3 sec]
EPOCH 457/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5549780040552449		[learning rate: 0.0012251]
	Learning Rate: 0.00122508
	LOSS [training: 0.5549780040552449 | validation: 0.5600155603960582]
	TIME [epoch: 10.3 sec]
EPOCH 458/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5699454215306845		[learning rate: 0.0012193]
	Learning Rate: 0.00121933
	LOSS [training: 0.5699454215306845 | validation: 0.5860161257389871]
	TIME [epoch: 10.3 sec]
EPOCH 459/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6072603671304199		[learning rate: 0.0012136]
	Learning Rate: 0.00121362
	LOSS [training: 0.6072603671304199 | validation: 0.6227607550409917]
	TIME [epoch: 10.3 sec]
EPOCH 460/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5706870451599118		[learning rate: 0.0012079]
	Learning Rate: 0.00120793
	LOSS [training: 0.5706870451599118 | validation: 0.5215487488495242]
	TIME [epoch: 10.3 sec]
EPOCH 461/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4944288295947933		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.4944288295947933 | validation: 0.5937137842361141]
	TIME [epoch: 10.3 sec]
EPOCH 462/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5807533422813187		[learning rate: 0.0011966]
	Learning Rate: 0.00119663
	LOSS [training: 0.5807533422813187 | validation: 0.5375778851447053]
	TIME [epoch: 10.3 sec]
EPOCH 463/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5150490992078712		[learning rate: 0.001191]
	Learning Rate: 0.00119102
	LOSS [training: 0.5150490992078712 | validation: 0.636427244728073]
	TIME [epoch: 10.3 sec]
EPOCH 464/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5147969987749699		[learning rate: 0.0011854]
	Learning Rate: 0.00118543
	LOSS [training: 0.5147969987749699 | validation: 0.817424417165772]
	TIME [epoch: 10.3 sec]
EPOCH 465/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6869479065661442		[learning rate: 0.0011799]
	Learning Rate: 0.00117988
	LOSS [training: 0.6869479065661442 | validation: 0.5643368014563754]
	TIME [epoch: 10.3 sec]
EPOCH 466/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5891521454270098		[learning rate: 0.0011743]
	Learning Rate: 0.00117435
	LOSS [training: 0.5891521454270098 | validation: 1.0616269315206297]
	TIME [epoch: 10.3 sec]
EPOCH 467/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6646327214794999		[learning rate: 0.0011688]
	Learning Rate: 0.00116884
	LOSS [training: 0.6646327214794999 | validation: 0.6814768961287497]
	TIME [epoch: 10.3 sec]
EPOCH 468/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5445046947426686		[learning rate: 0.0011634]
	Learning Rate: 0.00116336
	LOSS [training: 0.5445046947426686 | validation: 0.7396027041083052]
	TIME [epoch: 10.3 sec]
EPOCH 469/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6438613761522648		[learning rate: 0.0011579]
	Learning Rate: 0.00115791
	LOSS [training: 0.6438613761522648 | validation: 0.7019622121598778]
	TIME [epoch: 10.3 sec]
EPOCH 470/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6017372319720375		[learning rate: 0.0011525]
	Learning Rate: 0.00115248
	LOSS [training: 0.6017372319720375 | validation: 0.6132102974248582]
	TIME [epoch: 10.3 sec]
EPOCH 471/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4844061779012681		[learning rate: 0.0011471]
	Learning Rate: 0.00114708
	LOSS [training: 0.4844061779012681 | validation: 0.556145590669892]
	TIME [epoch: 10.3 sec]
EPOCH 472/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5412277999071378		[learning rate: 0.0011417]
	Learning Rate: 0.0011417
	LOSS [training: 0.5412277999071378 | validation: 0.5722596689772159]
	TIME [epoch: 10.3 sec]
EPOCH 473/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5494023244710686		[learning rate: 0.0011363]
	Learning Rate: 0.00113635
	LOSS [training: 0.5494023244710686 | validation: 0.5286854866784387]
	TIME [epoch: 10.3 sec]
EPOCH 474/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5459751423327007		[learning rate: 0.001131]
	Learning Rate: 0.00113102
	LOSS [training: 0.5459751423327007 | validation: 0.5922538455451577]
	TIME [epoch: 10.3 sec]
EPOCH 475/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5037780160742275		[learning rate: 0.0011257]
	Learning Rate: 0.00112572
	LOSS [training: 0.5037780160742275 | validation: 0.42804433779596296]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_475.pth
	Model improved!!!
EPOCH 476/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5079757482402483		[learning rate: 0.0011204]
	Learning Rate: 0.00112044
	LOSS [training: 0.5079757482402483 | validation: 0.6519169164460723]
	TIME [epoch: 10.3 sec]
EPOCH 477/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7362960842069712		[learning rate: 0.0011152]
	Learning Rate: 0.00111518
	LOSS [training: 0.7362960842069712 | validation: 0.9689536262162921]
	TIME [epoch: 10.3 sec]
EPOCH 478/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8641289650171124		[learning rate: 0.00111]
	Learning Rate: 0.00110996
	LOSS [training: 0.8641289650171124 | validation: 1.790100888023559]
	TIME [epoch: 10.3 sec]
EPOCH 479/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8416237590351934		[learning rate: 0.0011048]
	Learning Rate: 0.00110475
	LOSS [training: 0.8416237590351934 | validation: 0.45952854213432387]
	TIME [epoch: 10.3 sec]
EPOCH 480/500:
	Training over batches...
		[batch 5/5] avg loss: 0.495111531488386		[learning rate: 0.0010996]
	Learning Rate: 0.00109957
	LOSS [training: 0.495111531488386 | validation: 0.44731749024862183]
	TIME [epoch: 10.3 sec]
EPOCH 481/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5053127709316679		[learning rate: 0.0010944]
	Learning Rate: 0.00109442
	LOSS [training: 0.5053127709316679 | validation: 0.5896911733579827]
	TIME [epoch: 10.3 sec]
EPOCH 482/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7244879591667238		[learning rate: 0.0010893]
	Learning Rate: 0.00108929
	LOSS [training: 0.7244879591667238 | validation: 0.47372534594577287]
	TIME [epoch: 10.3 sec]
EPOCH 483/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5142805772653364		[learning rate: 0.0010842]
	Learning Rate: 0.00108418
	LOSS [training: 0.5142805772653364 | validation: 0.4263409291355941]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_483.pth
	Model improved!!!
EPOCH 484/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5975673848005953		[learning rate: 0.0010791]
	Learning Rate: 0.0010791
	LOSS [training: 0.5975673848005953 | validation: 0.5001830574428144]
	TIME [epoch: 10.3 sec]
EPOCH 485/500:
	Training over batches...
		[batch 5/5] avg loss: 0.536240043929693		[learning rate: 0.001074]
	Learning Rate: 0.00107404
	LOSS [training: 0.536240043929693 | validation: 0.48980887330306105]
	TIME [epoch: 10.3 sec]
EPOCH 486/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5026231602071737		[learning rate: 0.001069]
	Learning Rate: 0.001069
	LOSS [training: 0.5026231602071737 | validation: 0.450846086319457]
	TIME [epoch: 10.3 sec]
EPOCH 487/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4941340509408646		[learning rate: 0.001064]
	Learning Rate: 0.00106399
	LOSS [training: 0.4941340509408646 | validation: 0.4849486531528441]
	TIME [epoch: 10.3 sec]
EPOCH 488/500:
	Training over batches...
		[batch 5/5] avg loss: 0.500042821698884		[learning rate: 0.001059]
	Learning Rate: 0.001059
	LOSS [training: 0.500042821698884 | validation: 0.47068238861988565]
	TIME [epoch: 10.3 sec]
EPOCH 489/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5129631439011298		[learning rate: 0.001054]
	Learning Rate: 0.00105404
	LOSS [training: 0.5129631439011298 | validation: 0.5800321975228874]
	TIME [epoch: 10.3 sec]
EPOCH 490/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5017768856445379		[learning rate: 0.0010491]
	Learning Rate: 0.0010491
	LOSS [training: 0.5017768856445379 | validation: 0.4754938359531109]
	TIME [epoch: 10.3 sec]
EPOCH 491/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45901633948342724		[learning rate: 0.0010442]
	Learning Rate: 0.00104418
	LOSS [training: 0.45901633948342724 | validation: 0.5377457734954154]
	TIME [epoch: 10.3 sec]
EPOCH 492/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4862320663523855		[learning rate: 0.0010393]
	Learning Rate: 0.00103929
	LOSS [training: 0.4862320663523855 | validation: 0.4592555047402952]
	TIME [epoch: 10.3 sec]
EPOCH 493/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48400324726684224		[learning rate: 0.0010344]
	Learning Rate: 0.00103441
	LOSS [training: 0.48400324726684224 | validation: 0.5886821716936176]
	TIME [epoch: 10.3 sec]
EPOCH 494/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5356571744544663		[learning rate: 0.0010296]
	Learning Rate: 0.00102956
	LOSS [training: 0.5356571744544663 | validation: 0.514866482897692]
	TIME [epoch: 10.3 sec]
EPOCH 495/500:
	Training over batches...
		[batch 5/5] avg loss: 0.44218704586862306		[learning rate: 0.0010247]
	Learning Rate: 0.00102474
	LOSS [training: 0.44218704586862306 | validation: 0.49943558198096183]
	TIME [epoch: 10.3 sec]
EPOCH 496/500:
	Training over batches...
		[batch 5/5] avg loss: 0.49253633372887834		[learning rate: 0.0010199]
	Learning Rate: 0.00101993
	LOSS [training: 0.49253633372887834 | validation: 0.42324189920193533]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r0_20240214_234909/states/model_tr_study5_496.pth
	Model improved!!!
EPOCH 497/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5941116049687089		[learning rate: 0.0010152]
	Learning Rate: 0.00101515
	LOSS [training: 0.5941116049687089 | validation: 0.5910507075908682]
	TIME [epoch: 10.3 sec]
EPOCH 498/500:
	Training over batches...
		[batch 5/5] avg loss: 0.736538062521152		[learning rate: 0.0010104]
	Learning Rate: 0.00101039
	LOSS [training: 0.736538062521152 | validation: 1.0847765893821801]
	TIME [epoch: 10.3 sec]
EPOCH 499/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6188895844684552		[learning rate: 0.0010057]
	Learning Rate: 0.00100565
	LOSS [training: 0.6188895844684552 | validation: 0.4951859055409177]
	TIME [epoch: 10.3 sec]
EPOCH 500/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4666061608533981		[learning rate: 0.0010009]
	Learning Rate: 0.00100094
	LOSS [training: 0.4666061608533981 | validation: 0.5170173581848414]
	TIME [epoch: 10.3 sec]
Finished training in 5217.765 seconds.
