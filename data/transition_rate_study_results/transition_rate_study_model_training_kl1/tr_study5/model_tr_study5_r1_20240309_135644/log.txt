Args:
Namespace(name='model_tr_study5', outdir='out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1', training_data='data/transition_rate_studies/tr_study5/tr_study5_training/r1', validation_data='data/transition_rate_studies/tr_study5/tr_study5_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4241879934

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.285337606975975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.285337606975975 | validation: 9.47199140247708]
	TIME [epoch: 113 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.938717903794565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.938717903794565 | validation: 9.388051971248808]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.393037362529013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.393037362529013 | validation: 8.770789835419997]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.481781632973111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.481781632973111 | validation: 7.760277524932683]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.079959009280239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.079959009280239 | validation: 8.207265169380541]
	TIME [epoch: 24.8 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.421134624592833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.421134624592833 | validation: 7.353068497756837]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.886510871326497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.886510871326497 | validation: 7.343159718462514]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.707646831041426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.707646831041426 | validation: 7.183086393058342]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.65696888522081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.65696888522081 | validation: 6.749320260657302]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.499781518451735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.499781518451735 | validation: 6.626710435775431]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.271523280271525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.271523280271525 | validation: 6.436096373862996]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.165419003325879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.165419003325879 | validation: 6.157751931949012]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.089695020403708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.089695020403708 | validation: 6.328411884333964]
	TIME [epoch: 24.8 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.100560109093618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.100560109093618 | validation: 6.162923260916292]
	TIME [epoch: 24.8 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.892608086218435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.892608086218435 | validation: 5.973792403916304]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.896104096431037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.896104096431037 | validation: 5.85701529779699]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.8489104563670455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8489104563670455 | validation: 5.852839015797579]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.868753906100534		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.868753906100534 | validation: 5.674732877362872]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.835641096067709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.835641096067709 | validation: 5.810641904957516]
	TIME [epoch: 24.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.819871236147129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.819871236147129 | validation: 5.981950272519432]
	TIME [epoch: 24.9 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.980702060178466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.980702060178466 | validation: 5.6981969502744025]
	TIME [epoch: 24.9 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7301561954983855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7301561954983855 | validation: 5.584352211322]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.782289793512842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.782289793512842 | validation: 5.711133879173292]
	TIME [epoch: 24.9 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.714086484623808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.714086484623808 | validation: 5.695125853737482]
	TIME [epoch: 24.8 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.84029416563084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.84029416563084 | validation: 5.632397940547817]
	TIME [epoch: 24.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.779815146563119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.779815146563119 | validation: 5.645706715774042]
	TIME [epoch: 24.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.677459491089478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.677459491089478 | validation: 5.681128595666258]
	TIME [epoch: 24.8 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0236309007520665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0236309007520665 | validation: 5.768888446971325]
	TIME [epoch: 24.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.800484767561758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.800484767561758 | validation: 5.711826380048792]
	TIME [epoch: 24.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.678770766642289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.678770766642289 | validation: 5.528522442402666]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.636009432011564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.636009432011564 | validation: 5.595500250553878]
	TIME [epoch: 24.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.631072890666113		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.631072890666113 | validation: 5.517873369775548]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.636750738413479		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.636750738413479 | validation: 5.540107956306681]
	TIME [epoch: 24.8 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.562076948658917		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.562076948658917 | validation: 5.626185871874196]
	TIME [epoch: 24.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.591986685736648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.591986685736648 | validation: 5.447587179591112]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.50395565543103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.50395565543103 | validation: 5.5108986540714175]
	TIME [epoch: 24.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.666533268232904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.666533268232904 | validation: 5.544809258606031]
	TIME [epoch: 24.8 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5446240098374835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5446240098374835 | validation: 5.408151682076494]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.43690142865524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.43690142865524 | validation: 5.735202871282026]
	TIME [epoch: 24.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.605497673777922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.605497673777922 | validation: 5.602592826359249]
	TIME [epoch: 24.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.597930724161371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.597930724161371 | validation: 5.404982568775899]
	TIME [epoch: 25.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.452169200502457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.452169200502457 | validation: 5.86875087881698]
	TIME [epoch: 24.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.768626473155416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.768626473155416 | validation: 5.514660264852888]
	TIME [epoch: 24.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.534192866239306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.534192866239306 | validation: 5.342852172301796]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.520153542716157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.520153542716157 | validation: 5.294734964987501]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.401671789528371		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.401671789528371 | validation: 5.3613342018319505]
	TIME [epoch: 24.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.320867970515761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.320867970515761 | validation: 5.377047520500396]
	TIME [epoch: 24.8 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.796902605152971		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.796902605152971 | validation: 5.73450255579872]
	TIME [epoch: 24.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.51313206085646		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.51313206085646 | validation: 5.207073303813072]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.260845449029965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.260845449029965 | validation: 5.291949765087828]
	TIME [epoch: 24.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3464846151681344		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.3464846151681344 | validation: 5.096156596132073]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.318727690600955		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 5.318727690600955 | validation: 5.3659787801318]
	TIME [epoch: 24.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.230212498114143		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 5.230212498114143 | validation: 5.145071357251362]
	TIME [epoch: 24.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.128217591802759		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 5.128217591802759 | validation: 5.011472109538475]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.037594563370243		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 5.037594563370243 | validation: 4.827559616358111]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.996918730633902		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 4.996918730633902 | validation: 5.051905677229794]
	TIME [epoch: 24.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.0654443927951895		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 5.0654443927951895 | validation: 5.47153090368918]
	TIME [epoch: 24.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.820105414169717		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.820105414169717 | validation: 5.573765859286801]
	TIME [epoch: 24.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.371256626517348		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 5.371256626517348 | validation: 5.351338268704553]
	TIME [epoch: 24.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.840290540211717		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 5.840290540211717 | validation: 4.901655436197891]
	TIME [epoch: 24.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.091537910381841		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 5.091537910381841 | validation: 4.921783264210833]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.955662067294826		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.955662067294826 | validation: 5.21805888916714]
	TIME [epoch: 24.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.075490511805817		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 5.075490511805817 | validation: 5.105836873537144]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.033977752799252		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 5.033977752799252 | validation: 4.916327533942776]
	TIME [epoch: 24.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.774132576581537		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 4.774132576581537 | validation: 4.616711426032865]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.818028540910159		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 4.818028540910159 | validation: 5.041100247579313]
	TIME [epoch: 24.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.878066879320087		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.878066879320087 | validation: 4.676040190250663]
	TIME [epoch: 24.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.68477211144507		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 4.68477211144507 | validation: 4.543816414323992]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.542692436921131		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.542692436921131 | validation: 4.22808646404364]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.391088684468448		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 4.391088684468448 | validation: 7.754126518996088]
	TIME [epoch: 24.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.863353398944236		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 9.863353398944236 | validation: 8.044476214852708]
	TIME [epoch: 24.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.786080100494988		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 6.786080100494988 | validation: 5.126324585681823]
	TIME [epoch: 24.8 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.768787532027001		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.768787532027001 | validation: 4.399955348644901]
	TIME [epoch: 24.8 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.499896627643419		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 4.499896627643419 | validation: 4.536396565413987]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.407229929087498		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 5.407229929087498 | validation: 4.675413163474409]
	TIME [epoch: 24.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.859599771670264		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 4.859599771670264 | validation: 4.72435109329992]
	TIME [epoch: 24.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.40508197698372		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 4.40508197698372 | validation: 4.167648790070748]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.283804790771341		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 4.283804790771341 | validation: 4.116850666279719]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.080552995838026		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 4.080552995838026 | validation: 3.8421543036118857]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.165058189892247		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 4.165058189892247 | validation: 3.7439560460505015]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1380741701527395		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 4.1380741701527395 | validation: 4.584674083722894]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.883439502625599		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.883439502625599 | validation: 3.7549563368722794]
	TIME [epoch: 24.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.035411599561216		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.035411599561216 | validation: 3.8190528649958293]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9263906812891998		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.9263906812891998 | validation: 3.439235378854661]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.379690057715474		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 3.379690057715474 | validation: 3.536799422621023]
	TIME [epoch: 24.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5701647277095683		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.5701647277095683 | validation: 4.519043556498758]
	TIME [epoch: 24.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9213042752169667		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.9213042752169667 | validation: 4.737299835429467]
	TIME [epoch: 24.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.828492366450203		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.828492366450203 | validation: 3.6545704659670255]
	TIME [epoch: 24.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.347619117258913		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.347619117258913 | validation: 3.192511984722943]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0294488564738824		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.0294488564738824 | validation: 3.2495538647402964]
	TIME [epoch: 24.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4706063209408535		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 3.4706063209408535 | validation: 4.208534652220822]
	TIME [epoch: 24.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.43568272585075		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 4.43568272585075 | validation: 3.3040073456402848]
	TIME [epoch: 24.7 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0476569425853155		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.0476569425853155 | validation: 3.0401086077017054]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_93.pth
	Model improved!!!
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.12173392617208		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.12173392617208 | validation: 2.826115861554204]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4204750481430803		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.4204750481430803 | validation: 4.227693717736456]
	TIME [epoch: 24.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5003072475963055		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.5003072475963055 | validation: 4.9013637258707385]
	TIME [epoch: 24.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.827327197748653		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 6.827327197748653 | validation: 9.285491720676436]
	TIME [epoch: 24.8 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.358654872576988		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 8.358654872576988 | validation: 6.681553543001917]
	TIME [epoch: 24.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.952960460435555		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 7.952960460435555 | validation: 7.199430985138092]
	TIME [epoch: 24.7 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.922519092777922		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 6.922519092777922 | validation: 6.007422838225432]
	TIME [epoch: 24.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.000838508205916		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 6.000838508205916 | validation: 5.497895812023728]
	TIME [epoch: 24.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.832307228031692		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.832307228031692 | validation: 3.9492333413786054]
	TIME [epoch: 24.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.634784376800405		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.634784376800405 | validation: 3.6345783712309543]
	TIME [epoch: 24.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.020502085847095		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 4.020502085847095 | validation: 3.612130830350046]
	TIME [epoch: 24.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3009440217561865		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.3009440217561865 | validation: 3.4774276742116403]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2421794742808343		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.2421794742808343 | validation: 4.35164841733765]
	TIME [epoch: 24.7 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.841402124473872		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 3.841402124473872 | validation: 5.641795882284123]
	TIME [epoch: 24.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.745612241350881		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 4.745612241350881 | validation: 4.039457273733379]
	TIME [epoch: 24.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.020485028896697		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 4.020485028896697 | validation: 4.922811108395431]
	TIME [epoch: 24.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9413990031040282		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.9413990031040282 | validation: 6.128931011351349]
	TIME [epoch: 24.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.436588716474514		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 8.436588716474514 | validation: 8.389790796383672]
	TIME [epoch: 24.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.166380140050293		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 8.166380140050293 | validation: 6.654477545975423]
	TIME [epoch: 24.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.074548362091563		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 6.074548362091563 | validation: 4.31820859140929]
	TIME [epoch: 24.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7394050625280126		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 3.7394050625280126 | validation: 6.545199769668605]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.809877868888912		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 6.809877868888912 | validation: 6.036034870602942]
	TIME [epoch: 24.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.735419357481344		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 5.735419357481344 | validation: 6.570264203800581]
	TIME [epoch: 24.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.45204962927337		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 4.45204962927337 | validation: 2.718798848403146]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7184901228058695		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 3.7184901228058695 | validation: 3.193941635405431]
	TIME [epoch: 24.8 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1388627894818146		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 3.1388627894818146 | validation: 2.7931406991757037]
	TIME [epoch: 24.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.714185143297093		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.714185143297093 | validation: 2.9566433589363794]
	TIME [epoch: 24.8 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.840838111571727		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.840838111571727 | validation: 2.6454233531960827]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.124761255520006		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 5.124761255520006 | validation: 7.882677775824261]
	TIME [epoch: 24.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.329975866498683		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 7.329975866498683 | validation: 6.142885766192428]
	TIME [epoch: 24.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.314115754787904		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 6.314115754787904 | validation: 5.16645605368758]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.487887233677107		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 4.487887233677107 | validation: 3.2668609707614196]
	TIME [epoch: 24.8 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7442304356196483		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 3.7442304356196483 | validation: 3.1193103304038066]
	TIME [epoch: 24.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1385631836120194		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 3.1385631836120194 | validation: 3.1932777512622796]
	TIME [epoch: 24.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8991788716166353		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.8991788716166353 | validation: 2.972157475522603]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.721005141203955		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 6.721005141203955 | validation: 7.002676393785607]
	TIME [epoch: 24.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.953830936947458		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 6.953830936947458 | validation: 6.422195000593031]
	TIME [epoch: 24.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.505595981477453		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 6.505595981477453 | validation: 5.802169609942878]
	TIME [epoch: 24.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.091913208020332		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 7.091913208020332 | validation: 6.886990926968606]
	TIME [epoch: 24.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.3149357612069		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 7.3149357612069 | validation: 6.498032429643716]
	TIME [epoch: 24.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.103551237863465		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 7.103551237863465 | validation: 6.5204793554142215]
	TIME [epoch: 24.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.466381767653524		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 7.466381767653524 | validation: 6.660434510721068]
	TIME [epoch: 24.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.274015840938721		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 7.274015840938721 | validation: 6.569693215354333]
	TIME [epoch: 24.8 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.1970921954729645		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 7.1970921954729645 | validation: 6.616435745572635]
	TIME [epoch: 24.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.8825870992741285		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 7.8825870992741285 | validation: 6.757333448280271]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.449377865067207		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 7.449377865067207 | validation: 6.884808051553209]
	TIME [epoch: 24.8 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.21341443246671		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 7.21341443246671 | validation: 6.44404200806166]
	TIME [epoch: 24.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.059303393686803		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 7.059303393686803 | validation: 6.606289084094128]
	TIME [epoch: 24.7 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.08505904932813		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 7.08505904932813 | validation: 6.392797881501848]
	TIME [epoch: 24.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.892955427343179		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 6.892955427343179 | validation: 6.504691812847934]
	TIME [epoch: 24.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.951830872262017		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 6.951830872262017 | validation: 6.854993797720023]
	TIME [epoch: 24.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.500188788762717		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 7.500188788762717 | validation: 6.749459556113775]
	TIME [epoch: 24.7 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.3870412218192945		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 7.3870412218192945 | validation: 6.666171003858982]
	TIME [epoch: 24.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.297262426623019		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 7.297262426623019 | validation: 6.531871860823601]
	TIME [epoch: 24.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.025118596737904		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 7.025118596737904 | validation: 6.101442849290429]
	TIME [epoch: 24.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.505909644898155		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 6.505909644898155 | validation: 7.442154619727648]
	TIME [epoch: 24.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.327091235360446		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 6.327091235360446 | validation: 5.219893894210272]
	TIME [epoch: 24.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.147464221723812		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 5.147464221723812 | validation: 3.756765157743206]
	TIME [epoch: 24.8 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.787054557381879		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.787054557381879 | validation: 3.1744425565908485]
	TIME [epoch: 24.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3898900985098965		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 3.3898900985098965 | validation: 4.716416582636883]
	TIME [epoch: 24.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.799751213689423		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 3.799751213689423 | validation: 3.220259244429338]
	TIME [epoch: 24.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9297657077582517		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.9297657077582517 | validation: 2.8623448768729096]
	TIME [epoch: 24.8 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239565801376773		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.239565801376773 | validation: 4.707425067603723]
	TIME [epoch: 24.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.650300319777028		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 4.650300319777028 | validation: 3.6626412501672747]
	TIME [epoch: 24.8 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.838744684824187		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 4.838744684824187 | validation: 4.3637695231481075]
	TIME [epoch: 24.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.566574585646192		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.566574585646192 | validation: 2.9056568238641076]
	TIME [epoch: 24.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3767391894759378		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.3767391894759378 | validation: 2.9985755367655362]
	TIME [epoch: 24.8 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1858317210686393		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.1858317210686393 | validation: 3.6991611819166876]
	TIME [epoch: 24.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2517236484600844		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.2517236484600844 | validation: 3.114826812152172]
	TIME [epoch: 24.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.063387257992429		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 4.063387257992429 | validation: 3.7599765607809936]
	TIME [epoch: 24.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.570931147780235		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.570931147780235 | validation: 2.945391862624551]
	TIME [epoch: 24.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7914476095933694		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 2.7914476095933694 | validation: 2.634884323409466]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3835953518250537		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 2.3835953518250537 | validation: 3.1344347526245704]
	TIME [epoch: 24.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8568758662567406		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.8568758662567406 | validation: 3.666452263694532]
	TIME [epoch: 24.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7713820407572243		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.7713820407572243 | validation: 3.882408571246638]
	TIME [epoch: 24.9 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6893863161754896		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 3.6893863161754896 | validation: 3.9396182551969106]
	TIME [epoch: 24.8 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8483251746186573		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 3.8483251746186573 | validation: 3.668511781773343]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5891248590270997		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.5891248590270997 | validation: 3.4250263041487456]
	TIME [epoch: 24.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1078141971482456		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.1078141971482456 | validation: 3.2380007823612265]
	TIME [epoch: 24.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4945505044936627		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 2.4945505044936627 | validation: 2.2677066854612913]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.661028580799691		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 2.661028580799691 | validation: 3.8128819217736485]
	TIME [epoch: 24.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4680372726955895		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 5.4680372726955895 | validation: 5.924211737906233]
	TIME [epoch: 24.9 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.475024340467694		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 4.475024340467694 | validation: 3.699288963558061]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.705788262587114		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 2.705788262587114 | validation: 2.198282787238664]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1185719037131525		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 2.1185719037131525 | validation: 2.3722881455955473]
	TIME [epoch: 24.8 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.675739671237219		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.675739671237219 | validation: 6.094071414370799]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.348705372326734		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 4.348705372326734 | validation: 2.7754505593510586]
	TIME [epoch: 24.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6714104616510923		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 2.6714104616510923 | validation: 2.728333696119281]
	TIME [epoch: 24.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.388423765631341		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 2.388423765631341 | validation: 2.194111273846129]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.092754189334642		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 2.092754189334642 | validation: 2.2846647789554773]
	TIME [epoch: 24.8 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9620607240072614		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.9620607240072614 | validation: 2.166971824313589]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.370113320475476		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.370113320475476 | validation: 5.020845137162199]
	TIME [epoch: 24.7 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8370212764848777		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.8370212764848777 | validation: 2.3706463866446343]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.132210215211038		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.132210215211038 | validation: 5.034608800022806]
	TIME [epoch: 24.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.518995028075709		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 6.518995028075709 | validation: 5.992899333405356]
	TIME [epoch: 24.7 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.367169321231636		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 5.367169321231636 | validation: 3.567780890161639]
	TIME [epoch: 24.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4902113071055245		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 2.4902113071055245 | validation: 2.8941018560727843]
	TIME [epoch: 24.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5681835429275535		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 2.5681835429275535 | validation: 2.2822766220490722]
	TIME [epoch: 24.7 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0787353076492803		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 2.0787353076492803 | validation: 3.754318137179122]
	TIME [epoch: 24.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3889232581305873		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 3.3889232581305873 | validation: 2.880495000268136]
	TIME [epoch: 24.8 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.359436273003135		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 2.359436273003135 | validation: 1.9982178850285015]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_194.pth
	Model improved!!!
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.180777746099016		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 2.180777746099016 | validation: 2.645442330450603]
	TIME [epoch: 24.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.242214143190612		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 4.242214143190612 | validation: 2.620382775255457]
	TIME [epoch: 24.8 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.375730126755146		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 2.375730126755146 | validation: 4.234707309418592]
	TIME [epoch: 24.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.963803892995058		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 2.963803892995058 | validation: 2.652941424587915]
	TIME [epoch: 24.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1264705387622262		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 2.1264705387622262 | validation: 2.0990398220969935]
	TIME [epoch: 24.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.94381502415761		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.94381502415761 | validation: 2.046679279585004]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1009179752451304		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 2.1009179752451304 | validation: 2.571646085250685]
	TIME [epoch: 24.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0032875057056216		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 2.0032875057056216 | validation: 1.954533324331999]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_202.pth
	Model improved!!!
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8994266062336995		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.8994266062336995 | validation: 2.291533012042314]
	TIME [epoch: 24.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.115161595735329		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 2.115161595735329 | validation: 2.113647643044576]
	TIME [epoch: 24.8 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.93371565033441		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.93371565033441 | validation: 1.9123012489727353]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2574044418725316		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 2.2574044418725316 | validation: 2.1121459098454727]
	TIME [epoch: 24.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.752729890541373		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.752729890541373 | validation: 1.8261027850657738]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_207.pth
	Model improved!!!
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.922375945204608		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.922375945204608 | validation: 1.7316589629739412]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0351719966958215		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 2.0351719966958215 | validation: 1.9398602428305065]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6743317526818517		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.6743317526818517 | validation: 2.2169785295707163]
	TIME [epoch: 24.8 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7865629690737355		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.7865629690737355 | validation: 1.9072289255597485]
	TIME [epoch: 24.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.832234331337978		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 2.832234331337978 | validation: 3.5365414973029976]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.493169926568158		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 4.493169926568158 | validation: 3.6675540184263355]
	TIME [epoch: 24.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5115805060209273		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 3.5115805060209273 | validation: 2.318105387836254]
	TIME [epoch: 24.8 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9357665219177318		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.9357665219177318 | validation: 1.9473735340185072]
	TIME [epoch: 24.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.573744205029993		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.573744205029993 | validation: 1.5128966865348488]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4895179421323914		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.4895179421323914 | validation: 2.0440708233935028]
	TIME [epoch: 24.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4858959149590492		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.4858959149590492 | validation: 1.5580361646009357]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5061914526631834		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.5061914526631834 | validation: 1.6396127536239267]
	TIME [epoch: 24.8 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4753938472571206		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.4753938472571206 | validation: 6.542121352548494]
	TIME [epoch: 24.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.789198488130096		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 6.789198488130096 | validation: 5.395374001472451]
	TIME [epoch: 24.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.225176698955045		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 6.225176698955045 | validation: 5.540526848092731]
	TIME [epoch: 24.8 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.204319194517526		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 6.204319194517526 | validation: 5.793850938663816]
	TIME [epoch: 24.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.595607290804202		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 7.595607290804202 | validation: 7.166303049434134]
	TIME [epoch: 24.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.582205990040096		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 7.582205990040096 | validation: 4.287903533909234]
	TIME [epoch: 24.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3100233125108263		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 3.3100233125108263 | validation: 2.4673681495957562]
	TIME [epoch: 24.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6809719485434322		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 2.6809719485434322 | validation: 1.916356298948607]
	TIME [epoch: 24.7 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.942421458717288		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 1.942421458717288 | validation: 1.7281865751354173]
	TIME [epoch: 24.8 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5312077472463748		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 2.5312077472463748 | validation: 1.7450192757920968]
	TIME [epoch: 24.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.912445141779365		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.912445141779365 | validation: 1.5465155512336384]
	TIME [epoch: 24.7 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.378486226525207		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.378486226525207 | validation: 1.575240933070237]
	TIME [epoch: 24.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0332115943814264		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 2.0332115943814264 | validation: 1.7721669147349024]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4925657732421804		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.4925657732421804 | validation: 1.7547560806072398]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4956517430393195		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 1.4956517430393195 | validation: 1.670215308665437]
	TIME [epoch: 24.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6788673373088565		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.6788673373088565 | validation: 1.9905218398990543]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4012350067812442		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 1.4012350067812442 | validation: 1.4435955987585112]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2701728789837685		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.2701728789837685 | validation: 1.4053990741399236]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_237.pth
	Model improved!!!
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3368769188696517		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.3368769188696517 | validation: 1.400877089349837]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_238.pth
	Model improved!!!
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2114901795188258		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.2114901795188258 | validation: 1.584887463621182]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.555086941190298		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.555086941190298 | validation: 2.5869121234315937]
	TIME [epoch: 24.8 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.228471986419046		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 2.228471986419046 | validation: 1.8408175172057326]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4917839421147323		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.4917839421147323 | validation: 1.5787131339328568]
	TIME [epoch: 24.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2739923435180502		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.2739923435180502 | validation: 1.3068815326534182]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1355806378156597		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 1.1355806378156597 | validation: 1.3927905783947439]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3182475478465643		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 1.3182475478465643 | validation: 2.417059170796876]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7048126058287845		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 2.7048126058287845 | validation: 1.9759572454745962]
	TIME [epoch: 24.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4081311547286763		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 1.4081311547286763 | validation: 3.055643130783634]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.112478617570877		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 2.112478617570877 | validation: 1.8106937827637353]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2640715874414354		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 1.2640715874414354 | validation: 1.2553639375561145]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.776774288890172		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 1.776774288890172 | validation: 2.340492876141737]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8726721615878876		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 1.8726721615878876 | validation: 1.2673087067877413]
	TIME [epoch: 24.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.186656048320131		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 1.186656048320131 | validation: 1.4991800870329137]
	TIME [epoch: 24.8 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2938264287274999		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 1.2938264287274999 | validation: 1.4453188645682382]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1546694034666427		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 1.1546694034666427 | validation: 1.1410497442284098]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_254.pth
	Model improved!!!
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3453759671941943		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.3453759671941943 | validation: 1.8564792241581913]
	TIME [epoch: 24.8 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5286966059293607		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 1.5286966059293607 | validation: 1.854993229848986]
	TIME [epoch: 24.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8298042542294743		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 1.8298042542294743 | validation: 2.901389407343422]
	TIME [epoch: 24.8 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8729075496325778		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 1.8729075496325778 | validation: 1.4339841676532832]
	TIME [epoch: 24.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2754830232361545		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 1.2754830232361545 | validation: 1.887205743244295]
	TIME [epoch: 24.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2688000101318462		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.2688000101318462 | validation: 1.3725826548654385]
	TIME [epoch: 24.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2634717818007974		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.2634717818007974 | validation: 1.423976158841716]
	TIME [epoch: 24.8 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2982587407222816		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 1.2982587407222816 | validation: 1.4169500295083695]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.188758330803722		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 1.188758330803722 | validation: 1.515132313512695]
	TIME [epoch: 24.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2625159649869686		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.2625159649869686 | validation: 1.7508333676527965]
	TIME [epoch: 24.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7512292149064033		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 1.7512292149064033 | validation: 2.1231956684180475]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4269745231745457		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.4269745231745457 | validation: 1.3662455364593193]
	TIME [epoch: 24.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2760531645453486		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.2760531645453486 | validation: 1.2243520267967491]
	TIME [epoch: 24.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0235156608109077		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 1.0235156608109077 | validation: 1.0973331581779335]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1753707716050394		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 1.1753707716050394 | validation: 1.4461553338831135]
	TIME [epoch: 24.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3195604065664053		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 1.3195604065664053 | validation: 1.1381693009103386]
	TIME [epoch: 24.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1296350376292108		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 1.1296350376292108 | validation: 1.6967879789755518]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6889893069126949		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 1.6889893069126949 | validation: 1.1862536922133882]
	TIME [epoch: 24.8 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2460854067080516		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 1.2460854067080516 | validation: 1.7482384168192653]
	TIME [epoch: 24.8 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2510835903979327		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 1.2510835903979327 | validation: 1.1739283615155096]
	TIME [epoch: 24.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2531096445464467		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.2531096445464467 | validation: 1.292883582982783]
	TIME [epoch: 24.8 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.141596507043805		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.141596507043805 | validation: 1.1783767787853276]
	TIME [epoch: 24.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.335309723785207		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.335309723785207 | validation: 1.3558910533629784]
	TIME [epoch: 24.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9052046262774964		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 1.9052046262774964 | validation: 1.9275955152230884]
	TIME [epoch: 24.8 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7116712043328128		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 1.7116712043328128 | validation: 2.5463391380056914]
	TIME [epoch: 24.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.704557418190482		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 1.704557418190482 | validation: 1.248552657915025]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3173226000006695		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.3173226000006695 | validation: 1.8566864623137682]
	TIME [epoch: 24.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6318887758118374		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 3.6318887758118374 | validation: 1.9172847085412144]
	TIME [epoch: 24.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5115268517975722		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 1.5115268517975722 | validation: 1.3647006736086897]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6776902218977918		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.6776902218977918 | validation: 1.3275189420760867]
	TIME [epoch: 24.8 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1120026745495615		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 1.1120026745495615 | validation: 1.4236950872264447]
	TIME [epoch: 24.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2051831425715598		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.2051831425715598 | validation: 1.241414371310545]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0409405937188032		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.0409405937188032 | validation: 1.1041878843843984]
	TIME [epoch: 24.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1588145066516786		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 1.1588145066516786 | validation: 1.1498724476053552]
	TIME [epoch: 24.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1116345664456198		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 1.1116345664456198 | validation: 2.1293274449652717]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6066883516223611		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.6066883516223611 | validation: 1.7394334941959755]
	TIME [epoch: 24.8 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5075153014490787		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.5075153014490787 | validation: 1.338019834033868]
	TIME [epoch: 24.8 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0946390924489515		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 1.0946390924489515 | validation: 1.2948452426041712]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.341913503800198		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.341913503800198 | validation: 1.2694979283487466]
	TIME [epoch: 24.8 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9924686253270971		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.9924686253270971 | validation: 1.329222298730528]
	TIME [epoch: 24.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2599194437534862		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.2599194437534862 | validation: 1.371699582376701]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3056828972207344		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.3056828972207344 | validation: 1.5488987112936452]
	TIME [epoch: 24.8 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1208926342496848		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.1208926342496848 | validation: 1.098857160739505]
	TIME [epoch: 24.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2542569361536278		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.2542569361536278 | validation: 3.444115591161542]
	TIME [epoch: 24.8 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1271238901745915		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 2.1271238901745915 | validation: 1.3761842706268543]
	TIME [epoch: 24.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5405393628866524		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 1.5405393628866524 | validation: 1.2402004200033485]
	TIME [epoch: 24.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2319881010789302		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 1.2319881010789302 | validation: 1.4258366751790317]
	TIME [epoch: 24.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4059160980460685		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 1.4059160980460685 | validation: 1.342693900191181]
	TIME [epoch: 24.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8668708567010621		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 1.8668708567010621 | validation: 1.9602578145790421]
	TIME [epoch: 24.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.128925119626591		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 2.128925119626591 | validation: 1.9375471950340113]
	TIME [epoch: 24.8 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4944701518368764		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.4944701518368764 | validation: 3.1042008178626337]
	TIME [epoch: 24.8 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.860285982973567		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 1.860285982973567 | validation: 2.062646903297576]
	TIME [epoch: 24.8 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6474805477462346		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.6474805477462346 | validation: 1.2139540893937781]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.728756129004097		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.728756129004097 | validation: 1.3375835453707057]
	TIME [epoch: 24.8 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5384945383147937		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 2.5384945383147937 | validation: 1.6985306176215795]
	TIME [epoch: 24.8 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.363082075835524		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.363082075835524 | validation: 1.2668083751521158]
	TIME [epoch: 24.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.201505878039485		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.201505878039485 | validation: 2.525995696215604]
	TIME [epoch: 24.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1600168581825585		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 4.1600168581825585 | validation: 2.687467385027903]
	TIME [epoch: 24.8 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.239288191895924		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 2.239288191895924 | validation: 1.4453911846960572]
	TIME [epoch: 24.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5685057660767376		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 1.5685057660767376 | validation: 1.3473089767196558]
	TIME [epoch: 24.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2010093693386805		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 1.2010093693386805 | validation: 1.8052277271852035]
	TIME [epoch: 24.8 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.523590431796956		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.523590431796956 | validation: 1.9216405934799603]
	TIME [epoch: 24.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.323463065991688		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.323463065991688 | validation: 1.2075954623763938]
	TIME [epoch: 24.8 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3087795952936883		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.3087795952936883 | validation: 1.3154177539437504]
	TIME [epoch: 24.8 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1423433481258332		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.1423433481258332 | validation: 1.4164797415550137]
	TIME [epoch: 24.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.526583493191772		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.526583493191772 | validation: 2.315515004435394]
	TIME [epoch: 24.8 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7672070382501632		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.7672070382501632 | validation: 1.4174625517249388]
	TIME [epoch: 24.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2618705662883303		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.2618705662883303 | validation: 1.3303442992774743]
	TIME [epoch: 24.8 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.143993246193189		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.143993246193189 | validation: 1.2701167896916141]
	TIME [epoch: 24.8 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6047125562179025		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.6047125562179025 | validation: 1.221840550913413]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0802849122634806		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.0802849122634806 | validation: 1.3367140423394719]
	TIME [epoch: 24.8 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.351906306658043		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.351906306658043 | validation: 2.9048987384002762]
	TIME [epoch: 24.8 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.765184950964334		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.765184950964334 | validation: 2.0683373229184485]
	TIME [epoch: 24.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5290704192186075		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 1.5290704192186075 | validation: 1.3286290108449816]
	TIME [epoch: 24.8 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2221425157897914		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.2221425157897914 | validation: 1.5124761168605096]
	TIME [epoch: 24.8 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.237083567586008		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.237083567586008 | validation: 1.1542393935372253]
	TIME [epoch: 24.8 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5464721192391968		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 1.5464721192391968 | validation: 2.104831108293039]
	TIME [epoch: 24.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.62481828572283		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.62481828572283 | validation: 1.1625142818636505]
	TIME [epoch: 24.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7495684565977871		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 1.7495684565977871 | validation: 1.6767497933115605]
	TIME [epoch: 24.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3633897989998465		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 1.3633897989998465 | validation: 1.351571606595248]
	TIME [epoch: 24.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1819795824021435		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.1819795824021435 | validation: 1.1969681356022137]
	TIME [epoch: 24.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.404214564256104		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 1.404214564256104 | validation: 1.446094778256629]
	TIME [epoch: 24.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.442097776107762		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.442097776107762 | validation: 1.1981725218928025]
	TIME [epoch: 24.8 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1947156375531147		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 1.1947156375531147 | validation: 1.935312421823983]
	TIME [epoch: 24.8 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3361712368322451		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.3361712368322451 | validation: 1.4437267486635805]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.167803949338452		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 1.167803949338452 | validation: 1.34915914086344]
	TIME [epoch: 24.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3069034106114685		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.3069034106114685 | validation: 1.6327995080707793]
	TIME [epoch: 24.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3425396600315953		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.3425396600315953 | validation: 1.6579617764041468]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5071641039257382		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.5071641039257382 | validation: 2.4652973672491703]
	TIME [epoch: 24.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.624232429252334		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.624232429252334 | validation: 1.1652436175601915]
	TIME [epoch: 24.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2010976570780312		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 1.2010976570780312 | validation: 0.9990363008598091]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.963882817858217		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.963882817858217 | validation: 1.2991184650140344]
	TIME [epoch: 24.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064510709328792		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.064510709328792 | validation: 1.230494115641939]
	TIME [epoch: 24.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1179738763333504		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.1179738763333504 | validation: 1.3293372690782599]
	TIME [epoch: 24.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032552681009612		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.032552681009612 | validation: 1.4054940281533967]
	TIME [epoch: 24.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.310806517929274		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 1.310806517929274 | validation: 1.8506741141712064]
	TIME [epoch: 24.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2505877729389883		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.2505877729389883 | validation: 1.2459128290765216]
	TIME [epoch: 24.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1162411134300207		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.1162411134300207 | validation: 1.4672623341849675]
	TIME [epoch: 24.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.17760121431529		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 1.17760121431529 | validation: 1.0194010774135562]
	TIME [epoch: 24.8 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9612595059783811		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.9612595059783811 | validation: 1.0863419945836952]
	TIME [epoch: 24.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0093465854530979		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.0093465854530979 | validation: 1.4086905441045579]
	TIME [epoch: 24.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1598552463173053		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.1598552463173053 | validation: 1.2354649067901473]
	TIME [epoch: 24.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0476526729803868		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 1.0476526729803868 | validation: 1.1261993859000898]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.999097459065927		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.999097459065927 | validation: 1.633624638268356]
	TIME [epoch: 24.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2772633506963535		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 1.2772633506963535 | validation: 1.6290187933753344]
	TIME [epoch: 24.8 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1999180296759973		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 1.1999180296759973 | validation: 0.8905414350893941]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9672421680806169		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.9672421680806169 | validation: 0.9505694585106477]
	TIME [epoch: 24.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.047511533593253		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 1.047511533593253 | validation: 1.0813958578908565]
	TIME [epoch: 24.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1899596830159598		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 1.1899596830159598 | validation: 0.9693391711175159]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1038812900662751		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.1038812900662751 | validation: 1.453885198541468]
	TIME [epoch: 24.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.271768838285566		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.271768838285566 | validation: 1.5154197565864411]
	TIME [epoch: 24.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9748489106647391		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.9748489106647391 | validation: 1.8820110965572923]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3546457046022367		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 1.3546457046022367 | validation: 1.9404318272359413]
	TIME [epoch: 24.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307179448242533		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 1.2307179448242533 | validation: 1.3871913661019144]
	TIME [epoch: 24.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9338898905331647		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.9338898905331647 | validation: 1.0822158828024362]
	TIME [epoch: 24.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2604583775083642		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 1.2604583775083642 | validation: 1.65374451975113]
	TIME [epoch: 24.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2127818718838776		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 1.2127818718838776 | validation: 1.6956126786690937]
	TIME [epoch: 24.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3354789625967256		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 1.3354789625967256 | validation: 1.5263107480763638]
	TIME [epoch: 24.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1916628623867869		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 1.1916628623867869 | validation: 1.0161814858853462]
	TIME [epoch: 24.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3703643016573208		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 1.3703643016573208 | validation: 1.081119395371035]
	TIME [epoch: 24.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9637146448980005		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.9637146448980005 | validation: 1.5058110447950992]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2016092106331775		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 1.2016092106331775 | validation: 1.2348578546941993]
	TIME [epoch: 24.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9235441773809288		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.9235441773809288 | validation: 1.1192460286479395]
	TIME [epoch: 24.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1337150474304032		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 1.1337150474304032 | validation: 2.0627349540229183]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5294593036405608		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 1.5294593036405608 | validation: 0.9545904602249712]
	TIME [epoch: 24.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.145498373780657		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 1.145498373780657 | validation: 1.2613372670361787]
	TIME [epoch: 24.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0807168588735512		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 1.0807168588735512 | validation: 1.283260045859064]
	TIME [epoch: 24.8 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2746452010577052		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 1.2746452010577052 | validation: 1.6533963229787627]
	TIME [epoch: 24.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1270258860946556		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 1.1270258860946556 | validation: 1.066754623109226]
	TIME [epoch: 24.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9296925803709508		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.9296925803709508 | validation: 0.9313407432678099]
	TIME [epoch: 24.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8163126877451821		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.8163126877451821 | validation: 1.0155390908707609]
	TIME [epoch: 24.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0684571193406425		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 1.0684571193406425 | validation: 1.2284888129553921]
	TIME [epoch: 24.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1536711082197622		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 1.1536711082197622 | validation: 1.7953043518369187]
	TIME [epoch: 24.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1755715942495297		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.1755715942495297 | validation: 1.069999085498068]
	TIME [epoch: 24.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.250307513394585		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 1.250307513394585 | validation: 1.008556585983056]
	TIME [epoch: 24.8 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8950197858541871		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.8950197858541871 | validation: 0.958293147652762]
	TIME [epoch: 24.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4840099791842556		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.4840099791842556 | validation: 1.1933722314128734]
	TIME [epoch: 24.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0389925041765353		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 1.0389925041765353 | validation: 1.0981451240276316]
	TIME [epoch: 24.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1495233098434925		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 1.1495233098434925 | validation: 0.9765177595141488]
	TIME [epoch: 24.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8802754196541763		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.8802754196541763 | validation: 0.9231712970938949]
	TIME [epoch: 24.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.842319476743817		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.842319476743817 | validation: 0.7668630563735253]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_395.pth
	Model improved!!!
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0000752612410593		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 1.0000752612410593 | validation: 1.5249824119220705]
	TIME [epoch: 24.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5999379097199005		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 1.5999379097199005 | validation: 0.9851632680533935]
	TIME [epoch: 24.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.101223246129912		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 1.101223246129912 | validation: 0.8407541285825131]
	TIME [epoch: 24.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2930944466745042		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 1.2930944466745042 | validation: 1.3788362719072558]
	TIME [epoch: 24.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0466490534540591		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 1.0466490534540591 | validation: 2.5550008930942383]
	TIME [epoch: 24.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.610045433348713		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 1.610045433348713 | validation: 1.1370480694457137]
	TIME [epoch: 24.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9685170757433929		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.9685170757433929 | validation: 1.1501715743637666]
	TIME [epoch: 24.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0714646826942131		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 1.0714646826942131 | validation: 0.9780901971916985]
	TIME [epoch: 24.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.081157365871803		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.081157365871803 | validation: 1.2975362483363464]
	TIME [epoch: 24.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9368762694511583		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.9368762694511583 | validation: 0.8695687156161875]
	TIME [epoch: 24.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8349115285431066		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.8349115285431066 | validation: 1.0433856112550655]
	TIME [epoch: 24.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2246204150717057		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 1.2246204150717057 | validation: 1.1941469352922283]
	TIME [epoch: 24.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0149707579188134		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 1.0149707579188134 | validation: 1.042293689728243]
	TIME [epoch: 24.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3421537751039092		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 1.3421537751039092 | validation: 2.8769474025342845]
	TIME [epoch: 24.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8499185920254793		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 1.8499185920254793 | validation: 1.0304497619096864]
	TIME [epoch: 24.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.157930986713684		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 1.157930986713684 | validation: 1.1394062916011887]
	TIME [epoch: 24.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3154794057383439		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 1.3154794057383439 | validation: 1.1333871899611956]
	TIME [epoch: 24.8 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1487398895467456		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 1.1487398895467456 | validation: 1.032458939710889]
	TIME [epoch: 24.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.090529724977606		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 1.090529724977606 | validation: 1.6554623470213972]
	TIME [epoch: 24.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1244779906677558		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 1.1244779906677558 | validation: 0.9834317636771974]
	TIME [epoch: 24.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8800181936190897		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.8800181936190897 | validation: 1.0535097993823992]
	TIME [epoch: 24.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1419165077021964		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 1.1419165077021964 | validation: 0.9107538051552351]
	TIME [epoch: 24.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2596324468065183		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 1.2596324468065183 | validation: 3.1821719115783833]
	TIME [epoch: 24.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8031014511647405		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 1.8031014511647405 | validation: 1.2491311437294275]
	TIME [epoch: 24.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1365702719553301		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 1.1365702719553301 | validation: 0.927901775193878]
	TIME [epoch: 24.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9541904993548109		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.9541904993548109 | validation: 0.8533922151276601]
	TIME [epoch: 24.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8829275073938236		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.8829275073938236 | validation: 0.8688690953837436]
	TIME [epoch: 24.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.763524810493051		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.763524810493051 | validation: 1.0192401800091424]
	TIME [epoch: 24.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0284648561546907		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 1.0284648561546907 | validation: 4.507721673395142]
	TIME [epoch: 24.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.166276666394031		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 4.166276666394031 | validation: 2.590988632737419]
	TIME [epoch: 24.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6877023287397275		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 1.6877023287397275 | validation: 1.11518786441463]
	TIME [epoch: 24.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9710511320488393		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.9710511320488393 | validation: 1.064770935241265]
	TIME [epoch: 24.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.918312548049321		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.918312548049321 | validation: 0.9012520900078909]
	TIME [epoch: 24.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9689985418417338		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.9689985418417338 | validation: 1.0035165707371418]
	TIME [epoch: 24.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6418199114817618		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 1.6418199114817618 | validation: 2.3087960348969676]
	TIME [epoch: 24.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3211977470682246		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 1.3211977470682246 | validation: 1.1407257863430673]
	TIME [epoch: 24.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9587203347100774		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.9587203347100774 | validation: 0.9139606687600039]
	TIME [epoch: 24.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9893760280476785		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.9893760280476785 | validation: 1.0590931647087067]
	TIME [epoch: 24.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0625411210556732		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 1.0625411210556732 | validation: 1.014024182398396]
	TIME [epoch: 24.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.223699484500683		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 1.223699484500683 | validation: 1.129833990018409]
	TIME [epoch: 24.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0443423959277442		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 1.0443423959277442 | validation: 0.8884404290890475]
	TIME [epoch: 24.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0333140447114877		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 1.0333140447114877 | validation: 1.349080461133007]
	TIME [epoch: 24.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.400497750192708		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 1.400497750192708 | validation: 1.2485937853666602]
	TIME [epoch: 24.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229182923876146		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 1.229182923876146 | validation: 1.1062267804074413]
	TIME [epoch: 24.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.109155706742158		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 1.109155706742158 | validation: 1.3103403002322977]
	TIME [epoch: 24.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3319262930949751		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 1.3319262930949751 | validation: 1.067299761698147]
	TIME [epoch: 24.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0083563285906718		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 1.0083563285906718 | validation: 1.0737068044538414]
	TIME [epoch: 24.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.850625977096325		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.850625977096325 | validation: 1.1779159105274075]
	TIME [epoch: 24.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9975403674506709		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.9975403674506709 | validation: 1.154596297346998]
	TIME [epoch: 24.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8690973769886665		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.8690973769886665 | validation: 1.1018345525279452]
	TIME [epoch: 24.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9203815748684475		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.9203815748684475 | validation: 0.9585451369678455]
	TIME [epoch: 24.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7729245639755866		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.7729245639755866 | validation: 1.276623732037534]
	TIME [epoch: 24.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9211609841443538		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.9211609841443538 | validation: 1.1482348591699407]
	TIME [epoch: 24.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.865252460231659		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.865252460231659 | validation: 1.2566390880527178]
	TIME [epoch: 24.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0552549219722966		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.0552549219722966 | validation: 1.3226986765483526]
	TIME [epoch: 24.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8683178907550968		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.8683178907550968 | validation: 0.8789776983013212]
	TIME [epoch: 24.8 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7525433446547414		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.7525433446547414 | validation: 0.904076941898085]
	TIME [epoch: 24.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8253796899202573		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.8253796899202573 | validation: 0.9728213337606134]
	TIME [epoch: 24.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7669890397458101		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.7669890397458101 | validation: 0.8819628965331741]
	TIME [epoch: 24.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.90499181150737		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.90499181150737 | validation: 0.9977601724610159]
	TIME [epoch: 24.8 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9041890036275272		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.9041890036275272 | validation: 0.775988532409759]
	TIME [epoch: 24.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9208662181222902		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.9208662181222902 | validation: 0.8259694029036788]
	TIME [epoch: 24.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281138273379737		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.7281138273379737 | validation: 0.9174335312333863]
	TIME [epoch: 24.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7462990716574196		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.7462990716574196 | validation: 0.7806974992799779]
	TIME [epoch: 24.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1069704707414878		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 1.1069704707414878 | validation: 1.32659186582045]
	TIME [epoch: 24.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9244797470879857		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.9244797470879857 | validation: 0.7528950452786873]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_461.pth
	Model improved!!!
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7268132906852264		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.7268132906852264 | validation: 0.7875362062802319]
	TIME [epoch: 24.8 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8100404481590795		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.8100404481590795 | validation: 1.0466145296127867]
	TIME [epoch: 24.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8586301489075324		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.8586301489075324 | validation: 1.2835542221646634]
	TIME [epoch: 24.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0932313508456102		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.0932313508456102 | validation: 1.1529216899616959]
	TIME [epoch: 24.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8961632505249405		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.8961632505249405 | validation: 0.9095108404142189]
	TIME [epoch: 24.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8908485996829782		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.8908485996829782 | validation: 1.1279341303246224]
	TIME [epoch: 24.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9267603875862986		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.9267603875862986 | validation: 1.146372215730541]
	TIME [epoch: 24.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0319351135353712		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 1.0319351135353712 | validation: 0.9420897801215091]
	TIME [epoch: 24.8 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9293454405093973		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.9293454405093973 | validation: 1.0261287787297877]
	TIME [epoch: 24.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9822261301461213		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.9822261301461213 | validation: 1.0173221177457878]
	TIME [epoch: 24.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9622049882345648		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.9622049882345648 | validation: 0.928026105907592]
	TIME [epoch: 24.8 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8886900719195056		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.8886900719195056 | validation: 1.7431812983877144]
	TIME [epoch: 24.8 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1745529237541732		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 1.1745529237541732 | validation: 1.0022120015365952]
	TIME [epoch: 24.8 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8923565512895806		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.8923565512895806 | validation: 0.9143798284394872]
	TIME [epoch: 24.8 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2272476502715723		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 1.2272476502715723 | validation: 1.0703314740564855]
	TIME [epoch: 24.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9319272838818066		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.9319272838818066 | validation: 1.3088754927211523]
	TIME [epoch: 24.9 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.857486807417768		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.857486807417768 | validation: 0.7719261137293018]
	TIME [epoch: 24.8 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7383258734852869		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.7383258734852869 | validation: 1.0956087401910686]
	TIME [epoch: 24.8 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8785902516539035		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.8785902516539035 | validation: 0.7367807468210296]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_480.pth
	Model improved!!!
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697750553586042		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.6697750553586042 | validation: 0.8908656259956251]
	TIME [epoch: 25 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7532490345792378		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.7532490345792378 | validation: 0.8965661158071501]
	TIME [epoch: 24.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9866763082672476		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.9866763082672476 | validation: 0.8679449115944426]
	TIME [epoch: 24.8 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9627979659903776		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.9627979659903776 | validation: 1.0048899557936029]
	TIME [epoch: 24.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7689720026560798		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.7689720026560798 | validation: 0.9568553504272923]
	TIME [epoch: 24.9 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1703380937470622		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 1.1703380937470622 | validation: 1.9062379782157086]
	TIME [epoch: 24.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0726161254995794		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 1.0726161254995794 | validation: 1.433220852743529]
	TIME [epoch: 25 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9871664492757863		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.9871664492757863 | validation: 0.96193098961282]
	TIME [epoch: 24.9 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9663478039811544		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.9663478039811544 | validation: 1.0997323006429551]
	TIME [epoch: 24.8 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8017000143051374		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.8017000143051374 | validation: 0.7474680949866226]
	TIME [epoch: 24.8 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7730747504833384		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.7730747504833384 | validation: 1.235784501504165]
	TIME [epoch: 24.8 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9594697952121756		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.9594697952121756 | validation: 1.058497430600482]
	TIME [epoch: 24.8 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8445466514376041		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.8445466514376041 | validation: 0.7053991031113884]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_493.pth
	Model improved!!!
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7303130777214235		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.7303130777214235 | validation: 0.8464740305765293]
	TIME [epoch: 24.8 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9217736150946345		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.9217736150946345 | validation: 0.8490052241882563]
	TIME [epoch: 24.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.866874460713652		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.866874460713652 | validation: 1.4031048244976219]
	TIME [epoch: 24.8 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0051126603843659		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 1.0051126603843659 | validation: 0.9103867259387731]
	TIME [epoch: 24.8 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.804877775539448		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.804877775539448 | validation: 0.8046210966593563]
	TIME [epoch: 24.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8203321439739062		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.8203321439739062 | validation: 0.74714812845037]
	TIME [epoch: 24.8 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8000204685002015		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.8000204685002015 | validation: 0.731627166829167]
	TIME [epoch: 24.8 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6906785384894422		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6906785384894422 | validation: 1.0711324715896788]
	TIME [epoch: 24.8 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8669042175525955		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.8669042175525955 | validation: 0.7825792596843795]
	TIME [epoch: 24.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7728807154849897		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.7728807154849897 | validation: 0.804945802751042]
	TIME [epoch: 24.8 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9148588028743448		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.9148588028743448 | validation: 0.8912292076055497]
	TIME [epoch: 24.8 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8109427750559177		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.8109427750559177 | validation: 0.8501499837311599]
	TIME [epoch: 24.8 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8920972367742123		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.8920972367742123 | validation: 1.365003632441257]
	TIME [epoch: 24.8 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.066550317338689		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.066550317338689 | validation: 0.8998878324943638]
	TIME [epoch: 24.8 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7970051390084958		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.7970051390084958 | validation: 0.7908217873781158]
	TIME [epoch: 24.8 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1050889203174625		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.1050889203174625 | validation: 2.035148522393629]
	TIME [epoch: 24.8 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9247527927022765		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 2.9247527927022765 | validation: 3.3013255588828416]
	TIME [epoch: 24.8 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4823986157074565		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 2.4823986157074565 | validation: 1.398627296516587]
	TIME [epoch: 24.8 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8553254619842		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.8553254619842 | validation: 0.7976744159691295]
	TIME [epoch: 24.8 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6465320349636933		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.6465320349636933 | validation: 1.076553139757546]
	TIME [epoch: 24.8 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0033399131336453		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 1.0033399131336453 | validation: 0.9062844938124525]
	TIME [epoch: 24.8 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8733015085114867		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.8733015085114867 | validation: 0.8347872108363288]
	TIME [epoch: 24.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6349434466666128		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.6349434466666128 | validation: 0.8082531298861259]
	TIME [epoch: 24.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6700392199996029		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.6700392199996029 | validation: 0.8665919917609742]
	TIME [epoch: 24.8 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6648129100065838		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.6648129100065838 | validation: 0.9136880571111573]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9304996155179464		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.9304996155179464 | validation: 0.966491285630189]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7969728608421841		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.7969728608421841 | validation: 0.8195257630778084]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6256388210538791		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.6256388210538791 | validation: 0.68896032901117]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_521.pth
	Model improved!!!
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6426534228415869		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.6426534228415869 | validation: 0.7237795260316642]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957977499524362		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.6957977499524362 | validation: 0.7582022443958821]
	TIME [epoch: 24.8 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7901511035914195		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.7901511035914195 | validation: 0.7935417763709117]
	TIME [epoch: 24.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231512165100208		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.6231512165100208 | validation: 0.7393785226850372]
	TIME [epoch: 24.8 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6469762361213865		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.6469762361213865 | validation: 0.7454431737835313]
	TIME [epoch: 24.8 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.668719222100346		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.668719222100346 | validation: 0.8200879079943759]
	TIME [epoch: 24.8 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6491892155221144		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.6491892155221144 | validation: 0.7597111878751553]
	TIME [epoch: 24.8 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6891169893626676		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.6891169893626676 | validation: 0.842368620703423]
	TIME [epoch: 24.8 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8755303179904395		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.8755303179904395 | validation: 0.8825998423331427]
	TIME [epoch: 24.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8730307454754225		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.8730307454754225 | validation: 0.8810949526821518]
	TIME [epoch: 24.8 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6658079744735834		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.6658079744735834 | validation: 0.8460400020131391]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.667128245941442		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.667128245941442 | validation: 0.7706628722187805]
	TIME [epoch: 24.8 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8409418831181991		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.8409418831181991 | validation: 1.214963234871634]
	TIME [epoch: 24.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9501120259777135		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.9501120259777135 | validation: 0.8906321032213592]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.798670430653916		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.798670430653916 | validation: 1.158994310085759]
	TIME [epoch: 24.8 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8825995892902778		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.8825995892902778 | validation: 0.9935783107020442]
	TIME [epoch: 24.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7708354604936369		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.7708354604936369 | validation: 0.7631148025076538]
	TIME [epoch: 24.8 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8561218479625614		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.8561218479625614 | validation: 0.8204393889045071]
	TIME [epoch: 24.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6342182085051801		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.6342182085051801 | validation: 0.6959107562268776]
	TIME [epoch: 24.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6074314911499834		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.6074314911499834 | validation: 0.748800689960776]
	TIME [epoch: 24.8 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7754381139633357		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.7754381139633357 | validation: 0.837492127960579]
	TIME [epoch: 24.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7851304693903454		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.7851304693903454 | validation: 0.9994144770802197]
	TIME [epoch: 24.8 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.695825811214315		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.695825811214315 | validation: 0.780786345058311]
	TIME [epoch: 24.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6470579580683895		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.6470579580683895 | validation: 0.7901496646661026]
	TIME [epoch: 24.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6186615904901349		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.6186615904901349 | validation: 0.698305369876024]
	TIME [epoch: 24.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7984832036359489		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.7984832036359489 | validation: 0.9206122710623356]
	TIME [epoch: 24.8 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0043592194562156		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 1.0043592194562156 | validation: 0.9603159195526487]
	TIME [epoch: 24.8 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8319497217350492		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.8319497217350492 | validation: 0.8070422753393248]
	TIME [epoch: 24.8 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7619547000062741		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.7619547000062741 | validation: 0.7677781329167017]
	TIME [epoch: 24.8 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6030324197117529		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.6030324197117529 | validation: 0.997414663684409]
	TIME [epoch: 24.8 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7922532628177401		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.7922532628177401 | validation: 0.8263673962062333]
	TIME [epoch: 24.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.636368427890534		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.636368427890534 | validation: 0.913573375450946]
	TIME [epoch: 24.8 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6909285115444679		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.6909285115444679 | validation: 0.7347995772483857]
	TIME [epoch: 24.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6508348062105691		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.6508348062105691 | validation: 0.8878906738268378]
	TIME [epoch: 24.8 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6503668862259494		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.6503668862259494 | validation: 0.6979999445420654]
	TIME [epoch: 24.8 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5894974668499608		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.5894974668499608 | validation: 0.7148160261604438]
	TIME [epoch: 24.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5692196472538051		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.5692196472538051 | validation: 0.6917369277630522]
	TIME [epoch: 24.8 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6887233818135619		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.6887233818135619 | validation: 0.679783153518019]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_559.pth
	Model improved!!!
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6917971730814654		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.6917971730814654 | validation: 1.0059254255812395]
	TIME [epoch: 24.8 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7104396763521728		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.7104396763521728 | validation: 0.7653857271735399]
	TIME [epoch: 24.8 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6432196932703312		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.6432196932703312 | validation: 0.9084744804363103]
	TIME [epoch: 24.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7470484977564643		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.7470484977564643 | validation: 0.8835064675483533]
	TIME [epoch: 24.8 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283526181633925		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.6283526181633925 | validation: 0.884694424663428]
	TIME [epoch: 24.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6473493309509236		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.6473493309509236 | validation: 0.8694853160303427]
	TIME [epoch: 24.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6377598577133154		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.6377598577133154 | validation: 0.7916816523847215]
	TIME [epoch: 24.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7099587417606106		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.7099587417606106 | validation: 0.7812272367944115]
	TIME [epoch: 24.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6995745344455433		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.6995745344455433 | validation: 0.7656959846701071]
	TIME [epoch: 24.8 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6571769444365849		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.6571769444365849 | validation: 0.8368356913501975]
	TIME [epoch: 24.8 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8099650850025482		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.8099650850025482 | validation: 0.7650909885363538]
	TIME [epoch: 24.8 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6673749663714827		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.6673749663714827 | validation: 0.8365259020686509]
	TIME [epoch: 24.8 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7733944952030595		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.7733944952030595 | validation: 0.7052129672536195]
	TIME [epoch: 24.8 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6671144859373115		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.6671144859373115 | validation: 0.8638138131536364]
	TIME [epoch: 24.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6877755733255162		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.6877755733255162 | validation: 0.7216593945530343]
	TIME [epoch: 24.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687696910237229		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.687696910237229 | validation: 0.9056612658854567]
	TIME [epoch: 24.8 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8059802804995277		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.8059802804995277 | validation: 1.1320846227169297]
	TIME [epoch: 24.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7809656481749346		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.7809656481749346 | validation: 1.2247011682414253]
	TIME [epoch: 24.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8938039573393581		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.8938039573393581 | validation: 0.796077643884873]
	TIME [epoch: 24.8 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6859610873639035		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.6859610873639035 | validation: 0.8369020873008008]
	TIME [epoch: 24.8 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6511619230023331		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.6511619230023331 | validation: 0.774037944758485]
	TIME [epoch: 24.8 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231470313411159		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.6231470313411159 | validation: 0.6636200055532676]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_581.pth
	Model improved!!!
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5788985171148463		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.5788985171148463 | validation: 0.6854575497845861]
	TIME [epoch: 24.8 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5589507012138647		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.5589507012138647 | validation: 0.6900881646239561]
	TIME [epoch: 24.8 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5236482319845267		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.5236482319845267 | validation: 0.69904616408609]
	TIME [epoch: 24.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5726941981087696		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5726941981087696 | validation: 0.8586897035521153]
	TIME [epoch: 24.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5855485385736451		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.5855485385736451 | validation: 0.6834460878556309]
	TIME [epoch: 24.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5270164798000142		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.5270164798000142 | validation: 0.9349813206252447]
	TIME [epoch: 24.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6409305793108613		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.6409305793108613 | validation: 0.9650238177574135]
	TIME [epoch: 24.8 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9048084583335223		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.9048084583335223 | validation: 0.8764298350200455]
	TIME [epoch: 24.8 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7731497504934917		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.7731497504934917 | validation: 0.8943565554644587]
	TIME [epoch: 24.8 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6844772643063545		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.6844772643063545 | validation: 0.7218950710652225]
	TIME [epoch: 24.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6251282785032459		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.6251282785032459 | validation: 0.883317942017676]
	TIME [epoch: 24.8 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6591089715203853		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.6591089715203853 | validation: 0.6351914463903774]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_593.pth
	Model improved!!!
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5738723197663985		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.5738723197663985 | validation: 0.9317822232246025]
	TIME [epoch: 24.8 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.630403316389789		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.630403316389789 | validation: 0.8579212239407417]
	TIME [epoch: 24.8 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6660413326186368		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.6660413326186368 | validation: 0.6789738633373398]
	TIME [epoch: 24.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.610579801150859		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.610579801150859 | validation: 0.71243968585048]
	TIME [epoch: 24.8 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6481661965024317		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.6481661965024317 | validation: 0.9528363584954711]
	TIME [epoch: 24.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7092553051415		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.7092553051415 | validation: 0.7244539393468074]
	TIME [epoch: 24.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6390265086205753		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.6390265086205753 | validation: 1.2477134002952777]
	TIME [epoch: 24.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8205979858053746		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.8205979858053746 | validation: 0.7477977688695381]
	TIME [epoch: 24.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5843991790813352		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.5843991790813352 | validation: 0.8013073937601257]
	TIME [epoch: 24.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6207027541685077		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.6207027541685077 | validation: 0.9871545659030281]
	TIME [epoch: 24.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8473376838495337		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.8473376838495337 | validation: 0.8112945138129933]
	TIME [epoch: 24.8 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6733075148442914		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.6733075148442914 | validation: 0.7655214832626317]
	TIME [epoch: 24.8 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6755737696974078		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.6755737696974078 | validation: 1.1833293493249428]
	TIME [epoch: 24.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.921543677621787		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.921543677621787 | validation: 0.8149581918201151]
	TIME [epoch: 24.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.791582164556208		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.791582164556208 | validation: 0.9463902018418804]
	TIME [epoch: 24.8 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7444832922941935		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.7444832922941935 | validation: 1.0560669737620716]
	TIME [epoch: 24.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6413227659000772		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.6413227659000772 | validation: 0.843261589315063]
	TIME [epoch: 24.8 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8405985717287311		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.8405985717287311 | validation: 0.7615173925665704]
	TIME [epoch: 24.8 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5638816893227241		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.5638816893227241 | validation: 0.7507597729611363]
	TIME [epoch: 24.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5351170389954121		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.5351170389954121 | validation: 0.6930975370789386]
	TIME [epoch: 24.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7453808896383127		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.7453808896383127 | validation: 0.7673522847786858]
	TIME [epoch: 24.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283467500510412		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.6283467500510412 | validation: 0.7547921358421258]
	TIME [epoch: 24.8 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5914395086286937		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.5914395086286937 | validation: 0.810962929562576]
	TIME [epoch: 24.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6163947166309708		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.6163947166309708 | validation: 0.72271744118019]
	TIME [epoch: 24.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5689587429458002		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.5689587429458002 | validation: 0.6968963485012348]
	TIME [epoch: 24.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170223020982377		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.7170223020982377 | validation: 0.7906103166475561]
	TIME [epoch: 24.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6982666790820564		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.6982666790820564 | validation: 0.7305674321695257]
	TIME [epoch: 24.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6141333268902589		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.6141333268902589 | validation: 0.73076579033961]
	TIME [epoch: 24.8 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5428891710547267		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.5428891710547267 | validation: 0.6800809544934292]
	TIME [epoch: 24.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5794131218154761		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.5794131218154761 | validation: 0.7499623633188476]
	TIME [epoch: 24.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6084539697397078		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.6084539697397078 | validation: 0.6846643700614012]
	TIME [epoch: 24.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6396213967707465		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.6396213967707465 | validation: 0.821712900322627]
	TIME [epoch: 24.8 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5978425676114871		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.5978425676114871 | validation: 0.6654681732019716]
	TIME [epoch: 24.8 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5392810936164463		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5392810936164463 | validation: 0.6879272037674485]
	TIME [epoch: 24.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6492184165788794		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.6492184165788794 | validation: 0.9929657020697513]
	TIME [epoch: 24.8 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6684224163028879		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.6684224163028879 | validation: 0.7765232407276608]
	TIME [epoch: 24.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5452618648704286		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.5452618648704286 | validation: 0.8927173713578728]
	TIME [epoch: 24.8 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6436237896281692		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.6436237896281692 | validation: 0.694009963037067]
	TIME [epoch: 24.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5923290219945146		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.5923290219945146 | validation: 0.758616296764969]
	TIME [epoch: 24.8 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6010503183456819		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.6010503183456819 | validation: 0.7774684349176824]
	TIME [epoch: 24.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5895650369129571		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.5895650369129571 | validation: 0.6470207598862919]
	TIME [epoch: 24.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5728267028546203		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.5728267028546203 | validation: 0.6138358095662616]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_635.pth
	Model improved!!!
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.549252673984063		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.549252673984063 | validation: 0.6693215638381961]
	TIME [epoch: 24.8 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5637133599337854		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.5637133599337854 | validation: 0.9645336708305279]
	TIME [epoch: 24.8 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7979204982008928		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.7979204982008928 | validation: 0.7359960804541447]
	TIME [epoch: 24.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.595589970904898		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.595589970904898 | validation: 0.6503129053451923]
	TIME [epoch: 24.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6128834132099518		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.6128834132099518 | validation: 0.7048632974001009]
	TIME [epoch: 24.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5760639564299344		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.5760639564299344 | validation: 0.6248396994287874]
	TIME [epoch: 24.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5409924985070883		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.5409924985070883 | validation: 0.618957370722238]
	TIME [epoch: 24.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.617068527672219		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.617068527672219 | validation: 0.6153931463790512]
	TIME [epoch: 24.8 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5449179481227164		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.5449179481227164 | validation: 0.6644130856354719]
	TIME [epoch: 24.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5322765023809773		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.5322765023809773 | validation: 0.7058875882045774]
	TIME [epoch: 24.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5465262139844274		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.5465262139844274 | validation: 0.6831718657404315]
	TIME [epoch: 24.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5647864600888608		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.5647864600888608 | validation: 0.7204238132751342]
	TIME [epoch: 24.8 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5295681454191339		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.5295681454191339 | validation: 0.7266717422354332]
	TIME [epoch: 24.8 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871297435995585		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.5871297435995585 | validation: 0.7166450009486601]
	TIME [epoch: 24.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5730604709580978		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.5730604709580978 | validation: 0.5916269087371897]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_650.pth
	Model improved!!!
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5298063190343039		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.5298063190343039 | validation: 0.7100691899633708]
	TIME [epoch: 24.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5153814684777227		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5153814684777227 | validation: 0.7173767024035037]
	TIME [epoch: 24.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6307620076420757		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.6307620076420757 | validation: 0.6221537594894965]
	TIME [epoch: 24.8 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5542420244210837		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.5542420244210837 | validation: 0.8880798842552378]
	TIME [epoch: 24.8 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6063485937362614		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.6063485937362614 | validation: 0.6848347131641694]
	TIME [epoch: 24.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5224389722250431		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.5224389722250431 | validation: 0.7976255514320261]
	TIME [epoch: 24.8 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5379506355055597		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.5379506355055597 | validation: 0.7055591204732434]
	TIME [epoch: 24.8 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49279023801773403		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.49279023801773403 | validation: 0.6527145481855916]
	TIME [epoch: 24.8 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5199331539312233		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.5199331539312233 | validation: 0.7723241863324398]
	TIME [epoch: 24.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.564049170142275		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.564049170142275 | validation: 0.7153172307784641]
	TIME [epoch: 24.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986210778790819		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.6986210778790819 | validation: 0.7442963263239587]
	TIME [epoch: 24.8 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5924208518323439		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5924208518323439 | validation: 0.6933093093793216]
	TIME [epoch: 24.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6076602510228486		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.6076602510228486 | validation: 0.8328992428412231]
	TIME [epoch: 24.8 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5613074680966824		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.5613074680966824 | validation: 0.6528707679277986]
	TIME [epoch: 24.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4992625726223021		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.4992625726223021 | validation: 0.6139323165956251]
	TIME [epoch: 24.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4844208311587334		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.4844208311587334 | validation: 0.635073756040371]
	TIME [epoch: 24.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.590226171353785		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.590226171353785 | validation: 0.6600646088975185]
	TIME [epoch: 24.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5334079173222327		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.5334079173222327 | validation: 0.6830005594112128]
	TIME [epoch: 24.8 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5491617458457723		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.5491617458457723 | validation: 0.7672618988599877]
	TIME [epoch: 24.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5542616225829288		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.5542616225829288 | validation: 0.6478781451201746]
	TIME [epoch: 24.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4876282156535622		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.4876282156535622 | validation: 0.6979714853640769]
	TIME [epoch: 24.8 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113178525184232		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.5113178525184232 | validation: 0.6599253903279205]
	TIME [epoch: 24.8 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5561262504579677		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.5561262504579677 | validation: 0.7186725713097449]
	TIME [epoch: 24.8 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6366648874774276		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.6366648874774276 | validation: 0.8673104986768099]
	TIME [epoch: 24.8 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.624453276206571		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.624453276206571 | validation: 0.8197988835975943]
	TIME [epoch: 24.8 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5947506108599618		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.5947506108599618 | validation: 0.7912232214109114]
	TIME [epoch: 24.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5515984980853681		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.5515984980853681 | validation: 0.7368561035352883]
	TIME [epoch: 24.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6165995871553338		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.6165995871553338 | validation: 0.6611534012563576]
	TIME [epoch: 24.8 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6017628191474722		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.6017628191474722 | validation: 0.7824886288760773]
	TIME [epoch: 24.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.561929919492807		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.561929919492807 | validation: 0.7092053283155167]
	TIME [epoch: 24.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5109496435198159		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.5109496435198159 | validation: 0.6173982984031029]
	TIME [epoch: 24.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5122415882228111		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.5122415882228111 | validation: 0.6650389999243833]
	TIME [epoch: 24.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5017212316281077		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.5017212316281077 | validation: 0.6508550286577968]
	TIME [epoch: 24.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5096895591782563		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.5096895591782563 | validation: 0.7984134697143642]
	TIME [epoch: 24.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5694608517868872		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.5694608517868872 | validation: 0.6942951757696002]
	TIME [epoch: 24.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5297569004355491		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5297569004355491 | validation: 0.6265357469134571]
	TIME [epoch: 24.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5362477952652388		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.5362477952652388 | validation: 0.8221949118004611]
	TIME [epoch: 24.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6146968326194349		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.6146968326194349 | validation: 0.7110335610962667]
	TIME [epoch: 24.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5370783504874775		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.5370783504874775 | validation: 0.5990442561145821]
	TIME [epoch: 24.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5033284966076645		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5033284966076645 | validation: 0.7133226975633609]
	TIME [epoch: 24.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.556745380674358		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.556745380674358 | validation: 0.6540495162823176]
	TIME [epoch: 24.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.576702542941328		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.576702542941328 | validation: 1.0561387909382998]
	TIME [epoch: 24.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6918823292997436		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.6918823292997436 | validation: 0.7011316686480951]
	TIME [epoch: 24.8 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6643166843561978		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.6643166843561978 | validation: 0.7736815221474046]
	TIME [epoch: 24.8 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6259481618932188		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.6259481618932188 | validation: 0.7255819434854646]
	TIME [epoch: 24.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5795578383663874		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.5795578383663874 | validation: 0.6682287110904881]
	TIME [epoch: 24.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5292227103565175		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.5292227103565175 | validation: 0.6406585912071742]
	TIME [epoch: 24.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5066244692514124		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.5066244692514124 | validation: 0.569904495653319]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871253276391923		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.5871253276391923 | validation: 0.7794648024573906]
	TIME [epoch: 24.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5422748735998092		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.5422748735998092 | validation: 0.6387026049362688]
	TIME [epoch: 24.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5243496095559367		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.5243496095559367 | validation: 0.6221969568512806]
	TIME [epoch: 24.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5047994590135783		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.5047994590135783 | validation: 0.6125920947973085]
	TIME [epoch: 24.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5402135793750003		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.5402135793750003 | validation: 0.6289990258523237]
	TIME [epoch: 24.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5463038833683849		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.5463038833683849 | validation: 0.8816381617889146]
	TIME [epoch: 24.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6788502740828999		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.6788502740828999 | validation: 0.6456545907878252]
	TIME [epoch: 24.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5125672067840712		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.5125672067840712 | validation: 0.6666239666818717]
	TIME [epoch: 24.8 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.502141538549684		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.502141538549684 | validation: 0.6111034812115226]
	TIME [epoch: 24.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5099566705051897		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.5099566705051897 | validation: 0.615234307146276]
	TIME [epoch: 24.8 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5135492692748042		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.5135492692748042 | validation: 0.6156968901457084]
	TIME [epoch: 24.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5026524358561197		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5026524358561197 | validation: 0.641917408107093]
	TIME [epoch: 24.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6551983654822956		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.6551983654822956 | validation: 0.9529283616446621]
	TIME [epoch: 24.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7100170410744443		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.7100170410744443 | validation: 0.8704734236840974]
	TIME [epoch: 24.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6605961820993922		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.6605961820993922 | validation: 0.6621301377464923]
	TIME [epoch: 24.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7869488797442639		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.7869488797442639 | validation: 0.8247340163029492]
	TIME [epoch: 24.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8856934605855786		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.8856934605855786 | validation: 0.9934450701175593]
	TIME [epoch: 24.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6965464876412135		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.6965464876412135 | validation: 0.689246353247157]
	TIME [epoch: 24.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5297819857740783		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.5297819857740783 | validation: 0.7580120934026632]
	TIME [epoch: 24.8 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5870850489877699		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.5870850489877699 | validation: 0.7165179600396587]
	TIME [epoch: 24.8 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49502655084790353		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.49502655084790353 | validation: 0.6271007833664476]
	TIME [epoch: 24.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5592389194202506		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.5592389194202506 | validation: 0.757419865976975]
	TIME [epoch: 24.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5467074705732314		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.5467074705732314 | validation: 0.7231290850080374]
	TIME [epoch: 24.8 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5080636856029099		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.5080636856029099 | validation: 0.6302695455973675]
	TIME [epoch: 24.8 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49174232313831034		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.49174232313831034 | validation: 0.8200863569786868]
	TIME [epoch: 24.8 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5631688980957309		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.5631688980957309 | validation: 0.6853344024580154]
	TIME [epoch: 24.8 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5354479719098209		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.5354479719098209 | validation: 0.6852050562776358]
	TIME [epoch: 24.8 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5178168558142456		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.5178168558142456 | validation: 0.7045838904447302]
	TIME [epoch: 24.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.56032716848585		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.56032716848585 | validation: 0.6409111186860013]
	TIME [epoch: 24.8 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5171991423828618		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.5171991423828618 | validation: 0.6423870943027785]
	TIME [epoch: 24.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48966394390461954		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.48966394390461954 | validation: 0.6132761302983305]
	TIME [epoch: 24.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.537520197553343		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.537520197553343 | validation: 0.6838994222479456]
	TIME [epoch: 24.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5468075194078034		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.5468075194078034 | validation: 0.6992270288647109]
	TIME [epoch: 24.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49130551292671915		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.49130551292671915 | validation: 0.7468422669588113]
	TIME [epoch: 24.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5198696923682791		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.5198696923682791 | validation: 0.7050688911964141]
	TIME [epoch: 24.8 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.530702531233851		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.530702531233851 | validation: 0.721081288977986]
	TIME [epoch: 24.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.497183053046128		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.497183053046128 | validation: 0.6763612866958377]
	TIME [epoch: 24.8 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5018404987954155		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.5018404987954155 | validation: 0.7432371331331024]
	TIME [epoch: 24.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5754875270394665		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.5754875270394665 | validation: 0.7686801184138279]
	TIME [epoch: 24.8 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6049201083623508		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.6049201083623508 | validation: 0.6355482930003595]
	TIME [epoch: 24.8 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579253090633124		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.5579253090633124 | validation: 0.6918645463593618]
	TIME [epoch: 24.8 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6056276838225798		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.6056276838225798 | validation: 0.6892307393085665]
	TIME [epoch: 24.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.564502846879352		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.564502846879352 | validation: 0.6695594717528573]
	TIME [epoch: 24.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5020224733418852		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.5020224733418852 | validation: 0.6564949908151487]
	TIME [epoch: 24.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5180681831845649		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.5180681831845649 | validation: 0.6636370006654555]
	TIME [epoch: 24.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5818614128256095		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.5818614128256095 | validation: 0.6817400449388452]
	TIME [epoch: 24.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.53189846495141		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.53189846495141 | validation: 0.713814177013]
	TIME [epoch: 24.8 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5819343967885143		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.5819343967885143 | validation: 0.6505004165066944]
	TIME [epoch: 24.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5409600741921629		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.5409600741921629 | validation: 0.7358290785278305]
	TIME [epoch: 24.8 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5405788409119793		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.5405788409119793 | validation: 0.7407101626690047]
	TIME [epoch: 24.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5376691208391431		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.5376691208391431 | validation: 0.6727819595068758]
	TIME [epoch: 24.8 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6388843946551359		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.6388843946551359 | validation: 0.7092135761463377]
	TIME [epoch: 24.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5846834761217342		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.5846834761217342 | validation: 0.7005634413552417]
	TIME [epoch: 24.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5393439338283571		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.5393439338283571 | validation: 0.6826136847903963]
	TIME [epoch: 24.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5364103432064998		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.5364103432064998 | validation: 0.6949178095495764]
	TIME [epoch: 24.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5977812265823934		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.5977812265823934 | validation: 0.8270078150634785]
	TIME [epoch: 24.8 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5940754641550154		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.5940754641550154 | validation: 0.6459123096597247]
	TIME [epoch: 24.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.550660355558513		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.550660355558513 | validation: 0.677087974685993]
	TIME [epoch: 24.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6005541524442971		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.6005541524442971 | validation: 0.613638097763587]
	TIME [epoch: 24.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5133762373142253		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.5133762373142253 | validation: 0.6535735644889198]
	TIME [epoch: 24.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5111120162779657		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.5111120162779657 | validation: 0.6684541242870379]
	TIME [epoch: 24.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6438523924519061		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.6438523924519061 | validation: 0.7479071227609078]
	TIME [epoch: 24.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5637525332147749		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.5637525332147749 | validation: 0.6654672722959498]
	TIME [epoch: 24.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5714791253479249		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.5714791253479249 | validation: 0.8307214953234151]
	TIME [epoch: 24.8 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6370489320328673		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.6370489320328673 | validation: 0.759022828289859]
	TIME [epoch: 24.8 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5559738344018088		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.5559738344018088 | validation: 0.6383186700861969]
	TIME [epoch: 24.8 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5431179759442681		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.5431179759442681 | validation: 0.6960017827154761]
	TIME [epoch: 24.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5297527306431536		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.5297527306431536 | validation: 0.6279159468337099]
	TIME [epoch: 24.8 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5202365146276738		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.5202365146276738 | validation: 0.7319840203609027]
	TIME [epoch: 24.8 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5809812789201613		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.5809812789201613 | validation: 0.7049854903766755]
	TIME [epoch: 24.8 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5311696131604278		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.5311696131604278 | validation: 0.6387137589168582]
	TIME [epoch: 24.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.504283949908886		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.504283949908886 | validation: 0.7093887349093442]
	TIME [epoch: 24.8 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5471726060225278		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.5471726060225278 | validation: 0.7318652885885775]
	TIME [epoch: 24.8 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5540610020400912		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.5540610020400912 | validation: 0.6571698574677584]
	TIME [epoch: 24.8 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5153141093439346		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.5153141093439346 | validation: 0.6021235964225709]
	TIME [epoch: 24.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4816233323343021		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.4816233323343021 | validation: 0.5845128565750713]
	TIME [epoch: 24.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4886257198618485		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.4886257198618485 | validation: 0.6485143478670284]
	TIME [epoch: 24.8 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4881727085422273		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.4881727085422273 | validation: 0.5884843594636411]
	TIME [epoch: 24.8 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47560382106476223		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.47560382106476223 | validation: 0.6956425567174057]
	TIME [epoch: 24.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261489750636841		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.5261489750636841 | validation: 0.5846459797504813]
	TIME [epoch: 24.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.485305868865925		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.485305868865925 | validation: 0.6407892332055033]
	TIME [epoch: 24.8 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47313358572114067		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.47313358572114067 | validation: 0.5712188675892726]
	TIME [epoch: 24.8 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44918380375671835		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.44918380375671835 | validation: 0.5649837235357059]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_781.pth
	Model improved!!!
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4816515157048211		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.4816515157048211 | validation: 0.5613943121288593]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_782.pth
	Model improved!!!
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46784172127729995		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.46784172127729995 | validation: 0.5851406148438707]
	TIME [epoch: 25 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45835487174445255		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.45835487174445255 | validation: 0.538473449701065]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_784.pth
	Model improved!!!
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5305613815178959		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.5305613815178959 | validation: 0.5737279793632915]
	TIME [epoch: 24.8 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5263241920951661		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.5263241920951661 | validation: 0.6814598075326198]
	TIME [epoch: 24.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501175322696338		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.501175322696338 | validation: 0.7097833741400967]
	TIME [epoch: 24.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5955332501524626		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.5955332501524626 | validation: 0.5773496954282427]
	TIME [epoch: 24.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4661076591062821		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.4661076591062821 | validation: 0.562069581668039]
	TIME [epoch: 24.8 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4580091015019576		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.4580091015019576 | validation: 0.5739087817318855]
	TIME [epoch: 24.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5203548699489623		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.5203548699489623 | validation: 0.5661668913038699]
	TIME [epoch: 24.8 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4533968107685204		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.4533968107685204 | validation: 0.5579579654511706]
	TIME [epoch: 24.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46965508970434744		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.46965508970434744 | validation: 0.5714178102551335]
	TIME [epoch: 24.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5140418124285937		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.5140418124285937 | validation: 0.6879769475964637]
	TIME [epoch: 24.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48943575673223383		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.48943575673223383 | validation: 0.5760305125772046]
	TIME [epoch: 24.8 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4855719736387605		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.4855719736387605 | validation: 0.5799161185076781]
	TIME [epoch: 24.8 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44602988984075814		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.44602988984075814 | validation: 0.5395609794905761]
	TIME [epoch: 24.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4593546986636107		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.4593546986636107 | validation: 0.5346383294580116]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_798.pth
	Model improved!!!
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4504385893297716		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.4504385893297716 | validation: 0.5978412679459605]
	TIME [epoch: 24.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4690562521395913		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.4690562521395913 | validation: 0.6120618756305942]
	TIME [epoch: 24.8 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4517650058882002		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.4517650058882002 | validation: 0.610935556682521]
	TIME [epoch: 24.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4799877089940158		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.4799877089940158 | validation: 0.7801155404304337]
	TIME [epoch: 24.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.733399384614632		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.733399384614632 | validation: 0.871087950125592]
	TIME [epoch: 24.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6302864205258151		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.6302864205258151 | validation: 0.6916558301085681]
	TIME [epoch: 24.7 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.545479242645404		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.545479242645404 | validation: 0.6917700675814774]
	TIME [epoch: 24.8 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5264147372782408		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.5264147372782408 | validation: 0.6206436623752298]
	TIME [epoch: 24.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49588782873783505		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.49588782873783505 | validation: 0.591400309956866]
	TIME [epoch: 24.7 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4584349610948889		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.4584349610948889 | validation: 0.5696754334261969]
	TIME [epoch: 24.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46411838098984354		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.46411838098984354 | validation: 0.67937483045469]
	TIME [epoch: 24.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48689785991724327		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.48689785991724327 | validation: 0.6472282049080771]
	TIME [epoch: 24.8 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45320791081893236		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.45320791081893236 | validation: 0.7162535646904578]
	TIME [epoch: 24.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.535420552898585		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.535420552898585 | validation: 0.686612037021552]
	TIME [epoch: 24.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49368884447731104		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.49368884447731104 | validation: 0.6409806050478142]
	TIME [epoch: 24.8 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49564115720965224		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.49564115720965224 | validation: 0.6453838390542914]
	TIME [epoch: 24.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5045046274208449		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.5045046274208449 | validation: 0.6226735670101248]
	TIME [epoch: 24.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5065547164573584		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.5065547164573584 | validation: 0.6593124108454613]
	TIME [epoch: 24.8 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48566349348435134		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.48566349348435134 | validation: 0.6164809129158556]
	TIME [epoch: 24.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4867023789413434		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4867023789413434 | validation: 0.6445926596569987]
	TIME [epoch: 24.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.541452277037442		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.541452277037442 | validation: 0.5974311472007876]
	TIME [epoch: 24.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037472247837158		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.5037472247837158 | validation: 0.5894181722778037]
	TIME [epoch: 24.8 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48667221127701593		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.48667221127701593 | validation: 0.5508888691400706]
	TIME [epoch: 24.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5255942731399361		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.5255942731399361 | validation: 0.6512665733174111]
	TIME [epoch: 24.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5258197346770619		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.5258197346770619 | validation: 0.5543875269824815]
	TIME [epoch: 24.8 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.464362442571921		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.464362442571921 | validation: 0.5648522376392697]
	TIME [epoch: 24.8 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4876918220148828		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.4876918220148828 | validation: 0.6432579021155528]
	TIME [epoch: 24.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49832452258818094		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.49832452258818094 | validation: 0.6684392284683852]
	TIME [epoch: 24.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4903399252832613		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.4903399252832613 | validation: 0.5815450020114254]
	TIME [epoch: 24.8 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4829187689421798		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.4829187689421798 | validation: 0.573816651038022]
	TIME [epoch: 24.8 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46068523259281163		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.46068523259281163 | validation: 0.553126953711293]
	TIME [epoch: 24.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5185273905463662		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.5185273905463662 | validation: 0.6770284773132987]
	TIME [epoch: 24.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.544499966555196		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.544499966555196 | validation: 0.7192914751235564]
	TIME [epoch: 24.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6020360374183198		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.6020360374183198 | validation: 0.653257505840735]
	TIME [epoch: 24.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47500848650564786		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.47500848650564786 | validation: 0.583659632592698]
	TIME [epoch: 24.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.466156886312059		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.466156886312059 | validation: 0.5636369960501528]
	TIME [epoch: 24.8 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4623088654284149		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.4623088654284149 | validation: 0.5952503536438735]
	TIME [epoch: 24.8 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48379298979606383		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.48379298979606383 | validation: 0.6031287358888425]
	TIME [epoch: 24.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47160299988324994		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.47160299988324994 | validation: 0.6293639948033548]
	TIME [epoch: 24.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5421210468271904		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.5421210468271904 | validation: 0.6603861010691614]
	TIME [epoch: 24.8 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49615436934558993		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.49615436934558993 | validation: 0.6058965158895419]
	TIME [epoch: 24.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.503873217709854		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.503873217709854 | validation: 0.631659327830065]
	TIME [epoch: 24.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5000772953925895		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.5000772953925895 | validation: 0.672586772164646]
	TIME [epoch: 24.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572736259524914		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.572736259524914 | validation: 0.6474908945664936]
	TIME [epoch: 24.8 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5253051570548785		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.5253051570548785 | validation: 0.6854273333904983]
	TIME [epoch: 24.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5545840067832369		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.5545840067832369 | validation: 0.6599171845200584]
	TIME [epoch: 24.8 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5265381671294111		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.5265381671294111 | validation: 0.6458436965738057]
	TIME [epoch: 24.8 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5342083170095453		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.5342083170095453 | validation: 0.6361879011899777]
	TIME [epoch: 24.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5427929568767592		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.5427929568767592 | validation: 0.742510125292485]
	TIME [epoch: 24.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5428156752621878		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.5428156752621878 | validation: 0.664629149290635]
	TIME [epoch: 24.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5110986661591701		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.5110986661591701 | validation: 0.603945999467095]
	TIME [epoch: 24.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568853097526266		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.568853097526266 | validation: 0.7129804171235392]
	TIME [epoch: 24.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5505690177867961		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.5505690177867961 | validation: 0.6553163881550199]
	TIME [epoch: 24.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5163368223822018		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.5163368223822018 | validation: 0.6111325789132523]
	TIME [epoch: 24.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5082959767832825		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.5082959767832825 | validation: 0.5759627629914574]
	TIME [epoch: 24.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.488460193139282		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.488460193139282 | validation: 0.7673507919998898]
	TIME [epoch: 24.7 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6026034821230517		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.6026034821230517 | validation: 0.6181429635337559]
	TIME [epoch: 24.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4815630310389416		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.4815630310389416 | validation: 0.6178581089230113]
	TIME [epoch: 24.8 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47605583421563963		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.47605583421563963 | validation: 0.5639498027899766]
	TIME [epoch: 24.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.466199389973317		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.466199389973317 | validation: 0.5799525437027787]
	TIME [epoch: 24.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45171131023623756		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.45171131023623756 | validation: 0.6439991468780177]
	TIME [epoch: 24.8 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4876531770557308		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.4876531770557308 | validation: 0.6512066039210964]
	TIME [epoch: 24.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4759215015387014		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.4759215015387014 | validation: 0.5852031564443797]
	TIME [epoch: 24.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4612130637466628		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.4612130637466628 | validation: 0.597552811114709]
	TIME [epoch: 24.8 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4662414124540053		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.4662414124540053 | validation: 0.5495549296847516]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727653208160905		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.4727653208160905 | validation: 0.5773162613931002]
	TIME [epoch: 24.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46724285818447797		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.46724285818447797 | validation: 0.5616150557760888]
	TIME [epoch: 24.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556826507224543		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.4556826507224543 | validation: 0.5522238800704853]
	TIME [epoch: 24.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46689921587352123		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.46689921587352123 | validation: 0.5686808447096615]
	TIME [epoch: 24.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47681825925107113		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.47681825925107113 | validation: 0.5221624994383649]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study5/model_tr_study5_r1_20240309_135644/states/model_tr_study5_868.pth
	Model improved!!!
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4834642934671154		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.4834642934671154 | validation: 0.6042776006857189]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5067336805523744		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.5067336805523744 | validation: 0.5684373737266317]
	TIME [epoch: 24.8 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5568149313551134		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.5568149313551134 | validation: 0.7036355071871955]
	TIME [epoch: 24.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5739431677242514		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.5739431677242514 | validation: 0.557004855258908]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5007288016481319		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.5007288016481319 | validation: 0.6107909500969155]
	TIME [epoch: 24.8 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48087285483055703		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.48087285483055703 | validation: 0.6113548066816221]
	TIME [epoch: 24.8 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5210519417809595		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.5210519417809595 | validation: 0.5761941210996272]
	TIME [epoch: 24.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46107850834789366		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.46107850834789366 | validation: 0.5339967259557328]
	TIME [epoch: 24.8 sec]
EPOCH 877/2000:
	Training over batches...
