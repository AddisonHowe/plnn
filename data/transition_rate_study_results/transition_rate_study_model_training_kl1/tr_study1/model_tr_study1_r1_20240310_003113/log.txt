Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r1', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 775393221

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.102464801094541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.102464801094541 | validation: 9.799899675097157]
	TIME [epoch: 98.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.120992474018314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.120992474018314 | validation: 9.294452593939585]
	TIME [epoch: 6.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.639254379394739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.639254379394739 | validation: 8.145166945766913]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.078463656020401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.078463656020401 | validation: 7.934320595115257]
	TIME [epoch: 6.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.615026906149274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.615026906149274 | validation: 6.924877358270796]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.340589542240372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.340589542240372 | validation: 6.760458498166926]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.06976140961499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.06976140961499 | validation: 6.67221717714265]
	TIME [epoch: 6.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.393327399522281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.393327399522281 | validation: 6.472041466881891]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.852426545239791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.852426545239791 | validation: 6.296594873656148]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.7306100727107685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.7306100727107685 | validation: 6.675470743451426]
	TIME [epoch: 6.55 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.747975867735885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.747975867735885 | validation: 6.148416848781097]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.5834920726149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5834920726149 | validation: 6.1192045279941345]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.503318780760303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.503318780760303 | validation: 5.970121564287438]
	TIME [epoch: 6.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.975192733162896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.975192733162896 | validation: 6.507666921935664]
	TIME [epoch: 6.59 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.556958060517815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.556958060517815 | validation: 6.450238344983728]
	TIME [epoch: 6.52 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.746239211461139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.746239211461139 | validation: 5.855603578587941]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.3982697157900175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.3982697157900175 | validation: 5.7088153885943305]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.300466122140855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.300466122140855 | validation: 5.5901146555501295]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2415486958634325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2415486958634325 | validation: 5.5188977709783265]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.53526070635643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.53526070635643 | validation: 5.428998374399089]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.78516448142416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.78516448142416 | validation: 5.496561637003386]
	TIME [epoch: 6.59 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.935867303285692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.935867303285692 | validation: 4.91048009094975]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6609135033045925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6609135033045925 | validation: 5.599003547902632]
	TIME [epoch: 7.14 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.004444456056733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.004444456056733 | validation: 5.007734001361688]
	TIME [epoch: 6.56 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.848623771294719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.848623771294719 | validation: 5.17084795266376]
	TIME [epoch: 6.5 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.870782995582058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.870782995582058 | validation: 4.597032695821102]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.5382568724407735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5382568724407735 | validation: 4.656701773020439]
	TIME [epoch: 6.58 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.617576963512137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.617576963512137 | validation: 4.473822037866636]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.22375363572977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.22375363572977 | validation: 4.421109733424713]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.06644820772951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.06644820772951 | validation: 4.240425230409734]
	TIME [epoch: 6.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.00637750995434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.00637750995434 | validation: 4.072316822662895]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0989227114566456		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0989227114566456 | validation: 3.947849704290237]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7165060234751905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7165060234751905 | validation: 4.141551598899931]
	TIME [epoch: 6.61 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8261284493819887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8261284493819887 | validation: 3.550896131222474]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9995441272408216		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9995441272408216 | validation: 3.4235549777255954]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3652469515796097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3652469515796097 | validation: 4.086346721394313]
	TIME [epoch: 6.56 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5981943197403776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5981943197403776 | validation: 3.6810687024581985]
	TIME [epoch: 6.57 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3624700321500933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3624700321500933 | validation: 2.970828761447028]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0168747772569864		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0168747772569864 | validation: 3.577328800579749]
	TIME [epoch: 6.55 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6794271659062137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6794271659062137 | validation: 3.113517595999405]
	TIME [epoch: 6.57 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.993263885806719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.993263885806719 | validation: 2.5694914641740416]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.944245428245243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.944245428245243 | validation: 3.1272089609046567]
	TIME [epoch: 6.56 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.765456030341973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.765456030341973 | validation: 2.5497830927071257]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.875187390195375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.875187390195375 | validation: 2.6820672508140184]
	TIME [epoch: 6.57 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.943370922405827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.943370922405827 | validation: 2.418554634410767]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.349973003253303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.349973003253303 | validation: 2.70713152172654]
	TIME [epoch: 6.56 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.892337212996749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.892337212996749 | validation: 2.295839835917949]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.91589763829273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.91589763829273 | validation: 2.220994631567423]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.403524231986632		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.403524231986632 | validation: 2.2524995219032498]
	TIME [epoch: 6.57 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5877814224208175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5877814224208175 | validation: 2.1834971934251564]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3702790701744925		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.3702790701744925 | validation: 2.22270620464625]
	TIME [epoch: 6.55 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3371890682621985		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.3371890682621985 | validation: 2.611524590729983]
	TIME [epoch: 6.56 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6566986989566024		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.6566986989566024 | validation: 2.591420901650555]
	TIME [epoch: 6.55 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2940348690777137		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.2940348690777137 | validation: 1.8208826506211824]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.328501457631611		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.328501457631611 | validation: 2.1014153046697737]
	TIME [epoch: 6.57 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0361313988340863		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.0361313988340863 | validation: 2.5556114465715996]
	TIME [epoch: 6.55 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.606207237105188		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.606207237105188 | validation: 1.784322080018048]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6048181520273093		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.6048181520273093 | validation: 2.512147580887648]
	TIME [epoch: 6.57 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.532119359981145		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.532119359981145 | validation: 2.043644532901149]
	TIME [epoch: 6.54 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1518834986229614		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.1518834986229614 | validation: 3.236896173593079]
	TIME [epoch: 6.53 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8205283501567417		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.8205283501567417 | validation: 2.6155908653323845]
	TIME [epoch: 6.55 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3086285588614492		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.3086285588614492 | validation: 1.973925812598514]
	TIME [epoch: 6.57 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1830967977616327		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.1830967977616327 | validation: 2.2488433612632805]
	TIME [epoch: 6.49 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1540450136583273		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.1540450136583273 | validation: 2.3307334246144804]
	TIME [epoch: 6.55 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0556541789073557		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.0556541789073557 | validation: 3.8504764461448278]
	TIME [epoch: 6.55 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.565038826799926		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.565038826799926 | validation: 2.538581017636332]
	TIME [epoch: 6.54 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3999199789262993		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.3999199789262993 | validation: 1.8397933848160608]
	TIME [epoch: 6.54 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.891539596727306		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.891539596727306 | validation: 2.1982591467121684]
	TIME [epoch: 6.55 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.918774048668722		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.918774048668722 | validation: 2.678636964914805]
	TIME [epoch: 6.56 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.227224007056962		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.227224007056962 | validation: 2.0236247308356075]
	TIME [epoch: 6.59 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1966392529730063		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.1966392529730063 | validation: 2.0467818454961573]
	TIME [epoch: 6.52 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9802324773494142		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.9802324773494142 | validation: 1.9062870265236376]
	TIME [epoch: 6.54 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8546953268305828		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.8546953268305828 | validation: 1.9140947708419862]
	TIME [epoch: 6.54 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.798140784540682		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.798140784540682 | validation: 1.7501905045907487]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9177648583858715		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.9177648583858715 | validation: 1.9370108983725913]
	TIME [epoch: 6.61 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.041632387616654		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.041632387616654 | validation: 1.5162420295069599]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.755549696647235		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.755549696647235 | validation: 1.539524744594753]
	TIME [epoch: 6.53 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6951959426162047		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.6951959426162047 | validation: 1.2779425418378103]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5683532068626052		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.5683532068626052 | validation: 1.6236886324553503]
	TIME [epoch: 6.55 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7538184867359226		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.7538184867359226 | validation: 2.000671156068811]
	TIME [epoch: 6.55 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6778020952726784		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.6778020952726784 | validation: 1.7036620188176266]
	TIME [epoch: 6.56 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8342625217653696		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.8342625217653696 | validation: 1.3271773715136255]
	TIME [epoch: 6.56 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6670985017009712		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.6670985017009712 | validation: 1.3235124755672416]
	TIME [epoch: 6.55 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.670687188217761		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.670687188217761 | validation: 1.6681400189380216]
	TIME [epoch: 6.57 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7752941115138743		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.7752941115138743 | validation: 2.562431487444535]
	TIME [epoch: 6.61 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0046867755794113		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.0046867755794113 | validation: 1.2560406127621266]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_86.pth
	Model improved!!!
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5568620872138577		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.5568620872138577 | validation: 1.5245858699732673]
	TIME [epoch: 6.57 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6605355200837337		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.6605355200837337 | validation: 1.743729498002233]
	TIME [epoch: 6.58 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0369080499580168		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.0369080499580168 | validation: 2.0199294111032184]
	TIME [epoch: 6.5 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6103145448982275		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.6103145448982275 | validation: 1.2986625325892578]
	TIME [epoch: 6.56 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5802031818676223		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.5802031818676223 | validation: 1.9180999266437646]
	TIME [epoch: 6.55 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7395764795063116		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.7395764795063116 | validation: 1.1130691298497946]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6085190806829788		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.6085190806829788 | validation: 1.160549309147527]
	TIME [epoch: 6.55 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5703929283199851		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.5703929283199851 | validation: 1.393729662290516]
	TIME [epoch: 6.56 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4859352301012543		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.4859352301012543 | validation: 1.4228685063776936]
	TIME [epoch: 6.51 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8357175579952258		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.8357175579952258 | validation: 1.6594663218905816]
	TIME [epoch: 6.58 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4446894777982082		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.4446894777982082 | validation: 1.6867920536932814]
	TIME [epoch: 6.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4962190469162873		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.4962190469162873 | validation: 1.3306205302945595]
	TIME [epoch: 6.55 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5777573445199162		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.5777573445199162 | validation: 1.289083706019104]
	TIME [epoch: 6.56 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5567907623234813		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.5567907623234813 | validation: 1.0877483685811615]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.046302025734182		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.046302025734182 | validation: 1.3899203614668107]
	TIME [epoch: 6.56 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9802462989171699		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.9802462989171699 | validation: 1.4861489550496003]
	TIME [epoch: 6.56 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4404619491743431		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.4404619491743431 | validation: 1.4578970346137163]
	TIME [epoch: 6.54 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4931783246011254		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.4931783246011254 | validation: 1.2540465931695126]
	TIME [epoch: 6.54 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5176239961567197		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.5176239961567197 | validation: 2.037014956023686]
	TIME [epoch: 6.58 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6307454577548843		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.6307454577548843 | validation: 0.9259654923354296]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.366638500467127		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.366638500467127 | validation: 0.929288699963322]
	TIME [epoch: 6.56 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5424061175998736		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.5424061175998736 | validation: 1.3630255008966685]
	TIME [epoch: 6.52 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3153696612203154		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.3153696612203154 | validation: 1.3607331651598176]
	TIME [epoch: 6.54 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4238138562342688		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.4238138562342688 | validation: 1.1866242660503565]
	TIME [epoch: 6.56 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5952229016320254		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.5952229016320254 | validation: 1.0339374246802646]
	TIME [epoch: 6.56 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.245770479568036		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.245770479568036 | validation: 1.27064190197467]
	TIME [epoch: 6.57 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9186480921544333		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.9186480921544333 | validation: 2.7106714862915546]
	TIME [epoch: 6.49 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8383158285588612		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.8383158285588612 | validation: 1.969179736627499]
	TIME [epoch: 6.54 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6813909185733178		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.6813909185733178 | validation: 1.0745600379972335]
	TIME [epoch: 6.54 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3851420345738297		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.3851420345738297 | validation: 0.9683324009545126]
	TIME [epoch: 6.54 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1554858386141225		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.1554858386141225 | validation: 1.2849601316573656]
	TIME [epoch: 6.54 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.313289209742848		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.313289209742848 | validation: 1.1958284939225405]
	TIME [epoch: 6.56 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2571967755447726		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.2571967755447726 | validation: 1.2584339496654946]
	TIME [epoch: 6.55 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154481805877379		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.154481805877379 | validation: 1.596530460756087]
	TIME [epoch: 6.54 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.408457726428738		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.408457726428738 | validation: 0.9188461756127103]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0774577406702297		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.0774577406702297 | validation: 1.3637755669490614]
	TIME [epoch: 6.53 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2674010425661166		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.2674010425661166 | validation: 1.1959889181314338]
	TIME [epoch: 6.58 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2086328021363246		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.2086328021363246 | validation: 1.132052934466154]
	TIME [epoch: 6.56 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.110231851573526		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.110231851573526 | validation: 1.1510624587239462]
	TIME [epoch: 6.54 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.252300049444975		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.252300049444975 | validation: 1.2379560646044834]
	TIME [epoch: 6.49 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5358116823614796		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.5358116823614796 | validation: 1.0849434726743648]
	TIME [epoch: 6.56 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1825643493972853		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.1825643493972853 | validation: 0.8990828554457658]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_128.pth
	Model improved!!!
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4419274437099272		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.4419274437099272 | validation: 0.8168315746866588]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3602076030244827		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.3602076030244827 | validation: 1.0636424137812384]
	TIME [epoch: 6.55 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2236125291938227		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.2236125291938227 | validation: 1.1762382011500536]
	TIME [epoch: 6.55 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2810773023512407		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.2810773023512407 | validation: 0.8255118156415034]
	TIME [epoch: 6.57 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1568685277008857		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.1568685277008857 | validation: 0.8085282327084062]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.161756608305103		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.161756608305103 | validation: 0.9237608054382893]
	TIME [epoch: 6.53 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2959873645186308		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.2959873645186308 | validation: 1.0814431666039872]
	TIME [epoch: 6.56 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2994147193635268		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.2994147193635268 | validation: 1.088801685373583]
	TIME [epoch: 6.55 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0828691977667957		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.0828691977667957 | validation: 0.8245474398957896]
	TIME [epoch: 6.55 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3066120020856264		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.3066120020856264 | validation: 1.1801813099452765]
	TIME [epoch: 6.57 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1692179829347102		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.1692179829347102 | validation: 1.1099581504635259]
	TIME [epoch: 6.57 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2523202434567242		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.2523202434567242 | validation: 1.2160282611681295]
	TIME [epoch: 6.55 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2521758947857418		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.2521758947857418 | validation: 1.0225207542590176]
	TIME [epoch: 6.58 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0530208450156193		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.0530208450156193 | validation: 1.2398699383030003]
	TIME [epoch: 6.51 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0623276354724809		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.0623276354724809 | validation: 0.8590237617408684]
	TIME [epoch: 6.57 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.160703502118549		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.160703502118549 | validation: 0.7764311684936539]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9772224222504119		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.9772224222504119 | validation: 1.3654255787548522]
	TIME [epoch: 6.56 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4585353447272014		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.4585353447272014 | validation: 1.9684030041888907]
	TIME [epoch: 6.56 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.71864349406053		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.71864349406053 | validation: 0.9295456650018009]
	TIME [epoch: 6.55 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0530074087856418		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.0530074087856418 | validation: 1.2662240360129198]
	TIME [epoch: 6.56 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1010475759767475		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.1010475759767475 | validation: 0.8413762058128018]
	TIME [epoch: 6.58 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.06071685679556		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.06071685679556 | validation: 0.8678089237653]
	TIME [epoch: 6.52 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9241757181092776		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.9241757181092776 | validation: 1.6637632525141908]
	TIME [epoch: 6.56 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2263238413322164		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.2263238413322164 | validation: 1.6667885934924107]
	TIME [epoch: 6.56 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3510636937495095		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.3510636937495095 | validation: 1.0801839397681752]
	TIME [epoch: 6.57 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0977534196715757		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.0977534196715757 | validation: 0.7876842609747032]
	TIME [epoch: 6.57 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0120645765576737		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.0120645765576737 | validation: 1.0415566443810926]
	TIME [epoch: 6.57 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0250260469050245		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.0250260469050245 | validation: 0.9971834409166005]
	TIME [epoch: 6.51 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0501855528903081		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.0501855528903081 | validation: 0.7672281206873766]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_157.pth
	Model improved!!!
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.159731031935312		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.159731031935312 | validation: 0.9302359091941824]
	TIME [epoch: 6.55 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1823669923229212		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.1823669923229212 | validation: 0.9654373381468179]
	TIME [epoch: 6.56 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9752170024440583		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.9752170024440583 | validation: 1.2642141463920782]
	TIME [epoch: 6.54 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0745534308292388		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.0745534308292388 | validation: 1.0242967351641328]
	TIME [epoch: 6.57 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.056234413510676		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.056234413510676 | validation: 0.8560449914521318]
	TIME [epoch: 6.56 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9838094733796006		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.9838094733796006 | validation: 0.7849731876860778]
	TIME [epoch: 6.57 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0366022598741587		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.0366022598741587 | validation: 0.6880329857944577]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0106431062769006		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.0106431062769006 | validation: 0.8448645953946567]
	TIME [epoch: 6.58 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.966970256584142		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.966970256584142 | validation: 1.1803343738132026]
	TIME [epoch: 6.58 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1067207802684336		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.1067207802684336 | validation: 0.8185004105929917]
	TIME [epoch: 6.5 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0015292674066347		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.0015292674066347 | validation: 0.8464348012595988]
	TIME [epoch: 6.56 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9104503729334102		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.9104503729334102 | validation: 0.9295880137252489]
	TIME [epoch: 6.57 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9171497949708948		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.9171497949708948 | validation: 0.7701919065613936]
	TIME [epoch: 6.56 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9656826269019537		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.9656826269019537 | validation: 0.9743570034838966]
	TIME [epoch: 6.56 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0413367459547722		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.0413367459547722 | validation: 0.9015481647451573]
	TIME [epoch: 6.59 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0182007897297716		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.0182007897297716 | validation: 1.1185693668843906]
	TIME [epoch: 6.52 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0383062096770317		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.0383062096770317 | validation: 1.4491749144241886]
	TIME [epoch: 6.56 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0244536632110912		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.0244536632110912 | validation: 0.9358009415394165]
	TIME [epoch: 6.55 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8444773200433652		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.8444773200433652 | validation: 1.3910287047877694]
	TIME [epoch: 6.57 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1561878402120784		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.1561878402120784 | validation: 0.8497094109129592]
	TIME [epoch: 6.55 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9237977648675197		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.9237977648675197 | validation: 1.0609841120208479]
	TIME [epoch: 6.51 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9374760046120237		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.9374760046120237 | validation: 0.6254624601248807]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0088766362967183		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.0088766362967183 | validation: 0.8053597929293247]
	TIME [epoch: 6.58 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0323953905986132		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.0323953905986132 | validation: 0.7500049962056758]
	TIME [epoch: 6.58 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0058322794312569		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.0058322794312569 | validation: 1.2791773330836942]
	TIME [epoch: 6.51 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1087476089788968		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.1087476089788968 | validation: 0.7010844632216648]
	TIME [epoch: 6.55 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8822352834086051		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.8822352834086051 | validation: 1.2669348473030544]
	TIME [epoch: 6.57 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2793747977236636		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.2793747977236636 | validation: 1.2427522498270924]
	TIME [epoch: 6.55 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0831744261989695		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.0831744261989695 | validation: 0.863219702555721]
	TIME [epoch: 6.55 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.058903205513643		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.058903205513643 | validation: 0.759281665385611]
	TIME [epoch: 6.5 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0139532642309534		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.0139532642309534 | validation: 0.9028279311720673]
	TIME [epoch: 6.56 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1328035440886397		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.1328035440886397 | validation: 0.7623183962215836]
	TIME [epoch: 6.56 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0455508975528756		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.0455508975528756 | validation: 1.04101169801865]
	TIME [epoch: 6.57 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9325719936400259		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.9325719936400259 | validation: 0.895354390654525]
	TIME [epoch: 6.49 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8619814727958649		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.8619814727958649 | validation: 1.1912693829910992]
	TIME [epoch: 6.57 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9618654241074748		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.9618654241074748 | validation: 0.7201487564784964]
	TIME [epoch: 6.56 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1721381015500745		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.1721381015500745 | validation: 0.8090198705780565]
	TIME [epoch: 6.57 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8081290518030225		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.8081290518030225 | validation: 1.0536579002029933]
	TIME [epoch: 6.55 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8892739917229203		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8892739917229203 | validation: 0.7313925874035073]
	TIME [epoch: 7.11 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9430421447983492		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.9430421447983492 | validation: 0.8883571584048876]
	TIME [epoch: 6.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9429475949111831		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.9429475949111831 | validation: 0.7058091011158804]
	TIME [epoch: 6.54 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8284551017318341		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.8284551017318341 | validation: 0.781207887137937]
	TIME [epoch: 6.57 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1045165695362227		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.1045165695362227 | validation: 0.7557433494268478]
	TIME [epoch: 6.57 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7940910383057467		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.7940910383057467 | validation: 0.9094797067742338]
	TIME [epoch: 6.57 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8832431244792048		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8832431244792048 | validation: 0.7014144951899488]
	TIME [epoch: 6.56 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7742449438133172		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.7742449438133172 | validation: 0.7529510066116876]
	TIME [epoch: 6.57 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1465148279448483		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 1.1465148279448483 | validation: 1.8590671436255626]
	TIME [epoch: 6.57 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.220042518111943		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.220042518111943 | validation: 0.7647609762501035]
	TIME [epoch: 6.56 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9151650564724356		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.9151650564724356 | validation: 0.8569790374044635]
	TIME [epoch: 6.52 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8234322625316395		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.8234322625316395 | validation: 0.8925694310572458]
	TIME [epoch: 6.57 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8544026575773863		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.8544026575773863 | validation: 0.8098627894804262]
	TIME [epoch: 6.56 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8493755435893333		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8493755435893333 | validation: 1.0324570354177316]
	TIME [epoch: 6.56 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9982431564766312		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.9982431564766312 | validation: 0.751178469483114]
	TIME [epoch: 6.57 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9021721410560986		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.9021721410560986 | validation: 0.9650505880834698]
	TIME [epoch: 6.61 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7978602872979981		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.7978602872979981 | validation: 0.7643023900519411]
	TIME [epoch: 6.55 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.007863797480658		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.007863797480658 | validation: 1.0908797746978385]
	TIME [epoch: 6.59 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.031701306343771		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.031701306343771 | validation: 1.7507699215548602]
	TIME [epoch: 6.51 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0883251841690096		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.0883251841690096 | validation: 0.6486779172540418]
	TIME [epoch: 6.57 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9631333973024829		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.9631333973024829 | validation: 1.8944933904188765]
	TIME [epoch: 6.57 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2130736399872186		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.2130736399872186 | validation: 0.7008721217844301]
	TIME [epoch: 6.57 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7391344944504046		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.7391344944504046 | validation: 0.7120944679265654]
	TIME [epoch: 6.57 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8089093187689809		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.8089093187689809 | validation: 0.6672207615386657]
	TIME [epoch: 6.58 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7908449567601611		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.7908449567601611 | validation: 0.5642131348864827]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_220.pth
	Model improved!!!
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8719289734270346		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.8719289734270346 | validation: 0.5489864286151577]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_221.pth
	Model improved!!!
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.907204891246922		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.907204891246922 | validation: 0.7120587548836566]
	TIME [epoch: 6.58 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2417691428440008		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.2417691428440008 | validation: 0.7736951034769635]
	TIME [epoch: 6.57 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9553142751330792		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.9553142751330792 | validation: 0.6376006709238184]
	TIME [epoch: 6.55 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8224588827833201		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.8224588827833201 | validation: 0.6894213305173168]
	TIME [epoch: 6.55 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.786399131025292		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.786399131025292 | validation: 0.6170739137658044]
	TIME [epoch: 6.58 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7758780905751772		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.7758780905751772 | validation: 1.446158550951988]
	TIME [epoch: 6.56 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9515104534647485		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.9515104534647485 | validation: 0.8113542802334959]
	TIME [epoch: 6.56 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8150358166964741		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8150358166964741 | validation: 0.6958110163846942]
	TIME [epoch: 6.56 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.818340301817601		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.818340301817601 | validation: 0.538980195181387]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8042011320985052		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.8042011320985052 | validation: 0.6642773802827262]
	TIME [epoch: 6.55 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7849145612520714		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.7849145612520714 | validation: 0.7414016308057569]
	TIME [epoch: 6.58 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9142273891516218		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.9142273891516218 | validation: 0.7104818465918891]
	TIME [epoch: 6.55 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8066878706441012		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8066878706441012 | validation: 0.592032548585052]
	TIME [epoch: 6.58 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8179814670033949		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.8179814670033949 | validation: 0.785136089017108]
	TIME [epoch: 6.53 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8638411311098617		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.8638411311098617 | validation: 0.61346210709207]
	TIME [epoch: 6.59 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8673011654179597		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.8673011654179597 | validation: 0.7060367204098722]
	TIME [epoch: 6.56 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8978251945858264		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.8978251945858264 | validation: 0.6225443138072715]
	TIME [epoch: 6.55 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8024651685493933		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.8024651685493933 | validation: 0.9557147801669703]
	TIME [epoch: 6.56 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.869109722833241		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.869109722833241 | validation: 0.7865451619659297]
	TIME [epoch: 6.56 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7547589974892206		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.7547589974892206 | validation: 1.520120471960039]
	TIME [epoch: 6.55 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1292483967411637		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.1292483967411637 | validation: 0.8497690817978821]
	TIME [epoch: 6.5 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8160811743462371		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.8160811743462371 | validation: 0.6467854416008416]
	TIME [epoch: 6.55 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8234758329697895		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.8234758329697895 | validation: 0.9693352490215723]
	TIME [epoch: 6.56 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9652757112525533		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.9652757112525533 | validation: 1.372278591031265]
	TIME [epoch: 6.59 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.903319839491288		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.903319839491288 | validation: 0.5735152546704883]
	TIME [epoch: 6.55 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7767209008422432		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.7767209008422432 | validation: 0.9775356071584709]
	TIME [epoch: 6.55 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8427463636718098		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.8427463636718098 | validation: 0.5836796078688699]
	TIME [epoch: 6.5 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6688381424448959		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.6688381424448959 | validation: 0.6114675391365461]
	TIME [epoch: 6.56 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9435967045771718		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.9435967045771718 | validation: 0.625115293179596]
	TIME [epoch: 6.55 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7660289240670748		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.7660289240670748 | validation: 1.3877674437815646]
	TIME [epoch: 6.55 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9119115512772343		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.9119115512772343 | validation: 0.7180902585525542]
	TIME [epoch: 6.55 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7689685488867318		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7689685488867318 | validation: 0.5462101808783969]
	TIME [epoch: 6.56 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9314213212640682		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.9314213212640682 | validation: 0.5587524319435954]
	TIME [epoch: 6.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.937655717797661		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.937655717797661 | validation: 0.5787569259100674]
	TIME [epoch: 6.5 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7468920861956181		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7468920861956181 | validation: 0.8354382325796574]
	TIME [epoch: 6.56 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8028670899622302		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.8028670899622302 | validation: 0.5976420621221883]
	TIME [epoch: 6.56 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7770682626618842		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.7770682626618842 | validation: 0.7368509915498536]
	TIME [epoch: 6.59 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717957230930577		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.717957230930577 | validation: 0.6587489127002888]
	TIME [epoch: 6.56 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7113789063416424		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.7113789063416424 | validation: 0.6804445810731301]
	TIME [epoch: 6.56 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216515080206013		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.7216515080206013 | validation: 0.6683905931772864]
	TIME [epoch: 6.55 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7536710913210226		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.7536710913210226 | validation: 0.6042490926932985]
	TIME [epoch: 6.56 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421004036226425		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.6421004036226425 | validation: 0.5769386079058202]
	TIME [epoch: 6.55 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7102298153014497		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7102298153014497 | validation: 0.4536756033477082]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_264.pth
	Model improved!!!
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6642601811423424		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.6642601811423424 | validation: 0.5377303666412278]
	TIME [epoch: 6.57 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.674289844060967		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.674289844060967 | validation: 0.8571020430680713]
	TIME [epoch: 6.57 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7048791017155766		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.7048791017155766 | validation: 0.592215804562738]
	TIME [epoch: 6.5 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7590072805426175		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7590072805426175 | validation: 0.9555157430948913]
	TIME [epoch: 6.56 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7281618878035163		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.7281618878035163 | validation: 0.6484989816387245]
	TIME [epoch: 6.58 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6500090982665739		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.6500090982665739 | validation: 0.7279601253892227]
	TIME [epoch: 6.56 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6399316715065932		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.6399316715065932 | validation: 0.5829243055380751]
	TIME [epoch: 6.6 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7052731823726421		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7052731823726421 | validation: 0.5990572591339055]
	TIME [epoch: 6.54 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.607854629424322		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.607854629424322 | validation: 0.7206273739730275]
	TIME [epoch: 6.58 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9291904484365932		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.9291904484365932 | validation: 0.5790221898508614]
	TIME [epoch: 6.5 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6656857625581134		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.6656857625581134 | validation: 0.5540236128909511]
	TIME [epoch: 6.56 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7473674297736717		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.7473674297736717 | validation: 0.4548200022266013]
	TIME [epoch: 6.56 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757122825050689		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.5757122825050689 | validation: 0.5917889763195703]
	TIME [epoch: 6.56 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6482506460632846		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.6482506460632846 | validation: 0.5334434999351438]
	TIME [epoch: 6.56 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9041662157990593		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.9041662157990593 | validation: 0.7399586047105098]
	TIME [epoch: 6.56 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8128067560604648		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.8128067560604648 | validation: 0.7168271399639333]
	TIME [epoch: 6.55 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6850599884140667		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.6850599884140667 | validation: 0.6117493950958184]
	TIME [epoch: 6.51 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6722445790286177		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.6722445790286177 | validation: 0.6325118370270719]
	TIME [epoch: 6.56 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6209447488469076		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.6209447488469076 | validation: 0.9059448612825821]
	TIME [epoch: 6.55 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7461603408536797		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.7461603408536797 | validation: 0.9344229395256914]
	TIME [epoch: 6.56 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8310065892713192		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.8310065892713192 | validation: 0.5479599402169667]
	TIME [epoch: 6.56 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6635783845383072		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.6635783845383072 | validation: 0.5650994729511363]
	TIME [epoch: 6.57 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6698021427904396		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6698021427904396 | validation: 0.7355722067955877]
	TIME [epoch: 6.57 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7899277001035419		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.7899277001035419 | validation: 0.691112464640903]
	TIME [epoch: 6.58 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7640474607355694		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.7640474607355694 | validation: 0.5097784455048817]
	TIME [epoch: 6.56 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6944663451024558		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.6944663451024558 | validation: 0.4810898988161212]
	TIME [epoch: 6.57 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6490256977500537		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.6490256977500537 | validation: 0.8285250227493133]
	TIME [epoch: 6.55 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712749045811553		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.712749045811553 | validation: 0.4696129956450488]
	TIME [epoch: 6.5 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7164929681061972		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.7164929681061972 | validation: 0.5190147722282237]
	TIME [epoch: 6.56 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6846241815877371		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.6846241815877371 | validation: 0.620976204610437]
	TIME [epoch: 6.56 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6118992330923956		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.6118992330923956 | validation: 0.6954922196643198]
	TIME [epoch: 6.56 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475041741617637		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.7475041741617637 | validation: 0.580285870783302]
	TIME [epoch: 6.56 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6863061540469547		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.6863061540469547 | validation: 0.5654764507833793]
	TIME [epoch: 6.56 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6217341532169751		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.6217341532169751 | validation: 0.5382694560151382]
	TIME [epoch: 6.56 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5927308733579826		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.5927308733579826 | validation: 0.619395600006715]
	TIME [epoch: 6.56 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.664005373530262		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.664005373530262 | validation: 0.8923369775868437]
	TIME [epoch: 6.52 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8557453290173276		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.8557453290173276 | validation: 1.0540089476556438]
	TIME [epoch: 6.56 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.749708933881551		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.749708933881551 | validation: 0.9740879552014952]
	TIME [epoch: 6.55 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7838292869120856		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.7838292869120856 | validation: 0.8694705150534168]
	TIME [epoch: 6.56 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7784733038591727		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.7784733038591727 | validation: 0.8980619022460817]
	TIME [epoch: 6.56 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7916534642887225		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.7916534642887225 | validation: 0.6197584144072505]
	TIME [epoch: 6.58 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6229875537299888		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.6229875537299888 | validation: 0.859808666377721]
	TIME [epoch: 6.55 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7430887122861328		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.7430887122861328 | validation: 0.7780521954402221]
	TIME [epoch: 6.52 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6130024913310556		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.6130024913310556 | validation: 1.0957343308071443]
	TIME [epoch: 6.55 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7909660408398759		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.7909660408398759 | validation: 0.46042711875126674]
	TIME [epoch: 6.55 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6166884133968433		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.6166884133968433 | validation: 0.4322422463517592]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_310.pth
	Model improved!!!
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220863628762789		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6220863628762789 | validation: 0.4716028221034753]
	TIME [epoch: 6.57 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6584256239630784		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.6584256239630784 | validation: 0.4706891409566974]
	TIME [epoch: 6.58 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6542776026490003		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.6542776026490003 | validation: 0.5124922497535094]
	TIME [epoch: 6.5 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877855906080994		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5877855906080994 | validation: 1.0290423593951041]
	TIME [epoch: 6.56 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6500282399883686		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.6500282399883686 | validation: 0.6184203466787189]
	TIME [epoch: 6.56 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8114905388834992		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.8114905388834992 | validation: 0.4841425197544835]
	TIME [epoch: 6.56 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9286997833562652		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.9286997833562652 | validation: 0.7782066406838518]
	TIME [epoch: 6.55 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6757744911373762		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.6757744911373762 | validation: 0.46713153869338137]
	TIME [epoch: 6.5 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6079079153532788		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.6079079153532788 | validation: 0.8275205575129636]
	TIME [epoch: 6.55 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7075580466255516		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.7075580466255516 | validation: 0.4454489678687567]
	TIME [epoch: 6.56 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7060950529657003		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.7060950529657003 | validation: 0.8959496535067274]
	TIME [epoch: 6.56 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8002042123903352		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.8002042123903352 | validation: 0.5756596094440775]
	TIME [epoch: 6.5 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243576133495722		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6243576133495722 | validation: 0.523169985730007]
	TIME [epoch: 6.56 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254211811485748		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.6254211811485748 | validation: 0.3926166350517869]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.536776088018408		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.536776088018408 | validation: 0.48819093188939633]
	TIME [epoch: 6.55 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542262864271794		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.542262864271794 | validation: 0.9619827983600979]
	TIME [epoch: 6.56 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6000204735045431		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.6000204735045431 | validation: 0.38697289156861964]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_327.pth
	Model improved!!!
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5147292546492996		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.5147292546492996 | validation: 0.4018900019991736]
	TIME [epoch: 6.54 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6724306400084306		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6724306400084306 | validation: 0.45534245296086623]
	TIME [epoch: 6.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5816987003055085		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.5816987003055085 | validation: 0.5811403898627044]
	TIME [epoch: 6.52 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6258044547866204		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.6258044547866204 | validation: 0.8336470639735061]
	TIME [epoch: 6.56 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7027795073979527		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.7027795073979527 | validation: 0.4360752338459051]
	TIME [epoch: 6.56 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6432928529351835		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6432928529351835 | validation: 0.46007417274533674]
	TIME [epoch: 6.54 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144876057502086		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.5144876057502086 | validation: 0.6057309962967006]
	TIME [epoch: 6.55 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8011485161521053		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.8011485161521053 | validation: 0.5366620094383937]
	TIME [epoch: 6.55 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6061637809556699		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.6061637809556699 | validation: 0.39232188255188133]
	TIME [epoch: 6.51 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6966476254335745		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.6966476254335745 | validation: 0.8872842464959662]
	TIME [epoch: 6.55 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6518897905784653		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6518897905784653 | validation: 0.5476586024571886]
	TIME [epoch: 6.56 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685947868225618		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.685947868225618 | validation: 0.5649172471760244]
	TIME [epoch: 6.55 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5476791151871919		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.5476791151871919 | validation: 0.5447755363338485]
	TIME [epoch: 6.54 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6162645631893549		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.6162645631893549 | validation: 0.6096844946391878]
	TIME [epoch: 6.56 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5863988495935447		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.5863988495935447 | validation: 0.4328844599226055]
	TIME [epoch: 6.56 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560876426711234		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.560876426711234 | validation: 0.39098532205010594]
	TIME [epoch: 6.55 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5247183784325137		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5247183784325137 | validation: 0.527274556898508]
	TIME [epoch: 6.56 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5619236764752803		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.5619236764752803 | validation: 0.683532469174439]
	TIME [epoch: 6.54 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.626098925427717		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.626098925427717 | validation: 0.39072455064788486]
	TIME [epoch: 6.56 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5115093700366796		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5115093700366796 | validation: 0.7523187673360994]
	TIME [epoch: 6.56 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5520711330003257		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.5520711330003257 | validation: 0.8042284677560716]
	TIME [epoch: 6.56 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6131876602836196		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.6131876602836196 | validation: 0.37590839494645373]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_349.pth
	Model improved!!!
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5444597900560513		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5444597900560513 | validation: 0.5361621584811181]
	TIME [epoch: 6.56 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5245743888770573		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.5245743888770573 | validation: 0.5324338690017705]
	TIME [epoch: 6.56 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5927558068616695		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.5927558068616695 | validation: 0.4640800128326879]
	TIME [epoch: 6.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6254200780984125		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.6254200780984125 | validation: 0.4624631407242752]
	TIME [epoch: 6.5 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5326502200486523		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.5326502200486523 | validation: 0.3974407780937883]
	TIME [epoch: 6.6 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499320067092925		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5499320067092925 | validation: 0.650519025867428]
	TIME [epoch: 6.52 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6678864205833628		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.6678864205833628 | validation: 0.4078082208307505]
	TIME [epoch: 6.58 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5775821816918542		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.5775821816918542 | validation: 0.42810565747485174]
	TIME [epoch: 6.55 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6207848458866622		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.6207848458866622 | validation: 0.47311933148084107]
	TIME [epoch: 6.56 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5307940834789764		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.5307940834789764 | validation: 0.7461858975503861]
	TIME [epoch: 6.56 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6648322179540624		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.6648322179540624 | validation: 0.44873376129575065]
	TIME [epoch: 6.53 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5576528795207406		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.5576528795207406 | validation: 0.49274347211476965]
	TIME [epoch: 6.56 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6220921464627757		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.6220921464627757 | validation: 0.39078307794666417]
	TIME [epoch: 6.55 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5141827348182589		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.5141827348182589 | validation: 0.6026870540316929]
	TIME [epoch: 6.56 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5908050757392584		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.5908050757392584 | validation: 0.6008527948873945]
	TIME [epoch: 6.58 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5853728085105613		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.5853728085105613 | validation: 0.5860984841924402]
	TIME [epoch: 6.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6183860985696815		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.6183860985696815 | validation: 0.4403610885135107]
	TIME [epoch: 6.54 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.580928287067906		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.580928287067906 | validation: 0.4912421387501227]
	TIME [epoch: 6.55 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5596624864131434		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.5596624864131434 | validation: 0.7005852061071892]
	TIME [epoch: 6.55 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6629924240913067		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.6629924240913067 | validation: 0.40276882348377796]
	TIME [epoch: 6.55 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6191661303363574		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.6191661303363574 | validation: 0.3889674764712585]
	TIME [epoch: 6.56 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6029124782656777		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.6029124782656777 | validation: 0.39990087735849017]
	TIME [epoch: 6.56 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4980992484115234		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.4980992484115234 | validation: 0.3926171182637465]
	TIME [epoch: 6.62 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6320613812016604		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.6320613812016604 | validation: 0.563422869194798]
	TIME [epoch: 6.51 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7134210994212762		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.7134210994212762 | validation: 0.44202634054593076]
	TIME [epoch: 6.56 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5304002875359156		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.5304002875359156 | validation: 0.5652955771462813]
	TIME [epoch: 6.56 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5464465193775117		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.5464465193775117 | validation: 0.49316765646014304]
	TIME [epoch: 6.54 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6099309235510176		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.6099309235510176 | validation: 0.5511661694682272]
	TIME [epoch: 6.56 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5718881805709592		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.5718881805709592 | validation: 0.3744220921632146]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4530404751654454		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.4530404751654454 | validation: 0.48765387068037436]
	TIME [epoch: 6.56 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5196029764710781		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.5196029764710781 | validation: 0.9325450147765526]
	TIME [epoch: 6.55 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5871871027237823		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5871871027237823 | validation: 0.3931043910097617]
	TIME [epoch: 6.52 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5515812222954801		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5515812222954801 | validation: 1.1648827142608118]
	TIME [epoch: 6.56 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8510525558600178		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.8510525558600178 | validation: 0.5214319200979751]
	TIME [epoch: 6.56 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49321503777097486		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.49321503777097486 | validation: 0.4209545304947636]
	TIME [epoch: 6.57 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5791738815194245		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.5791738815194245 | validation: 0.5028671474881616]
	TIME [epoch: 6.55 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6519590206675572		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.6519590206675572 | validation: 0.45146069651113524]
	TIME [epoch: 6.56 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5483171501123076		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.5483171501123076 | validation: 0.5591894900450538]
	TIME [epoch: 6.6 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5405016691692455		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.5405016691692455 | validation: 0.46854922714359826]
	TIME [epoch: 6.55 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5240648047884969		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.5240648047884969 | validation: 0.6010814960137824]
	TIME [epoch: 6.55 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5379197602249092		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.5379197602249092 | validation: 0.4343447420781989]
	TIME [epoch: 6.5 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48082066740664864		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.48082066740664864 | validation: 0.3963917210624967]
	TIME [epoch: 6.56 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5223874390949714		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5223874390949714 | validation: 0.5375576840061028]
	TIME [epoch: 6.56 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.520062825899326		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.520062825899326 | validation: 0.997526926725414]
	TIME [epoch: 6.54 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6514370896423806		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.6514370896423806 | validation: 0.44276367508537234]
	TIME [epoch: 6.55 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5328345308293108		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.5328345308293108 | validation: 0.44453681750112706]
	TIME [epoch: 6.52 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5340302784134956		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.5340302784134956 | validation: 0.6761804319577979]
	TIME [epoch: 6.57 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6010904884448581		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.6010904884448581 | validation: 0.4544612461040806]
	TIME [epoch: 6.58 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5195328153857508		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.5195328153857508 | validation: 0.5346042063608473]
	TIME [epoch: 6.5 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.503930570530702		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.503930570530702 | validation: 0.5260597744268912]
	TIME [epoch: 6.55 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5916420982629584		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.5916420982629584 | validation: 0.4562393759804417]
	TIME [epoch: 6.54 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5238836291590986		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.5238836291590986 | validation: 0.4727311855885906]
	TIME [epoch: 6.52 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5340521188786683		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5340521188786683 | validation: 0.6285183265799573]
	TIME [epoch: 6.57 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49824843186667034		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.49824843186667034 | validation: 0.3980632693948457]
	TIME [epoch: 6.58 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4754577569007561		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.4754577569007561 | validation: 0.584554614356506]
	TIME [epoch: 6.51 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.510190817285911		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.510190817285911 | validation: 0.4391146646767199]
	TIME [epoch: 6.55 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4788809218640829		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.4788809218640829 | validation: 0.42626863837960066]
	TIME [epoch: 6.55 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4784540978417956		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.4784540978417956 | validation: 0.5838378423309792]
	TIME [epoch: 6.56 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6136229740440529		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.6136229740440529 | validation: 0.47782553682221446]
	TIME [epoch: 6.54 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5646462568717654		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.5646462568717654 | validation: 0.6121578319727656]
	TIME [epoch: 6.5 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4863517358179863		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.4863517358179863 | validation: 0.47477297138312113]
	TIME [epoch: 6.57 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5289361977252696		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5289361977252696 | validation: 0.3657760443142661]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_411.pth
	Model improved!!!
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4028041863321473		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.4028041863321473 | validation: 0.6772883749835903]
	TIME [epoch: 6.56 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399781110557029		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.5399781110557029 | validation: 0.41280438482432685]
	TIME [epoch: 6.56 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5095183890452678		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.5095183890452678 | validation: 0.4993258390910166]
	TIME [epoch: 7.07 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5039894933343148		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.5039894933343148 | validation: 0.6043539016532516]
	TIME [epoch: 6.56 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5055479651620123		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.5055479651620123 | validation: 0.4251396887137065]
	TIME [epoch: 6.53 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4823424881676038		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.4823424881676038 | validation: 0.38493366270640494]
	TIME [epoch: 6.58 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49555975404361263		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.49555975404361263 | validation: 0.3400195336054674]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_418.pth
	Model improved!!!
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43448368701784207		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.43448368701784207 | validation: 0.3720768330685678]
	TIME [epoch: 6.55 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6283792894265064		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.6283792894265064 | validation: 0.4156332371010609]
	TIME [epoch: 6.59 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5850200122610131		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.5850200122610131 | validation: 0.4286558338831823]
	TIME [epoch: 6.56 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4444169347909835		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.4444169347909835 | validation: 0.5337506696476735]
	TIME [epoch: 6.57 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46395968547402033		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.46395968547402033 | validation: 0.3246716794591337]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9203902621133289		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.9203902621133289 | validation: 0.41514240403106994]
	TIME [epoch: 6.58 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49176568605553383		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.49176568605553383 | validation: 0.40445263494953476]
	TIME [epoch: 6.59 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4670004229322097		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.4670004229322097 | validation: 0.3775510377847996]
	TIME [epoch: 6.51 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41118909404293935		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.41118909404293935 | validation: 0.43506651009542746]
	TIME [epoch: 6.57 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4585210490601893		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.4585210490601893 | validation: 0.30334234617204436]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_428.pth
	Model improved!!!
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.52565325556239		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.52565325556239 | validation: 0.45594705157872745]
	TIME [epoch: 6.56 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6043065872847121		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.6043065872847121 | validation: 0.5183286297409804]
	TIME [epoch: 6.56 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5765810233620002		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.5765810233620002 | validation: 0.36169819564379135]
	TIME [epoch: 6.56 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4141656113651324		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.4141656113651324 | validation: 0.5421476265210114]
	TIME [epoch: 6.57 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5404401634556388		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.5404401634556388 | validation: 0.4733023711650271]
	TIME [epoch: 6.58 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5203940327663809		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.5203940327663809 | validation: 0.3433741821503138]
	TIME [epoch: 6.5 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4835595118488149		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.4835595118488149 | validation: 0.36427242313962765]
	TIME [epoch: 6.57 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46493062594059714		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.46493062594059714 | validation: 0.3625172434304606]
	TIME [epoch: 6.56 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7361702152405644		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.7361702152405644 | validation: 0.3246116000576086]
	TIME [epoch: 6.55 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42814231276704123		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.42814231276704123 | validation: 0.31319630914382807]
	TIME [epoch: 6.57 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4191616549031554		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.4191616549031554 | validation: 0.42941312408322985]
	TIME [epoch: 6.55 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4494580530589365		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.4494580530589365 | validation: 0.36366192689313004]
	TIME [epoch: 6.55 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5450757378589697		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.5450757378589697 | validation: 0.3832305825139129]
	TIME [epoch: 6.55 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42383685462267606		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.42383685462267606 | validation: 0.43266673458581656]
	TIME [epoch: 6.58 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4787512795467243		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.4787512795467243 | validation: 0.34300769086751376]
	TIME [epoch: 6.56 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5087117177143535		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.5087117177143535 | validation: 0.35005063912731205]
	TIME [epoch: 6.52 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5067148132513131		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5067148132513131 | validation: 0.6409929141151472]
	TIME [epoch: 6.58 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5553409020057504		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.5553409020057504 | validation: 0.369869385125593]
	TIME [epoch: 6.55 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41111962263734714		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.41111962263734714 | validation: 0.4772788888192438]
	TIME [epoch: 6.59 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49825317497335453		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.49825317497335453 | validation: 0.3387658301109692]
	TIME [epoch: 6.57 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844908405272604		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.3844908405272604 | validation: 0.30961285684786133]
	TIME [epoch: 6.51 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4449736310240727		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.4449736310240727 | validation: 0.42521791558009725]
	TIME [epoch: 6.56 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4417937699441033		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.4417937699441033 | validation: 0.35535295917640164]
	TIME [epoch: 6.56 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4523680136314254		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.4523680136314254 | validation: 0.6196428365088907]
	TIME [epoch: 6.55 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4308184649632915		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.4308184649632915 | validation: 0.3195255388264029]
	TIME [epoch: 6.57 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4089485188391223		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.4089485188391223 | validation: 0.28129488173679623]
	TIME [epoch: 6.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44137407585558763		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.44137407585558763 | validation: 0.3315449863435467]
	TIME [epoch: 6.59 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4067394352901071		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.4067394352901071 | validation: 0.4587195634631513]
	TIME [epoch: 6.59 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45422644640126353		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.45422644640126353 | validation: 0.6620368532541852]
	TIME [epoch: 6.55 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5269364215411689		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.5269364215411689 | validation: 0.38471493644342597]
	TIME [epoch: 6.55 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41337186183348307		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.41337186183348307 | validation: 0.31998551231633243]
	TIME [epoch: 6.55 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.375886190694293		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.375886190694293 | validation: 0.5064497050227571]
	TIME [epoch: 6.55 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47455493135656146		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.47455493135656146 | validation: 0.5840640041586113]
	TIME [epoch: 6.56 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4361826764347836		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.4361826764347836 | validation: 0.3886367027098016]
	TIME [epoch: 6.56 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4372747499626121		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.4372747499626121 | validation: 0.3366704763589279]
	TIME [epoch: 6.56 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43073641423791		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.43073641423791 | validation: 0.36475587638343604]
	TIME [epoch: 6.55 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419818157578336		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.4419818157578336 | validation: 0.4713508368511563]
	TIME [epoch: 6.55 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4953624272226733		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.4953624272226733 | validation: 0.347737709755716]
	TIME [epoch: 6.49 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46444380807873786		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.46444380807873786 | validation: 0.3160003534508317]
	TIME [epoch: 6.56 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4359926233686403		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.4359926233686403 | validation: 0.3890189796811959]
	TIME [epoch: 6.55 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.440631913600522		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.440631913600522 | validation: 0.5030548902524307]
	TIME [epoch: 6.56 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4853047446979709		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.4853047446979709 | validation: 0.36085667264964144]
	TIME [epoch: 6.57 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45886089500699223		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.45886089500699223 | validation: 0.5514411319557018]
	TIME [epoch: 6.54 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.586482559836305		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.586482559836305 | validation: 0.4543505219200327]
	TIME [epoch: 6.57 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4577173277318418		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.4577173277318418 | validation: 0.33842854460262745]
	TIME [epoch: 6.58 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46915348858402117		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.46915348858402117 | validation: 0.4814023307225797]
	TIME [epoch: 6.5 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4196285893837369		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.4196285893837369 | validation: 0.3992729990874204]
	TIME [epoch: 6.55 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42013160187700005		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.42013160187700005 | validation: 0.5088613984902447]
	TIME [epoch: 6.58 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5118219336152137		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.5118219336152137 | validation: 0.39868984425342446]
	TIME [epoch: 6.58 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43561877349843253		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.43561877349843253 | validation: 0.34855014465529244]
	TIME [epoch: 6.56 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41337042534223295		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.41337042534223295 | validation: 0.29100771506174056]
	TIME [epoch: 6.5 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44144745551164655		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.44144745551164655 | validation: 0.5746289318524277]
	TIME [epoch: 6.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.428044055433475		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.428044055433475 | validation: 0.38933931521402015]
	TIME [epoch: 6.54 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4288568039693289		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.4288568039693289 | validation: 0.4055177937401659]
	TIME [epoch: 6.59 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5379886955874917		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5379886955874917 | validation: 0.3681587326382655]
	TIME [epoch: 6.55 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5905381984981769		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.5905381984981769 | validation: 0.8278245331371943]
	TIME [epoch: 6.5 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4882935798048391		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.4882935798048391 | validation: 0.3556745872472812]
	TIME [epoch: 6.56 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4371499378746745		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.4371499378746745 | validation: 0.30163372054065607]
	TIME [epoch: 6.6 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41296430800004724		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.41296430800004724 | validation: 0.42667729313646535]
	TIME [epoch: 6.56 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48113846702113505		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.48113846702113505 | validation: 0.42580237684775535]
	TIME [epoch: 6.57 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46065117409385903		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.46065117409385903 | validation: 0.3413640829559935]
	TIME [epoch: 6.56 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40974731361413264		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.40974731361413264 | validation: 0.31834539281127894]
	TIME [epoch: 6.57 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40590065752698085		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.40590065752698085 | validation: 0.4366704184620122]
	TIME [epoch: 6.57 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4600675399111078		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.4600675399111078 | validation: 0.36699014303218014]
	TIME [epoch: 6.57 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4256476958418837		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.4256476958418837 | validation: 0.3460484696510828]
	TIME [epoch: 6.55 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4890780253291029		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.4890780253291029 | validation: 0.5300755769459585]
	TIME [epoch: 6.56 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47427199133049813		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.47427199133049813 | validation: 0.32323001482504715]
	TIME [epoch: 6.55 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4139269481654593		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.4139269481654593 | validation: 0.35730488053656295]
	TIME [epoch: 6.55 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36761136597899646		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.36761136597899646 | validation: 0.3001416603987946]
	TIME [epoch: 6.56 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4444999282804244		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.4444999282804244 | validation: 0.37073723565738403]
	TIME [epoch: 6.57 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4204171020455495		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.4204171020455495 | validation: 0.39547447975127753]
	TIME [epoch: 6.56 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40932193579050385		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.40932193579050385 | validation: 0.40803557207625774]
	TIME [epoch: 6.56 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5067991396914531		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.5067991396914531 | validation: 0.35034336256467646]
	TIME [epoch: 6.54 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40024100905037285		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.40024100905037285 | validation: 0.6936006692848369]
	TIME [epoch: 6.56 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49165364713718734		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.49165364713718734 | validation: 0.30518176873751773]
	TIME [epoch: 6.58 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37098822032324597		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.37098822032324597 | validation: 0.4204938699556813]
	TIME [epoch: 6.54 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4126385920797515		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.4126385920797515 | validation: 0.5300413935496555]
	TIME [epoch: 6.56 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42173345503631054		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.42173345503631054 | validation: 0.37677737635635283]
	TIME [epoch: 6.57 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39568287369010197		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.39568287369010197 | validation: 0.327752269473399]
	TIME [epoch: 6.56 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4052145887715187		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.4052145887715187 | validation: 0.49248310705516346]
	TIME [epoch: 6.56 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49103689204284057		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.49103689204284057 | validation: 0.37244304715335774]
	TIME [epoch: 6.5 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4180816439184962		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.4180816439184962 | validation: 0.3611650322838976]
	TIME [epoch: 6.56 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38238083280586593		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.38238083280586593 | validation: 0.3467045354199223]
	TIME [epoch: 6.58 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47214233971383684		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.47214233971383684 | validation: 0.4231717363407059]
	TIME [epoch: 6.56 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3647085920265654		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.3647085920265654 | validation: 0.33426669163982325]
	TIME [epoch: 6.56 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3472499053182149		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.3472499053182149 | validation: 0.33295999148787403]
	TIME [epoch: 6.52 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3825571957546371		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.3825571957546371 | validation: 0.34023735685958933]
	TIME [epoch: 6.61 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4021964282985799		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.4021964282985799 | validation: 0.2895835856532954]
	TIME [epoch: 6.56 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3550944489441059		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.3550944489441059 | validation: 0.3821757060911381]
	TIME [epoch: 6.5 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42582322934409356		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.42582322934409356 | validation: 0.26600246413932327]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_518.pth
	Model improved!!!
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4567232851868791		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.4567232851868791 | validation: 0.44716715628240017]
	TIME [epoch: 6.57 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41124821071725537		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.41124821071725537 | validation: 0.41046930829470396]
	TIME [epoch: 6.58 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46884087223134785		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.46884087223134785 | validation: 0.3832377454992812]
	TIME [epoch: 6.49 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072409890278096		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.5072409890278096 | validation: 0.3625757510748174]
	TIME [epoch: 6.55 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3718352175770827		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.3718352175770827 | validation: 0.3391528995311877]
	TIME [epoch: 6.57 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778108470613827		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.3778108470613827 | validation: 0.37430077469102385]
	TIME [epoch: 6.57 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4493870925620491		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.4493870925620491 | validation: 0.30138489350778214]
	TIME [epoch: 6.55 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3967242009309578		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.3967242009309578 | validation: 0.2797709771691163]
	TIME [epoch: 6.57 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4270215470877386		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.4270215470877386 | validation: 0.33059608179372435]
	TIME [epoch: 6.55 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42989947019424823		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.42989947019424823 | validation: 0.2844321806391881]
	TIME [epoch: 6.52 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.344703725683838		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.344703725683838 | validation: 0.30349669720405265]
	TIME [epoch: 6.54 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3955487071150856		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.3955487071150856 | validation: 0.3219416176019273]
	TIME [epoch: 6.56 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4185751467551886		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.4185751467551886 | validation: 0.2992524630706621]
	TIME [epoch: 6.56 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4450600922519991		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.4450600922519991 | validation: 0.2946343355553642]
	TIME [epoch: 6.57 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4234177670872864		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.4234177670872864 | validation: 0.28172004817131796]
	TIME [epoch: 6.57 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44071307185633857		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.44071307185633857 | validation: 0.6980975851015373]
	TIME [epoch: 6.57 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4122939343743808		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.4122939343743808 | validation: 0.3468536359086118]
	TIME [epoch: 6.56 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527794905563545		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.3527794905563545 | validation: 0.48782132684659574]
	TIME [epoch: 6.55 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39589510007538997		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.39589510007538997 | validation: 0.3172175209055853]
	TIME [epoch: 6.57 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37654235119556817		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.37654235119556817 | validation: 0.26119988186223136]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3343172412024204		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.3343172412024204 | validation: 0.3221292747401081]
	TIME [epoch: 6.55 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4236268511440913		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.4236268511440913 | validation: 0.29513559786295723]
	TIME [epoch: 6.59 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34509543982623925		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.34509543982623925 | validation: 0.3996542726197849]
	TIME [epoch: 6.53 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3756923685356288		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.3756923685356288 | validation: 0.42162435989955244]
	TIME [epoch: 6.61 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393986901131335		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.393986901131335 | validation: 0.3404219554286662]
	TIME [epoch: 6.56 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3593619322758587		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.3593619322758587 | validation: 0.2452866621955882]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_544.pth
	Model improved!!!
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38806349444840016		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.38806349444840016 | validation: 0.3269421146951028]
	TIME [epoch: 6.58 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4132401602269476		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.4132401602269476 | validation: 0.2713633013340841]
	TIME [epoch: 6.59 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32965510344291954		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.32965510344291954 | validation: 0.2755146693280403]
	TIME [epoch: 6.62 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39303247564762495		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.39303247564762495 | validation: 0.29771102366757796]
	TIME [epoch: 6.57 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3800893596473384		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.3800893596473384 | validation: 0.3684061365242285]
	TIME [epoch: 6.57 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4088369642613155		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.4088369642613155 | validation: 0.25208467735161105]
	TIME [epoch: 6.59 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36784572401269744		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.36784572401269744 | validation: 0.3402409998092145]
	TIME [epoch: 6.58 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632042638508353		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.3632042638508353 | validation: 0.5577724153906557]
	TIME [epoch: 6.57 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4649279165614973		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.4649279165614973 | validation: 0.5217247498705245]
	TIME [epoch: 6.51 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48680308877872347		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.48680308877872347 | validation: 0.3315812247926539]
	TIME [epoch: 6.55 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44765372180445967		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.44765372180445967 | validation: 0.328050812128521]
	TIME [epoch: 6.56 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40255790924977736		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.40255790924977736 | validation: 0.42067960057066517]
	TIME [epoch: 6.55 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38306373902586094		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.38306373902586094 | validation: 0.5709076362774986]
	TIME [epoch: 6.56 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42496926610513863		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.42496926610513863 | validation: 0.31537088681135494]
	TIME [epoch: 6.58 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34575876280459805		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.34575876280459805 | validation: 0.3644797888232465]
	TIME [epoch: 6.56 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40408831747919355		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.40408831747919355 | validation: 0.28100018833977675]
	TIME [epoch: 6.56 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37073700850782143		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.37073700850782143 | validation: 0.29639634988163915]
	TIME [epoch: 6.61 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39461286780657095		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.39461286780657095 | validation: 0.33619361469472864]
	TIME [epoch: 6.57 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38193245139881676		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.38193245139881676 | validation: 0.2634908274822769]
	TIME [epoch: 6.57 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4813167547728568		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.4813167547728568 | validation: 0.2613878865631429]
	TIME [epoch: 6.57 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39860631879505903		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.39860631879505903 | validation: 0.4600441807238255]
	TIME [epoch: 6.57 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3668464221456921		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.3668464221456921 | validation: 0.3763868214130773]
	TIME [epoch: 6.57 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38385159633845717		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.38385159633845717 | validation: 0.2983827770042932]
	TIME [epoch: 6.57 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4090823971647262		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.4090823971647262 | validation: 0.318890141289055]
	TIME [epoch: 6.52 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39418711633810816		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.39418711633810816 | validation: 0.289602956082641]
	TIME [epoch: 6.59 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46668305786417497		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.46668305786417497 | validation: 0.4803682036679277]
	TIME [epoch: 6.59 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38664546996189275		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.38664546996189275 | validation: 0.300590209932909]
	TIME [epoch: 6.53 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.395659774280715		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.395659774280715 | validation: 0.376751693642286]
	TIME [epoch: 6.57 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3890989559575513		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.3890989559575513 | validation: 0.35304960330572976]
	TIME [epoch: 6.57 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771777729841058		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.3771777729841058 | validation: 0.4629107433220148]
	TIME [epoch: 6.55 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3575804005711901		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.3575804005711901 | validation: 0.2502855246902066]
	TIME [epoch: 6.57 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3189682519602849		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.3189682519602849 | validation: 0.33847868494277095]
	TIME [epoch: 6.58 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4238078746989516		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.4238078746989516 | validation: 0.31747023543655195]
	TIME [epoch: 6.56 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3805961984830567		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.3805961984830567 | validation: 0.2664483781504044]
	TIME [epoch: 6.55 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37067402803348243		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.37067402803348243 | validation: 0.34980844577791975]
	TIME [epoch: 6.57 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3393272948546311		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.3393272948546311 | validation: 0.3613218362420958]
	TIME [epoch: 6.56 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34040525495748086		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.34040525495748086 | validation: 0.4062124321104956]
	TIME [epoch: 6.57 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47275308852072917		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.47275308852072917 | validation: 0.3244396783732046]
	TIME [epoch: 6.55 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39023045359269437		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.39023045359269437 | validation: 0.29194604122372203]
	TIME [epoch: 6.56 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43631299247510136		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.43631299247510136 | validation: 0.2518710510831334]
	TIME [epoch: 6.56 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33453560480137806		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.33453560480137806 | validation: 0.39699752676595107]
	TIME [epoch: 6.57 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3732574017204896		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.3732574017204896 | validation: 0.2788136757044692]
	TIME [epoch: 6.56 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32434454656977213		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.32434454656977213 | validation: 0.31304551911526385]
	TIME [epoch: 6.6 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4161192828446124		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.4161192828446124 | validation: 0.2603894831403269]
	TIME [epoch: 6.56 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37586371400415325		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.37586371400415325 | validation: 0.4114781424218063]
	TIME [epoch: 6.56 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40405622357794246		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.40405622357794246 | validation: 0.352146796232664]
	TIME [epoch: 6.56 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34895706330377096		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.34895706330377096 | validation: 0.246210620895759]
	TIME [epoch: 6.57 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3268429528210883		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.3268429528210883 | validation: 0.3815783658818756]
	TIME [epoch: 6.55 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35392589599885765		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.35392589599885765 | validation: 0.36283174280336755]
	TIME [epoch: 6.52 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37682038774699916		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.37682038774699916 | validation: 0.2890688270295309]
	TIME [epoch: 6.55 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42047086350443313		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.42047086350443313 | validation: 0.25652395133917316]
	TIME [epoch: 6.56 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3383704006995837		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.3383704006995837 | validation: 0.27148336272908535]
	TIME [epoch: 6.57 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31471373705508576		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.31471373705508576 | validation: 0.33724397789066646]
	TIME [epoch: 6.57 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4673464210701224		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.4673464210701224 | validation: 0.3198867277611871]
	TIME [epoch: 6.55 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3845322877522635		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.3845322877522635 | validation: 0.25981704751798473]
	TIME [epoch: 6.55 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34096580469517734		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.34096580469517734 | validation: 0.32186029909134173]
	TIME [epoch: 6.57 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37891629890073836		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.37891629890073836 | validation: 0.264688687444024]
	TIME [epoch: 6.57 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3205085459941953		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.3205085459941953 | validation: 0.28537578736036745]
	TIME [epoch: 6.56 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783985818474305		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.3783985818474305 | validation: 0.2751852844291156]
	TIME [epoch: 6.57 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412045374112382		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.3412045374112382 | validation: 0.2273090976074959]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_604.pth
	Model improved!!!
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31027283329002275		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.31027283329002275 | validation: 0.29722954495387327]
	TIME [epoch: 6.56 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3183670545230717		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.3183670545230717 | validation: 0.33759804523816583]
	TIME [epoch: 6.57 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3368165140065318		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.3368165140065318 | validation: 0.3593872944093204]
	TIME [epoch: 6.59 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31550876305311837		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.31550876305311837 | validation: 0.2527859236385481]
	TIME [epoch: 6.49 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3047893289796677		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.3047893289796677 | validation: 0.2608802515352163]
	TIME [epoch: 6.55 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3219200379897698		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.3219200379897698 | validation: 0.2831230149798451]
	TIME [epoch: 6.56 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35560945668333876		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.35560945668333876 | validation: 0.3196786944874956]
	TIME [epoch: 6.56 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37841150536116985		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.37841150536116985 | validation: 0.2751491187842878]
	TIME [epoch: 6.56 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3921600350506903		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.3921600350506903 | validation: 0.2896371796950784]
	TIME [epoch: 6.56 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3314776799895207		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.3314776799895207 | validation: 0.3079767317597343]
	TIME [epoch: 6.57 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34184183382487127		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.34184183382487127 | validation: 0.31758495937776177]
	TIME [epoch: 6.56 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34537118991231025		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.34537118991231025 | validation: 0.28980144148433773]
	TIME [epoch: 6.51 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3266121712780344		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.3266121712780344 | validation: 0.24126600889257646]
	TIME [epoch: 6.55 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33915665864427197		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.33915665864427197 | validation: 0.32986387876262974]
	TIME [epoch: 6.57 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33458776851133876		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.33458776851133876 | validation: 0.243774651896529]
	TIME [epoch: 6.56 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333464417667791		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.333464417667791 | validation: 0.22520384259777942]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3249789691044602		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.3249789691044602 | validation: 0.26481788974323445]
	TIME [epoch: 6.52 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8062288566800975		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.8062288566800975 | validation: 0.4700000515673831]
	TIME [epoch: 6.53 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3800789627786568		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.3800789627786568 | validation: 0.4864950251507507]
	TIME [epoch: 6.55 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37540983490412944		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.37540983490412944 | validation: 0.22133535587972725]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_624.pth
	Model improved!!!
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33696347070273797		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.33696347070273797 | validation: 0.30301357253821226]
	TIME [epoch: 6.62 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3337024258509604		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.3337024258509604 | validation: 0.3575600803604148]
	TIME [epoch: 6.57 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32424775864025374		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.32424775864025374 | validation: 0.26303658877850317]
	TIME [epoch: 6.51 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34401454933415554		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.34401454933415554 | validation: 0.3453944159134242]
	TIME [epoch: 6.56 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3594856697407853		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.3594856697407853 | validation: 0.32784137099001726]
	TIME [epoch: 6.56 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3598566139006548		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.3598566139006548 | validation: 0.25998350514446145]
	TIME [epoch: 6.55 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31608765833225494		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.31608765833225494 | validation: 0.2305654540535717]
	TIME [epoch: 6.51 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3150959818074728		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.3150959818074728 | validation: 0.31626342646361216]
	TIME [epoch: 6.55 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3046179281263759		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.3046179281263759 | validation: 0.2403510352890514]
	TIME [epoch: 6.53 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3194844437838637		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.3194844437838637 | validation: 0.31362541816354217]
	TIME [epoch: 6.55 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32973473107447315		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.32973473107447315 | validation: 0.5146996202421764]
	TIME [epoch: 6.59 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4473931898318748		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.4473931898318748 | validation: 0.3166503222923245]
	TIME [epoch: 6.55 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3411424427517117		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.3411424427517117 | validation: 0.21793118359713798]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_637.pth
	Model improved!!!
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35770192389613553		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.35770192389613553 | validation: 0.2864946765145958]
	TIME [epoch: 6.67 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33798845936131794		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.33798845936131794 | validation: 0.26681993117497405]
	TIME [epoch: 6.54 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3018235191156654		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.3018235191156654 | validation: 0.3283223732741701]
	TIME [epoch: 6.56 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3384587685202994		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.3384587685202994 | validation: 0.2496601932701454]
	TIME [epoch: 6.59 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.297106228276355		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.297106228276355 | validation: 0.25468407490013056]
	TIME [epoch: 6.59 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.319327043819483		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.319327043819483 | validation: 0.2720162506385694]
	TIME [epoch: 6.59 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3116412879155681		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.3116412879155681 | validation: 0.22112828764144166]
	TIME [epoch: 6.59 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3582021449516526		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.3582021449516526 | validation: 0.3112626651201398]
	TIME [epoch: 6.58 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33560625700301666		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.33560625700301666 | validation: 0.23046466838217264]
	TIME [epoch: 6.59 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2930612324878886		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.2930612324878886 | validation: 0.2362028520537965]
	TIME [epoch: 6.6 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37365994886215137		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.37365994886215137 | validation: 0.2899017289381684]
	TIME [epoch: 6.63 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33653365329001417		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.33653365329001417 | validation: 0.27011868083696594]
	TIME [epoch: 6.59 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.339116853379118		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.339116853379118 | validation: 0.25626058926115247]
	TIME [epoch: 6.58 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30373617019948446		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.30373617019948446 | validation: 0.27919569215685575]
	TIME [epoch: 6.53 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3122486805217992		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.3122486805217992 | validation: 0.18990992390860048]
	TIME [epoch: 6.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_652.pth
	Model improved!!!
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4764243299676926		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.4764243299676926 | validation: 0.3950095977279651]
	TIME [epoch: 6.68 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3071754826562632		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.3071754826562632 | validation: 0.2478908445199357]
	TIME [epoch: 6.57 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29518034886311106		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.29518034886311106 | validation: 0.21199585706883348]
	TIME [epoch: 6.56 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3223929175570147		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.3223929175570147 | validation: 0.4154673174664974]
	TIME [epoch: 6.56 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3466978391623641		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.3466978391623641 | validation: 0.2850980108064767]
	TIME [epoch: 6.57 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3467977627056903		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.3467977627056903 | validation: 0.3847355750146984]
	TIME [epoch: 6.56 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3335692768261083		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.3335692768261083 | validation: 0.23287308546843175]
	TIME [epoch: 6.58 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29139352709340804		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.29139352709340804 | validation: 0.27338790497808435]
	TIME [epoch: 6.61 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31786131184989436		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.31786131184989436 | validation: 0.35009627714546826]
	TIME [epoch: 6.58 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3225269630357887		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.3225269630357887 | validation: 0.23327228176997664]
	TIME [epoch: 6.58 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285615928935801		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.285615928935801 | validation: 0.20220668622074767]
	TIME [epoch: 6.57 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29141412398866573		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.29141412398866573 | validation: 0.22374350080909872]
	TIME [epoch: 6.56 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2869799413531188		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.2869799413531188 | validation: 0.3101892153708623]
	TIME [epoch: 6.52 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31016193913885776		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.31016193913885776 | validation: 0.31297589669172765]
	TIME [epoch: 6.57 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30364247828900237		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.30364247828900237 | validation: 0.37116107301678797]
	TIME [epoch: 6.6 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36277035307820693		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.36277035307820693 | validation: 0.4061574355416845]
	TIME [epoch: 6.58 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3402389129829758		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.3402389129829758 | validation: 0.3881767464460691]
	TIME [epoch: 6.51 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3291956001790651		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.3291956001790651 | validation: 0.2206604782809883]
	TIME [epoch: 6.56 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28098801118850036		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.28098801118850036 | validation: 0.27853643798771294]
	TIME [epoch: 6.57 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30673883409094205		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.30673883409094205 | validation: 0.2810258804221571]
	TIME [epoch: 6.57 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3462776363552359		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.3462776363552359 | validation: 0.251308324352671]
	TIME [epoch: 6.56 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30230770653484806		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.30230770653484806 | validation: 0.2365867289613989]
	TIME [epoch: 6.56 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33128256108398346		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.33128256108398346 | validation: 0.3307832346052153]
	TIME [epoch: 6.51 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31112434653459464		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.31112434653459464 | validation: 0.30536988085775285]
	TIME [epoch: 6.57 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2800225822741785		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.2800225822741785 | validation: 0.23063986801293063]
	TIME [epoch: 6.57 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3264633457378656		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.3264633457378656 | validation: 0.3220725981793244]
	TIME [epoch: 6.57 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3521562804183196		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.3521562804183196 | validation: 0.2360150781389077]
	TIME [epoch: 6.56 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2896378348063998		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.2896378348063998 | validation: 0.35845651950318586]
	TIME [epoch: 6.57 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29646765332463076		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.29646765332463076 | validation: 0.2476985192683321]
	TIME [epoch: 6.56 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30098750238935223		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.30098750238935223 | validation: 0.2294529217428738]
	TIME [epoch: 6.56 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2968325271410148		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.2968325271410148 | validation: 0.18624128264829826]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_683.pth
	Model improved!!!
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29926409203330595		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.29926409203330595 | validation: 0.19837862597930772]
	TIME [epoch: 6.58 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27261609659397945		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.27261609659397945 | validation: 0.2619727543913069]
	TIME [epoch: 6.58 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33772856811895813		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.33772856811895813 | validation: 0.4770491247537737]
	TIME [epoch: 6.56 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3282829475088852		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.3282829475088852 | validation: 0.2448239850048686]
	TIME [epoch: 6.51 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29895249258399986		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.29895249258399986 | validation: 0.23038386941389072]
	TIME [epoch: 6.56 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30258932017154566		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.30258932017154566 | validation: 0.2570521558679746]
	TIME [epoch: 6.55 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3369948247419118		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.3369948247419118 | validation: 0.5232201151629036]
	TIME [epoch: 6.6 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3702874426177538		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.3702874426177538 | validation: 0.3261273281252744]
	TIME [epoch: 6.56 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3317950311210769		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.3317950311210769 | validation: 0.3774029866624336]
	TIME [epoch: 6.55 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412999301358784		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.3412999301358784 | validation: 0.2775651293236429]
	TIME [epoch: 6.58 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282442805898543		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.282442805898543 | validation: 0.25512383394191357]
	TIME [epoch: 6.6 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27306826071246504		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.27306826071246504 | validation: 0.26010385922152685]
	TIME [epoch: 6.56 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35835487680353906		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.35835487680353906 | validation: 0.23287994745398677]
	TIME [epoch: 6.55 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2880999801079782		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.2880999801079782 | validation: 0.2720014488647596]
	TIME [epoch: 6.57 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30315531224439307		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.30315531224439307 | validation: 0.2549546151338906]
	TIME [epoch: 6.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2997169183436057		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.2997169183436057 | validation: 0.28968050872048956]
	TIME [epoch: 6.57 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29299544966903074		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.29299544966903074 | validation: 0.20468138441869566]
	TIME [epoch: 6.6 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2678845236390509		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.2678845236390509 | validation: 0.3446408534208784]
	TIME [epoch: 6.52 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3165577929939341		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.3165577929939341 | validation: 0.262286164122674]
	TIME [epoch: 6.59 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3273892850869891		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.3273892850869891 | validation: 0.2953720974359022]
	TIME [epoch: 6.56 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30087531933229494		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.30087531933229494 | validation: 0.3180115065277904]
	TIME [epoch: 6.51 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.305114516965891		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.305114516965891 | validation: 0.22231715257336654]
	TIME [epoch: 6.56 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3012455658454576		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.3012455658454576 | validation: 0.39618735850672365]
	TIME [epoch: 6.56 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31959644846079716		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.31959644846079716 | validation: 0.2132200300165436]
	TIME [epoch: 6.56 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2888091081708233		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.2888091081708233 | validation: 0.22118806284234885]
	TIME [epoch: 6.55 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27844430463235126		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.27844430463235126 | validation: 0.27855989694546296]
	TIME [epoch: 6.55 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37016029157643565		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.37016029157643565 | validation: 0.2615775157586288]
	TIME [epoch: 6.56 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2609017453826189		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.2609017453826189 | validation: 0.22218838145557168]
	TIME [epoch: 6.56 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30718874377280303		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.30718874377280303 | validation: 0.2194027701354281]
	TIME [epoch: 6.56 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344247165966339		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.3344247165966339 | validation: 0.18674623597825382]
	TIME [epoch: 6.56 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2599863869535997		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.2599863869535997 | validation: 0.32363233869049957]
	TIME [epoch: 6.56 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31277742156609784		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.31277742156609784 | validation: 0.2637293784554746]
	TIME [epoch: 6.55 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2933174053312905		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.2933174053312905 | validation: 0.21963680291874751]
	TIME [epoch: 6.5 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2832818967927183		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.2832818967927183 | validation: 0.27864422726361127]
	TIME [epoch: 6.56 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3029333324535531		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.3029333324535531 | validation: 0.20239537524135273]
	TIME [epoch: 6.56 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2892824253024191		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.2892824253024191 | validation: 0.3257382451618597]
	TIME [epoch: 6.56 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3106316591645734		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.3106316591645734 | validation: 0.23276207773949506]
	TIME [epoch: 6.59 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30040355396779567		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.30040355396779567 | validation: 0.2316522170153236]
	TIME [epoch: 6.53 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27838530469119416		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.27838530469119416 | validation: 0.2219928822041956]
	TIME [epoch: 6.55 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2688355008817607		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.2688355008817607 | validation: 0.30719153979016356]
	TIME [epoch: 6.57 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2957674740104377		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.2957674740104377 | validation: 0.3038838529769417]
	TIME [epoch: 6.55 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3049012463486552		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.3049012463486552 | validation: 0.1828815790743309]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2621879133520681		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.2621879133520681 | validation: 0.245646212824297]
	TIME [epoch: 6.55 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.303975978458079		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.303975978458079 | validation: 0.24345678049780986]
	TIME [epoch: 6.55 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28022224831581355		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.28022224831581355 | validation: 0.20092092749259663]
	TIME [epoch: 6.55 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2624490430990212		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.2624490430990212 | validation: 0.36103724818672334]
	TIME [epoch: 6.55 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3099762855360924		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.3099762855360924 | validation: 0.21137877668772345]
	TIME [epoch: 6.56 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2625632697702852		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.2625632697702852 | validation: 0.2500325888136506]
	TIME [epoch: 6.57 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29680975081770167		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.29680975081770167 | validation: 0.393536483568755]
	TIME [epoch: 6.57 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2783551099339938		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.2783551099339938 | validation: 0.24751051094301638]
	TIME [epoch: 6.56 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26543226385494434		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.26543226385494434 | validation: 0.21463938349267056]
	TIME [epoch: 6.55 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2621868074663701		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.2621868074663701 | validation: 0.27050754533415494]
	TIME [epoch: 6.51 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28180010827637214		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.28180010827637214 | validation: 0.2467197354269485]
	TIME [epoch: 6.54 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27175308329022		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.27175308329022 | validation: 0.4566338933950538]
	TIME [epoch: 6.55 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40249672750957877		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.40249672750957877 | validation: 0.22965378502505457]
	TIME [epoch: 6.56 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2744777049335778		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.2744777049335778 | validation: 0.23071630538595805]
	TIME [epoch: 6.54 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590991822156611		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.2590991822156611 | validation: 0.2470514335345947]
	TIME [epoch: 6.57 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2547674717466173		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.2547674717466173 | validation: 0.2233584291368924]
	TIME [epoch: 6.57 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2732215298976862		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.2732215298976862 | validation: 0.21575782901071505]
	TIME [epoch: 6.56 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23715944824851606		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.23715944824851606 | validation: 0.2103684405872405]
	TIME [epoch: 6.55 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2913756319478446		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.2913756319478446 | validation: 0.3846524152246967]
	TIME [epoch: 6.56 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293873969823634		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.293873969823634 | validation: 0.3775514636569326]
	TIME [epoch: 6.56 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2872039800523336		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.2872039800523336 | validation: 0.3221272843435516]
	TIME [epoch: 6.56 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2846722293947987		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.2846722293947987 | validation: 0.21390988886837442]
	TIME [epoch: 6.55 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2784913628259706		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.2784913628259706 | validation: 0.20242970376841635]
	TIME [epoch: 6.54 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3108697113747893		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.3108697113747893 | validation: 0.20228024242084608]
	TIME [epoch: 6.57 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24170104156113087		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.24170104156113087 | validation: 0.21471322992015932]
	TIME [epoch: 6.57 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24020066021274222		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.24020066021274222 | validation: 0.2838961449134073]
	TIME [epoch: 6.6 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24525384447423831		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.24525384447423831 | validation: 0.19849687753035292]
	TIME [epoch: 6.51 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2506362351304091		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.2506362351304091 | validation: 0.23342449486409642]
	TIME [epoch: 6.59 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2735513765221273		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.2735513765221273 | validation: 0.26650860022657646]
	TIME [epoch: 6.58 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27312666491099413		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.27312666491099413 | validation: 0.23449558501804071]
	TIME [epoch: 6.56 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535128920575318		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.2535128920575318 | validation: 0.24981471054177454]
	TIME [epoch: 6.51 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24819694076316895		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.24819694076316895 | validation: 0.24707416308861668]
	TIME [epoch: 6.58 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2727526873706498		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.2727526873706498 | validation: 0.2531868769971135]
	TIME [epoch: 6.55 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26611561455439825		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.26611561455439825 | validation: 0.2241587269354235]
	TIME [epoch: 6.56 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2537488868469947		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.2537488868469947 | validation: 0.20877198789922083]
	TIME [epoch: 6.54 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2267818566087225		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.2267818566087225 | validation: 0.19627895936985387]
	TIME [epoch: 6.56 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23851705601680517		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.23851705601680517 | validation: 0.3018163234568333]
	TIME [epoch: 6.55 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28755083872155246		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.28755083872155246 | validation: 0.20286691962432962]
	TIME [epoch: 6.55 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2529498701877237		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.2529498701877237 | validation: 0.2442099308194552]
	TIME [epoch: 6.57 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26997629116187527		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.26997629116187527 | validation: 0.28122809335088866]
	TIME [epoch: 6.58 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.288772392559113		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.288772392559113 | validation: 0.26712469628250024]
	TIME [epoch: 6.59 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25163752094468445		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.25163752094468445 | validation: 0.1997049952680563]
	TIME [epoch: 6.58 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26354295442766024		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.26354295442766024 | validation: 0.21172260718755262]
	TIME [epoch: 6.57 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27630237262006685		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.27630237262006685 | validation: 0.24193227601232498]
	TIME [epoch: 6.59 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3298422701761245		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.3298422701761245 | validation: 0.413128373449497]
	TIME [epoch: 6.55 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.285812293417693		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.285812293417693 | validation: 0.26538042774838005]
	TIME [epoch: 6.57 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2791208448496659		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.2791208448496659 | validation: 0.30281591607389163]
	TIME [epoch: 6.57 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2681435257184409		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.2681435257184409 | validation: 0.2085587390844245]
	TIME [epoch: 6.59 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23385658162755024		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.23385658162755024 | validation: 0.19301282703336295]
	TIME [epoch: 6.59 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32024190020020826		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.32024190020020826 | validation: 0.1813655471385995]
	TIME [epoch: 6.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_775.pth
	Model improved!!!
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2711881799900668		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.2711881799900668 | validation: 0.2440146835123569]
	TIME [epoch: 6.57 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651910569394719		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.2651910569394719 | validation: 0.19299301613454722]
	TIME [epoch: 6.57 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24676240993886722		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.24676240993886722 | validation: 0.177018305231816]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_778.pth
	Model improved!!!
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2602937607579612		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.2602937607579612 | validation: 0.1963129591517116]
	TIME [epoch: 6.58 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26429975158740204		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.26429975158740204 | validation: 0.3194766343512959]
	TIME [epoch: 6.6 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31292088455460404		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.31292088455460404 | validation: 0.18111493975348558]
	TIME [epoch: 6.52 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25576849706620536		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.25576849706620536 | validation: 0.1747264245435985]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_782.pth
	Model improved!!!
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2422120223524691		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.2422120223524691 | validation: 0.19897288585302988]
	TIME [epoch: 6.57 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510839501307708		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.2510839501307708 | validation: 0.23066635656156084]
	TIME [epoch: 6.57 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23075798985632562		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.23075798985632562 | validation: 0.2048392473249613]
	TIME [epoch: 6.58 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23521324097702007		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.23521324097702007 | validation: 0.23397193449321477]
	TIME [epoch: 6.58 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30200652722772614		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.30200652722772614 | validation: 0.2559498394382166]
	TIME [epoch: 6.58 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24444243714503605		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.24444243714503605 | validation: 0.20297837044446684]
	TIME [epoch: 6.53 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29283009692647793		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.29283009692647793 | validation: 0.24345593217161607]
	TIME [epoch: 6.59 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25021688037726897		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.25021688037726897 | validation: 0.2157365102462542]
	TIME [epoch: 6.57 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23604070299462518		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.23604070299462518 | validation: 0.23413125075820723]
	TIME [epoch: 6.56 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23355202169982953		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.23355202169982953 | validation: 0.28660189791988194]
	TIME [epoch: 6.58 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2649496960712634		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.2649496960712634 | validation: 0.17921486687546984]
	TIME [epoch: 6.59 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23884132259864213		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.23884132259864213 | validation: 0.19609705519654852]
	TIME [epoch: 6.55 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2512745759611066		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.2512745759611066 | validation: 0.20604890287239905]
	TIME [epoch: 6.57 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24743601481313265		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.24743601481313265 | validation: 0.18849731692607066]
	TIME [epoch: 6.54 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25547809093464785		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.25547809093464785 | validation: 0.19698856011550867]
	TIME [epoch: 6.57 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26883619079179966		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.26883619079179966 | validation: 0.22461140674257757]
	TIME [epoch: 6.58 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2811436784809109		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.2811436784809109 | validation: 0.2120005480954425]
	TIME [epoch: 6.56 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23437672638926482		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.23437672638926482 | validation: 0.22898650420985361]
	TIME [epoch: 6.58 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30632806950535774		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.30632806950535774 | validation: 0.2210371252010272]
	TIME [epoch: 6.57 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24429837084352884		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.24429837084352884 | validation: 0.17325380716250796]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_802.pth
	Model improved!!!
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23686520707848566		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.23686520707848566 | validation: 0.2541574677453015]
	TIME [epoch: 6.61 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32554721570023226		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.32554721570023226 | validation: 0.23391360887802135]
	TIME [epoch: 6.57 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2438432413938887		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.2438432413938887 | validation: 0.20563715794426984]
	TIME [epoch: 6.56 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23993508160762703		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.23993508160762703 | validation: 0.19029758183735088]
	TIME [epoch: 6.56 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2652169494012617		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.2652169494012617 | validation: 0.36355824197628234]
	TIME [epoch: 6.57 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3092363741282027		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.3092363741282027 | validation: 0.18896432354432613]
	TIME [epoch: 6.56 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2306158943558783		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.2306158943558783 | validation: 0.23363352163360682]
	TIME [epoch: 6.55 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23434159568220253		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.23434159568220253 | validation: 0.2547947325666662]
	TIME [epoch: 6.49 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3460834487572426		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.3460834487572426 | validation: 0.2889594382479659]
	TIME [epoch: 6.56 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23081371188755415		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.23081371188755415 | validation: 0.18537925728558158]
	TIME [epoch: 6.55 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22802418824458665		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.22802418824458665 | validation: 0.2768300286161606]
	TIME [epoch: 6.57 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23312742465287645		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.23312742465287645 | validation: 0.21672962685410282]
	TIME [epoch: 6.56 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2503377207773949		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.2503377207773949 | validation: 0.23712176544281632]
	TIME [epoch: 6.48 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2351628986973503		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.2351628986973503 | validation: 0.21400279865271948]
	TIME [epoch: 6.59 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584531760702028		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.2584531760702028 | validation: 0.1975241065715383]
	TIME [epoch: 6.56 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23766456178780973		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.23766456178780973 | validation: 0.20812025934076256]
	TIME [epoch: 6.56 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23354031349839344		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.23354031349839344 | validation: 0.22089642988569774]
	TIME [epoch: 6.57 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24897702148671375		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.24897702148671375 | validation: 0.2748035498984449]
	TIME [epoch: 6.54 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28242417842176915		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.28242417842176915 | validation: 0.33365367632605036]
	TIME [epoch: 6.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890304359790805		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.2890304359790805 | validation: 0.22623469695178666]
	TIME [epoch: 6.54 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25058685790829494		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.25058685790829494 | validation: 0.19475223101794456]
	TIME [epoch: 6.57 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24864891801494618		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.24864891801494618 | validation: 0.19350576277761997]
	TIME [epoch: 6.54 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24628479880008375		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.24628479880008375 | validation: 0.19303065522374746]
	TIME [epoch: 6.6 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25229830574593604		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.25229830574593604 | validation: 0.3184574631085161]
	TIME [epoch: 6.53 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23020685882041805		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.23020685882041805 | validation: 0.30435325322748674]
	TIME [epoch: 6.58 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25955124394003676		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.25955124394003676 | validation: 0.19679602625150736]
	TIME [epoch: 6.49 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23982509031894186		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.23982509031894186 | validation: 0.2663425418930177]
	TIME [epoch: 6.56 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23432351014384725		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.23432351014384725 | validation: 0.2486917163688273]
	TIME [epoch: 6.54 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26593449430112814		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.26593449430112814 | validation: 0.22081320674301047]
	TIME [epoch: 6.56 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25145643888093006		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.25145643888093006 | validation: 0.20853831532110512]
	TIME [epoch: 6.57 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25382085838877133		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.25382085838877133 | validation: 0.20320410158906307]
	TIME [epoch: 6.57 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581264551972728		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.2581264551972728 | validation: 0.2441776103909129]
	TIME [epoch: 6.55 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2516102488878188		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.2516102488878188 | validation: 0.19251605367041863]
	TIME [epoch: 6.56 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22625609844450417		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.22625609844450417 | validation: 0.19053247399700238]
	TIME [epoch: 6.55 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25220089364411896		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.25220089364411896 | validation: 0.16303297525456362]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_837.pth
	Model improved!!!
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2557072554127741		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.2557072554127741 | validation: 0.2574485595107722]
	TIME [epoch: 6.59 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23583971737099396		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.23583971737099396 | validation: 0.181453656292623]
	TIME [epoch: 6.61 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22661098197183735		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.22661098197183735 | validation: 0.1945851478776801]
	TIME [epoch: 6.52 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2685716359801894		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.2685716359801894 | validation: 0.2673936306474294]
	TIME [epoch: 6.56 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524291960101036		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.2524291960101036 | validation: 0.20792005576882255]
	TIME [epoch: 6.55 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23406967085553032		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.23406967085553032 | validation: 0.2415051523387907]
	TIME [epoch: 6.54 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24871004125927088		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.24871004125927088 | validation: 0.19129427383299807]
	TIME [epoch: 6.57 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2944956842248182		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.2944956842248182 | validation: 0.21346240020888915]
	TIME [epoch: 6.54 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23651195773075373		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.23651195773075373 | validation: 0.17239779375583092]
	TIME [epoch: 6.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2417900563131882		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.2417900563131882 | validation: 0.18690241214104775]
	TIME [epoch: 6.56 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25134838438431995		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.25134838438431995 | validation: 0.1720030636310132]
	TIME [epoch: 6.55 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24491748084312398		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.24491748084312398 | validation: 0.2301827852791773]
	TIME [epoch: 6.55 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25419446001333723		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.25419446001333723 | validation: 0.2351480338177248]
	TIME [epoch: 6.56 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24713134453833507		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.24713134453833507 | validation: 0.2568388153319139]
	TIME [epoch: 6.56 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27037529444371555		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.27037529444371555 | validation: 0.2913166239073331]
	TIME [epoch: 6.6 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802556826663427		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.2802556826663427 | validation: 0.3255668856461048]
	TIME [epoch: 6.49 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26324722231676606		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.26324722231676606 | validation: 0.20093509994902156]
	TIME [epoch: 6.56 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22550884692800913		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.22550884692800913 | validation: 0.19197058953741597]
	TIME [epoch: 6.57 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22453753293156006		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.22453753293156006 | validation: 0.17738721350171613]
	TIME [epoch: 6.57 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2150651987531301		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.2150651987531301 | validation: 0.1853648483295401]
	TIME [epoch: 6.51 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22966211590018878		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.22966211590018878 | validation: 0.21736858247304336]
	TIME [epoch: 6.55 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3028887308021856		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.3028887308021856 | validation: 0.2947920019565585]
	TIME [epoch: 6.54 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23720850735610066		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.23720850735610066 | validation: 0.1840805379556074]
	TIME [epoch: 6.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21715445307606435		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.21715445307606435 | validation: 0.22289126112751498]
	TIME [epoch: 6.53 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25017140297387236		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.25017140297387236 | validation: 0.24762236298263005]
	TIME [epoch: 6.54 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2842794068229828		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.2842794068229828 | validation: 0.19677740143512587]
	TIME [epoch: 6.56 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.284559431089681		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.284559431089681 | validation: 0.1971744963137202]
	TIME [epoch: 6.54 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2229182235263193		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.2229182235263193 | validation: 0.2288268249955876]
	TIME [epoch: 6.53 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24757285483491656		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.24757285483491656 | validation: 0.18253132870799765]
	TIME [epoch: 6.59 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23313071421109277		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.23313071421109277 | validation: 0.2114871848872315]
	TIME [epoch: 6.49 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2229425746027463		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.2229425746027463 | validation: 0.18668064504015303]
	TIME [epoch: 6.55 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22450597969906264		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.22450597969906264 | validation: 0.20561291689513983]
	TIME [epoch: 6.55 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2477500837817858		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.2477500837817858 | validation: 0.16951011042373335]
	TIME [epoch: 6.51 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23288170935089011		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.23288170935089011 | validation: 0.29926233126726176]
	TIME [epoch: 6.53 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2793304656044148		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.2793304656044148 | validation: 0.1944496353168673]
	TIME [epoch: 6.55 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2632231924341845		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.2632231924341845 | validation: 0.1556202592114366]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_873.pth
	Model improved!!!
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2451580794989483		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.2451580794989483 | validation: 0.27137751327049997]
	TIME [epoch: 6.55 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530492969192631		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.2530492969192631 | validation: 0.17819455776991416]
	TIME [epoch: 6.53 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2178602874545565		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.2178602874545565 | validation: 0.21523444571308908]
	TIME [epoch: 6.56 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36894646602902653		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.36894646602902653 | validation: 0.1899780721052307]
	TIME [epoch: 6.58 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2221501448050586		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.2221501448050586 | validation: 0.19565027287927145]
	TIME [epoch: 6.55 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22626691458126819		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.22626691458126819 | validation: 0.20584761245752034]
	TIME [epoch: 6.56 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2210315875782688		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.2210315875782688 | validation: 0.23634503255731357]
	TIME [epoch: 6.54 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23031157943450342		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.23031157943450342 | validation: 0.25053478284176667]
	TIME [epoch: 6.54 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23086582215193083		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.23086582215193083 | validation: 0.20638897627291997]
	TIME [epoch: 6.54 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21760968857430957		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.21760968857430957 | validation: 0.15859743961265604]
	TIME [epoch: 6.54 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25635383049065524		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.25635383049065524 | validation: 0.27231540920112385]
	TIME [epoch: 6.54 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2351337580748341		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.2351337580748341 | validation: 0.18416012113507105]
	TIME [epoch: 6.54 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23815041311137217		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.23815041311137217 | validation: 0.19657945627852635]
	TIME [epoch: 6.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21178267575862902		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.21178267575862902 | validation: 0.19595498097508526]
	TIME [epoch: 6.55 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2153023332934073		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.2153023332934073 | validation: 0.16173715285445447]
	TIME [epoch: 6.55 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24999826939089817		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.24999826939089817 | validation: 0.22893841873604626]
	TIME [epoch: 6.55 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22603121887771277		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.22603121887771277 | validation: 0.28539424618194653]
	TIME [epoch: 6.58 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25442591607968196		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.25442591607968196 | validation: 0.2582116541875135]
	TIME [epoch: 6.56 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22156273931710527		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.22156273931710527 | validation: 0.2096851677973244]
	TIME [epoch: 6.56 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22754971910621136		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.22754971910621136 | validation: 0.2538209117243143]
	TIME [epoch: 6.56 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22350948937189613		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.22350948937189613 | validation: 0.16799983497384724]
	TIME [epoch: 6.56 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21992452909737362		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.21992452909737362 | validation: 0.2023779320490699]
	TIME [epoch: 6.5 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22106592306786427		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.22106592306786427 | validation: 0.2885021687994306]
	TIME [epoch: 6.57 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25701459790534387		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.25701459790534387 | validation: 0.20301319535570186]
	TIME [epoch: 6.56 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21254860988993252		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.21254860988993252 | validation: 0.1607845001795621]
	TIME [epoch: 6.57 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2082864415350326		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.2082864415350326 | validation: 0.231668447719059]
	TIME [epoch: 6.57 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22143817872254296		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.22143817872254296 | validation: 0.18608249144004874]
	TIME [epoch: 6.56 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2240994446028535		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.2240994446028535 | validation: 0.2092199872994651]
	TIME [epoch: 6.51 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23170381334569742		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.23170381334569742 | validation: 0.20997349099674814]
	TIME [epoch: 6.56 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2550102055385003		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.2550102055385003 | validation: 0.25573229257414215]
	TIME [epoch: 6.55 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21531273977194135		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.21531273977194135 | validation: 0.1807956767895172]
	TIME [epoch: 6.6 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22616973300602086		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.22616973300602086 | validation: 0.20077300293019348]
	TIME [epoch: 6.56 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2338225883595778		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.2338225883595778 | validation: 0.25329457515170517]
	TIME [epoch: 6.5 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22012527595435874		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.22012527595435874 | validation: 0.17071919355721618]
	TIME [epoch: 6.54 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23942308284763836		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.23942308284763836 | validation: 0.21014397403814353]
	TIME [epoch: 6.54 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2533146902900322		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.2533146902900322 | validation: 0.27328650225107043]
	TIME [epoch: 6.49 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2400458757801544		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.2400458757801544 | validation: 0.3139312736725796]
	TIME [epoch: 6.56 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.280612844744442		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.280612844744442 | validation: 0.18409934425585406]
	TIME [epoch: 6.54 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20645115377157708		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.20645115377157708 | validation: 0.17374041531273038]
	TIME [epoch: 6.54 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21046761390852148		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.21046761390852148 | validation: 0.17245788428019332]
	TIME [epoch: 6.55 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21502116085099798		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.21502116085099798 | validation: 0.2593620909357627]
	TIME [epoch: 6.54 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22850577005713693		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.22850577005713693 | validation: 0.17406713622705222]
	TIME [epoch: 6.55 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2225924759060539		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.2225924759060539 | validation: 0.27093497993183807]
	TIME [epoch: 6.5 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2278705857446191		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.2278705857446191 | validation: 0.2053938855118377]
	TIME [epoch: 6.55 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2272096438544068		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.2272096438544068 | validation: 0.18323820009556108]
	TIME [epoch: 6.54 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22578145948237632		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.22578145948237632 | validation: 0.2977064048202948]
	TIME [epoch: 6.55 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2326238591363005		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.2326238591363005 | validation: 0.18045776645148892]
	TIME [epoch: 6.55 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2088329266328383		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.2088329266328383 | validation: 0.18220338222468088]
	TIME [epoch: 6.58 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22161563851538407		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.22161563851538407 | validation: 0.20129542066361666]
	TIME [epoch: 6.54 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2191347453320696		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.2191347453320696 | validation: 0.18386421335640937]
	TIME [epoch: 6.55 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21041050379145215		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.21041050379145215 | validation: 0.15610853118253107]
	TIME [epoch: 6.6 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2139518537001429		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.2139518537001429 | validation: 0.1734379203426947]
	TIME [epoch: 6.49 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22880161718810063		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.22880161718810063 | validation: 0.251682409812963]
	TIME [epoch: 6.54 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21188282687426274		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.21188282687426274 | validation: 0.1891463032631704]
	TIME [epoch: 6.49 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23766276287367344		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.23766276287367344 | validation: 0.15664726101318696]
	TIME [epoch: 6.56 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2376312874045061		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.2376312874045061 | validation: 0.23811576309667615]
	TIME [epoch: 6.54 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2355796320918303		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.2355796320918303 | validation: 0.15709843554082623]
	TIME [epoch: 6.53 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22341808639268707		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.22341808639268707 | validation: 0.15898717016613048]
	TIME [epoch: 6.55 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20528321439294034		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.20528321439294034 | validation: 0.1583101835269646]
	TIME [epoch: 6.56 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2022691903559305		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.2022691903559305 | validation: 0.17390863179394195]
	TIME [epoch: 6.58 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2110221868431371		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.2110221868431371 | validation: 0.14949673410309655]
	TIME [epoch: 6.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_934.pth
	Model improved!!!
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23694115787654949		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.23694115787654949 | validation: 0.2266285579714851]
	TIME [epoch: 6.57 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2262016835829931		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.2262016835829931 | validation: 0.15991146425092298]
	TIME [epoch: 6.56 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21535224286045734		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.21535224286045734 | validation: 0.2672505406853719]
	TIME [epoch: 6.55 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22613863389570193		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.22613863389570193 | validation: 0.1935770765906006]
	TIME [epoch: 6.56 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2063442990241682		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.2063442990241682 | validation: 0.21067656436331803]
	TIME [epoch: 6.56 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2123160848737247		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.2123160848737247 | validation: 0.16011914917887354]
	TIME [epoch: 6.55 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2010260212612515		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.2010260212612515 | validation: 0.15907108554143848]
	TIME [epoch: 6.56 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22759653747674197		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.22759653747674197 | validation: 0.23545950096181717]
	TIME [epoch: 6.57 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21274395919738662		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.21274395919738662 | validation: 0.16183253098718567]
	TIME [epoch: 6.6 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2112822529314145		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.2112822529314145 | validation: 0.1619269799275291]
	TIME [epoch: 6.56 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19181775925570402		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.19181775925570402 | validation: 0.15873726918299216]
	TIME [epoch: 6.56 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2004777440718945		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.2004777440718945 | validation: 0.24461640124571202]
	TIME [epoch: 6.52 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22399524914439453		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.22399524914439453 | validation: 0.15898704208718012]
	TIME [epoch: 6.55 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23475283435169342		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.23475283435169342 | validation: 0.18780454652848996]
	TIME [epoch: 6.56 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21294789273195894		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.21294789273195894 | validation: 0.1527068516711698]
	TIME [epoch: 6.57 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23244644266528652		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.23244644266528652 | validation: 0.20432562257403625]
	TIME [epoch: 6.55 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22933651675848668		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.22933651675848668 | validation: 0.16334574672299065]
	TIME [epoch: 6.56 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2159174850840953		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.2159174850840953 | validation: 0.16494257740753043]
	TIME [epoch: 6.56 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2252797063054375		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.2252797063054375 | validation: 0.17035335115376074]
	TIME [epoch: 6.57 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2293878215745709		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.2293878215745709 | validation: 0.21020010806819542]
	TIME [epoch: 6.56 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21549119676025796		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.21549119676025796 | validation: 0.19079601386435038]
	TIME [epoch: 6.57 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21271433476352242		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.21271433476352242 | validation: 0.2632786639544624]
	TIME [epoch: 6.59 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2293063365456607		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.2293063365456607 | validation: 0.18625755044035006]
	TIME [epoch: 6.58 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24205671672364518		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.24205671672364518 | validation: 0.20460260814313716]
	TIME [epoch: 6.56 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2018724052470624		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.2018724052470624 | validation: 0.15397389013532528]
	TIME [epoch: 6.59 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20643405398374198		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.20643405398374198 | validation: 0.23704490947634674]
	TIME [epoch: 6.59 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20277345816401363		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.20277345816401363 | validation: 0.17565367886958547]
	TIME [epoch: 6.51 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24655868308076617		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.24655868308076617 | validation: 0.1955464119727564]
	TIME [epoch: 6.58 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059901369307922		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.2059901369307922 | validation: 0.19866314744490104]
	TIME [epoch: 6.57 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23943969800809162		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.23943969800809162 | validation: 0.2680305925448586]
	TIME [epoch: 6.59 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3017544013912669		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.3017544013912669 | validation: 0.40437368039896837]
	TIME [epoch: 6.54 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23054919311179375		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.23054919311179375 | validation: 0.1816963236908072]
	TIME [epoch: 6.57 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19810927015699298		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.19810927015699298 | validation: 0.19041724950927688]
	TIME [epoch: 6.58 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23417934078550773		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.23417934078550773 | validation: 0.19760995583766644]
	TIME [epoch: 6.57 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21418007995746616		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.21418007995746616 | validation: 0.15579662797249996]
	TIME [epoch: 6.57 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20548954352455212		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.20548954352455212 | validation: 0.2630884565164275]
	TIME [epoch: 6.52 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22793486573258218		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.22793486573258218 | validation: 0.3185597610354209]
	TIME [epoch: 6.57 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2829156573043412		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.2829156573043412 | validation: 0.18746331976199784]
	TIME [epoch: 6.61 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20743335557113182		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.20743335557113182 | validation: 0.1517380518152229]
	TIME [epoch: 6.58 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19094259678323772		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.19094259678323772 | validation: 0.17238826400342436]
	TIME [epoch: 6.57 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21905510715851736		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.21905510715851736 | validation: 0.17646557044775374]
	TIME [epoch: 6.57 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21679428710081164		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.21679428710081164 | validation: 0.1595511339844404]
	TIME [epoch: 6.56 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20057246259031886		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.20057246259031886 | validation: 0.2097789987385334]
	TIME [epoch: 6.57 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21910664245811992		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.21910664245811992 | validation: 0.262251826891963]
	TIME [epoch: 6.57 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2360413284627394		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.2360413284627394 | validation: 0.20999753920953154]
	TIME [epoch: 6.58 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20827091376762874		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.20827091376762874 | validation: 0.1817603154218428]
	TIME [epoch: 6.57 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1939496315734598		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.1939496315734598 | validation: 0.15341172400700515]
	TIME [epoch: 6.6 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19340247960382084		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.19340247960382084 | validation: 0.1990994266115716]
	TIME [epoch: 6.58 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21663565000987664		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.21663565000987664 | validation: 0.2124942483854266]
	TIME [epoch: 6.57 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21851105554511807		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.21851105554511807 | validation: 0.21153129173825178]
	TIME [epoch: 6.53 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21341870069915403		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.21341870069915403 | validation: 0.23338945781684103]
	TIME [epoch: 6.55 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20940341224464823		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.20940341224464823 | validation: 0.1488909224259818]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_986.pth
	Model improved!!!
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20055573657147835		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.20055573657147835 | validation: 0.14529130048612784]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_987.pth
	Model improved!!!
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19806240713693135		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.19806240713693135 | validation: 0.18289433514035314]
	TIME [epoch: 6.58 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19687384160966032		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.19687384160966032 | validation: 0.1720137563965865]
	TIME [epoch: 6.56 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21359538143994095		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.21359538143994095 | validation: 0.15221253645148342]
	TIME [epoch: 6.56 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19689231847504293		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.19689231847504293 | validation: 0.19344942592830006]
	TIME [epoch: 6.55 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20097377358225343		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.20097377358225343 | validation: 0.15071520386694345]
	TIME [epoch: 6.56 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1953209873554352		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.1953209873554352 | validation: 0.15807713775310442]
	TIME [epoch: 6.57 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1996965752316388		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.1996965752316388 | validation: 0.1415411413700744]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_994.pth
	Model improved!!!
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2038926030822826		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.2038926030822826 | validation: 0.20169923297169248]
	TIME [epoch: 6.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18781884484497166		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.18781884484497166 | validation: 0.16583772930732635]
	TIME [epoch: 6.59 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19228574584636932		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.19228574584636932 | validation: 0.18619967679155444]
	TIME [epoch: 6.55 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2209626534373066		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.2209626534373066 | validation: 0.15159228933824773]
	TIME [epoch: 6.49 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20084269477528105		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.20084269477528105 | validation: 0.21783314487411212]
	TIME [epoch: 6.58 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20478794617388804		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.20478794617388804 | validation: 0.15196536577347183]
	TIME [epoch: 6.54 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19766237907226575		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.19766237907226575 | validation: 0.147255889909012]
	TIME [epoch: 6.53 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20137238703500912		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.20137238703500912 | validation: 0.13540781113811204]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1002.pth
	Model improved!!!
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19343825144678614		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.19343825144678614 | validation: 0.19180615578922214]
	TIME [epoch: 6.57 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19912521404288064		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.19912521404288064 | validation: 0.16807195767828945]
	TIME [epoch: 6.57 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2020762239956553		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.2020762239956553 | validation: 0.19333600129057069]
	TIME [epoch: 6.5 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20241688560354407		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.20241688560354407 | validation: 0.18128842388627384]
	TIME [epoch: 6.55 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21198324913978073		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.21198324913978073 | validation: 0.18109868909182908]
	TIME [epoch: 6.55 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22392553218254613		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.22392553218254613 | validation: 0.16753026652848874]
	TIME [epoch: 6.5 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19183474186857985		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.19183474186857985 | validation: 0.16093629724891986]
	TIME [epoch: 6.56 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18866843818466855		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.18866843818466855 | validation: 0.1444920434872885]
	TIME [epoch: 6.59 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17788099036777444		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.17788099036777444 | validation: 0.19372482521664927]
	TIME [epoch: 6.56 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24177855947194735		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.24177855947194735 | validation: 0.3176999872488065]
	TIME [epoch: 6.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22505277981083355		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.22505277981083355 | validation: 0.1563882318602592]
	TIME [epoch: 6.56 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20592405517845835		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.20592405517845835 | validation: 0.14764623721321513]
	TIME [epoch: 6.55 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1920052472628713		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.1920052472628713 | validation: 0.15359419692555057]
	TIME [epoch: 6.55 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20680762956550253		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.20680762956550253 | validation: 0.1897907959649126]
	TIME [epoch: 6.56 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1913697603085871		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.1913697603085871 | validation: 0.1592555609522874]
	TIME [epoch: 6.54 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19789139452802137		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.19789139452802137 | validation: 0.1543002232697729]
	TIME [epoch: 6.58 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20758276184097388		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.20758276184097388 | validation: 0.17940112983349088]
	TIME [epoch: 6.54 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21065367269979532		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.21065367269979532 | validation: 0.1399172641561201]
	TIME [epoch: 6.49 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19071062077639717		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.19071062077639717 | validation: 0.1576204198537909]
	TIME [epoch: 6.58 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19911096677220935		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.19911096677220935 | validation: 0.26743856840410685]
	TIME [epoch: 6.55 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21519380163870486		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.21519380163870486 | validation: 0.15311324151462233]
	TIME [epoch: 6.54 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18390365075679807		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.18390365075679807 | validation: 0.1919299149018978]
	TIME [epoch: 6.54 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22249939321659465		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.22249939321659465 | validation: 0.16248468916737216]
	TIME [epoch: 6.54 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19170056705764488		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.19170056705764488 | validation: 0.15772758643124224]
	TIME [epoch: 6.48 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19371782920094288		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.19371782920094288 | validation: 0.1686202706547607]
	TIME [epoch: 6.55 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19589452191714155		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.19589452191714155 | validation: 0.167127912512818]
	TIME [epoch: 6.55 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1834019507180171		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.1834019507180171 | validation: 0.14093535148638028]
	TIME [epoch: 6.54 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18851500005043162		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.18851500005043162 | validation: 0.1777935737939362]
	TIME [epoch: 6.5 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21136701654991658		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.21136701654991658 | validation: 0.21123071951917344]
	TIME [epoch: 6.55 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21721744872161858		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.21721744872161858 | validation: 0.17852051270221383]
	TIME [epoch: 6.55 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19521353321273177		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.19521353321273177 | validation: 0.17626139247035863]
	TIME [epoch: 6.49 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21279697808216277		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.21279697808216277 | validation: 0.185643059513017]
	TIME [epoch: 6.55 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22372978908004998		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.22372978908004998 | validation: 0.26801869200421213]
	TIME [epoch: 6.55 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20295339345224		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.20295339345224 | validation: 0.1930512487619648]
	TIME [epoch: 6.54 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19085411405798083		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.19085411405798083 | validation: 0.17830580890174885]
	TIME [epoch: 6.55 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19846083058550829		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.19846083058550829 | validation: 0.15176889297354165]
	TIME [epoch: 6.54 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1948516267689799		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.1948516267689799 | validation: 0.18470714878221273]
	TIME [epoch: 6.57 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19671440382204894		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.19671440382204894 | validation: 0.15695331521316824]
	TIME [epoch: 6.55 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18091242047106487		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.18091242047106487 | validation: 0.15681370508651116]
	TIME [epoch: 6.51 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21189321930022584		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.21189321930022584 | validation: 0.14685775563380132]
	TIME [epoch: 6.58 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19701348205997005		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.19701348205997005 | validation: 0.13285078815545043]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1043.pth
	Model improved!!!
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1833964067490914		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.1833964067490914 | validation: 0.16272716713051444]
	TIME [epoch: 6.55 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1839708446863978		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.1839708446863978 | validation: 0.1362939740077191]
	TIME [epoch: 6.56 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19909188734934966		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.19909188734934966 | validation: 0.23099766512660982]
	TIME [epoch: 6.55 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1931087006179022		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.1931087006179022 | validation: 0.14746565116158436]
	TIME [epoch: 6.55 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19861226394401404		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.19861226394401404 | validation: 0.15752574923364798]
	TIME [epoch: 6.56 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1918911121589762		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.1918911121589762 | validation: 0.170067210020358]
	TIME [epoch: 6.55 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18795428039105466		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.18795428039105466 | validation: 0.16476364285839076]
	TIME [epoch: 6.55 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2309232653943072		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.2309232653943072 | validation: 0.17778682196871853]
	TIME [epoch: 6.49 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19770722066575236		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.19770722066575236 | validation: 0.19233928741177703]
	TIME [epoch: 6.59 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2025437515891385		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.2025437515891385 | validation: 0.14617887413590225]
	TIME [epoch: 6.54 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1793483115783408		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.1793483115783408 | validation: 0.14113084532163991]
	TIME [epoch: 6.48 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18202956572581655		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.18202956572581655 | validation: 0.14992034778032307]
	TIME [epoch: 6.54 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17257044533527266		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.17257044533527266 | validation: 0.14692596600755561]
	TIME [epoch: 6.55 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19352160480887903		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.19352160480887903 | validation: 0.1392044861764864]
	TIME [epoch: 6.54 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1782806218588986		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.1782806218588986 | validation: 0.17659323420598166]
	TIME [epoch: 6.49 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24527196935209788		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.24527196935209788 | validation: 0.2351937843267382]
	TIME [epoch: 6.55 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20649079293159145		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.20649079293159145 | validation: 0.16726151163717007]
	TIME [epoch: 6.54 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19285910053367705		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.19285910053367705 | validation: 0.2120924294739334]
	TIME [epoch: 6.48 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1886797183029357		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.1886797183029357 | validation: 0.1720447240393137]
	TIME [epoch: 6.55 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1966240930455888		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.1966240930455888 | validation: 0.20558908245793744]
	TIME [epoch: 6.55 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20970087033389628		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.20970087033389628 | validation: 0.18510769104457148]
	TIME [epoch: 6.54 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1818445855656295		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.1818445855656295 | validation: 0.1435251947270261]
	TIME [epoch: 6.49 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18940313063375375		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.18940313063375375 | validation: 0.15352558117656154]
	TIME [epoch: 6.55 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18702896048105402		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.18702896048105402 | validation: 0.17297746618692592]
	TIME [epoch: 6.54 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19165001723480452		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.19165001723480452 | validation: 0.16138320086619395]
	TIME [epoch: 6.55 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1849779791749847		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.1849779791749847 | validation: 0.18156708313753023]
	TIME [epoch: 6.56 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18029513920617807		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.18029513920617807 | validation: 0.16546083355654784]
	TIME [epoch: 6.56 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1778429183500011		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.1778429183500011 | validation: 0.15678468211926266]
	TIME [epoch: 6.5 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18875245912487418		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.18875245912487418 | validation: 0.18421255831108369]
	TIME [epoch: 6.57 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18750061443652571		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.18750061443652571 | validation: 0.15202051978404785]
	TIME [epoch: 6.54 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19158309080011016		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.19158309080011016 | validation: 0.15624251656518326]
	TIME [epoch: 6.55 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18255958545651574		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.18255958545651574 | validation: 0.15862364556228062]
	TIME [epoch: 6.56 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17567667558265768		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.17567667558265768 | validation: 0.17261535300503306]
	TIME [epoch: 6.55 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18943671414335958		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.18943671414335958 | validation: 0.18660252814426564]
	TIME [epoch: 6.56 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18445691191766406		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.18445691191766406 | validation: 0.19096827028891994]
	TIME [epoch: 6.5 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1888622692997718		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.1888622692997718 | validation: 0.1589013773312172]
	TIME [epoch: 6.56 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1764769113458039		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.1764769113458039 | validation: 0.1446602363924506]
	TIME [epoch: 6.55 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18472477123868408		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.18472477123868408 | validation: 0.15693527119826942]
	TIME [epoch: 6.56 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19529340885805357		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.19529340885805357 | validation: 0.17937424528914647]
	TIME [epoch: 6.55 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18426589560329992		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.18426589560329992 | validation: 0.14749430473689507]
	TIME [epoch: 6.54 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1816074398896856		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.1816074398896856 | validation: 0.14667589111724857]
	TIME [epoch: 6.56 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1859126311505312		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.1859126311505312 | validation: 0.13994520616371273]
	TIME [epoch: 6.48 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18061769231995897		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.18061769231995897 | validation: 0.15888669271686504]
	TIME [epoch: 6.56 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17657551639497804		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.17657551639497804 | validation: 0.16758829505592196]
	TIME [epoch: 6.54 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1874052700072784		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.1874052700072784 | validation: 0.20241276247691317]
	TIME [epoch: 6.48 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18395363862994407		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.18395363862994407 | validation: 0.2225525740237505]
	TIME [epoch: 6.53 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18614275694271198		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.18614275694271198 | validation: 0.14229075602936497]
	TIME [epoch: 6.54 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1730453872084644		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.1730453872084644 | validation: 0.19710450528677026]
	TIME [epoch: 6.49 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17818545790601273		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.17818545790601273 | validation: 0.15620020360644632]
	TIME [epoch: 6.55 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1880649320208791		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.1880649320208791 | validation: 0.1811034816630883]
	TIME [epoch: 6.55 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23439872839729997		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.23439872839729997 | validation: 0.24978344619510506]
	TIME [epoch: 6.55 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1980545920695087		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.1980545920695087 | validation: 0.14549735200306704]
	TIME [epoch: 6.54 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1718120620610314		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.1718120620610314 | validation: 0.14274334395109542]
	TIME [epoch: 6.53 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17820499269610565		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.17820499269610565 | validation: 0.17868760628147878]
	TIME [epoch: 6.58 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18778865876924455		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.18778865876924455 | validation: 0.2042192269138775]
	TIME [epoch: 6.48 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18180068569316812		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.18180068569316812 | validation: 0.15376974914786304]
	TIME [epoch: 6.56 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17956986978890654		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.17956986978890654 | validation: 0.14096407625718432]
	TIME [epoch: 6.55 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1867331279291381		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.1867331279291381 | validation: 0.14561975757644446]
	TIME [epoch: 6.54 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17494696346906144		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.17494696346906144 | validation: 0.1513966993956974]
	TIME [epoch: 6.57 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17590729302623728		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.17590729302623728 | validation: 0.15473258012066507]
	TIME [epoch: 6.54 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18504610662102744		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.18504610662102744 | validation: 0.16896198807108967]
	TIME [epoch: 6.55 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19994889552652279		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.19994889552652279 | validation: 0.18860518361332199]
	TIME [epoch: 6.49 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18132515604373803		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.18132515604373803 | validation: 0.13713903268949995]
	TIME [epoch: 6.54 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17573238965547278		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.17573238965547278 | validation: 0.15136241797514646]
	TIME [epoch: 6.55 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17262888798248271		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.17262888798248271 | validation: 0.14071941297128296]
	TIME [epoch: 6.57 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20038013879668937		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.20038013879668937 | validation: 0.16574450846676722]
	TIME [epoch: 6.59 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1827462691370182		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.1827462691370182 | validation: 0.19346231439792355]
	TIME [epoch: 6.56 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18193539897782351		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.18193539897782351 | validation: 0.17354231379190566]
	TIME [epoch: 6.55 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18446063248356537		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.18446063248356537 | validation: 0.14237387724506817]
	TIME [epoch: 6.5 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19402561853996678		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.19402561853996678 | validation: 0.18193105029983844]
	TIME [epoch: 6.54 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18063056310873726		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.18063056310873726 | validation: 0.18620937766725262]
	TIME [epoch: 6.56 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18571859825254095		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.18571859825254095 | validation: 0.15075534568878732]
	TIME [epoch: 6.55 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2020767832116916		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.2020767832116916 | validation: 0.1520826557096073]
	TIME [epoch: 6.55 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18626032266708295		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.18626032266708295 | validation: 0.19213234488717917]
	TIME [epoch: 6.53 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17132581482566792		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.17132581482566792 | validation: 0.12371727542868703]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1118.pth
	Model improved!!!
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.187858206692875		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.187858206692875 | validation: 0.13090732677367276]
	TIME [epoch: 6.55 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1760143764372112		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.1760143764372112 | validation: 0.1495801181951525]
	TIME [epoch: 6.54 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1848520648929567		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.1848520648929567 | validation: 0.20829722258046313]
	TIME [epoch: 6.6 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20247166997831664		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.20247166997831664 | validation: 0.15772637300994358]
	TIME [epoch: 6.56 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17391106969944592		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.17391106969944592 | validation: 0.14359155241408947]
	TIME [epoch: 6.55 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17220044262858902		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.17220044262858902 | validation: 0.1623266193579798]
	TIME [epoch: 6.56 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18014632721469587		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.18014632721469587 | validation: 0.18755879296015684]
	TIME [epoch: 6.55 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20567322877300032		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.20567322877300032 | validation: 0.17073094063995478]
	TIME [epoch: 6.56 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1956226911591662		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.1956226911591662 | validation: 0.1956675361415752]
	TIME [epoch: 6.54 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1899529075790149		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.1899529075790149 | validation: 0.14133184252916434]
	TIME [epoch: 6.55 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18236688084904557		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.18236688084904557 | validation: 0.16903371416282256]
	TIME [epoch: 6.55 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18090389262696688		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.18090389262696688 | validation: 0.1309746140713414]
	TIME [epoch: 6.49 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18151153851552498		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.18151153851552498 | validation: 0.17087827930362992]
	TIME [epoch: 6.55 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20714632283236215		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.20714632283236215 | validation: 0.17080671762882035]
	TIME [epoch: 6.56 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19115622629416498		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.19115622629416498 | validation: 0.16027960920387074]
	TIME [epoch: 6.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17113363946962723		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.17113363946962723 | validation: 0.13063034528260165]
	TIME [epoch: 6.55 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17914458244124118		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.17914458244124118 | validation: 0.14500214275208642]
	TIME [epoch: 6.55 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17288196682219273		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.17288196682219273 | validation: 0.15666532442230932]
	TIME [epoch: 6.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1726910103279415		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.1726910103279415 | validation: 0.13174463150871957]
	TIME [epoch: 6.54 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1906262479433204		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.1906262479433204 | validation: 0.13380022414570053]
	TIME [epoch: 6.55 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1724414839066475		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.1724414839066475 | validation: 0.1405314133236649]
	TIME [epoch: 6.5 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1816582799427361		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.1816582799427361 | validation: 0.13233559174935564]
	TIME [epoch: 6.56 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18229305813462315		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.18229305813462315 | validation: 0.14679283651232072]
	TIME [epoch: 6.56 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18752128298476278		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.18752128298476278 | validation: 0.14550911962232627]
	TIME [epoch: 6.56 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17030599802269897		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.17030599802269897 | validation: 0.12902769337774]
	TIME [epoch: 6.54 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18456417509604836		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.18456417509604836 | validation: 0.1413841094974244]
	TIME [epoch: 6.51 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1894685928603302		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.1894685928603302 | validation: 0.17496836977973598]
	TIME [epoch: 6.55 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20292533581842287		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.20292533581842287 | validation: 0.14135732783707827]
	TIME [epoch: 6.53 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1712737287882728		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.1712737287882728 | validation: 0.14137435387648634]
	TIME [epoch: 6.55 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18393338865903244		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.18393338865903244 | validation: 0.1514599838541797]
	TIME [epoch: 6.56 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796298357395543		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.1796298357395543 | validation: 0.16346182919402577]
	TIME [epoch: 6.57 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18640024255449805		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.18640024255449805 | validation: 0.1431802752721978]
	TIME [epoch: 6.49 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19198318777434226		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.19198318777434226 | validation: 0.18942683135469815]
	TIME [epoch: 6.57 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18250202051823594		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.18250202051823594 | validation: 0.13177976192552804]
	TIME [epoch: 6.56 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17461472651798654		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.17461472651798654 | validation: 0.15203859210082002]
	TIME [epoch: 6.47 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16821818007334943		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.16821818007334943 | validation: 0.12594225659497668]
	TIME [epoch: 6.54 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1801725878393765		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.1801725878393765 | validation: 0.13241497511833442]
	TIME [epoch: 6.48 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16858403322823762		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.16858403322823762 | validation: 0.1572457723801029]
	TIME [epoch: 6.58 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18038312025152659		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.18038312025152659 | validation: 0.13571058405345846]
	TIME [epoch: 6.55 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18019149280743701		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.18019149280743701 | validation: 0.1667052384009897]
	TIME [epoch: 6.55 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18525148896761345		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.18525148896761345 | validation: 0.14966466869603473]
	TIME [epoch: 6.56 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1764435143704946		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.1764435143704946 | validation: 0.14387540763650233]
	TIME [epoch: 6.55 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1943658782764912		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.1943658782764912 | validation: 0.18956830821403156]
	TIME [epoch: 6.56 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20651429240657554		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.20651429240657554 | validation: 0.15433865648223294]
	TIME [epoch: 6.54 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1713152213704496		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.1713152213704496 | validation: 0.15639237347451318]
	TIME [epoch: 6.55 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17440056207195026		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.17440056207195026 | validation: 0.16457980587982107]
	TIME [epoch: 6.54 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1995627730191742		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.1995627730191742 | validation: 0.2067400991449822]
	TIME [epoch: 6.55 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21486957089428846		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.21486957089428846 | validation: 0.18057468375180677]
	TIME [epoch: 6.55 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18663718656474493		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.18663718656474493 | validation: 0.15792117083441645]
	TIME [epoch: 6.58 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18000480972600041		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.18000480972600041 | validation: 0.12492153697996801]
	TIME [epoch: 6.56 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18611744355655835		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.18611744355655835 | validation: 0.13960197345878247]
	TIME [epoch: 6.54 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19632943661903512		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.19632943661903512 | validation: 0.13845192369501974]
	TIME [epoch: 6.55 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19988528347025503		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.19988528347025503 | validation: 0.16157797704180726]
	TIME [epoch: 6.54 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1988151379026676		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.1988151379026676 | validation: 0.1530714464909979]
	TIME [epoch: 6.49 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16677820386863706		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.16677820386863706 | validation: 0.1488955774771205]
	TIME [epoch: 6.55 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1728349332799633		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.1728349332799633 | validation: 0.17341630162893729]
	TIME [epoch: 6.57 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1734674831896285		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.1734674831896285 | validation: 0.14238520924550085]
	TIME [epoch: 6.58 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16696820249428004		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.16696820249428004 | validation: 0.13722836493980714]
	TIME [epoch: 6.56 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17636218858435876		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.17636218858435876 | validation: 0.13374063994240662]
	TIME [epoch: 6.56 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17131231985961398		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.17131231985961398 | validation: 0.14236640718388646]
	TIME [epoch: 6.55 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16631491329103087		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.16631491329103087 | validation: 0.14535253387857844]
	TIME [epoch: 6.57 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17834094004022438		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.17834094004022438 | validation: 0.13853968184398072]
	TIME [epoch: 6.54 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16774351805139184		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.16774351805139184 | validation: 0.13618278653508353]
	TIME [epoch: 6.51 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16448071648997425		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.16448071648997425 | validation: 0.13947806519469633]
	TIME [epoch: 6.54 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1761951744602923		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.1761951744602923 | validation: 0.15340959991383668]
	TIME [epoch: 6.56 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16846205588733817		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.16846205588733817 | validation: 0.15073267722063313]
	TIME [epoch: 6.56 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1734530950506336		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.1734530950506336 | validation: 0.14317819994291614]
	TIME [epoch: 6.55 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17510771975003658		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.17510771975003658 | validation: 0.13328512696983222]
	TIME [epoch: 6.58 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16399109899021294		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.16399109899021294 | validation: 0.15241869311983805]
	TIME [epoch: 6.55 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17195272450408997		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.17195272450408997 | validation: 0.17144122196441905]
	TIME [epoch: 6.54 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19062272112864503		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.19062272112864503 | validation: 0.28046557321140764]
	TIME [epoch: 6.53 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21498301617682702		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.21498301617682702 | validation: 0.15281547840160717]
	TIME [epoch: 6.58 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17529459467931172		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.17529459467931172 | validation: 0.12693549828590145]
	TIME [epoch: 6.56 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16879491271509922		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.16879491271509922 | validation: 0.16725133138839782]
	TIME [epoch: 6.56 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18087133199651176		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.18087133199651176 | validation: 0.16765315785165055]
	TIME [epoch: 6.56 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17601015047518212		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.17601015047518212 | validation: 0.15827063553480877]
	TIME [epoch: 6.56 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1758080995800907		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.1758080995800907 | validation: 0.17225425143119907]
	TIME [epoch: 6.48 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17982939682422355		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.17982939682422355 | validation: 0.14504605780444904]
	TIME [epoch: 6.55 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18392645771094618		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.18392645771094618 | validation: 0.15079580412657945]
	TIME [epoch: 6.54 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17073307576335978		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.17073307576335978 | validation: 0.1581998547352033]
	TIME [epoch: 6.55 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17236601517305153		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.17236601517305153 | validation: 0.13991390653901023]
	TIME [epoch: 6.54 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17078076517869684		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.17078076517869684 | validation: 0.13355818611998055]
	TIME [epoch: 6.57 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19411594909445062		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.19411594909445062 | validation: 0.1844718140352731]
	TIME [epoch: 6.49 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20666754707317503		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.20666754707317503 | validation: 0.17710102270583092]
	TIME [epoch: 6.56 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17862639772466252		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.17862639772466252 | validation: 0.168592028177542]
	TIME [epoch: 6.56 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18034021478225293		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.18034021478225293 | validation: 0.13636707736053436]
	TIME [epoch: 6.55 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16865102575976337		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.16865102575976337 | validation: 0.1440739360006902]
	TIME [epoch: 6.56 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1673485966772529		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.1673485966772529 | validation: 0.15677137510095726]
	TIME [epoch: 6.56 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16671057185139393		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.16671057185139393 | validation: 0.2005557831603109]
	TIME [epoch: 6.57 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690150475356442		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.1690150475356442 | validation: 0.13060018539263962]
	TIME [epoch: 6.55 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18649982678152724		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.18649982678152724 | validation: 0.13156778589674356]
	TIME [epoch: 6.48 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18259947564953402		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.18259947564953402 | validation: 0.13956507327831832]
	TIME [epoch: 6.55 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16961585248204963		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.16961585248204963 | validation: 0.14963599614733414]
	TIME [epoch: 6.54 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18245307534606592		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.18245307534606592 | validation: 0.17864648522329468]
	TIME [epoch: 6.55 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21086874568713365		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.21086874568713365 | validation: 0.1457525914024836]
	TIME [epoch: 6.54 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1657210726009237		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.1657210726009237 | validation: 0.14231614547141713]
	TIME [epoch: 6.55 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17612055021806536		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.17612055021806536 | validation: 0.14137434641805047]
	TIME [epoch: 6.54 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17915009387149472		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.17915009387149472 | validation: 0.17809301497586666]
	TIME [epoch: 6.51 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18292360927505127		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.18292360927505127 | validation: 0.14291823183601127]
	TIME [epoch: 6.54 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1748943083992635		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.1748943083992635 | validation: 0.14274079355716038]
	TIME [epoch: 6.56 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17798330067437007		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.17798330067437007 | validation: 0.13103916584820682]
	TIME [epoch: 6.54 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16899433141969813		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.16899433141969813 | validation: 0.14052829726184643]
	TIME [epoch: 6.54 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17024861093922894		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.17024861093922894 | validation: 0.1487858083888525]
	TIME [epoch: 6.55 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18096938664522658		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.18096938664522658 | validation: 0.1750957962101176]
	TIME [epoch: 6.54 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17221891853438104		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.17221891853438104 | validation: 0.17092947705405087]
	TIME [epoch: 6.54 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17380586606522053		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.17380586606522053 | validation: 0.12267438309985984]
	TIME [epoch: 6.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1224.pth
	Model improved!!!
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17349929938755057		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.17349929938755057 | validation: 0.13244782831720134]
	TIME [epoch: 6.57 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18377655220492364		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.18377655220492364 | validation: 0.14111596432999515]
	TIME [epoch: 6.55 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17236983369329686		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.17236983369329686 | validation: 0.12139374312808728]
	TIME [epoch: 6.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1227.pth
	Model improved!!!
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1739707864610726		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.1739707864610726 | validation: 0.1374593703134958]
	TIME [epoch: 6.54 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17761596737630775		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.17761596737630775 | validation: 0.1338195166408754]
	TIME [epoch: 6.56 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19178781753451452		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.19178781753451452 | validation: 0.18384426571426285]
	TIME [epoch: 6.55 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18707828426798168		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.18707828426798168 | validation: 0.22965346663524222]
	TIME [epoch: 6.48 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19052187996741116		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.19052187996741116 | validation: 0.1472575497982937]
	TIME [epoch: 6.54 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16460362206802925		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.16460362206802925 | validation: 0.15140188541194088]
	TIME [epoch: 6.55 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1690135815962288		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.1690135815962288 | validation: 0.17034372384581192]
	TIME [epoch: 6.54 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17068658309725787		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.17068658309725787 | validation: 0.12758908301568647]
	TIME [epoch: 6.55 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16446782569475732		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.16446782569475732 | validation: 0.12263455802940432]
	TIME [epoch: 6.56 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17085603069390212		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.17085603069390212 | validation: 0.13687147612155523]
	TIME [epoch: 6.54 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1883949352343543		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.1883949352343543 | validation: 0.16573360123515346]
	TIME [epoch: 6.56 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18232509929302346		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.18232509929302346 | validation: 0.13642628997227327]
	TIME [epoch: 6.56 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16518646857523112		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.16518646857523112 | validation: 0.15170329752479816]
	TIME [epoch: 6.58 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1682032839598615		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.1682032839598615 | validation: 0.1481486463517028]
	TIME [epoch: 6.56 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.167951696033375		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.167951696033375 | validation: 0.15092813887293896]
	TIME [epoch: 6.55 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17015796109793913		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.17015796109793913 | validation: 0.17346006597329922]
	TIME [epoch: 6.6 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1940244605593513		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.1940244605593513 | validation: 0.1774313230379627]
	TIME [epoch: 6.55 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17681503703349408		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.17681503703349408 | validation: 0.12908050513428487]
	TIME [epoch: 6.55 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16528145313061984		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.16528145313061984 | validation: 0.15534514216609946]
	TIME [epoch: 6.56 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17067935490559916		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.17067935490559916 | validation: 0.1589212936575031]
	TIME [epoch: 6.55 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16768984519970828		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.16768984519970828 | validation: 0.1471255646442282]
	TIME [epoch: 6.54 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16967821306791975		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.16967821306791975 | validation: 0.1633646312817905]
	TIME [epoch: 6.56 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17900749558613976		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.17900749558613976 | validation: 0.17395529212828625]
	TIME [epoch: 6.56 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19904567913344912		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.19904567913344912 | validation: 0.16577095154754481]
	TIME [epoch: 6.49 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17086110912534952		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.17086110912534952 | validation: 0.13256403854637475]
	TIME [epoch: 6.56 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1636700131584859		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.1636700131584859 | validation: 0.13620035520153936]
	TIME [epoch: 6.55 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632999066225635		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.1632999066225635 | validation: 0.1861012151286341]
	TIME [epoch: 6.49 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17294082605806257		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.17294082605806257 | validation: 0.14054453010440895]
	TIME [epoch: 6.56 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18347461318800423		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.18347461318800423 | validation: 0.13336269475891835]
	TIME [epoch: 6.57 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16696773394220285		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.16696773394220285 | validation: 0.12946475187831827]
	TIME [epoch: 6.57 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16892982804182988		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.16892982804182988 | validation: 0.1366099262379823]
	TIME [epoch: 6.56 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17370042958074974		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.17370042958074974 | validation: 0.1383869622962089]
	TIME [epoch: 6.56 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16726623220088926		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.16726623220088926 | validation: 0.13338877286813502]
	TIME [epoch: 6.56 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16736177679668993		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.16736177679668993 | validation: 0.12968787434061002]
	TIME [epoch: 6.58 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.167283308290875		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.167283308290875 | validation: 0.12969206290476268]
	TIME [epoch: 6.48 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.165003309141675		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.165003309141675 | validation: 0.14599202409736386]
	TIME [epoch: 6.56 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16340225764418037		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.16340225764418037 | validation: 0.12843912644447322]
	TIME [epoch: 6.55 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17338774822060338		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.17338774822060338 | validation: 0.1313551742125085]
	TIME [epoch: 6.55 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16840603579165536		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.16840603579165536 | validation: 0.13596061566979473]
	TIME [epoch: 6.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16715275917899758		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.16715275917899758 | validation: 0.1250354624589182]
	TIME [epoch: 6.59 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16974705384650254		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.16974705384650254 | validation: 0.13042322684297875]
	TIME [epoch: 6.56 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17533875809165622		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.17533875809165622 | validation: 0.12410590984818014]
	TIME [epoch: 6.56 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654326874914715		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.1654326874914715 | validation: 0.14721246374387806]
	TIME [epoch: 6.49 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1682013461153374		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.1682013461153374 | validation: 0.12316551803482007]
	TIME [epoch: 6.56 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17090088997615302		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.17090088997615302 | validation: 0.1466786995017485]
	TIME [epoch: 6.56 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16787311844160546		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.16787311844160546 | validation: 0.1221170244322311]
	TIME [epoch: 6.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16554319850806357		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.16554319850806357 | validation: 0.17772956157735217]
	TIME [epoch: 6.56 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17403317097581775		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.17403317097581775 | validation: 0.15305542619238183]
	TIME [epoch: 6.57 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17043098066023069		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.17043098066023069 | validation: 0.14574841650382742]
	TIME [epoch: 6.55 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1735576128492002		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.1735576128492002 | validation: 0.1522309796429726]
	TIME [epoch: 6.56 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1753682085610112		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.1753682085610112 | validation: 0.1504296086674109]
	TIME [epoch: 6.56 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17115747381720778		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.17115747381720778 | validation: 0.15194701467332195]
	TIME [epoch: 6.55 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16935945937925104		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.16935945937925104 | validation: 0.16162385502989488]
	TIME [epoch: 6.55 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.162088972500171		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.162088972500171 | validation: 0.15380313037290477]
	TIME [epoch: 6.57 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16621645299386534		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.16621645299386534 | validation: 0.13358762629612567]
	TIME [epoch: 6.57 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1780393837624893		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.1780393837624893 | validation: 0.13342763317274348]
	TIME [epoch: 6.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1666045701689334		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.1666045701689334 | validation: 0.13751233749189598]
	TIME [epoch: 6.54 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16679587454137462		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.16679587454137462 | validation: 0.12089135790239165]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1285.pth
	Model improved!!!
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16956343800480123		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.16956343800480123 | validation: 0.13090732883628803]
	TIME [epoch: 6.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16701180266204038		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.16701180266204038 | validation: 0.1316434691200589]
	TIME [epoch: 6.55 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17182421615256055		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.17182421615256055 | validation: 0.1430686252469551]
	TIME [epoch: 6.54 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17434506090757756		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.17434506090757756 | validation: 0.1538036326641546]
	TIME [epoch: 6.54 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17097989978015796		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.17097989978015796 | validation: 0.14202006289883037]
	TIME [epoch: 6.52 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16744252636629495		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.16744252636629495 | validation: 0.13018736679338708]
	TIME [epoch: 6.55 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17137478185116367		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.17137478185116367 | validation: 0.13150547681602373]
	TIME [epoch: 6.56 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17871532929484035		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.17871532929484035 | validation: 0.12944423811538597]
	TIME [epoch: 6.57 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19019183161984074		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.19019183161984074 | validation: 0.12810954375429706]
	TIME [epoch: 6.55 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1653480501023882		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.1653480501023882 | validation: 0.15731262138202698]
	TIME [epoch: 6.53 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17620239209540037		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.17620239209540037 | validation: 0.1772382294186125]
	TIME [epoch: 6.56 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.172008660156267		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.172008660156267 | validation: 0.12083822803660367]
	TIME [epoch: 6.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1297.pth
	Model improved!!!
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16532111206930886		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.16532111206930886 | validation: 0.13358774055435324]
	TIME [epoch: 6.59 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16569473799595544		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.16569473799595544 | validation: 0.13378169669200826]
	TIME [epoch: 6.55 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16226450624691824		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.16226450624691824 | validation: 0.14249114411351793]
	TIME [epoch: 6.51 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15684609183477594		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.15684609183477594 | validation: 0.1443507881728821]
	TIME [epoch: 6.54 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15971592531721368		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.15971592531721368 | validation: 0.15616663054241364]
	TIME [epoch: 6.56 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16953415955395854		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.16953415955395854 | validation: 0.13823613706107946]
	TIME [epoch: 6.57 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19361282345485797		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.19361282345485797 | validation: 0.15039339000275273]
	TIME [epoch: 6.55 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20912124082671074		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.20912124082671074 | validation: 0.13226651235143697]
	TIME [epoch: 6.55 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17579217494045807		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.17579217494045807 | validation: 0.14409742733172945]
	TIME [epoch: 6.56 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16733380608393947		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.16733380608393947 | validation: 0.17880704072086326]
	TIME [epoch: 6.57 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18065371545542683		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.18065371545542683 | validation: 0.18953479952904084]
	TIME [epoch: 6.61 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17668842195924062		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.17668842195924062 | validation: 0.13042735591656981]
	TIME [epoch: 6.57 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17165026515005113		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.17165026515005113 | validation: 0.145845055111693]
	TIME [epoch: 6.57 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16275424468375607		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.16275424468375607 | validation: 0.13657558623842825]
	TIME [epoch: 6.56 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16290428383506494		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.16290428383506494 | validation: 0.12622468340908882]
	TIME [epoch: 6.57 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16241112187592555		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.16241112187592555 | validation: 0.13357225606616777]
	TIME [epoch: 6.6 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16923371785854163		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.16923371785854163 | validation: 0.13506257619131704]
	TIME [epoch: 6.6 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16178033574219236		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.16178033574219236 | validation: 0.1568406034220263]
	TIME [epoch: 6.51 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16159439177744428		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.16159439177744428 | validation: 0.12713124226680958]
	TIME [epoch: 6.57 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16240575082198083		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.16240575082198083 | validation: 0.1118459260815504]
	TIME [epoch: 6.57 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1317.pth
	Model improved!!!
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16157741203935272		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.16157741203935272 | validation: 0.1366816974983904]
	TIME [epoch: 6.55 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1626803545606766		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.1626803545606766 | validation: 0.12696359499078777]
	TIME [epoch: 6.56 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15893092457963867		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.15893092457963867 | validation: 0.12910670338987446]
	TIME [epoch: 6.56 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16516788074968342		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.16516788074968342 | validation: 0.14147230898122748]
	TIME [epoch: 6.5 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17111411624536688		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.17111411624536688 | validation: 0.1635442526566255]
	TIME [epoch: 6.56 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16948266739612672		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.16948266739612672 | validation: 0.16417500427012588]
	TIME [epoch: 6.56 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17252741926073412		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.17252741926073412 | validation: 0.14682733070621146]
	TIME [epoch: 6.56 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16951831675274986		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.16951831675274986 | validation: 0.15055099409893408]
	TIME [epoch: 6.55 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16383690604458248		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.16383690604458248 | validation: 0.1561069790264187]
	TIME [epoch: 6.55 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1671973974197804		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.1671973974197804 | validation: 0.12440632011597841]
	TIME [epoch: 6.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16980941567436106		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.16980941567436106 | validation: 0.1489777900607202]
	TIME [epoch: 6.55 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16214105354897812		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.16214105354897812 | validation: 0.12631653646575164]
	TIME [epoch: 6.56 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16313275804172722		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.16313275804172722 | validation: 0.12394358583556109]
	TIME [epoch: 6.56 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.164613961307013		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.164613961307013 | validation: 0.14312173045543805]
	TIME [epoch: 6.56 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1628354530122705		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.1628354530122705 | validation: 0.14005610181168748]
	TIME [epoch: 6.56 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612183045670658		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.1612183045670658 | validation: 0.1254761675340291]
	TIME [epoch: 6.5 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16102804324425452		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.16102804324425452 | validation: 0.1364612054950771]
	TIME [epoch: 6.57 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16675821550941275		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.16675821550941275 | validation: 0.16125132640602505]
	TIME [epoch: 6.55 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16564223871024897		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.16564223871024897 | validation: 0.1342629303912807]
	TIME [epoch: 6.55 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16256791207633373		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.16256791207633373 | validation: 0.1174058205985389]
	TIME [epoch: 6.52 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16686321821230898		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.16686321821230898 | validation: 0.11734782154534681]
	TIME [epoch: 6.54 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1595385943891703		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.1595385943891703 | validation: 0.13997893537356307]
	TIME [epoch: 6.56 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1595919756083104		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.1595919756083104 | validation: 0.12837174951462743]
	TIME [epoch: 6.57 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16960706904159215		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.16960706904159215 | validation: 0.13693772229230594]
	TIME [epoch: 6.55 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16240817098370322		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.16240817098370322 | validation: 0.14628410082559654]
	TIME [epoch: 6.6 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16572775738477571		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.16572775738477571 | validation: 0.14746366544617015]
	TIME [epoch: 6.56 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17042471061695358		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.17042471061695358 | validation: 0.14847101535411372]
	TIME [epoch: 6.55 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16840086129995005		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.16840086129995005 | validation: 0.15099885980743788]
	TIME [epoch: 6.56 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1652951028723043		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.1652951028723043 | validation: 0.13148118836060144]
	TIME [epoch: 6.55 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16139597286656454		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.16139597286656454 | validation: 0.13189375588112665]
	TIME [epoch: 6.55 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16499814173349436		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.16499814173349436 | validation: 0.15536958137340717]
	TIME [epoch: 6.55 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1818915759243196		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.1818915759243196 | validation: 0.21134285503728648]
	TIME [epoch: 6.56 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19166097972983287		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.19166097972983287 | validation: 0.18900138543789755]
	TIME [epoch: 6.56 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17060231764879452		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.17060231764879452 | validation: 0.13551511968019928]
	TIME [epoch: 6.53 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16150508089289278		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.16150508089289278 | validation: 0.12954879599473917]
	TIME [epoch: 6.55 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1670920520967869		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.1670920520967869 | validation: 0.13960972606559405]
	TIME [epoch: 6.56 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17146074068552816		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.17146074068552816 | validation: 0.13832790004129167]
	TIME [epoch: 6.54 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16081891353630917		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.16081891353630917 | validation: 0.13580093258661016]
	TIME [epoch: 6.59 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15862121568703869		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.15862121568703869 | validation: 0.13231239193729633]
	TIME [epoch: 6.56 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16046112853715683		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.16046112853715683 | validation: 0.1359396150845254]
	TIME [epoch: 6.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1691627705758468		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.1691627705758468 | validation: 0.18931996728299225]
	TIME [epoch: 6.56 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18968304469530578		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.18968304469530578 | validation: 0.20645026461878463]
	TIME [epoch: 6.56 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17852565812350346		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.17852565812350346 | validation: 0.14274931027286325]
	TIME [epoch: 6.55 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15736881660461566		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.15736881660461566 | validation: 0.1320290649387985]
	TIME [epoch: 6.55 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15701929173038093		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.15701929173038093 | validation: 0.13544509343140806]
	TIME [epoch: 6.51 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16792009313190914		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.16792009313190914 | validation: 0.1552325765126063]
	TIME [epoch: 6.55 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1645967043808076		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.1645967043808076 | validation: 0.15194794484677257]
	TIME [epoch: 6.54 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17484903937619964		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.17484903937619964 | validation: 0.17898116798264913]
	TIME [epoch: 6.59 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17949253224459913		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.17949253224459913 | validation: 0.15432478858821444]
	TIME [epoch: 6.56 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1714180503435656		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.1714180503435656 | validation: 0.17042802767894266]
	TIME [epoch: 6.5 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1731558318338101		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.1731558318338101 | validation: 0.13590406929205215]
	TIME [epoch: 6.55 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1701050209685478		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.1701050209685478 | validation: 0.12602561507207521]
	TIME [epoch: 6.56 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16414729020956179		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.16414729020956179 | validation: 0.12688014505092673]
	TIME [epoch: 6.53 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15798047927534584		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.15798047927534584 | validation: 0.13065133092140033]
	TIME [epoch: 6.57 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1640372747382422		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.1640372747382422 | validation: 0.14778228145386169]
	TIME [epoch: 6.5 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16993909614888755		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.16993909614888755 | validation: 0.14621942148352285]
	TIME [epoch: 6.56 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15721227543150768		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.15721227543150768 | validation: 0.12265543679023097]
	TIME [epoch: 6.55 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555132690842464		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.1555132690842464 | validation: 0.13366928308316944]
	TIME [epoch: 6.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17403992488565104		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.17403992488565104 | validation: 0.14462590770008718]
	TIME [epoch: 6.56 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18226300959450287		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.18226300959450287 | validation: 0.14142564261934018]
	TIME [epoch: 6.54 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16472026610611487		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.16472026610611487 | validation: 0.12796703468529852]
	TIME [epoch: 6.55 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.161575659567559		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.161575659567559 | validation: 0.13367565030240258]
	TIME [epoch: 6.56 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1625737768460393		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.1625737768460393 | validation: 0.13592559060082057]
	TIME [epoch: 6.55 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1601359708966877		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.1601359708966877 | validation: 0.1265481755002898]
	TIME [epoch: 6.55 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16237090575953148		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.16237090575953148 | validation: 0.1487795955399289]
	TIME [epoch: 6.51 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1599520439215188		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.1599520439215188 | validation: 0.12433831333008355]
	TIME [epoch: 6.56 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16070724934321717		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.16070724934321717 | validation: 0.13754968289663005]
	TIME [epoch: 6.56 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16442769928613513		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.16442769928613513 | validation: 0.13026491755329528]
	TIME [epoch: 6.55 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15603750798763943		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.15603750798763943 | validation: 0.1585103290964146]
	TIME [epoch: 6.56 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17260059338843467		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.17260059338843467 | validation: 0.14097801647398092]
	TIME [epoch: 6.58 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16992679921492765		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.16992679921492765 | validation: 0.12391021422520694]
	TIME [epoch: 6.58 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16241151889788177		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.16241151889788177 | validation: 0.12661140695179687]
	TIME [epoch: 6.5 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15956023420191934		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.15956023420191934 | validation: 0.14002631177883906]
	TIME [epoch: 6.55 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15867474417888822		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.15867474417888822 | validation: 0.12094126286982661]
	TIME [epoch: 6.55 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1650827952540275		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.1650827952540275 | validation: 0.1172513085824967]
	TIME [epoch: 6.55 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1628160895848587		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.1628160895848587 | validation: 0.14109996140800274]
	TIME [epoch: 6.56 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16153415595549245		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.16153415595549245 | validation: 0.13694424649083212]
	TIME [epoch: 6.56 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15825168768416814		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.15825168768416814 | validation: 0.12865182110580645]
	TIME [epoch: 6.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1618189143506491		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.1618189143506491 | validation: 0.1322496228453515]
	TIME [epoch: 6.55 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15489852994511735		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.15489852994511735 | validation: 0.12002409234886936]
	TIME [epoch: 6.56 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15677648605169925		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.15677648605169925 | validation: 0.13612078679915046]
	TIME [epoch: 6.5 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16148167276877254		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.16148167276877254 | validation: 0.14104736979602955]
	TIME [epoch: 6.56 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16490205237535094		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.16490205237535094 | validation: 0.12150865380704846]
	TIME [epoch: 6.55 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1627709855303155		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.1627709855303155 | validation: 0.16176007870484582]
	TIME [epoch: 6.51 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17538919270628445		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.17538919270628445 | validation: 0.13767652668607971]
	TIME [epoch: 6.59 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15827786129129318		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.15827786129129318 | validation: 0.1260410263740458]
	TIME [epoch: 6.56 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16234447517361733		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.16234447517361733 | validation: 0.1252585428746854]
	TIME [epoch: 6.5 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15387784728571308		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.15387784728571308 | validation: 0.1333391304870555]
	TIME [epoch: 6.56 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15726664044755034		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.15726664044755034 | validation: 0.14799662512149167]
	TIME [epoch: 6.55 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.163647770006276		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.163647770006276 | validation: 0.13113251030702258]
	TIME [epoch: 6.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1622575139285759		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.1622575139285759 | validation: 0.13521027660146728]
	TIME [epoch: 6.56 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15330582612201182		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.15330582612201182 | validation: 0.14322246501769423]
	TIME [epoch: 6.55 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1574901639953082		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.1574901639953082 | validation: 0.14050962515760923]
	TIME [epoch: 6.54 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16204116299401075		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.16204116299401075 | validation: 0.15330146186072946]
	TIME [epoch: 6.5 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1660676766632474		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.1660676766632474 | validation: 0.1659221126719252]
	TIME [epoch: 6.56 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1724362307994426		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.1724362307994426 | validation: 0.1451958045180034]
	TIME [epoch: 6.56 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632726636851979		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.1632726636851979 | validation: 0.1174715274097052]
	TIME [epoch: 6.55 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15923375716572774		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.15923375716572774 | validation: 0.12784319249232975]
	TIME [epoch: 6.59 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16281536099967817		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.16281536099967817 | validation: 0.1258632488078222]
	TIME [epoch: 6.55 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16540588358132643		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.16540588358132643 | validation: 0.14348779768349343]
	TIME [epoch: 6.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16159672247281517		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.16159672247281517 | validation: 0.150623593671069]
	TIME [epoch: 6.56 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1715306595029502		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.1715306595029502 | validation: 0.15042846031880405]
	TIME [epoch: 6.56 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16035737226055607		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.16035737226055607 | validation: 0.12669259302114305]
	TIME [epoch: 6.56 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15868166336955256		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.15868166336955256 | validation: 0.12926458248635492]
	TIME [epoch: 6.5 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593699039321053		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.1593699039321053 | validation: 0.12088943125699668]
	TIME [epoch: 6.55 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16815474856090096		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.16815474856090096 | validation: 0.1372711983370996]
	TIME [epoch: 6.54 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17904365233505593		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.17904365233505593 | validation: 0.12721809647048132]
	TIME [epoch: 6.58 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15873550137541598		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.15873550137541598 | validation: 0.12535289830975163]
	TIME [epoch: 6.56 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15632419907677478		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.15632419907677478 | validation: 0.1338610491067145]
	TIME [epoch: 6.52 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15900265009413317		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.15900265009413317 | validation: 0.11584073808309554]
	TIME [epoch: 6.54 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15930495092971272		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.15930495092971272 | validation: 0.13398380874697022]
	TIME [epoch: 6.56 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16128746594062082		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.16128746594062082 | validation: 0.12673270502708905]
	TIME [epoch: 6.58 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15925494029982246		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.15925494029982246 | validation: 0.12693393584541235]
	TIME [epoch: 6.58 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15753171930900062		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.15753171930900062 | validation: 0.1302332163897481]
	TIME [epoch: 6.5 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15575462612824126		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.15575462612824126 | validation: 0.1240687926279486]
	TIME [epoch: 6.57 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15377331272083924		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.15377331272083924 | validation: 0.1272771121944544]
	TIME [epoch: 6.57 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15957176687225902		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.15957176687225902 | validation: 0.11604091557376617]
	TIME [epoch: 6.56 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16069938671809555		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.16069938671809555 | validation: 0.14640970678034942]
	TIME [epoch: 6.51 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16289957129238972		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.16289957129238972 | validation: 0.16000988157558882]
	TIME [epoch: 6.56 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16567868836774544		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.16567868836774544 | validation: 0.1433430539101256]
	TIME [epoch: 6.56 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16417108261488822		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.16417108261488822 | validation: 0.13320404155760943]
	TIME [epoch: 6.51 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16116764809787643		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.16116764809787643 | validation: 0.13970027905246657]
	TIME [epoch: 6.56 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1666558870864891		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.1666558870864891 | validation: 0.11470250191593617]
	TIME [epoch: 6.58 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16659978658963032		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.16659978658963032 | validation: 0.11622727717156714]
	TIME [epoch: 6.6 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15695426606347623		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.15695426606347623 | validation: 0.12681206517992188]
	TIME [epoch: 6.55 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15909425434667238		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.15909425434667238 | validation: 0.13141531265603537]
	TIME [epoch: 6.56 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.160516282680985		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.160516282680985 | validation: 0.12347386247418995]
	TIME [epoch: 6.58 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16102169566393398		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.16102169566393398 | validation: 0.14673151710459548]
	TIME [epoch: 6.58 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16155916510394858		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.16155916510394858 | validation: 0.13872182881779607]
	TIME [epoch: 6.57 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1611043280204122		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.1611043280204122 | validation: 0.1481525625641417]
	TIME [epoch: 6.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16172596564608677		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.16172596564608677 | validation: 0.14819910235153555]
	TIME [epoch: 6.56 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612866006720964		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.1612866006720964 | validation: 0.13519981837039563]
	TIME [epoch: 6.55 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16026510978576194		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.16026510978576194 | validation: 0.10932325739351004]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1450.pth
	Model improved!!!
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15944552084289007		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.15944552084289007 | validation: 0.131828479105578]
	TIME [epoch: 6.55 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15594747015245589		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.15594747015245589 | validation: 0.13033834476407485]
	TIME [epoch: 6.57 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538732545078497		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.1538732545078497 | validation: 0.13420116600048487]
	TIME [epoch: 6.54 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15559018853787554		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.15559018853787554 | validation: 0.12554669508529195]
	TIME [epoch: 6.54 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15525988473889019		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.15525988473889019 | validation: 0.11865149194091808]
	TIME [epoch: 6.54 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15969672039769994		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.15969672039769994 | validation: 0.12394815558034201]
	TIME [epoch: 6.54 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1597011889492873		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.1597011889492873 | validation: 0.12803588678429617]
	TIME [epoch: 6.49 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1599561377560666		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.1599561377560666 | validation: 0.13323811265272087]
	TIME [epoch: 6.54 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16265772877060566		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.16265772877060566 | validation: 0.13065645119759656]
	TIME [epoch: 6.54 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15967379251171052		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.15967379251171052 | validation: 0.12432691136911027]
	TIME [epoch: 6.49 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16531525405193204		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.16531525405193204 | validation: 0.1300941375166928]
	TIME [epoch: 6.54 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16497026971218087		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.16497026971218087 | validation: 0.13148916056874993]
	TIME [epoch: 6.49 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16336772802736446		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.16336772802736446 | validation: 0.13242965540459298]
	TIME [epoch: 6.55 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16235566518261635		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.16235566518261635 | validation: 0.16087389689558304]
	TIME [epoch: 6.58 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16564886983785349		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.16564886983785349 | validation: 0.17091239130737407]
	TIME [epoch: 6.55 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1748937835509835		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.1748937835509835 | validation: 0.15678764902511078]
	TIME [epoch: 6.56 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16288802762056065		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.16288802762056065 | validation: 0.12711785609484044]
	TIME [epoch: 6.55 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16308892986511714		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.16308892986511714 | validation: 0.14176202843636918]
	TIME [epoch: 6.54 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16762415669116998		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.16762415669116998 | validation: 0.14278533847988922]
	TIME [epoch: 6.57 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16033651913416933		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.16033651913416933 | validation: 0.12088720518637598]
	TIME [epoch: 6.53 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16812074307186914		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.16812074307186914 | validation: 0.14592004651285737]
	TIME [epoch: 6.55 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16609665509692442		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.16609665509692442 | validation: 0.13248303993393212]
	TIME [epoch: 6.56 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15760425857938548		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.15760425857938548 | validation: 0.1255859307815711]
	TIME [epoch: 6.58 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15451349249042237		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.15451349249042237 | validation: 0.12886863504338453]
	TIME [epoch: 6.51 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15898221989552594		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.15898221989552594 | validation: 0.1285420116084573]
	TIME [epoch: 6.55 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582489085471272		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.1582489085471272 | validation: 0.12496000199524829]
	TIME [epoch: 6.59 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15600038189727403		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.15600038189727403 | validation: 0.12847533953655546]
	TIME [epoch: 6.54 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15321808547942914		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.15321808547942914 | validation: 0.12651395776136976]
	TIME [epoch: 6.54 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549472071514674		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.1549472071514674 | validation: 0.12990352133710795]
	TIME [epoch: 6.56 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553228253262618		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.1553228253262618 | validation: 0.11389489805686179]
	TIME [epoch: 6.55 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15357976558305325		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.15357976558305325 | validation: 0.12485904654352263]
	TIME [epoch: 6.5 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16203035085672823		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.16203035085672823 | validation: 0.1306502355815314]
	TIME [epoch: 6.54 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15735865895562726		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.15735865895562726 | validation: 0.14080298609433828]
	TIME [epoch: 6.54 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1658484535637518		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.1658484535637518 | validation: 0.15845389676247748]
	TIME [epoch: 6.49 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16774944839115147		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.16774944839115147 | validation: 0.15994974154801195]
	TIME [epoch: 6.55 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1596187520408441		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.1596187520408441 | validation: 0.14517905475792642]
	TIME [epoch: 6.54 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15980898593706933		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.15980898593706933 | validation: 0.1464512697818543]
	TIME [epoch: 6.48 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16075343849364387		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.16075343849364387 | validation: 0.13513735976828836]
	TIME [epoch: 6.55 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15510496628279177		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.15510496628279177 | validation: 0.12337984515223567]
	TIME [epoch: 6.54 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15551605036056437		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.15551605036056437 | validation: 0.12591721954067772]
	TIME [epoch: 6.5 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15587312901045436		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.15587312901045436 | validation: 0.12412744032947626]
	TIME [epoch: 6.55 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1596354366627592		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.1596354366627592 | validation: 0.13714667654115859]
	TIME [epoch: 6.54 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1583215306558453		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.1583215306558453 | validation: 0.14111489270355132]
	TIME [epoch: 6.49 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15780270461604803		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.15780270461604803 | validation: 0.11244763478232664]
	TIME [epoch: 6.55 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16548244644242782		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.16548244644242782 | validation: 0.12258382232946063]
	TIME [epoch: 6.55 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15467647818386845		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.15467647818386845 | validation: 0.1320939458277256]
	TIME [epoch: 6.48 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15397882882645159		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.15397882882645159 | validation: 0.14409627536532515]
	TIME [epoch: 6.55 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15355118149459052		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.15355118149459052 | validation: 0.11662371980278557]
	TIME [epoch: 6.54 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15890067413533882		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.15890067413533882 | validation: 0.1285198097282141]
	TIME [epoch: 6.53 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15773795420371284		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.15773795420371284 | validation: 0.13881842366183944]
	TIME [epoch: 6.49 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523579693937384		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.1523579693937384 | validation: 0.1337804065530698]
	TIME [epoch: 6.54 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15831700457535314		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.15831700457535314 | validation: 0.14133617547785082]
	TIME [epoch: 6.54 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15919106113228823		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.15919106113228823 | validation: 0.12446664606933236]
	TIME [epoch: 6.56 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159168946089585		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.159168946089585 | validation: 0.13031825771314837]
	TIME [epoch: 6.54 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15854781708811433		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.15854781708811433 | validation: 0.11435251768714466]
	TIME [epoch: 6.55 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16264592210060153		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.16264592210060153 | validation: 0.11939773954602113]
	TIME [epoch: 6.56 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1568964010563112		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.1568964010563112 | validation: 0.12190337272374675]
	TIME [epoch: 6.53 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15666063962197724		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.15666063962197724 | validation: 0.1304403026616454]
	TIME [epoch: 6.54 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16273768983939568		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.16273768983939568 | validation: 0.12817641709608907]
	TIME [epoch: 6.54 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15361136738990114		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.15361136738990114 | validation: 0.13382708320000897]
	TIME [epoch: 6.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15525332970866873		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.15525332970866873 | validation: 0.14079186686027506]
	TIME [epoch: 6.54 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16090182282613763		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.16090182282613763 | validation: 0.14435924182381357]
	TIME [epoch: 6.54 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590823379137966		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.1590823379137966 | validation: 0.1425981706907959]
	TIME [epoch: 6.57 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16051628725325623		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.16051628725325623 | validation: 0.1366035866613542]
	TIME [epoch: 6.53 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15932091830106965		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.15932091830106965 | validation: 0.14117506554697076]
	TIME [epoch: 6.55 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530225716282327		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.1530225716282327 | validation: 0.1262835614267954]
	TIME [epoch: 6.57 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542786900663463		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.1542786900663463 | validation: 0.12333840500555823]
	TIME [epoch: 6.54 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15906176783906018		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.15906176783906018 | validation: 0.11907096538309726]
	TIME [epoch: 6.6 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.160149623181428		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.160149623181428 | validation: 0.12134248311005554]
	TIME [epoch: 6.54 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15390729317409815		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.15390729317409815 | validation: 0.1277986265181846]
	TIME [epoch: 6.55 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15626892048958024		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.15626892048958024 | validation: 0.13162712729031287]
	TIME [epoch: 6.5 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15798642315285133		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.15798642315285133 | validation: 0.1307992022818585]
	TIME [epoch: 6.54 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1578262016418807		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.1578262016418807 | validation: 0.12413487118446817]
	TIME [epoch: 6.54 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15546002928678737		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.15546002928678737 | validation: 0.13493318668250495]
	TIME [epoch: 6.56 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15841552342222584		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.15841552342222584 | validation: 0.1372416345788631]
	TIME [epoch: 6.57 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15565859315082992		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.15565859315082992 | validation: 0.13758714880507414]
	TIME [epoch: 6.58 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15303113790556838		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.15303113790556838 | validation: 0.12385762247366415]
	TIME [epoch: 6.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15571330735156103		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.15571330735156103 | validation: 0.12961077229925272]
	TIME [epoch: 6.55 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15875305486726732		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.15875305486726732 | validation: 0.14116431917955624]
	TIME [epoch: 6.54 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15512134818109122		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.15512134818109122 | validation: 0.13007836821189497]
	TIME [epoch: 6.54 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15786112881004577		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.15786112881004577 | validation: 0.1255605448290234]
	TIME [epoch: 6.55 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15200350035500587		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.15200350035500587 | validation: 0.12710880776173727]
	TIME [epoch: 6.56 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15188203365804137		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.15188203365804137 | validation: 0.1243294659112487]
	TIME [epoch: 6.56 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15837911702572988		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.15837911702572988 | validation: 0.1223436617841988]
	TIME [epoch: 6.55 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15759674171080235		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.15759674171080235 | validation: 0.13277658837377185]
	TIME [epoch: 6.56 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15421872604898842		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.15421872604898842 | validation: 0.11998276517907826]
	TIME [epoch: 6.55 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536430640765186		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.1536430640765186 | validation: 0.1307394784104841]
	TIME [epoch: 6.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1513445121717679		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.1513445121717679 | validation: 0.12702458608828873]
	TIME [epoch: 6.55 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15486881502082894		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.15486881502082894 | validation: 0.12933458877931606]
	TIME [epoch: 6.55 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516858587141589		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.1516858587141589 | validation: 0.11861814018656609]
	TIME [epoch: 6.54 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15445274491663818		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.15445274491663818 | validation: 0.13179837237407585]
	TIME [epoch: 6.55 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15604823022751763		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.15604823022751763 | validation: 0.13089200918619795]
	TIME [epoch: 6.55 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15056123681698616		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.15056123681698616 | validation: 0.1149976144285958]
	TIME [epoch: 6.56 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582816168429367		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.1582816168429367 | validation: 0.12224641630675018]
	TIME [epoch: 6.55 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15534915140055572		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.15534915140055572 | validation: 0.12399554588466265]
	TIME [epoch: 6.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15742084173904097		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.15742084173904097 | validation: 0.13191237396876274]
	TIME [epoch: 6.55 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15918753538074565		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.15918753538074565 | validation: 0.11974697592159128]
	TIME [epoch: 6.55 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16497017851580253		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.16497017851580253 | validation: 0.13355305016507027]
	TIME [epoch: 6.54 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15849720296391362		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.15849720296391362 | validation: 0.12066498716922336]
	TIME [epoch: 6.54 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15867207483805407		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.15867207483805407 | validation: 0.12153373003846106]
	TIME [epoch: 6.48 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15716352255532484		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.15716352255532484 | validation: 0.1301276710907351]
	TIME [epoch: 6.54 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15975547651041422		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.15975547651041422 | validation: 0.14096304824320424]
	TIME [epoch: 6.55 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16064138011477747		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.16064138011477747 | validation: 0.12181725997720425]
	TIME [epoch: 6.55 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15968815854970642		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.15968815854970642 | validation: 0.12887630287475102]
	TIME [epoch: 6.55 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1558809481159256		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.1558809481159256 | validation: 0.12856109046832148]
	TIME [epoch: 6.58 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15452846771098994		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.15452846771098994 | validation: 0.12601886042189434]
	TIME [epoch: 6.55 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15315880262678155		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.15315880262678155 | validation: 0.11831628398789462]
	TIME [epoch: 6.56 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15460735618986846		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.15460735618986846 | validation: 0.11858904008840625]
	TIME [epoch: 6.5 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15424033038040164		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.15424033038040164 | validation: 0.1289734315750328]
	TIME [epoch: 6.56 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15692031511542945		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.15692031511542945 | validation: 0.14961250236734133]
	TIME [epoch: 6.52 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16033278170109377		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.16033278170109377 | validation: 0.15284714427374377]
	TIME [epoch: 6.54 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16147787324021168		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.16147787324021168 | validation: 0.1368338313571936]
	TIME [epoch: 6.55 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15471440543358622		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.15471440543358622 | validation: 0.14321219039654604]
	TIME [epoch: 6.49 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16223550095858816		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.16223550095858816 | validation: 0.1411000348812206]
	TIME [epoch: 6.52 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16004556986900473		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.16004556986900473 | validation: 0.15339539303218905]
	TIME [epoch: 6.53 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15354404574121563		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.15354404574121563 | validation: 0.13390136710227157]
	TIME [epoch: 6.54 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15269254639210272		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.15269254639210272 | validation: 0.13379350490271885]
	TIME [epoch: 6.52 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15853068544997626		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.15853068544997626 | validation: 0.15645661684729212]
	TIME [epoch: 6.55 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15752747154139551		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.15752747154139551 | validation: 0.1524158006765262]
	TIME [epoch: 6.56 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15779707797351578		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.15779707797351578 | validation: 0.1522563951195603]
	TIME [epoch: 6.55 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15796933131954458		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.15796933131954458 | validation: 0.15481614360089788]
	TIME [epoch: 6.53 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1615215908861919		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.1615215908861919 | validation: 0.14011442304520366]
	TIME [epoch: 6.49 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1545549614061209		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.1545549614061209 | validation: 0.1411977114460772]
	TIME [epoch: 6.54 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614782346862182		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.1614782346862182 | validation: 0.12801591048579236]
	TIME [epoch: 6.52 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15505380696498924		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.15505380696498924 | validation: 0.13455827392271666]
	TIME [epoch: 6.53 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15371252556357307		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.15371252556357307 | validation: 0.1256468013880695]
	TIME [epoch: 6.55 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15357379507693197		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.15357379507693197 | validation: 0.12462396306565623]
	TIME [epoch: 6.54 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15111853649877546		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.15111853649877546 | validation: 0.1224428139988088]
	TIME [epoch: 6.54 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15401795775398186		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.15401795775398186 | validation: 0.12758596287289017]
	TIME [epoch: 6.56 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15409770605199233		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.15409770605199233 | validation: 0.12655875150308726]
	TIME [epoch: 6.57 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15454209194735188		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.15454209194735188 | validation: 0.12713787649967295]
	TIME [epoch: 6.53 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15673650489319646		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.15673650489319646 | validation: 0.12808679463581546]
	TIME [epoch: 6.54 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550295335139366		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.1550295335139366 | validation: 0.1325342612238854]
	TIME [epoch: 6.55 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557432892879478		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.1557432892879478 | validation: 0.12584785829322911]
	TIME [epoch: 6.54 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15780713568142385		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.15780713568142385 | validation: 0.11612012444423474]
	TIME [epoch: 6.54 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16042603597682303		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.16042603597682303 | validation: 0.1246413868221436]
	TIME [epoch: 6.56 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1555911536136239		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.1555911536136239 | validation: 0.125220703154912]
	TIME [epoch: 6.59 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536970019380658		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.1536970019380658 | validation: 0.11393574049572724]
	TIME [epoch: 6.54 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15432896220487294		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.15432896220487294 | validation: 0.11805218173597354]
	TIME [epoch: 6.54 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1617298799463653		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.1617298799463653 | validation: 0.12115697819256196]
	TIME [epoch: 6.48 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15982792885627756		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.15982792885627756 | validation: 0.11826492263941579]
	TIME [epoch: 6.53 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520563865696101		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.1520563865696101 | validation: 0.12246256818667024]
	TIME [epoch: 6.53 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1529549821439714		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.1529549821439714 | validation: 0.1327320201760023]
	TIME [epoch: 6.58 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516405830912106		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.1516405830912106 | validation: 0.13397125882135305]
	TIME [epoch: 6.51 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15281787275940253		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.15281787275940253 | validation: 0.15460271493723482]
	TIME [epoch: 6.55 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15481480566368866		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.15481480566368866 | validation: 0.1436433800881236]
	TIME [epoch: 6.56 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1564544603114278		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.1564544603114278 | validation: 0.14344338938297427]
	TIME [epoch: 6.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550156786710124		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.1550156786710124 | validation: 0.13365092305080825]
	TIME [epoch: 6.53 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15433359644510167		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.15433359644510167 | validation: 0.12795424491634116]
	TIME [epoch: 6.54 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15523231383578875		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.15523231383578875 | validation: 0.1319986463894448]
	TIME [epoch: 6.49 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.155237527717681		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.155237527717681 | validation: 0.12713428080719974]
	TIME [epoch: 6.56 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15043541918226974		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.15043541918226974 | validation: 0.1316409550840843]
	TIME [epoch: 6.55 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15865339487360722		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.15865339487360722 | validation: 0.12532990781844888]
	TIME [epoch: 6.56 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15488681173971275		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.15488681173971275 | validation: 0.12279208742115437]
	TIME [epoch: 6.56 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15292627554439725		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.15292627554439725 | validation: 0.12909718792781694]
	TIME [epoch: 6.56 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522191920465543		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.1522191920465543 | validation: 0.13304424508842125]
	TIME [epoch: 6.55 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518329021208088		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.1518329021208088 | validation: 0.13225348161618453]
	TIME [epoch: 6.56 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15012445037082126		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.15012445037082126 | validation: 0.13095716124058004]
	TIME [epoch: 6.54 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15542312202793085		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.15542312202793085 | validation: 0.13800289164495552]
	TIME [epoch: 6.57 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15326371028340258		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.15326371028340258 | validation: 0.13465294780005127]
	TIME [epoch: 6.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543180427671565		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.1543180427671565 | validation: 0.13940196099697194]
	TIME [epoch: 6.56 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15229694808653288		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.15229694808653288 | validation: 0.1439170326592985]
	TIME [epoch: 6.57 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15735373357702398		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.15735373357702398 | validation: 0.12938447261994435]
	TIME [epoch: 6.53 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1596522095321814		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.1596522095321814 | validation: 0.12192087094082846]
	TIME [epoch: 6.55 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537472067246208		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.1537472067246208 | validation: 0.12580254405190672]
	TIME [epoch: 6.49 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582334683589699		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.1582334683589699 | validation: 0.12422442654800672]
	TIME [epoch: 6.54 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15301118189704815		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.15301118189704815 | validation: 0.12337593367488321]
	TIME [epoch: 6.53 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15170789773260188		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.15170789773260188 | validation: 0.1307651695840735]
	TIME [epoch: 6.55 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15954726840133165		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.15954726840133165 | validation: 0.13989049184316135]
	TIME [epoch: 6.53 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1591442750569343		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.1591442750569343 | validation: 0.1258908460668451]
	TIME [epoch: 6.55 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15554837793976575		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.15554837793976575 | validation: 0.137058709840066]
	TIME [epoch: 6.57 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15707723144242405		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.15707723144242405 | validation: 0.13232394258167693]
	TIME [epoch: 6.6 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537585384353082		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.1537585384353082 | validation: 0.12152518472868405]
	TIME [epoch: 6.55 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1534127496865749		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.1534127496865749 | validation: 0.1185465287857113]
	TIME [epoch: 6.54 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15423521130369702		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.15423521130369702 | validation: 0.12046358224466777]
	TIME [epoch: 6.53 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15909477827991947		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.15909477827991947 | validation: 0.11961085313437102]
	TIME [epoch: 6.57 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523356274706488		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.1523356274706488 | validation: 0.11558120371485654]
	TIME [epoch: 6.5 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14996240135492214		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.14996240135492214 | validation: 0.12199280211866789]
	TIME [epoch: 6.56 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15368472501336433		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.15368472501336433 | validation: 0.12505237687562448]
	TIME [epoch: 6.56 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15145483021995215		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.15145483021995215 | validation: 0.11888152115428938]
	TIME [epoch: 6.56 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1546565431775685		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.1546565431775685 | validation: 0.1189353021559382]
	TIME [epoch: 6.55 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15361048353610998		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.15361048353610998 | validation: 0.12255435902304193]
	TIME [epoch: 6.55 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15347901467202552		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.15347901467202552 | validation: 0.12032179955114021]
	TIME [epoch: 6.54 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1501722263703506		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.1501722263703506 | validation: 0.13071858286038462]
	TIME [epoch: 6.55 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.154844674991388		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.154844674991388 | validation: 0.13478303775860676]
	TIME [epoch: 6.5 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15305477099328		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.15305477099328 | validation: 0.12773073112706815]
	TIME [epoch: 6.55 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15453923667749045		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.15453923667749045 | validation: 0.13387831759552632]
	TIME [epoch: 6.56 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15108092938860013		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.15108092938860013 | validation: 0.12886254228334998]
	TIME [epoch: 6.56 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15115777548807857		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.15115777548807857 | validation: 0.12491435783777086]
	TIME [epoch: 6.57 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15214206464346747		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.15214206464346747 | validation: 0.12936726451038807]
	TIME [epoch: 6.6 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15488570315892444		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.15488570315892444 | validation: 0.137282405722951]
	TIME [epoch: 6.56 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1527093557055605		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.1527093557055605 | validation: 0.13611001280641374]
	TIME [epoch: 6.56 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15760045147974946		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.15760045147974946 | validation: 0.13202794935197626]
	TIME [epoch: 6.51 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15859367162313412		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.15859367162313412 | validation: 0.13421522789746185]
	TIME [epoch: 6.55 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16065240902068184		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.16065240902068184 | validation: 0.13061821450321037]
	TIME [epoch: 6.56 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15621568302999328		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.15621568302999328 | validation: 0.11716296218182186]
	TIME [epoch: 6.58 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15031897320249307		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.15031897320249307 | validation: 0.1244652629521952]
	TIME [epoch: 6.58 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15845409625244336		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.15845409625244336 | validation: 0.12060943628419844]
	TIME [epoch: 6.5 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15411301195950872		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.15411301195950872 | validation: 0.11774120080251599]
	TIME [epoch: 6.55 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510975832487789		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.1510975832487789 | validation: 0.1113866035840212]
	TIME [epoch: 6.56 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15681940143299516		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.15681940143299516 | validation: 0.11718925332054048]
	TIME [epoch: 6.5 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15334748743616883		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.15334748743616883 | validation: 0.12205677724418801]
	TIME [epoch: 6.57 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15030156885749688		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.15030156885749688 | validation: 0.1372600073011961]
	TIME [epoch: 6.56 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526588393096122		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.1526588393096122 | validation: 0.1505056855312891]
	TIME [epoch: 6.56 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15658746957676886		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.15658746957676886 | validation: 0.1513625524639708]
	TIME [epoch: 6.56 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15474653823418677		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.15474653823418677 | validation: 0.1363126865972108]
	TIME [epoch: 6.57 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15174079016020697		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.15174079016020697 | validation: 0.13767004770738708]
	TIME [epoch: 6.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14884295761791144		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.14884295761791144 | validation: 0.11795572153086402]
	TIME [epoch: 6.56 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.153240176397816		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.153240176397816 | validation: 0.12384371591696101]
	TIME [epoch: 6.56 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1590669967438623		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.1590669967438623 | validation: 0.1159817230960694]
	TIME [epoch: 6.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1575354229899091		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.1575354229899091 | validation: 0.12564720933421794]
	TIME [epoch: 6.55 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15558009818948798		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.15558009818948798 | validation: 0.12147308503802375]
	TIME [epoch: 6.55 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15313150485060767		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.15313150485060767 | validation: 0.12798454524161212]
	TIME [epoch: 6.55 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15638541518845003		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.15638541518845003 | validation: 0.1282513193921028]
	TIME [epoch: 6.56 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15199892296775835		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.15199892296775835 | validation: 0.12656224977858666]
	TIME [epoch: 6.55 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15070703824632303		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.15070703824632303 | validation: 0.13724207562609503]
	TIME [epoch: 6.54 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522236589920108		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.1522236589920108 | validation: 0.12187392300260719]
	TIME [epoch: 6.55 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15132228350059784		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.15132228350059784 | validation: 0.11881412026871697]
	TIME [epoch: 6.53 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15075184288534507		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.15075184288534507 | validation: 0.12716291273014177]
	TIME [epoch: 6.54 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1547076320095848		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.1547076320095848 | validation: 0.12785771318555827]
	TIME [epoch: 6.55 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15547931225007952		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.15547931225007952 | validation: 0.1262574990900745]
	TIME [epoch: 6.54 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1537842683344411		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.1537842683344411 | validation: 0.13319771259379873]
	TIME [epoch: 6.55 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15725198991698455		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.15725198991698455 | validation: 0.1379184032316316]
	TIME [epoch: 6.54 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15601966553001428		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.15601966553001428 | validation: 0.1248467210068037]
	TIME [epoch: 6.52 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15255077855179464		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.15255077855179464 | validation: 0.12253253621999506]
	TIME [epoch: 6.56 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14821030111268582		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.14821030111268582 | validation: 0.12369381706580994]
	TIME [epoch: 6.55 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15416629592187311		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.15416629592187311 | validation: 0.11968525860629126]
	TIME [epoch: 6.52 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14965949865041195		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.14965949865041195 | validation: 0.1259946784875982]
	TIME [epoch: 6.53 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1490528492363748		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.1490528492363748 | validation: 0.1273751335990744]
	TIME [epoch: 6.56 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15291597174014604		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.15291597174014604 | validation: 0.13173234221980137]
	TIME [epoch: 6.55 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15300126231263061		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.15300126231263061 | validation: 0.1234079550394193]
	TIME [epoch: 6.54 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1528189733235208		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.1528189733235208 | validation: 0.12836938198226985]
	TIME [epoch: 6.54 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14994938836222502		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.14994938836222502 | validation: 0.1298230521843022]
	TIME [epoch: 6.54 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536280939036684		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.1536280939036684 | validation: 0.13518636421407332]
	TIME [epoch: 6.55 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15088726006431755		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.15088726006431755 | validation: 0.12233221201634054]
	TIME [epoch: 6.56 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1536811618145303		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.1536811618145303 | validation: 0.12350870352781958]
	TIME [epoch: 6.6 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.159277301245954		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.159277301245954 | validation: 0.12627974408241233]
	TIME [epoch: 6.55 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15101582805878144		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.15101582805878144 | validation: 0.11836051430980597]
	TIME [epoch: 6.55 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15227081745685167		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.15227081745685167 | validation: 0.13307581305152735]
	TIME [epoch: 6.52 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15415483931536167		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.15415483931536167 | validation: 0.1359486654847546]
	TIME [epoch: 6.54 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15463670752932374		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.15463670752932374 | validation: 0.13716030992055608]
	TIME [epoch: 6.55 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1560689091382552		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.1560689091382552 | validation: 0.1339707411111495]
	TIME [epoch: 6.57 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15496480547597463		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.15496480547597463 | validation: 0.12811678851182035]
	TIME [epoch: 6.56 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15443627446928032		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.15443627446928032 | validation: 0.12179977958242731]
	TIME [epoch: 6.56 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15285755738550205		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.15285755738550205 | validation: 0.12385971051024357]
	TIME [epoch: 6.54 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15832591068491786		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.15832591068491786 | validation: 0.1299604426022583]
	TIME [epoch: 6.55 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15118411606562848		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.15118411606562848 | validation: 0.11445612892650991]
	TIME [epoch: 6.56 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1566795212978874		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.1566795212978874 | validation: 0.12283666484712188]
	TIME [epoch: 6.54 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15557403916154755		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.15557403916154755 | validation: 0.12077675954486954]
	TIME [epoch: 6.59 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15375355354221792		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.15375355354221792 | validation: 0.1275743906258052]
	TIME [epoch: 6.56 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15560720834640135		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.15560720834640135 | validation: 0.12166041150233632]
	TIME [epoch: 6.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15463542877777628		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.15463542877777628 | validation: 0.13453271556000304]
	TIME [epoch: 6.55 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15249069084668168		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.15249069084668168 | validation: 0.12380173540626302]
	TIME [epoch: 6.55 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15712170000574063		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.15712170000574063 | validation: 0.12295746248523605]
	TIME [epoch: 6.49 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15420073494360265		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.15420073494360265 | validation: 0.12596822843004118]
	TIME [epoch: 6.56 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514536407078344		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.1514536407078344 | validation: 0.11845273697100214]
	TIME [epoch: 6.54 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15206005600795627		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.15206005600795627 | validation: 0.1304057485096515]
	TIME [epoch: 6.49 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14965384155796396		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.14965384155796396 | validation: 0.12938939970529412]
	TIME [epoch: 6.54 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15461453673218428		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.15461453673218428 | validation: 0.14079808973539223]
	TIME [epoch: 6.57 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15208092903195664		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.15208092903195664 | validation: 0.14527812778745622]
	TIME [epoch: 6.58 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1524808389693045		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.1524808389693045 | validation: 0.12528635430230803]
	TIME [epoch: 6.56 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15415705811856123		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.15415705811856123 | validation: 0.11740177237968148]
	TIME [epoch: 6.55 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532225606651961		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.1532225606651961 | validation: 0.13145900483916775]
	TIME [epoch: 6.53 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1513157869138549		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.1513157869138549 | validation: 0.1274009484117747]
	TIME [epoch: 6.54 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15687164879489204		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.15687164879489204 | validation: 0.13790986296216642]
	TIME [epoch: 6.55 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15420008827212253		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.15420008827212253 | validation: 0.134265454568521]
	TIME [epoch: 6.58 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15337575931182335		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.15337575931182335 | validation: 0.13631483043089318]
	TIME [epoch: 6.54 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15063302364536285		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.15063302364536285 | validation: 0.12671884896218413]
	TIME [epoch: 6.54 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15212204868105006		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.15212204868105006 | validation: 0.1264058206829699]
	TIME [epoch: 6.54 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15351531899320206		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.15351531899320206 | validation: 0.12095202852426507]
	TIME [epoch: 6.56 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15390363708934623		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.15390363708934623 | validation: 0.12399391392980967]
	TIME [epoch: 6.51 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1525440354749971		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.1525440354749971 | validation: 0.11730329564624342]
	TIME [epoch: 6.54 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15198443112066315		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.15198443112066315 | validation: 0.11708099280138726]
	TIME [epoch: 6.59 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15479514856877402		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.15479514856877402 | validation: 0.11914193746280086]
	TIME [epoch: 6.56 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1568964740670183		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.1568964740670183 | validation: 0.1205676928577532]
	TIME [epoch: 6.54 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15609556410070066		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.15609556410070066 | validation: 0.11508331338023255]
	TIME [epoch: 6.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15392738357123387		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.15392738357123387 | validation: 0.11567830003610435]
	TIME [epoch: 6.54 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15281428190797378		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.15281428190797378 | validation: 0.11992921611368627]
	TIME [epoch: 6.54 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1538515999486697		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.1538515999486697 | validation: 0.11252232654737489]
	TIME [epoch: 6.56 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1585505074807974		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.1585505074807974 | validation: 0.11993348469426579]
	TIME [epoch: 6.57 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15400074243691658		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.15400074243691658 | validation: 0.12014414548846865]
	TIME [epoch: 6.58 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15179358475297178		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.15179358475297178 | validation: 0.1142871418580471]
	TIME [epoch: 6.57 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15526566484635343		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.15526566484635343 | validation: 0.12182845773088229]
	TIME [epoch: 6.51 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15442713081027418		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.15442713081027418 | validation: 0.12779400421569295]
	TIME [epoch: 6.55 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15291242812834727		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.15291242812834727 | validation: 0.12525706357259775]
	TIME [epoch: 6.49 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15426274903792275		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.15426274903792275 | validation: 0.1278497994039944]
	TIME [epoch: 6.55 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1527731805438057		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.1527731805438057 | validation: 0.13054340742544426]
	TIME [epoch: 6.59 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1524725347060153		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.1524725347060153 | validation: 0.1295522210795299]
	TIME [epoch: 6.55 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15250252656495147		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.15250252656495147 | validation: 0.12946621579673065]
	TIME [epoch: 6.53 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15064245453824315		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.15064245453824315 | validation: 0.1269193555178517]
	TIME [epoch: 6.55 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15121705051147902		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.15121705051147902 | validation: 0.12352876620557857]
	TIME [epoch: 6.56 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544865348428284		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.1544865348428284 | validation: 0.12051926793676257]
	TIME [epoch: 6.58 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14985012789170876		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.14985012789170876 | validation: 0.13476031091084323]
	TIME [epoch: 6.54 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1530793997783614		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.1530793997783614 | validation: 0.1260674208381098]
	TIME [epoch: 6.53 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15039699304649923		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.15039699304649923 | validation: 0.12563825929702122]
	TIME [epoch: 6.55 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15112863697721413		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.15112863697721413 | validation: 0.11485108797764217]
	TIME [epoch: 6.58 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15231912617005688		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.15231912617005688 | validation: 0.11683918453963298]
	TIME [epoch: 6.57 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1534655948882248		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.1534655948882248 | validation: 0.11993402870127046]
	TIME [epoch: 6.49 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15058269751827083		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.15058269751827083 | validation: 0.11986078906966859]
	TIME [epoch: 6.56 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1484385068086688		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.1484385068086688 | validation: 0.12870951620333546]
	TIME [epoch: 6.54 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15542364366211975		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.15542364366211975 | validation: 0.1310118149390377]
	TIME [epoch: 6.48 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.152361685287419		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.152361685287419 | validation: 0.131543211061996]
	TIME [epoch: 6.55 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15434356245923359		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.15434356245923359 | validation: 0.13858890748442063]
	TIME [epoch: 6.54 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15872245063797677		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.15872245063797677 | validation: 0.13015298399593997]
	TIME [epoch: 6.56 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15108691486469245		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.15108691486469245 | validation: 0.12964755306602987]
	TIME [epoch: 6.52 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15077105799192037		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.15077105799192037 | validation: 0.13362512161236992]
	TIME [epoch: 6.55 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487201988744519		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.1487201988744519 | validation: 0.11979461465154295]
	TIME [epoch: 6.55 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14969563561301902		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.14969563561301902 | validation: 0.12542127145506066]
	TIME [epoch: 6.51 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15128990075763432		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.15128990075763432 | validation: 0.13238022607346286]
	TIME [epoch: 6.57 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15267326255059926		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.15267326255059926 | validation: 0.12514863170681134]
	TIME [epoch: 6.54 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15221273539794516		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.15221273539794516 | validation: 0.12019632366395516]
	TIME [epoch: 6.59 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15025222592223222		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.15025222592223222 | validation: 0.1298455917171108]
	TIME [epoch: 6.55 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14955212669160317		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.14955212669160317 | validation: 0.12999947672676002]
	TIME [epoch: 6.55 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1550339627513539		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.1550339627513539 | validation: 0.13166876451859913]
	TIME [epoch: 6.55 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14797850980592675		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.14797850980592675 | validation: 0.12709459382887142]
	TIME [epoch: 6.57 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15302843444630662		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.15302843444630662 | validation: 0.12681022079296672]
	TIME [epoch: 6.51 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1498706968316293		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.1498706968316293 | validation: 0.12946334238907486]
	TIME [epoch: 6.56 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1490386433475214		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.1490386433475214 | validation: 0.12557831067759276]
	TIME [epoch: 6.58 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15117507335821884		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.15117507335821884 | validation: 0.11594658518763012]
	TIME [epoch: 6.63 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15194246620161972		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.15194246620161972 | validation: 0.11512784134095037]
	TIME [epoch: 6.55 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14853589025529013		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.14853589025529013 | validation: 0.11899362791328492]
	TIME [epoch: 6.57 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14694172354742338		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.14694172354742338 | validation: 0.12215690524651157]
	TIME [epoch: 6.57 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15139931597296954		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.15139931597296954 | validation: 0.11145531723986789]
	TIME [epoch: 6.55 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15326807541923212		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.15326807541923212 | validation: 0.11379619748614253]
	TIME [epoch: 6.56 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518842119520047		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.1518842119520047 | validation: 0.12930397130221585]
	TIME [epoch: 6.49 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14868848653391878		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.14868848653391878 | validation: 0.1254058315790315]
	TIME [epoch: 6.55 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15101375912750747		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.15101375912750747 | validation: 0.12317374248445362]
	TIME [epoch: 6.54 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15333658999906769		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.15333658999906769 | validation: 0.12461439080343059]
	TIME [epoch: 6.49 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15126914459975585		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.15126914459975585 | validation: 0.13120216605382148]
	TIME [epoch: 6.55 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15258685217867796		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.15258685217867796 | validation: 0.1193767513598858]
	TIME [epoch: 6.54 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15176208964171017		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.15176208964171017 | validation: 0.11764255523808896]
	TIME [epoch: 6.54 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1512294306354843		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.1512294306354843 | validation: 0.12454156680918109]
	TIME [epoch: 6.56 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1480343597178126		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.1480343597178126 | validation: 0.12344011074951156]
	TIME [epoch: 6.55 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466122009429644		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.1466122009429644 | validation: 0.1248224341992232]
	TIME [epoch: 6.53 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507779542618483		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.1507779542618483 | validation: 0.12685369679427652]
	TIME [epoch: 6.52 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15185689281499615		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.15185689281499615 | validation: 0.12152166627800169]
	TIME [epoch: 6.54 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15536106809250697		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.15536106809250697 | validation: 0.12404499740158624]
	TIME [epoch: 6.53 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15477991017259246		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.15477991017259246 | validation: 0.12686564108178272]
	TIME [epoch: 6.54 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15100337572626824		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.15100337572626824 | validation: 0.12281546799778184]
	TIME [epoch: 6.55 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14819106931303688		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.14819106931303688 | validation: 0.12770807724407546]
	TIME [epoch: 6.52 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14891475678796667		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.14891475678796667 | validation: 0.1425906752467609]
	TIME [epoch: 6.57 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1508189204290778		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.1508189204290778 | validation: 0.13661670308907442]
	TIME [epoch: 6.55 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15627855397278573		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.15627855397278573 | validation: 0.13304034958826025]
	TIME [epoch: 6.57 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15160901327262988		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.15160901327262988 | validation: 0.1284216913375385]
	TIME [epoch: 6.55 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15243579576787256		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.15243579576787256 | validation: 0.12407259833203423]
	TIME [epoch: 6.55 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14864818017994344		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.14864818017994344 | validation: 0.12174683758093476]
	TIME [epoch: 6.51 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14660159230259223		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.14660159230259223 | validation: 0.1333456294273205]
	TIME [epoch: 6.55 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15094309311733076		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.15094309311733076 | validation: 0.12808216639295977]
	TIME [epoch: 6.55 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15020257831287445		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.15020257831287445 | validation: 0.13160731044638704]
	TIME [epoch: 6.53 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15028397910524016		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.15028397910524016 | validation: 0.13873207103546023]
	TIME [epoch: 6.54 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15026834831984942		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.15026834831984942 | validation: 0.14065583426971234]
	TIME [epoch: 6.6 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507970473236947		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.1507970473236947 | validation: 0.1374124999443454]
	TIME [epoch: 6.55 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14975381538244614		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.14975381538244614 | validation: 0.13701180178111144]
	TIME [epoch: 6.54 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15091529706407994		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.15091529706407994 | validation: 0.12942774760378567]
	TIME [epoch: 6.58 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15000965335429062		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.15000965335429062 | validation: 0.1413729376808491]
	TIME [epoch: 6.54 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1544013852181147		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.1544013852181147 | validation: 0.14190732483040905]
	TIME [epoch: 6.49 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14953472697414927		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.14953472697414927 | validation: 0.1213576929393232]
	TIME [epoch: 6.55 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15204588844373074		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.15204588844373074 | validation: 0.1263503006802581]
	TIME [epoch: 6.56 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15085311094269266		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.15085311094269266 | validation: 0.12910247181380427]
	TIME [epoch: 6.54 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1513113640011669		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.1513113640011669 | validation: 0.11506017565686584]
	TIME [epoch: 6.49 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1492478434686459		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.1492478434686459 | validation: 0.12454460043578343]
	TIME [epoch: 6.56 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15052010455136133		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.15052010455136133 | validation: 0.12053740631951282]
	TIME [epoch: 6.55 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15249424346852114		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.15249424346852114 | validation: 0.11692965188465637]
	TIME [epoch: 6.51 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15247476381465477		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.15247476381465477 | validation: 0.12378627006015468]
	TIME [epoch: 6.55 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15637682338824513		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.15637682338824513 | validation: 0.12410385664176285]
	TIME [epoch: 6.55 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15278200558625513		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.15278200558625513 | validation: 0.11847245850701384]
	TIME [epoch: 6.49 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15127757437155984		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.15127757437155984 | validation: 0.12799404341507756]
	TIME [epoch: 6.55 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15215838722403868		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.15215838722403868 | validation: 0.12870853079723954]
	TIME [epoch: 6.56 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14930885028203394		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.14930885028203394 | validation: 0.11190641156496418]
	TIME [epoch: 6.51 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559036268886939		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.1559036268886939 | validation: 0.12203825408837948]
	TIME [epoch: 6.55 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14795503528206283		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.14795503528206283 | validation: 0.12637932607711386]
	TIME [epoch: 6.53 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14994922719806036		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.14994922719806036 | validation: 0.13021174433234314]
	TIME [epoch: 6.56 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503799970327735		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.1503799970327735 | validation: 0.12071954414540123]
	TIME [epoch: 6.54 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14782345068591635		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.14782345068591635 | validation: 0.12210023234041804]
	TIME [epoch: 6.54 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14991724154203678		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.14991724154203678 | validation: 0.125868236266686]
	TIME [epoch: 6.54 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14674300279619013		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.14674300279619013 | validation: 0.12219530150838775]
	TIME [epoch: 6.57 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14860479318542924		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.14860479318542924 | validation: 0.11977701360575244]
	TIME [epoch: 6.57 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14704116170609435		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.14704116170609435 | validation: 0.1323190392150545]
	TIME [epoch: 6.57 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1497019403563227		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.1497019403563227 | validation: 0.12036063505306711]
	TIME [epoch: 6.55 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14931553221044128		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.14931553221044128 | validation: 0.12606599038325622]
	TIME [epoch: 6.56 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15025110245478915		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.15025110245478915 | validation: 0.13397794731694646]
	TIME [epoch: 6.51 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14762301938571593		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.14762301938571593 | validation: 0.13131471251534135]
	TIME [epoch: 6.54 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1517826301813698		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.1517826301813698 | validation: 0.12625027069248876]
	TIME [epoch: 6.56 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488717171413024		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.1488717171413024 | validation: 0.13330077766760454]
	TIME [epoch: 6.58 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14975511829357335		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.14975511829357335 | validation: 0.13015435956964688]
	TIME [epoch: 6.55 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14851344684855508		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.14851344684855508 | validation: 0.12026302472666771]
	TIME [epoch: 6.54 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.150061096660982		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.150061096660982 | validation: 0.12429110048809339]
	TIME [epoch: 6.57 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1506512092546143		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.1506512092546143 | validation: 0.12450262225967758]
	TIME [epoch: 6.54 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14813487235399256		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.14813487235399256 | validation: 0.11887678890523326]
	TIME [epoch: 6.56 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15090166430538282		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.15090166430538282 | validation: 0.12697565331448238]
	TIME [epoch: 6.55 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14895980473894116		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.14895980473894116 | validation: 0.12104645872661608]
	TIME [epoch: 6.55 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.149292725604331		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.149292725604331 | validation: 0.11850814563578223]
	TIME [epoch: 6.55 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14965138990087365		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.14965138990087365 | validation: 0.12399763639524122]
	TIME [epoch: 6.57 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1494460814304024		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.1494460814304024 | validation: 0.12492044991148855]
	TIME [epoch: 6.57 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504085369888526		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.1504085369888526 | validation: 0.1235083332383326]
	TIME [epoch: 6.55 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507057566205285		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.1507057566205285 | validation: 0.11431971918498775]
	TIME [epoch: 6.54 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14660965287935496		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.14660965287935496 | validation: 0.11871416944893115]
	TIME [epoch: 6.49 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1507694048234614		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.1507694048234614 | validation: 0.13252002653072104]
	TIME [epoch: 6.63 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14821751173010872		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.14821751173010872 | validation: 0.12280327214054207]
	TIME [epoch: 6.54 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1531310127367272		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.1531310127367272 | validation: 0.12644342295651728]
	TIME [epoch: 6.57 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1514880809943358		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.1514880809943358 | validation: 0.11964649295891273]
	TIME [epoch: 6.48 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14956624029332047		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.14956624029332047 | validation: 0.13165484185542808]
	TIME [epoch: 6.53 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15159156267823737		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.15159156267823737 | validation: 0.1237802531284167]
	TIME [epoch: 6.55 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15351659415250346		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.15351659415250346 | validation: 0.13250223211180898]
	TIME [epoch: 6.54 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15237618679147705		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.15237618679147705 | validation: 0.13087724021795655]
	TIME [epoch: 6.57 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15233278706175613		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.15233278706175613 | validation: 0.12020095406745972]
	TIME [epoch: 6.57 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15240431656288292		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.15240431656288292 | validation: 0.11629417008946796]
	TIME [epoch: 6.56 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15093666318130197		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.15093666318130197 | validation: 0.12000642277802785]
	TIME [epoch: 6.55 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532833723513716		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.1532833723513716 | validation: 0.1183852932384892]
	TIME [epoch: 6.54 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15326172239025782		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.15326172239025782 | validation: 0.11822065034233649]
	TIME [epoch: 6.49 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15112629774233158		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.15112629774233158 | validation: 0.12134186552581103]
	TIME [epoch: 6.54 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.151487730379372		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.151487730379372 | validation: 0.12642566044493375]
	TIME [epoch: 6.55 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15325164816309306		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.15325164816309306 | validation: 0.12149819438932039]
	TIME [epoch: 6.49 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14860475941078286		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.14860475941078286 | validation: 0.11950242466062229]
	TIME [epoch: 6.55 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14823178704654308		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.14823178704654308 | validation: 0.1132911025326185]
	TIME [epoch: 6.55 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1505695381915709		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.1505695381915709 | validation: 0.1165652636950655]
	TIME [epoch: 6.54 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1468425832901244		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.1468425832901244 | validation: 0.11725412351184022]
	TIME [epoch: 6.51 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14787925839177934		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.14787925839177934 | validation: 0.1199336582264489]
	TIME [epoch: 6.54 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14831722185507973		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.14831722185507973 | validation: 0.11862826601898471]
	TIME [epoch: 6.55 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15181595540628884		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.15181595540628884 | validation: 0.1181995257507722]
	TIME [epoch: 6.56 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14921170454644322		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.14921170454644322 | validation: 0.12742976864482952]
	TIME [epoch: 6.53 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1491819986387447		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.1491819986387447 | validation: 0.12299507268918607]
	TIME [epoch: 6.56 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14936754022645266		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.14936754022645266 | validation: 0.12610945673857532]
	TIME [epoch: 6.57 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14866993794774058		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.14866993794774058 | validation: 0.13135542086736124]
	TIME [epoch: 6.57 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14649193066311966		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.14649193066311966 | validation: 0.12989137736071593]
	TIME [epoch: 6.54 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1520181365039538		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.1520181365039538 | validation: 0.1269147792906697]
	TIME [epoch: 6.55 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14722602509950472		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.14722602509950472 | validation: 0.1175334697170938]
	TIME [epoch: 6.57 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15117464061204952		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.15117464061204952 | validation: 0.12599968069039985]
	TIME [epoch: 6.57 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510325374086952		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.1510325374086952 | validation: 0.12066941483337791]
	TIME [epoch: 6.55 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467978067952878		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.1467978067952878 | validation: 0.11780766055300919]
	TIME [epoch: 6.54 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15738747880029288		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.15738747880029288 | validation: 0.11402415653535217]
	TIME [epoch: 6.54 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15370242369359885		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.15370242369359885 | validation: 0.12517205450739924]
	TIME [epoch: 6.56 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15071586591888844		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.15071586591888844 | validation: 0.12498047495342116]
	TIME [epoch: 6.49 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14830054374230625		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.14830054374230625 | validation: 0.11123565105714786]
	TIME [epoch: 6.57 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15314537834881478		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.15314537834881478 | validation: 0.11755760947441075]
	TIME [epoch: 6.56 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15104701562349004		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.15104701562349004 | validation: 0.12392734839562182]
	TIME [epoch: 6.56 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14292341721656582		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.14292341721656582 | validation: 0.1261615073994879]
	TIME [epoch: 6.56 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14950284536267305		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.14950284536267305 | validation: 0.11814354632102675]
	TIME [epoch: 6.55 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14870548359193564		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.14870548359193564 | validation: 0.12103306541776265]
	TIME [epoch: 6.58 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14746981244401422		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.14746981244401422 | validation: 0.12453071993527287]
	TIME [epoch: 6.52 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14719364050509798		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.14719364050509798 | validation: 0.12589872750582715]
	TIME [epoch: 6.56 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14755534237891307		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.14755534237891307 | validation: 0.12574471961325315]
	TIME [epoch: 6.56 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15049486149630809		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.15049486149630809 | validation: 0.12108202496353691]
	TIME [epoch: 6.49 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15066430340495443		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.15066430340495443 | validation: 0.11859930478267777]
	TIME [epoch: 6.56 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14900028697822026		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.14900028697822026 | validation: 0.1176425808061786]
	TIME [epoch: 6.59 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502503525882683		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.1502503525882683 | validation: 0.11400938207450015]
	TIME [epoch: 6.55 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15223634075096948		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.15223634075096948 | validation: 0.11437169237675864]
	TIME [epoch: 6.56 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522329014876654		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.1522329014876654 | validation: 0.1193564697837828]
	TIME [epoch: 6.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14928193213304286		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.14928193213304286 | validation: 0.1171226954795724]
	TIME [epoch: 6.53 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14765282899758977		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.14765282899758977 | validation: 0.12580064191354728]
	TIME [epoch: 6.55 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14963144450972077		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.14963144450972077 | validation: 0.11961416534999392]
	TIME [epoch: 6.57 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516185062140235		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.1516185062140235 | validation: 0.12374476609720889]
	TIME [epoch: 6.55 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14936747903927391		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.14936747903927391 | validation: 0.11733421351041766]
	TIME [epoch: 6.59 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503692968244945		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.1503692968244945 | validation: 0.1165012725210594]
	TIME [epoch: 6.56 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14825175252245518		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.14825175252245518 | validation: 0.11266410188190172]
	TIME [epoch: 6.49 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14931375420269422		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.14931375420269422 | validation: 0.11332298105287004]
	TIME [epoch: 6.56 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14865285015063268		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.14865285015063268 | validation: 0.11762422131730726]
	TIME [epoch: 6.55 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14729802175639592		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.14729802175639592 | validation: 0.1184897599642176]
	TIME [epoch: 6.56 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14566109567189534		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.14566109567189534 | validation: 0.13131472128893557]
	TIME [epoch: 6.55 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14930362964673458		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.14930362964673458 | validation: 0.1280248388516411]
	TIME [epoch: 6.55 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15426039242499962		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.15426039242499962 | validation: 0.11531070255475397]
	TIME [epoch: 6.49 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15088213356101537		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.15088213356101537 | validation: 0.11538030899529275]
	TIME [epoch: 6.56 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1534252167837174		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.1534252167837174 | validation: 0.12271169596747879]
	TIME [epoch: 6.55 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15028233751322173		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.15028233751322173 | validation: 0.11957791297801404]
	TIME [epoch: 6.54 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.148112580445276		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.148112580445276 | validation: 0.12187517559323005]
	TIME [epoch: 6.56 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15228436713421903		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.15228436713421903 | validation: 0.12913613031287222]
	TIME [epoch: 6.54 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14809512326551427		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.14809512326551427 | validation: 0.1243038938745335]
	TIME [epoch: 6.54 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14974977001607478		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.14974977001607478 | validation: 0.13142026057315861]
	TIME [epoch: 6.54 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1523098182889977		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.1523098182889977 | validation: 0.12391256184418513]
	TIME [epoch: 6.53 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15081447363219275		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.15081447363219275 | validation: 0.12419955881341757]
	TIME [epoch: 6.54 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471333334585805		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.1471333334585805 | validation: 0.12236351735163666]
	TIME [epoch: 6.56 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1489062556174583		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.1489062556174583 | validation: 0.1153665905388167]
	TIME [epoch: 6.54 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502698917547832		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.1502698917547832 | validation: 0.12132261230625804]
	TIME [epoch: 6.52 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1518661100452023		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.1518661100452023 | validation: 0.1246894456273416]
	TIME [epoch: 6.53 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521546409775249		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.1521546409775249 | validation: 0.12324192898506851]
	TIME [epoch: 6.55 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14931269792694118		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.14931269792694118 | validation: 0.1182670832964104]
	TIME [epoch: 6.53 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15151579889512679		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.15151579889512679 | validation: 0.12467480785475676]
	TIME [epoch: 6.53 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14901143266742287		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.14901143266742287 | validation: 0.13603694762098265]
	TIME [epoch: 6.54 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14962116194938263		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.14962116194938263 | validation: 0.1294135364261283]
	TIME [epoch: 6.56 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15088921091514185		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.15088921091514185 | validation: 0.1323301484013481]
	TIME [epoch: 6.56 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1522092816150839		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.1522092816150839 | validation: 0.13180120109839738]
	TIME [epoch: 6.49 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485911950970974		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.1485911950970974 | validation: 0.13489061683377027]
	TIME [epoch: 6.55 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1502922695905894		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.1502922695905894 | validation: 0.13925659449759928]
	TIME [epoch: 6.55 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15281330086167044		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.15281330086167044 | validation: 0.12481650825870944]
	TIME [epoch: 6.54 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15066519261543795		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.15066519261543795 | validation: 0.1301958873126287]
	TIME [epoch: 6.54 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15020380631829247		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.15020380631829247 | validation: 0.12237999415315307]
	TIME [epoch: 6.53 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1472192439025422		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.1472192439025422 | validation: 0.11612859667479562]
	TIME [epoch: 6.53 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15046999726531157		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.15046999726531157 | validation: 0.11547056094238965]
	TIME [epoch: 6.52 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14786027981350036		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.14786027981350036 | validation: 0.1213250506776183]
	TIME [epoch: 6.54 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14694942382883552		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.14694942382883552 | validation: 0.12588759505384853]
	TIME [epoch: 6.55 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1493883656281368		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.1493883656281368 | validation: 0.11979306212379584]
	TIME [epoch: 6.57 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15078676478572378		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.15078676478572378 | validation: 0.12487082862417744]
	TIME [epoch: 6.54 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14922238273501223		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.14922238273501223 | validation: 0.12012410080930291]
	TIME [epoch: 6.53 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14903750161122054		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.14903750161122054 | validation: 0.12120154794536747]
	TIME [epoch: 6.49 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482519371037756		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.1482519371037756 | validation: 0.13046377002579998]
	TIME [epoch: 6.52 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14928471911257438		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.14928471911257438 | validation: 0.13102657405730414]
	TIME [epoch: 6.53 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15059420662662076		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.15059420662662076 | validation: 0.13985013024692394]
	TIME [epoch: 6.55 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15107145650789774		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.15107145650789774 | validation: 0.12698325125875207]
	TIME [epoch: 6.57 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15148356135316193		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.15148356135316193 | validation: 0.1266934089713426]
	TIME [epoch: 6.54 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14849771055707822		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.14849771055707822 | validation: 0.12584256422930387]
	TIME [epoch: 6.54 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15070431335950973		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.15070431335950973 | validation: 0.1291396460959792]
	TIME [epoch: 6.5 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1532176462232568		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.1532176462232568 | validation: 0.12516815343064944]
	TIME [epoch: 6.53 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14828033243265779		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.14828033243265779 | validation: 0.11619444100632902]
	TIME [epoch: 6.54 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15111590447621132		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.15111590447621132 | validation: 0.11612329336273941]
	TIME [epoch: 6.55 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14598078218354135		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.14598078218354135 | validation: 0.11904219323879196]
	TIME [epoch: 6.53 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14882680271879575		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.14882680271879575 | validation: 0.12344324300288208]
	TIME [epoch: 6.54 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15035258289095346		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.15035258289095346 | validation: 0.11832296621855015]
	TIME [epoch: 6.55 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14970538330885175		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.14970538330885175 | validation: 0.12193014315225849]
	TIME [epoch: 6.54 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14845620384606475		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.14845620384606475 | validation: 0.132966517133362]
	TIME [epoch: 6.53 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15403674676798523		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.15403674676798523 | validation: 0.11961004638655919]
	TIME [epoch: 6.55 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15129104893782455		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.15129104893782455 | validation: 0.1159417775405224]
	TIME [epoch: 6.55 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15149194483091316		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.15149194483091316 | validation: 0.1085631812566756]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240310_003113/states/model_tr_study1_1962.pth
	Model improved!!!
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15083448755764103		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.15083448755764103 | validation: 0.11521128400616765]
	TIME [epoch: 6.54 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503765592562708		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.1503765592562708 | validation: 0.12691341766506653]
	TIME [epoch: 6.52 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1479958427852585		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.1479958427852585 | validation: 0.12630799846320834]
	TIME [epoch: 6.52 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15176898692448282		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.15176898692448282 | validation: 0.11508650818647813]
	TIME [epoch: 6.54 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14671605227215587		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.14671605227215587 | validation: 0.12461283417507757]
	TIME [epoch: 6.55 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15077033878246893		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.15077033878246893 | validation: 0.12077138367140432]
	TIME [epoch: 6.57 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14582856472292705		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.14582856472292705 | validation: 0.12857771344250116]
	TIME [epoch: 6.54 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15123506461675212		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.15123506461675212 | validation: 0.11933083908563032]
	TIME [epoch: 6.53 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15041360052861075		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.15041360052861075 | validation: 0.12075965920590893]
	TIME [epoch: 6.49 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14631943424607094		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.14631943424607094 | validation: 0.11798897973776538]
	TIME [epoch: 6.53 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1547621240143951		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.1547621240143951 | validation: 0.12499221353774928]
	TIME [epoch: 6.53 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14984413131276866		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.14984413131276866 | validation: 0.11464653489188724]
	TIME [epoch: 6.54 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14864295000310354		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.14864295000310354 | validation: 0.11925878847934149]
	TIME [epoch: 6.53 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14956143135709982		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.14956143135709982 | validation: 0.11998741402122672]
	TIME [epoch: 6.52 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14915023390008167		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.14915023390008167 | validation: 0.11844918541275937]
	TIME [epoch: 6.57 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14657739857656876		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.14657739857656876 | validation: 0.12344300633742311]
	TIME [epoch: 6.54 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14742747895740474		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.14742747895740474 | validation: 0.11839887822427128]
	TIME [epoch: 6.48 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14800394387581947		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.14800394387581947 | validation: 0.12579070728819372]
	TIME [epoch: 6.54 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15105005553981063		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.15105005553981063 | validation: 0.11540460788014581]
	TIME [epoch: 6.56 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1465445183550528		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.1465445183550528 | validation: 0.12210259259499495]
	TIME [epoch: 6.53 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15201945916197637		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.15201945916197637 | validation: 0.11720888248536969]
	TIME [epoch: 6.48 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1471473210715063		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.1471473210715063 | validation: 0.12864897701254793]
	TIME [epoch: 6.54 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1504311014543469		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.1504311014543469 | validation: 0.11984095937838893]
	TIME [epoch: 6.53 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1487697559191058		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.1487697559191058 | validation: 0.12600653497048106]
	TIME [epoch: 6.48 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15156805068109042		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.15156805068109042 | validation: 0.12464354967651488]
	TIME [epoch: 6.53 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15353813760028548		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.15353813760028548 | validation: 0.13467766842991538]
	TIME [epoch: 6.53 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14937915986145692		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.14937915986145692 | validation: 0.12035486524770588]
	TIME [epoch: 6.48 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1488261709359667		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.1488261709359667 | validation: 0.11926382478553917]
	TIME [epoch: 6.54 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14943445161318944		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.14943445161318944 | validation: 0.12450740259224936]
	TIME [epoch: 6.54 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14894158917213335		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.14894158917213335 | validation: 0.12655290405898798]
	TIME [epoch: 6.49 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14990160898149973		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.14990160898149973 | validation: 0.11636681559152684]
	TIME [epoch: 6.54 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15057338798266104		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.15057338798266104 | validation: 0.11727304193529879]
	TIME [epoch: 6.55 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14862050600111057		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.14862050600111057 | validation: 0.11343855677427182]
	TIME [epoch: 6.54 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14905247085784668		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.14905247085784668 | validation: 0.11511086702009869]
	TIME [epoch: 6.56 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15368014024952562		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.15368014024952562 | validation: 0.11710414788420907]
	TIME [epoch: 6.56 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1510985693063201		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.1510985693063201 | validation: 0.11779477202804611]
	TIME [epoch: 6.54 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14818462613163097		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.14818462613163097 | validation: 0.11958736686156513]
	TIME [epoch: 6.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1515677897996323		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.1515677897996323 | validation: 0.11606726291908175]
	TIME [epoch: 6.53 sec]
Finished training in 13416.902 seconds.
