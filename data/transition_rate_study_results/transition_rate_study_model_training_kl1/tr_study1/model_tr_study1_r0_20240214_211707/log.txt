Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r0', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2176539041

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/20] avg loss: 9.809616761413947		[learning rate: 0.01]
		[batch 20/20] avg loss: 8.2327629790811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.021189870247522 | validation: 7.392004492768195]
	TIME [epoch: 48.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/20] avg loss: 6.937563744051133		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.800455739845442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.869009741948287 | validation: 6.274064625289521]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/20] avg loss: 6.556581847436559		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.120754855520345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.338668351478452 | validation: 6.292060365528291]
	TIME [epoch: 8.9 sec]
EPOCH 4/500:
	Training over batches...
		[batch 10/20] avg loss: 6.145359419739583		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.530283918912841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.337821669326212 | validation: 6.203858474698346]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/20] avg loss: 6.3546460654099155		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.2369708958354675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.295808480622691 | validation: 6.317178547258716]
	TIME [epoch: 8.87 sec]
EPOCH 6/500:
	Training over batches...
		[batch 10/20] avg loss: 6.2653586881317205		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.1173182042402825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.191338446186001 | validation: 6.089669005956836]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/20] avg loss: 6.191659654325393		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.862046956292959		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.026853305309174 | validation: 5.983431837320342]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 10/20] avg loss: 6.184423088933159		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.907975982883795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.046199535908476 | validation: 6.065543437522668]
	TIME [epoch: 8.84 sec]
EPOCH 9/500:
	Training over batches...
		[batch 10/20] avg loss: 5.863775863761177		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.034914125998555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.949344994879866 | validation: 5.8767461421587734]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/20] avg loss: 5.921359591782702		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.895163344813364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.908261468298033 | validation: 6.02927674151863]
	TIME [epoch: 8.83 sec]
EPOCH 11/500:
	Training over batches...
		[batch 10/20] avg loss: 6.055823835419508		[learning rate: 0.0099789]
		[batch 20/20] avg loss: 5.699454341350853		[learning rate: 0.0099555]
	Learning Rate: 0.00995546
	LOSS [training: 5.877639088385181 | validation: 5.833393589487922]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/20] avg loss: 5.846554996397768		[learning rate: 0.0099321]
		[batch 20/20] avg loss: 5.919722291965327		[learning rate: 0.0099088]
	Learning Rate: 0.00990879
	LOSS [training: 5.883138644181549 | validation: 5.900715750998863]
	TIME [epoch: 8.89 sec]
EPOCH 13/500:
	Training over batches...
		[batch 10/20] avg loss: 5.920795079292775		[learning rate: 0.0098855]
		[batch 20/20] avg loss: 5.800130768384561		[learning rate: 0.0098623]
	Learning Rate: 0.00986233
	LOSS [training: 5.860462923838669 | validation: 5.828994664734769]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 10/20] avg loss: 5.791731274108683		[learning rate: 0.0098392]
		[batch 20/20] avg loss: 5.909113326088063		[learning rate: 0.0098161]
	Learning Rate: 0.0098161
	LOSS [training: 5.850422300098375 | validation: 5.780211218226564]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 10/20] avg loss: 5.708693559839693		[learning rate: 0.0097931]
		[batch 20/20] avg loss: 5.916382159909338		[learning rate: 0.0097701]
	Learning Rate: 0.00977008
	LOSS [training: 5.8125378598745145 | validation: 6.126235530366854]
	TIME [epoch: 8.9 sec]
EPOCH 16/500:
	Training over batches...
		[batch 10/20] avg loss: 5.862646120804475		[learning rate: 0.0097471]
		[batch 20/20] avg loss: 5.833870507424626		[learning rate: 0.0097243]
	Learning Rate: 0.00972427
	LOSS [training: 5.84825831411455 | validation: 5.893953464022118]
	TIME [epoch: 8.89 sec]
EPOCH 17/500:
	Training over batches...
		[batch 10/20] avg loss: 6.045770821697076		[learning rate: 0.0097015]
		[batch 20/20] avg loss: 5.6464978435286355		[learning rate: 0.0096787]
	Learning Rate: 0.00967868
	LOSS [training: 5.846134332612855 | validation: 5.76663278867645]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 10/20] avg loss: 5.879897618800436		[learning rate: 0.009656]
		[batch 20/20] avg loss: 5.8827449340015425		[learning rate: 0.0096333]
	Learning Rate: 0.00963331
	LOSS [training: 5.881321276400991 | validation: 5.847947887729072]
	TIME [epoch: 8.88 sec]
EPOCH 19/500:
	Training over batches...
		[batch 10/20] avg loss: 5.950408906313324		[learning rate: 0.0096107]
		[batch 20/20] avg loss: 5.78162291730694		[learning rate: 0.0095881]
	Learning Rate: 0.00958815
	LOSS [training: 5.866015911810132 | validation: 5.833373924461928]
	TIME [epoch: 8.89 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/20] avg loss: 6.050687128105624		[learning rate: 0.0095656]
		[batch 20/20] avg loss: 5.560632964094166		[learning rate: 0.0095432]
	Learning Rate: 0.0095432
	LOSS [training: 5.805660046099895 | validation: 6.108707506069349]
	TIME [epoch: 8.87 sec]
EPOCH 21/500:
	Training over batches...
		[batch 10/20] avg loss: 5.942077854643044		[learning rate: 0.0095208]
		[batch 20/20] avg loss: 5.655450397046149		[learning rate: 0.0094985]
	Learning Rate: 0.00949846
	LOSS [training: 5.7987641258445946 | validation: 6.095359212883613]
	TIME [epoch: 8.86 sec]
EPOCH 22/500:
	Training over batches...
		[batch 10/20] avg loss: 5.75123600829533		[learning rate: 0.0094762]
		[batch 20/20] avg loss: 5.911747918121916		[learning rate: 0.0094539]
	Learning Rate: 0.00945393
	LOSS [training: 5.831491963208624 | validation: 5.867343652033547]
	TIME [epoch: 8.85 sec]
EPOCH 23/500:
	Training over batches...
		[batch 10/20] avg loss: 5.762842495046998		[learning rate: 0.0094317]
		[batch 20/20] avg loss: 5.8919158919624675		[learning rate: 0.0094096]
	Learning Rate: 0.00940961
	LOSS [training: 5.827379193504734 | validation: 5.828343844173864]
	TIME [epoch: 8.86 sec]
EPOCH 24/500:
	Training over batches...
		[batch 10/20] avg loss: 5.918229023240975		[learning rate: 0.0093875]
		[batch 20/20] avg loss: 5.768395629392848		[learning rate: 0.0093655]
	Learning Rate: 0.00936549
	LOSS [training: 5.843312326316912 | validation: 5.848259880499271]
	TIME [epoch: 8.88 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/20] avg loss: 5.667950587468061		[learning rate: 0.0093435]
		[batch 20/20] avg loss: 6.019669320768859		[learning rate: 0.0093216]
	Learning Rate: 0.00932159
	LOSS [training: 5.843809954118461 | validation: 5.810847810992159]
	TIME [epoch: 8.86 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/20] avg loss: 5.716986978276536		[learning rate: 0.0092997]
		[batch 20/20] avg loss: 5.9166858891639595		[learning rate: 0.0092779]
	Learning Rate: 0.00927788
	LOSS [training: 5.816836433720248 | validation: 5.8761382779165245]
	TIME [epoch: 8.86 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/20] avg loss: 5.8862961439196155		[learning rate: 0.0092561]
		[batch 20/20] avg loss: 5.780822650205433		[learning rate: 0.0092344]
	Learning Rate: 0.00923439
	LOSS [training: 5.833559397062524 | validation: 6.009440281150545]
	TIME [epoch: 8.86 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/20] avg loss: 5.647747027491552		[learning rate: 0.0092127]
		[batch 20/20] avg loss: 5.99334465077843		[learning rate: 0.0091911]
	Learning Rate: 0.0091911
	LOSS [training: 5.820545839134991 | validation: 5.837206730869843]
	TIME [epoch: 8.88 sec]
EPOCH 29/500:
	Training over batches...
		[batch 10/20] avg loss: 6.053049352829763		[learning rate: 0.0091695]
		[batch 20/20] avg loss: 5.602859611205902		[learning rate: 0.009148]
	Learning Rate: 0.00914801
	LOSS [training: 5.827954482017832 | validation: 5.767910420167977]
	TIME [epoch: 8.87 sec]
EPOCH 30/500:
	Training over batches...
		[batch 10/20] avg loss: 5.5375727040566485		[learning rate: 0.0091265]
		[batch 20/20] avg loss: 6.080280672878316		[learning rate: 0.0091051]
	Learning Rate: 0.00910512
	LOSS [training: 5.808926688467481 | validation: 5.779135189591056]
	TIME [epoch: 8.86 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/20] avg loss: 5.850876013577128		[learning rate: 0.0090838]
		[batch 20/20] avg loss: 5.730538679118873		[learning rate: 0.0090624]
	Learning Rate: 0.00906243
	LOSS [training: 5.790707346348002 | validation: 5.880859411143143]
	TIME [epoch: 8.86 sec]
EPOCH 32/500:
	Training over batches...
		[batch 10/20] avg loss: 5.764282565173529		[learning rate: 0.0090412]
		[batch 20/20] avg loss: 5.763427956339271		[learning rate: 0.0090199]
	Learning Rate: 0.00901995
	LOSS [training: 5.7638552607564 | validation: 5.805097263978932]
	TIME [epoch: 8.87 sec]
EPOCH 33/500:
	Training over batches...
		[batch 10/20] avg loss: 5.687061903998288		[learning rate: 0.0089988]
		[batch 20/20] avg loss: 5.886641478561734		[learning rate: 0.0089777]
	Learning Rate: 0.00897766
	LOSS [training: 5.786851691280011 | validation: 5.755280344553403]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 10/20] avg loss: 5.674203778050254		[learning rate: 0.0089566]
		[batch 20/20] avg loss: 5.976175657536959		[learning rate: 0.0089356]
	Learning Rate: 0.00893557
	LOSS [training: 5.825189717793607 | validation: 5.873212502473031]
	TIME [epoch: 8.85 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/20] avg loss: 5.7116922794943035		[learning rate: 0.0089146]
		[batch 20/20] avg loss: 5.965856460011284		[learning rate: 0.0088937]
	Learning Rate: 0.00889368
	LOSS [training: 5.838774369752793 | validation: 5.843348277695033]
	TIME [epoch: 8.84 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/20] avg loss: 5.61095904782386		[learning rate: 0.0088728]
		[batch 20/20] avg loss: 6.014521502127098		[learning rate: 0.008852]
	Learning Rate: 0.00885199
	LOSS [training: 5.812740274975478 | validation: 5.770762671506986]
	TIME [epoch: 8.85 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/20] avg loss: 5.766668528023927		[learning rate: 0.0088312]
		[batch 20/20] avg loss: 5.871313340004864		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 5.818990934014396 | validation: 5.7365595517380585]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 10/20] avg loss: 5.789093990905409		[learning rate: 0.0087898]
		[batch 20/20] avg loss: 5.758231824732851		[learning rate: 0.0087692]
	Learning Rate: 0.00876918
	LOSS [training: 5.773662907819131 | validation: 5.94529788898798]
	TIME [epoch: 8.86 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/20] avg loss: 5.8348058332054915		[learning rate: 0.0087486]
		[batch 20/20] avg loss: 5.723200515728269		[learning rate: 0.0087281]
	Learning Rate: 0.00872807
	LOSS [training: 5.779003174466881 | validation: 5.783373056747998]
	TIME [epoch: 8.85 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/20] avg loss: 5.972000180924928		[learning rate: 0.0087076]
		[batch 20/20] avg loss: 5.646421009852699		[learning rate: 0.0086872]
	Learning Rate: 0.00868715
	LOSS [training: 5.809210595388813 | validation: 5.801583330487841]
	TIME [epoch: 8.85 sec]
EPOCH 41/500:
	Training over batches...
		[batch 10/20] avg loss: 5.570821314064587		[learning rate: 0.0086668]
		[batch 20/20] avg loss: 6.066377360586706		[learning rate: 0.0086464]
	Learning Rate: 0.00864643
	LOSS [training: 5.818599337325648 | validation: 6.018827593853046]
	TIME [epoch: 8.87 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/20] avg loss: 5.723429050451936		[learning rate: 0.0086261]
		[batch 20/20] avg loss: 5.882449309895134		[learning rate: 0.0086059]
	Learning Rate: 0.00860589
	LOSS [training: 5.802939180173534 | validation: 5.747037767085603]
	TIME [epoch: 8.85 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/20] avg loss: 5.822282083258182		[learning rate: 0.0085857]
		[batch 20/20] avg loss: 5.70590895747606		[learning rate: 0.0085655]
	Learning Rate: 0.00856555
	LOSS [training: 5.764095520367121 | validation: 5.7994302773846815]
	TIME [epoch: 8.85 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/20] avg loss: 5.778738815118906		[learning rate: 0.0085454]
		[batch 20/20] avg loss: 5.755550240638426		[learning rate: 0.0085254]
	Learning Rate: 0.00852539
	LOSS [training: 5.767144527878665 | validation: 5.72465809715842]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_44.pth
	Model improved!!!
EPOCH 45/500:
	Training over batches...
		[batch 10/20] avg loss: 5.850121244416945		[learning rate: 0.0085054]
		[batch 20/20] avg loss: 5.700841933847144		[learning rate: 0.0084854]
	Learning Rate: 0.00848542
	LOSS [training: 5.7754815891320455 | validation: 5.934244041583576]
	TIME [epoch: 8.87 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/20] avg loss: 5.784793556072726		[learning rate: 0.0084655]
		[batch 20/20] avg loss: 5.780813162563762		[learning rate: 0.0084456]
	Learning Rate: 0.00844564
	LOSS [training: 5.782803359318244 | validation: 5.818314167216041]
	TIME [epoch: 8.85 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/20] avg loss: 5.777380445143842		[learning rate: 0.0084258]
		[batch 20/20] avg loss: 5.723203654060798		[learning rate: 0.008406]
	Learning Rate: 0.00840605
	LOSS [training: 5.75029204960232 | validation: 5.787902182564701]
	TIME [epoch: 8.85 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/20] avg loss: 5.80174267119269		[learning rate: 0.0083863]
		[batch 20/20] avg loss: 5.744454144510164		[learning rate: 0.0083666]
	Learning Rate: 0.00836664
	LOSS [training: 5.7730984078514265 | validation: 5.777582916577462]
	TIME [epoch: 8.84 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/20] avg loss: 5.7107682897557766		[learning rate: 0.008347]
		[batch 20/20] avg loss: 5.8110327552203955		[learning rate: 0.0083274]
	Learning Rate: 0.00832742
	LOSS [training: 5.760900522488086 | validation: 5.852678377522192]
	TIME [epoch: 8.85 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/20] avg loss: 5.869791692415433		[learning rate: 0.0083079]
		[batch 20/20] avg loss: 5.7155300345642575		[learning rate: 0.0082884]
	Learning Rate: 0.00828838
	LOSS [training: 5.7926608634898455 | validation: 5.854604517949843]
	TIME [epoch: 8.86 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/20] avg loss: 5.692032000554705		[learning rate: 0.0082689]
		[batch 20/20] avg loss: 5.8083777255355695		[learning rate: 0.0082495]
	Learning Rate: 0.00824952
	LOSS [training: 5.750204863045136 | validation: 5.741536981451298]
	TIME [epoch: 8.85 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/20] avg loss: 5.811067790345742		[learning rate: 0.0082302]
		[batch 20/20] avg loss: 5.640965257723126		[learning rate: 0.0082108]
	Learning Rate: 0.00821084
	LOSS [training: 5.726016524034433 | validation: 5.698308722077938]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 10/20] avg loss: 5.573555760335713		[learning rate: 0.0081916]
		[batch 20/20] avg loss: 6.220453693347833		[learning rate: 0.0081723]
	Learning Rate: 0.00817235
	LOSS [training: 5.897004726841774 | validation: 5.94563703357866]
	TIME [epoch: 8.86 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/20] avg loss: 5.534974486693638		[learning rate: 0.0081532]
		[batch 20/20] avg loss: 5.99156975815768		[learning rate: 0.008134]
	Learning Rate: 0.00813404
	LOSS [training: 5.76327212242566 | validation: 5.7396269823115755]
	TIME [epoch: 8.88 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/20] avg loss: 5.460009045092839		[learning rate: 0.0081149]
		[batch 20/20] avg loss: 6.014142513645347		[learning rate: 0.0080959]
	Learning Rate: 0.0080959
	LOSS [training: 5.737075779369094 | validation: 5.726784430337167]
	TIME [epoch: 8.86 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/20] avg loss: 5.451242119252842		[learning rate: 0.0080769]
		[batch 20/20] avg loss: 6.052486786319126		[learning rate: 0.0080579]
	Learning Rate: 0.00805795
	LOSS [training: 5.751864452785984 | validation: 5.716619209259894]
	TIME [epoch: 8.85 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/20] avg loss: 5.55739943722035		[learning rate: 0.008039]
		[batch 20/20] avg loss: 5.900983960575415		[learning rate: 0.0080202]
	Learning Rate: 0.00802017
	LOSS [training: 5.729191698897883 | validation: 5.746357477482092]
	TIME [epoch: 8.85 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/20] avg loss: 5.900170444515845		[learning rate: 0.0080013]
		[batch 20/20] avg loss: 5.551912216202664		[learning rate: 0.0079826]
	Learning Rate: 0.00798257
	LOSS [training: 5.726041330359256 | validation: 5.70210704556802]
	TIME [epoch: 8.88 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/20] avg loss: 5.708937436959114		[learning rate: 0.0079638]
		[batch 20/20] avg loss: 5.800494296054844		[learning rate: 0.0079451]
	Learning Rate: 0.00794515
	LOSS [training: 5.754715866506979 | validation: 5.733228426324507]
	TIME [epoch: 8.86 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/20] avg loss: 5.724928035066074		[learning rate: 0.0079265]
		[batch 20/20] avg loss: 5.70908805331516		[learning rate: 0.0079079]
	Learning Rate: 0.0079079
	LOSS [training: 5.717008044190616 | validation: 5.960199677209439]
	TIME [epoch: 8.85 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/20] avg loss: 5.7615634260572985		[learning rate: 0.0078893]
		[batch 20/20] avg loss: 5.684477847339592		[learning rate: 0.0078708]
	Learning Rate: 0.00787083
	LOSS [training: 5.723020636698447 | validation: 5.9667985332490865]
	TIME [epoch: 8.86 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/20] avg loss: 5.855647877920501		[learning rate: 0.0078524]
		[batch 20/20] avg loss: 5.617494994522581		[learning rate: 0.0078339]
	Learning Rate: 0.00783393
	LOSS [training: 5.736571436221541 | validation: 5.726357203675674]
	TIME [epoch: 8.88 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/20] avg loss: 5.51273757424708		[learning rate: 0.0078155]
		[batch 20/20] avg loss: 5.857263031834415		[learning rate: 0.0077972]
	Learning Rate: 0.0077972
	LOSS [training: 5.685000303040747 | validation: 5.857519927778327]
	TIME [epoch: 8.86 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/20] avg loss: 5.6707183840713515		[learning rate: 0.0077789]
		[batch 20/20] avg loss: 5.730490314988275		[learning rate: 0.0077606]
	Learning Rate: 0.00776065
	LOSS [training: 5.7006043495298115 | validation: 5.635176014684443]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 10/20] avg loss: 5.378780513171065		[learning rate: 0.0077424]
		[batch 20/20] avg loss: 5.867450740155421		[learning rate: 0.0077243]
	Learning Rate: 0.00772426
	LOSS [training: 5.623115626663243 | validation: 5.5785547305505805]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 10/20] avg loss: 5.512557955332563		[learning rate: 0.0077061]
		[batch 20/20] avg loss: 5.291752616193584		[learning rate: 0.0076881]
	Learning Rate: 0.00768805
	LOSS [training: 5.402155285763074 | validation: 5.183664042637429]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_66.pth
	Model improved!!!
EPOCH 67/500:
	Training over batches...
		[batch 10/20] avg loss: 5.057953833180885		[learning rate: 0.00767]
		[batch 20/20] avg loss: 3.9293314127656807		[learning rate: 0.007652]
	Learning Rate: 0.00765201
	LOSS [training: 4.493642622973283 | validation: 3.53043785440107]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_67.pth
	Model improved!!!
EPOCH 68/500:
	Training over batches...
		[batch 10/20] avg loss: 3.6867493813512966		[learning rate: 0.0076341]
		[batch 20/20] avg loss: 3.5430636038525636		[learning rate: 0.0076161]
	Learning Rate: 0.00761614
	LOSS [training: 3.61490649260193 | validation: 3.4332691250011544]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_68.pth
	Model improved!!!
EPOCH 69/500:
	Training over batches...
		[batch 10/20] avg loss: 3.788726322649822		[learning rate: 0.0075983]
		[batch 20/20] avg loss: 3.7025173608120645		[learning rate: 0.0075804]
	Learning Rate: 0.00758043
	LOSS [training: 3.7456218417309435 | validation: 3.4491306082397877]
	TIME [epoch: 8.85 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/20] avg loss: 3.573705802475446		[learning rate: 0.0075626]
		[batch 20/20] avg loss: 3.852219876368406		[learning rate: 0.0075449]
	Learning Rate: 0.00754489
	LOSS [training: 3.7129628394219254 | validation: 3.620188535672743]
	TIME [epoch: 8.84 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/20] avg loss: 3.6558870673403456		[learning rate: 0.0075272]
		[batch 20/20] avg loss: 3.5827761982875304		[learning rate: 0.0075095]
	Learning Rate: 0.00750952
	LOSS [training: 3.619331632813938 | validation: 3.5245726584497388]
	TIME [epoch: 8.87 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/20] avg loss: 3.7294829102422744		[learning rate: 0.0074919]
		[batch 20/20] avg loss: 3.6469480697077143		[learning rate: 0.0074743]
	Learning Rate: 0.00747431
	LOSS [training: 3.6882154899749944 | validation: 3.4584044071127544]
	TIME [epoch: 8.85 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/20] avg loss: 3.5738096080158086		[learning rate: 0.0074568]
		[batch 20/20] avg loss: 3.794331360231041		[learning rate: 0.0074393]
	Learning Rate: 0.00743927
	LOSS [training: 3.6840704841234255 | validation: 3.478454122746625]
	TIME [epoch: 8.84 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/20] avg loss: 3.657520546431509		[learning rate: 0.0074218]
		[batch 20/20] avg loss: 3.7940407276438664		[learning rate: 0.0074044]
	Learning Rate: 0.0074044
	LOSS [training: 3.725780637037687 | validation: 3.697941177329635]
	TIME [epoch: 8.84 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/20] avg loss: 3.707674994450021		[learning rate: 0.007387]
		[batch 20/20] avg loss: 3.4276646275919234		[learning rate: 0.0073697]
	Learning Rate: 0.00736969
	LOSS [training: 3.5676698110209712 | validation: 3.6005272854233836]
	TIME [epoch: 8.86 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/20] avg loss: 3.4561815628273864		[learning rate: 0.0073524]
		[batch 20/20] avg loss: 3.5473123552043546		[learning rate: 0.0073351]
	Learning Rate: 0.00733514
	LOSS [training: 3.501746959015871 | validation: 3.2183033348469223]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_76.pth
	Model improved!!!
EPOCH 77/500:
	Training over batches...
		[batch 10/20] avg loss: 3.4062128521693915		[learning rate: 0.0073179]
		[batch 20/20] avg loss: 3.3356709943004255		[learning rate: 0.0073007]
	Learning Rate: 0.00730075
	LOSS [training: 3.3709419232349083 | validation: 3.3186802994306395]
	TIME [epoch: 8.84 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/20] avg loss: 3.0546265289269483		[learning rate: 0.0072836]
		[batch 20/20] avg loss: 3.1549988113868337		[learning rate: 0.0072665]
	Learning Rate: 0.00726652
	LOSS [training: 3.104812670156891 | validation: 3.154584991512948]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_78.pth
	Model improved!!!
EPOCH 79/500:
	Training over batches...
		[batch 10/20] avg loss: 2.7605553201141673		[learning rate: 0.0072495]
		[batch 20/20] avg loss: 1.6696947866960514		[learning rate: 0.0072325]
	Learning Rate: 0.00723246
	LOSS [training: 2.215125053405109 | validation: 1.3829026777391382]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 10/20] avg loss: 1.293588247730543		[learning rate: 0.0072155]
		[batch 20/20] avg loss: 1.1352920287759078		[learning rate: 0.0071985]
	Learning Rate: 0.00719855
	LOSS [training: 1.2144401382532255 | validation: 1.0789283856260328]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_80.pth
	Model improved!!!
EPOCH 81/500:
	Training over batches...
		[batch 10/20] avg loss: 1.120793043918164		[learning rate: 0.0071817]
		[batch 20/20] avg loss: 1.1857155799443675		[learning rate: 0.0071648]
	Learning Rate: 0.0071648
	LOSS [training: 1.1532543119312657 | validation: 1.0891429026626065]
	TIME [epoch: 8.85 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0833461675163227		[learning rate: 0.007148]
		[batch 20/20] avg loss: 1.0491559392316652		[learning rate: 0.0071312]
	Learning Rate: 0.00713121
	LOSS [training: 1.066251053373994 | validation: 0.7588438390386947]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_82.pth
	Model improved!!!
EPOCH 83/500:
	Training over batches...
		[batch 10/20] avg loss: 0.915039671459693		[learning rate: 0.0071145]
		[batch 20/20] avg loss: 1.028138879958632		[learning rate: 0.0070978]
	Learning Rate: 0.00709778
	LOSS [training: 0.9715892757091625 | validation: 1.1702506615205388]
	TIME [epoch: 8.86 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/20] avg loss: 0.981295042129857		[learning rate: 0.0070811]
		[batch 20/20] avg loss: 0.8845178266339788		[learning rate: 0.0070645]
	Learning Rate: 0.0070645
	LOSS [training: 0.9329064343819178 | validation: 0.9452612446417139]
	TIME [epoch: 8.87 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/20] avg loss: 0.839939802089113		[learning rate: 0.0070479]
		[batch 20/20] avg loss: 0.9884825324696921		[learning rate: 0.0070314]
	Learning Rate: 0.00703138
	LOSS [training: 0.9142111672794027 | validation: 0.8470257285099246]
	TIME [epoch: 8.84 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8561719359151903		[learning rate: 0.0070149]
		[batch 20/20] avg loss: 0.8344366775794899		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.8453043067473403 | validation: 0.698378702565456]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_86.pth
	Model improved!!!
EPOCH 87/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8386253248606526		[learning rate: 0.006982]
		[batch 20/20] avg loss: 0.830418688274615		[learning rate: 0.0069656]
	Learning Rate: 0.00696561
	LOSS [training: 0.8345220065676339 | validation: 0.8109529545547325]
	TIME [epoch: 8.84 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8169154570141787		[learning rate: 0.0069493]
		[batch 20/20] avg loss: 0.8098659673583427		[learning rate: 0.006933]
	Learning Rate: 0.00693295
	LOSS [training: 0.8133907121862608 | validation: 0.7720050941119094]
	TIME [epoch: 8.87 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/20] avg loss: 0.859266757558447		[learning rate: 0.0069167]
		[batch 20/20] avg loss: 0.7973197437660439		[learning rate: 0.0069005]
	Learning Rate: 0.00690045
	LOSS [training: 0.8282932506622454 | validation: 0.8440845814528691]
	TIME [epoch: 8.84 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7305801371656688		[learning rate: 0.0068843]
		[batch 20/20] avg loss: 0.8004216418920487		[learning rate: 0.0068681]
	Learning Rate: 0.0068681
	LOSS [training: 0.7655008895288586 | validation: 0.9354017519342155]
	TIME [epoch: 8.85 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/20] avg loss: 0.828054002850765		[learning rate: 0.006852]
		[batch 20/20] avg loss: 0.7922946004047465		[learning rate: 0.0068359]
	Learning Rate: 0.0068359
	LOSS [training: 0.8101743016277556 | validation: 0.8657812323565923]
	TIME [epoch: 8.84 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7616987044526399		[learning rate: 0.0068199]
		[batch 20/20] avg loss: 0.7407955742295282		[learning rate: 0.0068039]
	Learning Rate: 0.00680386
	LOSS [training: 0.751247139341084 | validation: 0.5801839855166571]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_92.pth
	Model improved!!!
EPOCH 93/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8328935197607713		[learning rate: 0.0067879]
		[batch 20/20] avg loss: 0.8118766398409741		[learning rate: 0.006772]
	Learning Rate: 0.00677196
	LOSS [training: 0.8223850798008726 | validation: 0.6577029092401814]
	TIME [epoch: 8.85 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7892104857323222		[learning rate: 0.0067561]
		[batch 20/20] avg loss: 0.8508550065729832		[learning rate: 0.0067402]
	Learning Rate: 0.00674021
	LOSS [training: 0.8200327461526526 | validation: 0.8153046712768993]
	TIME [epoch: 8.84 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7476358066073707		[learning rate: 0.0067244]
		[batch 20/20] avg loss: 0.766082277040717		[learning rate: 0.0067086]
	Learning Rate: 0.00670861
	LOSS [training: 0.7568590418240436 | validation: 0.8139621817640722]
	TIME [epoch: 8.84 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7122607908760764		[learning rate: 0.0066929]
		[batch 20/20] avg loss: 0.8042965840909844		[learning rate: 0.0066772]
	Learning Rate: 0.00667716
	LOSS [training: 0.7582786874835303 | validation: 0.6459343157411241]
	TIME [epoch: 8.86 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7794063760238317		[learning rate: 0.0066615]
		[batch 20/20] avg loss: 0.8033820578424663		[learning rate: 0.0066459]
	Learning Rate: 0.00664586
	LOSS [training: 0.7913942169331489 | validation: 0.7465199427694926]
	TIME [epoch: 8.84 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/20] avg loss: 0.835490386365222		[learning rate: 0.0066303]
		[batch 20/20] avg loss: 0.7156505172267795		[learning rate: 0.0066147]
	Learning Rate: 0.0066147
	LOSS [training: 0.7755704517960007 | validation: 0.86844476069012]
	TIME [epoch: 8.84 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6992752376240058		[learning rate: 0.0065992]
		[batch 20/20] avg loss: 0.7443245516212158		[learning rate: 0.0065837]
	Learning Rate: 0.00658369
	LOSS [training: 0.7217998946226108 | validation: 1.5719283123306225]
	TIME [epoch: 8.84 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8355483290368939		[learning rate: 0.0065682]
		[batch 20/20] avg loss: 0.7702202943332485		[learning rate: 0.0065528]
	Learning Rate: 0.00655282
	LOSS [training: 0.802884311685071 | validation: 0.7471437886675404]
	TIME [epoch: 8.85 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6527263074475296		[learning rate: 0.0065374]
		[batch 20/20] avg loss: 0.7778157515080799		[learning rate: 0.0065221]
	Learning Rate: 0.0065221
	LOSS [training: 0.7152710294778047 | validation: 0.9111510037527473]
	TIME [epoch: 8.87 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7643695083810937		[learning rate: 0.0065068]
		[batch 20/20] avg loss: 0.6852082638787426		[learning rate: 0.0064915]
	Learning Rate: 0.00649153
	LOSS [training: 0.7247888861299181 | validation: 0.5385792175886208]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_102.pth
	Model improved!!!
EPOCH 103/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7008405847392613		[learning rate: 0.0064763]
		[batch 20/20] avg loss: 0.6937377320122009		[learning rate: 0.0064611]
	Learning Rate: 0.0064611
	LOSS [training: 0.697289158375731 | validation: 0.6119320897755487]
	TIME [epoch: 8.87 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6406919936191557		[learning rate: 0.0064459]
		[batch 20/20] avg loss: 0.6470714615502003		[learning rate: 0.0064308]
	Learning Rate: 0.0064308
	LOSS [training: 0.6438817275846782 | validation: 0.5683033169334204]
	TIME [epoch: 8.87 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6200900688776311		[learning rate: 0.0064157]
		[batch 20/20] avg loss: 0.8370313288953062		[learning rate: 0.0064007]
	Learning Rate: 0.00640066
	LOSS [training: 0.7285606988864687 | validation: 0.5921895469157478]
	TIME [epoch: 8.9 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/20] avg loss: 0.618386824008181		[learning rate: 0.0063856]
		[batch 20/20] avg loss: 0.6914186188955901		[learning rate: 0.0063706]
	Learning Rate: 0.00637065
	LOSS [training: 0.6549027214518855 | validation: 0.5072329308037046]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_106.pth
	Model improved!!!
EPOCH 107/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6359695618551424		[learning rate: 0.0063557]
		[batch 20/20] avg loss: 0.7851104257524248		[learning rate: 0.0063408]
	Learning Rate: 0.00634078
	LOSS [training: 0.7105399938037836 | validation: 0.8521603188071073]
	TIME [epoch: 8.87 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6981594926070072		[learning rate: 0.0063259]
		[batch 20/20] avg loss: 0.6593782959891452		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.6787688942980761 | validation: 0.5603491284960238]
	TIME [epoch: 8.85 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/20] avg loss: 0.629750121674104		[learning rate: 0.0062962]
		[batch 20/20] avg loss: 0.6405010700553798		[learning rate: 0.0062815]
	Learning Rate: 0.00628147
	LOSS [training: 0.6351255958647419 | validation: 0.4825062464935526]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_109.pth
	Model improved!!!
EPOCH 110/500:
	Training over batches...
		[batch 10/20] avg loss: 0.888239224197347		[learning rate: 0.0062667]
		[batch 20/20] avg loss: 0.6324914123608023		[learning rate: 0.006252]
	Learning Rate: 0.00625202
	LOSS [training: 0.7603653182790746 | validation: 0.48149832530463815]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6776631989161271		[learning rate: 0.0062373]
		[batch 20/20] avg loss: 0.6655761245661884		[learning rate: 0.0062227]
	Learning Rate: 0.00622271
	LOSS [training: 0.6716196617411577 | validation: 0.47902863886329744]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_111.pth
	Model improved!!!
EPOCH 112/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6266713268913325		[learning rate: 0.0062081]
		[batch 20/20] avg loss: 0.9258866931141483		[learning rate: 0.0061935]
	Learning Rate: 0.00619354
	LOSS [training: 0.7762790100027405 | validation: 0.6568168816758942]
	TIME [epoch: 8.85 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6976373827674781		[learning rate: 0.006179]
		[batch 20/20] avg loss: 0.6122847236836726		[learning rate: 0.0061645]
	Learning Rate: 0.0061645
	LOSS [training: 0.6549610532255752 | validation: 0.7525729717543357]
	TIME [epoch: 8.87 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6076123372201272		[learning rate: 0.00615]
		[batch 20/20] avg loss: 0.6996129168383605		[learning rate: 0.0061356]
	Learning Rate: 0.0061356
	LOSS [training: 0.6536126270292438 | validation: 0.8726698839997732]
	TIME [epoch: 8.85 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7324147891065089		[learning rate: 0.0061212]
		[batch 20/20] avg loss: 0.6148368947623388		[learning rate: 0.0061068]
	Learning Rate: 0.00610684
	LOSS [training: 0.6736258419344239 | validation: 0.4792534855233654]
	TIME [epoch: 8.85 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/20] avg loss: 0.527982785541579		[learning rate: 0.0060925]
		[batch 20/20] avg loss: 0.5759326889115607		[learning rate: 0.0060782]
	Learning Rate: 0.00607821
	LOSS [training: 0.5519577372265697 | validation: 0.5320339811291483]
	TIME [epoch: 8.84 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/20] avg loss: 0.605369272385084		[learning rate: 0.0060639]
		[batch 20/20] avg loss: 0.5749813627032146		[learning rate: 0.0060497]
	Learning Rate: 0.00604971
	LOSS [training: 0.5901753175441493 | validation: 0.5325976372243584]
	TIME [epoch: 8.85 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5317784050757683		[learning rate: 0.0060355]
		[batch 20/20] avg loss: 0.6106038048528954		[learning rate: 0.0060213]
	Learning Rate: 0.00602135
	LOSS [training: 0.5711911049643319 | validation: 0.5114468663689411]
	TIME [epoch: 8.86 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6297327128990593		[learning rate: 0.0060072]
		[batch 20/20] avg loss: 0.6477915237598617		[learning rate: 0.0059931]
	Learning Rate: 0.00599312
	LOSS [training: 0.6387621183294606 | validation: 0.520571181964959]
	TIME [epoch: 8.85 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5608707419362856		[learning rate: 0.0059791]
		[batch 20/20] avg loss: 0.7157680770433515		[learning rate: 0.005965]
	Learning Rate: 0.00596502
	LOSS [training: 0.6383194094898186 | validation: 0.5654315480305447]
	TIME [epoch: 8.85 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5146657878000966		[learning rate: 0.005951]
		[batch 20/20] avg loss: 0.5453368691059042		[learning rate: 0.0059371]
	Learning Rate: 0.00593706
	LOSS [training: 0.5300013284530005 | validation: 0.8628059123792478]
	TIME [epoch: 8.84 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/20] avg loss: 0.545275984466896		[learning rate: 0.0059231]
		[batch 20/20] avg loss: 0.6671207890846615		[learning rate: 0.0059092]
	Learning Rate: 0.00590923
	LOSS [training: 0.6061983867757788 | validation: 0.9381248092330161]
	TIME [epoch: 8.87 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/20] avg loss: 0.557673492539518		[learning rate: 0.0058954]
		[batch 20/20] avg loss: 0.53928142627868		[learning rate: 0.0058815]
	Learning Rate: 0.00588152
	LOSS [training: 0.5484774594090991 | validation: 0.6119319160889845]
	TIME [epoch: 8.84 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5562538141506129		[learning rate: 0.0058677]
		[batch 20/20] avg loss: 0.5063265439640068		[learning rate: 0.0058539]
	Learning Rate: 0.00585395
	LOSS [training: 0.5312901790573099 | validation: 0.5265229024878623]
	TIME [epoch: 8.84 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6712966976486051		[learning rate: 0.0058402]
		[batch 20/20] avg loss: 0.6009107968254784		[learning rate: 0.0058265]
	Learning Rate: 0.00582651
	LOSS [training: 0.6361037472370417 | validation: 0.727299904165797]
	TIME [epoch: 8.84 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/20] avg loss: 0.616307428988804		[learning rate: 0.0058128]
		[batch 20/20] avg loss: 0.5000469128438397		[learning rate: 0.0057992]
	Learning Rate: 0.00579919
	LOSS [training: 0.5581771709163219 | validation: 0.5848837252785988]
	TIME [epoch: 8.87 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5672778971822916		[learning rate: 0.0057856]
		[batch 20/20] avg loss: 0.5639771163521904		[learning rate: 0.005772]
	Learning Rate: 0.005772
	LOSS [training: 0.565627506767241 | validation: 0.5150184187822845]
	TIME [epoch: 8.85 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6523241268727655		[learning rate: 0.0057585]
		[batch 20/20] avg loss: 0.46032032231256076		[learning rate: 0.0057449]
	Learning Rate: 0.00574494
	LOSS [training: 0.5563222245926631 | validation: 0.38099794506915213]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_128.pth
	Model improved!!!
EPOCH 129/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5321516057231543		[learning rate: 0.0057315]
		[batch 20/20] avg loss: 0.517120543442825		[learning rate: 0.005718]
	Learning Rate: 0.00571801
	LOSS [training: 0.5246360745829896 | validation: 1.347075301340816]
	TIME [epoch: 8.84 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6800854153510402		[learning rate: 0.0057046]
		[batch 20/20] avg loss: 0.4283130549295436		[learning rate: 0.0056912]
	Learning Rate: 0.0056912
	LOSS [training: 0.554199235140292 | validation: 0.327659153721488]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_130.pth
	Model improved!!!
EPOCH 131/500:
	Training over batches...
		[batch 10/20] avg loss: 0.45783116061643037		[learning rate: 0.0056778]
		[batch 20/20] avg loss: 0.573621804266399		[learning rate: 0.0056645]
	Learning Rate: 0.00566452
	LOSS [training: 0.5157264824414147 | validation: 0.42386837417029866]
	TIME [epoch: 8.87 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44221056047745144		[learning rate: 0.0056512]
		[batch 20/20] avg loss: 0.5943692755173522		[learning rate: 0.005638]
	Learning Rate: 0.00563797
	LOSS [training: 0.5182899179974018 | validation: 0.5064766567367411]
	TIME [epoch: 8.86 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/20] avg loss: 0.446034658302633		[learning rate: 0.0056247]
		[batch 20/20] avg loss: 0.46662753449342514		[learning rate: 0.0056115]
	Learning Rate: 0.00561153
	LOSS [training: 0.45633109639802905 | validation: 0.24124952396227434]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_133.pth
	Model improved!!!
EPOCH 134/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4954888222601297		[learning rate: 0.0055984]
		[batch 20/20] avg loss: 0.46795968163306584		[learning rate: 0.0055852]
	Learning Rate: 0.00558523
	LOSS [training: 0.48172425194659774 | validation: 0.2987927067189359]
	TIME [epoch: 8.86 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3853143085961552		[learning rate: 0.0055721]
		[batch 20/20] avg loss: 0.5357952327441241		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.46055477067013967 | validation: 0.36422130110086975]
	TIME [epoch: 8.88 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4589969914971423		[learning rate: 0.005546]
		[batch 20/20] avg loss: 0.41416813118987894		[learning rate: 0.005533]
	Learning Rate: 0.00553298
	LOSS [training: 0.43658256134351064 | validation: 0.5214032320523893]
	TIME [epoch: 8.86 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/20] avg loss: 0.502849312224397		[learning rate: 0.00552]
		[batch 20/20] avg loss: 0.38578000334210255		[learning rate: 0.005507]
	Learning Rate: 0.00550704
	LOSS [training: 0.4443146577832498 | validation: 0.3875532484402045]
	TIME [epoch: 8.86 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5111075907873774		[learning rate: 0.0054941]
		[batch 20/20] avg loss: 0.4474144503607576		[learning rate: 0.0054812]
	Learning Rate: 0.00548122
	LOSS [training: 0.4792610205740675 | validation: 0.3660553658955068]
	TIME [epoch: 8.86 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4751303430063035		[learning rate: 0.0054684]
		[batch 20/20] avg loss: 0.5010191617822868		[learning rate: 0.0054555]
	Learning Rate: 0.00545553
	LOSS [training: 0.48807475239429515 | validation: 0.5004590269683926]
	TIME [epoch: 8.86 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3810738570466893		[learning rate: 0.0054427]
		[batch 20/20] avg loss: 0.5098740985412944		[learning rate: 0.00543]
	Learning Rate: 0.00542995
	LOSS [training: 0.4454739777939918 | validation: 0.32353995395195345]
	TIME [epoch: 8.89 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/20] avg loss: 0.37252037602478005		[learning rate: 0.0054172]
		[batch 20/20] avg loss: 0.5504060965670358		[learning rate: 0.0054045]
	Learning Rate: 0.00540449
	LOSS [training: 0.461463236295908 | validation: 0.575686069802136]
	TIME [epoch: 8.86 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5249180717258098		[learning rate: 0.0053918]
		[batch 20/20] avg loss: 0.5370691026990748		[learning rate: 0.0053792]
	Learning Rate: 0.00537916
	LOSS [training: 0.5309935872124424 | validation: 0.33315048960642435]
	TIME [epoch: 8.86 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5135430738133502		[learning rate: 0.0053665]
		[batch 20/20] avg loss: 0.33437096023277185		[learning rate: 0.0053539]
	Learning Rate: 0.00535394
	LOSS [training: 0.42395701702306104 | validation: 0.22221986898160975]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_143.pth
	Model improved!!!
EPOCH 144/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4603508863079672		[learning rate: 0.0053414]
		[batch 20/20] avg loss: 0.5364185842200844		[learning rate: 0.0053288]
	Learning Rate: 0.00532884
	LOSS [training: 0.4983847352640258 | validation: 0.817475137059972]
	TIME [epoch: 8.89 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4058948007005392		[learning rate: 0.0053163]
		[batch 20/20] avg loss: 0.3744402353336067		[learning rate: 0.0053039]
	Learning Rate: 0.00530386
	LOSS [training: 0.390167518017073 | validation: 0.2549740783901254]
	TIME [epoch: 8.87 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3703863970501454		[learning rate: 0.0052914]
		[batch 20/20] avg loss: 0.3871159735911665		[learning rate: 0.005279]
	Learning Rate: 0.00527899
	LOSS [training: 0.37875118532065594 | validation: 0.3187234479050499]
	TIME [epoch: 8.86 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3455732724436791		[learning rate: 0.0052666]
		[batch 20/20] avg loss: 0.45287604224670563		[learning rate: 0.0052542]
	Learning Rate: 0.00525424
	LOSS [training: 0.3992246573451923 | validation: 0.49834953272335103]
	TIME [epoch: 8.88 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4944637230248586		[learning rate: 0.0052419]
		[batch 20/20] avg loss: 0.34193338396565587		[learning rate: 0.0052296]
	Learning Rate: 0.00522961
	LOSS [training: 0.4181985534952572 | validation: 0.682655515564978]
	TIME [epoch: 8.87 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5682580421299875		[learning rate: 0.0052173]
		[batch 20/20] avg loss: 0.5290910347721246		[learning rate: 0.0052051]
	Learning Rate: 0.00520509
	LOSS [training: 0.5486745384510561 | validation: 0.5556310058852617]
	TIME [epoch: 8.88 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/20] avg loss: 0.37615202519909047		[learning rate: 0.0051929]
		[batch 20/20] avg loss: 0.42048016605670313		[learning rate: 0.0051807]
	Learning Rate: 0.00518069
	LOSS [training: 0.3983160956278968 | validation: 0.35484106393434184]
	TIME [epoch: 8.86 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3479732359201687		[learning rate: 0.0051685]
		[batch 20/20] avg loss: 0.3883867414623114		[learning rate: 0.0051564]
	Learning Rate: 0.0051564
	LOSS [training: 0.3681799886912401 | validation: 0.3639947956491109]
	TIME [epoch: 8.86 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35210577129819864		[learning rate: 0.0051443]
		[batch 20/20] avg loss: 0.33157388355456674		[learning rate: 0.0051322]
	Learning Rate: 0.00513223
	LOSS [training: 0.3418398274263827 | validation: 0.42116008890952283]
	TIME [epoch: 8.86 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/20] avg loss: 0.48388977077984324		[learning rate: 0.0051202]
		[batch 20/20] avg loss: 0.5322933546195203		[learning rate: 0.0051082]
	Learning Rate: 0.00510817
	LOSS [training: 0.5080915626996816 | validation: 0.34849700124393357]
	TIME [epoch: 8.88 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33985251039917724		[learning rate: 0.0050962]
		[batch 20/20] avg loss: 0.38942803975757534		[learning rate: 0.0050842]
	Learning Rate: 0.00508422
	LOSS [training: 0.36464027507837626 | validation: 0.30359660123854026]
	TIME [epoch: 8.86 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27494818253525594		[learning rate: 0.0050723]
		[batch 20/20] avg loss: 0.6286660896757756		[learning rate: 0.0050604]
	Learning Rate: 0.00506039
	LOSS [training: 0.4518071361055158 | validation: 0.6281509748486156]
	TIME [epoch: 8.85 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4192890445618742		[learning rate: 0.0050485]
		[batch 20/20] avg loss: 0.32886771590155783		[learning rate: 0.0050367]
	Learning Rate: 0.00503666
	LOSS [training: 0.374078380231716 | validation: 0.5346297484701042]
	TIME [epoch: 8.86 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40867144778890035		[learning rate: 0.0050248]
		[batch 20/20] avg loss: 0.384188133638396		[learning rate: 0.005013]
	Learning Rate: 0.00501305
	LOSS [training: 0.3964297907136482 | validation: 0.25119630832634926]
	TIME [epoch: 8.88 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4175984155802498		[learning rate: 0.0050013]
		[batch 20/20] avg loss: 0.41067471630265306		[learning rate: 0.0049895]
	Learning Rate: 0.00498955
	LOSS [training: 0.41413656594145143 | validation: 0.5589898409696239]
	TIME [epoch: 8.86 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/20] avg loss: 0.429733812091345		[learning rate: 0.0049778]
		[batch 20/20] avg loss: 0.30906123136776553		[learning rate: 0.0049662]
	Learning Rate: 0.00496616
	LOSS [training: 0.3693975217295552 | validation: 0.44336386259393956]
	TIME [epoch: 8.86 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34387687192989785		[learning rate: 0.0049545]
		[batch 20/20] avg loss: 0.33761601311012635		[learning rate: 0.0049429]
	Learning Rate: 0.00494287
	LOSS [training: 0.34074644252001224 | validation: 0.580388588027527]
	TIME [epoch: 8.86 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3997183354715854		[learning rate: 0.0049313]
		[batch 20/20] avg loss: 0.43201299583599495		[learning rate: 0.0049197]
	Learning Rate: 0.0049197
	LOSS [training: 0.41586566565379013 | validation: 0.599667218209606]
	TIME [epoch: 8.86 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/20] avg loss: 0.42220341578929454		[learning rate: 0.0049082]
		[batch 20/20] avg loss: 0.33835717271544763		[learning rate: 0.0048966]
	Learning Rate: 0.00489664
	LOSS [training: 0.38028029425237103 | validation: 0.2457971184357785]
	TIME [epoch: 8.88 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/20] avg loss: 0.360556226326392		[learning rate: 0.0048851]
		[batch 20/20] avg loss: 0.3511980635149205		[learning rate: 0.0048737]
	Learning Rate: 0.00487368
	LOSS [training: 0.35587714492065625 | validation: 0.3209592603763032]
	TIME [epoch: 8.86 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3906211802726727		[learning rate: 0.0048622]
		[batch 20/20] avg loss: 0.3677119699295633		[learning rate: 0.0048508]
	Learning Rate: 0.00485083
	LOSS [training: 0.379166575101118 | validation: 1.5527792422169426]
	TIME [epoch: 8.86 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7099135160063297		[learning rate: 0.0048394]
		[batch 20/20] avg loss: 0.3403484328017744		[learning rate: 0.0048281]
	Learning Rate: 0.00482809
	LOSS [training: 0.525130974404052 | validation: 0.19127303070351517]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_165.pth
	Model improved!!!
EPOCH 166/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32677777042688155		[learning rate: 0.0048168]
		[batch 20/20] avg loss: 0.46331928721721044		[learning rate: 0.0048055]
	Learning Rate: 0.00480546
	LOSS [training: 0.39504852882204594 | validation: 0.45920511272196446]
	TIME [epoch: 8.89 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3223093830003347		[learning rate: 0.0047942]
		[batch 20/20] avg loss: 0.4040554783765288		[learning rate: 0.0047829]
	Learning Rate: 0.00478293
	LOSS [training: 0.36318243068843165 | validation: 0.3613099285722601]
	TIME [epoch: 8.86 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/20] avg loss: 0.46568396122679906		[learning rate: 0.0047717]
		[batch 20/20] avg loss: 0.3715312260628958		[learning rate: 0.0047605]
	Learning Rate: 0.00476051
	LOSS [training: 0.4186075936448474 | validation: 0.25478603170491765]
	TIME [epoch: 8.86 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2875649629398477		[learning rate: 0.0047493]
		[batch 20/20] avg loss: 0.30062518803474686		[learning rate: 0.0047382]
	Learning Rate: 0.00473819
	LOSS [training: 0.2940950754872973 | validation: 0.26249031201038187]
	TIME [epoch: 8.86 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31710097882501953		[learning rate: 0.0047271]
		[batch 20/20] avg loss: 0.3929885602051545		[learning rate: 0.004716]
	Learning Rate: 0.00471597
	LOSS [training: 0.355044769515087 | validation: 0.27531680027674493]
	TIME [epoch: 8.87 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3462361898620564		[learning rate: 0.0047049]
		[batch 20/20] avg loss: 0.24506376810878933		[learning rate: 0.0046939]
	Learning Rate: 0.00469386
	LOSS [training: 0.29564997898542283 | validation: 0.255472257555332]
	TIME [epoch: 8.87 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3633346291315495		[learning rate: 0.0046828]
		[batch 20/20] avg loss: 0.35680425483249356		[learning rate: 0.0046719]
	Learning Rate: 0.00467186
	LOSS [training: 0.3600694419820215 | validation: 0.23333053898396094]
	TIME [epoch: 8.86 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29280866303166714		[learning rate: 0.0046609]
		[batch 20/20] avg loss: 0.27629614483891757		[learning rate: 0.00465]
	Learning Rate: 0.00464996
	LOSS [training: 0.28455240393529235 | validation: 0.33047916062386695]
	TIME [epoch: 8.85 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3239314258212419		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.31426976500802706		[learning rate: 0.0046282]
	Learning Rate: 0.00462816
	LOSS [training: 0.31910059541463454 | validation: 0.18118472016560802]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_174.pth
	Model improved!!!
EPOCH 175/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2764818504488674		[learning rate: 0.0046173]
		[batch 20/20] avg loss: 0.32512290836471347		[learning rate: 0.0046065]
	Learning Rate: 0.00460646
	LOSS [training: 0.3008023794067905 | validation: 0.23215901034812148]
	TIME [epoch: 8.88 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22669679934852938		[learning rate: 0.0045956]
		[batch 20/20] avg loss: 0.4052536724156994		[learning rate: 0.0045849]
	Learning Rate: 0.00458486
	LOSS [training: 0.31597523588211435 | validation: 0.23748372747636387]
	TIME [epoch: 8.85 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24237942237705293		[learning rate: 0.0045741]
		[batch 20/20] avg loss: 0.296803290587836		[learning rate: 0.0045634]
	Learning Rate: 0.00456337
	LOSS [training: 0.2695913564824444 | validation: 0.2019531400916678]
	TIME [epoch: 8.86 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27699884735271074		[learning rate: 0.0045527]
		[batch 20/20] avg loss: 0.3931910289048556		[learning rate: 0.004542]
	Learning Rate: 0.00454198
	LOSS [training: 0.33509493812878316 | validation: 0.5997951006715743]
	TIME [epoch: 8.85 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3841563630676374		[learning rate: 0.0045313]
		[batch 20/20] avg loss: 0.2699230290739614		[learning rate: 0.0045207]
	Learning Rate: 0.00452068
	LOSS [training: 0.32703969607079936 | validation: 0.3066452433818383]
	TIME [epoch: 8.87 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2921807047781479		[learning rate: 0.0045101]
		[batch 20/20] avg loss: 0.3557217644033107		[learning rate: 0.0044995]
	Learning Rate: 0.00449949
	LOSS [training: 0.3239512345907294 | validation: 0.7364839319257479]
	TIME [epoch: 8.87 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44238453013547935		[learning rate: 0.0044889]
		[batch 20/20] avg loss: 0.3151963707736106		[learning rate: 0.0044784]
	Learning Rate: 0.0044784
	LOSS [training: 0.37879045045454507 | validation: 0.531660692580113]
	TIME [epoch: 8.85 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3845016494482259		[learning rate: 0.0044679]
		[batch 20/20] avg loss: 0.26516676569821085		[learning rate: 0.0044574]
	Learning Rate: 0.0044574
	LOSS [training: 0.32483420757321835 | validation: 0.15336787515960085]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_182.pth
	Model improved!!!
EPOCH 183/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25727068228838895		[learning rate: 0.0044469]
		[batch 20/20] avg loss: 0.2812596407306295		[learning rate: 0.0044365]
	Learning Rate: 0.0044365
	LOSS [training: 0.26926516150950924 | validation: 0.1823975350159627]
	TIME [epoch: 8.85 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2534293055929116		[learning rate: 0.0044261]
		[batch 20/20] avg loss: 0.3290646662041961		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.2912469858985538 | validation: 0.20165911186637878]
	TIME [epoch: 8.88 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2571361197562994		[learning rate: 0.0044053]
		[batch 20/20] avg loss: 0.23656829186261677		[learning rate: 0.004395]
	Learning Rate: 0.004395
	LOSS [training: 0.24685220580945808 | validation: 0.23724396355014504]
	TIME [epoch: 8.85 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29756551524796426		[learning rate: 0.0043847]
		[batch 20/20] avg loss: 0.266703407965863		[learning rate: 0.0043744]
	Learning Rate: 0.0043744
	LOSS [training: 0.28213446160691363 | validation: 0.721455532111298]
	TIME [epoch: 8.85 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29340138356590223		[learning rate: 0.0043641]
		[batch 20/20] avg loss: 0.2712154451073391		[learning rate: 0.0043539]
	Learning Rate: 0.00435389
	LOSS [training: 0.2823084143366206 | validation: 0.1458062557950422]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_187.pth
	Model improved!!!
EPOCH 188/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2653435548719106		[learning rate: 0.0043437]
		[batch 20/20] avg loss: 0.30593257764974985		[learning rate: 0.0043335]
	Learning Rate: 0.00433348
	LOSS [training: 0.28563806626083027 | validation: 0.3047256145302937]
	TIME [epoch: 8.88 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24369052866572835		[learning rate: 0.0043233]
		[batch 20/20] avg loss: 0.30371187851147846		[learning rate: 0.0043132]
	Learning Rate: 0.00431316
	LOSS [training: 0.2737012035886034 | validation: 0.23585306077839702]
	TIME [epoch: 8.85 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4071109659709869		[learning rate: 0.004303]
		[batch 20/20] avg loss: 0.2454779016692415		[learning rate: 0.0042929]
	Learning Rate: 0.00429294
	LOSS [training: 0.3262944338201141 | validation: 0.8835162799831184]
	TIME [epoch: 8.85 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3564388578297133		[learning rate: 0.0042829]
		[batch 20/20] avg loss: 0.34851984838042593		[learning rate: 0.0042728]
	Learning Rate: 0.00427282
	LOSS [training: 0.35247935310506967 | validation: 0.45740061007683813]
	TIME [epoch: 8.85 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/20] avg loss: 0.334696036535367		[learning rate: 0.0042628]
		[batch 20/20] avg loss: 0.291977494360394		[learning rate: 0.0042528]
	Learning Rate: 0.00425279
	LOSS [training: 0.3133367654478806 | validation: 0.18504550809442435]
	TIME [epoch: 8.87 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2726483275909931		[learning rate: 0.0042428]
		[batch 20/20] avg loss: 0.3138941574648223		[learning rate: 0.0042328]
	Learning Rate: 0.00423285
	LOSS [training: 0.2932712425279077 | validation: 0.2613820987781321]
	TIME [epoch: 8.85 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28983259376915166		[learning rate: 0.0042229]
		[batch 20/20] avg loss: 0.2800893893152012		[learning rate: 0.004213]
	Learning Rate: 0.004213
	LOSS [training: 0.28496099154217647 | validation: 0.22612062809781036]
	TIME [epoch: 8.85 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2643160408811339		[learning rate: 0.0042031]
		[batch 20/20] avg loss: 0.2759687224015873		[learning rate: 0.0041933]
	Learning Rate: 0.00419325
	LOSS [training: 0.27014238164136056 | validation: 0.18427432957459303]
	TIME [epoch: 8.84 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2516213626366752		[learning rate: 0.0041834]
		[batch 20/20] avg loss: 0.34733547568758494		[learning rate: 0.0041736]
	Learning Rate: 0.00417359
	LOSS [training: 0.29947841916213 | validation: 0.19420432497916287]
	TIME [epoch: 8.86 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19394946513316064		[learning rate: 0.0041638]
		[batch 20/20] avg loss: 0.3661234670912038		[learning rate: 0.004154]
	Learning Rate: 0.00415403
	LOSS [training: 0.2800364661121822 | validation: 0.23042723607874865]
	TIME [epoch: 8.87 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23798776065877383		[learning rate: 0.0041443]
		[batch 20/20] avg loss: 0.24348173133673906		[learning rate: 0.0041346]
	Learning Rate: 0.00413455
	LOSS [training: 0.2407347459977564 | validation: 0.40834305868077997]
	TIME [epoch: 8.87 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27571150400758987		[learning rate: 0.0041249]
		[batch 20/20] avg loss: 0.42955288438389505		[learning rate: 0.0041152]
	Learning Rate: 0.00411517
	LOSS [training: 0.3526321941957425 | validation: 0.17845903053646467]
	TIME [epoch: 8.85 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28047669078716525		[learning rate: 0.0041055]
		[batch 20/20] avg loss: 0.27325677842565066		[learning rate: 0.0040959]
	Learning Rate: 0.00409588
	LOSS [training: 0.27686673460640787 | validation: 0.7487635866468307]
	TIME [epoch: 8.84 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3415879759786935		[learning rate: 0.0040863]
		[batch 20/20] avg loss: 0.2728360706543055		[learning rate: 0.0040767]
	Learning Rate: 0.00407667
	LOSS [training: 0.30721202331649944 | validation: 0.22173851433550662]
	TIME [epoch: 8.87 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20015007997115525		[learning rate: 0.0040671]
		[batch 20/20] avg loss: 0.3494761196186308		[learning rate: 0.0040576]
	Learning Rate: 0.00405756
	LOSS [training: 0.27481309979489305 | validation: 0.5899704484566365]
	TIME [epoch: 8.84 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30541464716412275		[learning rate: 0.004048]
		[batch 20/20] avg loss: 0.25362968650036904		[learning rate: 0.0040385]
	Learning Rate: 0.00403854
	LOSS [training: 0.2795221668322459 | validation: 0.42897585544176603]
	TIME [epoch: 8.85 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2371168904743705		[learning rate: 0.0040291]
		[batch 20/20] avg loss: 0.19758524418199758		[learning rate: 0.0040196]
	Learning Rate: 0.00401961
	LOSS [training: 0.21735106732818407 | validation: 0.21161381482113345]
	TIME [epoch: 8.85 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23075107048037805		[learning rate: 0.0040102]
		[batch 20/20] avg loss: 0.26910427293238115		[learning rate: 0.0040008]
	Learning Rate: 0.00400076
	LOSS [training: 0.24992767170637958 | validation: 0.20308172874872898]
	TIME [epoch: 8.87 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27068323390702687		[learning rate: 0.0039914]
		[batch 20/20] avg loss: 0.21730585786504908		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.24399454588603792 | validation: 0.09343640380930895]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_206.pth
	Model improved!!!
EPOCH 207/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19236937123385695		[learning rate: 0.0039727]
		[batch 20/20] avg loss: 0.2287039367188343		[learning rate: 0.0039633]
	Learning Rate: 0.00396334
	LOSS [training: 0.21053665397634566 | validation: 0.4134738229836042]
	TIME [epoch: 8.85 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27173408233352747		[learning rate: 0.003954]
		[batch 20/20] avg loss: 0.18427292294696573		[learning rate: 0.0039448]
	Learning Rate: 0.00394476
	LOSS [training: 0.22800350264024663 | validation: 0.2007297658684868]
	TIME [epoch: 8.84 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23373373562779393		[learning rate: 0.0039355]
		[batch 20/20] avg loss: 0.32315546834739617		[learning rate: 0.0039263]
	Learning Rate: 0.00392627
	LOSS [training: 0.2784446019875951 | validation: 0.5053036321708607]
	TIME [epoch: 8.85 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27976927453794226		[learning rate: 0.0039171]
		[batch 20/20] avg loss: 0.22340745675256177		[learning rate: 0.0039079]
	Learning Rate: 0.00390786
	LOSS [training: 0.25158836564525205 | validation: 0.1649371412649719]
	TIME [epoch: 8.86 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16500694071566085		[learning rate: 0.0038987]
		[batch 20/20] avg loss: 0.24292248840651204		[learning rate: 0.0038895]
	Learning Rate: 0.00388954
	LOSS [training: 0.20396471456108642 | validation: 0.3883730035414725]
	TIME [epoch: 8.85 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3297629629449257		[learning rate: 0.0038804]
		[batch 20/20] avg loss: 0.20960270694675476		[learning rate: 0.0038713]
	Learning Rate: 0.0038713
	LOSS [training: 0.2696828349458403 | validation: 0.21242159453644915]
	TIME [epoch: 8.85 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24207548271641652		[learning rate: 0.0038622]
		[batch 20/20] avg loss: 0.21414085463731203		[learning rate: 0.0038532]
	Learning Rate: 0.00385315
	LOSS [training: 0.2281081686768643 | validation: 0.35005638740703415]
	TIME [epoch: 8.86 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2653772019278978		[learning rate: 0.0038441]
		[batch 20/20] avg loss: 0.25656541713338443		[learning rate: 0.0038351]
	Learning Rate: 0.00383509
	LOSS [training: 0.2609713095306411 | validation: 0.18184670779781836]
	TIME [epoch: 8.86 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21085971874741677		[learning rate: 0.0038261]
		[batch 20/20] avg loss: 0.24874804705830758		[learning rate: 0.0038171]
	Learning Rate: 0.00381711
	LOSS [training: 0.22980388290286213 | validation: 0.41209636377964876]
	TIME [epoch: 8.85 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2843351657266195		[learning rate: 0.0038082]
		[batch 20/20] avg loss: 0.20507844727622407		[learning rate: 0.0037992]
	Learning Rate: 0.00379921
	LOSS [training: 0.2447068065014218 | validation: 0.26512480465615834]
	TIME [epoch: 8.85 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2091753838172863		[learning rate: 0.0037903]
		[batch 20/20] avg loss: 0.21330636358724026		[learning rate: 0.0037814]
	Learning Rate: 0.0037814
	LOSS [training: 0.21124087370226324 | validation: 0.22579264931073373]
	TIME [epoch: 8.84 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2061621618940074		[learning rate: 0.0037725]
		[batch 20/20] avg loss: 0.20434586984030867		[learning rate: 0.0037637]
	Learning Rate: 0.00376368
	LOSS [training: 0.20525401586715808 | validation: 0.21463628065039284]
	TIME [epoch: 8.87 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30745482620664827		[learning rate: 0.0037548]
		[batch 20/20] avg loss: 0.2570843660030493		[learning rate: 0.003746]
	Learning Rate: 0.00374603
	LOSS [training: 0.28226959610484875 | validation: 0.18221207822613766]
	TIME [epoch: 8.85 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20407072254322545		[learning rate: 0.0037372]
		[batch 20/20] avg loss: 0.2193017316574814		[learning rate: 0.0037285]
	Learning Rate: 0.00372847
	LOSS [training: 0.21168622710035345 | validation: 0.1854980568614881]
	TIME [epoch: 8.85 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22013869142270356		[learning rate: 0.0037197]
		[batch 20/20] avg loss: 0.22579673811563367		[learning rate: 0.003711]
	Learning Rate: 0.00371099
	LOSS [training: 0.22296771476916866 | validation: 0.23174154792765883]
	TIME [epoch: 8.84 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20037180152696585		[learning rate: 0.0037023]
		[batch 20/20] avg loss: 0.23489686767678947		[learning rate: 0.0036936]
	Learning Rate: 0.00369359
	LOSS [training: 0.2176343346018777 | validation: 0.14854634545828135]
	TIME [epoch: 8.87 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2687256712279203		[learning rate: 0.0036849]
		[batch 20/20] avg loss: 0.18540028208059964		[learning rate: 0.0036763]
	Learning Rate: 0.00367628
	LOSS [training: 0.22706297665425992 | validation: 0.3087654628875551]
	TIME [epoch: 8.85 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25133596784580015		[learning rate: 0.0036676]
		[batch 20/20] avg loss: 0.22020393339728708		[learning rate: 0.003659]
	Learning Rate: 0.00365904
	LOSS [training: 0.23576995062154366 | validation: 0.18555515573396095]
	TIME [epoch: 8.85 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2381618502986531		[learning rate: 0.0036505]
		[batch 20/20] avg loss: 0.2308359851634174		[learning rate: 0.0036419]
	Learning Rate: 0.00364189
	LOSS [training: 0.23449891773103526 | validation: 0.1909075584019299]
	TIME [epoch: 8.85 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19441943859121122		[learning rate: 0.0036333]
		[batch 20/20] avg loss: 0.3323421369458212		[learning rate: 0.0036248]
	Learning Rate: 0.00362481
	LOSS [training: 0.26338078776851626 | validation: 0.10530108498792165]
	TIME [epoch: 8.85 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19008110291507826		[learning rate: 0.0036163]
		[batch 20/20] avg loss: 0.20915618457691942		[learning rate: 0.0036078]
	Learning Rate: 0.00360782
	LOSS [training: 0.19961864374599886 | validation: 0.10384913962499334]
	TIME [epoch: 8.86 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24762153269462872		[learning rate: 0.0035994]
		[batch 20/20] avg loss: 0.1991988865582539		[learning rate: 0.0035909]
	Learning Rate: 0.00359091
	LOSS [training: 0.2234102096264413 | validation: 0.1965497459850918]
	TIME [epoch: 8.85 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17682848191943484		[learning rate: 0.0035825]
		[batch 20/20] avg loss: 0.21964495467878203		[learning rate: 0.0035741]
	Learning Rate: 0.00357407
	LOSS [training: 0.19823671829910844 | validation: 0.24686379125714203]
	TIME [epoch: 8.85 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19573897916137423		[learning rate: 0.0035657]
		[batch 20/20] avg loss: 0.22268680422014028		[learning rate: 0.0035573]
	Learning Rate: 0.00355732
	LOSS [training: 0.20921289169075727 | validation: 0.16240754861039247]
	TIME [epoch: 8.85 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19096041808432895		[learning rate: 0.003549]
		[batch 20/20] avg loss: 0.224356269040759		[learning rate: 0.0035406]
	Learning Rate: 0.00354064
	LOSS [training: 0.207658343562544 | validation: 0.08432522035045001]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_231.pth
	Model improved!!!
EPOCH 232/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20439697130058448		[learning rate: 0.0035323]
		[batch 20/20] avg loss: 0.19923623265607415		[learning rate: 0.003524]
	Learning Rate: 0.00352404
	LOSS [training: 0.20181660197832932 | validation: 0.1552084167361904]
	TIME [epoch: 8.84 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19749580565922986		[learning rate: 0.0035158]
		[batch 20/20] avg loss: 0.1542987261169281		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.17589726588807902 | validation: 0.16296346073210632]
	TIME [epoch: 8.85 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21011915606170933		[learning rate: 0.0034993]
		[batch 20/20] avg loss: 0.20106367659439636		[learning rate: 0.0034911]
	Learning Rate: 0.00349107
	LOSS [training: 0.20559141632805283 | validation: 0.12049037446449047]
	TIME [epoch: 8.84 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14681572356452516		[learning rate: 0.0034829]
		[batch 20/20] avg loss: 0.1603709008413413		[learning rate: 0.0034747]
	Learning Rate: 0.00347471
	LOSS [training: 0.15359331220293324 | validation: 0.14202700096339774]
	TIME [epoch: 8.87 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28174120578486106		[learning rate: 0.0034666]
		[batch 20/20] avg loss: 0.14608812787247566		[learning rate: 0.0034584]
	Learning Rate: 0.00345842
	LOSS [training: 0.21391466682866836 | validation: 0.29317354963137493]
	TIME [epoch: 8.85 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2151029151566517		[learning rate: 0.0034503]
		[batch 20/20] avg loss: 0.24949942166088718		[learning rate: 0.0034422]
	Learning Rate: 0.00344221
	LOSS [training: 0.2323011684087694 | validation: 0.18823288957527695]
	TIME [epoch: 8.85 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16374023718083955		[learning rate: 0.0034341]
		[batch 20/20] avg loss: 0.17006721660747043		[learning rate: 0.0034261]
	Learning Rate: 0.00342607
	LOSS [training: 0.16690372689415495 | validation: 0.11548443673914413]
	TIME [epoch: 8.85 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1581802894438044		[learning rate: 0.003418]
		[batch 20/20] avg loss: 0.1814471216764461		[learning rate: 0.00341]
	Learning Rate: 0.00341001
	LOSS [training: 0.16981370556012526 | validation: 0.30951535891841625]
	TIME [epoch: 8.86 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18851183635404622		[learning rate: 0.003402]
		[batch 20/20] avg loss: 0.17089940588908023		[learning rate: 0.003394]
	Learning Rate: 0.00339402
	LOSS [training: 0.17970562112156324 | validation: 0.2390410936490281]
	TIME [epoch: 8.85 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20826411915220727		[learning rate: 0.0033861]
		[batch 20/20] avg loss: 0.2525736928759557		[learning rate: 0.0033781]
	Learning Rate: 0.00337811
	LOSS [training: 0.23041890601408146 | validation: 0.23487294015015667]
	TIME [epoch: 8.85 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2025153123610078		[learning rate: 0.0033702]
		[batch 20/20] avg loss: 0.1550676900871559		[learning rate: 0.0033623]
	Learning Rate: 0.00336227
	LOSS [training: 0.17879150122408186 | validation: 0.16894297066431935]
	TIME [epoch: 8.84 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14566029071324352		[learning rate: 0.0033544]
		[batch 20/20] avg loss: 0.19804690972866104		[learning rate: 0.0033465]
	Learning Rate: 0.00334651
	LOSS [training: 0.17185360022095228 | validation: 0.37838402167058627]
	TIME [epoch: 8.86 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17359436479627852		[learning rate: 0.0033387]
		[batch 20/20] avg loss: 0.226595679664217		[learning rate: 0.0033308]
	Learning Rate: 0.00333082
	LOSS [training: 0.20009502223024778 | validation: 0.34634649724952304]
	TIME [epoch: 8.86 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24265283260672454		[learning rate: 0.003323]
		[batch 20/20] avg loss: 0.19176255223457167		[learning rate: 0.0033152]
	Learning Rate: 0.0033152
	LOSS [training: 0.21720769242064816 | validation: 0.1322881913042876]
	TIME [epoch: 8.84 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22404695201207353		[learning rate: 0.0033074]
		[batch 20/20] avg loss: 0.1880501489653903		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.20604855048873186 | validation: 0.28793134890180383]
	TIME [epoch: 8.84 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19607457401135608		[learning rate: 0.0032919]
		[batch 20/20] avg loss: 0.20216207015187643		[learning rate: 0.0032842]
	Learning Rate: 0.00328419
	LOSS [training: 0.19911832208161628 | validation: 0.13114625233016033]
	TIME [epoch: 8.84 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1598211431465403		[learning rate: 0.0032765]
		[batch 20/20] avg loss: 0.2023108239738008		[learning rate: 0.0032688]
	Learning Rate: 0.0032688
	LOSS [training: 0.18106598356017053 | validation: 0.12107705632867602]
	TIME [epoch: 8.87 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15685169972917798		[learning rate: 0.0032611]
		[batch 20/20] avg loss: 0.16483069272308784		[learning rate: 0.0032535]
	Learning Rate: 0.00325347
	LOSS [training: 0.16084119622613294 | validation: 0.21221369953202743]
	TIME [epoch: 8.85 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11841120500943685		[learning rate: 0.0032458]
		[batch 20/20] avg loss: 0.2583070125252583		[learning rate: 0.0032382]
	Learning Rate: 0.00323822
	LOSS [training: 0.18835910876734757 | validation: 0.20637942831124603]
	TIME [epoch: 8.85 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18555514290658975		[learning rate: 0.0032306]
		[batch 20/20] avg loss: 0.14514128835028098		[learning rate: 0.003223]
	Learning Rate: 0.00322304
	LOSS [training: 0.1653482156284354 | validation: 0.09053644035137386]
	TIME [epoch: 8.85 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16591742701688086		[learning rate: 0.0032155]
		[batch 20/20] avg loss: 0.12883112141331557		[learning rate: 0.0032079]
	Learning Rate: 0.00320793
	LOSS [training: 0.14737427421509824 | validation: 0.24362679630441678]
	TIME [epoch: 8.86 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24204175584546395		[learning rate: 0.0032004]
		[batch 20/20] avg loss: 0.20085274739943046		[learning rate: 0.0031929]
	Learning Rate: 0.00319289
	LOSS [training: 0.22144725162244722 | validation: 0.1417204937863775]
	TIME [epoch: 8.85 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14737970243526302		[learning rate: 0.0031854]
		[batch 20/20] avg loss: 0.18011328925497866		[learning rate: 0.0031779]
	Learning Rate: 0.00317792
	LOSS [training: 0.1637464958451208 | validation: 0.08354019212967324]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_254.pth
	Model improved!!!
EPOCH 255/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14967497622601525		[learning rate: 0.0031705]
		[batch 20/20] avg loss: 0.11749792012837885		[learning rate: 0.003163]
	Learning Rate: 0.00316302
	LOSS [training: 0.13358644817719706 | validation: 0.09811950697753698]
	TIME [epoch: 8.85 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1432492171217296		[learning rate: 0.0031556]
		[batch 20/20] avg loss: 0.14768364316775945		[learning rate: 0.0031482]
	Learning Rate: 0.00314819
	LOSS [training: 0.1454664301447445 | validation: 0.7698020658093869]
	TIME [epoch: 8.85 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31107078487022033		[learning rate: 0.0031408]
		[batch 20/20] avg loss: 0.2448313186167534		[learning rate: 0.0031334]
	Learning Rate: 0.00313343
	LOSS [training: 0.27795105174348694 | validation: 0.19846779935727196]
	TIME [epoch: 8.86 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15738979964770422		[learning rate: 0.0031261]
		[batch 20/20] avg loss: 0.17567237427710608		[learning rate: 0.0031187]
	Learning Rate: 0.00311874
	LOSS [training: 0.1665310869624051 | validation: 0.3272222927051203]
	TIME [epoch: 8.84 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20822642072906633		[learning rate: 0.0031114]
		[batch 20/20] avg loss: 0.12934409772920805		[learning rate: 0.0031041]
	Learning Rate: 0.00310412
	LOSS [training: 0.16878525922913717 | validation: 0.23290718319473194]
	TIME [epoch: 8.84 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1619664183816616		[learning rate: 0.0030968]
		[batch 20/20] avg loss: 0.17301554124340157		[learning rate: 0.0030896]
	Learning Rate: 0.00308957
	LOSS [training: 0.1674909798125316 | validation: 0.10067120769480503]
	TIME [epoch: 8.84 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18155804964788652		[learning rate: 0.0030823]
		[batch 20/20] avg loss: 0.1255897029372971		[learning rate: 0.0030751]
	Learning Rate: 0.00307509
	LOSS [training: 0.15357387629259184 | validation: 0.12062227524392086]
	TIME [epoch: 8.86 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12523736037353467		[learning rate: 0.0030679]
		[batch 20/20] avg loss: 0.16033702107402603		[learning rate: 0.0030607]
	Learning Rate: 0.00306067
	LOSS [training: 0.14278719072378035 | validation: 0.24981519564906363]
	TIME [epoch: 8.85 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15531209764191556		[learning rate: 0.0030535]
		[batch 20/20] avg loss: 0.20867631276720155		[learning rate: 0.0030463]
	Learning Rate: 0.00304632
	LOSS [training: 0.18199420520455856 | validation: 0.15900180101090491]
	TIME [epoch: 8.85 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16651810857928714		[learning rate: 0.0030392]
		[batch 20/20] avg loss: 0.1433767861170076		[learning rate: 0.003032]
	Learning Rate: 0.00303204
	LOSS [training: 0.1549474473481474 | validation: 0.17756128204416444]
	TIME [epoch: 8.84 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1749311142543209		[learning rate: 0.0030249]
		[batch 20/20] avg loss: 0.1436392331085173		[learning rate: 0.0030178]
	Learning Rate: 0.00301782
	LOSS [training: 0.1592851736814191 | validation: 0.0998904874524531]
	TIME [epoch: 8.85 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2781919777467682		[learning rate: 0.0030107]
		[batch 20/20] avg loss: 0.13320239628097214		[learning rate: 0.0030037]
	Learning Rate: 0.00300368
	LOSS [training: 0.20569718701387013 | validation: 0.13717601251126507]
	TIME [epoch: 8.86 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/20] avg loss: 0.136511673010615		[learning rate: 0.0029966]
		[batch 20/20] avg loss: 0.13065309434188668		[learning rate: 0.0029896]
	Learning Rate: 0.00298959
	LOSS [training: 0.13358238367625083 | validation: 0.21610010935697382]
	TIME [epoch: 8.84 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24792407682593542		[learning rate: 0.0029826]
		[batch 20/20] avg loss: 0.13557657992013344		[learning rate: 0.0029756]
	Learning Rate: 0.00297558
	LOSS [training: 0.1917503283730344 | validation: 0.27361071257583014]
	TIME [epoch: 8.84 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30715089749047		[learning rate: 0.0029686]
		[batch 20/20] avg loss: 0.15864736046750555		[learning rate: 0.0029616]
	Learning Rate: 0.00296163
	LOSS [training: 0.23289912897898776 | validation: 0.07888399042466543]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_269.pth
	Model improved!!!
EPOCH 270/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1730003164387553		[learning rate: 0.0029547]
		[batch 20/20] avg loss: 0.1767320072370511		[learning rate: 0.0029477]
	Learning Rate: 0.00294774
	LOSS [training: 0.17486616183790318 | validation: 0.28765368276099323]
	TIME [epoch: 8.87 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1433722926025307		[learning rate: 0.0029408]
		[batch 20/20] avg loss: 0.16075905222875359		[learning rate: 0.0029339]
	Learning Rate: 0.00293393
	LOSS [training: 0.15206567241564214 | validation: 0.19046345729778824]
	TIME [epoch: 8.83 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16228779037717916		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.17864085423305615		[learning rate: 0.0029202]
	Learning Rate: 0.00292017
	LOSS [training: 0.17046432230511765 | validation: 0.13317806855502035]
	TIME [epoch: 8.84 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1697894763661411		[learning rate: 0.0029133]
		[batch 20/20] avg loss: 0.1501259863141667		[learning rate: 0.0029065]
	Learning Rate: 0.00290648
	LOSS [training: 0.15995773134015392 | validation: 0.12093831047650277]
	TIME [epoch: 8.83 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16845218864766565		[learning rate: 0.0028997]
		[batch 20/20] avg loss: 0.13147288260587353		[learning rate: 0.0028929]
	Learning Rate: 0.00289285
	LOSS [training: 0.1499625356267696 | validation: 0.13841708136969025]
	TIME [epoch: 8.86 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1901380016379545		[learning rate: 0.0028861]
		[batch 20/20] avg loss: 0.1517290625202241		[learning rate: 0.0028793]
	Learning Rate: 0.00287929
	LOSS [training: 0.17093353207908935 | validation: 0.11318752517381771]
	TIME [epoch: 8.84 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14443507940694764		[learning rate: 0.0028725]
		[batch 20/20] avg loss: 0.16502671767481575		[learning rate: 0.0028658]
	Learning Rate: 0.00286579
	LOSS [training: 0.15473089854088168 | validation: 0.19108768617208804]
	TIME [epoch: 8.84 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13131420055925727		[learning rate: 0.0028591]
		[batch 20/20] avg loss: 0.1591982703712777		[learning rate: 0.0028524]
	Learning Rate: 0.00285236
	LOSS [training: 0.1452562354652675 | validation: 0.19584859771374552]
	TIME [epoch: 8.84 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14560178599181997		[learning rate: 0.0028457]
		[batch 20/20] avg loss: 0.11178781040236388		[learning rate: 0.002839]
	Learning Rate: 0.00283899
	LOSS [training: 0.12869479819709193 | validation: 0.1593166941490794]
	TIME [epoch: 8.86 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12956118204350964		[learning rate: 0.0028323]
		[batch 20/20] avg loss: 0.1926425611358058		[learning rate: 0.0028257]
	Learning Rate: 0.00282568
	LOSS [training: 0.16110187158965772 | validation: 0.16604650247448358]
	TIME [epoch: 8.84 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1374095778883854		[learning rate: 0.002819]
		[batch 20/20] avg loss: 0.13696887966988272		[learning rate: 0.0028124]
	Learning Rate: 0.00281243
	LOSS [training: 0.13718922877913403 | validation: 0.17378590992747875]
	TIME [epoch: 8.84 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14634900471819098		[learning rate: 0.0028058]
		[batch 20/20] avg loss: 0.13579718432280238		[learning rate: 0.0027992]
	Learning Rate: 0.00279924
	LOSS [training: 0.14107309452049668 | validation: 0.11411453253935172]
	TIME [epoch: 8.84 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1533207371687135		[learning rate: 0.0027927]
		[batch 20/20] avg loss: 0.1548733519473095		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.15409704455801154 | validation: 0.14635669466950965]
	TIME [epoch: 8.84 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19567271285727333		[learning rate: 0.0027796]
		[batch 20/20] avg loss: 0.11196032081469118		[learning rate: 0.0027731]
	Learning Rate: 0.00277306
	LOSS [training: 0.15381651683598227 | validation: 0.1298755350927515]
	TIME [epoch: 8.86 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2056037592477363		[learning rate: 0.0027666]
		[batch 20/20] avg loss: 0.12953240509173272		[learning rate: 0.0027601]
	Learning Rate: 0.00276006
	LOSS [training: 0.16756808216973448 | validation: 0.1273989483886619]
	TIME [epoch: 8.84 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1604118076229632		[learning rate: 0.0027536]
		[batch 20/20] avg loss: 0.1292624835463046		[learning rate: 0.0027471]
	Learning Rate: 0.00274712
	LOSS [training: 0.14483714558463393 | validation: 0.15696838818518652]
	TIME [epoch: 8.84 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14540778267631047		[learning rate: 0.0027407]
		[batch 20/20] avg loss: 0.1499360371943959		[learning rate: 0.0027342]
	Learning Rate: 0.00273424
	LOSS [training: 0.14767190993535315 | validation: 0.1815307663986859]
	TIME [epoch: 8.84 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14727277475358846		[learning rate: 0.0027278]
		[batch 20/20] avg loss: 0.08641901827113628		[learning rate: 0.0027214]
	Learning Rate: 0.00272142
	LOSS [training: 0.11684589651236237 | validation: 0.16377918314555734]
	TIME [epoch: 8.84 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15780613333347976		[learning rate: 0.002715]
		[batch 20/20] avg loss: 0.1499518235142346		[learning rate: 0.0027087]
	Learning Rate: 0.00270866
	LOSS [training: 0.15387897842385717 | validation: 0.1905575223504546]
	TIME [epoch: 8.86 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18731119274519256		[learning rate: 0.0027023]
		[batch 20/20] avg loss: 0.12600048393046148		[learning rate: 0.002696]
	Learning Rate: 0.00269597
	LOSS [training: 0.15665583833782706 | validation: 0.03960595207055687]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_289.pth
	Model improved!!!
EPOCH 290/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1190159522270838		[learning rate: 0.0026896]
		[batch 20/20] avg loss: 0.14337350106888053		[learning rate: 0.0026833]
	Learning Rate: 0.00268333
	LOSS [training: 0.13119472664798218 | validation: 0.09496797281359488]
	TIME [epoch: 8.84 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13148415841244673		[learning rate: 0.002677]
		[batch 20/20] avg loss: 0.1093908761401418		[learning rate: 0.0026707]
	Learning Rate: 0.00267075
	LOSS [training: 0.12043751727629426 | validation: 0.22534652074085754]
	TIME [epoch: 8.83 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/20] avg loss: 0.118533469720613		[learning rate: 0.0026645]
		[batch 20/20] avg loss: 0.14451406330885447		[learning rate: 0.0026582]
	Learning Rate: 0.00265823
	LOSS [training: 0.13152376651473371 | validation: 0.20250279954277722]
	TIME [epoch: 8.84 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20624219250595616		[learning rate: 0.002652]
		[batch 20/20] avg loss: 0.12052943651734623		[learning rate: 0.0026458]
	Learning Rate: 0.00264576
	LOSS [training: 0.16338581451165127 | validation: 0.15183963935890116]
	TIME [epoch: 8.85 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1347442144255814		[learning rate: 0.0026396]
		[batch 20/20] avg loss: 0.1523318016222123		[learning rate: 0.0026334]
	Learning Rate: 0.00263336
	LOSS [training: 0.14353800802389685 | validation: 0.03703350659745438]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_294.pth
	Model improved!!!
EPOCH 295/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10911089206971991		[learning rate: 0.0026272]
		[batch 20/20] avg loss: 0.10793361132605987		[learning rate: 0.002621]
	Learning Rate: 0.00262101
	LOSS [training: 0.1085222516978899 | validation: 0.06045646906172799]
	TIME [epoch: 8.84 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11509282369218281		[learning rate: 0.0026149]
		[batch 20/20] avg loss: 0.18022171500132714		[learning rate: 0.0026087]
	Learning Rate: 0.00260873
	LOSS [training: 0.14765726934675497 | validation: 0.20016172842274102]
	TIME [epoch: 8.82 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13330526639049775		[learning rate: 0.0026026]
		[batch 20/20] avg loss: 0.1262625818157214		[learning rate: 0.0025965]
	Learning Rate: 0.0025965
	LOSS [training: 0.12978392410310954 | validation: 0.12420801437136489]
	TIME [epoch: 8.86 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15013108088009783		[learning rate: 0.0025904]
		[batch 20/20] avg loss: 0.09368663646428552		[learning rate: 0.0025843]
	Learning Rate: 0.00258432
	LOSS [training: 0.12190885867219167 | validation: 0.11694202999531902]
	TIME [epoch: 8.83 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12174894538924712		[learning rate: 0.0025783]
		[batch 20/20] avg loss: 0.19739202661787728		[learning rate: 0.0025722]
	Learning Rate: 0.00257221
	LOSS [training: 0.15957048600356222 | validation: 0.06726801463880089]
	TIME [epoch: 8.83 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11845029474910906		[learning rate: 0.0025662]
		[batch 20/20] avg loss: 0.11633500917614814		[learning rate: 0.0025601]
	Learning Rate: 0.00256015
	LOSS [training: 0.1173926519626286 | validation: 0.11954712106744081]
	TIME [epoch: 8.83 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1337660728387998		[learning rate: 0.0025541]
		[batch 20/20] avg loss: 0.12114173447068974		[learning rate: 0.0025481]
	Learning Rate: 0.00254815
	LOSS [training: 0.1274539036547448 | validation: 0.12722960105332123]
	TIME [epoch: 8.83 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13356083057616075		[learning rate: 0.0025422]
		[batch 20/20] avg loss: 0.18255869781751125		[learning rate: 0.0025362]
	Learning Rate: 0.0025362
	LOSS [training: 0.158059764196836 | validation: 0.12298861591863446]
	TIME [epoch: 8.86 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10267919906585972		[learning rate: 0.0025302]
		[batch 20/20] avg loss: 0.13787747761905506		[learning rate: 0.0025243]
	Learning Rate: 0.00252431
	LOSS [training: 0.12027833834245738 | validation: 0.09045583498796766]
	TIME [epoch: 8.83 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10767580494964062		[learning rate: 0.0025184]
		[batch 20/20] avg loss: 0.15407018681748402		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.1308729958835623 | validation: 0.17312128692937423]
	TIME [epoch: 8.83 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1530527325366006		[learning rate: 0.0025066]
		[batch 20/20] avg loss: 0.19224278128609115		[learning rate: 0.0025007]
	Learning Rate: 0.0025007
	LOSS [training: 0.17264775691134587 | validation: 0.18063369278199606]
	TIME [epoch: 8.83 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1307160146101984		[learning rate: 0.0024948]
		[batch 20/20] avg loss: 0.1902718269796717		[learning rate: 0.002489]
	Learning Rate: 0.00248897
	LOSS [training: 0.16049392079493505 | validation: 0.10655819875815145]
	TIME [epoch: 8.84 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11329090468392358		[learning rate: 0.0024831]
		[batch 20/20] avg loss: 0.23101939256512521		[learning rate: 0.0024773]
	Learning Rate: 0.00247731
	LOSS [training: 0.17215514862452436 | validation: 0.1561156347970437]
	TIME [epoch: 8.85 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10893548968631701		[learning rate: 0.0024715]
		[batch 20/20] avg loss: 0.13394374879741355		[learning rate: 0.0024657]
	Learning Rate: 0.00246569
	LOSS [training: 0.1214396192418653 | validation: 0.07738328501513345]
	TIME [epoch: 8.83 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1133962516382672		[learning rate: 0.0024599]
		[batch 20/20] avg loss: 0.10843796859707344		[learning rate: 0.0024541]
	Learning Rate: 0.00245413
	LOSS [training: 0.11091711011767032 | validation: 0.13812054137655444]
	TIME [epoch: 8.83 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11098255102861507		[learning rate: 0.0024484]
		[batch 20/20] avg loss: 0.10136655839479809		[learning rate: 0.0024426]
	Learning Rate: 0.00244263
	LOSS [training: 0.10617455471170659 | validation: 0.17252712435936057]
	TIME [epoch: 8.83 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11497111382121314		[learning rate: 0.0024369]
		[batch 20/20] avg loss: 0.11909081257291203		[learning rate: 0.0024312]
	Learning Rate: 0.00243118
	LOSS [training: 0.11703096319706256 | validation: 0.11816175217399694]
	TIME [epoch: 8.86 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08954824136686232		[learning rate: 0.0024255]
		[batch 20/20] avg loss: 0.08541485989196887		[learning rate: 0.0024198]
	Learning Rate: 0.00241978
	LOSS [training: 0.08748155062941557 | validation: 0.21004473708745622]
	TIME [epoch: 8.84 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11725537567898703		[learning rate: 0.0024141]
		[batch 20/20] avg loss: 0.09926753033852401		[learning rate: 0.0024084]
	Learning Rate: 0.00240843
	LOSS [training: 0.10826145300875552 | validation: 0.13975991940527718]
	TIME [epoch: 8.83 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14117586117137648		[learning rate: 0.0024028]
		[batch 20/20] avg loss: 0.08336423578389648		[learning rate: 0.0023971]
	Learning Rate: 0.00239714
	LOSS [training: 0.11227004847763647 | validation: 0.10262887195357706]
	TIME [epoch: 8.83 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12145825563020754		[learning rate: 0.0023915]
		[batch 20/20] avg loss: 0.16092355788548718		[learning rate: 0.0023859]
	Learning Rate: 0.0023859
	LOSS [training: 0.14119090675784735 | validation: 0.08746632460615134]
	TIME [epoch: 8.83 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11742331334312987		[learning rate: 0.0023803]
		[batch 20/20] avg loss: 0.07321661960062353		[learning rate: 0.0023747]
	Learning Rate: 0.00237472
	LOSS [training: 0.0953199664718767 | validation: 0.11625541237710521]
	TIME [epoch: 8.86 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13044691533118866		[learning rate: 0.0023691]
		[batch 20/20] avg loss: 0.12568581549993824		[learning rate: 0.0023636]
	Learning Rate: 0.00236359
	LOSS [training: 0.12806636541556346 | validation: 0.11959856883837858]
	TIME [epoch: 8.84 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10001513179431083		[learning rate: 0.002358]
		[batch 20/20] avg loss: 0.20624873175188657		[learning rate: 0.0023525]
	Learning Rate: 0.00235251
	LOSS [training: 0.15313193177309872 | validation: 0.2860112545638883]
	TIME [epoch: 8.84 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14898318894423432		[learning rate: 0.002347]
		[batch 20/20] avg loss: 0.0788907321320541		[learning rate: 0.0023415]
	Learning Rate: 0.00234148
	LOSS [training: 0.1139369605381442 | validation: 0.21321476614219112]
	TIME [epoch: 8.84 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22378140939496327		[learning rate: 0.002336]
		[batch 20/20] avg loss: 0.11896839312012433		[learning rate: 0.0023305]
	Learning Rate: 0.0023305
	LOSS [training: 0.1713749012575438 | validation: 0.11511077529774041]
	TIME [epoch: 8.89 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08977602035950158		[learning rate: 0.002325]
		[batch 20/20] avg loss: 0.12597527332762046		[learning rate: 0.0023196]
	Learning Rate: 0.00231957
	LOSS [training: 0.10787564684356103 | validation: 0.10997598055517824]
	TIME [epoch: 8.86 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11601902877889463		[learning rate: 0.0023141]
		[batch 20/20] avg loss: 0.09641984722616379		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.1062194380025292 | validation: 0.07995268735414662]
	TIME [epoch: 8.84 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14056331296349947		[learning rate: 0.0023033]
		[batch 20/20] avg loss: 0.11358878460932623		[learning rate: 0.0022979]
	Learning Rate: 0.00229788
	LOSS [training: 0.12707604878641282 | validation: 0.16557073057420554]
	TIME [epoch: 8.84 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12427551026403365		[learning rate: 0.0022925]
		[batch 20/20] avg loss: 0.14143913408081038		[learning rate: 0.0022871]
	Learning Rate: 0.0022871
	LOSS [training: 0.13285732217242202 | validation: 0.16928279056783024]
	TIME [epoch: 8.84 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12187278309421648		[learning rate: 0.0022817]
		[batch 20/20] avg loss: 0.23481209999790634		[learning rate: 0.0022764]
	Learning Rate: 0.00227638
	LOSS [training: 0.17834244154606138 | validation: 0.19844029383135875]
	TIME [epoch: 8.85 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16417952419329138		[learning rate: 0.002271]
		[batch 20/20] avg loss: 0.12103771641673741		[learning rate: 0.0022657]
	Learning Rate: 0.00226571
	LOSS [training: 0.14260862030501437 | validation: 0.07554373241794285]
	TIME [epoch: 8.86 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08847220159126593		[learning rate: 0.0022604]
		[batch 20/20] avg loss: 0.12720092113484394		[learning rate: 0.0022551]
	Learning Rate: 0.00225509
	LOSS [training: 0.1078365613630549 | validation: 0.04433187967292363]
	TIME [epoch: 8.83 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11602672801885724		[learning rate: 0.0022498]
		[batch 20/20] avg loss: 0.09273523647597509		[learning rate: 0.0022445]
	Learning Rate: 0.00224451
	LOSS [training: 0.10438098224741618 | validation: 0.07094842050888935]
	TIME [epoch: 8.83 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1506512827143826		[learning rate: 0.0022392]
		[batch 20/20] avg loss: 0.14011138996944916		[learning rate: 0.002234]
	Learning Rate: 0.00223399
	LOSS [training: 0.14538133634191586 | validation: 0.16794802531899322]
	TIME [epoch: 8.83 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15599053541117897		[learning rate: 0.0022287]
		[batch 20/20] avg loss: 0.12629954378015026		[learning rate: 0.0022235]
	Learning Rate: 0.00222352
	LOSS [training: 0.14114503959566463 | validation: 0.05635913439064487]
	TIME [epoch: 8.85 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12156082066894018		[learning rate: 0.0022183]
		[batch 20/20] avg loss: 0.12672364743838185		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.12414223405366101 | validation: 0.10775298054807295]
	TIME [epoch: 8.83 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05411017788954816		[learning rate: 0.0022079]
		[batch 20/20] avg loss: 0.07205478423201478		[learning rate: 0.0022027]
	Learning Rate: 0.00220272
	LOSS [training: 0.06308248106078147 | validation: 0.15580848588646595]
	TIME [epoch: 8.83 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11492729011070438		[learning rate: 0.0021976]
		[batch 20/20] avg loss: 0.09864323024514463		[learning rate: 0.0021924]
	Learning Rate: 0.00219239
	LOSS [training: 0.10678526017792449 | validation: 0.10698824436796964]
	TIME [epoch: 8.83 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12414688840222572		[learning rate: 0.0021872]
		[batch 20/20] avg loss: 0.13764899248069123		[learning rate: 0.0021821]
	Learning Rate: 0.00218211
	LOSS [training: 0.13089794044145844 | validation: 0.10692302726615863]
	TIME [epoch: 8.83 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0972564234459753		[learning rate: 0.002177]
		[batch 20/20] avg loss: 0.10878715747979703		[learning rate: 0.0021719]
	Learning Rate: 0.00217188
	LOSS [training: 0.10302179046288618 | validation: 0.09096196291133349]
	TIME [epoch: 8.86 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12276604151289332		[learning rate: 0.0021668]
		[batch 20/20] avg loss: 0.09590671804362423		[learning rate: 0.0021617]
	Learning Rate: 0.0021617
	LOSS [training: 0.10933637977825879 | validation: 0.21581399605533808]
	TIME [epoch: 8.83 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11315629985610465		[learning rate: 0.0021566]
		[batch 20/20] avg loss: 0.10924718280539578		[learning rate: 0.0021516]
	Learning Rate: 0.00215157
	LOSS [training: 0.11120174133075023 | validation: 0.05579897739124969]
	TIME [epoch: 8.83 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11414730884801572		[learning rate: 0.0021465]
		[batch 20/20] avg loss: 0.11827491837626909		[learning rate: 0.0021415]
	Learning Rate: 0.00214148
	LOSS [training: 0.11621111361214242 | validation: 0.08171144794866407]
	TIME [epoch: 8.83 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10373090372120894		[learning rate: 0.0021365]
		[batch 20/20] avg loss: 0.09022454123704027		[learning rate: 0.0021314]
	Learning Rate: 0.00213144
	LOSS [training: 0.0969777224791246 | validation: 0.10901680059220278]
	TIME [epoch: 8.84 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09530978765171168		[learning rate: 0.0021264]
		[batch 20/20] avg loss: 0.10338566018739215		[learning rate: 0.0021214]
	Learning Rate: 0.00212145
	LOSS [training: 0.09934772391955192 | validation: 0.11355485510184204]
	TIME [epoch: 8.84 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10766275067557993		[learning rate: 0.0021165]
		[batch 20/20] avg loss: 0.10404244654266778		[learning rate: 0.0021115]
	Learning Rate: 0.0021115
	LOSS [training: 0.10585259860912385 | validation: 0.1419618442101333]
	TIME [epoch: 8.83 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14226253144122403		[learning rate: 0.0021065]
		[batch 20/20] avg loss: 0.15998048347717017		[learning rate: 0.0021016]
	Learning Rate: 0.0021016
	LOSS [training: 0.1511215074591971 | validation: 0.084589932539189]
	TIME [epoch: 8.83 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08713471748439355		[learning rate: 0.0020967]
		[batch 20/20] avg loss: 0.09625100329158545		[learning rate: 0.0020918]
	Learning Rate: 0.00209175
	LOSS [training: 0.09169286038798952 | validation: 0.10217873057903595]
	TIME [epoch: 8.83 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09403355024388814		[learning rate: 0.0020868]
		[batch 20/20] avg loss: 0.10794971702740283		[learning rate: 0.0020819]
	Learning Rate: 0.00208195
	LOSS [training: 0.10099163363564549 | validation: 0.07605837120488713]
	TIME [epoch: 8.84 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08223743723528784		[learning rate: 0.0020771]
		[batch 20/20] avg loss: 0.12647835743199062		[learning rate: 0.0020722]
	Learning Rate: 0.00207219
	LOSS [training: 0.10435789733363925 | validation: 0.11982294529914365]
	TIME [epoch: 8.85 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09205333113852915		[learning rate: 0.0020673]
		[batch 20/20] avg loss: 0.13273145390621258		[learning rate: 0.0020625]
	Learning Rate: 0.00206247
	LOSS [training: 0.11239239252237088 | validation: 0.08288733709013878]
	TIME [epoch: 8.83 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11622082443501172		[learning rate: 0.0020576]
		[batch 20/20] avg loss: 0.1005843678486494		[learning rate: 0.0020528]
	Learning Rate: 0.0020528
	LOSS [training: 0.10840259614183054 | validation: 0.05992824763297065]
	TIME [epoch: 8.83 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14122027836802925		[learning rate: 0.002048]
		[batch 20/20] avg loss: 0.10148873126607942		[learning rate: 0.0020432]
	Learning Rate: 0.00204318
	LOSS [training: 0.12135450481705437 | validation: 0.06965682762321551]
	TIME [epoch: 8.83 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07945978387777274		[learning rate: 0.0020384]
		[batch 20/20] avg loss: 0.07444580235452		[learning rate: 0.0020336]
	Learning Rate: 0.0020336
	LOSS [training: 0.07695279311614636 | validation: 0.06606753578931875]
	TIME [epoch: 8.85 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08194798897658491		[learning rate: 0.0020288]
		[batch 20/20] avg loss: 0.09764322468726537		[learning rate: 0.0020241]
	Learning Rate: 0.00202407
	LOSS [training: 0.08979560683192514 | validation: 0.0638009641107865]
	TIME [epoch: 8.83 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06943131905702155		[learning rate: 0.0020193]
		[batch 20/20] avg loss: 0.08503027825141983		[learning rate: 0.0020146]
	Learning Rate: 0.00201458
	LOSS [training: 0.07723079865422071 | validation: 0.06809146703788939]
	TIME [epoch: 8.84 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09925616179224984		[learning rate: 0.0020098]
		[batch 20/20] avg loss: 0.11039847350777836		[learning rate: 0.0020051]
	Learning Rate: 0.00200513
	LOSS [training: 0.1048273176500141 | validation: 0.15892979822703587]
	TIME [epoch: 8.84 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10171887839719036		[learning rate: 0.0020004]
		[batch 20/20] avg loss: 0.07356978700005608		[learning rate: 0.0019957]
	Learning Rate: 0.00199573
	LOSS [training: 0.08764433269862322 | validation: 0.03296194957060339]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_353.pth
	Model improved!!!
EPOCH 354/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09388391565772139		[learning rate: 0.001991]
		[batch 20/20] avg loss: 0.08526775018421986		[learning rate: 0.0019864]
	Learning Rate: 0.00198637
	LOSS [training: 0.08957583292097064 | validation: 0.10686247551592808]
	TIME [epoch: 8.85 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13255525091430131		[learning rate: 0.0019817]
		[batch 20/20] avg loss: 0.15326446959829693		[learning rate: 0.0019771]
	Learning Rate: 0.00197706
	LOSS [training: 0.14290986025629915 | validation: 0.15223668672037954]
	TIME [epoch: 8.83 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12350893822709393		[learning rate: 0.0019724]
		[batch 20/20] avg loss: 0.11514945231572764		[learning rate: 0.0019678]
	Learning Rate: 0.00196779
	LOSS [training: 0.11932919527141077 | validation: 0.1138583232174951]
	TIME [epoch: 8.83 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0829211086752937		[learning rate: 0.0019632]
		[batch 20/20] avg loss: 0.08262403842134923		[learning rate: 0.0019586]
	Learning Rate: 0.00195857
	LOSS [training: 0.08277257354832147 | validation: 0.052752679874902786]
	TIME [epoch: 8.83 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07872639209929648		[learning rate: 0.001954]
		[batch 20/20] avg loss: 0.09610125015072567		[learning rate: 0.0019494]
	Learning Rate: 0.00194939
	LOSS [training: 0.08741382112501107 | validation: 0.13486335715488257]
	TIME [epoch: 8.84 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11872510947671011		[learning rate: 0.0019448]
		[batch 20/20] avg loss: 0.09533507686835081		[learning rate: 0.0019402]
	Learning Rate: 0.00194025
	LOSS [training: 0.10703009317253045 | validation: 0.07776383125591707]
	TIME [epoch: 8.84 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14441943499206802		[learning rate: 0.0019357]
		[batch 20/20] avg loss: 0.09955133476916968		[learning rate: 0.0019312]
	Learning Rate: 0.00193115
	LOSS [training: 0.12198538488061886 | validation: 0.0861884328845636]
	TIME [epoch: 8.83 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10706512702966157		[learning rate: 0.0019266]
		[batch 20/20] avg loss: 0.10200583856885692		[learning rate: 0.0019221]
	Learning Rate: 0.0019221
	LOSS [training: 0.10453548279925926 | validation: 0.11481040998207113]
	TIME [epoch: 8.83 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08663106360659724		[learning rate: 0.0019176]
		[batch 20/20] avg loss: 0.0986785872242456		[learning rate: 0.0019131]
	Learning Rate: 0.00191309
	LOSS [training: 0.09265482541542142 | validation: 0.1062132171288375]
	TIME [epoch: 8.83 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0820746154957597		[learning rate: 0.0019086]
		[batch 20/20] avg loss: 0.10115350648203399		[learning rate: 0.0019041]
	Learning Rate: 0.00190412
	LOSS [training: 0.09161406098889684 | validation: 0.06436423500055628]
	TIME [epoch: 8.86 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07679053334311518		[learning rate: 0.0018996]
		[batch 20/20] avg loss: 0.09144702797343869		[learning rate: 0.0018952]
	Learning Rate: 0.00189519
	LOSS [training: 0.08411878065827695 | validation: 0.05466184374498116]
	TIME [epoch: 8.83 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11042138088547768		[learning rate: 0.0018907]
		[batch 20/20] avg loss: 0.0782326201765828		[learning rate: 0.0018863]
	Learning Rate: 0.00188631
	LOSS [training: 0.09432700053103024 | validation: 0.07865900503966972]
	TIME [epoch: 8.84 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09230715572575265		[learning rate: 0.0018819]
		[batch 20/20] avg loss: 0.13652060304055003		[learning rate: 0.0018775]
	Learning Rate: 0.00187746
	LOSS [training: 0.11441387938315135 | validation: 0.09824906224020838]
	TIME [epoch: 8.83 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07066510347924239		[learning rate: 0.0018731]
		[batch 20/20] avg loss: 0.07260890026511672		[learning rate: 0.0018687]
	Learning Rate: 0.00186866
	LOSS [training: 0.07163700187217956 | validation: 0.034617547847254806]
	TIME [epoch: 8.84 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07026069143762878		[learning rate: 0.0018643]
		[batch 20/20] avg loss: 0.09372950249138902		[learning rate: 0.0018599]
	Learning Rate: 0.0018599
	LOSS [training: 0.08199509696450889 | validation: 0.0777085888145786]
	TIME [epoch: 8.86 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08144443639691817		[learning rate: 0.0018555]
		[batch 20/20] avg loss: 0.08442285210357839		[learning rate: 0.0018512]
	Learning Rate: 0.00185118
	LOSS [training: 0.08293364425024827 | validation: 0.07772654580944327]
	TIME [epoch: 8.84 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09618360371095717		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.08310824302001932		[learning rate: 0.0018425]
	Learning Rate: 0.0018425
	LOSS [training: 0.08964592336548824 | validation: 0.1456442802410379]
	TIME [epoch: 8.84 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08606062446132624		[learning rate: 0.0018382]
		[batch 20/20] avg loss: 0.08976838204242218		[learning rate: 0.0018339]
	Learning Rate: 0.00183386
	LOSS [training: 0.0879145032518742 | validation: 0.11279293354268946]
	TIME [epoch: 8.83 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09517961360668477		[learning rate: 0.0018296]
		[batch 20/20] avg loss: 0.09929357632797729		[learning rate: 0.0018253]
	Learning Rate: 0.00182527
	LOSS [training: 0.09723659496733103 | validation: 0.2563053257990726]
	TIME [epoch: 8.84 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09751957881940188		[learning rate: 0.001821]
		[batch 20/20] avg loss: 0.07847030815409423		[learning rate: 0.0018167]
	Learning Rate: 0.00181671
	LOSS [training: 0.08799494348674805 | validation: 0.11171403209197957]
	TIME [epoch: 8.85 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09274415003330952		[learning rate: 0.0018124]
		[batch 20/20] avg loss: 0.08761679879831671		[learning rate: 0.0018082]
	Learning Rate: 0.00180819
	LOSS [training: 0.09018047441581313 | validation: 0.09584003138773667]
	TIME [epoch: 8.83 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08197767166372578		[learning rate: 0.001804]
		[batch 20/20] avg loss: 0.07347166979175615		[learning rate: 0.0017997]
	Learning Rate: 0.00179972
	LOSS [training: 0.07772467072774096 | validation: 0.044187009864850524]
	TIME [epoch: 8.83 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09495021571379927		[learning rate: 0.0017955]
		[batch 20/20] avg loss: 0.10293869404726763		[learning rate: 0.0017913]
	Learning Rate: 0.00179128
	LOSS [training: 0.09894445488053344 | validation: 0.05766752453927604]
	TIME [epoch: 8.83 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07859911497535141		[learning rate: 0.0017871]
		[batch 20/20] avg loss: 0.08242254864959428		[learning rate: 0.0017829]
	Learning Rate: 0.00178288
	LOSS [training: 0.08051083181247284 | validation: 0.03267900899213519]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_377.pth
	Model improved!!!
EPOCH 378/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07571916039459893		[learning rate: 0.0017787]
		[batch 20/20] avg loss: 0.10268383497271674		[learning rate: 0.0017745]
	Learning Rate: 0.00177452
	LOSS [training: 0.08920149768365782 | validation: 0.107338536692395]
	TIME [epoch: 8.85 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07578350150066435		[learning rate: 0.0017704]
		[batch 20/20] avg loss: 0.0786032660491651		[learning rate: 0.0017662]
	Learning Rate: 0.0017662
	LOSS [training: 0.07719338377491472 | validation: 0.22945346717111634]
	TIME [epoch: 8.83 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0941916918750054		[learning rate: 0.0017621]
		[batch 20/20] avg loss: 0.11050060148921773		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.10234614668211157 | validation: 0.06250171014366886]
	TIME [epoch: 8.83 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10018721182232751		[learning rate: 0.0017538]
		[batch 20/20] avg loss: 0.07714036480359152		[learning rate: 0.0017497]
	Learning Rate: 0.00174968
	LOSS [training: 0.0886637883129595 | validation: 0.028919875665193728]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_381.pth
	Model improved!!!
EPOCH 382/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08436984122909437		[learning rate: 0.0017456]
		[batch 20/20] avg loss: 0.10311959994021136		[learning rate: 0.0017415]
	Learning Rate: 0.00174148
	LOSS [training: 0.09374472058465287 | validation: 0.11672203544891216]
	TIME [epoch: 8.85 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08292926353128657		[learning rate: 0.0017374]
		[batch 20/20] avg loss: 0.07849274534048768		[learning rate: 0.0017333]
	Learning Rate: 0.00173331
	LOSS [training: 0.08071100443588712 | validation: 0.04368573277750065]
	TIME [epoch: 8.83 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09409071914709874		[learning rate: 0.0017292]
		[batch 20/20] avg loss: 0.06800022898607973		[learning rate: 0.0017252]
	Learning Rate: 0.00172519
	LOSS [training: 0.08104547406658923 | validation: 0.09946146581012602]
	TIME [epoch: 8.83 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08186903802014282		[learning rate: 0.0017211]
		[batch 20/20] avg loss: 0.07431874082644793		[learning rate: 0.0017171]
	Learning Rate: 0.0017171
	LOSS [training: 0.07809388942329538 | validation: 0.13985138757705573]
	TIME [epoch: 8.86 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/20] avg loss: 0.061197366089738636		[learning rate: 0.0017131]
		[batch 20/20] avg loss: 0.08344391375670142		[learning rate: 0.0017091]
	Learning Rate: 0.00170905
	LOSS [training: 0.07232063992322002 | validation: 0.1603750060906335]
	TIME [epoch: 8.83 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07579831358240495		[learning rate: 0.001705]
		[batch 20/20] avg loss: 0.07312699508637699		[learning rate: 0.001701]
	Learning Rate: 0.00170104
	LOSS [training: 0.07446265433439095 | validation: 0.12263231537074855]
	TIME [epoch: 8.85 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06404732596833383		[learning rate: 0.001697]
		[batch 20/20] avg loss: 0.06929453039699653		[learning rate: 0.0016931]
	Learning Rate: 0.00169306
	LOSS [training: 0.06667092818266517 | validation: 0.05218036235909137]
	TIME [epoch: 8.83 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1253687588451127		[learning rate: 0.0016891]
		[batch 20/20] avg loss: 0.11449983614039642		[learning rate: 0.0016851]
	Learning Rate: 0.00168513
	LOSS [training: 0.11993429749275455 | validation: 0.0707368102222119]
	TIME [epoch: 8.83 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09677311883584794		[learning rate: 0.0016812]
		[batch 20/20] avg loss: 0.07898555043587129		[learning rate: 0.0016772]
	Learning Rate: 0.00167723
	LOSS [training: 0.08787933463585963 | validation: 0.06385145900112658]
	TIME [epoch: 8.83 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0798939673467327		[learning rate: 0.0016733]
		[batch 20/20] avg loss: 0.09790196075757444		[learning rate: 0.0016694]
	Learning Rate: 0.00166936
	LOSS [training: 0.08889796405215358 | validation: 0.06455602200565501]
	TIME [epoch: 8.84 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07710053132554269		[learning rate: 0.0016654]
		[batch 20/20] avg loss: 0.07868151131187215		[learning rate: 0.0016615]
	Learning Rate: 0.00166154
	LOSS [training: 0.07789102131870743 | validation: 0.14485074425359365]
	TIME [epoch: 8.84 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07263647619951408		[learning rate: 0.0016576]
		[batch 20/20] avg loss: 0.0554096691923844		[learning rate: 0.0016537]
	Learning Rate: 0.00165375
	LOSS [training: 0.06402307269594924 | validation: 0.19053535836109473]
	TIME [epoch: 8.83 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09225118525298502		[learning rate: 0.0016499]
		[batch 20/20] avg loss: 0.05741062321755371		[learning rate: 0.001646]
	Learning Rate: 0.001646
	LOSS [training: 0.07483090423526936 | validation: 0.07339074904069505]
	TIME [epoch: 8.83 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08438532609892309		[learning rate: 0.0016421]
		[batch 20/20] avg loss: 0.0805944085659471		[learning rate: 0.0016383]
	Learning Rate: 0.00163828
	LOSS [training: 0.08248986733243507 | validation: 0.06196940039277518]
	TIME [epoch: 8.83 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07434279205308758		[learning rate: 0.0016344]
		[batch 20/20] avg loss: 0.08788357263375404		[learning rate: 0.0016306]
	Learning Rate: 0.0016306
	LOSS [training: 0.08111318234342081 | validation: 0.08044667368584096]
	TIME [epoch: 8.85 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07015169430907672		[learning rate: 0.0016268]
		[batch 20/20] avg loss: 0.055455055741778905		[learning rate: 0.001623]
	Learning Rate: 0.00162295
	LOSS [training: 0.06280337502542781 | validation: 0.07368944146970871]
	TIME [epoch: 8.83 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07349056618375434		[learning rate: 0.0016191]
		[batch 20/20] avg loss: 0.12495734179014409		[learning rate: 0.0016153]
	Learning Rate: 0.00161535
	LOSS [training: 0.0992239539869492 | validation: 0.07364960461438985]
	TIME [epoch: 8.83 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10549466235847345		[learning rate: 0.0016116]
		[batch 20/20] avg loss: 0.09112975928782949		[learning rate: 0.0016078]
	Learning Rate: 0.00160777
	LOSS [training: 0.09831221082315147 | validation: 0.0614208335289904]
	TIME [epoch: 8.83 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08582980832567835		[learning rate: 0.001604]
		[batch 20/20] avg loss: 0.11253619078282566		[learning rate: 0.0016002]
	Learning Rate: 0.00160023
	LOSS [training: 0.09918299955425203 | validation: 0.14233867329722105]
	TIME [epoch: 8.83 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09670424699517512		[learning rate: 0.0015965]
		[batch 20/20] avg loss: 0.08762924068033878		[learning rate: 0.0015927]
	Learning Rate: 0.00159273
	LOSS [training: 0.09216674383775694 | validation: 0.04263854446463771]
	TIME [epoch: 8.86 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/20] avg loss: 0.058092814194890895		[learning rate: 0.001589]
		[batch 20/20] avg loss: 0.05043502920583863		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.05426392170036478 | validation: 0.12899472333649126]
	TIME [epoch: 8.83 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08014771006501055		[learning rate: 0.0015815]
		[batch 20/20] avg loss: 0.10954753620442226		[learning rate: 0.0015778]
	Learning Rate: 0.00157783
	LOSS [training: 0.09484762313471641 | validation: 0.05975628761156614]
	TIME [epoch: 8.83 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07399344608440643		[learning rate: 0.0015741]
		[batch 20/20] avg loss: 0.1398415726474383		[learning rate: 0.0015704]
	Learning Rate: 0.00157044
	LOSS [training: 0.10691750936592237 | validation: 0.19274009835904746]
	TIME [epoch: 8.83 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09369061184857155		[learning rate: 0.0015668]
		[batch 20/20] avg loss: 0.09949858404242673		[learning rate: 0.0015631]
	Learning Rate: 0.00156307
	LOSS [training: 0.09659459794549914 | validation: 0.11032469371021268]
	TIME [epoch: 8.84 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07544543833188902		[learning rate: 0.0015594]
		[batch 20/20] avg loss: 0.0672344792687714		[learning rate: 0.0015557]
	Learning Rate: 0.00155575
	LOSS [training: 0.0713399588003302 | validation: 0.06144743557908289]
	TIME [epoch: 8.85 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10107664099122968		[learning rate: 0.0015521]
		[batch 20/20] avg loss: 0.12600437163469663		[learning rate: 0.0015485]
	Learning Rate: 0.00154845
	LOSS [training: 0.11354050631296313 | validation: 0.0884531690707929]
	TIME [epoch: 8.83 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1025136564966805		[learning rate: 0.0015448]
		[batch 20/20] avg loss: 0.08529117389123023		[learning rate: 0.0015412]
	Learning Rate: 0.00154119
	LOSS [training: 0.09390241519395535 | validation: 0.06219863952112972]
	TIME [epoch: 8.83 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08627240824184174		[learning rate: 0.0015376]
		[batch 20/20] avg loss: 0.07846129914207237		[learning rate: 0.001534]
	Learning Rate: 0.00153397
	LOSS [training: 0.08236685369195704 | validation: 0.0737152373240668]
	TIME [epoch: 8.83 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08775720138124973		[learning rate: 0.0015304]
		[batch 20/20] avg loss: 0.08754124091695314		[learning rate: 0.0015268]
	Learning Rate: 0.00152678
	LOSS [training: 0.08764922114910144 | validation: 0.07079721921392065]
	TIME [epoch: 8.84 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10964201205409851		[learning rate: 0.0015232]
		[batch 20/20] avg loss: 0.09909832678347226		[learning rate: 0.0015196]
	Learning Rate: 0.00151962
	LOSS [training: 0.10437016941878541 | validation: 0.05216824719348912]
	TIME [epoch: 8.84 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04608978948162907		[learning rate: 0.0015161]
		[batch 20/20] avg loss: 0.050786432599432406		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.04843811104053075 | validation: 0.04136747258304514]
	TIME [epoch: 8.83 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08850985440552868		[learning rate: 0.0015089]
		[batch 20/20] avg loss: 0.058857524963986566		[learning rate: 0.0015054]
	Learning Rate: 0.0015054
	LOSS [training: 0.07368368968475761 | validation: 0.06132564759075588]
	TIME [epoch: 8.83 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06445956495149555		[learning rate: 0.0015019]
		[batch 20/20] avg loss: 0.06703239424901812		[learning rate: 0.0014983]
	Learning Rate: 0.00149835
	LOSS [training: 0.06574597960025681 | validation: 0.032760766355287976]
	TIME [epoch: 8.83 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0766430374644234		[learning rate: 0.0014948]
		[batch 20/20] avg loss: 0.07872851815266464		[learning rate: 0.0014913]
	Learning Rate: 0.00149132
	LOSS [training: 0.07768577780854401 | validation: 0.27572004379414417]
	TIME [epoch: 8.85 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09361105999920974		[learning rate: 0.0014878]
		[batch 20/20] avg loss: 0.08955735765493876		[learning rate: 0.0014843]
	Learning Rate: 0.00148433
	LOSS [training: 0.09158420882707426 | validation: 0.08023436199269449]
	TIME [epoch: 8.83 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08616749793626141		[learning rate: 0.0014808]
		[batch 20/20] avg loss: 0.08425118383177077		[learning rate: 0.0014774]
	Learning Rate: 0.00147737
	LOSS [training: 0.08520934088401609 | validation: 0.05594178653322712]
	TIME [epoch: 8.83 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07219856110573662		[learning rate: 0.0014739]
		[batch 20/20] avg loss: 0.06348870242143051		[learning rate: 0.0014704]
	Learning Rate: 0.00147045
	LOSS [training: 0.06784363176358357 | validation: 0.056093477706795236]
	TIME [epoch: 8.83 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/20] avg loss: 0.052392812668202005		[learning rate: 0.001467]
		[batch 20/20] avg loss: 0.08123160817440579		[learning rate: 0.0014636]
	Learning Rate: 0.00146355
	LOSS [training: 0.0668122104213039 | validation: 0.11787098078902924]
	TIME [epoch: 8.83 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10008172982176693		[learning rate: 0.0014601]
		[batch 20/20] avg loss: 0.08791503564925537		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.09399838273551114 | validation: 0.032875983973458145]
	TIME [epoch: 8.86 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05528900998915505		[learning rate: 0.0014533]
		[batch 20/20] avg loss: 0.06363649634364639		[learning rate: 0.0014499]
	Learning Rate: 0.00144986
	LOSS [training: 0.059462753166400706 | validation: 0.06620969912644288]
	TIME [epoch: 8.83 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06512641451819257		[learning rate: 0.0014465]
		[batch 20/20] avg loss: 0.05968812592099546		[learning rate: 0.0014431]
	Learning Rate: 0.00144306
	LOSS [training: 0.06240727021959401 | validation: 0.09163646099056624]
	TIME [epoch: 8.83 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/20] avg loss: 0.074963905375047		[learning rate: 0.0014397]
		[batch 20/20] avg loss: 0.06784598344967496		[learning rate: 0.0014363]
	Learning Rate: 0.0014363
	LOSS [training: 0.07140494441236098 | validation: 0.08407361857643735]
	TIME [epoch: 8.83 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07378779291292589		[learning rate: 0.0014329]
		[batch 20/20] avg loss: 0.04867877202274444		[learning rate: 0.0014296]
	Learning Rate: 0.00142957
	LOSS [training: 0.06123328246783516 | validation: 0.050939798188822744]
	TIME [epoch: 8.84 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05104785564422106		[learning rate: 0.0014262]
		[batch 20/20] avg loss: 0.06466012726153099		[learning rate: 0.0014229]
	Learning Rate: 0.00142286
	LOSS [training: 0.05785399145287602 | validation: 0.046489160445293894]
	TIME [epoch: 8.84 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0884122976527847		[learning rate: 0.0014195]
		[batch 20/20] avg loss: 0.058607466351198755		[learning rate: 0.0014162]
	Learning Rate: 0.00141619
	LOSS [training: 0.07350988200199172 | validation: 0.050619693118062775]
	TIME [epoch: 8.83 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07705293162506224		[learning rate: 0.0014129]
		[batch 20/20] avg loss: 0.08706627252184235		[learning rate: 0.0014096]
	Learning Rate: 0.00140955
	LOSS [training: 0.08205960207345228 | validation: 0.11766957107468715]
	TIME [epoch: 8.82 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08821325959347442		[learning rate: 0.0014062]
		[batch 20/20] avg loss: 0.05270028686132387		[learning rate: 0.0014029]
	Learning Rate: 0.00140295
	LOSS [training: 0.07045677322739914 | validation: 0.16568300704098177]
	TIME [epoch: 8.83 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09427270725793721		[learning rate: 0.0013997]
		[batch 20/20] avg loss: 0.08461467997435877		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.089443693616148 | validation: 0.04451240240232136]
	TIME [epoch: 8.85 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06891396100683893		[learning rate: 0.0013931]
		[batch 20/20] avg loss: 0.1112058420052567		[learning rate: 0.0013898]
	Learning Rate: 0.00138982
	LOSS [training: 0.09005990150604781 | validation: 0.11233118667110793]
	TIME [epoch: 8.83 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06901153176900823		[learning rate: 0.0013866]
		[batch 20/20] avg loss: 0.1030214423199276		[learning rate: 0.0013833]
	Learning Rate: 0.00138331
	LOSS [training: 0.08601648704446793 | validation: 0.05846426935436658]
	TIME [epoch: 8.83 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07330270770670141		[learning rate: 0.0013801]
		[batch 20/20] avg loss: 0.055219849224601734		[learning rate: 0.0013768]
	Learning Rate: 0.00137682
	LOSS [training: 0.06426127846565158 | validation: 0.04730208304095886]
	TIME [epoch: 8.83 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06913561080994582		[learning rate: 0.0013736]
		[batch 20/20] avg loss: 0.06939559759492685		[learning rate: 0.0013704]
	Learning Rate: 0.00137037
	LOSS [training: 0.06926560420243633 | validation: 0.047747174767928634]
	TIME [epoch: 8.83 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06912876787719743		[learning rate: 0.0013672]
		[batch 20/20] avg loss: 0.08075468728717289		[learning rate: 0.0013639]
	Learning Rate: 0.00136394
	LOSS [training: 0.07494172758218517 | validation: 0.05829909251455995]
	TIME [epoch: 8.85 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0846950411590684		[learning rate: 0.0013607]
		[batch 20/20] avg loss: 0.08184465671931222		[learning rate: 0.0013575]
	Learning Rate: 0.00135755
	LOSS [training: 0.0832698489391903 | validation: 0.0825075295512761]
	TIME [epoch: 8.83 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06266472131067892		[learning rate: 0.0013544]
		[batch 20/20] avg loss: 0.08575880491450237		[learning rate: 0.0013512]
	Learning Rate: 0.00135118
	LOSS [training: 0.07421176311259063 | validation: 0.10924640157124571]
	TIME [epoch: 8.83 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05709028073912177		[learning rate: 0.001348]
		[batch 20/20] avg loss: 0.05326840215476177		[learning rate: 0.0013448]
	Learning Rate: 0.00134485
	LOSS [training: 0.05517934144694179 | validation: 0.03911642121320834]
	TIME [epoch: 8.83 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/20] avg loss: 0.057733534346207684		[learning rate: 0.0013417]
		[batch 20/20] avg loss: 0.08047600502890544		[learning rate: 0.0013385]
	Learning Rate: 0.00133854
	LOSS [training: 0.06910476968755656 | validation: 0.061531054703515366]
	TIME [epoch: 8.84 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06451071130729658		[learning rate: 0.0013354]
		[batch 20/20] avg loss: 0.054978471681062624		[learning rate: 0.0013323]
	Learning Rate: 0.00133227
	LOSS [training: 0.0597445914941796 | validation: 0.159024310288865]
	TIME [epoch: 8.85 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08287885595376956		[learning rate: 0.0013291]
		[batch 20/20] avg loss: 0.05075563957616623		[learning rate: 0.001326]
	Learning Rate: 0.00132602
	LOSS [training: 0.06681724776496789 | validation: 0.07653602776859186]
	TIME [epoch: 8.83 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/20] avg loss: 0.050754813893591946		[learning rate: 0.0013229]
		[batch 20/20] avg loss: 0.05594605083861083		[learning rate: 0.0013198]
	Learning Rate: 0.00131981
	LOSS [training: 0.053350432366101395 | validation: 0.11561768695459103]
	TIME [epoch: 8.83 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09285591697492734		[learning rate: 0.0013167]
		[batch 20/20] avg loss: 0.10374726164174745		[learning rate: 0.0013136]
	Learning Rate: 0.00131362
	LOSS [training: 0.0983015893083374 | validation: 0.0406255990172749]
	TIME [epoch: 8.83 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05296464426638382		[learning rate: 0.0013105]
		[batch 20/20] avg loss: 0.0754198864240062		[learning rate: 0.0013075]
	Learning Rate: 0.00130746
	LOSS [training: 0.064192265345195 | validation: 0.06579812630170755]
	TIME [epoch: 8.84 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06941353081607002		[learning rate: 0.0013044]
		[batch 20/20] avg loss: 0.06052849272620971		[learning rate: 0.0013013]
	Learning Rate: 0.00130133
	LOSS [training: 0.06497101177113986 | validation: 0.04763413189851459]
	TIME [epoch: 8.84 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04613792828058263		[learning rate: 0.0012983]
		[batch 20/20] avg loss: 0.05212263638933954		[learning rate: 0.0012952]
	Learning Rate: 0.00129523
	LOSS [training: 0.04913028233496108 | validation: 0.07312972328254866]
	TIME [epoch: 8.83 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05032940762025754		[learning rate: 0.0012922]
		[batch 20/20] avg loss: 0.05802411918583063		[learning rate: 0.0012892]
	Learning Rate: 0.00128916
	LOSS [training: 0.05417676340304407 | validation: 0.08731943932496966]
	TIME [epoch: 8.83 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0868390610458241		[learning rate: 0.0012861]
		[batch 20/20] avg loss: 0.06206764560278857		[learning rate: 0.0012831]
	Learning Rate: 0.00128311
	LOSS [training: 0.07445335332430633 | validation: 0.05023760413121527]
	TIME [epoch: 8.82 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0765560585702202		[learning rate: 0.0012801]
		[batch 20/20] avg loss: 0.10618575333488778		[learning rate: 0.0012771]
	Learning Rate: 0.0012771
	LOSS [training: 0.091370905952554 | validation: 0.06347931600817461]
	TIME [epoch: 8.85 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05270906086775975		[learning rate: 0.0012741]
		[batch 20/20] avg loss: 0.047515626036657974		[learning rate: 0.0012711]
	Learning Rate: 0.00127111
	LOSS [training: 0.050112343452208864 | validation: 0.04323751317239917]
	TIME [epoch: 8.83 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05230926843487612		[learning rate: 0.0012681]
		[batch 20/20] avg loss: 0.07803264746752595		[learning rate: 0.0012652]
	Learning Rate: 0.00126515
	LOSS [training: 0.06517095795120104 | validation: 0.058150106727780454]
	TIME [epoch: 8.83 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06982037335344503		[learning rate: 0.0012622]
		[batch 20/20] avg loss: 0.044448525718086024		[learning rate: 0.0012592]
	Learning Rate: 0.00125922
	LOSS [training: 0.05713444953576553 | validation: 0.09358764588123172]
	TIME [epoch: 8.82 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06492797548362113		[learning rate: 0.0012563]
		[batch 20/20] avg loss: 0.07139870982618893		[learning rate: 0.0012533]
	Learning Rate: 0.00125332
	LOSS [training: 0.06816334265490502 | validation: 0.06717063371959722]
	TIME [epoch: 8.83 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05427420357541727		[learning rate: 0.0012504]
		[batch 20/20] avg loss: 0.05332516424147762		[learning rate: 0.0012474]
	Learning Rate: 0.00124744
	LOSS [training: 0.053799683908447436 | validation: 0.10900487465782772]
	TIME [epoch: 8.85 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0744413392246256		[learning rate: 0.0012445]
		[batch 20/20] avg loss: 0.05870243325859983		[learning rate: 0.0012416]
	Learning Rate: 0.00124159
	LOSS [training: 0.06657188624161273 | validation: 0.08183915325371317]
	TIME [epoch: 8.83 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07406865752409077		[learning rate: 0.0012387]
		[batch 20/20] avg loss: 0.08662964675854838		[learning rate: 0.0012358]
	Learning Rate: 0.00123577
	LOSS [training: 0.08034915214131956 | validation: 0.03581220735208139]
	TIME [epoch: 8.83 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0573772368510328		[learning rate: 0.0012329]
		[batch 20/20] avg loss: 0.08575531056895677		[learning rate: 0.00123]
	Learning Rate: 0.00122998
	LOSS [training: 0.07156627370999477 | validation: 0.13293831521910032]
	TIME [epoch: 8.83 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0633820145578122		[learning rate: 0.0012271]
		[batch 20/20] avg loss: 0.05974005050249052		[learning rate: 0.0012242]
	Learning Rate: 0.00122421
	LOSS [training: 0.06156103253015135 | validation: 0.08651048095213763]
	TIME [epoch: 8.83 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0720357092687604		[learning rate: 0.0012213]
		[batch 20/20] avg loss: 0.08542979666955954		[learning rate: 0.0012185]
	Learning Rate: 0.00121847
	LOSS [training: 0.07873275296915996 | validation: 0.0581094287520658]
	TIME [epoch: 8.84 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/20] avg loss: 0.069727595585091		[learning rate: 0.0012156]
		[batch 20/20] avg loss: 0.08915922247821442		[learning rate: 0.0012128]
	Learning Rate: 0.00121276
	LOSS [training: 0.07944340903165273 | validation: 0.0351751442227714]
	TIME [epoch: 8.83 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/20] avg loss: 0.049066159133823485		[learning rate: 0.0012099]
		[batch 20/20] avg loss: 0.04719161017346557		[learning rate: 0.0012071]
	Learning Rate: 0.00120708
	LOSS [training: 0.048128884653644524 | validation: 0.055870736243155854]
	TIME [epoch: 8.83 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/20] avg loss: 0.055891058689285025		[learning rate: 0.0012042]
		[batch 20/20] avg loss: 0.07125772302456947		[learning rate: 0.0012014]
	Learning Rate: 0.00120142
	LOSS [training: 0.06357439085692726 | validation: 0.046822053208650585]
	TIME [epoch: 8.83 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06660052337840212		[learning rate: 0.0011986]
		[batch 20/20] avg loss: 0.07491105722387167		[learning rate: 0.0011958]
	Learning Rate: 0.00119578
	LOSS [training: 0.07075579030113689 | validation: 0.0546025894592827]
	TIME [epoch: 8.85 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05447882810027439		[learning rate: 0.001193]
		[batch 20/20] avg loss: 0.07739585255123979		[learning rate: 0.0011902]
	Learning Rate: 0.00119018
	LOSS [training: 0.06593734032575707 | validation: 0.05242447735317738]
	TIME [epoch: 8.83 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05083724443323069		[learning rate: 0.0011874]
		[batch 20/20] avg loss: 0.042593959447964305		[learning rate: 0.0011846]
	Learning Rate: 0.0011846
	LOSS [training: 0.0467156019405975 | validation: 0.02926997108158378]
	TIME [epoch: 8.82 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04741815836370349		[learning rate: 0.0011818]
		[batch 20/20] avg loss: 0.06787303445171741		[learning rate: 0.001179]
	Learning Rate: 0.00117905
	LOSS [training: 0.05764559640771046 | validation: 0.07952041430574909]
	TIME [epoch: 8.83 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06694472888305611		[learning rate: 0.0011763]
		[batch 20/20] avg loss: 0.07468672005910733		[learning rate: 0.0011735]
	Learning Rate: 0.00117352
	LOSS [training: 0.07081572447108173 | validation: 0.05285618041323835]
	TIME [epoch: 8.82 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06480667627102607		[learning rate: 0.0011708]
		[batch 20/20] avg loss: 0.07465213360122455		[learning rate: 0.001168]
	Learning Rate: 0.00116802
	LOSS [training: 0.06972940493612531 | validation: 0.044379131019666895]
	TIME [epoch: 8.86 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05683105524052615		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.10458443023108999		[learning rate: 0.0011625]
	Learning Rate: 0.00116254
	LOSS [training: 0.08070774273580807 | validation: 0.12363270999398716]
	TIME [epoch: 8.83 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07516856534428025		[learning rate: 0.0011598]
		[batch 20/20] avg loss: 0.06303779365731017		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.06910317950079521 | validation: 0.08821632052807363]
	TIME [epoch: 8.83 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06489554929121942		[learning rate: 0.0011544]
		[batch 20/20] avg loss: 0.05130847865993389		[learning rate: 0.0011517]
	Learning Rate: 0.00115167
	LOSS [training: 0.05810201397557665 | validation: 0.07906933329066344]
	TIME [epoch: 8.83 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06732740881012877		[learning rate: 0.001149]
		[batch 20/20] avg loss: 0.05375745632951975		[learning rate: 0.0011463]
	Learning Rate: 0.00114627
	LOSS [training: 0.06054243256982426 | validation: 0.08295040993717295]
	TIME [epoch: 8.84 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06434313154492599		[learning rate: 0.0011436]
		[batch 20/20] avg loss: 0.07642744247176957		[learning rate: 0.0011409]
	Learning Rate: 0.00114089
	LOSS [training: 0.07038528700834779 | validation: 0.03210781840489848]
	TIME [epoch: 8.85 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05167888737930613		[learning rate: 0.0011382]
		[batch 20/20] avg loss: 0.05287265693952246		[learning rate: 0.0011355]
	Learning Rate: 0.00113554
	LOSS [training: 0.05227577215941429 | validation: 0.08810363663174889]
	TIME [epoch: 8.83 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0993025468134162		[learning rate: 0.0011329]
		[batch 20/20] avg loss: 0.0795309427369488		[learning rate: 0.0011302]
	Learning Rate: 0.00113022
	LOSS [training: 0.0894167447751825 | validation: 0.050814205471035614]
	TIME [epoch: 8.82 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06018234090829744		[learning rate: 0.0011276]
		[batch 20/20] avg loss: 0.05334128334450292		[learning rate: 0.0011249]
	Learning Rate: 0.00112492
	LOSS [training: 0.05676181212640017 | validation: 0.06364127504761027]
	TIME [epoch: 8.83 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/20] avg loss: 0.045892292437477535		[learning rate: 0.0011223]
		[batch 20/20] avg loss: 0.06876271763758428		[learning rate: 0.0011196]
	Learning Rate: 0.00111965
	LOSS [training: 0.057327505037530924 | validation: 0.0879792669168403]
	TIME [epoch: 8.84 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0790906987248812		[learning rate: 0.001117]
		[batch 20/20] avg loss: 0.03845373650083676		[learning rate: 0.0011144]
	Learning Rate: 0.0011144
	LOSS [training: 0.05877221761285898 | validation: 0.04389009712776333]
	TIME [epoch: 8.84 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04072479462578919		[learning rate: 0.0011118]
		[batch 20/20] avg loss: 0.062302852956151254		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.05151382379097021 | validation: 0.04731099902226933]
	TIME [epoch: 8.83 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04269214238864781		[learning rate: 0.0011066]
		[batch 20/20] avg loss: 0.05869548323750372		[learning rate: 0.001104]
	Learning Rate: 0.00110397
	LOSS [training: 0.050693812813075764 | validation: 0.03585913886007653]
	TIME [epoch: 8.82 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04758514297610986		[learning rate: 0.0011014]
		[batch 20/20] avg loss: 0.046159309197430914		[learning rate: 0.0010988]
	Learning Rate: 0.0010988
	LOSS [training: 0.04687222608677038 | validation: 0.025613066339525443]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_480.pth
	Model improved!!!
EPOCH 481/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04034243412050848		[learning rate: 0.0010962]
		[batch 20/20] avg loss: 0.0517471005042071		[learning rate: 0.0010936]
	Learning Rate: 0.00109365
	LOSS [training: 0.0460447673123578 | validation: 0.0916391313737701]
	TIME [epoch: 8.86 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07611566273467352		[learning rate: 0.0010911]
		[batch 20/20] avg loss: 0.053349134176363236		[learning rate: 0.0010885]
	Learning Rate: 0.00108852
	LOSS [training: 0.06473239845551836 | validation: 0.039158224380521856]
	TIME [epoch: 8.84 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04785756900313863		[learning rate: 0.001086]
		[batch 20/20] avg loss: 0.06795672104605634		[learning rate: 0.0010834]
	Learning Rate: 0.00108342
	LOSS [training: 0.057907145024597484 | validation: 0.026910042676898855]
	TIME [epoch: 8.84 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/20] avg loss: 0.047225276991554835		[learning rate: 0.0010809]
		[batch 20/20] avg loss: 0.07393341953272772		[learning rate: 0.0010783]
	Learning Rate: 0.00107834
	LOSS [training: 0.060579348262141286 | validation: 0.04159124721462153]
	TIME [epoch: 8.83 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/20] avg loss: 0.06902035597356797		[learning rate: 0.0010758]
		[batch 20/20] avg loss: 0.051355599447547993		[learning rate: 0.0010733]
	Learning Rate: 0.00107328
	LOSS [training: 0.060187977710557984 | validation: 0.01623752681869022]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240214_211707/states/model_tr_study1_485.pth
	Model improved!!!
EPOCH 486/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05221318961328736		[learning rate: 0.0010708]
		[batch 20/20] avg loss: 0.06352777279903106		[learning rate: 0.0010683]
	Learning Rate: 0.00106825
	LOSS [training: 0.057870481206159216 | validation: 0.07626038826909114]
	TIME [epoch: 8.85 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04037579489399653		[learning rate: 0.0010657]
		[batch 20/20] avg loss: 0.048786997912411686		[learning rate: 0.0010632]
	Learning Rate: 0.00106324
	LOSS [training: 0.0445813964032041 | validation: 0.05647509017137463]
	TIME [epoch: 8.83 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04751746552361995		[learning rate: 0.0010607]
		[batch 20/20] avg loss: 0.05061857323290697		[learning rate: 0.0010583]
	Learning Rate: 0.00105826
	LOSS [training: 0.04906801937826345 | validation: 0.06127113617503132]
	TIME [epoch: 8.82 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04345053256326239		[learning rate: 0.0010558]
		[batch 20/20] avg loss: 0.03652002571081142		[learning rate: 0.0010533]
	Learning Rate: 0.0010533
	LOSS [training: 0.0399852791370369 | validation: 0.052553417491491]
	TIME [epoch: 8.83 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/20] avg loss: 0.05991681850734135		[learning rate: 0.0010508]
		[batch 20/20] avg loss: 0.029413740972332215		[learning rate: 0.0010484]
	Learning Rate: 0.00104836
	LOSS [training: 0.044665279739836784 | validation: 0.08634856182724551]
	TIME [epoch: 8.83 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/20] avg loss: 0.050791085318018604		[learning rate: 0.0010459]
		[batch 20/20] avg loss: 0.03822270988590472		[learning rate: 0.0010434]
	Learning Rate: 0.00104344
	LOSS [training: 0.044506897601961665 | validation: 0.035277386412377224]
	TIME [epoch: 8.84 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04146341915105218		[learning rate: 0.001041]
		[batch 20/20] avg loss: 0.0732474420786712		[learning rate: 0.0010386]
	Learning Rate: 0.00103855
	LOSS [training: 0.05735543061486169 | validation: 0.040952574109441454]
	TIME [epoch: 8.83 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/20] avg loss: 0.042773748353419384		[learning rate: 0.0010361]
		[batch 20/20] avg loss: 0.05275522808868048		[learning rate: 0.0010337]
	Learning Rate: 0.00103368
	LOSS [training: 0.047764488221049936 | validation: 0.06622610203679856]
	TIME [epoch: 8.83 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/20] avg loss: 0.052106982554246783		[learning rate: 0.0010313]
		[batch 20/20] avg loss: 0.04443099898174767		[learning rate: 0.0010288]
	Learning Rate: 0.00102884
	LOSS [training: 0.04826899076799722 | validation: 0.029229980409106356]
	TIME [epoch: 8.83 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/20] avg loss: 0.035088014021848704		[learning rate: 0.0010264]
		[batch 20/20] avg loss: 0.037691794050060734		[learning rate: 0.001024]
	Learning Rate: 0.00102401
	LOSS [training: 0.036389904035954726 | validation: 0.04449042444784185]
	TIME [epoch: 8.85 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/20] avg loss: 0.050881292271944156		[learning rate: 0.0010216]
		[batch 20/20] avg loss: 0.0607391166922586		[learning rate: 0.0010192]
	Learning Rate: 0.00101921
	LOSS [training: 0.05581020448210139 | validation: 0.05914401683354084]
	TIME [epoch: 8.83 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/20] avg loss: 0.04680487521650453		[learning rate: 0.0010168]
		[batch 20/20] avg loss: 0.04163325111135879		[learning rate: 0.0010144]
	Learning Rate: 0.00101444
	LOSS [training: 0.044219063163931656 | validation: 0.04422197940365841]
	TIME [epoch: 8.83 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07187776643973859		[learning rate: 0.0010121]
		[batch 20/20] avg loss: 0.05945386673623283		[learning rate: 0.0010097]
	Learning Rate: 0.00100968
	LOSS [training: 0.06566581658798572 | validation: 0.06342266764403431]
	TIME [epoch: 8.86 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/20] avg loss: 0.057990432293143976		[learning rate: 0.0010073]
		[batch 20/20] avg loss: 0.06517880067231657		[learning rate: 0.0010049]
	Learning Rate: 0.00100495
	LOSS [training: 0.06158461648273028 | validation: 0.05211410686612996]
	TIME [epoch: 8.87 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0468357727844322		[learning rate: 0.0010026]
		[batch 20/20] avg loss: 0.04058360469889917		[learning rate: 0.0010002]
	Learning Rate: 0.00100023
	LOSS [training: 0.043709688741665684 | validation: 0.05015589438547223]
	TIME [epoch: 8.87 sec]
Finished training in 4486.312 seconds.
