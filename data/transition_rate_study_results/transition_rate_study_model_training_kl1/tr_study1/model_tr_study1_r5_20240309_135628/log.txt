Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r5', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 12642950

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.804718868883038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.804718868883038 | validation: 8.107491522239105]
	TIME [epoch: 84.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.427129059696547		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.427129059696547 | validation: 8.369039134411826]
	TIME [epoch: 6.43 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.779731062890908		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.779731062890908 | validation: 7.144224469556682]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.553084518588976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.553084518588976 | validation: 7.209776826649109]
	TIME [epoch: 6.44 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.989958550589836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.989958550589836 | validation: 5.96893035575469]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.275601838703803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.275601838703803 | validation: 11.085383654944152]
	TIME [epoch: 6.41 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.507172828325922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.507172828325922 | validation: 6.052748522578452]
	TIME [epoch: 6.41 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.309956531113153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.309956531113153 | validation: 5.649678808024346]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.658508755498692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.658508755498692 | validation: 5.138506849452941]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.799621140587157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.799621140587157 | validation: 5.587412696153833]
	TIME [epoch: 6.41 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.445591705695786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.445591705695786 | validation: 5.515141029272914]
	TIME [epoch: 6.44 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.41364619288756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.41364619288756 | validation: 5.384043409853115]
	TIME [epoch: 6.4 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.2995224684211575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.2995224684211575 | validation: 5.109328359015384]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.007432906179589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.007432906179589 | validation: 5.475679014957332]
	TIME [epoch: 6.41 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.993644951816886		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.993644951816886 | validation: 4.854355443360117]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.957025730811174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.957025730811174 | validation: 4.814622430994795]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.894389096790404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.894389096790404 | validation: 4.611334251593398]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.695805599059814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.695805599059814 | validation: 5.409338053431969]
	TIME [epoch: 6.44 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.862144336251786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.862144336251786 | validation: 5.211643467794627]
	TIME [epoch: 6.43 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.94605009254909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.94605009254909 | validation: 4.903213501932028]
	TIME [epoch: 6.45 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.552620786978613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.552620786978613 | validation: 4.682810650618358]
	TIME [epoch: 6.45 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.405598849916638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.405598849916638 | validation: 4.731363333648314]
	TIME [epoch: 6.45 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.560413907502957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.560413907502957 | validation: 4.4415563746717215]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.4774803475827785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4774803475827785 | validation: 4.446468584049247]
	TIME [epoch: 6.47 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.526053663548846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.526053663548846 | validation: 4.821406521574184]
	TIME [epoch: 6.44 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.223169434600011		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.223169434600011 | validation: 3.941533676851883]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.956717691033737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.956717691033737 | validation: 3.78874843506726]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8846854613046493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8846854613046493 | validation: 3.7625002365514035]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8645427351400463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8645427351400463 | validation: 3.5962356486672036]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1331022930035335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1331022930035335 | validation: 3.7913996415836158]
	TIME [epoch: 6.46 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.644251230179754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.644251230179754 | validation: 3.768673074704431]
	TIME [epoch: 6.45 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.593923554392273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.593923554392273 | validation: 3.204255538018652]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.475917532764515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.475917532764515 | validation: 3.1346312635223352]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7168068655083686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7168068655083686 | validation: 3.286354178738725]
	TIME [epoch: 6.44 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1313785286035123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1313785286035123 | validation: 3.3059808283804397]
	TIME [epoch: 6.44 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1121225208431644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1121225208431644 | validation: 2.610854268920359]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2001670931310837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2001670931310837 | validation: 2.5317694768570487]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.957680097339596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.957680097339596 | validation: 2.640263472358617]
	TIME [epoch: 6.45 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.79801776233525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.79801776233525 | validation: 4.672190599501777]
	TIME [epoch: 6.44 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.801685917962099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.801685917962099 | validation: 3.155509429556488]
	TIME [epoch: 6.44 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1055405336286266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1055405336286266 | validation: 2.3860268066651757]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6084359141252524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6084359141252524 | validation: 2.5541270202659105]
	TIME [epoch: 6.45 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.789976852326218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.789976852326218 | validation: 3.1228052053309243]
	TIME [epoch: 6.48 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1425498206875293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1425498206875293 | validation: 2.30324312290154]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6514070145341817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6514070145341817 | validation: 2.791172151984508]
	TIME [epoch: 6.45 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8409776561080387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8409776561080387 | validation: 2.1624017942630935]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6001579350235007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6001579350235007 | validation: 2.4860077113482144]
	TIME [epoch: 6.45 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.450260571072805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.450260571072805 | validation: 2.613549955736313]
	TIME [epoch: 6.46 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.868776902530423		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.868776902530423 | validation: 2.2119920901398125]
	TIME [epoch: 6.47 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.468848672572089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.468848672572089 | validation: 2.163810803227252]
	TIME [epoch: 6.48 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.596000987095704		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.596000987095704 | validation: 4.3205300349798605]
	TIME [epoch: 6.46 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.003730428508456		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.003730428508456 | validation: 2.4175961421301855]
	TIME [epoch: 6.44 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.354010443247552		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.354010443247552 | validation: 2.193419619769398]
	TIME [epoch: 6.44 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.372717480636151		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.372717480636151 | validation: 1.8740208114789976]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.10921432154157		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.10921432154157 | validation: 1.9304757353635427]
	TIME [epoch: 6.46 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.85981840178676		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.85981840178676 | validation: 5.8772091140805705]
	TIME [epoch: 6.47 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.880698440992842		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.880698440992842 | validation: 2.3333040740115045]
	TIME [epoch: 6.46 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4382900583948506		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.4382900583948506 | validation: 1.9057212897214344]
	TIME [epoch: 6.46 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.187202650747223		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.187202650747223 | validation: 2.0919965566388017]
	TIME [epoch: 6.45 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2042824636915985		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.2042824636915985 | validation: 2.5823425930299346]
	TIME [epoch: 6.46 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.438308299781744		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.438308299781744 | validation: 1.9767278416249183]
	TIME [epoch: 6.45 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.424067880288492		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.424067880288492 | validation: 1.6903743985535433]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9798507377011592		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.9798507377011592 | validation: 2.237697595599477]
	TIME [epoch: 6.48 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.308440901609251		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.308440901609251 | validation: 3.1334701869546953]
	TIME [epoch: 6.45 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5389222153569264		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.5389222153569264 | validation: 2.0732089365481032]
	TIME [epoch: 6.45 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.152129071836119		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.152129071836119 | validation: 1.9996297366304192]
	TIME [epoch: 6.44 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.240292886927522		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.240292886927522 | validation: 2.474271300640994]
	TIME [epoch: 6.45 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2229788558830967		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.2229788558830967 | validation: 1.6445788234960848]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9682711703317346		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.9682711703317346 | validation: 1.7184383183962662]
	TIME [epoch: 6.49 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1432777910460885		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.1432777910460885 | validation: 1.8990297628554293]
	TIME [epoch: 6.47 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.13357127103118		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.13357127103118 | validation: 1.9113343898115]
	TIME [epoch: 6.46 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.843191247436164		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.843191247436164 | validation: 2.038541839589379]
	TIME [epoch: 6.46 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2213272483402173		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.2213272483402173 | validation: 2.4236387256769625]
	TIME [epoch: 6.45 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.05252045697104		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.05252045697104 | validation: 1.6653401728246318]
	TIME [epoch: 6.45 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0884819101984946		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.0884819101984946 | validation: 1.6428841019050702]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.235392061838194		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.235392061838194 | validation: 2.0102595632119433]
	TIME [epoch: 6.49 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.13838068759781		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.13838068759781 | validation: 2.2287483836889335]
	TIME [epoch: 6.45 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.656189726824605		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.656189726824605 | validation: 1.925084203390138]
	TIME [epoch: 6.46 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9443279022725541		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.9443279022725541 | validation: 1.7115993695653935]
	TIME [epoch: 6.46 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7244677495976095		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.7244677495976095 | validation: 1.6417215140050234]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.334718764649653		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 2.334718764649653 | validation: 1.9585015765291025]
	TIME [epoch: 6.46 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3211385103151105		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.3211385103151105 | validation: 1.6244916743247786]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.807978979016402		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.807978979016402 | validation: 1.4838888123404388]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_83.pth
	Model improved!!!
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.770034713281282		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.770034713281282 | validation: 1.517672487069902]
	TIME [epoch: 6.45 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4133076720730156		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.4133076720730156 | validation: 2.225456432100159]
	TIME [epoch: 6.46 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1701392391781655		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.1701392391781655 | validation: 1.7316149041192193]
	TIME [epoch: 6.46 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7404753682176908		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.7404753682176908 | validation: 1.8922391597932526]
	TIME [epoch: 6.47 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8034153609855554		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.8034153609855554 | validation: 1.7218086543159896]
	TIME [epoch: 6.46 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.685297770080899		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.685297770080899 | validation: 1.4418083512936313]
	TIME [epoch: 6.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7684221628921448		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.7684221628921448 | validation: 1.236486251300757]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.068852894498425		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.068852894498425 | validation: 2.27438802581669]
	TIME [epoch: 6.44 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.996824802650087		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.996824802650087 | validation: 2.1008739441659343]
	TIME [epoch: 6.44 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8954785039983704		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.8954785039983704 | validation: 1.320475175383395]
	TIME [epoch: 6.45 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.884212442465863		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.884212442465863 | validation: 1.4369928724115417]
	TIME [epoch: 6.44 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8307466182573335		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.8307466182573335 | validation: 1.4889503849462336]
	TIME [epoch: 6.47 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.614138750667064		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.614138750667064 | validation: 1.4136834065236326]
	TIME [epoch: 6.46 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5603542874433112		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.5603542874433112 | validation: 3.6876055544217055]
	TIME [epoch: 6.45 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9917772908139524		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.9917772908139524 | validation: 1.7688543792001656]
	TIME [epoch: 6.45 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6538624001646416		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.6538624001646416 | validation: 1.2563000353255906]
	TIME [epoch: 6.45 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5754725601883357		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.5754725601883357 | validation: 2.8434326801869174]
	TIME [epoch: 6.46 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9689396339010856		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.9689396339010856 | validation: 1.5005437906087633]
	TIME [epoch: 6.45 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.568564235916337		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.568564235916337 | validation: 1.633378126298666]
	TIME [epoch: 6.48 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5901310799841624		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.5901310799841624 | validation: 2.055208128371539]
	TIME [epoch: 6.45 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7307163629135265		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.7307163629135265 | validation: 1.399606764854044]
	TIME [epoch: 6.45 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7344535803674648		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.7344535803674648 | validation: 1.6542494979795368]
	TIME [epoch: 6.45 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9119166855643295		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.9119166855643295 | validation: 1.838105475537713]
	TIME [epoch: 6.45 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.866680240278961		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.866680240278961 | validation: 2.437439222379126]
	TIME [epoch: 6.45 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8758772107900954		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.8758772107900954 | validation: 1.7137856112920538]
	TIME [epoch: 6.46 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6242661956083553		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.6242661956083553 | validation: 1.4305329842424686]
	TIME [epoch: 6.46 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043350541221616		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.043350541221616 | validation: 2.695809171611087]
	TIME [epoch: 6.45 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.150097889650497		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.150097889650497 | validation: 1.7567847418506002]
	TIME [epoch: 6.43 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7337892283109255		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.7337892283109255 | validation: 1.4488894418930824]
	TIME [epoch: 6.44 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8477688771754175		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.8477688771754175 | validation: 1.5542539710412095]
	TIME [epoch: 6.44 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9699043353487025		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.9699043353487025 | validation: 2.2779508447614343]
	TIME [epoch: 6.45 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8553510365241743		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.8553510365241743 | validation: 1.4473638223591683]
	TIME [epoch: 6.47 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0579572197495968		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.0579572197495968 | validation: 1.6423921096858316]
	TIME [epoch: 6.45 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0756727526063337		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 2.0756727526063337 | validation: 1.672001141686586]
	TIME [epoch: 6.44 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7867315184815469		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.7867315184815469 | validation: 2.6492527882589942]
	TIME [epoch: 6.45 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.212307568894875		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.212307568894875 | validation: 1.9203440303891242]
	TIME [epoch: 6.44 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8677413252082662		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.8677413252082662 | validation: 1.4166893574477342]
	TIME [epoch: 6.44 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7435117135413587		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.7435117135413587 | validation: 1.5466346335450858]
	TIME [epoch: 6.45 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6912516856436972		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.6912516856436972 | validation: 1.2969690664857876]
	TIME [epoch: 6.47 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8206962002372933		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.8206962002372933 | validation: 1.4710464876101383]
	TIME [epoch: 6.45 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7737678921825581		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.7737678921825581 | validation: 1.530864545650694]
	TIME [epoch: 6.45 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8335012882854635		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.8335012882854635 | validation: 1.7475713860642714]
	TIME [epoch: 6.44 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9005826985829666		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.9005826985829666 | validation: 1.7119888636572882]
	TIME [epoch: 6.45 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6161208121202753		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.6161208121202753 | validation: 1.5709886382337461]
	TIME [epoch: 6.45 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5832972361169093		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.5832972361169093 | validation: 1.4609960613763509]
	TIME [epoch: 6.48 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7505719722307989		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.7505719722307989 | validation: 1.5278254677540632]
	TIME [epoch: 6.45 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7678300095891897		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.7678300095891897 | validation: 2.272397985702598]
	TIME [epoch: 6.44 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8941630815244113		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.8941630815244113 | validation: 1.552258627881073]
	TIME [epoch: 6.44 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6778443679233233		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.6778443679233233 | validation: 1.8149816321086336]
	TIME [epoch: 6.44 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6161566660294113		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.6161566660294113 | validation: 1.9136905010186698]
	TIME [epoch: 6.45 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7483466319040597		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.7483466319040597 | validation: 2.0214435318953314]
	TIME [epoch: 6.44 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6933613404202852		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.6933613404202852 | validation: 1.4557310163456783]
	TIME [epoch: 6.47 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4912368100340974		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.4912368100340974 | validation: 1.3460172977906297]
	TIME [epoch: 6.45 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.586680751541574		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.586680751541574 | validation: 1.3279203219504132]
	TIME [epoch: 6.45 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6691879810590255		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.6691879810590255 | validation: 2.170594710099215]
	TIME [epoch: 6.45 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6894119680486486		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.6894119680486486 | validation: 1.3174118096094956]
	TIME [epoch: 6.45 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.595259763884229		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.595259763884229 | validation: 1.5111991166821477]
	TIME [epoch: 6.44 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7605203402553247		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.7605203402553247 | validation: 1.4857456570308762]
	TIME [epoch: 6.46 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4857728558957208		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.4857728558957208 | validation: 1.7071991413234662]
	TIME [epoch: 6.46 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.554752684588919		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.554752684588919 | validation: 1.4570312988378455]
	TIME [epoch: 6.45 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5768608748379167		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.5768608748379167 | validation: 1.1291440775301904]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6646673214201986		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.6646673214201986 | validation: 1.158601725367246]
	TIME [epoch: 6.44 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.284314128383804		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.284314128383804 | validation: 1.1188987263808294]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6336828075015373		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.6336828075015373 | validation: 1.2344112017222921]
	TIME [epoch: 6.44 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3113026821476534		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.3113026821476534 | validation: 1.8327458120864433]
	TIME [epoch: 6.48 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5542753341307183		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.5542753341307183 | validation: 1.196687963822175]
	TIME [epoch: 6.45 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5079758771208376		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.5079758771208376 | validation: 1.304466344371635]
	TIME [epoch: 6.44 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4013349960708301		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.4013349960708301 | validation: 1.4862320944078484]
	TIME [epoch: 6.45 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.506441078656731		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.506441078656731 | validation: 1.3277319703701267]
	TIME [epoch: 6.45 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5087209696319817		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.5087209696319817 | validation: 2.699460297545349]
	TIME [epoch: 6.44 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.78798655825265		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.78798655825265 | validation: 1.70266574498077]
	TIME [epoch: 6.44 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5584965305233274		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.5584965305233274 | validation: 1.1109202735529216]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_155.pth
	Model improved!!!
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2307218359985281		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.2307218359985281 | validation: 1.850757609956101]
	TIME [epoch: 6.45 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5177536297775633		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.5177536297775633 | validation: 1.3596177736960056]
	TIME [epoch: 6.45 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3179008482928627		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.3179008482928627 | validation: 1.7491622486693685]
	TIME [epoch: 6.45 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5841653971467053		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.5841653971467053 | validation: 1.7116434798872573]
	TIME [epoch: 6.44 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4534314197132914		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.4534314197132914 | validation: 1.160502903921451]
	TIME [epoch: 6.45 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3425704609155997		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.3425704609155997 | validation: 1.0056992999220515]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_161.pth
	Model improved!!!
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2439953863617785		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.2439953863617785 | validation: 1.0827664243465445]
	TIME [epoch: 6.46 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.518003126653925		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.518003126653925 | validation: 0.9919327800458537]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3416286200641918		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.3416286200641918 | validation: 1.2986625264150076]
	TIME [epoch: 6.44 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.512376739593275		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.512376739593275 | validation: 2.4468349256541218]
	TIME [epoch: 6.45 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5826137317874942		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.5826137317874942 | validation: 1.0713698148216653]
	TIME [epoch: 6.44 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2467266155828867		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.2467266155828867 | validation: 1.178062805043442]
	TIME [epoch: 6.47 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.364480728256613		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.364480728256613 | validation: 1.284072265967908]
	TIME [epoch: 6.49 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.519810565462949		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.519810565462949 | validation: 0.9793812521934382]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2350086459094196		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.2350086459094196 | validation: 1.1944928544807136]
	TIME [epoch: 6.45 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.341223441711485		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.341223441711485 | validation: 1.992139031876673]
	TIME [epoch: 6.45 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5766516124526302		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.5766516124526302 | validation: 1.144564226287211]
	TIME [epoch: 6.45 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2284480024506184		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.2284480024506184 | validation: 1.6032749876151793]
	TIME [epoch: 6.46 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6003048612125417		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.6003048612125417 | validation: 1.5117417707046048]
	TIME [epoch: 6.49 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.902065390404815		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.902065390404815 | validation: 1.382249211262411]
	TIME [epoch: 6.47 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4915829550429383		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.4915829550429383 | validation: 0.9895555010981952]
	TIME [epoch: 6.45 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2508549213496247		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.2508549213496247 | validation: 1.0072754718432433]
	TIME [epoch: 6.45 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4210903188690915		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.4210903188690915 | validation: 1.8687738167965202]
	TIME [epoch: 6.46 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.419779212338201		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.419779212338201 | validation: 1.1756930684360416]
	TIME [epoch: 6.46 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.283373499634318		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.283373499634318 | validation: 1.1196672498400655]
	TIME [epoch: 6.48 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3389265657148774		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.3389265657148774 | validation: 1.6912663116487965]
	TIME [epoch: 6.49 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4449912933471194		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.4449912933471194 | validation: 1.1763066598624752]
	TIME [epoch: 6.47 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3444781696158983		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.3444781696158983 | validation: 0.9493762455707326]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3081096244255002		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.3081096244255002 | validation: 1.0604966910460807]
	TIME [epoch: 6.45 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.203296124841056		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.203296124841056 | validation: 0.9242313389782703]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_185.pth
	Model improved!!!
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2125461355737113		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.2125461355737113 | validation: 0.9546367278739178]
	TIME [epoch: 6.45 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0313489541228134		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.0313489541228134 | validation: 1.1227624463329786]
	TIME [epoch: 6.49 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2367307046449298		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.2367307046449298 | validation: 0.8082190318688856]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9647545913947535		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.9647545913947535 | validation: 1.7964732635159095]
	TIME [epoch: 6.46 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3264732397040537		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.3264732397040537 | validation: 1.092865127545047]
	TIME [epoch: 6.46 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2824515926451605		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.2824515926451605 | validation: 1.2369409223797625]
	TIME [epoch: 6.46 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4054821240354431		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.4054821240354431 | validation: 1.260609761999382]
	TIME [epoch: 6.45 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0980306456628834		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.0980306456628834 | validation: 0.7178263316196885]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0301440161228967		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.0301440161228967 | validation: 0.912517375780433]
	TIME [epoch: 6.48 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3824182680743107		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.3824182680743107 | validation: 0.9252948509974477]
	TIME [epoch: 6.45 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0260767949935743		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 1.0260767949935743 | validation: 0.7899929699422077]
	TIME [epoch: 6.45 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0686400610802598		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.0686400610802598 | validation: 0.6909113861912565]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_197.pth
	Model improved!!!
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.948634015969704		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.948634015969704 | validation: 0.9827584070267419]
	TIME [epoch: 6.45 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0731908608494911		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.0731908608494911 | validation: 1.185424026706855]
	TIME [epoch: 6.45 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.112756663710797		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.112756663710797 | validation: 0.6045751899936037]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.441717752192595		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.441717752192595 | validation: 1.4955453780958663]
	TIME [epoch: 6.45 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0714033264372083		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.0714033264372083 | validation: 0.8224759117584963]
	TIME [epoch: 6.46 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9164373996262851		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.9164373996262851 | validation: 0.7389657922605111]
	TIME [epoch: 6.46 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9547451158770768		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.9547451158770768 | validation: 0.7552513351018899]
	TIME [epoch: 6.46 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8863268447098634		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.8863268447098634 | validation: 0.8561385412495959]
	TIME [epoch: 6.47 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0072901988040925		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.0072901988040925 | validation: 0.6228210214366687]
	TIME [epoch: 6.47 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9716406338836225		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.9716406338836225 | validation: 1.264425588974959]
	TIME [epoch: 6.5 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.13152957062051		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.13152957062051 | validation: 0.5688406852026978]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_208.pth
	Model improved!!!
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9160855230909332		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.9160855230909332 | validation: 1.0570456569035067]
	TIME [epoch: 6.47 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9143804020906298		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.9143804020906298 | validation: 0.9318289465146447]
	TIME [epoch: 6.47 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9622635952811956		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.9622635952811956 | validation: 0.7353484225368245]
	TIME [epoch: 6.47 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0235713160069388		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.0235713160069388 | validation: 1.0363904777656894]
	TIME [epoch: 6.46 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0328389435556007		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 1.0328389435556007 | validation: 0.6518575591234091]
	TIME [epoch: 6.51 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.80190720594906		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.80190720594906 | validation: 0.6673379657010686]
	TIME [epoch: 6.48 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.957540822338474		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.957540822338474 | validation: 0.8391402110956585]
	TIME [epoch: 6.47 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9959054825070983		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.9959054825070983 | validation: 0.675554780260438]
	TIME [epoch: 6.47 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0756455611736184		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 1.0756455611736184 | validation: 0.72443576739534]
	TIME [epoch: 6.47 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8123549210785216		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.8123549210785216 | validation: 0.6515162833966244]
	TIME [epoch: 6.47 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8634850233333402		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.8634850233333402 | validation: 0.9299030125161599]
	TIME [epoch: 6.47 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.043296183306115		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.043296183306115 | validation: 0.8170349990415771]
	TIME [epoch: 6.5 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1434884680516697		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.1434884680516697 | validation: 0.8434038607008022]
	TIME [epoch: 6.47 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.823175413027138		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.823175413027138 | validation: 1.0508448092274]
	TIME [epoch: 6.47 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9481631918482176		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.9481631918482176 | validation: 0.6063361280396546]
	TIME [epoch: 6.46 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9642857478667419		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.9642857478667419 | validation: 0.9157223589123852]
	TIME [epoch: 6.46 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0086971429666678		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.0086971429666678 | validation: 0.599647342289826]
	TIME [epoch: 6.46 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1169632046732096		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.1169632046732096 | validation: 0.6860265488083621]
	TIME [epoch: 6.47 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0357686559941268		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 1.0357686559941268 | validation: 0.7653831386068913]
	TIME [epoch: 6.48 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.82869120931007		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.82869120931007 | validation: 0.7804659112832772]
	TIME [epoch: 6.47 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8421039860140986		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8421039860140986 | validation: 0.585805627676857]
	TIME [epoch: 6.47 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8082948198051513		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.8082948198051513 | validation: 1.1509850316009962]
	TIME [epoch: 6.47 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0726324588898333		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 1.0726324588898333 | validation: 0.6101656637313446]
	TIME [epoch: 6.46 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8750529165925042		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.8750529165925042 | validation: 0.5807874652308053]
	TIME [epoch: 6.46 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7380535180367059		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.7380535180367059 | validation: 0.5431610736550248]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_233.pth
	Model improved!!!
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8148393887373075		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8148393887373075 | validation: 0.6307831203851865]
	TIME [epoch: 6.47 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6997165002475759		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.6997165002475759 | validation: 0.859999745330999]
	TIME [epoch: 6.47 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7022654014135212		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.7022654014135212 | validation: 0.4695441780290239]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_236.pth
	Model improved!!!
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0569621698040663		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.0569621698040663 | validation: 0.5608792865253923]
	TIME [epoch: 6.46 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.905980267585506		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.905980267585506 | validation: 0.5130579249063413]
	TIME [epoch: 6.48 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9923569613652624		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.9923569613652624 | validation: 1.1481578864974589]
	TIME [epoch: 6.49 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3673493855305439		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 1.3673493855305439 | validation: 1.1436240026660973]
	TIME [epoch: 6.5 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1326599745172479		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.1326599745172479 | validation: 1.0398851230501576]
	TIME [epoch: 6.47 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064478127220728		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 1.064478127220728 | validation: 0.6474093316976997]
	TIME [epoch: 6.48 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.008514592739506		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.008514592739506 | validation: 0.5932296004136157]
	TIME [epoch: 6.47 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6882908778932229		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.6882908778932229 | validation: 0.46348194435226936]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.779309236208144		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.779309236208144 | validation: 0.8469140297947669]
	TIME [epoch: 6.47 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.854677843792092		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.854677843792092 | validation: 0.7756296721117054]
	TIME [epoch: 6.51 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7701067244668103		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.7701067244668103 | validation: 0.5677254136960552]
	TIME [epoch: 6.48 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6575751870040154		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.6575751870040154 | validation: 0.6049325058881206]
	TIME [epoch: 6.48 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6979566093579223		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.6979566093579223 | validation: 0.48129010035363884]
	TIME [epoch: 6.48 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6075475709835306		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.6075475709835306 | validation: 0.9986334924544821]
	TIME [epoch: 6.48 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8585833898547612		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.8585833898547612 | validation: 0.47339447677418633]
	TIME [epoch: 6.47 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6352595019820004		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6352595019820004 | validation: 0.8874761647055452]
	TIME [epoch: 6.48 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7324189875876643		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7324189875876643 | validation: 0.6760390276460101]
	TIME [epoch: 6.51 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6757774234020819		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.6757774234020819 | validation: 0.5312304632811998]
	TIME [epoch: 6.48 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6485294343909612		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.6485294343909612 | validation: 0.5860063577774832]
	TIME [epoch: 6.48 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5217707628992562		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.5217707628992562 | validation: 0.7449092530253976]
	TIME [epoch: 6.48 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6643929248572982		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6643929248572982 | validation: 0.45048504196357786]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7962437070763292		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.7962437070763292 | validation: 0.7658422913735226]
	TIME [epoch: 6.48 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6937347079002562		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.6937347079002562 | validation: 0.5389881903123841]
	TIME [epoch: 6.51 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9671244081112931		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.9671244081112931 | validation: 0.9884018942811627]
	TIME [epoch: 6.49 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6886470712358513		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.6886470712358513 | validation: 0.9076705286991842]
	TIME [epoch: 6.47 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7390595765417266		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.7390595765417266 | validation: 0.9389436166909773]
	TIME [epoch: 6.47 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.792910377913468		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.792910377913468 | validation: 0.7228770921443521]
	TIME [epoch: 6.48 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0425844895447267		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.0425844895447267 | validation: 0.7795248001456798]
	TIME [epoch: 6.47 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7607991862713537		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.7607991862713537 | validation: 0.4588260177327437]
	TIME [epoch: 6.48 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7312063422812142		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.7312063422812142 | validation: 1.1566179923555078]
	TIME [epoch: 6.51 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.821826423445513		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.821826423445513 | validation: 0.6118735269629817]
	TIME [epoch: 6.48 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7209679064638291		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7209679064638291 | validation: 0.4835449469602395]
	TIME [epoch: 6.48 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5761746113662273		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.5761746113662273 | validation: 0.9335413616634816]
	TIME [epoch: 6.48 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8386250976237103		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.8386250976237103 | validation: 1.052896839870027]
	TIME [epoch: 6.48 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7081879344916041		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.7081879344916041 | validation: 0.7374899160917369]
	TIME [epoch: 6.48 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7134398495772185		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7134398495772185 | validation: 0.5824169815040995]
	TIME [epoch: 6.5 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6416914969405617		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6416914969405617 | validation: 0.5071749051583756]
	TIME [epoch: 6.5 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7050473710626973		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.7050473710626973 | validation: 0.7135901682173912]
	TIME [epoch: 6.48 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2204464446639567		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.2204464446639567 | validation: 1.2698976983478267]
	TIME [epoch: 6.48 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0267643111042162		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.0267643111042162 | validation: 0.746264790215503]
	TIME [epoch: 6.48 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6980915253978422		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.6980915253978422 | validation: 0.8308567801720044]
	TIME [epoch: 6.48 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.946944013317375		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.946944013317375 | validation: 0.5756324115642133]
	TIME [epoch: 6.47 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6522755125091558		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6522755125091558 | validation: 0.45479821419588917]
	TIME [epoch: 6.52 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6782815367744321		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.6782815367744321 | validation: 0.4224376740098472]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7648821689080272		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.7648821689080272 | validation: 0.47213225320541]
	TIME [epoch: 6.48 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6616671848582238		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.6616671848582238 | validation: 0.3425158950987367]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_282.pth
	Model improved!!!
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7737593430126496		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.7737593430126496 | validation: 0.5221039114883265]
	TIME [epoch: 6.47 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6697524158973758		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.6697524158973758 | validation: 0.5793070832794098]
	TIME [epoch: 6.47 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5498110298399378		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.5498110298399378 | validation: 0.3895731981128847]
	TIME [epoch: 6.51 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5645644992963359		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.5645644992963359 | validation: 0.708793517466085]
	TIME [epoch: 6.48 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6095496382174043		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6095496382174043 | validation: 0.41027305734394254]
	TIME [epoch: 6.47 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6224735502475649		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.6224735502475649 | validation: 0.5534646490380432]
	TIME [epoch: 6.48 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9411506801047833		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.9411506801047833 | validation: 0.8838606226636893]
	TIME [epoch: 6.47 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6392776030075845		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.6392776030075845 | validation: 0.36195848940728786]
	TIME [epoch: 6.47 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5174517291300627		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.5174517291300627 | validation: 0.33768121543203644]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_291.pth
	Model improved!!!
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4780104478663287		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.4780104478663287 | validation: 0.4192914276625524]
	TIME [epoch: 6.51 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6091178073166333		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.6091178073166333 | validation: 0.34193420249727396]
	TIME [epoch: 6.48 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5751455011864576		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.5751455011864576 | validation: 0.5246621712635309]
	TIME [epoch: 6.47 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6237710995123824		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.6237710995123824 | validation: 0.49307555470275893]
	TIME [epoch: 6.47 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287902490062284		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.6287902490062284 | validation: 0.4914391090211093]
	TIME [epoch: 6.48 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5563844269375013		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5563844269375013 | validation: 1.088638818623775]
	TIME [epoch: 6.47 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7959789237645124		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.7959789237645124 | validation: 0.38981120374354655]
	TIME [epoch: 6.48 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5747974258998149		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.5747974258998149 | validation: 0.7870310560737719]
	TIME [epoch: 6.49 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6836313454681042		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.6836313454681042 | validation: 0.7030817397581633]
	TIME [epoch: 6.48 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6138828068159085		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.6138828068159085 | validation: 0.37860955607547897]
	TIME [epoch: 6.48 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4839362131580731		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.4839362131580731 | validation: 0.5930946314079087]
	TIME [epoch: 6.48 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5475463937136404		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.5475463937136404 | validation: 0.8071372119240189]
	TIME [epoch: 6.47 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5844825941736858		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.5844825941736858 | validation: 0.553133667244697]
	TIME [epoch: 6.47 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5835284707004949		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.5835284707004949 | validation: 0.6374020852473421]
	TIME [epoch: 6.51 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5917358170204245		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.5917358170204245 | validation: 0.35101675447652836]
	TIME [epoch: 6.48 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6028831493178258		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6028831493178258 | validation: 0.735158723757214]
	TIME [epoch: 6.47 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6762621139362603		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.6762621139362603 | validation: 0.457654635895088]
	TIME [epoch: 6.47 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48925001867150847		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.48925001867150847 | validation: 0.34791327927685556]
	TIME [epoch: 6.48 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5188666418293881		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.5188666418293881 | validation: 0.8636685915681566]
	TIME [epoch: 6.48 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6342434703529828		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6342434703529828 | validation: 0.5044475568724961]
	TIME [epoch: 6.49 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5167073363879532		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5167073363879532 | validation: 0.9124404340806472]
	TIME [epoch: 6.49 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.033241151275651		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.033241151275651 | validation: 0.5073688433237428]
	TIME [epoch: 6.47 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7394013505539718		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7394013505539718 | validation: 0.37337610137964194]
	TIME [epoch: 6.47 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6818494391684453		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.6818494391684453 | validation: 0.5195629665999434]
	TIME [epoch: 6.48 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6316416586574733		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.6316416586574733 | validation: 0.3016522190662342]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_316.pth
	Model improved!!!
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189490181179266		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.5189490181179266 | validation: 0.25861538999886063]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_317.pth
	Model improved!!!
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.550376062057533		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.550376062057533 | validation: 0.48831191951999536]
	TIME [epoch: 6.51 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531957617715374		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.531957617715374 | validation: 0.4401684204117555]
	TIME [epoch: 6.48 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5796277555332263		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.5796277555332263 | validation: 0.5133801106486219]
	TIME [epoch: 6.47 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6287283774069529		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6287283774069529 | validation: 0.46741570178047054]
	TIME [epoch: 6.46 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6348011518525578		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.6348011518525578 | validation: 0.49652927544959974]
	TIME [epoch: 6.46 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5994322900860813		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.5994322900860813 | validation: 0.4195950317587909]
	TIME [epoch: 6.48 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5724060494548917		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5724060494548917 | validation: 0.44527059721971496]
	TIME [epoch: 6.48 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.487329387524731		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.487329387524731 | validation: 0.4396849165536569]
	TIME [epoch: 6.51 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507682405504902		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5507682405504902 | validation: 1.0724591095893583]
	TIME [epoch: 6.47 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6928648295858408		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.6928648295858408 | validation: 0.37323216861002306]
	TIME [epoch: 6.46 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4028114382767771		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.4028114382767771 | validation: 0.3504604276026504]
	TIME [epoch: 6.47 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5495635288330669		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.5495635288330669 | validation: 0.5357633212562241]
	TIME [epoch: 6.46 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4914477230520651		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.4914477230520651 | validation: 0.629471970152899]
	TIME [epoch: 6.47 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4745456439619263		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.4745456439619263 | validation: 0.3592229430560992]
	TIME [epoch: 6.5 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4747918754060819		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.4747918754060819 | validation: 0.5482777522626396]
	TIME [epoch: 6.47 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6838937829232115		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6838937829232115 | validation: 0.40175455391681325]
	TIME [epoch: 6.46 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5515308144507688		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.5515308144507688 | validation: 0.6524114103024558]
	TIME [epoch: 6.47 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5616482708362396		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5616482708362396 | validation: 0.5030258368848874]
	TIME [epoch: 6.47 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5870594280463103		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.5870594280463103 | validation: 0.41879952433244155]
	TIME [epoch: 6.46 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6275367808158314		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.6275367808158314 | validation: 0.6640436476980053]
	TIME [epoch: 6.48 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7355764678481987		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.7355764678481987 | validation: 0.49500290465893515]
	TIME [epoch: 6.51 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4157151888762426		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.4157151888762426 | validation: 0.6623234499816661]
	TIME [epoch: 6.49 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272058160458216		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.5272058160458216 | validation: 0.3763922834887795]
	TIME [epoch: 6.48 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4299399931761088		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.4299399931761088 | validation: 0.2933274223215674]
	TIME [epoch: 6.48 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4579341702569618		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.4579341702569618 | validation: 0.5608922226585251]
	TIME [epoch: 6.49 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47892578879415915		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.47892578879415915 | validation: 0.2393933886692108]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_343.pth
	Model improved!!!
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42456656294980283		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.42456656294980283 | validation: 0.29451358373033387]
	TIME [epoch: 6.48 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34345535170601493		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.34345535170601493 | validation: 0.5694804737537844]
	TIME [epoch: 6.49 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6569912510621753		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.6569912510621753 | validation: 0.5440408418476707]
	TIME [epoch: 6.46 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5423857216564077		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5423857216564077 | validation: 0.6032294573541737]
	TIME [epoch: 6.45 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8048205829366697		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.8048205829366697 | validation: 0.8645537206037809]
	TIME [epoch: 6.44 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5695623375669223		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.5695623375669223 | validation: 0.45169123049428195]
	TIME [epoch: 6.44 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5208364801055251		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5208364801055251 | validation: 0.4706157533553632]
	TIME [epoch: 6.45 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4349093845267905		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.4349093845267905 | validation: 0.3737954153864736]
	TIME [epoch: 6.47 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.399203750782093		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.399203750782093 | validation: 0.45929429195114835]
	TIME [epoch: 6.44 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5282328953148803		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.5282328953148803 | validation: 0.31719348861604135]
	TIME [epoch: 6.44 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4167589297381888		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.4167589297381888 | validation: 0.26078219389233753]
	TIME [epoch: 6.45 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5255345904193833		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5255345904193833 | validation: 0.38294963213791294]
	TIME [epoch: 6.44 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44879383282811447		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.44879383282811447 | validation: 0.4445879439318124]
	TIME [epoch: 6.46 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.530544278989919		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.530544278989919 | validation: 0.527413718642236]
	TIME [epoch: 6.47 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5430543348431685		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.5430543348431685 | validation: 0.3980353959987201]
	TIME [epoch: 6.48 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4549583519789465		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.4549583519789465 | validation: 0.3819968527746698]
	TIME [epoch: 6.45 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5157728055276809		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5157728055276809 | validation: 0.2934466309724641]
	TIME [epoch: 6.46 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5054630000140203		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.5054630000140203 | validation: 0.5042501517357872]
	TIME [epoch: 6.45 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4029683707253322		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.4029683707253322 | validation: 0.9120829755874393]
	TIME [epoch: 6.47 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6023357791332087		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.6023357791332087 | validation: 0.30874508719430677]
	TIME [epoch: 6.45 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3623294983859501		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.3623294983859501 | validation: 0.40809969930325707]
	TIME [epoch: 6.5 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.507620595560865		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.507620595560865 | validation: 0.33748086368225994]
	TIME [epoch: 6.47 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4109341733233911		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.4109341733233911 | validation: 0.6458569252116922]
	TIME [epoch: 6.47 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6250925663075684		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.6250925663075684 | validation: 0.41304270542775007]
	TIME [epoch: 6.47 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4164845663577962		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.4164845663577962 | validation: 0.24655691491559964]
	TIME [epoch: 6.48 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3329484190123762		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.3329484190123762 | validation: 0.38056332541566035]
	TIME [epoch: 6.48 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4853292252960747		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.4853292252960747 | validation: 0.45409301555481263]
	TIME [epoch: 6.49 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.524879939491008		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.524879939491008 | validation: 0.9532915720657968]
	TIME [epoch: 6.51 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014082328484647		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.5014082328484647 | validation: 0.27977875324099694]
	TIME [epoch: 6.48 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3753193833519371		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.3753193833519371 | validation: 0.4672539794639232]
	TIME [epoch: 6.48 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5342968820576369		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.5342968820576369 | validation: 0.2998488114317131]
	TIME [epoch: 6.47 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37147622004590386		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.37147622004590386 | validation: 0.3226937095551803]
	TIME [epoch: 6.48 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5223596937846141		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.5223596937846141 | validation: 0.9847733818821388]
	TIME [epoch: 6.47 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7915984913622756		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.7915984913622756 | validation: 0.37344954619424214]
	TIME [epoch: 6.49 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4527147941232709		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.4527147941232709 | validation: 0.38359714837917547]
	TIME [epoch: 6.49 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373575908371671		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.373575908371671 | validation: 0.29797452517619843]
	TIME [epoch: 6.49 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33517448649336246		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.33517448649336246 | validation: 0.3622231509936163]
	TIME [epoch: 6.48 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4143089518021591		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.4143089518021591 | validation: 0.28238241880507126]
	TIME [epoch: 6.47 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46287191281977585		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.46287191281977585 | validation: 0.40677896239054406]
	TIME [epoch: 6.47 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4153564273780923		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.4153564273780923 | validation: 0.42616003875171005]
	TIME [epoch: 6.47 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4506388570427453		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.4506388570427453 | validation: 0.36941355610658533]
	TIME [epoch: 6.51 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39735837711441824		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.39735837711441824 | validation: 0.34863326549883655]
	TIME [epoch: 6.48 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47040835485609855		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.47040835485609855 | validation: 0.8783710845390857]
	TIME [epoch: 6.47 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.669272328122062		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.669272328122062 | validation: 0.5190057522161207]
	TIME [epoch: 6.48 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4487370632750296		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.4487370632750296 | validation: 0.6717047093526688]
	TIME [epoch: 6.47 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4666722612786245		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.4666722612786245 | validation: 0.41304444511183425]
	TIME [epoch: 6.47 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990537452227382		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.3990537452227382 | validation: 0.4608451331119329]
	TIME [epoch: 6.49 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4518128322407492		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.4518128322407492 | validation: 0.3636840704093672]
	TIME [epoch: 6.49 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40780353890526005		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.40780353890526005 | validation: 0.7548367783458036]
	TIME [epoch: 6.47 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4559409038933485		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.4559409038933485 | validation: 0.26034345361906197]
	TIME [epoch: 6.47 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2893129800381492		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.2893129800381492 | validation: 0.39673555443803565]
	TIME [epoch: 6.47 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31728951246706816		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.31728951246706816 | validation: 0.3154156787785687]
	TIME [epoch: 6.47 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36785157878388863		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.36785157878388863 | validation: 0.29337846383363253]
	TIME [epoch: 6.46 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33289328139930463		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.33289328139930463 | validation: 0.3673404835343607]
	TIME [epoch: 6.5 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3546536031312223		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.3546536031312223 | validation: 0.5279454772794582]
	TIME [epoch: 6.47 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5497454286246646		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.5497454286246646 | validation: 0.49509203525365153]
	TIME [epoch: 6.48 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46725706718159343		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.46725706718159343 | validation: 0.4255466994617474]
	TIME [epoch: 6.46 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107216989437484		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.5107216989437484 | validation: 0.43928475735757716]
	TIME [epoch: 6.47 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3504065883706666		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.3504065883706666 | validation: 0.4862287385326545]
	TIME [epoch: 6.47 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40877354784670433		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.40877354784670433 | validation: 0.4410497592980744]
	TIME [epoch: 6.48 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3009378491841106		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.3009378491841106 | validation: 0.39860344085716576]
	TIME [epoch: 6.52 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3776282761205234		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.3776282761205234 | validation: 0.4442994858359573]
	TIME [epoch: 6.47 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46802050916194704		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.46802050916194704 | validation: 0.6357499090589108]
	TIME [epoch: 6.47 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46483138975393956		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.46483138975393956 | validation: 0.32977005098661616]
	TIME [epoch: 6.47 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5931545227922068		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.5931545227922068 | validation: 0.5330577435687082]
	TIME [epoch: 6.47 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39493893731912966		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.39493893731912966 | validation: 0.2734877881702908]
	TIME [epoch: 6.46 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3001853463723694		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.3001853463723694 | validation: 0.44203013232916283]
	TIME [epoch: 6.5 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.604381377217149		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.604381377217149 | validation: 0.9229955140306217]
	TIME [epoch: 6.48 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7009366524833895		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.7009366524833895 | validation: 0.5887732095072457]
	TIME [epoch: 6.48 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3781877888465187		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.3781877888465187 | validation: 0.25377886114837717]
	TIME [epoch: 6.47 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33460838434256246		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.33460838434256246 | validation: 0.28233260222717754]
	TIME [epoch: 6.48 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3895949784745938		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.3895949784745938 | validation: 0.3495652032337841]
	TIME [epoch: 6.47 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3328545817841561		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.3328545817841561 | validation: 0.243028476007763]
	TIME [epoch: 6.47 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30160295108099705		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.30160295108099705 | validation: 0.6343436774971123]
	TIME [epoch: 6.51 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6383862160844491		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.6383862160844491 | validation: 0.3421605691102782]
	TIME [epoch: 6.46 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3656008149910642		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.3656008149910642 | validation: 0.36392046973243625]
	TIME [epoch: 6.46 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31371337410263817		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.31371337410263817 | validation: 0.5302072652706417]
	TIME [epoch: 6.47 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4039016483632689		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.4039016483632689 | validation: 0.31288268700175526]
	TIME [epoch: 6.47 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.339510019028788		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.339510019028788 | validation: 0.7541353517839596]
	TIME [epoch: 6.47 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4833872309798035		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.4833872309798035 | validation: 0.7957075639024064]
	TIME [epoch: 6.49 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49933074931150184		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.49933074931150184 | validation: 1.0568052419485645]
	TIME [epoch: 6.49 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6128185722902553		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.6128185722902553 | validation: 0.36500098554514393]
	TIME [epoch: 6.47 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3559347462088912		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.3559347462088912 | validation: 0.3806251313435841]
	TIME [epoch: 6.48 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41180962802530263		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.41180962802530263 | validation: 0.4676815060236968]
	TIME [epoch: 6.47 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758421514744767		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.3758421514744767 | validation: 0.6975149113069745]
	TIME [epoch: 6.47 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6646256172488502		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.6646256172488502 | validation: 0.48944455701330797]
	TIME [epoch: 6.46 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.457209288504985		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.457209288504985 | validation: 0.47253105636539566]
	TIME [epoch: 6.5 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3527031810735096		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.3527031810735096 | validation: 0.37357467986170234]
	TIME [epoch: 6.47 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4611451018901466		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.4611451018901466 | validation: 0.777932421441741]
	TIME [epoch: 6.47 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4820154047607561		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.4820154047607561 | validation: 0.5303250826567366]
	TIME [epoch: 6.47 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35199550647559563		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.35199550647559563 | validation: 0.6958065690737542]
	TIME [epoch: 6.47 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48976711304082976		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.48976711304082976 | validation: 0.33534483511442775]
	TIME [epoch: 6.47 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37737472704487074		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.37737472704487074 | validation: 0.4425797836817401]
	TIME [epoch: 6.49 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.554930943154937		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.554930943154937 | validation: 0.511673228127824]
	TIME [epoch: 6.5 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4762259215277663		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.4762259215277663 | validation: 0.6686284086832319]
	TIME [epoch: 6.47 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4114228045611667		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.4114228045611667 | validation: 0.3003632618506723]
	TIME [epoch: 6.47 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30769556495662664		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.30769556495662664 | validation: 0.26837550908481755]
	TIME [epoch: 6.48 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2914427737844024		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.2914427737844024 | validation: 0.3502106494866275]
	TIME [epoch: 6.47 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42764154590743314		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.42764154590743314 | validation: 0.32107220529394653]
	TIME [epoch: 6.46 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37516398080382607		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.37516398080382607 | validation: 0.31807610108487283]
	TIME [epoch: 6.5 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38257726157957944		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.38257726157957944 | validation: 0.5582721966604675]
	TIME [epoch: 6.49 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976580039664336		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.3976580039664336 | validation: 0.3837140264864607]
	TIME [epoch: 6.48 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31159718217281634		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.31159718217281634 | validation: 0.5607855534353011]
	TIME [epoch: 6.48 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41092892855697494		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.41092892855697494 | validation: 0.679831561092258]
	TIME [epoch: 6.47 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33744434133393053		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.33744434133393053 | validation: 0.42763890395696524]
	TIME [epoch: 6.47 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34145253958313593		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.34145253958313593 | validation: 0.3075340901404533]
	TIME [epoch: 6.47 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37624298606507783		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.37624298606507783 | validation: 0.2905879267984238]
	TIME [epoch: 6.5 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40790846422704674		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.40790846422704674 | validation: 0.3034741943628575]
	TIME [epoch: 6.47 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778799020711815		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3778799020711815 | validation: 0.285411793764264]
	TIME [epoch: 6.47 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2677556290002518		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.2677556290002518 | validation: 0.30699215962129617]
	TIME [epoch: 6.49 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33062722498524016		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.33062722498524016 | validation: 0.44591314757453887]
	TIME [epoch: 6.48 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3534982086801955		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.3534982086801955 | validation: 0.6052921437527645]
	TIME [epoch: 6.48 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3971884375556818		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.3971884375556818 | validation: 0.2819727375997697]
	TIME [epoch: 6.48 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444326089527142		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.3444326089527142 | validation: 0.35417593968520167]
	TIME [epoch: 6.5 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876576005530564		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.2876576005530564 | validation: 0.2286225591688028]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_458.pth
	Model improved!!!
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44210088539143266		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.44210088539143266 | validation: 0.6293940002654934]
	TIME [epoch: 6.47 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6040641637625633		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.6040641637625633 | validation: 0.29884482240471366]
	TIME [epoch: 6.48 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4687151552218676		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.4687151552218676 | validation: 0.35984308441969814]
	TIME [epoch: 6.47 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37528496507672515		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.37528496507672515 | validation: 0.2952601082843524]
	TIME [epoch: 6.47 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3530128175527318		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.3530128175527318 | validation: 0.2671508184061675]
	TIME [epoch: 6.5 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36039927857484527		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.36039927857484527 | validation: 0.7633169370530951]
	TIME [epoch: 6.48 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43994090342734327		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.43994090342734327 | validation: 0.5234138377063451]
	TIME [epoch: 6.48 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3348183985836366		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.3348183985836366 | validation: 0.35215301543414074]
	TIME [epoch: 6.47 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3013706463377458		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.3013706463377458 | validation: 0.3846136937261212]
	TIME [epoch: 6.47 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39272984004326517		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.39272984004326517 | validation: 0.4874351447357257]
	TIME [epoch: 6.47 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3714299191936082		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.3714299191936082 | validation: 0.4874002207541179]
	TIME [epoch: 6.48 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3334708279150138		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.3334708279150138 | validation: 0.41940803034046625]
	TIME [epoch: 6.49 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35460944883082174		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.35460944883082174 | validation: 0.49340907257766853]
	TIME [epoch: 6.49 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42135311758227145		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.42135311758227145 | validation: 0.5791745607275179]
	TIME [epoch: 6.46 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5172099855242088		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.5172099855242088 | validation: 0.6765968078306211]
	TIME [epoch: 6.47 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4095618800606929		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.4095618800606929 | validation: 0.5885486459190967]
	TIME [epoch: 6.46 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3917037273943435		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.3917037273943435 | validation: 0.5001712540397008]
	TIME [epoch: 6.46 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3060026197986672		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.3060026197986672 | validation: 0.33300971308191324]
	TIME [epoch: 6.5 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39763330907630834		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.39763330907630834 | validation: 0.3475451511998369]
	TIME [epoch: 6.47 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2847211806874977		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.2847211806874977 | validation: 0.212810886020049]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_478.pth
	Model improved!!!
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.247559695975159		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.247559695975159 | validation: 0.3530192757445195]
	TIME [epoch: 6.47 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3366032527183048		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.3366032527183048 | validation: 0.31726678360933724]
	TIME [epoch: 6.48 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2392246688536972		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.2392246688536972 | validation: 0.2715181330625307]
	TIME [epoch: 6.47 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568000266454485		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.3568000266454485 | validation: 0.4116741695757116]
	TIME [epoch: 6.47 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4756769420202126		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.4756769420202126 | validation: 0.2854520653751487]
	TIME [epoch: 6.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4178666887712047		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.4178666887712047 | validation: 0.2939529885655987]
	TIME [epoch: 6.47 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38009649277591456		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.38009649277591456 | validation: 0.3525334367013497]
	TIME [epoch: 6.46 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3403761337351249		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.3403761337351249 | validation: 0.3465201520280276]
	TIME [epoch: 6.46 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32598184425628607		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.32598184425628607 | validation: 0.4312231569371566]
	TIME [epoch: 6.48 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36362775403999315		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.36362775403999315 | validation: 0.2518105669227031]
	TIME [epoch: 6.46 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3075222161465636		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.3075222161465636 | validation: 0.331071644527834]
	TIME [epoch: 6.51 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31868802486340086		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.31868802486340086 | validation: 0.2955808227818355]
	TIME [epoch: 6.48 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27492423801466037		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.27492423801466037 | validation: 0.532505955579781]
	TIME [epoch: 6.48 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42747377479092885		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.42747377479092885 | validation: 0.364239781075021]
	TIME [epoch: 6.47 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4255872943124557		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.4255872943124557 | validation: 0.307836047627017]
	TIME [epoch: 6.49 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37986120626348535		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.37986120626348535 | validation: 0.3408323889996946]
	TIME [epoch: 6.47 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4869546228598103		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.4869546228598103 | validation: 0.34516142673498224]
	TIME [epoch: 6.47 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38815217839900884		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.38815217839900884 | validation: 0.262209963335424]
	TIME [epoch: 6.52 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3742819542739726		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.3742819542739726 | validation: 0.38829023597933715]
	TIME [epoch: 6.48 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42716365555051755		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.42716365555051755 | validation: 0.5256190103533155]
	TIME [epoch: 6.48 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48108144418362486		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.48108144418362486 | validation: 0.30524124661276114]
	TIME [epoch: 6.47 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26523160898758463		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.26523160898758463 | validation: 0.3491433018565824]
	TIME [epoch: 6.47 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2682564209375708		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.2682564209375708 | validation: 0.3670910881713353]
	TIME [epoch: 6.49 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35249864678117043		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.35249864678117043 | validation: 0.21649611185022913]
	TIME [epoch: 6.49 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24156240435845372		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.24156240435845372 | validation: 0.3968863728796967]
	TIME [epoch: 6.5 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33843256202676		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.33843256202676 | validation: 0.5138956150604868]
	TIME [epoch: 6.48 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30891033586748023		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.30891033586748023 | validation: 0.22866816847237875]
	TIME [epoch: 6.47 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29984496343237965		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.29984496343237965 | validation: 0.29638337828466155]
	TIME [epoch: 6.48 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25174724291206313		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.25174724291206313 | validation: 0.2621259313887383]
	TIME [epoch: 6.48 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2650210855200204		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.2650210855200204 | validation: 0.327418699839504]
	TIME [epoch: 6.47 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3609994346155531		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.3609994346155531 | validation: 0.31925444352783144]
	TIME [epoch: 6.52 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31157674618516973		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.31157674618516973 | validation: 0.251406473718785]
	TIME [epoch: 6.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26178640773580303		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.26178640773580303 | validation: 0.2738985025568789]
	TIME [epoch: 6.47 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3045708033269475		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.3045708033269475 | validation: 0.2860143110681727]
	TIME [epoch: 6.47 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2803523398489929		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.2803523398489929 | validation: 0.26890597527355425]
	TIME [epoch: 6.47 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29886716617473885		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.29886716617473885 | validation: 0.31027359510798036]
	TIME [epoch: 6.48 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32985134299478563		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.32985134299478563 | validation: 0.23187835208120208]
	TIME [epoch: 6.48 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25300071234561355		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.25300071234561355 | validation: 0.22633133314702064]
	TIME [epoch: 6.51 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32235742732014677		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.32235742732014677 | validation: 0.25868650188649406]
	TIME [epoch: 6.48 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2710785291171919		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.2710785291171919 | validation: 0.330737514523802]
	TIME [epoch: 6.48 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326956172116651		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.3326956172116651 | validation: 0.26925281166547615]
	TIME [epoch: 6.49 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3412361734373666		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.3412361734373666 | validation: 0.389154485029478]
	TIME [epoch: 6.47 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5841631865453553		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.5841631865453553 | validation: 0.4575365420633681]
	TIME [epoch: 6.48 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38466401019218505		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.38466401019218505 | validation: 0.32601742214944907]
	TIME [epoch: 6.51 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2644991723046868		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.2644991723046868 | validation: 0.2320590728232314]
	TIME [epoch: 6.48 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3056389941631347		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.3056389941631347 | validation: 0.24806760574310388]
	TIME [epoch: 6.49 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642313959231179		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.2642313959231179 | validation: 0.363514077106874]
	TIME [epoch: 6.47 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2973386779899645		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.2973386779899645 | validation: 0.3058474304997606]
	TIME [epoch: 6.49 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30079837203007864		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.30079837203007864 | validation: 0.22077644496706403]
	TIME [epoch: 6.48 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332732177272545		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.2332732177272545 | validation: 0.2901993804942352]
	TIME [epoch: 6.49 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36935833812378993		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.36935833812378993 | validation: 0.2992275126818404]
	TIME [epoch: 6.52 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30465133835315805		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.30465133835315805 | validation: 0.27308150454041036]
	TIME [epoch: 6.48 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27515296270656386		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.27515296270656386 | validation: 0.2723160488970083]
	TIME [epoch: 6.47 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29475912938066356		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.29475912938066356 | validation: 0.23345204940242092]
	TIME [epoch: 6.47 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24719915806574516		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.24719915806574516 | validation: 0.1915564968111281]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25850828192769015		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.25850828192769015 | validation: 0.31279385376755114]
	TIME [epoch: 6.48 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32686777480449214		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.32686777480449214 | validation: 0.4921390371592419]
	TIME [epoch: 6.49 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4096152847823082		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.4096152847823082 | validation: 0.3839331069885015]
	TIME [epoch: 6.5 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2427687406686828		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.2427687406686828 | validation: 0.2885176239635065]
	TIME [epoch: 6.47 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24230594812684186		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.24230594812684186 | validation: 0.30024833767522624]
	TIME [epoch: 6.48 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2326036858104845		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.2326036858104845 | validation: 0.24655810517551313]
	TIME [epoch: 6.47 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2866893037936487		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.2866893037936487 | validation: 0.2927852873238361]
	TIME [epoch: 6.48 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26277524970504973		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.26277524970504973 | validation: 0.2244840492377067]
	TIME [epoch: 6.47 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22324759077990122		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.22324759077990122 | validation: 0.4539029104941507]
	TIME [epoch: 6.53 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2709353930798939		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.2709353930798939 | validation: 0.27452871439655036]
	TIME [epoch: 6.48 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28555905481560695		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.28555905481560695 | validation: 0.37446763362395913]
	TIME [epoch: 6.47 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31148284407072274		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.31148284407072274 | validation: 0.29048162172499503]
	TIME [epoch: 6.48 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2961640033799525		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.2961640033799525 | validation: 0.2601459150630392]
	TIME [epoch: 6.48 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3134133904212817		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.3134133904212817 | validation: 0.2962314070706885]
	TIME [epoch: 6.47 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21351399352709632		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.21351399352709632 | validation: 0.30002746697652766]
	TIME [epoch: 6.5 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29233579243846414		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.29233579243846414 | validation: 0.2933711163215873]
	TIME [epoch: 6.5 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2456562218816978		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.2456562218816978 | validation: 0.4105105131167122]
	TIME [epoch: 6.48 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2518812536490342		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.2518812536490342 | validation: 0.21203905574003262]
	TIME [epoch: 6.49 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2357545964748845		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.2357545964748845 | validation: 0.2003550542458191]
	TIME [epoch: 6.49 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22702252419316513		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.22702252419316513 | validation: 0.30379182309350755]
	TIME [epoch: 6.47 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23447949326033518		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.23447949326033518 | validation: 0.48050885600205745]
	TIME [epoch: 6.47 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2496747337920171		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.2496747337920171 | validation: 0.2121326349482187]
	TIME [epoch: 6.51 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26063797783449527		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.26063797783449527 | validation: 0.17290384222142272]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_556.pth
	Model improved!!!
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19647307066502206		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.19647307066502206 | validation: 0.18322105649939502]
	TIME [epoch: 6.47 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22611838053707067		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.22611838053707067 | validation: 0.38424230261764286]
	TIME [epoch: 6.48 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2562396406531806		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.2562396406531806 | validation: 0.202196402357365]
	TIME [epoch: 6.49 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.207945289677034		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.207945289677034 | validation: 0.31946025267828143]
	TIME [epoch: 6.48 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28639291579715853		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.28639291579715853 | validation: 0.5338950190569197]
	TIME [epoch: 6.51 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43612211660274974		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.43612211660274974 | validation: 0.35993740308511385]
	TIME [epoch: 6.51 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32733256664623633		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.32733256664623633 | validation: 0.24721689628506427]
	TIME [epoch: 6.49 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2266037760985401		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.2266037760985401 | validation: 0.2386934558016784]
	TIME [epoch: 6.46 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23861696284720688		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.23861696284720688 | validation: 0.21933671614690997]
	TIME [epoch: 6.48 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2516724537137141		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.2516724537137141 | validation: 0.5542331277672486]
	TIME [epoch: 6.48 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36511054630725565		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.36511054630725565 | validation: 0.4082626895247291]
	TIME [epoch: 6.47 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28261044849257777		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.28261044849257777 | validation: 0.35718495899713]
	TIME [epoch: 6.52 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26461905049973744		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.26461905049973744 | validation: 0.27041572052352786]
	TIME [epoch: 6.48 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3016621668441233		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.3016621668441233 | validation: 0.2587874192088577]
	TIME [epoch: 6.48 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29055014545251834		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.29055014545251834 | validation: 0.25320006603340145]
	TIME [epoch: 6.47 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2204577390132954		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.2204577390132954 | validation: 0.1857025715073433]
	TIME [epoch: 6.48 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17907235144806652		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.17907235144806652 | validation: 0.24591207553691619]
	TIME [epoch: 6.48 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23200980243487382		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.23200980243487382 | validation: 0.3014525080324165]
	TIME [epoch: 6.48 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2371468141649183		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.2371468141649183 | validation: 0.22858269942828513]
	TIME [epoch: 6.52 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856962471303275		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.2856962471303275 | validation: 0.20901328856227308]
	TIME [epoch: 6.49 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23909707873905828		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.23909707873905828 | validation: 0.21294763765637148]
	TIME [epoch: 6.48 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2268108464951178		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.2268108464951178 | validation: 0.18979738746265193]
	TIME [epoch: 6.48 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1858331974027082		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.1858331974027082 | validation: 0.2933124849221378]
	TIME [epoch: 6.48 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22255838408208306		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.22255838408208306 | validation: 0.23882381929049964]
	TIME [epoch: 6.48 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20411762086099106		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.20411762086099106 | validation: 0.1805984168594096]
	TIME [epoch: 6.51 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21315991362576034		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.21315991362576034 | validation: 0.4198157154324339]
	TIME [epoch: 6.51 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25179564211364824		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.25179564211364824 | validation: 0.2641930348076738]
	TIME [epoch: 6.49 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2060376140473091		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.2060376140473091 | validation: 0.23951017623855778]
	TIME [epoch: 6.48 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21137434564190796		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.21137434564190796 | validation: 0.20654749736456104]
	TIME [epoch: 6.48 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2370811160219936		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.2370811160219936 | validation: 0.1969547967123311]
	TIME [epoch: 6.47 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.225859310394462		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.225859310394462 | validation: 0.2539792293661297]
	TIME [epoch: 6.48 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3101565441634216		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.3101565441634216 | validation: 0.19483296946939807]
	TIME [epoch: 6.52 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21357409958030804		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.21357409958030804 | validation: 0.21931963162730952]
	TIME [epoch: 6.48 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21694059391585394		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.21694059391585394 | validation: 0.3561073681276589]
	TIME [epoch: 6.49 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24008131865974655		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.24008131865974655 | validation: 0.1987844884877342]
	TIME [epoch: 6.48 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26492563945530734		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.26492563945530734 | validation: 0.29101821538159645]
	TIME [epoch: 6.47 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3769047984290541		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.3769047984290541 | validation: 0.3928839988431546]
	TIME [epoch: 6.47 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36379517919050003		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.36379517919050003 | validation: 0.26948436860040614]
	TIME [epoch: 6.48 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24241810290612958		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.24241810290612958 | validation: 0.23078566194800196]
	TIME [epoch: 6.5 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2125089289641711		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.2125089289641711 | validation: 0.2832821046305798]
	TIME [epoch: 6.48 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2453550332474635		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.2453550332474635 | validation: 0.18361719769268298]
	TIME [epoch: 6.49 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22241489232512124		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.22241489232512124 | validation: 0.2247727781161078]
	TIME [epoch: 6.47 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19728179350915426		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.19728179350915426 | validation: 0.19565647375819453]
	TIME [epoch: 6.48 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19998123034436202		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.19998123034436202 | validation: 0.22610080178073794]
	TIME [epoch: 6.47 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26451332771879665		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.26451332771879665 | validation: 0.19837528548369512]
	TIME [epoch: 6.5 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2263321608594009		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.2263321608594009 | validation: 0.31787713791251315]
	TIME [epoch: 6.48 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2529967809630213		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.2529967809630213 | validation: 0.20233069969084613]
	TIME [epoch: 6.47 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20323330031397793		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.20323330031397793 | validation: 0.18747216021109667]
	TIME [epoch: 6.47 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19345632474497793		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.19345632474497793 | validation: 0.28355325659319575]
	TIME [epoch: 6.49 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28049856048608396		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.28049856048608396 | validation: 0.23152390453842017]
	TIME [epoch: 6.48 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25464902908034087		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.25464902908034087 | validation: 0.18824712675671657]
	TIME [epoch: 6.49 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23911549903307994		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.23911549903307994 | validation: 0.2642045132413954]
	TIME [epoch: 6.51 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24249814266036712		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.24249814266036712 | validation: 0.2049699494352538]
	TIME [epoch: 6.48 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19114046314008715		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.19114046314008715 | validation: 0.19097347374104842]
	TIME [epoch: 6.48 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23520588422593633		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.23520588422593633 | validation: 0.29731420858286933]
	TIME [epoch: 6.49 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25325651912465175		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.25325651912465175 | validation: 0.2377319089224653]
	TIME [epoch: 6.48 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.264004490906597		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.264004490906597 | validation: 0.27643107376637566]
	TIME [epoch: 6.49 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3326040334891992		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.3326040334891992 | validation: 0.29883323323924976]
	TIME [epoch: 6.51 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2515898401659245		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.2515898401659245 | validation: 0.35126192820355023]
	TIME [epoch: 6.48 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2559875542350192		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.2559875542350192 | validation: 0.2021429872701994]
	TIME [epoch: 6.47 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23417863675855127		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.23417863675855127 | validation: 0.2296266949405953]
	TIME [epoch: 6.48 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2190304664871608		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.2190304664871608 | validation: 0.2886387786911539]
	TIME [epoch: 6.48 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27012114186884		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.27012114186884 | validation: 0.2613211013457804]
	TIME [epoch: 6.48 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23461677763018138		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.23461677763018138 | validation: 0.22759460151800145]
	TIME [epoch: 6.49 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22723348244397026		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.22723348244397026 | validation: 0.2650950153940314]
	TIME [epoch: 6.52 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25702073316012686		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.25702073316012686 | validation: 0.2342908018115364]
	TIME [epoch: 6.49 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2932260148959402		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.2932260148959402 | validation: 0.2134839979060514]
	TIME [epoch: 6.48 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25819709216235726		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.25819709216235726 | validation: 0.3062099161230992]
	TIME [epoch: 6.49 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2438154573260275		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.2438154573260275 | validation: 0.17878087978218957]
	TIME [epoch: 6.48 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18379251005321204		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.18379251005321204 | validation: 0.29202131257520175]
	TIME [epoch: 6.49 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2044209715298549		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.2044209715298549 | validation: 0.18919079584754556]
	TIME [epoch: 6.5 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17133878561339702		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.17133878561339702 | validation: 0.23257959976418913]
	TIME [epoch: 6.51 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23229095415523854		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.23229095415523854 | validation: 0.2407837912659497]
	TIME [epoch: 6.49 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19483698179133693		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.19483698179133693 | validation: 0.174228445510999]
	TIME [epoch: 6.48 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19403148229427042		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.19403148229427042 | validation: 0.268135112190513]
	TIME [epoch: 6.49 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2423442103360431		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.2423442103360431 | validation: 0.3738518973250011]
	TIME [epoch: 6.49 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26658797601314677		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.26658797601314677 | validation: 0.2719614373514921]
	TIME [epoch: 6.49 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24417894045055744		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.24417894045055744 | validation: 0.24203203144905658]
	TIME [epoch: 6.53 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21334567271158744		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.21334567271158744 | validation: 0.211891757350702]
	TIME [epoch: 6.49 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530148194000117		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.2530148194000117 | validation: 0.34315448948653865]
	TIME [epoch: 6.49 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3267493215891104		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.3267493215891104 | validation: 0.2523301746801728]
	TIME [epoch: 6.49 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2351081627378614		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.2351081627378614 | validation: 0.20298020039408002]
	TIME [epoch: 6.48 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2807392063478332		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.2807392063478332 | validation: 0.23480665548788682]
	TIME [epoch: 6.49 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25867181483934654		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.25867181483934654 | validation: 0.7164897442279049]
	TIME [epoch: 6.5 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.411467017331806		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.411467017331806 | validation: 0.5423877874205119]
	TIME [epoch: 6.5 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32649042487853547		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.32649042487853547 | validation: 0.4070136968260842]
	TIME [epoch: 6.48 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259533752006205		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.259533752006205 | validation: 0.16443944177946684]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_643.pth
	Model improved!!!
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18150841377745172		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.18150841377745172 | validation: 0.19172137706828885]
	TIME [epoch: 6.49 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18590657608470176		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.18590657608470176 | validation: 0.29938310606495305]
	TIME [epoch: 6.49 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26718543861442		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.26718543861442 | validation: 0.3267605976134763]
	TIME [epoch: 6.49 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27983472439894314		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.27983472439894314 | validation: 0.21599588069668196]
	TIME [epoch: 6.51 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20842606104436898		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.20842606104436898 | validation: 0.22898728984891834]
	TIME [epoch: 6.48 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17576123205664945		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.17576123205664945 | validation: 0.1990565033424747]
	TIME [epoch: 6.48 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23870981972460842		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.23870981972460842 | validation: 0.2068404689590926]
	TIME [epoch: 6.47 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1682132104280712		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.1682132104280712 | validation: 0.20708093224999147]
	TIME [epoch: 6.47 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2864116130303555		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.2864116130303555 | validation: 0.31323758051563877]
	TIME [epoch: 6.48 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3717041077294688		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.3717041077294688 | validation: 0.24092931069238485]
	TIME [epoch: 6.48 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22159731039467756		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.22159731039467756 | validation: 0.18185344793339528]
	TIME [epoch: 6.52 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1824707957175597		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.1824707957175597 | validation: 0.3130229205216132]
	TIME [epoch: 6.47 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719744420693414		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.2719744420693414 | validation: 0.2629734159738875]
	TIME [epoch: 6.47 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20234601735869312		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.20234601735869312 | validation: 0.2397337189484585]
	TIME [epoch: 6.47 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21134620889173075		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.21134620889173075 | validation: 0.20623402301265487]
	TIME [epoch: 6.48 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17742752722211586		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.17742752722211586 | validation: 0.16328170900426522]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_659.pth
	Model improved!!!
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15733556992756353		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.15733556992756353 | validation: 0.3087907297182366]
	TIME [epoch: 6.53 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25014518362753324		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.25014518362753324 | validation: 0.26017948878465]
	TIME [epoch: 6.5 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2277134037684555		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.2277134037684555 | validation: 0.18814121299027328]
	TIME [epoch: 6.49 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23083080524053434		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.23083080524053434 | validation: 0.1991095746546007]
	TIME [epoch: 6.49 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21788446913700968		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.21788446913700968 | validation: 0.16592741197761854]
	TIME [epoch: 6.49 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18016578822693086		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.18016578822693086 | validation: 0.16643403241829163]
	TIME [epoch: 6.49 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16114130559510575		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.16114130559510575 | validation: 0.18819582980741437]
	TIME [epoch: 6.5 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2150332654286643		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.2150332654286643 | validation: 0.23834479921897228]
	TIME [epoch: 6.52 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29002983937511934		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.29002983937511934 | validation: 0.28547434371938846]
	TIME [epoch: 6.49 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.236247163152799		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.236247163152799 | validation: 0.17084604880169146]
	TIME [epoch: 6.49 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2036274530702369		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.2036274530702369 | validation: 0.18629592331798484]
	TIME [epoch: 6.49 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1955828489000127		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.1955828489000127 | validation: 0.17598453603237857]
	TIME [epoch: 6.49 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2157596151852461		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.2157596151852461 | validation: 0.18765112021453148]
	TIME [epoch: 6.49 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1700306853353583		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.1700306853353583 | validation: 0.25715761861196257]
	TIME [epoch: 6.53 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2635039446691288		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.2635039446691288 | validation: 0.29768100896681865]
	TIME [epoch: 6.52 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25734155010332166		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.25734155010332166 | validation: 0.19646418514438238]
	TIME [epoch: 6.49 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19699969086058228		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.19699969086058228 | validation: 0.2337286019094299]
	TIME [epoch: 6.48 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20935311663030967		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.20935311663030967 | validation: 0.25067654627876623]
	TIME [epoch: 6.48 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20210472573555047		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.20210472573555047 | validation: 0.20358870976024127]
	TIME [epoch: 6.48 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24291411411429803		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.24291411411429803 | validation: 0.20914983509211119]
	TIME [epoch: 6.49 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1782685421136757		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.1782685421136757 | validation: 0.21875974592371228]
	TIME [epoch: 6.52 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2328788004154837		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.2328788004154837 | validation: 0.2071249903127928]
	TIME [epoch: 6.49 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28272194437240605		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.28272194437240605 | validation: 0.25530501936199024]
	TIME [epoch: 6.49 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21492657215259806		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.21492657215259806 | validation: 0.2754465888696096]
	TIME [epoch: 6.49 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24503560935139895		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.24503560935139895 | validation: 0.2651318672169274]
	TIME [epoch: 6.49 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23214207311609808		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.23214207311609808 | validation: 0.22887555015527802]
	TIME [epoch: 6.49 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20367564707974817		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.20367564707974817 | validation: 0.2031115281012579]
	TIME [epoch: 6.51 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1804194988199884		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1804194988199884 | validation: 0.20350749651610844]
	TIME [epoch: 6.52 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22345074937499199		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.22345074937499199 | validation: 0.31007739202029]
	TIME [epoch: 6.49 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24161279961149648		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.24161279961149648 | validation: 0.16579784784755766]
	TIME [epoch: 6.5 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15711576132506144		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.15711576132506144 | validation: 0.18164028663322968]
	TIME [epoch: 6.49 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18365350235074374		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.18365350235074374 | validation: 0.2562142051645468]
	TIME [epoch: 6.49 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22042021495364858		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.22042021495364858 | validation: 0.2266744768065503]
	TIME [epoch: 6.49 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2528497242615359		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.2528497242615359 | validation: 0.2514915780117704]
	TIME [epoch: 6.53 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2107292847986792		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.2107292847986792 | validation: 0.2731433339628165]
	TIME [epoch: 6.5 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23294215127940265		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.23294215127940265 | validation: 0.21588787195770895]
	TIME [epoch: 6.49 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19332515514037596		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.19332515514037596 | validation: 0.3187715153960165]
	TIME [epoch: 6.5 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3078905050623678		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.3078905050623678 | validation: 0.203500222312046]
	TIME [epoch: 6.49 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24310596367549459		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.24310596367549459 | validation: 0.23209544213658886]
	TIME [epoch: 6.5 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18967506361449177		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.18967506361449177 | validation: 0.17648512621802895]
	TIME [epoch: 6.51 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18049765388350883		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.18049765388350883 | validation: 0.213529647752018]
	TIME [epoch: 6.52 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17622843642467734		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.17622843642467734 | validation: 0.20739947088012883]
	TIME [epoch: 6.5 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1654941026893037		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.1654941026893037 | validation: 0.19563437226982736]
	TIME [epoch: 6.5 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17978535219449174		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.17978535219449174 | validation: 0.18995272639681665]
	TIME [epoch: 6.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502482168006314		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.2502482168006314 | validation: 0.22557819536285587]
	TIME [epoch: 6.49 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19374846831371348		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.19374846831371348 | validation: 0.2398136283453242]
	TIME [epoch: 6.5 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2656436107751438		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.2656436107751438 | validation: 0.24662998292869312]
	TIME [epoch: 6.53 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19865910378829324		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.19865910378829324 | validation: 0.2179671116647599]
	TIME [epoch: 6.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21410026709414948		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.21410026709414948 | validation: 0.18757934297829873]
	TIME [epoch: 6.49 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1823483034636302		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.1823483034636302 | validation: 0.2519531487957209]
	TIME [epoch: 6.49 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20652476034801986		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.20652476034801986 | validation: 0.19459694324517535]
	TIME [epoch: 6.49 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19118108243737073		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.19118108243737073 | validation: 0.2431844128946772]
	TIME [epoch: 6.49 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2382583285338749		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.2382583285338749 | validation: 0.2604278185785746]
	TIME [epoch: 6.5 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20843188498892212		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.20843188498892212 | validation: 0.18445650368375346]
	TIME [epoch: 6.53 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17159673838236728		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.17159673838236728 | validation: 0.21958750513296676]
	TIME [epoch: 6.5 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19381700644289385		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.19381700644289385 | validation: 0.1857221946153826]
	TIME [epoch: 6.49 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24702190554815268		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.24702190554815268 | validation: 0.18575180768314384]
	TIME [epoch: 6.49 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26597729251710944		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.26597729251710944 | validation: 0.41136847925539133]
	TIME [epoch: 6.5 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3561147314630644		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.3561147314630644 | validation: 0.22057217098675128]
	TIME [epoch: 6.5 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1643753811120477		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1643753811120477 | validation: 0.22460521596792526]
	TIME [epoch: 6.53 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18330001663579365		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.18330001663579365 | validation: 0.19813090695145907]
	TIME [epoch: 6.5 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15376648111219907		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.15376648111219907 | validation: 0.1739236687488588]
	TIME [epoch: 6.49 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15595149513826317		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.15595149513826317 | validation: 0.2138691977942333]
	TIME [epoch: 6.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16827365560979365		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.16827365560979365 | validation: 0.18683474295507496]
	TIME [epoch: 6.5 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12728016713354273		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.12728016713354273 | validation: 0.17254964962429165]
	TIME [epoch: 6.5 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1586089792223817		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.1586089792223817 | validation: 0.24070113646530536]
	TIME [epoch: 6.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22502889539571339		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.22502889539571339 | validation: 0.19780467625136255]
	TIME [epoch: 6.53 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19508030931866768		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.19508030931866768 | validation: 0.23953561481774363]
	TIME [epoch: 6.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2085904553519988		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.2085904553519988 | validation: 0.1966552569414421]
	TIME [epoch: 6.49 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15809556973705977		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.15809556973705977 | validation: 0.2511772293816142]
	TIME [epoch: 6.5 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1965309910091673		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.1965309910091673 | validation: 0.24873296572117262]
	TIME [epoch: 6.5 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20337386088982254		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.20337386088982254 | validation: 0.22850583651663928]
	TIME [epoch: 6.5 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17063547868501922		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.17063547868501922 | validation: 0.24564204192148445]
	TIME [epoch: 6.53 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18910474131106536		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.18910474131106536 | validation: 0.17833859237487196]
	TIME [epoch: 6.5 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18145023165128177		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.18145023165128177 | validation: 0.23508176007839368]
	TIME [epoch: 6.5 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17224594082307493		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.17224594082307493 | validation: 0.19211905977461957]
	TIME [epoch: 6.5 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19414694194750293		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.19414694194750293 | validation: 0.24754124179746473]
	TIME [epoch: 6.5 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25146177696523314		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.25146177696523314 | validation: 0.31324847650974297]
	TIME [epoch: 6.5 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2831303606428264		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.2831303606428264 | validation: 0.17387345749604666]
	TIME [epoch: 6.49 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18574131408049868		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.18574131408049868 | validation: 0.23098090045770536]
	TIME [epoch: 6.53 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17506622374029748		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.17506622374029748 | validation: 0.20622565797798081]
	TIME [epoch: 6.5 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21502360828105155		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.21502360828105155 | validation: 0.17822097733023548]
	TIME [epoch: 6.49 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1786980508306379		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.1786980508306379 | validation: 0.17342446635177802]
	TIME [epoch: 6.49 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871223154326016		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.1871223154326016 | validation: 0.22338921813879423]
	TIME [epoch: 6.49 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17880284523669845		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.17880284523669845 | validation: 0.18357745460722455]
	TIME [epoch: 6.5 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17909120607812098		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.17909120607812098 | validation: 0.23721824524680268]
	TIME [epoch: 6.51 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17919199298192154		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.17919199298192154 | validation: 0.2444662374191936]
	TIME [epoch: 6.51 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19785040448485902		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.19785040448485902 | validation: 0.2595569757487078]
	TIME [epoch: 6.49 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20065497608727925		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.20065497608727925 | validation: 0.2119582112209737]
	TIME [epoch: 6.49 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16214929958411323		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.16214929958411323 | validation: 0.17091506413505841]
	TIME [epoch: 6.49 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16011484026022776		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.16011484026022776 | validation: 0.18991287293745554]
	TIME [epoch: 6.49 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1880823848938949		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.1880823848938949 | validation: 0.16365776837020118]
	TIME [epoch: 6.49 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13833791397330647		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.13833791397330647 | validation: 0.1660705715927602]
	TIME [epoch: 6.53 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14166830777705605		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.14166830777705605 | validation: 0.1946083105954969]
	TIME [epoch: 6.5 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16155056079102684		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.16155056079102684 | validation: 0.2731253142069645]
	TIME [epoch: 6.49 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.192046779380673		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.192046779380673 | validation: 0.1691169555973943]
	TIME [epoch: 6.49 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.170744631294521		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.170744631294521 | validation: 0.26480022538390485]
	TIME [epoch: 6.49 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18021476767503103		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.18021476767503103 | validation: 0.23708305616867986]
	TIME [epoch: 6.49 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1903584581155696		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.1903584581155696 | validation: 0.25376514131941064]
	TIME [epoch: 6.51 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1901554648555385		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.1901554648555385 | validation: 0.25482384591481677]
	TIME [epoch: 6.51 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1766098943361138		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.1766098943361138 | validation: 0.17252146217969688]
	TIME [epoch: 6.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17550685789313206		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.17550685789313206 | validation: 0.17859129861946296]
	TIME [epoch: 6.49 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21438515646151374		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.21438515646151374 | validation: 0.21961955614788703]
	TIME [epoch: 6.49 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15277682629382222		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.15277682629382222 | validation: 0.15135664887995112]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_763.pth
	Model improved!!!
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15613941743434362		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.15613941743434362 | validation: 0.16767129460767463]
	TIME [epoch: 6.49 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15565782840168957		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.15565782840168957 | validation: 0.1792069927130861]
	TIME [epoch: 6.52 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14695454186540458		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.14695454186540458 | validation: 0.16584628188658138]
	TIME [epoch: 6.49 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1339691573654249		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.1339691573654249 | validation: 0.17079480421249446]
	TIME [epoch: 6.49 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353377137017507		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.1353377137017507 | validation: 0.18046908182331986]
	TIME [epoch: 6.49 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1559934484032736		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.1559934484032736 | validation: 0.18828121345150414]
	TIME [epoch: 6.49 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15123044500549812		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.15123044500549812 | validation: 0.1531905439927921]
	TIME [epoch: 6.49 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15544534778825533		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.15544534778825533 | validation: 0.19973286789278594]
	TIME [epoch: 6.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15172783323920405		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.15172783323920405 | validation: 0.184548648215858]
	TIME [epoch: 6.51 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1687485708526809		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.1687485708526809 | validation: 0.20480189420181596]
	TIME [epoch: 6.49 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421810607352637		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.1421810607352637 | validation: 0.1729112437090485]
	TIME [epoch: 6.49 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14352391310442317		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.14352391310442317 | validation: 0.20427579845840094]
	TIME [epoch: 6.49 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1401390976315418		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.1401390976315418 | validation: 0.18226770520065758]
	TIME [epoch: 6.49 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16172170746069076		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.16172170746069076 | validation: 0.174983236616429]
	TIME [epoch: 6.49 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16647342664885653		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.16647342664885653 | validation: 0.27765532971307916]
	TIME [epoch: 6.51 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2046102005318055		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.2046102005318055 | validation: 0.2217590914044333]
	TIME [epoch: 6.49 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17934378773921597		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.17934378773921597 | validation: 0.1630237043923318]
	TIME [epoch: 6.48 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12903092129204966		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.12903092129204966 | validation: 0.1766182091473852]
	TIME [epoch: 6.48 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1782950494602476		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.1782950494602476 | validation: 0.1707868521587831]
	TIME [epoch: 6.48 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1425875325734483		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.1425875325734483 | validation: 0.24675386204052352]
	TIME [epoch: 6.48 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22984733863979195		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.22984733863979195 | validation: 0.1960495881393456]
	TIME [epoch: 6.48 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17424855667842987		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.17424855667842987 | validation: 0.1738995734733297]
	TIME [epoch: 6.51 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1485315350519601		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.1485315350519601 | validation: 0.24304281122978447]
	TIME [epoch: 6.49 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18670654577618814		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.18670654577618814 | validation: 0.1912214519620572]
	TIME [epoch: 6.48 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16981499001478045		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.16981499001478045 | validation: 0.20633709520685195]
	TIME [epoch: 6.48 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1909062572482833		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.1909062572482833 | validation: 0.2114962198139193]
	TIME [epoch: 6.48 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1871055216653702		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.1871055216653702 | validation: 0.21163551222252533]
	TIME [epoch: 6.49 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1853588996425024		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.1853588996425024 | validation: 0.22052276702460938]
	TIME [epoch: 6.51 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16095122474102655		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.16095122474102655 | validation: 0.19158231109340257]
	TIME [epoch: 6.5 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1885216875451422		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.1885216875451422 | validation: 0.19911162056544726]
	TIME [epoch: 6.49 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1636950957201119		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.1636950957201119 | validation: 0.18748128275399545]
	TIME [epoch: 6.49 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1614493302627854		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.1614493302627854 | validation: 0.24344919718268762]
	TIME [epoch: 6.48 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17679577219917936		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.17679577219917936 | validation: 0.2561881328490711]
	TIME [epoch: 6.49 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20341706289600436		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.20341706289600436 | validation: 0.20884866177683922]
	TIME [epoch: 6.49 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14286028366857073		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.14286028366857073 | validation: 0.2063724783843074]
	TIME [epoch: 6.52 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2120841934045471		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.2120841934045471 | validation: 0.16610048884762832]
	TIME [epoch: 6.49 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15119003279458582		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.15119003279458582 | validation: 0.19635056010042398]
	TIME [epoch: 6.49 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14583882668390064		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.14583882668390064 | validation: 0.17819490200969945]
	TIME [epoch: 6.49 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15651634071823012		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.15651634071823012 | validation: 0.20057979485367988]
	TIME [epoch: 6.49 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14953581894661852		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.14953581894661852 | validation: 0.19258925270749822]
	TIME [epoch: 6.47 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.180487292767928		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.180487292767928 | validation: 0.17993296013290647]
	TIME [epoch: 6.49 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17282690176171728		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.17282690176171728 | validation: 0.15614425515617847]
	TIME [epoch: 6.5 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15739872619929562		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.15739872619929562 | validation: 0.19240376067296747]
	TIME [epoch: 6.49 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25335420634788347		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.25335420634788347 | validation: 0.22043195313089337]
	TIME [epoch: 6.49 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1848954772970425		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.1848954772970425 | validation: 0.2584301130833686]
	TIME [epoch: 6.49 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17928764878919917		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.17928764878919917 | validation: 0.18086238605042326]
	TIME [epoch: 6.49 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2059645249568386		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.2059645249568386 | validation: 0.2284569559225082]
	TIME [epoch: 6.49 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18584476346946802		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.18584476346946802 | validation: 0.23136252096624282]
	TIME [epoch: 6.52 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15200832102163248		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.15200832102163248 | validation: 0.17184310182117415]
	TIME [epoch: 6.49 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16753059721788066		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.16753059721788066 | validation: 0.18598906910330407]
	TIME [epoch: 6.49 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20116416720022023		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.20116416720022023 | validation: 0.26406546500696015]
	TIME [epoch: 6.49 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20169555733178662		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.20169555733178662 | validation: 0.17492857558921338]
	TIME [epoch: 6.47 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17166734033793535		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.17166734033793535 | validation: 0.21051752490518064]
	TIME [epoch: 6.48 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1947913564153253		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.1947913564153253 | validation: 0.19306286816497142]
	TIME [epoch: 6.49 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1893127049775914		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.1893127049775914 | validation: 0.2050414373329733]
	TIME [epoch: 6.5 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16577196626339047		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.16577196626339047 | validation: 0.1737980561190551]
	TIME [epoch: 6.49 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569244132733419		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1569244132733419 | validation: 0.18491737895736904]
	TIME [epoch: 6.49 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15372811721801244		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.15372811721801244 | validation: 0.15755295796347274]
	TIME [epoch: 6.49 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15725764040823945		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.15725764040823945 | validation: 0.1709294594248213]
	TIME [epoch: 6.49 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16277684877785042		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.16277684877785042 | validation: 0.19323934015374675]
	TIME [epoch: 6.49 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14964745121880563		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.14964745121880563 | validation: 0.17298832299458508]
	TIME [epoch: 6.53 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1751350128783317		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.1751350128783317 | validation: 0.2542126667525424]
	TIME [epoch: 6.5 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17982323040011447		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.17982323040011447 | validation: 0.2098237096590227]
	TIME [epoch: 6.47 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16729906715093987		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.16729906715093987 | validation: 0.2722610259389175]
	TIME [epoch: 6.49 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15127876894931647		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.15127876894931647 | validation: 0.1727292712894554]
	TIME [epoch: 6.47 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14124170289916216		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.14124170289916216 | validation: 0.2061669083163263]
	TIME [epoch: 6.49 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17290181435659246		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.17290181435659246 | validation: 0.2140624313951732]
	TIME [epoch: 6.48 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16378823029610243		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.16378823029610243 | validation: 0.18762054538376127]
	TIME [epoch: 6.52 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14307593385708667		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.14307593385708667 | validation: 0.1871075448572416]
	TIME [epoch: 6.47 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14211299154338855		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.14211299154338855 | validation: 0.17408997423317082]
	TIME [epoch: 6.49 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17774106511024834		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.17774106511024834 | validation: 0.2337615715200613]
	TIME [epoch: 6.48 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16871841161483062		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.16871841161483062 | validation: 0.21388066112438922]
	TIME [epoch: 6.49 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1571434220261425		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.1571434220261425 | validation: 0.17207543636407366]
	TIME [epoch: 6.49 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16626623490397402		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.16626623490397402 | validation: 0.18722861544692074]
	TIME [epoch: 6.49 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14215379816615323		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.14215379816615323 | validation: 0.19117080456949326]
	TIME [epoch: 6.49 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16049310294959526		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.16049310294959526 | validation: 0.2057867014600413]
	TIME [epoch: 6.48 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15031626677675622		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.15031626677675622 | validation: 0.16498391093230808]
	TIME [epoch: 6.49 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14983250453769426		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.14983250453769426 | validation: 0.1844346100440164]
	TIME [epoch: 6.47 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13926584881375753		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.13926584881375753 | validation: 0.155467523438391]
	TIME [epoch: 6.48 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16631913510336044		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.16631913510336044 | validation: 0.1938980325095387]
	TIME [epoch: 6.48 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19485418128720938		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.19485418128720938 | validation: 0.15659883969698063]
	TIME [epoch: 6.52 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14347120075599779		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.14347120075599779 | validation: 0.15293506217536265]
	TIME [epoch: 6.5 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13717269705589816		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.13717269705589816 | validation: 0.14712423739721417]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_846.pth
	Model improved!!!
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12232425083749164		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.12232425083749164 | validation: 0.17696266015244952]
	TIME [epoch: 6.49 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13851674390183819		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.13851674390183819 | validation: 0.17084221478611603]
	TIME [epoch: 6.48 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14968691931990638		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.14968691931990638 | validation: 0.20130807615032556]
	TIME [epoch: 6.47 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16471811949345538		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.16471811949345538 | validation: 0.18055099172523903]
	TIME [epoch: 6.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1579101835700298		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.1579101835700298 | validation: 0.17468023623063034]
	TIME [epoch: 6.51 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16849611776220677		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.16849611776220677 | validation: 0.15358530523283562]
	TIME [epoch: 6.48 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17110356524769932		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.17110356524769932 | validation: 0.17641490184752193]
	TIME [epoch: 6.49 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1866041214391233		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.1866041214391233 | validation: 0.19468076470399354]
	TIME [epoch: 6.47 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1632653841292069		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.1632653841292069 | validation: 0.15488891220242024]
	TIME [epoch: 6.49 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15491098544821022		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.15491098544821022 | validation: 0.15160791349021172]
	TIME [epoch: 6.47 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16943607078790124		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.16943607078790124 | validation: 0.17448678597007208]
	TIME [epoch: 6.53 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17125146457903784		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.17125146457903784 | validation: 0.17569907984017646]
	TIME [epoch: 6.47 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1733694875020508		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.1733694875020508 | validation: 0.1473666168290759]
	TIME [epoch: 6.48 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16705140396382268		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.16705140396382268 | validation: 0.16591356250243258]
	TIME [epoch: 6.48 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16588287803991641		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.16588287803991641 | validation: 0.17233544446708146]
	TIME [epoch: 6.48 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14881100686577453		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.14881100686577453 | validation: 0.16306314480086645]
	TIME [epoch: 6.47 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14047437600954119		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.14047437600954119 | validation: 0.1431677402699099]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_863.pth
	Model improved!!!
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14867294184123306		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.14867294184123306 | validation: 0.1625857111724099]
	TIME [epoch: 6.49 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16939573363893423		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.16939573363893423 | validation: 0.12952416279300435]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_865.pth
	Model improved!!!
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1431337637081201		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.1431337637081201 | validation: 0.14750590428880053]
	TIME [epoch: 6.48 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14943787036774922		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.14943787036774922 | validation: 0.16740692135448831]
	TIME [epoch: 6.47 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13653900808011107		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.13653900808011107 | validation: 0.16603111234307905]
	TIME [epoch: 6.47 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1421618456758337		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.1421618456758337 | validation: 0.1836808759522377]
	TIME [epoch: 6.47 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13081457050483236		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.13081457050483236 | validation: 0.15549136474744327]
	TIME [epoch: 6.52 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14612636696094905		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.14612636696094905 | validation: 0.18688631472568096]
	TIME [epoch: 6.47 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424349327575886		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.1424349327575886 | validation: 0.15110754613575791]
	TIME [epoch: 6.48 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14491633307165486		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.14491633307165486 | validation: 0.19237739819914226]
	TIME [epoch: 6.47 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13257680187037696		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.13257680187037696 | validation: 0.17086270997545874]
	TIME [epoch: 6.47 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21214353358281346		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.21214353358281346 | validation: 0.24512145650838352]
	TIME [epoch: 6.48 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20550946808881737		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.20550946808881737 | validation: 0.23454719936399585]
	TIME [epoch: 6.49 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1607596028748462		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.1607596028748462 | validation: 0.16794024790625361]
	TIME [epoch: 6.5 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1435071781296669		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.1435071781296669 | validation: 0.15344914778816696]
	TIME [epoch: 6.49 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13693206918515477		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.13693206918515477 | validation: 0.13389865245282961]
	TIME [epoch: 6.49 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418601168064614		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.1418601168064614 | validation: 0.15963289989573354]
	TIME [epoch: 6.47 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14077510815436803		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.14077510815436803 | validation: 0.1874684715163077]
	TIME [epoch: 6.47 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15876299795668153		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.15876299795668153 | validation: 0.1698379093477627]
	TIME [epoch: 6.48 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16957453758444235		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.16957453758444235 | validation: 0.16142947835339244]
	TIME [epoch: 6.52 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15907683211054588		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.15907683211054588 | validation: 0.14787916916136978]
	TIME [epoch: 6.49 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15078494093492822		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.15078494093492822 | validation: 0.15170882960246865]
	TIME [epoch: 6.47 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12309854077773569		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.12309854077773569 | validation: 0.1565625945760442]
	TIME [epoch: 6.48 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14549024665274699		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.14549024665274699 | validation: 0.241920648150079]
	TIME [epoch: 6.49 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1774165542548598		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.1774165542548598 | validation: 0.16218954196057866]
	TIME [epoch: 6.47 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13936740503597234		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.13936740503597234 | validation: 0.15632943439015798]
	TIME [epoch: 6.49 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15613018319499578		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.15613018319499578 | validation: 0.17017706139948519]
	TIME [epoch: 6.51 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15376351424492188		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.15376351424492188 | validation: 0.2135112007906067]
	TIME [epoch: 6.48 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15987104667880148		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.15987104667880148 | validation: 0.19361248889123517]
	TIME [epoch: 6.47 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17033827746809277		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.17033827746809277 | validation: 0.18386182293339284]
	TIME [epoch: 6.48 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14504901393000807		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.14504901393000807 | validation: 0.1772200178379653]
	TIME [epoch: 6.48 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1411399448542538		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.1411399448542538 | validation: 0.1484531124668139]
	TIME [epoch: 6.47 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13816102137001002		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.13816102137001002 | validation: 0.1451135063403801]
	TIME [epoch: 6.52 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13864261107388787		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.13864261107388787 | validation: 0.1624947904217992]
	TIME [epoch: 6.49 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14796142041101543		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.14796142041101543 | validation: 0.16970079539381538]
	TIME [epoch: 6.49 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14472372369029995		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.14472372369029995 | validation: 0.20556373265703015]
	TIME [epoch: 6.48 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1863077950878215		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.1863077950878215 | validation: 0.2129348621072227]
	TIME [epoch: 6.49 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17426559534403085		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.17426559534403085 | validation: 0.23483634073020226]
	TIME [epoch: 6.49 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1708141683892736		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.1708141683892736 | validation: 0.1894732274000348]
	TIME [epoch: 6.49 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16505275287069743		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.16505275287069743 | validation: 0.19904802175469014]
	TIME [epoch: 6.52 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15000548997287136		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.15000548997287136 | validation: 0.14872260460060552]
	TIME [epoch: 6.49 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13278961548370577		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.13278961548370577 | validation: 0.14990402221021742]
	TIME [epoch: 6.47 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13894648101185672		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.13894648101185672 | validation: 0.15483107053040573]
	TIME [epoch: 6.49 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1425120364542262		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.1425120364542262 | validation: 0.1448565985387112]
	TIME [epoch: 6.48 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12467061552763187		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.12467061552763187 | validation: 0.17442075321154016]
	TIME [epoch: 6.49 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13913362827653875		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.13913362827653875 | validation: 0.1651889510322017]
	TIME [epoch: 6.49 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12994461711967145		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.12994461711967145 | validation: 0.1439995945118811]
	TIME [epoch: 6.5 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409837041297578		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.1409837041297578 | validation: 0.1712267623585796]
	TIME [epoch: 6.48 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13884705930159238		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.13884705930159238 | validation: 0.13860589389753436]
	TIME [epoch: 6.49 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13084635737678071		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.13084635737678071 | validation: 0.14384480986415327]
	TIME [epoch: 6.48 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14914052500460537		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.14914052500460537 | validation: 0.18690045385940401]
	TIME [epoch: 6.49 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381591640952796		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.1381591640952796 | validation: 0.14726772707743177]
	TIME [epoch: 6.48 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13476359281894865		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.13476359281894865 | validation: 0.2110217053555102]
	TIME [epoch: 6.52 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1549422919059481		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.1549422919059481 | validation: 0.1755731606580801]
	TIME [epoch: 6.48 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14948699840548824		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.14948699840548824 | validation: 0.1949042516734237]
	TIME [epoch: 6.49 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16566902162703212		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.16566902162703212 | validation: 0.16179942508606115]
	TIME [epoch: 6.47 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1543547577066033		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.1543547577066033 | validation: 0.15477998700868334]
	TIME [epoch: 6.47 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385407104477949		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.1385407104477949 | validation: 0.18187472619529793]
	TIME [epoch: 6.48 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12986179592569996		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.12986179592569996 | validation: 0.17282468356514785]
	TIME [epoch: 6.49 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14032313659230397		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.14032313659230397 | validation: 0.19335673451374324]
	TIME [epoch: 6.5 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1588604575158517		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.1588604575158517 | validation: 0.16435058566821806]
	TIME [epoch: 6.49 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.136977234899143		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.136977234899143 | validation: 0.17013611414872537]
	TIME [epoch: 6.47 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15023358410009235		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.15023358410009235 | validation: 0.1579627782414364]
	TIME [epoch: 6.49 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13001701807456595		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.13001701807456595 | validation: 0.1583402571655005]
	TIME [epoch: 6.47 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12536873163723472		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.12536873163723472 | validation: 0.1627739078225194]
	TIME [epoch: 6.48 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.122603019782246		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.122603019782246 | validation: 0.1495566135854824]
	TIME [epoch: 6.51 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13896972213748054		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.13896972213748054 | validation: 0.17079380351645904]
	TIME [epoch: 6.49 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894571415693842		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.12894571415693842 | validation: 0.1475299367792035]
	TIME [epoch: 6.48 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12541548265814872		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.12541548265814872 | validation: 0.11842979953515367]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240309_135628/states/model_tr_study1_932.pth
	Model improved!!!
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13345822546154995		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.13345822546154995 | validation: 0.1324052687554361]
	TIME [epoch: 6.46 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12623941173178935		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.12623941173178935 | validation: 0.13463423607523542]
	TIME [epoch: 6.47 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1297856253355614		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.1297856253355614 | validation: 0.14639540361359768]
	TIME [epoch: 6.49 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14569909048376875		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.14569909048376875 | validation: 0.15750871820218512]
	TIME [epoch: 6.52 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12564317868734887		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.12564317868734887 | validation: 0.14520735342642602]
	TIME [epoch: 6.49 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12678384940210763		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.12678384940210763 | validation: 0.15309016635923692]
	TIME [epoch: 6.47 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13447806884478192		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.13447806884478192 | validation: 0.135144031389928]
	TIME [epoch: 6.48 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1264281282729878		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.1264281282729878 | validation: 0.1760005429485926]
	TIME [epoch: 6.47 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16920026341165922		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.16920026341165922 | validation: 0.13745060874384368]
	TIME [epoch: 6.48 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1282277815163816		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.1282277815163816 | validation: 0.13703187703334976]
	TIME [epoch: 6.51 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12479445887394115		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.12479445887394115 | validation: 0.20466126547264302]
	TIME [epoch: 6.48 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17553288049304633		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.17553288049304633 | validation: 0.18653203895744055]
	TIME [epoch: 6.48 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14692385046137107		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.14692385046137107 | validation: 0.1690150237893208]
	TIME [epoch: 6.47 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12391983713726064		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.12391983713726064 | validation: 0.1486050102099675]
	TIME [epoch: 6.48 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1412834301567877		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.1412834301567877 | validation: 0.15256455775467362]
	TIME [epoch: 6.48 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500377536111051		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.1500377536111051 | validation: 0.15548225647358674]
	TIME [epoch: 6.48 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1292847703852306		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.1292847703852306 | validation: 0.14760703826620244]
	TIME [epoch: 6.51 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12869193817894092		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.12869193817894092 | validation: 0.1458767010052827]
	TIME [epoch: 6.47 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14651387479580932		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.14651387479580932 | validation: 0.13011298377558572]
	TIME [epoch: 6.49 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12825963891064976		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.12825963891064976 | validation: 0.15271240984640394]
	TIME [epoch: 6.47 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16319914703199923		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.16319914703199923 | validation: 0.18480235615544893]
	TIME [epoch: 6.48 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13689186680211118		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.13689186680211118 | validation: 0.1555611216903015]
	TIME [epoch: 6.47 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1451469772559127		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.1451469772559127 | validation: 0.15630676519185482]
	TIME [epoch: 6.48 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15322698871061136		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.15322698871061136 | validation: 0.1388035256237644]
	TIME [epoch: 6.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14315966843953856		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.14315966843953856 | validation: 0.1790496433847213]
	TIME [epoch: 6.49 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14511756799850148		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.14511756799850148 | validation: 0.16705214073360572]
	TIME [epoch: 6.47 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1535294292779079		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.1535294292779079 | validation: 0.22210393877700224]
	TIME [epoch: 6.48 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665634308634814		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.1665634308634814 | validation: 0.17197818577353302]
	TIME [epoch: 6.47 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13811146579160433		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.13811146579160433 | validation: 0.12623184953110841]
	TIME [epoch: 6.47 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12532664165506094		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.12532664165506094 | validation: 0.14758445744885637]
	TIME [epoch: 6.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12809362626284523		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.12809362626284523 | validation: 0.17745831870367013]
	TIME [epoch: 6.49 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124343183118974		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.124343183118974 | validation: 0.14858765133499807]
	TIME [epoch: 6.47 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1221392307469835		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.1221392307469835 | validation: 0.16658728986782756]
	TIME [epoch: 6.49 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14626729039449304		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.14626729039449304 | validation: 0.13688573819775815]
	TIME [epoch: 6.48 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13327898465145932		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.13327898465145932 | validation: 0.17327715279586778]
	TIME [epoch: 6.47 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383773108912824		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.1383773108912824 | validation: 0.1615555501459056]
	TIME [epoch: 6.49 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1352796699791109		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.1352796699791109 | validation: 0.14957361742641775]
	TIME [epoch: 6.51 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15702740847786306		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.15702740847786306 | validation: 0.15416532822218632]
	TIME [epoch: 6.48 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13754969879170975		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.13754969879170975 | validation: 0.17712607454163518]
	TIME [epoch: 6.48 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12268297305227761		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.12268297305227761 | validation: 0.13586262960977089]
	TIME [epoch: 6.47 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12071518394468198		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.12071518394468198 | validation: 0.1301179996623703]
	TIME [epoch: 6.48 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1229071119791544		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.1229071119791544 | validation: 0.1357572549052852]
	TIME [epoch: 6.48 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12583990428666364		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.12583990428666364 | validation: 0.15061876849267875]
	TIME [epoch: 6.51 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14481424145227798		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.14481424145227798 | validation: 0.20071554105615125]
	TIME [epoch: 6.5 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13702762071685537		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.13702762071685537 | validation: 0.12775682856361895]
	TIME [epoch: 6.47 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12956191151206436		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.12956191151206436 | validation: 0.16635832393402494]
	TIME [epoch: 6.47 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13702867672975955		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.13702867672975955 | validation: 0.13966925690763252]
	TIME [epoch: 6.47 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1268570456509942		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.1268570456509942 | validation: 0.13748801397718236]
	TIME [epoch: 6.47 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13077491469246522		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.13077491469246522 | validation: 0.14748561160739584]
	TIME [epoch: 6.48 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1389731766946465		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.1389731766946465 | validation: 0.17477707682608934]
	TIME [epoch: 6.51 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12894072818822921		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.12894072818822921 | validation: 0.1312906531845107]
	TIME [epoch: 6.49 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410668454281981		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.1410668454281981 | validation: 0.14059481786629405]
	TIME [epoch: 6.48 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1384685630449853		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.1384685630449853 | validation: 0.15044291458171433]
	TIME [epoch: 6.48 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13587864503979477		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.13587864503979477 | validation: 0.13488491443213693]
	TIME [epoch: 6.47 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14031649762604184		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.14031649762604184 | validation: 0.14994698374806187]
	TIME [epoch: 6.48 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12604059853274266		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.12604059853274266 | validation: 0.1362109391656778]
	TIME [epoch: 6.51 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11151578128981877		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.11151578128981877 | validation: 0.140949881909013]
	TIME [epoch: 6.49 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12434051436164129		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.12434051436164129 | validation: 0.13540629670764645]
	TIME [epoch: 6.48 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15018099652230182		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.15018099652230182 | validation: 0.15663222516270384]
	TIME [epoch: 6.49 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15196570712737265		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.15196570712737265 | validation: 0.1497706703489718]
	TIME [epoch: 6.48 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14913515314588427		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.14913515314588427 | validation: 0.14902721538328403]
	TIME [epoch: 6.48 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1328768178492804		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.1328768178492804 | validation: 0.1615378917788904]
	TIME [epoch: 6.48 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12728775778512688		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.12728775778512688 | validation: 0.1385369105477425]
	TIME [epoch: 6.51 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1467622661428355		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.1467622661428355 | validation: 0.14949395430008353]
	TIME [epoch: 6.47 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13702486037293002		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.13702486037293002 | validation: 0.13564406464396642]
	TIME [epoch: 6.48 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11213483656510398		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.11213483656510398 | validation: 0.1424981347391261]
	TIME [epoch: 6.47 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269090675071095		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.1269090675071095 | validation: 0.17492513841551835]
	TIME [epoch: 6.48 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14159331423687085		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.14159331423687085 | validation: 0.14525993301741438]
	TIME [epoch: 6.47 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14059016311200795		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.14059016311200795 | validation: 0.15762627186861586]
	TIME [epoch: 6.5 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14204176333789775		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.14204176333789775 | validation: 0.17127349552761373]
	TIME [epoch: 6.5 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13249414995040354		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.13249414995040354 | validation: 0.1496817155204998]
	TIME [epoch: 6.48 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130442649798317		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.130442649798317 | validation: 0.14954763253951833]
	TIME [epoch: 6.49 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130162481230743		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.130162481230743 | validation: 0.1575982683431563]
	TIME [epoch: 6.47 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12130441703395696		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.12130441703395696 | validation: 0.1453036170823108]
	TIME [epoch: 6.47 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12197978812803112		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.12197978812803112 | validation: 0.16025421798548098]
	TIME [epoch: 6.47 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1556213186917101		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.1556213186917101 | validation: 0.18077638543149277]
	TIME [epoch: 6.52 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406655004800813		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.1406655004800813 | validation: 0.17396120760835643]
	TIME [epoch: 6.49 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14689738172139788		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.14689738172139788 | validation: 0.17421985514468602]
	TIME [epoch: 6.48 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14511594514746545		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.14511594514746545 | validation: 0.19822310142533944]
	TIME [epoch: 6.49 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14275470682212527		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.14275470682212527 | validation: 0.15534976535909534]
	TIME [epoch: 6.48 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13734065377175428		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.13734065377175428 | validation: 0.16200727519535316]
	TIME [epoch: 6.49 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12225127677400964		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.12225127677400964 | validation: 0.16845718413638597]
	TIME [epoch: 6.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13266249872843755		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.13266249872843755 | validation: 0.17578062022643473]
	TIME [epoch: 6.5 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1241350434527044		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.1241350434527044 | validation: 0.14926257747171082]
	TIME [epoch: 6.48 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12144116043609664		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.12144116043609664 | validation: 0.16917238042192115]
	TIME [epoch: 6.49 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13927051901155668		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.13927051901155668 | validation: 0.18743748947510497]
	TIME [epoch: 6.47 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15273485992906616		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.15273485992906616 | validation: 0.20953126077916537]
	TIME [epoch: 6.48 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15872801768904185		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.15872801768904185 | validation: 0.1646906760352519]
	TIME [epoch: 6.47 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12602007365809487		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.12602007365809487 | validation: 0.16043914362323355]
	TIME [epoch: 6.52 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11419783218725013		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.11419783218725013 | validation: 0.1650826649622509]
	TIME [epoch: 6.47 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12228635325727044		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.12228635325727044 | validation: 0.17717197751500532]
	TIME [epoch: 6.48 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14088553383970095		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.14088553383970095 | validation: 0.18486687447385974]
	TIME [epoch: 6.47 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1381182667136445		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.1381182667136445 | validation: 0.16066428764187626]
	TIME [epoch: 6.47 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12692338967486144		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.12692338967486144 | validation: 0.1733400574208622]
	TIME [epoch: 6.47 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12993840486233113		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.12993840486233113 | validation: 0.17369755265612555]
	TIME [epoch: 6.49 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11867467179866578		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.11867467179866578 | validation: 0.13587346873992082]
	TIME [epoch: 6.51 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11903768507906012		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.11903768507906012 | validation: 0.1305418808310117]
	TIME [epoch: 6.48 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10942430355446979		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.10942430355446979 | validation: 0.15885948486443213]
	TIME [epoch: 6.48 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11685064551352227		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.11685064551352227 | validation: 0.15778460553898832]
	TIME [epoch: 6.48 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11308606745172325		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.11308606745172325 | validation: 0.14755439682312932]
	TIME [epoch: 6.47 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12165817214039477		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.12165817214039477 | validation: 0.14929367925886364]
	TIME [epoch: 6.47 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13727296634084324		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.13727296634084324 | validation: 0.14852895613372605]
	TIME [epoch: 6.52 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1248886686739881		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.1248886686739881 | validation: 0.12996221141547915]
	TIME [epoch: 6.49 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1201086758128764		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.1201086758128764 | validation: 0.1366292399187651]
	TIME [epoch: 6.49 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14301884600135822		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.14301884600135822 | validation: 0.16723062227156335]
	TIME [epoch: 6.47 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.152283448141423		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.152283448141423 | validation: 0.16433817695995426]
	TIME [epoch: 6.48 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1809509380751884		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.1809509380751884 | validation: 0.15164026416493656]
	TIME [epoch: 6.49 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15072511281277207		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.15072511281277207 | validation: 0.15149999505208345]
	TIME [epoch: 6.48 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13824248813190299		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.13824248813190299 | validation: 0.14513403598815117]
	TIME [epoch: 6.51 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12779189113828932		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.12779189113828932 | validation: 0.14641616576959696]
	TIME [epoch: 6.49 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14064634660419034		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.14064634660419034 | validation: 0.16201777131009226]
	TIME [epoch: 6.47 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1363981974901754		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.1363981974901754 | validation: 0.14058051594447854]
	TIME [epoch: 6.47 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13443132635971605		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.13443132635971605 | validation: 0.15183022686684175]
	TIME [epoch: 6.48 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12719774759881736		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.12719774759881736 | validation: 0.14472759639950175]
	TIME [epoch: 6.47 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13801550828891707		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.13801550828891707 | validation: 0.14073765089082282]
	TIME [epoch: 6.49 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1255618692577168		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.1255618692577168 | validation: 0.1325699484083119]
	TIME [epoch: 6.51 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12068201067770877		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.12068201067770877 | validation: 0.13839967770124234]
	TIME [epoch: 6.48 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12476911351182575		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.12476911351182575 | validation: 0.1344166292301281]
	TIME [epoch: 6.49 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1260863430995423		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.1260863430995423 | validation: 0.15303481762478174]
	TIME [epoch: 6.47 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13332996899678215		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.13332996899678215 | validation: 0.14142554295800805]
	TIME [epoch: 6.47 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1269167336318202		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.1269167336318202 | validation: 0.14940719392263574]
	TIME [epoch: 6.47 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11900379133648378		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.11900379133648378 | validation: 0.1578965541519664]
	TIME [epoch: 6.52 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13368640031159756		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.13368640031159756 | validation: 0.1636833627580894]
	TIME [epoch: 6.48 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12735848526656499		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.12735848526656499 | validation: 0.1400863715294114]
	TIME [epoch: 6.47 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12388533129540827		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.12388533129540827 | validation: 0.14774865422234987]
	TIME [epoch: 6.48 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11695633941166936		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.11695633941166936 | validation: 0.13375257058192028]
	TIME [epoch: 6.47 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1086327399413284		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.1086327399413284 | validation: 0.15389602033853172]
	TIME [epoch: 6.48 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13244954059838984		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.13244954059838984 | validation: 0.1890302868638527]
	TIME [epoch: 6.5 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1519333242905306		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.1519333242905306 | validation: 0.19191580198909391]
	TIME [epoch: 6.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13434779086264975		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.13434779086264975 | validation: 0.1821985360338136]
	TIME [epoch: 6.49 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12588360303220253		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.12588360303220253 | validation: 0.14984991360335492]
	TIME [epoch: 6.47 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12336792853649065		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.12336792853649065 | validation: 0.17343806891878935]
	TIME [epoch: 6.47 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13109088711357678		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.13109088711357678 | validation: 0.1552967704729459]
	TIME [epoch: 6.48 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11962027953282532		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.11962027953282532 | validation: 0.15161672179622265]
	TIME [epoch: 6.49 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12961828907660802		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.12961828907660802 | validation: 0.15196097404928036]
	TIME [epoch: 6.52 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1309935406688215		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.1309935406688215 | validation: 0.1469126753898417]
	TIME [epoch: 6.49 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12408945437450787		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.12408945437450787 | validation: 0.1534599897118636]
	TIME [epoch: 6.48 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12282377061115303		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.12282377061115303 | validation: 0.14802998461603573]
	TIME [epoch: 6.48 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11605033757976035		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.11605033757976035 | validation: 0.1526201900622005]
	TIME [epoch: 6.48 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.117874433332631		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.117874433332631 | validation: 0.15544832774139733]
	TIME [epoch: 6.48 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1206086905559081		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.1206086905559081 | validation: 0.16940678688231928]
	TIME [epoch: 6.48 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13194374182343926		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.13194374182343926 | validation: 0.1564020977574135]
	TIME [epoch: 6.51 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13458370806576608		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.13458370806576608 | validation: 0.18506077332521303]
	TIME [epoch: 6.48 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13010993932221745		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.13010993932221745 | validation: 0.14444715007198278]
	TIME [epoch: 6.48 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11826416337077977		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.11826416337077977 | validation: 0.16635926845705865]
	TIME [epoch: 6.48 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11620541033008172		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.11620541033008172 | validation: 0.12481055484985909]
	TIME [epoch: 6.46 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12515165218131732		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.12515165218131732 | validation: 0.14602193546586117]
	TIME [epoch: 6.48 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124172701155864		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.124172701155864 | validation: 0.14092359965722637]
	TIME [epoch: 6.52 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1324683190377136		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.1324683190377136 | validation: 0.1265679496222124]
	TIME [epoch: 6.48 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11998762667707305		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.11998762667707305 | validation: 0.12537725675936526]
	TIME [epoch: 6.47 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11177104934785914		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.11177104934785914 | validation: 0.16224711723488708]
	TIME [epoch: 6.48 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13036689455812833		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.13036689455812833 | validation: 0.13980586451555962]
	TIME [epoch: 6.48 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12722950564083904		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.12722950564083904 | validation: 0.13729531123498664]
	TIME [epoch: 6.47 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12116803611032351		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.12116803611032351 | validation: 0.14131878772195267]
	TIME [epoch: 6.48 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1193088060871154		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.1193088060871154 | validation: 0.15067094461231967]
	TIME [epoch: 6.52 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12268635881275115		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.12268635881275115 | validation: 0.1291139222550412]
	TIME [epoch: 6.49 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11006846068207947		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.11006846068207947 | validation: 0.1515532544439953]
	TIME [epoch: 6.48 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11453587886369171		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.11453587886369171 | validation: 0.15177154511046953]
	TIME [epoch: 6.48 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12113842766737587		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.12113842766737587 | validation: 0.17129051383846908]
	TIME [epoch: 6.48 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124148176105065		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.124148176105065 | validation: 0.17331524971326812]
	TIME [epoch: 6.47 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11977675369033472		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.11977675369033472 | validation: 0.17561474628421866]
	TIME [epoch: 6.5 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12024955360813958		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.12024955360813958 | validation: 0.15638765966446191]
	TIME [epoch: 6.49 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12450931033098411		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.12450931033098411 | validation: 0.17084529713622085]
	TIME [epoch: 6.48 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11333101799261033		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.11333101799261033 | validation: 0.149995406300835]
	TIME [epoch: 6.48 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1205296156297668		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.1205296156297668 | validation: 0.16828006499126624]
	TIME [epoch: 6.49 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12468302300922487		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.12468302300922487 | validation: 0.13501393531302408]
	TIME [epoch: 6.48 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11192925947571385		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.11192925947571385 | validation: 0.14415460305365377]
	TIME [epoch: 6.48 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11583961839732124		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.11583961839732124 | validation: 0.1419537548030131]
	TIME [epoch: 6.5 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12094574669204336		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.12094574669204336 | validation: 0.16409369638270171]
	TIME [epoch: 6.48 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12524105776567335		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.12524105776567335 | validation: 0.14055911125976556]
	TIME [epoch: 6.48 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12573555268104206		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.12573555268104206 | validation: 0.138572913434184]
	TIME [epoch: 6.49 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11566795774328145		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.11566795774328145 | validation: 0.1348444392008567]
	TIME [epoch: 6.47 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12349081607565252		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.12349081607565252 | validation: 0.1430275377376709]
	TIME [epoch: 6.47 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11791884555320273		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.11791884555320273 | validation: 0.1279655760491704]
	TIME [epoch: 6.49 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12437380001804367		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.12437380001804367 | validation: 0.130589770248223]
	TIME [epoch: 6.51 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11352637063461633		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.11352637063461633 | validation: 0.1393881506571908]
	TIME [epoch: 6.49 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064548672431936		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.11064548672431936 | validation: 0.1397846202056477]
	TIME [epoch: 6.48 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11782614443641999		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.11782614443641999 | validation: 0.1481993585158691]
	TIME [epoch: 6.48 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11769403552254755		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.11769403552254755 | validation: 0.14273410895818947]
	TIME [epoch: 6.47 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12034817440648266		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.12034817440648266 | validation: 0.1611449942387045]
	TIME [epoch: 6.49 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11236468846358327		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.11236468846358327 | validation: 0.14362760507270658]
	TIME [epoch: 6.51 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1183577116699503		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.1183577116699503 | validation: 0.16555899096107082]
	TIME [epoch: 6.48 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11402645858824331		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.11402645858824331 | validation: 0.16835338741157682]
	TIME [epoch: 6.48 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11707823869774091		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.11707823869774091 | validation: 0.17946885720507713]
	TIME [epoch: 6.47 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1305718787468359		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.1305718787468359 | validation: 0.1711169446260869]
	TIME [epoch: 6.47 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11853318657786244		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.11853318657786244 | validation: 0.15033905685282972]
	TIME [epoch: 6.46 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1164091132000897		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.1164091132000897 | validation: 0.1434216589749959]
	TIME [epoch: 6.48 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11587770865671516		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.11587770865671516 | validation: 0.15790638025890189]
	TIME [epoch: 6.51 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12622255011649802		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.12622255011649802 | validation: 0.16222023774563013]
	TIME [epoch: 6.48 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14260670389966368		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.14260670389966368 | validation: 0.16159706017170972]
	TIME [epoch: 6.48 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12469729686602402		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.12469729686602402 | validation: 0.1464277335982263]
	TIME [epoch: 6.48 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13869221557438832		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.13869221557438832 | validation: 0.15919110349826207]
	TIME [epoch: 6.48 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.130206110290619		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.130206110290619 | validation: 0.1690151543008171]
	TIME [epoch: 6.48 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569426089921538		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.1569426089921538 | validation: 0.15246034370231865]
	TIME [epoch: 6.53 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1250797480263459		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.1250797480263459 | validation: 0.128583444300113]
	TIME [epoch: 6.47 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1206682354072569		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.1206682354072569 | validation: 0.14810910553988232]
	TIME [epoch: 6.49 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12726023367402833		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.12726023367402833 | validation: 0.1419638028807645]
	TIME [epoch: 6.49 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12726192778268203		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.12726192778268203 | validation: 0.1511613401683476]
	TIME [epoch: 6.49 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12559210979976293		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.12559210979976293 | validation: 0.1686949138656314]
	TIME [epoch: 6.47 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14249948321231398		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.14249948321231398 | validation: 0.17277870024017078]
	TIME [epoch: 6.48 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14550637900254265		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.14550637900254265 | validation: 0.1998170113679935]
	TIME [epoch: 6.5 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13042422241485932		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.13042422241485932 | validation: 0.18028807496167548]
	TIME [epoch: 6.48 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12527230471947587		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.12527230471947587 | validation: 0.15828429803617483]
	TIME [epoch: 6.48 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12477240266004733		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.12477240266004733 | validation: 0.14940340944063865]
	TIME [epoch: 6.47 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1126337384603486		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.1126337384603486 | validation: 0.14562134976721455]
	TIME [epoch: 6.48 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12478575661898665		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.12478575661898665 | validation: 0.16524007665191537]
	TIME [epoch: 6.48 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11567605595426089		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.11567605595426089 | validation: 0.1461567293669291]
	TIME [epoch: 6.49 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11393534257044166		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.11393534257044166 | validation: 0.14663165088257915]
	TIME [epoch: 6.49 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11481775312161221		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.11481775312161221 | validation: 0.17973321831509714]
	TIME [epoch: 6.48 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1173104184589078		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.1173104184589078 | validation: 0.15299525655816712]
	TIME [epoch: 6.49 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11822920592707016		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.11822920592707016 | validation: 0.16582080587625192]
	TIME [epoch: 6.48 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11067301420164116		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.11067301420164116 | validation: 0.1409875828399508]
	TIME [epoch: 6.48 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11168101042723419		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.11168101042723419 | validation: 0.1631927594657248]
	TIME [epoch: 6.47 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231460761898926		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.1231460761898926 | validation: 0.1434417223779709]
	TIME [epoch: 6.52 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11555446400074476		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.11555446400074476 | validation: 0.15138253908622465]
	TIME [epoch: 6.48 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11552610641172426		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.11552610641172426 | validation: 0.14269442109242853]
	TIME [epoch: 6.48 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11694875080039713		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.11694875080039713 | validation: 0.15448381073152767]
	TIME [epoch: 6.49 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110158993796036		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.110158993796036 | validation: 0.14006317962886547]
	TIME [epoch: 6.47 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11439801220984258		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.11439801220984258 | validation: 0.14453097439896406]
	TIME [epoch: 6.48 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13518478318754168		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.13518478318754168 | validation: 0.14475003494375313]
	TIME [epoch: 6.49 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13191175186103704		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.13191175186103704 | validation: 0.1655259230485366]
	TIME [epoch: 6.51 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13315220080133355		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.13315220080133355 | validation: 0.18114230051619548]
	TIME [epoch: 6.48 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1300747437118433		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.1300747437118433 | validation: 0.16231740792506716]
	TIME [epoch: 6.48 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12069833959919556		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.12069833959919556 | validation: 0.15231315250482863]
	TIME [epoch: 6.48 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11753707835503356		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.11753707835503356 | validation: 0.14121207431467034]
	TIME [epoch: 6.49 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11012709268767301		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.11012709268767301 | validation: 0.14002085479426485]
	TIME [epoch: 6.48 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1243022806259867		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.1243022806259867 | validation: 0.14676425410912392]
	TIME [epoch: 6.51 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1358093210966228		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.1358093210966228 | validation: 0.14035596667638406]
	TIME [epoch: 6.48 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1365013614790521		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.1365013614790521 | validation: 0.13079087866772554]
	TIME [epoch: 6.48 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11536848094602688		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.11536848094602688 | validation: 0.13709407792632416]
	TIME [epoch: 6.49 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10821977748995928		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.10821977748995928 | validation: 0.14631921538008744]
	TIME [epoch: 6.48 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10965504187290562		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.10965504187290562 | validation: 0.13868428986978945]
	TIME [epoch: 6.47 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10455362427063668		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.10455362427063668 | validation: 0.13085451501306694]
	TIME [epoch: 6.48 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11449046286161312		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.11449046286161312 | validation: 0.1515158984147928]
	TIME [epoch: 6.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1135042794164761		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.1135042794164761 | validation: 0.14453817307601372]
	TIME [epoch: 6.47 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12139046844617184		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.12139046844617184 | validation: 0.15663242660480062]
	TIME [epoch: 6.46 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11158450461583697		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.11158450461583697 | validation: 0.14332365076239756]
	TIME [epoch: 6.45 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11206951151518371		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.11206951151518371 | validation: 0.13967650227533068]
	TIME [epoch: 6.46 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11214236218966399		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.11214236218966399 | validation: 0.13793283909962373]
	TIME [epoch: 6.45 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11069102428716568		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.11069102428716568 | validation: 0.1306792676859091]
	TIME [epoch: 6.49 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10565587626024306		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.10565587626024306 | validation: 0.13596928299883834]
	TIME [epoch: 6.45 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1181122432399337		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.1181122432399337 | validation: 0.13263475411763198]
	TIME [epoch: 6.46 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10922083529776802		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.10922083529776802 | validation: 0.1412250604514532]
	TIME [epoch: 6.44 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12126161839541894		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.12126161839541894 | validation: 0.13710281618774267]
	TIME [epoch: 6.46 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12603597451617224		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.12603597451617224 | validation: 0.15390214102584537]
	TIME [epoch: 6.44 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11317945687625523		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.11317945687625523 | validation: 0.14119805524789367]
	TIME [epoch: 6.45 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10902486024051625		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.10902486024051625 | validation: 0.1374853154247589]
	TIME [epoch: 6.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1163059812249656		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.1163059812249656 | validation: 0.13093491405516194]
	TIME [epoch: 6.46 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11640734086294639		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.11640734086294639 | validation: 0.17646737870287674]
	TIME [epoch: 6.44 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12432903575973686		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.12432903575973686 | validation: 0.1361579557810341]
	TIME [epoch: 6.46 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11872984278337392		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.11872984278337392 | validation: 0.1548285518854802]
	TIME [epoch: 6.46 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11655206274003613		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.11655206274003613 | validation: 0.14250410910459355]
	TIME [epoch: 6.44 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11948384786007701		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.11948384786007701 | validation: 0.15990322936260498]
	TIME [epoch: 6.47 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12674217430521245		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.12674217430521245 | validation: 0.14537574257066546]
	TIME [epoch: 6.47 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11499130845107122		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.11499130845107122 | validation: 0.137564203685384]
	TIME [epoch: 6.46 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10676739801156472		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.10676739801156472 | validation: 0.15442346108311952]
	TIME [epoch: 6.47 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11369471351278616		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.11369471351278616 | validation: 0.149346634915693]
	TIME [epoch: 6.48 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11546756737770152		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.11546756737770152 | validation: 0.16270802651014002]
	TIME [epoch: 6.48 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12310478060688539		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.12310478060688539 | validation: 0.16053518616552262]
	TIME [epoch: 6.48 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11544865467917678		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.11544865467917678 | validation: 0.16177714384655356]
	TIME [epoch: 6.52 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11663267081141496		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.11663267081141496 | validation: 0.15704682064615746]
	TIME [epoch: 6.48 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11505231599193394		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.11505231599193394 | validation: 0.16414993115057044]
	TIME [epoch: 6.48 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12183870099064974		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.12183870099064974 | validation: 0.16685224222433384]
	TIME [epoch: 6.49 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11958370255776557		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.11958370255776557 | validation: 0.1605050275392194]
	TIME [epoch: 6.48 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11617501964719987		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.11617501964719987 | validation: 0.13004317046918842]
	TIME [epoch: 6.49 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11462141730982638		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.11462141730982638 | validation: 0.15037336940816257]
	TIME [epoch: 6.51 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11688908310283833		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.11688908310283833 | validation: 0.14181812299527452]
	TIME [epoch: 6.51 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11369664431890078		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.11369664431890078 | validation: 0.13594868790854095]
	TIME [epoch: 6.47 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11133131356245944		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.11133131356245944 | validation: 0.13407836541292611]
	TIME [epoch: 6.49 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11569996179514638		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.11569996179514638 | validation: 0.13568599517259627]
	TIME [epoch: 6.48 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11315291400681371		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.11315291400681371 | validation: 0.13734815128618774]
	TIME [epoch: 6.49 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12011932922678618		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.12011932922678618 | validation: 0.13596560572707125]
	TIME [epoch: 6.48 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12171353591680129		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.12171353591680129 | validation: 0.13773812007694386]
	TIME [epoch: 6.51 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11778048327286612		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.11778048327286612 | validation: 0.12402146237354827]
	TIME [epoch: 6.48 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1126427775516872		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.1126427775516872 | validation: 0.14394635202492664]
	TIME [epoch: 6.47 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1145218873212702		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.1145218873212702 | validation: 0.12874014723380695]
	TIME [epoch: 6.48 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11504569811918357		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.11504569811918357 | validation: 0.14095968759441385]
	TIME [epoch: 6.47 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1201898128148052		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.1201898128148052 | validation: 0.14542850423042808]
	TIME [epoch: 6.48 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11480147504282795		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.11480147504282795 | validation: 0.13146566530642648]
	TIME [epoch: 6.48 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11404437495730677		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.11404437495730677 | validation: 0.1540971529541853]
	TIME [epoch: 6.53 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11733887041299784		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.11733887041299784 | validation: 0.1487399374090184]
	TIME [epoch: 6.49 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11611452131914382		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.11611452131914382 | validation: 0.15407014528477198]
	TIME [epoch: 6.49 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13535344224181994		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.13535344224181994 | validation: 0.17662354630799867]
	TIME [epoch: 6.47 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13561605354248615		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.13561605354248615 | validation: 0.1749076387200097]
	TIME [epoch: 6.48 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12325250610685418		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.12325250610685418 | validation: 0.16318187317486182]
	TIME [epoch: 6.47 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11253323020662431		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.11253323020662431 | validation: 0.16091178552694088]
	TIME [epoch: 6.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11609762249819057		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.11609762249819057 | validation: 0.15472679512721696]
	TIME [epoch: 6.48 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11610782832723952		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.11610782832723952 | validation: 0.1625866886252357]
	TIME [epoch: 6.48 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11482960170792361		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.11482960170792361 | validation: 0.1551664624567516]
	TIME [epoch: 6.46 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11633492905246137		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.11633492905246137 | validation: 0.153532133245579]
	TIME [epoch: 6.48 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114933302003007		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.114933302003007 | validation: 0.1541588966119987]
	TIME [epoch: 6.47 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11999934501256365		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.11999934501256365 | validation: 0.16308488056063625]
	TIME [epoch: 6.46 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12522164080105747		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.12522164080105747 | validation: 0.14557209042580874]
	TIME [epoch: 6.5 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11079352218017538		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.11079352218017538 | validation: 0.1479935205530151]
	TIME [epoch: 6.47 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12351659625930882		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.12351659625930882 | validation: 0.15823350377268255]
	TIME [epoch: 6.47 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12461658601237854		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.12461658601237854 | validation: 0.13680907438857673]
	TIME [epoch: 6.48 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11207956188474541		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.11207956188474541 | validation: 0.1432834281278629]
	TIME [epoch: 6.49 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11643277899154952		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.11643277899154952 | validation: 0.14863408353495255]
	TIME [epoch: 6.47 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1119858790347373		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.1119858790347373 | validation: 0.12848085586770633]
	TIME [epoch: 6.48 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11304672669253646		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.11304672669253646 | validation: 0.12810699827664038]
	TIME [epoch: 6.5 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10910721432229353		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.10910721432229353 | validation: 0.13108797914644135]
	TIME [epoch: 6.48 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10587399774585045		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.10587399774585045 | validation: 0.14088139978656103]
	TIME [epoch: 6.47 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11566655730610802		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.11566655730610802 | validation: 0.15368849635318527]
	TIME [epoch: 6.46 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11426994655770402		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.11426994655770402 | validation: 0.1308903157314179]
	TIME [epoch: 6.47 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1130657194676821		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.1130657194676821 | validation: 0.13710525180299762]
	TIME [epoch: 6.48 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11074244466263289		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.11074244466263289 | validation: 0.14600326128638924]
	TIME [epoch: 6.52 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11570974673868173		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.11570974673868173 | validation: 0.12797024194511225]
	TIME [epoch: 6.47 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11680502330328621		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.11680502330328621 | validation: 0.14066138835102224]
	TIME [epoch: 6.47 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12123809177742542		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.12123809177742542 | validation: 0.1476689102934039]
	TIME [epoch: 6.48 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12701132211466937		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.12701132211466937 | validation: 0.15392011695164867]
	TIME [epoch: 6.48 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1307246880959221		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.1307246880959221 | validation: 0.14507689912538138]
	TIME [epoch: 6.47 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12154811782827074		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.12154811782827074 | validation: 0.12956158682674093]
	TIME [epoch: 6.49 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11521923578787222		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.11521923578787222 | validation: 0.14046526263444375]
	TIME [epoch: 6.49 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11164227490893255		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.11164227490893255 | validation: 0.1429493839184058]
	TIME [epoch: 6.48 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11969597490266694		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.11969597490266694 | validation: 0.14162158792844076]
	TIME [epoch: 6.47 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10942483291430638		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.10942483291430638 | validation: 0.14306864039968392]
	TIME [epoch: 6.47 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11421434381670391		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.11421434381670391 | validation: 0.1395481312354985]
	TIME [epoch: 6.48 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11537437197846898		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.11537437197846898 | validation: 0.14534787478638314]
	TIME [epoch: 6.48 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12458398518701222		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.12458398518701222 | validation: 0.15142507144800654]
	TIME [epoch: 6.49 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12086263258192653		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.12086263258192653 | validation: 0.15728511139737106]
	TIME [epoch: 6.47 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11811246293710806		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.11811246293710806 | validation: 0.15441731236954784]
	TIME [epoch: 6.46 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1329738292949667		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.1329738292949667 | validation: 0.1677655003042559]
	TIME [epoch: 6.46 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13699324863887805		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.13699324863887805 | validation: 0.15371276090236807]
	TIME [epoch: 6.48 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12576150517608373		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.12576150517608373 | validation: 0.16819896603903212]
	TIME [epoch: 6.46 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12581929115571686		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.12581929115571686 | validation: 0.16725182114972675]
	TIME [epoch: 6.46 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12246762834588724		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.12246762834588724 | validation: 0.1645380898313995]
	TIME [epoch: 6.5 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1234499457677886		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.1234499457677886 | validation: 0.16508742977036725]
	TIME [epoch: 6.47 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12040465486796775		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.12040465486796775 | validation: 0.16011510438753807]
	TIME [epoch: 6.46 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11850395726287262		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.11850395726287262 | validation: 0.15829208292370464]
	TIME [epoch: 6.47 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.124161510520813		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.124161510520813 | validation: 0.1661800830504434]
	TIME [epoch: 6.46 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12417352675995881		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.12417352675995881 | validation: 0.15895132846844381]
	TIME [epoch: 6.48 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11847472096374914		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.11847472096374914 | validation: 0.14680088861824264]
	TIME [epoch: 6.5 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11905205982483025		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.11905205982483025 | validation: 0.14182457723424313]
	TIME [epoch: 6.48 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1231478532376799		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.1231478532376799 | validation: 0.15241973565778424]
	TIME [epoch: 6.47 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11596389798414485		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.11596389798414485 | validation: 0.15203585971717562]
	TIME [epoch: 6.47 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11451630325815947		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.11451630325815947 | validation: 0.15086630307653778]
	TIME [epoch: 6.47 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11429135861014371		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.11429135861014371 | validation: 0.15519098273673734]
	TIME [epoch: 6.47 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11605815139465825		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.11605815139465825 | validation: 0.15128758266015535]
	TIME [epoch: 6.47 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11989519215863377		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.11989519215863377 | validation: 0.16288049437209595]
	TIME [epoch: 6.51 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12452053848594828		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.12452053848594828 | validation: 0.15470043481334272]
	TIME [epoch: 6.47 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11283704896834029		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.11283704896834029 | validation: 0.15003263186408713]
	TIME [epoch: 6.47 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11594796324229115		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.11594796324229115 | validation: 0.14692094090638294]
	TIME [epoch: 6.47 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11265770944877788		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.11265770944877788 | validation: 0.13383691620336824]
	TIME [epoch: 6.47 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11126083440320492		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.11126083440320492 | validation: 0.14746409324292203]
	TIME [epoch: 6.47 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11689164957323565		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.11689164957323565 | validation: 0.15393967347223786]
	TIME [epoch: 6.49 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11322168514677455		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.11322168514677455 | validation: 0.1524269905730639]
	TIME [epoch: 6.49 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12246796842685093		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.12246796842685093 | validation: 0.15117171689310682]
	TIME [epoch: 6.47 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11668414099952891		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.11668414099952891 | validation: 0.15795499082412262]
	TIME [epoch: 6.47 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10966576271708839		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.10966576271708839 | validation: 0.14172354343499075]
	TIME [epoch: 6.47 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11110126240760818		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.11110126240760818 | validation: 0.16352032908244632]
	TIME [epoch: 6.47 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11594111150074796		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.11594111150074796 | validation: 0.16973185425957923]
	TIME [epoch: 6.47 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11825921178406755		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.11825921178406755 | validation: 0.141486696445157]
	TIME [epoch: 6.51 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.118630235700618		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.118630235700618 | validation: 0.138348560123429]
	TIME [epoch: 6.48 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12341045666321289		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.12341045666321289 | validation: 0.13706907465149476]
	TIME [epoch: 6.47 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11381143885109088		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.11381143885109088 | validation: 0.1528314487044097]
	TIME [epoch: 6.48 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12070979378463743		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.12070979378463743 | validation: 0.16261225102394408]
	TIME [epoch: 6.47 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12372231185540813		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.12372231185540813 | validation: 0.1400800756940531]
	TIME [epoch: 6.48 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12248400526243851		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.12248400526243851 | validation: 0.13685019491387088]
	TIME [epoch: 6.47 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11271410295198171		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.11271410295198171 | validation: 0.149895422967542]
	TIME [epoch: 6.51 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11474409059963604		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.11474409059963604 | validation: 0.14728926807057785]
	TIME [epoch: 6.47 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11756499288720812		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.11756499288720812 | validation: 0.1546215494433864]
	TIME [epoch: 6.47 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1155797989158437		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.1155797989158437 | validation: 0.14098776960941276]
	TIME [epoch: 6.46 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12329376907999705		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.12329376907999705 | validation: 0.15164240377217617]
	TIME [epoch: 6.48 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1171774497975298		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.1171774497975298 | validation: 0.1599802235237264]
	TIME [epoch: 6.47 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11152675765742837		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.11152675765742837 | validation: 0.13799762914498068]
	TIME [epoch: 6.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11357984905976594		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.11357984905976594 | validation: 0.15142139536846244]
	TIME [epoch: 6.49 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12081235438509338		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.12081235438509338 | validation: 0.15716286103814914]
	TIME [epoch: 6.49 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11710326716112643		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.11710326716112643 | validation: 0.14410481049451485]
	TIME [epoch: 6.48 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11628892685114742		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.11628892685114742 | validation: 0.13786023477728407]
	TIME [epoch: 6.48 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10630167619777103		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.10630167619777103 | validation: 0.1383763901275761]
	TIME [epoch: 6.48 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1066371173814997		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.1066371173814997 | validation: 0.13667907396432666]
	TIME [epoch: 6.48 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11167549162860149		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.11167549162860149 | validation: 0.13887302552346031]
	TIME [epoch: 6.51 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11329713600140759		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.11329713600140759 | validation: 0.130182279752446]
	TIME [epoch: 6.48 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11560022868053792		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.11560022868053792 | validation: 0.1384708784297958]
	TIME [epoch: 6.47 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10971283935693653		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.10971283935693653 | validation: 0.1337025598733463]
	TIME [epoch: 6.47 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10960727605867882		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.10960727605867882 | validation: 0.13694647931060508]
	TIME [epoch: 6.48 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10886415526529714		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.10886415526529714 | validation: 0.14090003768591106]
	TIME [epoch: 6.48 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11569514820734068		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.11569514820734068 | validation: 0.14443154683630374]
	TIME [epoch: 6.5 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11366715176047772		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.11366715176047772 | validation: 0.14211995883182826]
	TIME [epoch: 6.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11201548152889929		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.11201548152889929 | validation: 0.14109663341571008]
	TIME [epoch: 6.48 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11707048501298103		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.11707048501298103 | validation: 0.13863719149357429]
	TIME [epoch: 6.47 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11439983172404256		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.11439983172404256 | validation: 0.13776151036388068]
	TIME [epoch: 6.48 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11637618973158821		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.11637618973158821 | validation: 0.14897395578486075]
	TIME [epoch: 6.48 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11259074221737297		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.11259074221737297 | validation: 0.1339658079600021]
	TIME [epoch: 6.48 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10957638378510748		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.10957638378510748 | validation: 0.15314925385062367]
	TIME [epoch: 6.52 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1154511183718492		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.1154511183718492 | validation: 0.15406304948117153]
	TIME [epoch: 6.48 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11899491066202783		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.11899491066202783 | validation: 0.14936592120761838]
	TIME [epoch: 6.48 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11042902451768746		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.11042902451768746 | validation: 0.12874044777981727]
	TIME [epoch: 6.48 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11442071123540266		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.11442071123540266 | validation: 0.13509845427060208]
	TIME [epoch: 6.48 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11495825138234243		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.11495825138234243 | validation: 0.13218643376130126]
	TIME [epoch: 6.48 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1129683896181306		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.1129683896181306 | validation: 0.13240902204650165]
	TIME [epoch: 6.49 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11127942035463842		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.11127942035463842 | validation: 0.14830775204977556]
	TIME [epoch: 6.5 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1122545352589357		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.1122545352589357 | validation: 0.14781987739364202]
	TIME [epoch: 6.49 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10979472921738244		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.10979472921738244 | validation: 0.14291372871825977]
	TIME [epoch: 6.49 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10825529042726215		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.10825529042726215 | validation: 0.13753547498110977]
	TIME [epoch: 6.47 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10789042603473749		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.10789042603473749 | validation: 0.14865579330891576]
	TIME [epoch: 6.48 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11871293959126189		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.11871293959126189 | validation: 0.14210965629706995]
	TIME [epoch: 6.49 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11781423480095132		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.11781423480095132 | validation: 0.1528650881647847]
	TIME [epoch: 6.51 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1140615596482744		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.1140615596482744 | validation: 0.13623127313171948]
	TIME [epoch: 6.48 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11195868678078866		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.11195868678078866 | validation: 0.13480688126354357]
	TIME [epoch: 6.47 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11062644890150047		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.11062644890150047 | validation: 0.13250938055761505]
	TIME [epoch: 6.48 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10924488176708588		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.10924488176708588 | validation: 0.15380383365732672]
	TIME [epoch: 6.48 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11511407090774423		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.11511407090774423 | validation: 0.1516304470736817]
	TIME [epoch: 6.49 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11825943542155394		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.11825943542155394 | validation: 0.14725864746212983]
	TIME [epoch: 6.5 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11103757731900137		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.11103757731900137 | validation: 0.14968623265626993]
	TIME [epoch: 6.51 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11243953220622285		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.11243953220622285 | validation: 0.14841152259621432]
	TIME [epoch: 6.49 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11642821564909538		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.11642821564909538 | validation: 0.1440193629366903]
	TIME [epoch: 6.48 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11101352166049537		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.11101352166049537 | validation: 0.14595325231507683]
	TIME [epoch: 6.48 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11211975300763902		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.11211975300763902 | validation: 0.13454475409399821]
	TIME [epoch: 6.47 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11403868183169877		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.11403868183169877 | validation: 0.14772542123461171]
	TIME [epoch: 6.49 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12086939293660523		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.12086939293660523 | validation: 0.148756708422288]
	TIME [epoch: 6.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11619284026777735		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.11619284026777735 | validation: 0.14957732451677777]
	TIME [epoch: 6.5 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1087343061968462		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.1087343061968462 | validation: 0.1517209858386639]
	TIME [epoch: 6.47 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11385908832327149		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.11385908832327149 | validation: 0.1480955069238942]
	TIME [epoch: 6.49 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10860264788455803		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.10860264788455803 | validation: 0.13159212483701244]
	TIME [epoch: 6.47 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10981546163779102		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.10981546163779102 | validation: 0.13748165040706772]
	TIME [epoch: 6.48 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11423499153351747		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.11423499153351747 | validation: 0.13552362454172975]
	TIME [epoch: 6.48 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11165122423026942		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.11165122423026942 | validation: 0.13540278150833626]
	TIME [epoch: 6.51 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11379851740525862		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.11379851740525862 | validation: 0.1438731747918416]
	TIME [epoch: 6.48 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10615404948069283		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.10615404948069283 | validation: 0.14624248360410363]
	TIME [epoch: 6.47 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1115629525134685		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.1115629525134685 | validation: 0.14578436199760708]
	TIME [epoch: 6.48 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11958231711324423		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.11958231711324423 | validation: 0.1453485998440511]
	TIME [epoch: 6.47 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11682723259983874		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.11682723259983874 | validation: 0.1340247995669469]
	TIME [epoch: 6.48 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11428584392756642		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.11428584392756642 | validation: 0.15233832732330801]
	TIME [epoch: 6.5 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11321122222598315		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.11321122222598315 | validation: 0.15154220088056164]
	TIME [epoch: 6.48 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11666548911207417		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.11666548911207417 | validation: 0.14161747499725938]
	TIME [epoch: 6.47 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11487527837721215		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.11487527837721215 | validation: 0.13993708908996602]
	TIME [epoch: 6.47 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11594532182533004		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.11594532182533004 | validation: 0.14512655134515737]
	TIME [epoch: 6.48 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12631319754043666		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.12631319754043666 | validation: 0.14915029411705924]
	TIME [epoch: 6.47 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12195430368394661		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.12195430368394661 | validation: 0.14251521525225785]
	TIME [epoch: 6.47 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12537361725204196		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.12537361725204196 | validation: 0.15754310484365328]
	TIME [epoch: 6.5 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625823643662706		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.12625823643662706 | validation: 0.15764455153272747]
	TIME [epoch: 6.47 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1175081816705914		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.1175081816705914 | validation: 0.15668072740100233]
	TIME [epoch: 6.47 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11113373116269128		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.11113373116269128 | validation: 0.1433568198321113]
	TIME [epoch: 6.47 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10710793261450632		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.10710793261450632 | validation: 0.1382109289158587]
	TIME [epoch: 6.47 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10713992283769641		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.10713992283769641 | validation: 0.16331145595165475]
	TIME [epoch: 6.47 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11467404882557677		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.11467404882557677 | validation: 0.14918226746393443]
	TIME [epoch: 6.49 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11127190284887009		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.11127190284887009 | validation: 0.14131735955458413]
	TIME [epoch: 6.49 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11423596390522996		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.11423596390522996 | validation: 0.15222167160450617]
	TIME [epoch: 6.47 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12049734583405407		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.12049734583405407 | validation: 0.14918742632382712]
	TIME [epoch: 6.47 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12059269765577443		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.12059269765577443 | validation: 0.1371111364537377]
	TIME [epoch: 6.47 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11512097059685214		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.11512097059685214 | validation: 0.14009498528086287]
	TIME [epoch: 6.48 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11560849500596265		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.11560849500596265 | validation: 0.14126814101662158]
	TIME [epoch: 6.47 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11385583072335496		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.11385583072335496 | validation: 0.13876725094775005]
	TIME [epoch: 6.51 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11736807682765144		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.11736807682765144 | validation: 0.1431174194545341]
	TIME [epoch: 6.48 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11251803025960841		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.11251803025960841 | validation: 0.13519466042593778]
	TIME [epoch: 6.46 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11321469394944575		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.11321469394944575 | validation: 0.13091439683786618]
	TIME [epoch: 6.47 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11397738694826276		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.11397738694826276 | validation: 0.14250210296751]
	TIME [epoch: 6.47 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11950871457984322		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.11950871457984322 | validation: 0.1562666789416335]
	TIME [epoch: 6.47 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12037733799948064		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.12037733799948064 | validation: 0.15591535056987235]
	TIME [epoch: 6.5 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12077629147822551		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.12077629147822551 | validation: 0.1426014278053557]
	TIME [epoch: 6.49 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11209269751421252		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.11209269751421252 | validation: 0.1395238656731342]
	TIME [epoch: 6.47 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187258247498075		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.11187258247498075 | validation: 0.1343785811883579]
	TIME [epoch: 6.47 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11581642362639541		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.11581642362639541 | validation: 0.12171026906371542]
	TIME [epoch: 6.47 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10934914056973334		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.10934914056973334 | validation: 0.14151086227889514]
	TIME [epoch: 6.47 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11031387282117625		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.11031387282117625 | validation: 0.1415591234249591]
	TIME [epoch: 6.47 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11123140808457185		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.11123140808457185 | validation: 0.1459854752305345]
	TIME [epoch: 6.51 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11739596008978394		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.11739596008978394 | validation: 0.13682358246439166]
	TIME [epoch: 6.48 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10940138331618113		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.10940138331618113 | validation: 0.1383303128881746]
	TIME [epoch: 6.47 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11221120745353257		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.11221120745353257 | validation: 0.14363771098846084]
	TIME [epoch: 6.47 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11087603231291998		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.11087603231291998 | validation: 0.14501225057531592]
	TIME [epoch: 6.48 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11146719303300569		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.11146719303300569 | validation: 0.14134014537748502]
	TIME [epoch: 6.47 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11203009463921626		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.11203009463921626 | validation: 0.1467363220349926]
	TIME [epoch: 6.48 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10921920933831475		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.10921920933831475 | validation: 0.138535198652764]
	TIME [epoch: 6.51 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11087209977296059		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.11087209977296059 | validation: 0.14392506282022027]
	TIME [epoch: 6.48 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11044366158659835		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.11044366158659835 | validation: 0.1504845661746194]
	TIME [epoch: 6.49 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11516300003829036		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.11516300003829036 | validation: 0.1418618398588169]
	TIME [epoch: 6.49 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10627053778102123		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.10627053778102123 | validation: 0.14088774063711898]
	TIME [epoch: 6.47 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10783751741099444		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.10783751741099444 | validation: 0.14778243794111148]
	TIME [epoch: 6.47 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11078738367721523		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.11078738367721523 | validation: 0.1408486172043983]
	TIME [epoch: 6.5 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11251701888187196		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.11251701888187196 | validation: 0.14938974219646808]
	TIME [epoch: 6.49 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11631168801099863		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.11631168801099863 | validation: 0.1404560993919133]
	TIME [epoch: 6.49 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.113398281602196		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.113398281602196 | validation: 0.13521795366146805]
	TIME [epoch: 6.48 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10986439523768335		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.10986439523768335 | validation: 0.12957592293308756]
	TIME [epoch: 6.47 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1135289152008172		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.1135289152008172 | validation: 0.12985574766215485]
	TIME [epoch: 6.48 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10934695513095935		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.10934695513095935 | validation: 0.1421754427763823]
	TIME [epoch: 6.47 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11575431784011858		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.11575431784011858 | validation: 0.13445912246743238]
	TIME [epoch: 6.51 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1143990199251952		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.1143990199251952 | validation: 0.13270953875487193]
	TIME [epoch: 6.47 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11383944797229945		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.11383944797229945 | validation: 0.1376596316149655]
	TIME [epoch: 6.47 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11940002807387602		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.11940002807387602 | validation: 0.1305934710867972]
	TIME [epoch: 6.47 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11721605214683195		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.11721605214683195 | validation: 0.14311348676056565]
	TIME [epoch: 6.47 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11081018034656417		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.11081018034656417 | validation: 0.1386416062994027]
	TIME [epoch: 6.47 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11138369610526501		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.11138369610526501 | validation: 0.14126211379074458]
	TIME [epoch: 6.49 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.116520907227158		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.116520907227158 | validation: 0.14735920748067255]
	TIME [epoch: 6.49 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12194406711216567		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.12194406711216567 | validation: 0.1400188027359317]
	TIME [epoch: 6.48 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11220966884566616		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.11220966884566616 | validation: 0.1346605377806083]
	TIME [epoch: 6.48 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11532916730320567		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.11532916730320567 | validation: 0.1487772715502085]
	TIME [epoch: 6.47 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11834472808494409		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.11834472808494409 | validation: 0.14406910070396817]
	TIME [epoch: 6.48 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11385097123425303		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.11385097123425303 | validation: 0.14449221476839835]
	TIME [epoch: 6.48 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11189200079376575		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.11189200079376575 | validation: 0.13429314360566677]
	TIME [epoch: 6.52 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11451845628026341		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.11451845628026341 | validation: 0.1411495225042081]
	TIME [epoch: 6.49 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10639819416518169		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.10639819416518169 | validation: 0.13503322152402622]
	TIME [epoch: 6.49 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1127925992037086		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.1127925992037086 | validation: 0.14421836820674855]
	TIME [epoch: 6.47 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10957157585421787		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.10957157585421787 | validation: 0.14146603756571666]
	TIME [epoch: 6.47 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11439178775534431		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.11439178775534431 | validation: 0.14898822268969103]
	TIME [epoch: 6.47 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11527451805433925		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.11527451805433925 | validation: 0.14696039807643574]
	TIME [epoch: 6.49 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11515780475511384		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.11515780475511384 | validation: 0.13365792854707922]
	TIME [epoch: 6.49 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11243537080659396		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.11243537080659396 | validation: 0.1363927821772226]
	TIME [epoch: 6.48 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11383546577846221		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.11383546577846221 | validation: 0.14834127017911894]
	TIME [epoch: 6.47 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12033456910535568		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.12033456910535568 | validation: 0.14128130696183916]
	TIME [epoch: 6.47 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11405938708478437		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.11405938708478437 | validation: 0.13515499092322458]
	TIME [epoch: 6.47 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11051535855216693		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.11051535855216693 | validation: 0.1445658266481296]
	TIME [epoch: 6.47 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11597162043040256		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.11597162043040256 | validation: 0.14418189638104825]
	TIME [epoch: 6.51 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11659891264318241		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.11659891264318241 | validation: 0.13395759652464534]
	TIME [epoch: 6.48 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1130981106742234		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.1130981106742234 | validation: 0.1266614840718465]
	TIME [epoch: 6.47 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1193259014626572		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.1193259014626572 | validation: 0.1378336130415158]
	TIME [epoch: 6.48 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1162877179660608		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.1162877179660608 | validation: 0.12292449235619754]
	TIME [epoch: 6.47 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11286487392842615		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.11286487392842615 | validation: 0.13396786355971194]
	TIME [epoch: 6.47 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11862975337983127		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.11862975337983127 | validation: 0.13830928007019666]
	TIME [epoch: 6.49 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1169680889571472		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.1169680889571472 | validation: 0.1392382793984329]
	TIME [epoch: 6.52 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12131730673828381		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.12131730673828381 | validation: 0.13180215284801058]
	TIME [epoch: 6.48 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.115898412388499		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.115898412388499 | validation: 0.13651493494899256]
	TIME [epoch: 6.48 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1140598724303479		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.1140598724303479 | validation: 0.13255908120035811]
	TIME [epoch: 6.49 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11419540020712901		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.11419540020712901 | validation: 0.13864904933531136]
	TIME [epoch: 6.49 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11701699298669603		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.11701699298669603 | validation: 0.14238478326005907]
	TIME [epoch: 6.48 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11166999258527761		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.11166999258527761 | validation: 0.1533827416388804]
	TIME [epoch: 6.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11674900454851352		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.11674900454851352 | validation: 0.14261995929072488]
	TIME [epoch: 6.47 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11785398964465452		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.11785398964465452 | validation: 0.14203744824083422]
	TIME [epoch: 6.49 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11291384697923033		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.11291384697923033 | validation: 0.1331823945070862]
	TIME [epoch: 6.48 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11227672617785386		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.11227672617785386 | validation: 0.13748193589719923]
	TIME [epoch: 6.49 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11022408605181494		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.11022408605181494 | validation: 0.14291203839253064]
	TIME [epoch: 6.48 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11253989518280727		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.11253989518280727 | validation: 0.13476935915356605]
	TIME [epoch: 6.49 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10871672290205345		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.10871672290205345 | validation: 0.13318579796119057]
	TIME [epoch: 6.52 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10945185933916951		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.10945185933916951 | validation: 0.14092174243195016]
	TIME [epoch: 6.48 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1095905157187813		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.1095905157187813 | validation: 0.13841083406806307]
	TIME [epoch: 6.48 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11049689870608684		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.11049689870608684 | validation: 0.13677686328116775]
	TIME [epoch: 6.48 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11248103604794257		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.11248103604794257 | validation: 0.14080700526216647]
	TIME [epoch: 6.48 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11177599997838117		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.11177599997838117 | validation: 0.14165162631133468]
	TIME [epoch: 6.48 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11730353540098139		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.11730353540098139 | validation: 0.15253683813380917]
	TIME [epoch: 6.51 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11198297912302152		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.11198297912302152 | validation: 0.13765167614847976]
	TIME [epoch: 6.51 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1137876632378171		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.1137876632378171 | validation: 0.14206029066745046]
	TIME [epoch: 6.49 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11362885586122888		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.11362885586122888 | validation: 0.13575664767151524]
	TIME [epoch: 6.49 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11227552171954511		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.11227552171954511 | validation: 0.1348091362449297]
	TIME [epoch: 6.48 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1191864406381854		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.1191864406381854 | validation: 0.13519794882726927]
	TIME [epoch: 6.48 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11393065554963658		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.11393065554963658 | validation: 0.13106062109179115]
	TIME [epoch: 6.48 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11446589573462067		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.11446589573462067 | validation: 0.13403615714750441]
	TIME [epoch: 6.52 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11583120305615117		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.11583120305615117 | validation: 0.13723089799340726]
	TIME [epoch: 6.49 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11921720913113464		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.11921720913113464 | validation: 0.14376821152486305]
	TIME [epoch: 6.48 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11365201240884447		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.11365201240884447 | validation: 0.14117145587937865]
	TIME [epoch: 6.49 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11198474364778194		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.11198474364778194 | validation: 0.12408970452909149]
	TIME [epoch: 6.48 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11356880241013896		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.11356880241013896 | validation: 0.1365997744074417]
	TIME [epoch: 6.48 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11166703737082392		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.11166703737082392 | validation: 0.14012443269296956]
	TIME [epoch: 6.5 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11163347059990764		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.11163347059990764 | validation: 0.13322868529541576]
	TIME [epoch: 6.51 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10912448786366966		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.10912448786366966 | validation: 0.1399993025140528]
	TIME [epoch: 6.49 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1103556693679649		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.1103556693679649 | validation: 0.13928781779691027]
	TIME [epoch: 6.48 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11057488473660435		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.11057488473660435 | validation: 0.13648126786474055]
	TIME [epoch: 6.48 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11162683843984532		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.11162683843984532 | validation: 0.1420608405869523]
	TIME [epoch: 6.48 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10338745816215987		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.10338745816215987 | validation: 0.14061533577769386]
	TIME [epoch: 6.48 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10734567531909012		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.10734567531909012 | validation: 0.14216500180389283]
	TIME [epoch: 6.52 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11152124754027305		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.11152124754027305 | validation: 0.13195663388461212]
	TIME [epoch: 6.48 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10938120713103028		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.10938120713103028 | validation: 0.13790397108060837]
	TIME [epoch: 6.49 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10984141244110371		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.10984141244110371 | validation: 0.13752171632305157]
	TIME [epoch: 6.47 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10300104257749584		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.10300104257749584 | validation: 0.13710750939739277]
	TIME [epoch: 6.47 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10417226413442102		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.10417226413442102 | validation: 0.13538672173500657]
	TIME [epoch: 6.46 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11204610990031001		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.11204610990031001 | validation: 0.13620313964868008]
	TIME [epoch: 6.48 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10756133254981233		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.10756133254981233 | validation: 0.13945034954451865]
	TIME [epoch: 6.5 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10818368894920861		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.10818368894920861 | validation: 0.1416900025099473]
	TIME [epoch: 6.49 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11252638511084864		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.11252638511084864 | validation: 0.12970727377851246]
	TIME [epoch: 6.49 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11029216320514662		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.11029216320514662 | validation: 0.1364173645582632]
	TIME [epoch: 6.46 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11247824706890888		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.11247824706890888 | validation: 0.13605254696301863]
	TIME [epoch: 6.47 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10883060566552498		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.10883060566552498 | validation: 0.13636943047262845]
	TIME [epoch: 6.49 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10776098791833189		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.10776098791833189 | validation: 0.14198291247702216]
	TIME [epoch: 6.51 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1162169761170445		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.1162169761170445 | validation: 0.14252527482170863]
	TIME [epoch: 6.47 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11488913902231784		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.11488913902231784 | validation: 0.14015565183200868]
	TIME [epoch: 6.47 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11364290058891172		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.11364290058891172 | validation: 0.14350341512401923]
	TIME [epoch: 6.48 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11129914214371542		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.11129914214371542 | validation: 0.14850785701263758]
	TIME [epoch: 6.47 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11117549692844785		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.11117549692844785 | validation: 0.14105936817618098]
	TIME [epoch: 6.47 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11089890436864196		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.11089890436864196 | validation: 0.13674386730366664]
	TIME [epoch: 6.47 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11131339910467136		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.11131339910467136 | validation: 0.14388067012329223]
	TIME [epoch: 6.5 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10824536192057793		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.10824536192057793 | validation: 0.1498375987987864]
	TIME [epoch: 6.47 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10721066069361158		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.10721066069361158 | validation: 0.15323932464191173]
	TIME [epoch: 6.46 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11184157334707923		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.11184157334707923 | validation: 0.13980870266578155]
	TIME [epoch: 6.47 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10679903879184174		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.10679903879184174 | validation: 0.1456034826811446]
	TIME [epoch: 6.46 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11231134763621706		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.11231134763621706 | validation: 0.1449345104598908]
	TIME [epoch: 6.47 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11482433090167142		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.11482433090167142 | validation: 0.13200120735465956]
	TIME [epoch: 6.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10809250258649532		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.10809250258649532 | validation: 0.1507192315358608]
	TIME [epoch: 6.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10863937426733397		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.10863937426733397 | validation: 0.1424304325703292]
	TIME [epoch: 6.47 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1083479180444475		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.1083479180444475 | validation: 0.1413618792841001]
	TIME [epoch: 6.47 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11114734468370083		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.11114734468370083 | validation: 0.1333179006658179]
	TIME [epoch: 6.46 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11204773660803156		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.11204773660803156 | validation: 0.1384729101240167]
	TIME [epoch: 6.47 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.100529501234866		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.100529501234866 | validation: 0.13346023036806448]
	TIME [epoch: 6.49 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10867088661226977		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.10867088661226977 | validation: 0.1346511123789213]
	TIME [epoch: 6.52 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1119636566184725		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.1119636566184725 | validation: 0.13412668148939136]
	TIME [epoch: 6.48 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11330948785537207		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.11330948785537207 | validation: 0.13275640978198816]
	TIME [epoch: 6.48 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11393957368414133		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.11393957368414133 | validation: 0.1369185371746828]
	TIME [epoch: 6.47 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11717661252104505		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.11717661252104505 | validation: 0.1370598407467317]
	TIME [epoch: 6.47 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11055127365321105		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.11055127365321105 | validation: 0.1330454816145042]
	TIME [epoch: 6.49 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11134748525276046		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.11134748525276046 | validation: 0.13124021499815136]
	TIME [epoch: 6.49 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10919891841584868		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.10919891841584868 | validation: 0.12839680391696356]
	TIME [epoch: 6.49 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10763387527722408		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.10763387527722408 | validation: 0.14068759328999178]
	TIME [epoch: 6.47 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090395391695738		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.1090395391695738 | validation: 0.1277886380294809]
	TIME [epoch: 6.47 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10726357540211606		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.10726357540211606 | validation: 0.13359218420879182]
	TIME [epoch: 6.47 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.110786340703659		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.110786340703659 | validation: 0.12994886985286752]
	TIME [epoch: 6.47 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1054398358156868		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.1054398358156868 | validation: 0.1353450575302658]
	TIME [epoch: 6.47 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10873373127626257		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.10873373127626257 | validation: 0.1346878195073925]
	TIME [epoch: 6.53 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10650571746387283		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.10650571746387283 | validation: 0.1330841499905705]
	TIME [epoch: 6.49 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1126354711179789		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.1126354711179789 | validation: 0.12888191383769815]
	TIME [epoch: 6.47 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11381244895946113		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.11381244895946113 | validation: 0.141595908148799]
	TIME [epoch: 6.47 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10929231512371387		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.10929231512371387 | validation: 0.14209245281085164]
	TIME [epoch: 6.47 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11038371043631097		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.11038371043631097 | validation: 0.1447847731991365]
	TIME [epoch: 6.47 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060800013186271		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.1060800013186271 | validation: 0.1379328061548079]
	TIME [epoch: 6.48 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11014778225123406		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.11014778225123406 | validation: 0.13072608224601304]
	TIME [epoch: 6.49 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11076197166773195		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.11076197166773195 | validation: 0.13629282603255888]
	TIME [epoch: 6.47 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11045942231847183		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.11045942231847183 | validation: 0.14358170606404405]
	TIME [epoch: 6.47 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11139005312407793		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.11139005312407793 | validation: 0.133832233600249]
	TIME [epoch: 6.48 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11193591401372187		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.11193591401372187 | validation: 0.1450340440346254]
	TIME [epoch: 6.48 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11376807780585019		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.11376807780585019 | validation: 0.13615771189906142]
	TIME [epoch: 6.48 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1106381932633906		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.1106381932633906 | validation: 0.14017398706430897]
	TIME [epoch: 6.51 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10864371386177603		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.10864371386177603 | validation: 0.13581611849736913]
	TIME [epoch: 6.49 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11278265755464664		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.11278265755464664 | validation: 0.14268639911791012]
	TIME [epoch: 6.48 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11370779231901047		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.11370779231901047 | validation: 0.14157700996986863]
	TIME [epoch: 6.48 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11066177915345862		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.11066177915345862 | validation: 0.1426597894098965]
	TIME [epoch: 6.48 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11001740170573851		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.11001740170573851 | validation: 0.1410375641855802]
	TIME [epoch: 6.47 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11013724509218212		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.11013724509218212 | validation: 0.1273647075396415]
	TIME [epoch: 6.48 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10845411615123965		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.10845411615123965 | validation: 0.1325022169448872]
	TIME [epoch: 6.52 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11080835980239459		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.11080835980239459 | validation: 0.1481704102430261]
	TIME [epoch: 6.48 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11054457044462793		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.11054457044462793 | validation: 0.13466230039615582]
	TIME [epoch: 6.47 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11347451179848622		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.11347451179848622 | validation: 0.14384409596140685]
	TIME [epoch: 6.47 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11177808284079957		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.11177808284079957 | validation: 0.143293084667953]
	TIME [epoch: 6.48 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11501844219264772		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.11501844219264772 | validation: 0.14170578388088512]
	TIME [epoch: 6.47 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11391527693798134		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.11391527693798134 | validation: 0.1438862423607176]
	TIME [epoch: 6.52 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11524949428559866		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.11524949428559866 | validation: 0.15640096344782625]
	TIME [epoch: 6.49 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11585655617818949		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.11585655617818949 | validation: 0.14049669756006503]
	TIME [epoch: 6.49 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11879225379855156		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.11879225379855156 | validation: 0.14450647372823816]
	TIME [epoch: 6.48 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1149795075280122		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.1149795075280122 | validation: 0.15010969497926513]
	TIME [epoch: 6.49 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1206079662852112		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.1206079662852112 | validation: 0.13676393545503893]
	TIME [epoch: 6.48 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11232504138146973		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.11232504138146973 | validation: 0.1401084442212854]
	TIME [epoch: 6.49 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1117329903640725		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.1117329903640725 | validation: 0.1438193371983487]
	TIME [epoch: 6.51 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10814558265723617		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.10814558265723617 | validation: 0.1436219828971419]
	TIME [epoch: 6.48 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10772553173395802		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.10772553173395802 | validation: 0.13425002282623133]
	TIME [epoch: 6.47 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11157033237239955		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.11157033237239955 | validation: 0.14209307996485207]
	TIME [epoch: 6.47 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11161960581863527		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.11161960581863527 | validation: 0.1398917133477815]
	TIME [epoch: 6.49 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10775561698508408		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.10775561698508408 | validation: 0.14123463614349185]
	TIME [epoch: 6.47 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10901370649720481		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.10901370649720481 | validation: 0.14306796338511682]
	TIME [epoch: 6.48 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10993704565314255		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.10993704565314255 | validation: 0.1387846260783174]
	TIME [epoch: 6.51 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10910913915723264		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.10910913915723264 | validation: 0.14720292279935707]
	TIME [epoch: 6.47 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187715519222124		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.11187715519222124 | validation: 0.14359872477995073]
	TIME [epoch: 6.49 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1096174051053953		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.1096174051053953 | validation: 0.14857014130869833]
	TIME [epoch: 6.48 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10657987395427589		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.10657987395427589 | validation: 0.14499576144913298]
	TIME [epoch: 6.48 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11759252479677199		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.11759252479677199 | validation: 0.14317084029161858]
	TIME [epoch: 6.47 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11662129762993259		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.11662129762993259 | validation: 0.13413833651691315]
	TIME [epoch: 6.51 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11128590422307784		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.11128590422307784 | validation: 0.13787141663474897]
	TIME [epoch: 6.49 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10509960394649234		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.10509960394649234 | validation: 0.1389076110158042]
	TIME [epoch: 6.48 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10727956184990856		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.10727956184990856 | validation: 0.14166462885559722]
	TIME [epoch: 6.46 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1127298251935529		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.1127298251935529 | validation: 0.13189140328903284]
	TIME [epoch: 6.48 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11235284740478754		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.11235284740478754 | validation: 0.14055856980580705]
	TIME [epoch: 6.47 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11203043998752006		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.11203043998752006 | validation: 0.14319271575081535]
	TIME [epoch: 6.5 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11258693786627892		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.11258693786627892 | validation: 0.1304075532682019]
	TIME [epoch: 6.49 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11082886039119597		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.11082886039119597 | validation: 0.14157215545882082]
	TIME [epoch: 6.49 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10530843149092974		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.10530843149092974 | validation: 0.14580265808240483]
	TIME [epoch: 6.48 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11007534359821228		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.11007534359821228 | validation: 0.1413803150784268]
	TIME [epoch: 6.47 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11235495398856467		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.11235495398856467 | validation: 0.1442938392083901]
	TIME [epoch: 6.47 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10801154339913951		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.10801154339913951 | validation: 0.1416673583019917]
	TIME [epoch: 6.47 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11160234588084317		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.11160234588084317 | validation: 0.14432473833261936]
	TIME [epoch: 6.52 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.109316778797315		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.109316778797315 | validation: 0.14162354124524063]
	TIME [epoch: 6.48 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11200234119478572		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.11200234119478572 | validation: 0.14403875325221888]
	TIME [epoch: 6.49 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10966574615510541		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.10966574615510541 | validation: 0.14798389600247683]
	TIME [epoch: 6.47 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1122082351052594		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.1122082351052594 | validation: 0.13918385735956393]
	TIME [epoch: 6.48 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110764853406836		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.1110764853406836 | validation: 0.13238553643348247]
	TIME [epoch: 6.47 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11146415252337945		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.11146415252337945 | validation: 0.13632348351804133]
	TIME [epoch: 6.49 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11065927663607333		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.11065927663607333 | validation: 0.1376798774131093]
	TIME [epoch: 6.52 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11381788532639156		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.11381788532639156 | validation: 0.1397034722653061]
	TIME [epoch: 6.48 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11122476928799027		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.11122476928799027 | validation: 0.1255142686430794]
	TIME [epoch: 6.48 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11252102050332018		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.11252102050332018 | validation: 0.13204969987457157]
	TIME [epoch: 6.48 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1110885785513015		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.1110885785513015 | validation: 0.13836085059968833]
	TIME [epoch: 6.48 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10900005450549252		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.10900005450549252 | validation: 0.12940924472787857]
	TIME [epoch: 6.48 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11118457666775966		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.11118457666775966 | validation: 0.1327892541890531]
	TIME [epoch: 6.52 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11414897975401381		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.11414897975401381 | validation: 0.132061310367146]
	TIME [epoch: 6.48 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11124563104963553		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.11124563104963553 | validation: 0.14675118142525098]
	TIME [epoch: 6.49 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11131307083789249		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.11131307083789249 | validation: 0.13795231151815748]
	TIME [epoch: 6.49 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10628103078629238		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.10628103078629238 | validation: 0.1363587634523449]
	TIME [epoch: 6.47 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11319230182826967		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.11319230182826967 | validation: 0.14367133242640143]
	TIME [epoch: 6.48 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11121966188400567		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.11121966188400567 | validation: 0.13382614113047342]
	TIME [epoch: 6.48 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10913092658492608		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.10913092658492608 | validation: 0.14119444928482766]
	TIME [epoch: 6.51 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1078926885218286		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.1078926885218286 | validation: 0.13184878727137547]
	TIME [epoch: 6.48 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11301322321320839		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.11301322321320839 | validation: 0.1485982833736844]
	TIME [epoch: 6.47 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11027518817494068		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.11027518817494068 | validation: 0.14057974750889474]
	TIME [epoch: 6.47 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11034527516171475		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.11034527516171475 | validation: 0.14370177140681703]
	TIME [epoch: 6.48 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1079261638205691		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.1079261638205691 | validation: 0.14134035653501548]
	TIME [epoch: 6.47 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11234084110699064		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.11234084110699064 | validation: 0.1376769206153516]
	TIME [epoch: 6.51 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.108454395291607		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.108454395291607 | validation: 0.14021852591064507]
	TIME [epoch: 6.48 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10681572943820727		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.10681572943820727 | validation: 0.14913693207189757]
	TIME [epoch: 6.47 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11109058648980527		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.11109058648980527 | validation: 0.14252656391226376]
	TIME [epoch: 6.47 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10548329757517125		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.10548329757517125 | validation: 0.14289618926228603]
	TIME [epoch: 6.47 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10998811536649312		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.10998811536649312 | validation: 0.13966269562417502]
	TIME [epoch: 6.47 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10945485590796339		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.10945485590796339 | validation: 0.14122218317784613]
	TIME [epoch: 6.48 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10730737128967391		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.10730737128967391 | validation: 0.1318406082560954]
	TIME [epoch: 6.51 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11031564961340462		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.11031564961340462 | validation: 0.14240628264219307]
	TIME [epoch: 6.47 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10562280086932094		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.10562280086932094 | validation: 0.1394445797140373]
	TIME [epoch: 6.47 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10425901430497095		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.10425901430497095 | validation: 0.14369372751660228]
	TIME [epoch: 6.47 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10949438132053346		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.10949438132053346 | validation: 0.1397621578133425]
	TIME [epoch: 6.48 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11155821985287766		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.11155821985287766 | validation: 0.14009367284859442]
	TIME [epoch: 6.48 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060313358788784		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.1060313358788784 | validation: 0.14892303687699715]
	TIME [epoch: 6.49 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10463159789084013		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.10463159789084013 | validation: 0.1363502675491136]
	TIME [epoch: 6.49 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10583862386217681		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.10583862386217681 | validation: 0.13626435598628192]
	TIME [epoch: 6.49 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10627006303922577		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.10627006303922577 | validation: 0.1324552510859968]
	TIME [epoch: 6.47 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10895029391580438		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.10895029391580438 | validation: 0.13537910859768476]
	TIME [epoch: 6.46 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10750643758556297		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.10750643758556297 | validation: 0.13041246918232102]
	TIME [epoch: 6.48 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10640476703813914		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.10640476703813914 | validation: 0.1275453184795665]
	TIME [epoch: 6.47 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10902906811493379		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.10902906811493379 | validation: 0.1400152686910827]
	TIME [epoch: 6.52 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10600608371885363		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.10600608371885363 | validation: 0.13737875592244675]
	TIME [epoch: 6.47 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11086376368775874		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.11086376368775874 | validation: 0.13962307441231597]
	TIME [epoch: 6.48 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10709132316855959		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.10709132316855959 | validation: 0.13863309596125428]
	TIME [epoch: 6.46 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064427863080702		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.11064427863080702 | validation: 0.13920202707125978]
	TIME [epoch: 6.48 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09977848376700696		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.09977848376700696 | validation: 0.1379475682391377]
	TIME [epoch: 6.47 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1070760205959063		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.1070760205959063 | validation: 0.13639665976691917]
	TIME [epoch: 6.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10688047655839436		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.10688047655839436 | validation: 0.13897932931310852]
	TIME [epoch: 6.49 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11009169770329058		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.11009169770329058 | validation: 0.14229287348149744]
	TIME [epoch: 6.48 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10735720140411997		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.10735720140411997 | validation: 0.1421741061544029]
	TIME [epoch: 6.47 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11355248370807744		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.11355248370807744 | validation: 0.1478468158626259]
	TIME [epoch: 6.48 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1132241641272333		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.1132241641272333 | validation: 0.15229248289590427]
	TIME [epoch: 6.47 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11550521856632968		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.11550521856632968 | validation: 0.15018553405558124]
	TIME [epoch: 6.48 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11002147811441393		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.11002147811441393 | validation: 0.13844833515513472]
	TIME [epoch: 6.5 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11262222814272338		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.11262222814272338 | validation: 0.14549605090741052]
	TIME [epoch: 6.49 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11188761029613652		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.11188761029613652 | validation: 0.15032625906219665]
	TIME [epoch: 6.47 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11234467356245693		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.11234467356245693 | validation: 0.15190729548100115]
	TIME [epoch: 6.49 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10983639248215712		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.10983639248215712 | validation: 0.14336360748271512]
	TIME [epoch: 6.47 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11334624725922313		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.11334624725922313 | validation: 0.1423401745937061]
	TIME [epoch: 6.49 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1089664675889223		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.1089664675889223 | validation: 0.14146567347146208]
	TIME [epoch: 6.47 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064664500956403		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.11064664500956403 | validation: 0.14206882513848293]
	TIME [epoch: 6.52 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1126041986991165		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.1126041986991165 | validation: 0.14356705213540374]
	TIME [epoch: 6.49 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10670404023601575		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.10670404023601575 | validation: 0.14536596545232439]
	TIME [epoch: 6.49 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11150697651614098		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.11150697651614098 | validation: 0.13984996415394643]
	TIME [epoch: 6.48 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11092590096847703		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.11092590096847703 | validation: 0.1387685961944359]
	TIME [epoch: 6.48 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11017799962467552		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.11017799962467552 | validation: 0.13780644907071019]
	TIME [epoch: 6.45 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11387512103080545		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.11387512103080545 | validation: 0.15195167834275453]
	TIME [epoch: 6.5 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11634886367846123		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.11634886367846123 | validation: 0.14172178514895684]
	TIME [epoch: 6.47 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10889037313482372		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.10889037313482372 | validation: 0.14610065599289362]
	TIME [epoch: 6.46 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11011183338651785		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.11011183338651785 | validation: 0.14275997552499656]
	TIME [epoch: 6.45 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10955368712864985		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.10955368712864985 | validation: 0.1439096359048754]
	TIME [epoch: 6.46 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11064386314808808		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.11064386314808808 | validation: 0.1470695576398342]
	TIME [epoch: 6.45 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10983375074901836		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.10983375074901836 | validation: 0.14514503039112825]
	TIME [epoch: 6.46 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11201020178505963		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.11201020178505963 | validation: 0.15226662173237354]
	TIME [epoch: 6.48 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11000964918955987		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.11000964918955987 | validation: 0.14451455151252895]
	TIME [epoch: 6.47 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1108328482319665		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.1108328482319665 | validation: 0.15025738054828983]
	TIME [epoch: 6.44 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10810325095816474		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.10810325095816474 | validation: 0.13789812570965118]
	TIME [epoch: 6.46 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10921643137005498		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.10921643137005498 | validation: 0.1385040001872783]
	TIME [epoch: 6.45 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11045710368068677		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.11045710368068677 | validation: 0.14168779256748423]
	TIME [epoch: 6.47 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11093440846913744		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.11093440846913744 | validation: 0.14471861575221115]
	TIME [epoch: 6.47 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10411913559156993		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.10411913559156993 | validation: 0.14110377997631635]
	TIME [epoch: 6.49 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1071921126772604		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.1071921126772604 | validation: 0.136436038832054]
	TIME [epoch: 6.45 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11187318252042494		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.11187318252042494 | validation: 0.13599369943735085]
	TIME [epoch: 6.48 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10494464929775796		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.10494464929775796 | validation: 0.1443561327391049]
	TIME [epoch: 6.46 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11022729059280931		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.11022729059280931 | validation: 0.13652033138104913]
	TIME [epoch: 6.48 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10878306615587324		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.10878306615587324 | validation: 0.134309973669243]
	TIME [epoch: 6.46 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11023632726049351		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.11023632726049351 | validation: 0.13612342951221557]
	TIME [epoch: 6.52 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1084695357904778		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.1084695357904778 | validation: 0.14461822332155058]
	TIME [epoch: 6.47 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10766630387709711		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.10766630387709711 | validation: 0.1331047312591447]
	TIME [epoch: 6.49 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1039118580989799		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.1039118580989799 | validation: 0.13535962112916325]
	TIME [epoch: 6.47 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10443432022455486		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.10443432022455486 | validation: 0.13587324612545568]
	TIME [epoch: 6.49 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10595258059813306		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.10595258059813306 | validation: 0.1421762382826114]
	TIME [epoch: 6.49 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10161878223312518		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.10161878223312518 | validation: 0.13255746659899062]
	TIME [epoch: 6.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10978780403058155		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.10978780403058155 | validation: 0.13135944798246255]
	TIME [epoch: 6.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10869670991172975		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.10869670991172975 | validation: 0.14493623311609702]
	TIME [epoch: 6.49 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10355426334952456		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.10355426334952456 | validation: 0.13132177470492842]
	TIME [epoch: 6.47 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10974316252195529		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.10974316252195529 | validation: 0.14280108273771347]
	TIME [epoch: 6.48 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10526790790784515		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.10526790790784515 | validation: 0.13329625181245472]
	TIME [epoch: 6.46 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10886525404886267		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.10886525404886267 | validation: 0.13271257043608384]
	TIME [epoch: 6.49 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10742488696132504		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.10742488696132504 | validation: 0.14073159094586113]
	TIME [epoch: 6.51 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10716747144141917		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.10716747144141917 | validation: 0.12599026684371373]
	TIME [epoch: 6.49 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11005782462770047		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.11005782462770047 | validation: 0.13325000631916975]
	TIME [epoch: 6.48 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1085669627482635		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.1085669627482635 | validation: 0.1409304460258057]
	TIME [epoch: 6.47 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10771795811508911		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.10771795811508911 | validation: 0.1451190536856574]
	TIME [epoch: 6.49 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10333256425337327		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.10333256425337327 | validation: 0.1380468454317199]
	TIME [epoch: 6.47 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10578731233647311		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.10578731233647311 | validation: 0.14147002145732293]
	TIME [epoch: 6.48 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10305116019237395		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.10305116019237395 | validation: 0.15222817375517944]
	TIME [epoch: 6.52 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11058310362289833		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.11058310362289833 | validation: 0.14574621671287577]
	TIME [epoch: 6.49 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10953895637207411		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.10953895637207411 | validation: 0.1296166467876355]
	TIME [epoch: 6.48 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10768351191377593		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.10768351191377593 | validation: 0.14888776005326315]
	TIME [epoch: 6.49 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10874100038547634		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.10874100038547634 | validation: 0.13936293700479851]
	TIME [epoch: 6.46 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10647646943070586		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.10647646943070586 | validation: 0.1441288419687163]
	TIME [epoch: 6.48 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1084867028054498		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.1084867028054498 | validation: 0.14166724066343536]
	TIME [epoch: 6.5 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1083729068276326		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.1083729068276326 | validation: 0.1462112230663701]
	TIME [epoch: 6.49 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10969641775959804		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.10969641775959804 | validation: 0.133458341629161]
	TIME [epoch: 6.46 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1087015812922392		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.1087015812922392 | validation: 0.13765760390409434]
	TIME [epoch: 6.48 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1072459630813587		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.1072459630813587 | validation: 0.13767407120245245]
	TIME [epoch: 6.46 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077498687456133		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.1077498687456133 | validation: 0.13195215550354866]
	TIME [epoch: 6.48 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10871286449675278		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.10871286449675278 | validation: 0.14285014728443637]
	TIME [epoch: 6.48 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1059163162834147		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.1059163162834147 | validation: 0.1404726298275522]
	TIME [epoch: 6.51 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10591026817028916		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.10591026817028916 | validation: 0.13450009700326135]
	TIME [epoch: 6.47 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11003943867633195		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.11003943867633195 | validation: 0.1322866606887678]
	TIME [epoch: 6.46 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10561723093472082		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.10561723093472082 | validation: 0.131925422717307]
	TIME [epoch: 6.48 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10254829785140897		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.10254829785140897 | validation: 0.12953684391707415]
	TIME [epoch: 6.48 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573292855788281		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.10573292855788281 | validation: 0.12980037189036747]
	TIME [epoch: 6.46 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10980458716446874		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.10980458716446874 | validation: 0.12755891217926416]
	TIME [epoch: 6.48 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10771439310012036		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.10771439310012036 | validation: 0.13427524063281301]
	TIME [epoch: 6.48 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1094677183019093		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.1094677183019093 | validation: 0.1414270545181106]
	TIME [epoch: 6.47 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10849542891620378		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.10849542891620378 | validation: 0.1421699423991851]
	TIME [epoch: 6.48 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10347199651827593		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.10347199651827593 | validation: 0.13305895208257185]
	TIME [epoch: 6.48 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10825380662355005		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.10825380662355005 | validation: 0.13897464754898256]
	TIME [epoch: 6.46 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10195858233177758		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.10195858233177758 | validation: 0.14183410850583175]
	TIME [epoch: 6.48 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10567649280226434		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.10567649280226434 | validation: 0.14582625980617547]
	TIME [epoch: 6.52 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1096367617068846		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.1096367617068846 | validation: 0.13302290097455388]
	TIME [epoch: 6.48 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167372720925373		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.10167372720925373 | validation: 0.14104240695944265]
	TIME [epoch: 6.47 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10889171505640476		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.10889171505640476 | validation: 0.12606290950500998]
	TIME [epoch: 6.48 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10195180864933603		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.10195180864933603 | validation: 0.1461207509116477]
	TIME [epoch: 6.48 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10706478103720436		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.10706478103720436 | validation: 0.13312365450370642]
	TIME [epoch: 6.46 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1018819693286738		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.1018819693286738 | validation: 0.14148484564648406]
	TIME [epoch: 6.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10584520123571933		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.10584520123571933 | validation: 0.1387164376749393]
	TIME [epoch: 6.49 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10406596372026342		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.10406596372026342 | validation: 0.14586935523402986]
	TIME [epoch: 6.48 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10788729735836816		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.10788729735836816 | validation: 0.13957002664238316]
	TIME [epoch: 6.47 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10526354446868921		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.10526354446868921 | validation: 0.1337361191170082]
	TIME [epoch: 6.48 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10834742136012095		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.10834742136012095 | validation: 0.1436654582406901]
	TIME [epoch: 6.48 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10663360932610398		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.10663360932610398 | validation: 0.13742499203368977]
	TIME [epoch: 6.48 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10845361102991188		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.10845361102991188 | validation: 0.1462153922060761]
	TIME [epoch: 6.52 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10777695181739733		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.10777695181739733 | validation: 0.1473598473753981]
	TIME [epoch: 6.48 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049210197207416		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.1049210197207416 | validation: 0.14272803598697156]
	TIME [epoch: 6.46 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10618619155512687		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.10618619155512687 | validation: 0.14714698151618213]
	TIME [epoch: 6.48 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10879191892366695		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.10879191892366695 | validation: 0.14197565774900248]
	TIME [epoch: 6.48 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1053694914148988		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.1053694914148988 | validation: 0.1339148867517823]
	TIME [epoch: 6.47 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10542753438967331		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.10542753438967331 | validation: 0.1462579355267923]
	TIME [epoch: 6.49 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10851152284922017		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.10851152284922017 | validation: 0.13650294405687055]
	TIME [epoch: 6.51 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1038555169557103		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.1038555169557103 | validation: 0.13811812424231448]
	TIME [epoch: 6.49 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10741827279108265		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.10741827279108265 | validation: 0.1490383830153758]
	TIME [epoch: 6.47 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10657801496076769		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.10657801496076769 | validation: 0.1359003594686611]
	TIME [epoch: 6.49 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10320663413408776		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.10320663413408776 | validation: 0.137898407126027]
	TIME [epoch: 6.48 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10651827513631829		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.10651827513631829 | validation: 0.14283981395902134]
	TIME [epoch: 6.49 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1004031478644652		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.1004031478644652 | validation: 0.13644124824649226]
	TIME [epoch: 6.52 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317643482138916		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.10317643482138916 | validation: 0.1376793913690913]
	TIME [epoch: 6.5 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10394128778936901		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.10394128778936901 | validation: 0.13808708762366623]
	TIME [epoch: 6.49 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10992203953307744		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.10992203953307744 | validation: 0.13589570147873173]
	TIME [epoch: 6.49 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10867933542641219		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.10867933542641219 | validation: 0.13832863883971866]
	TIME [epoch: 6.48 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10440045484896143		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.10440045484896143 | validation: 0.13972230932741447]
	TIME [epoch: 6.49 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10883548182137552		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.10883548182137552 | validation: 0.13367149915687587]
	TIME [epoch: 6.48 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10310909030805762		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.10310909030805762 | validation: 0.13681326564207155]
	TIME [epoch: 6.52 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10665076284408656		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.10665076284408656 | validation: 0.1387058635523672]
	TIME [epoch: 6.49 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10938362690830344		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.10938362690830344 | validation: 0.1328280464851885]
	TIME [epoch: 6.49 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10887232429186318		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.10887232429186318 | validation: 0.1500774073242758]
	TIME [epoch: 6.47 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10461350523428428		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.10461350523428428 | validation: 0.1377414808096701]
	TIME [epoch: 6.48 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10482774509226431		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.10482774509226431 | validation: 0.14398645278454267]
	TIME [epoch: 6.49 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10092767745806118		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.10092767745806118 | validation: 0.1305598355844948]
	TIME [epoch: 6.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10839145046647537		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.10839145046647537 | validation: 0.1388435512776578]
	TIME [epoch: 6.48 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1042018358012251		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.1042018358012251 | validation: 0.13762582488305708]
	TIME [epoch: 6.47 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10388054925445259		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.10388054925445259 | validation: 0.14082631503125526]
	TIME [epoch: 6.47 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10752197793404933		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.10752197793404933 | validation: 0.13377853877682586]
	TIME [epoch: 6.47 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09681027987711674		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.09681027987711674 | validation: 0.1311139567338381]
	TIME [epoch: 6.49 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11098807829363484		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.11098807829363484 | validation: 0.13388722381727458]
	TIME [epoch: 6.47 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10503778431011165		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.10503778431011165 | validation: 0.13501763576390238]
	TIME [epoch: 6.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10936663604097319		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.10936663604097319 | validation: 0.14277780957168704]
	TIME [epoch: 6.47 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10436640441959726		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.10436640441959726 | validation: 0.14172163239496946]
	TIME [epoch: 6.48 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10604076159556042		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.10604076159556042 | validation: 0.13497945805433248]
	TIME [epoch: 6.47 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10861904474495518		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.10861904474495518 | validation: 0.1297525952518484]
	TIME [epoch: 6.49 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10407090833366839		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.10407090833366839 | validation: 0.14494485475933178]
	TIME [epoch: 6.48 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10656801253253943		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.10656801253253943 | validation: 0.1323581986073355]
	TIME [epoch: 6.5 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10199763715831926		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.10199763715831926 | validation: 0.14449920040003034]
	TIME [epoch: 6.5 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10785500586263341		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.10785500586263341 | validation: 0.1424861029583943]
	TIME [epoch: 6.49 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1061716836669442		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.1061716836669442 | validation: 0.14555425512557574]
	TIME [epoch: 6.48 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10471281477905081		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.10471281477905081 | validation: 0.14185293020734985]
	TIME [epoch: 6.48 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10855182621900976		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.10855182621900976 | validation: 0.14632407500824288]
	TIME [epoch: 6.48 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10414512358556915		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.10414512358556915 | validation: 0.14697332205963512]
	TIME [epoch: 6.48 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09886864702645484		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.09886864702645484 | validation: 0.1445359620756608]
	TIME [epoch: 6.51 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1009466546824623		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.1009466546824623 | validation: 0.13479268275879822]
	TIME [epoch: 6.49 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1060306152873816		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.1060306152873816 | validation: 0.13565544158805454]
	TIME [epoch: 6.47 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11082843150054306		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.11082843150054306 | validation: 0.14569101533330114]
	TIME [epoch: 6.49 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10906464121446116		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.10906464121446116 | validation: 0.14538452874525637]
	TIME [epoch: 6.48 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10392664350334925		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.10392664350334925 | validation: 0.13608629951217058]
	TIME [epoch: 6.49 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1017744676446802		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.1017744676446802 | validation: 0.13543087425860237]
	TIME [epoch: 6.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10650657511143745		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.10650657511143745 | validation: 0.1309569962353647]
	TIME [epoch: 6.51 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10951493994435546		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.10951493994435546 | validation: 0.14359576185145784]
	TIME [epoch: 6.48 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10518297933839413		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.10518297933839413 | validation: 0.13052202500466656]
	TIME [epoch: 6.48 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10834875259015467		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.10834875259015467 | validation: 0.13806804401317022]
	TIME [epoch: 6.49 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10226589605285806		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.10226589605285806 | validation: 0.13674448888727647]
	TIME [epoch: 6.48 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10288356006875919		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.10288356006875919 | validation: 0.1319235409727265]
	TIME [epoch: 6.47 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10594657074463755		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.10594657074463755 | validation: 0.13283576978328784]
	TIME [epoch: 6.52 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10601419489235193		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.10601419489235193 | validation: 0.14130206949107285]
	TIME [epoch: 6.49 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1059371951108011		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.1059371951108011 | validation: 0.1346981374717463]
	TIME [epoch: 6.48 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10535069119396262		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.10535069119396262 | validation: 0.13412384147002843]
	TIME [epoch: 6.48 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10436119073105796		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.10436119073105796 | validation: 0.1480691467845757]
	TIME [epoch: 6.48 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10344836747367722		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.10344836747367722 | validation: 0.13621814438232357]
	TIME [epoch: 6.47 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10849777024615706		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.10849777024615706 | validation: 0.14527860253327768]
	TIME [epoch: 6.48 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10552867437884185		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.10552867437884185 | validation: 0.13859493893553354]
	TIME [epoch: 6.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.104966418758103		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.104966418758103 | validation: 0.1288687945146643]
	TIME [epoch: 6.48 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10072139636550681		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.10072139636550681 | validation: 0.12788058953354]
	TIME [epoch: 6.48 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10568038024972126		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.10568038024972126 | validation: 0.13766018038017852]
	TIME [epoch: 6.48 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10611094273068798		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.10611094273068798 | validation: 0.13419693050176243]
	TIME [epoch: 6.49 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103246913266821		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.103246913266821 | validation: 0.14222066700751987]
	TIME [epoch: 6.47 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10379116063830594		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.10379116063830594 | validation: 0.1266275582822392]
	TIME [epoch: 6.52 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10631738533734897		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.10631738533734897 | validation: 0.13915930460714224]
	TIME [epoch: 6.48 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09981401841065905		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.09981401841065905 | validation: 0.13904089387558682]
	TIME [epoch: 6.48 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10590811902344975		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.10590811902344975 | validation: 0.13408847969173784]
	TIME [epoch: 6.47 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.104484048474489		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.104484048474489 | validation: 0.1336081037962358]
	TIME [epoch: 6.48 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10384802047549394		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.10384802047549394 | validation: 0.13387190421622555]
	TIME [epoch: 6.47 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10549299760419542		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.10549299760419542 | validation: 0.1410301248644357]
	TIME [epoch: 6.48 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10750756541281928		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.10750756541281928 | validation: 0.1356335518359826]
	TIME [epoch: 6.51 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1051009382163795		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.1051009382163795 | validation: 0.14093949109123255]
	TIME [epoch: 6.48 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10404656319113384		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.10404656319113384 | validation: 0.14114114221820465]
	TIME [epoch: 6.47 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10508124306184208		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.10508124306184208 | validation: 0.1322924798217553]
	TIME [epoch: 6.48 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10260472597203803		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.10260472597203803 | validation: 0.1443436538227043]
	TIME [epoch: 6.47 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10672751554635158		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.10672751554635158 | validation: 0.13746970380772847]
	TIME [epoch: 6.46 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1071231261695828		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.1071231261695828 | validation: 0.1436069263603122]
	TIME [epoch: 6.5 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10666554133052414		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.10666554133052414 | validation: 0.1346323144563354]
	TIME [epoch: 6.48 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10560741754233888		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.10560741754233888 | validation: 0.13244663834643425]
	TIME [epoch: 6.47 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10480702725574037		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.10480702725574037 | validation: 0.1367857656739426]
	TIME [epoch: 6.48 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10777186941516206		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.10777186941516206 | validation: 0.14173479214362872]
	TIME [epoch: 6.47 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.103403268461245		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.103403268461245 | validation: 0.13581830130454814]
	TIME [epoch: 6.48 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10155351879681591		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.10155351879681591 | validation: 0.1287338589616863]
	TIME [epoch: 6.48 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10769046068490812		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.10769046068490812 | validation: 0.13735635101940954]
	TIME [epoch: 6.5 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10872387036281261		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.10872387036281261 | validation: 0.1388772714004864]
	TIME [epoch: 6.47 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477727765057354		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.10477727765057354 | validation: 0.13566167436875856]
	TIME [epoch: 6.47 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1052823354134319		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.1052823354134319 | validation: 0.13763629514067743]
	TIME [epoch: 6.47 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10365925030814671		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.10365925030814671 | validation: 0.12981901658478232]
	TIME [epoch: 6.48 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10659066108688717		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.10659066108688717 | validation: 0.1485155481957532]
	TIME [epoch: 6.47 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10624910422814696		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.10624910422814696 | validation: 0.1369966647778558]
	TIME [epoch: 6.49 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1037447393258599		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.1037447393258599 | validation: 0.13628089516891648]
	TIME [epoch: 6.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10536914701927953		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.10536914701927953 | validation: 0.12460856944987848]
	TIME [epoch: 6.48 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10918672592666144		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.10918672592666144 | validation: 0.13986480181107636]
	TIME [epoch: 6.47 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10782272910016502		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.10782272910016502 | validation: 0.13920984457181643]
	TIME [epoch: 6.47 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10737969839729797		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.10737969839729797 | validation: 0.13561556634450586]
	TIME [epoch: 6.47 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10380007008911042		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.10380007008911042 | validation: 0.133920564359446]
	TIME [epoch: 6.47 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10441050610353625		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.10441050610353625 | validation: 0.1302100194881288]
	TIME [epoch: 6.51 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10657594240558868		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.10657594240558868 | validation: 0.14051380495487528]
	TIME [epoch: 6.47 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10890031349262597		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.10890031349262597 | validation: 0.13785510110576546]
	TIME [epoch: 6.47 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10660377748217228		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.10660377748217228 | validation: 0.1361646809842102]
	TIME [epoch: 6.47 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10563648674719268		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.10563648674719268 | validation: 0.13654124387316427]
	TIME [epoch: 6.47 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10849404322199029		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.10849404322199029 | validation: 0.1352021627506886]
	TIME [epoch: 6.49 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10522761742256259		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.10522761742256259 | validation: 0.14315079914639203]
	TIME [epoch: 6.48 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1075306258007165		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.1075306258007165 | validation: 0.13057813153070036]
	TIME [epoch: 6.5 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10051156093394284		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.10051156093394284 | validation: 0.13046385743764954]
	TIME [epoch: 6.48 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573040121733046		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.10573040121733046 | validation: 0.1283377687782358]
	TIME [epoch: 6.47 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10505350026397534		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.10505350026397534 | validation: 0.13316364041154238]
	TIME [epoch: 6.48 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10758176446691325		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.10758176446691325 | validation: 0.1389406417299937]
	TIME [epoch: 6.47 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10442216897028198		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.10442216897028198 | validation: 0.1344321815969967]
	TIME [epoch: 6.47 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10443530236717424		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.10443530236717424 | validation: 0.13605404506873828]
	TIME [epoch: 6.51 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10627849221276889		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.10627849221276889 | validation: 0.1344000705364498]
	TIME [epoch: 6.47 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10168789863190209		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.10168789863190209 | validation: 0.14659888708376984]
	TIME [epoch: 6.46 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10868831829837051		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.10868831829837051 | validation: 0.13714437541816651]
	TIME [epoch: 6.48 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10416565778851604		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.10416565778851604 | validation: 0.1484261979935132]
	TIME [epoch: 6.48 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10323714432487754		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.10323714432487754 | validation: 0.13508212647073872]
	TIME [epoch: 6.47 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10342092984654477		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.10342092984654477 | validation: 0.14124670516255186]
	TIME [epoch: 6.5 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10513006630891644		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.10513006630891644 | validation: 0.13754198437134313]
	TIME [epoch: 6.49 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10131228675116662		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.10131228675116662 | validation: 0.133674155231778]
	TIME [epoch: 6.48 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10190532595871232		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.10190532595871232 | validation: 0.14336044365814252]
	TIME [epoch: 6.49 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10844428502605974		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.10844428502605974 | validation: 0.13867488611204368]
	TIME [epoch: 6.46 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10420306016242642		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.10420306016242642 | validation: 0.1446431149115245]
	TIME [epoch: 6.47 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1020743929537679		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.1020743929537679 | validation: 0.13743773132006898]
	TIME [epoch: 6.48 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1099503231520642		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.1099503231520642 | validation: 0.1332914765387119]
	TIME [epoch: 6.5 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10655001470938553		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.10655001470938553 | validation: 0.13701638186639803]
	TIME [epoch: 6.49 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10691524647119938		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.10691524647119938 | validation: 0.1370929956558006]
	TIME [epoch: 6.48 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10649855909210618		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.10649855909210618 | validation: 0.13786532682587685]
	TIME [epoch: 6.46 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10460266676426791		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.10460266676426791 | validation: 0.13427460574665662]
	TIME [epoch: 6.47 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10274757249707384		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.10274757249707384 | validation: 0.13953530979911807]
	TIME [epoch: 6.46 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10237540225383224		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.10237540225383224 | validation: 0.1362480399506678]
	TIME [epoch: 6.49 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10469623254086549		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.10469623254086549 | validation: 0.12747986811140782]
	TIME [epoch: 6.52 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11033437651234204		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.11033437651234204 | validation: 0.13469481170930947]
	TIME [epoch: 6.49 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10428623900018157		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.10428623900018157 | validation: 0.13263353142467652]
	TIME [epoch: 6.47 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10249643683543788		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.10249643683543788 | validation: 0.1292957630163043]
	TIME [epoch: 6.48 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10659200150660558		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.10659200150660558 | validation: 0.13820680754863454]
	TIME [epoch: 6.47 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10315282543269978		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.10315282543269978 | validation: 0.1372096181178826]
	TIME [epoch: 6.49 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10278836285961324		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.10278836285961324 | validation: 0.1480291549379099]
	TIME [epoch: 6.52 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10586149218040819		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.10586149218040819 | validation: 0.14444487792411997]
	TIME [epoch: 6.49 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10443121257835665		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.10443121257835665 | validation: 0.14362882072528455]
	TIME [epoch: 6.48 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10441145172340793		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.10441145172340793 | validation: 0.13524265333001892]
	TIME [epoch: 6.48 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10499950125109243		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.10499950125109243 | validation: 0.1486973023678764]
	TIME [epoch: 6.48 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10744114885403337		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.10744114885403337 | validation: 0.13265355058037573]
	TIME [epoch: 6.47 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10090539460570247		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.10090539460570247 | validation: 0.1290571409657397]
	TIME [epoch: 6.49 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10309247165998936		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.10309247165998936 | validation: 0.1532316180748403]
	TIME [epoch: 6.52 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10570256556154412		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.10570256556154412 | validation: 0.13972493084552665]
	TIME [epoch: 6.49 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10866658349133806		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.10866658349133806 | validation: 0.13819774804389165]
	TIME [epoch: 6.48 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10494117156365064		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.10494117156365064 | validation: 0.14284688245341193]
	TIME [epoch: 6.47 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10458610968338337		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.10458610968338337 | validation: 0.12854844400280388]
	TIME [epoch: 6.47 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10804710295698887		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.10804710295698887 | validation: 0.13813069482092719]
	TIME [epoch: 6.46 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10462699680180809		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.10462699680180809 | validation: 0.14134022302151045]
	TIME [epoch: 6.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10429446701059022		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.10429446701059022 | validation: 0.14331134254613512]
	TIME [epoch: 6.5 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10529047115271256		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.10529047115271256 | validation: 0.13774884434756599]
	TIME [epoch: 6.48 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10364641998430948		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.10364641998430948 | validation: 0.1394831197364625]
	TIME [epoch: 6.47 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10339332002780026		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.10339332002780026 | validation: 0.1369775577240944]
	TIME [epoch: 6.48 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10949496909427983		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.10949496909427983 | validation: 0.14290659462644972]
	TIME [epoch: 6.47 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10869756051833956		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.10869756051833956 | validation: 0.13805967265616315]
	TIME [epoch: 6.48 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10385810683396397		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.10385810683396397 | validation: 0.1477941464012306]
	TIME [epoch: 6.51 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10174997194373919		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.10174997194373919 | validation: 0.14049450883689704]
	TIME [epoch: 6.47 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10338443302853746		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.10338443302853746 | validation: 0.13611520639423774]
	TIME [epoch: 6.47 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10542976889065002		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.10542976889065002 | validation: 0.1424054839935592]
	TIME [epoch: 6.48 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1013005468121045		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.1013005468121045 | validation: 0.12956142923290376]
	TIME [epoch: 6.48 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10807344402078203		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.10807344402078203 | validation: 0.1294588292086989]
	TIME [epoch: 6.48 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10365069873149409		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.10365069873149409 | validation: 0.14240491182407364]
	TIME [epoch: 6.49 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10651267151674614		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.10651267151674614 | validation: 0.1347328497236341]
	TIME [epoch: 6.51 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10167346206783576		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.10167346206783576 | validation: 0.14629219881393912]
	TIME [epoch: 6.49 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10630803375785049		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.10630803375785049 | validation: 0.1373569213041693]
	TIME [epoch: 6.48 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10628803436265083		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.10628803436265083 | validation: 0.13088280497778354]
	TIME [epoch: 6.48 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10523583177729941		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.10523583177729941 | validation: 0.14053048318905906]
	TIME [epoch: 6.48 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10347136109703757		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.10347136109703757 | validation: 0.13993767058165157]
	TIME [epoch: 6.48 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1005004689542004		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.1005004689542004 | validation: 0.13826449993525397]
	TIME [epoch: 6.51 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1043791929216445		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.1043791929216445 | validation: 0.1434107063170781]
	TIME [epoch: 6.49 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10731270389314775		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.10731270389314775 | validation: 0.14254574214041665]
	TIME [epoch: 6.46 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10494430288768164		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.10494430288768164 | validation: 0.14186752055861482]
	TIME [epoch: 6.46 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10207686082202892		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.10207686082202892 | validation: 0.13601566272290855]
	TIME [epoch: 6.47 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10741178278965959		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.10741178278965959 | validation: 0.13428815152863688]
	TIME [epoch: 6.49 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317540500999388		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.10317540500999388 | validation: 0.1394135383334022]
	TIME [epoch: 6.5 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10607388708327986		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.10607388708327986 | validation: 0.1395704712813183]
	TIME [epoch: 6.5 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10552033831123349		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.10552033831123349 | validation: 0.13745151126265104]
	TIME [epoch: 6.48 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10728316942930846		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.10728316942930846 | validation: 0.13684311204962488]
	TIME [epoch: 6.49 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10435770260739316		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.10435770260739316 | validation: 0.13778421025639534]
	TIME [epoch: 6.48 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10654286224840583		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.10654286224840583 | validation: 0.1492347194133609]
	TIME [epoch: 6.48 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1039369899142809		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.1039369899142809 | validation: 0.1355917703542938]
	TIME [epoch: 6.46 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10468898256002185		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.10468898256002185 | validation: 0.13907157252246835]
	TIME [epoch: 6.5 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10732312051516191		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.10732312051516191 | validation: 0.1514302903730451]
	TIME [epoch: 6.49 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10735454113685597		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.10735454113685597 | validation: 0.14880318594007377]
	TIME [epoch: 6.47 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10632863353180488		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.10632863353180488 | validation: 0.1407143661098192]
	TIME [epoch: 6.49 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10037929458808773		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.10037929458808773 | validation: 0.13694716755020644]
	TIME [epoch: 6.46 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049734890006093		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.1049734890006093 | validation: 0.13269432274992532]
	TIME [epoch: 6.47 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10422503444645992		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.10422503444645992 | validation: 0.13583735482059595]
	TIME [epoch: 6.49 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10723329150739282		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.10723329150739282 | validation: 0.14078651216509894]
	TIME [epoch: 6.52 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10574989026532247		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.10574989026532247 | validation: 0.13797890694658535]
	TIME [epoch: 6.47 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10605170531106455		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.10605170531106455 | validation: 0.14295157611612194]
	TIME [epoch: 6.47 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10875928814182513		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.10875928814182513 | validation: 0.14165076914932528]
	TIME [epoch: 6.47 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10225760022758744		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.10225760022758744 | validation: 0.14185821038520893]
	TIME [epoch: 6.49 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10680308729119672		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.10680308729119672 | validation: 0.13828714206983503]
	TIME [epoch: 6.48 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10963729003611364		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.10963729003611364 | validation: 0.1442545248752389]
	TIME [epoch: 6.51 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10510632190114766		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.10510632190114766 | validation: 0.12342807321295853]
	TIME [epoch: 6.48 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10708375325755154		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.10708375325755154 | validation: 0.13776778955222901]
	TIME [epoch: 6.47 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10054364132190605		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.10054364132190605 | validation: 0.14164767907209883]
	TIME [epoch: 6.47 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.105613642861867		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.105613642861867 | validation: 0.13509051448297166]
	TIME [epoch: 6.47 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1067729700784198		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.1067729700784198 | validation: 0.13574240050576386]
	TIME [epoch: 6.47 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10654108174897262		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.10654108174897262 | validation: 0.13745619924732908]
	TIME [epoch: 6.47 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10469192860765737		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.10469192860765737 | validation: 0.1394936051363514]
	TIME [epoch: 6.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10233732854976371		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.10233732854976371 | validation: 0.13910814091500218]
	TIME [epoch: 6.47 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10477449290856017		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.10477449290856017 | validation: 0.1373831419594575]
	TIME [epoch: 6.46 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1050846688100543		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.1050846688100543 | validation: 0.14313213616130838]
	TIME [epoch: 6.47 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10168391717084599		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.10168391717084599 | validation: 0.1336547915002613]
	TIME [epoch: 6.47 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10420407037832083		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.10420407037832083 | validation: 0.14686410387276896]
	TIME [epoch: 6.47 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10634948063583521		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.10634948063583521 | validation: 0.1361207288902567]
	TIME [epoch: 6.5 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10444645131143539		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.10444645131143539 | validation: 0.13864233113850227]
	TIME [epoch: 6.51 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1050739609272033		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.1050739609272033 | validation: 0.1377374932430582]
	TIME [epoch: 6.48 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10385039653058195		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.10385039653058195 | validation: 0.13473548843233502]
	TIME [epoch: 6.47 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10379330875823911		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.10379330875823911 | validation: 0.13672738964073333]
	TIME [epoch: 6.47 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10373054439727308		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.10373054439727308 | validation: 0.13977304926456757]
	TIME [epoch: 6.46 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10251509051544555		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.10251509051544555 | validation: 0.14179865964245358]
	TIME [epoch: 6.48 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10374835171180263		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.10374835171180263 | validation: 0.12977287930258943]
	TIME [epoch: 6.51 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10543564402892608		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.10543564402892608 | validation: 0.13699003913837626]
	TIME [epoch: 6.49 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0981394829275903		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.0981394829275903 | validation: 0.1441248556534006]
	TIME [epoch: 6.47 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10631802947616746		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.10631802947616746 | validation: 0.13552182890461015]
	TIME [epoch: 6.47 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10710384497808795		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.10710384497808795 | validation: 0.1432555746420054]
	TIME [epoch: 6.48 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10566131053303354		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.10566131053303354 | validation: 0.1316502465977011]
	TIME [epoch: 6.47 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10804721900199205		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.10804721900199205 | validation: 0.13666719324129634]
	TIME [epoch: 6.49 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10413379761369895		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.10413379761369895 | validation: 0.1375186446972977]
	TIME [epoch: 6.51 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10258288566308904		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.10258288566308904 | validation: 0.13701313004429433]
	TIME [epoch: 6.47 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10627972858004414		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.10627972858004414 | validation: 0.1490956187634455]
	TIME [epoch: 6.47 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10390514012944951		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.10390514012944951 | validation: 0.1369712138213602]
	TIME [epoch: 6.47 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10616475658164815		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.10616475658164815 | validation: 0.14085414330174553]
	TIME [epoch: 6.47 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10462541546265476		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.10462541546265476 | validation: 0.12911918505713396]
	TIME [epoch: 6.46 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10380601996694444		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.10380601996694444 | validation: 0.14021467083628175]
	TIME [epoch: 6.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10613754593338784		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.10613754593338784 | validation: 0.135853911089832]
	TIME [epoch: 6.49 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10408988549455801		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.10408988549455801 | validation: 0.1359438097154655]
	TIME [epoch: 6.48 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10511679773489953		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.10511679773489953 | validation: 0.1226004338936756]
	TIME [epoch: 6.47 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10901341040269275		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.10901341040269275 | validation: 0.13444476460107604]
	TIME [epoch: 6.47 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10630518181400307		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.10630518181400307 | validation: 0.13296104065536926]
	TIME [epoch: 6.49 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.104993276375716		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.104993276375716 | validation: 0.13689915485705212]
	TIME [epoch: 6.48 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10461487834167794		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.10461487834167794 | validation: 0.13253001359198374]
	TIME [epoch: 6.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10671290436854897		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.10671290436854897 | validation: 0.14621986215928456]
	TIME [epoch: 6.49 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10599897819842606		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.10599897819842606 | validation: 0.13489254250956817]
	TIME [epoch: 6.47 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10930783990006657		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.10930783990006657 | validation: 0.13288671429180174]
	TIME [epoch: 6.47 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10543131633923528		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.10543131633923528 | validation: 0.13485834560697277]
	TIME [epoch: 6.46 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10316983096673901		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.10316983096673901 | validation: 0.13677551995242387]
	TIME [epoch: 6.46 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10525704817447454		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.10525704817447454 | validation: 0.13282803239312096]
	TIME [epoch: 6.49 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10682804803621801		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.10682804803621801 | validation: 0.14081219195121586]
	TIME [epoch: 6.48 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10308631516768833		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.10308631516768833 | validation: 0.14168089678924653]
	TIME [epoch: 6.46 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10341051269971878		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.10341051269971878 | validation: 0.1405429206563928]
	TIME [epoch: 6.47 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10660879714774046		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.10660879714774046 | validation: 0.1396489765851408]
	TIME [epoch: 6.47 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10654698045302385		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.10654698045302385 | validation: 0.14435160733852637]
	TIME [epoch: 6.46 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10474980923685315		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.10474980923685315 | validation: 0.13579855930203938]
	TIME [epoch: 6.46 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10198247223823034		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.10198247223823034 | validation: 0.14355407908285198]
	TIME [epoch: 6.51 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10462707424327349		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.10462707424327349 | validation: 0.1406305569129101]
	TIME [epoch: 6.46 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10581082353655573		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.10581082353655573 | validation: 0.13637744996613446]
	TIME [epoch: 6.46 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10403085035662887		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.10403085035662887 | validation: 0.14052702741577153]
	TIME [epoch: 6.47 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1043772249761134		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.1043772249761134 | validation: 0.1328289706666672]
	TIME [epoch: 6.47 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10802366790327596		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.10802366790327596 | validation: 0.13956757854862895]
	TIME [epoch: 6.47 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10725654860793157		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.10725654860793157 | validation: 0.13490811487007823]
	TIME [epoch: 6.51 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10521654225728543		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.10521654225728543 | validation: 0.14194534050778185]
	TIME [epoch: 6.46 sec]
Finished training in 13141.118 seconds.
