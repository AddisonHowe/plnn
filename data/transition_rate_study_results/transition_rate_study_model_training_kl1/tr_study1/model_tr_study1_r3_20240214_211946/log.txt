Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r3', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 702596156

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/20] avg loss: 10.942926338890661		[learning rate: 0.01]
		[batch 20/20] avg loss: 9.795337452002066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.369131895446365 | validation: 8.576820981934127]
	TIME [epoch: 48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/20] avg loss: 8.537152561646066		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.621862319500416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.079507440573241 | validation: 6.675040245149998]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/20] avg loss: 8.736430974125174		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.227950295713438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.4821906349193075 | validation: 5.225716324631245]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/20] avg loss: 5.840492017561546		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.143252002792535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4918720101770395 | validation: 5.0669415884618125]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/20] avg loss: 4.775011101741069		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.502972411334912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.63899175653799 | validation: 5.209700032016463]
	TIME [epoch: 8.9 sec]
EPOCH 6/500:
	Training over batches...
		[batch 10/20] avg loss: 4.534984067378948		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.3607255971886065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.447854832283777 | validation: 4.026586251188942]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/20] avg loss: 4.594879215579485		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.364023598170676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.47945140687508 | validation: 4.079256609667637]
	TIME [epoch: 8.92 sec]
EPOCH 8/500:
	Training over batches...
		[batch 10/20] avg loss: 4.242963875586975		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.6184714890663967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.930717682326687 | validation: 3.2692026718256075]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 10/20] avg loss: 3.4382722557457073		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0429827625914756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2406275091685908 | validation: 2.8889906281687368]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/20] avg loss: 2.937367615536794		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.9741492781239303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9557584468303624 | validation: 2.5360182846764436]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 10/20] avg loss: 2.617617890285789		[learning rate: 0.0099789]
		[batch 20/20] avg loss: 2.5876895328371896		[learning rate: 0.0099555]
	Learning Rate: 0.00995546
	LOSS [training: 2.60265371156149 | validation: 2.7241976893065383]
	TIME [epoch: 8.94 sec]
EPOCH 12/500:
	Training over batches...
		[batch 10/20] avg loss: 2.5711873498444695		[learning rate: 0.0099321]
		[batch 20/20] avg loss: 2.467197887705686		[learning rate: 0.0099088]
	Learning Rate: 0.00990879
	LOSS [training: 2.5191926187750773 | validation: 1.998224565910881]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 10/20] avg loss: 2.2124681428076682		[learning rate: 0.0098855]
		[batch 20/20] avg loss: 2.221965278379614		[learning rate: 0.0098623]
	Learning Rate: 0.00986233
	LOSS [training: 2.217216710593641 | validation: 2.3944354960028695]
	TIME [epoch: 8.9 sec]
EPOCH 14/500:
	Training over batches...
		[batch 10/20] avg loss: 2.209852527926122		[learning rate: 0.0098392]
		[batch 20/20] avg loss: 2.603032653161287		[learning rate: 0.0098161]
	Learning Rate: 0.0098161
	LOSS [training: 2.406442590543705 | validation: 1.6780428902899782]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 10/20] avg loss: 2.096585159669416		[learning rate: 0.0097931]
		[batch 20/20] avg loss: 2.1958993295107563		[learning rate: 0.0097701]
	Learning Rate: 0.00977008
	LOSS [training: 2.1462422445900864 | validation: 3.629999842885198]
	TIME [epoch: 8.92 sec]
EPOCH 16/500:
	Training over batches...
		[batch 10/20] avg loss: 2.344843478812645		[learning rate: 0.0097471]
		[batch 20/20] avg loss: 1.789374266000485		[learning rate: 0.0097243]
	Learning Rate: 0.00972427
	LOSS [training: 2.067108872406566 | validation: 1.8909978934338731]
	TIME [epoch: 8.9 sec]
EPOCH 17/500:
	Training over batches...
		[batch 10/20] avg loss: 1.7723557228126743		[learning rate: 0.0097015]
		[batch 20/20] avg loss: 1.72388890894374		[learning rate: 0.0096787]
	Learning Rate: 0.00967868
	LOSS [training: 1.7481223158782075 | validation: 2.485385391548665]
	TIME [epoch: 8.89 sec]
EPOCH 18/500:
	Training over batches...
		[batch 10/20] avg loss: 1.8581715157496579		[learning rate: 0.009656]
		[batch 20/20] avg loss: 1.776736121374255		[learning rate: 0.0096333]
	Learning Rate: 0.00963331
	LOSS [training: 1.8174538185619564 | validation: 1.3032989465970055]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 10/20] avg loss: 1.5864924371139524		[learning rate: 0.0096107]
		[batch 20/20] avg loss: 1.5569579944464167		[learning rate: 0.0095881]
	Learning Rate: 0.00958815
	LOSS [training: 1.5717252157801844 | validation: 1.5125324123873503]
	TIME [epoch: 8.94 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/20] avg loss: 1.5903331302803054		[learning rate: 0.0095656]
		[batch 20/20] avg loss: 1.6199272285007713		[learning rate: 0.0095432]
	Learning Rate: 0.0095432
	LOSS [training: 1.6051301793905384 | validation: 1.2532580187019262]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4476500175361962		[learning rate: 0.0095208]
		[batch 20/20] avg loss: 1.4221938249300794		[learning rate: 0.0094985]
	Learning Rate: 0.00949846
	LOSS [training: 1.434921921233138 | validation: 0.9579833874060257]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 10/20] avg loss: 1.5313683496464674		[learning rate: 0.0094762]
		[batch 20/20] avg loss: 1.3900225442850833		[learning rate: 0.0094539]
	Learning Rate: 0.00945393
	LOSS [training: 1.460695446965775 | validation: 1.4690318086779888]
	TIME [epoch: 8.92 sec]
EPOCH 23/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3989707282205153		[learning rate: 0.0094317]
		[batch 20/20] avg loss: 1.487587338180135		[learning rate: 0.0094096]
	Learning Rate: 0.00940961
	LOSS [training: 1.4432790332003251 | validation: 1.3759222956453696]
	TIME [epoch: 8.91 sec]
EPOCH 24/500:
	Training over batches...
		[batch 10/20] avg loss: 1.503810667380231		[learning rate: 0.0093875]
		[batch 20/20] avg loss: 1.3455365448644312		[learning rate: 0.0093655]
	Learning Rate: 0.00936549
	LOSS [training: 1.4246736061223308 | validation: 0.9863766142186482]
	TIME [epoch: 8.92 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3640744075982334		[learning rate: 0.0093435]
		[batch 20/20] avg loss: 1.3395248284543908		[learning rate: 0.0093216]
	Learning Rate: 0.00932159
	LOSS [training: 1.351799618026312 | validation: 2.3813723182177866]
	TIME [epoch: 8.91 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3401443440010776		[learning rate: 0.0092997]
		[batch 20/20] avg loss: 1.2755260589436808		[learning rate: 0.0092779]
	Learning Rate: 0.00927788
	LOSS [training: 1.307835201472379 | validation: 1.1374884502391394]
	TIME [epoch: 8.91 sec]
EPOCH 27/500:
	Training over batches...
		[batch 10/20] avg loss: 1.5918188209005344		[learning rate: 0.0092561]
		[batch 20/20] avg loss: 1.3206695143546117		[learning rate: 0.0092344]
	Learning Rate: 0.00923439
	LOSS [training: 1.456244167627573 | validation: 1.4670718797589741]
	TIME [epoch: 8.91 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3493483791096677		[learning rate: 0.0092127]
		[batch 20/20] avg loss: 1.4143380738160238		[learning rate: 0.0091911]
	Learning Rate: 0.0091911
	LOSS [training: 1.3818432264628457 | validation: 1.0056181004242206]
	TIME [epoch: 8.91 sec]
EPOCH 29/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4275742794519948		[learning rate: 0.0091695]
		[batch 20/20] avg loss: 1.2055452427032158		[learning rate: 0.009148]
	Learning Rate: 0.00914801
	LOSS [training: 1.3165597610776052 | validation: 0.9152601055128087]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 10/20] avg loss: 1.2978197805726952		[learning rate: 0.0091265]
		[batch 20/20] avg loss: 1.520994988087295		[learning rate: 0.0091051]
	Learning Rate: 0.00910512
	LOSS [training: 1.4094073843299952 | validation: 2.4582559745873698]
	TIME [epoch: 8.85 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/20] avg loss: 1.6361477774753124		[learning rate: 0.0090838]
		[batch 20/20] avg loss: 1.3464932189645427		[learning rate: 0.0090624]
	Learning Rate: 0.00906243
	LOSS [training: 1.4913204982199275 | validation: 0.9440684648776418]
	TIME [epoch: 8.86 sec]
EPOCH 32/500:
	Training over batches...
		[batch 10/20] avg loss: 1.2226552862630742		[learning rate: 0.0090412]
		[batch 20/20] avg loss: 1.5074861541242615		[learning rate: 0.0090199]
	Learning Rate: 0.00901995
	LOSS [training: 1.365070720193668 | validation: 1.15133834633059]
	TIME [epoch: 8.87 sec]
EPOCH 33/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1807214870737925		[learning rate: 0.0089988]
		[batch 20/20] avg loss: 1.2594919568576513		[learning rate: 0.0089777]
	Learning Rate: 0.00897766
	LOSS [training: 1.2201067219657218 | validation: 1.0267762436583674]
	TIME [epoch: 8.88 sec]
EPOCH 34/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1538031887858238		[learning rate: 0.0089566]
		[batch 20/20] avg loss: 1.2886359130804685		[learning rate: 0.0089356]
	Learning Rate: 0.00893557
	LOSS [training: 1.221219550933146 | validation: 2.1476009368143187]
	TIME [epoch: 8.88 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/20] avg loss: 1.401568675559141		[learning rate: 0.0089146]
		[batch 20/20] avg loss: 1.3248602649463468		[learning rate: 0.0088937]
	Learning Rate: 0.00889368
	LOSS [training: 1.363214470252744 | validation: 0.9394279844940694]
	TIME [epoch: 8.87 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1735033039335288		[learning rate: 0.0088728]
		[batch 20/20] avg loss: 1.1443154897212862		[learning rate: 0.008852]
	Learning Rate: 0.00885199
	LOSS [training: 1.1589093968274076 | validation: 1.2438369191676555]
	TIME [epoch: 8.86 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4219180175502644		[learning rate: 0.0088312]
		[batch 20/20] avg loss: 1.320564399505719		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.3712412085279917 | validation: 1.013758109692609]
	TIME [epoch: 8.86 sec]
EPOCH 38/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1494086738002653		[learning rate: 0.0087898]
		[batch 20/20] avg loss: 1.393504844464082		[learning rate: 0.0087692]
	Learning Rate: 0.00876918
	LOSS [training: 1.271456759132174 | validation: 1.201008863973521]
	TIME [epoch: 8.88 sec]
EPOCH 39/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3834995506573857		[learning rate: 0.0087486]
		[batch 20/20] avg loss: 1.1340534864654992		[learning rate: 0.0087281]
	Learning Rate: 0.00872807
	LOSS [training: 1.2587765185614423 | validation: 1.1941648285364221]
	TIME [epoch: 8.87 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/20] avg loss: 1.234671108050756		[learning rate: 0.0087076]
		[batch 20/20] avg loss: 1.094704008613566		[learning rate: 0.0086872]
	Learning Rate: 0.00868715
	LOSS [training: 1.164687558332161 | validation: 0.7963395516144067]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1109613639806404		[learning rate: 0.0086668]
		[batch 20/20] avg loss: 0.992678171204284		[learning rate: 0.0086464]
	Learning Rate: 0.00864643
	LOSS [training: 1.051819767592462 | validation: 0.9731968810149156]
	TIME [epoch: 8.88 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1270463610876686		[learning rate: 0.0086261]
		[batch 20/20] avg loss: 1.085584238147206		[learning rate: 0.0086059]
	Learning Rate: 0.00860589
	LOSS [training: 1.1063152996174375 | validation: 0.7068447438381895]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0616418189888166		[learning rate: 0.0085857]
		[batch 20/20] avg loss: 1.0802783931916073		[learning rate: 0.0085655]
	Learning Rate: 0.00856555
	LOSS [training: 1.0709601060902119 | validation: 0.9116230658062373]
	TIME [epoch: 8.91 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1556207747477916		[learning rate: 0.0085454]
		[batch 20/20] avg loss: 1.0201747809288286		[learning rate: 0.0085254]
	Learning Rate: 0.00852539
	LOSS [training: 1.0878977778383099 | validation: 0.6230022787445677]
	TIME [epoch: 8.89 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_44.pth
	Model improved!!!
EPOCH 45/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9625994801040705		[learning rate: 0.0085054]
		[batch 20/20] avg loss: 0.9878532983067456		[learning rate: 0.0084854]
	Learning Rate: 0.00848542
	LOSS [training: 0.9752263892054079 | validation: 0.676828444941529]
	TIME [epoch: 8.91 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/20] avg loss: 0.953865483063859		[learning rate: 0.0084655]
		[batch 20/20] avg loss: 1.1943432142313422		[learning rate: 0.0084456]
	Learning Rate: 0.00844564
	LOSS [training: 1.0741043486476007 | validation: 1.2534588097731232]
	TIME [epoch: 8.92 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0619431257716136		[learning rate: 0.0084258]
		[batch 20/20] avg loss: 1.0888742718228923		[learning rate: 0.008406]
	Learning Rate: 0.00840605
	LOSS [training: 1.0754086987972529 | validation: 1.8781877018344049]
	TIME [epoch: 8.92 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0475729263011375		[learning rate: 0.0083863]
		[batch 20/20] avg loss: 1.0094675771683783		[learning rate: 0.0083666]
	Learning Rate: 0.00836664
	LOSS [training: 1.028520251734758 | validation: 0.7392748699110978]
	TIME [epoch: 8.91 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9840077941543358		[learning rate: 0.008347]
		[batch 20/20] avg loss: 1.0613976367013955		[learning rate: 0.0083274]
	Learning Rate: 0.00832742
	LOSS [training: 1.0227027154278656 | validation: 0.9789530521051315]
	TIME [epoch: 8.89 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9435037266435214		[learning rate: 0.0083079]
		[batch 20/20] avg loss: 0.8359975028677666		[learning rate: 0.0082884]
	Learning Rate: 0.00828838
	LOSS [training: 0.8897506147556442 | validation: 1.5691403026378081]
	TIME [epoch: 8.88 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1236736576094433		[learning rate: 0.0082689]
		[batch 20/20] avg loss: 1.003647562473328		[learning rate: 0.0082495]
	Learning Rate: 0.00824952
	LOSS [training: 1.063660610041386 | validation: 0.7679511334394381]
	TIME [epoch: 8.89 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/20] avg loss: 1.2404368519017264		[learning rate: 0.0082302]
		[batch 20/20] avg loss: 0.9557139901414413		[learning rate: 0.0082108]
	Learning Rate: 0.00821084
	LOSS [training: 1.098075421021584 | validation: 0.8936010376684085]
	TIME [epoch: 8.9 sec]
EPOCH 53/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9603694471899109		[learning rate: 0.0081916]
		[batch 20/20] avg loss: 0.8324822495628077		[learning rate: 0.0081723]
	Learning Rate: 0.00817235
	LOSS [training: 0.8964258483763592 | validation: 0.581886579084643]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8761709657295805		[learning rate: 0.0081532]
		[batch 20/20] avg loss: 0.9183191287000911		[learning rate: 0.008134]
	Learning Rate: 0.00813404
	LOSS [training: 0.8972450472148358 | validation: 0.6230188801014775]
	TIME [epoch: 8.93 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0998593067842433		[learning rate: 0.0081149]
		[batch 20/20] avg loss: 1.0476731784752473		[learning rate: 0.0080959]
	Learning Rate: 0.0080959
	LOSS [training: 1.0737662426297452 | validation: 0.6253762547252054]
	TIME [epoch: 8.91 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8943515898966012		[learning rate: 0.0080769]
		[batch 20/20] avg loss: 0.9454347861568978		[learning rate: 0.0080579]
	Learning Rate: 0.00805795
	LOSS [training: 0.9198931880267496 | validation: 1.0832601800354102]
	TIME [epoch: 8.93 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9203034120590121		[learning rate: 0.008039]
		[batch 20/20] avg loss: 0.7806844296473683		[learning rate: 0.0080202]
	Learning Rate: 0.00802017
	LOSS [training: 0.8504939208531901 | validation: 0.9106939687281975]
	TIME [epoch: 8.92 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3249005195811876		[learning rate: 0.0080013]
		[batch 20/20] avg loss: 0.9184407607700814		[learning rate: 0.0079826]
	Learning Rate: 0.00798257
	LOSS [training: 1.1216706401756347 | validation: 0.6532282951489476]
	TIME [epoch: 8.9 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9352118462553273		[learning rate: 0.0079638]
		[batch 20/20] avg loss: 1.39049896632677		[learning rate: 0.0079451]
	Learning Rate: 0.00794515
	LOSS [training: 1.162855406291049 | validation: 1.0051551613105254]
	TIME [epoch: 8.92 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0336943468609063		[learning rate: 0.0079265]
		[batch 20/20] avg loss: 0.8009497499904679		[learning rate: 0.0079079]
	Learning Rate: 0.0079079
	LOSS [training: 0.9173220484256872 | validation: 0.6346951533945773]
	TIME [epoch: 8.95 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9209600305248576		[learning rate: 0.0078893]
		[batch 20/20] avg loss: 0.775264285276203		[learning rate: 0.0078708]
	Learning Rate: 0.00787083
	LOSS [training: 0.8481121579005302 | validation: 0.5484915330928506]
	TIME [epoch: 8.94 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_61.pth
	Model improved!!!
EPOCH 62/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0598209921907131		[learning rate: 0.0078524]
		[batch 20/20] avg loss: 0.9951183623743635		[learning rate: 0.0078339]
	Learning Rate: 0.00783393
	LOSS [training: 1.0274696772825382 | validation: 0.7316435930385304]
	TIME [epoch: 8.93 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8329059491096276		[learning rate: 0.0078155]
		[batch 20/20] avg loss: 0.9591039854065		[learning rate: 0.0077972]
	Learning Rate: 0.0077972
	LOSS [training: 0.896004967258064 | validation: 0.6602440251697007]
	TIME [epoch: 8.92 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/20] avg loss: 0.802395851984909		[learning rate: 0.0077789]
		[batch 20/20] avg loss: 0.899326445392588		[learning rate: 0.0077606]
	Learning Rate: 0.00776065
	LOSS [training: 0.8508611486887485 | validation: 3.17215054827593]
	TIME [epoch: 8.93 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0753269093123121		[learning rate: 0.0077424]
		[batch 20/20] avg loss: 0.7466526323114738		[learning rate: 0.0077243]
	Learning Rate: 0.00772426
	LOSS [training: 0.9109897708118929 | validation: 0.7713104144838543]
	TIME [epoch: 8.91 sec]
EPOCH 66/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9042732393691335		[learning rate: 0.0077061]
		[batch 20/20] avg loss: 0.6467543585152669		[learning rate: 0.0076881]
	Learning Rate: 0.00768805
	LOSS [training: 0.7755137989422003 | validation: 0.8220372021316864]
	TIME [epoch: 8.91 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8104633670082786		[learning rate: 0.00767]
		[batch 20/20] avg loss: 1.0128879908079482		[learning rate: 0.007652]
	Learning Rate: 0.00765201
	LOSS [training: 0.9116756789081135 | validation: 0.815137665176348]
	TIME [epoch: 8.92 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0754999001145624		[learning rate: 0.0076341]
		[batch 20/20] avg loss: 1.111412228507819		[learning rate: 0.0076161]
	Learning Rate: 0.00761614
	LOSS [training: 1.093456064311191 | validation: 1.041486362107032]
	TIME [epoch: 8.91 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9424149317291907		[learning rate: 0.0075983]
		[batch 20/20] avg loss: 0.7664338080385972		[learning rate: 0.0075804]
	Learning Rate: 0.00758043
	LOSS [training: 0.8544243698838937 | validation: 0.9617557242405114]
	TIME [epoch: 8.92 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8828515219175825		[learning rate: 0.0075626]
		[batch 20/20] avg loss: 0.8946467373206097		[learning rate: 0.0075449]
	Learning Rate: 0.00754489
	LOSS [training: 0.888749129619096 | validation: 1.9332170844541994]
	TIME [epoch: 8.91 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9329521352884201		[learning rate: 0.0075272]
		[batch 20/20] avg loss: 0.723661101650832		[learning rate: 0.0075095]
	Learning Rate: 0.00750952
	LOSS [training: 0.8283066184696259 | validation: 0.41592926714174744]
	TIME [epoch: 8.93 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7678663539144306		[learning rate: 0.0074919]
		[batch 20/20] avg loss: 0.676044231456886		[learning rate: 0.0074743]
	Learning Rate: 0.00747431
	LOSS [training: 0.7219552926856584 | validation: 0.49215372427109805]
	TIME [epoch: 8.92 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7220413795040213		[learning rate: 0.0074568]
		[batch 20/20] avg loss: 0.859890731721616		[learning rate: 0.0074393]
	Learning Rate: 0.00743927
	LOSS [training: 0.7909660556128186 | validation: 0.4236317755702579]
	TIME [epoch: 8.9 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5379461440248893		[learning rate: 0.0074218]
		[batch 20/20] avg loss: 0.8203111895168217		[learning rate: 0.0074044]
	Learning Rate: 0.0074044
	LOSS [training: 0.6791286667708555 | validation: 0.5440583043661997]
	TIME [epoch: 8.91 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6455964402947745		[learning rate: 0.007387]
		[batch 20/20] avg loss: 0.8489071771047382		[learning rate: 0.0073697]
	Learning Rate: 0.00736969
	LOSS [training: 0.7472518086997563 | validation: 0.7025064267917209]
	TIME [epoch: 8.92 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/20] avg loss: 0.821456406329696		[learning rate: 0.0073524]
		[batch 20/20] avg loss: 0.8244152502492037		[learning rate: 0.0073351]
	Learning Rate: 0.00733514
	LOSS [training: 0.8229358282894497 | validation: 1.0692163723812116]
	TIME [epoch: 8.91 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6818235839981555		[learning rate: 0.0073179]
		[batch 20/20] avg loss: 0.86020653604189		[learning rate: 0.0073007]
	Learning Rate: 0.00730075
	LOSS [training: 0.7710150600200227 | validation: 0.4814183923113229]
	TIME [epoch: 8.92 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7286725053828059		[learning rate: 0.0072836]
		[batch 20/20] avg loss: 0.5431005675843024		[learning rate: 0.0072665]
	Learning Rate: 0.00726652
	LOSS [training: 0.635886536483554 | validation: 0.9240181070579596]
	TIME [epoch: 8.9 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6495733824600834		[learning rate: 0.0072495]
		[batch 20/20] avg loss: 0.6483291749439697		[learning rate: 0.0072325]
	Learning Rate: 0.00723246
	LOSS [training: 0.6489512787020266 | validation: 0.6939082749513277]
	TIME [epoch: 8.93 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8184059446282653		[learning rate: 0.0072155]
		[batch 20/20] avg loss: 0.7565600771599094		[learning rate: 0.0071985]
	Learning Rate: 0.00719855
	LOSS [training: 0.7874830108940875 | validation: 0.4534896062150121]
	TIME [epoch: 8.93 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/20] avg loss: 0.953795104647558		[learning rate: 0.0071817]
		[batch 20/20] avg loss: 0.7046852651743367		[learning rate: 0.0071648]
	Learning Rate: 0.0071648
	LOSS [training: 0.8292401849109474 | validation: 0.5487222894726553]
	TIME [epoch: 8.93 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0767258663330956		[learning rate: 0.007148]
		[batch 20/20] avg loss: 0.6399391303333593		[learning rate: 0.0071312]
	Learning Rate: 0.00713121
	LOSS [training: 0.8583324983332273 | validation: 0.4873429702348254]
	TIME [epoch: 8.92 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6556984156355267		[learning rate: 0.0071145]
		[batch 20/20] avg loss: 0.8877308260191175		[learning rate: 0.0070978]
	Learning Rate: 0.00709778
	LOSS [training: 0.771714620827322 | validation: 2.6265846459278928]
	TIME [epoch: 8.92 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0890075531799872		[learning rate: 0.0070811]
		[batch 20/20] avg loss: 0.6422345872813547		[learning rate: 0.0070645]
	Learning Rate: 0.0070645
	LOSS [training: 0.865621070230671 | validation: 0.4116503133320517]
	TIME [epoch: 8.95 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_84.pth
	Model improved!!!
EPOCH 85/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6815080636486357		[learning rate: 0.0070479]
		[batch 20/20] avg loss: 0.8822209200161281		[learning rate: 0.0070314]
	Learning Rate: 0.00703138
	LOSS [training: 0.7818644918323818 | validation: 0.5711271782346037]
	TIME [epoch: 8.93 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7977314660315676		[learning rate: 0.0070149]
		[batch 20/20] avg loss: 0.5995701843035108		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.6986508251675392 | validation: 0.6575803776320119]
	TIME [epoch: 8.88 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7975098668675564		[learning rate: 0.006982]
		[batch 20/20] avg loss: 0.6707968194039333		[learning rate: 0.0069656]
	Learning Rate: 0.00696561
	LOSS [training: 0.734153343135745 | validation: 0.7216578674604375]
	TIME [epoch: 8.92 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7049417094400163		[learning rate: 0.0069493]
		[batch 20/20] avg loss: 0.5534851375687247		[learning rate: 0.006933]
	Learning Rate: 0.00693295
	LOSS [training: 0.6292134235043706 | validation: 0.40364138438683084]
	TIME [epoch: 8.91 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_88.pth
	Model improved!!!
EPOCH 89/500:
	Training over batches...
		[batch 10/20] avg loss: 0.614816352917733		[learning rate: 0.0069167]
		[batch 20/20] avg loss: 0.7705910112501939		[learning rate: 0.0069005]
	Learning Rate: 0.00690045
	LOSS [training: 0.6927036820839635 | validation: 0.6865201834519945]
	TIME [epoch: 8.94 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6016701504446448		[learning rate: 0.0068843]
		[batch 20/20] avg loss: 0.6347285143986057		[learning rate: 0.0068681]
	Learning Rate: 0.0068681
	LOSS [training: 0.6181993324216253 | validation: 0.37733556107587823]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_90.pth
	Model improved!!!
EPOCH 91/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5129378323966263		[learning rate: 0.006852]
		[batch 20/20] avg loss: 0.5930819688430246		[learning rate: 0.0068359]
	Learning Rate: 0.0068359
	LOSS [training: 0.5530099006198255 | validation: 0.3782107356334174]
	TIME [epoch: 8.91 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5146553776565044		[learning rate: 0.0068199]
		[batch 20/20] avg loss: 0.615120446764983		[learning rate: 0.0068039]
	Learning Rate: 0.00680386
	LOSS [training: 0.5648879122107436 | validation: 0.5246634685673374]
	TIME [epoch: 8.92 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7075731306003518		[learning rate: 0.0067879]
		[batch 20/20] avg loss: 0.6286915027648572		[learning rate: 0.006772]
	Learning Rate: 0.00677196
	LOSS [training: 0.6681323166826044 | validation: 0.45386023860757696]
	TIME [epoch: 8.91 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5070678909944959		[learning rate: 0.0067561]
		[batch 20/20] avg loss: 0.479375642347066		[learning rate: 0.0067402]
	Learning Rate: 0.00674021
	LOSS [training: 0.49322176667078105 | validation: 0.38144697957438095]
	TIME [epoch: 8.94 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4874954224827398		[learning rate: 0.0067244]
		[batch 20/20] avg loss: 0.6213582439246206		[learning rate: 0.0067086]
	Learning Rate: 0.00670861
	LOSS [training: 0.5544268332036801 | validation: 0.6641484861735006]
	TIME [epoch: 8.93 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9095177694726162		[learning rate: 0.0066929]
		[batch 20/20] avg loss: 0.7715298384056638		[learning rate: 0.0066772]
	Learning Rate: 0.00667716
	LOSS [training: 0.8405238039391401 | validation: 0.4587752673529136]
	TIME [epoch: 8.93 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5226719241094406		[learning rate: 0.0066615]
		[batch 20/20] avg loss: 0.859074418880932		[learning rate: 0.0066459]
	Learning Rate: 0.00664586
	LOSS [training: 0.6908731714951862 | validation: 0.6868273836822347]
	TIME [epoch: 8.92 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6014495262214161		[learning rate: 0.0066303]
		[batch 20/20] avg loss: 0.45744927236303246		[learning rate: 0.0066147]
	Learning Rate: 0.0066147
	LOSS [training: 0.5294493992922242 | validation: 0.5791830294982658]
	TIME [epoch: 8.92 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/20] avg loss: 0.45019083890425204		[learning rate: 0.0065992]
		[batch 20/20] avg loss: 0.5359389036736099		[learning rate: 0.0065837]
	Learning Rate: 0.00658369
	LOSS [training: 0.4930648712889309 | validation: 0.6093933463450968]
	TIME [epoch: 8.92 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6324679323447505		[learning rate: 0.0065682]
		[batch 20/20] avg loss: 0.4671321829165157		[learning rate: 0.0065528]
	Learning Rate: 0.00655282
	LOSS [training: 0.549800057630633 | validation: 0.6862911230693618]
	TIME [epoch: 8.92 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5572680200724464		[learning rate: 0.0065374]
		[batch 20/20] avg loss: 0.4808651407033618		[learning rate: 0.0065221]
	Learning Rate: 0.0065221
	LOSS [training: 0.5190665803879041 | validation: 0.526294453586768]
	TIME [epoch: 8.9 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6930664308554226		[learning rate: 0.0065068]
		[batch 20/20] avg loss: 0.5118913880493555		[learning rate: 0.0064915]
	Learning Rate: 0.00649153
	LOSS [training: 0.6024789094523892 | validation: 0.8517150971423509]
	TIME [epoch: 8.9 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6167593358746651		[learning rate: 0.0064763]
		[batch 20/20] avg loss: 0.607727839794245		[learning rate: 0.0064611]
	Learning Rate: 0.0064611
	LOSS [training: 0.6122435878344552 | validation: 0.3187758672454182]
	TIME [epoch: 8.93 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_103.pth
	Model improved!!!
EPOCH 104/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4874249238142526		[learning rate: 0.0064459]
		[batch 20/20] avg loss: 0.49279129192300364		[learning rate: 0.0064308]
	Learning Rate: 0.0064308
	LOSS [training: 0.49010810786862813 | validation: 0.47596439087846787]
	TIME [epoch: 8.93 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4701932033001226		[learning rate: 0.0064157]
		[batch 20/20] avg loss: 0.6533549765660028		[learning rate: 0.0064007]
	Learning Rate: 0.00640066
	LOSS [training: 0.5617740899330627 | validation: 0.5185028376944436]
	TIME [epoch: 8.93 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4977515646209317		[learning rate: 0.0063856]
		[batch 20/20] avg loss: 0.5502817545011376		[learning rate: 0.0063706]
	Learning Rate: 0.00637065
	LOSS [training: 0.5240166595610346 | validation: 0.6317963447623973]
	TIME [epoch: 8.92 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/20] avg loss: 0.48355809048332316		[learning rate: 0.0063557]
		[batch 20/20] avg loss: 0.5489211214042333		[learning rate: 0.0063408]
	Learning Rate: 0.00634078
	LOSS [training: 0.5162396059437783 | validation: 0.6263954429414977]
	TIME [epoch: 8.93 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6054142581787163		[learning rate: 0.0063259]
		[batch 20/20] avg loss: 0.5786689110960296		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.5920415846373728 | validation: 0.3769280252481685]
	TIME [epoch: 8.94 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40337059663094327		[learning rate: 0.0062962]
		[batch 20/20] avg loss: 0.424226545100323		[learning rate: 0.0062815]
	Learning Rate: 0.00628147
	LOSS [training: 0.41379857086563315 | validation: 0.40906683491353596]
	TIME [epoch: 8.9 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5264812308016411		[learning rate: 0.0062667]
		[batch 20/20] avg loss: 0.5796357944430135		[learning rate: 0.006252]
	Learning Rate: 0.00625202
	LOSS [training: 0.5530585126223273 | validation: 0.3413812641325395]
	TIME [epoch: 8.91 sec]
EPOCH 111/500:
	Training over batches...
		[batch 10/20] avg loss: 0.503853368007486		[learning rate: 0.0062373]
		[batch 20/20] avg loss: 0.5413163449294881		[learning rate: 0.0062227]
	Learning Rate: 0.00622271
	LOSS [training: 0.5225848564684872 | validation: 0.3308369100763955]
	TIME [epoch: 8.91 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4583562364180688		[learning rate: 0.0062081]
		[batch 20/20] avg loss: 0.47999841795867526		[learning rate: 0.0061935]
	Learning Rate: 0.00619354
	LOSS [training: 0.469177327188372 | validation: 0.3175642438196467]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_112.pth
	Model improved!!!
EPOCH 113/500:
	Training over batches...
		[batch 10/20] avg loss: 0.43729153836483536		[learning rate: 0.006179]
		[batch 20/20] avg loss: 0.4959367476960962		[learning rate: 0.0061645]
	Learning Rate: 0.0061645
	LOSS [training: 0.46661414303046567 | validation: 0.553591361451147]
	TIME [epoch: 8.91 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5715337193007343		[learning rate: 0.00615]
		[batch 20/20] avg loss: 0.6518901391535207		[learning rate: 0.0061356]
	Learning Rate: 0.0061356
	LOSS [training: 0.6117119292271276 | validation: 0.6360373197238498]
	TIME [epoch: 8.9 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5365417672612218		[learning rate: 0.0061212]
		[batch 20/20] avg loss: 0.5008126590777082		[learning rate: 0.0061068]
	Learning Rate: 0.00610684
	LOSS [training: 0.518677213169465 | validation: 0.6241771010275972]
	TIME [epoch: 8.91 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5732996394799462		[learning rate: 0.0060925]
		[batch 20/20] avg loss: 0.5053667060757735		[learning rate: 0.0060782]
	Learning Rate: 0.00607821
	LOSS [training: 0.5393331727778599 | validation: 0.5093051195899078]
	TIME [epoch: 8.92 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5421989148178497		[learning rate: 0.0060639]
		[batch 20/20] avg loss: 0.44833752848535385		[learning rate: 0.0060497]
	Learning Rate: 0.00604971
	LOSS [training: 0.49526822165160167 | validation: 0.38390489274042083]
	TIME [epoch: 8.94 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/20] avg loss: 0.443344155618065		[learning rate: 0.0060355]
		[batch 20/20] avg loss: 0.4766452235473205		[learning rate: 0.0060213]
	Learning Rate: 0.00602135
	LOSS [training: 0.45999468958269285 | validation: 0.5810144144702571]
	TIME [epoch: 8.91 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/20] avg loss: 0.46106779568935197		[learning rate: 0.0060072]
		[batch 20/20] avg loss: 0.3892240926717729		[learning rate: 0.0059931]
	Learning Rate: 0.00599312
	LOSS [training: 0.42514594418056245 | validation: 0.30435392652280235]
	TIME [epoch: 8.92 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_119.pth
	Model improved!!!
EPOCH 120/500:
	Training over batches...
		[batch 10/20] avg loss: 0.43815626876148617		[learning rate: 0.0059791]
		[batch 20/20] avg loss: 0.5261642562047758		[learning rate: 0.005965]
	Learning Rate: 0.00596502
	LOSS [training: 0.4821602624831309 | validation: 0.3466666331692365]
	TIME [epoch: 8.89 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6111455644832351		[learning rate: 0.005951]
		[batch 20/20] avg loss: 0.5115159982642161		[learning rate: 0.0059371]
	Learning Rate: 0.00593706
	LOSS [training: 0.5613307813737256 | validation: 0.2422118326386062]
	TIME [epoch: 8.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_121.pth
	Model improved!!!
EPOCH 122/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4920290475480954		[learning rate: 0.0059231]
		[batch 20/20] avg loss: 0.4959148022348637		[learning rate: 0.0059092]
	Learning Rate: 0.00590923
	LOSS [training: 0.49397192489147973 | validation: 0.5861704912711327]
	TIME [epoch: 8.94 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4262401083468618		[learning rate: 0.0058954]
		[batch 20/20] avg loss: 0.4258195303309454		[learning rate: 0.0058815]
	Learning Rate: 0.00588152
	LOSS [training: 0.42602981933890377 | validation: 0.24484193086152337]
	TIME [epoch: 8.94 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/20] avg loss: 0.43912224505769687		[learning rate: 0.0058677]
		[batch 20/20] avg loss: 0.47558202681502093		[learning rate: 0.0058539]
	Learning Rate: 0.00585395
	LOSS [training: 0.457352135936359 | validation: 0.22600103561002816]
	TIME [epoch: 8.94 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_124.pth
	Model improved!!!
EPOCH 125/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44959771008725885		[learning rate: 0.0058402]
		[batch 20/20] avg loss: 0.445402512617011		[learning rate: 0.0058265]
	Learning Rate: 0.00582651
	LOSS [training: 0.44750011135213497 | validation: 0.5154191821066796]
	TIME [epoch: 8.96 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35791529274754963		[learning rate: 0.0058128]
		[batch 20/20] avg loss: 0.3807139807352869		[learning rate: 0.0057992]
	Learning Rate: 0.00579919
	LOSS [training: 0.3693146367414183 | validation: 0.44860765953593373]
	TIME [epoch: 8.96 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4192361672908656		[learning rate: 0.0057856]
		[batch 20/20] avg loss: 0.5994566089898542		[learning rate: 0.005772]
	Learning Rate: 0.005772
	LOSS [training: 0.5093463881403599 | validation: 0.39168016789339716]
	TIME [epoch: 8.97 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44726680539156066		[learning rate: 0.0057585]
		[batch 20/20] avg loss: 0.47328553485872565		[learning rate: 0.0057449]
	Learning Rate: 0.00574494
	LOSS [training: 0.4602761701251431 | validation: 0.42559469011170226]
	TIME [epoch: 8.94 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40451288276283126		[learning rate: 0.0057315]
		[batch 20/20] avg loss: 0.4912221667937047		[learning rate: 0.005718]
	Learning Rate: 0.00571801
	LOSS [training: 0.44786752477826797 | validation: 0.38932794632462875]
	TIME [epoch: 8.94 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3810939168574357		[learning rate: 0.0057046]
		[batch 20/20] avg loss: 0.5039068113322384		[learning rate: 0.0056912]
	Learning Rate: 0.0056912
	LOSS [training: 0.4425003640948371 | validation: 0.23996315067048046]
	TIME [epoch: 8.94 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3882351090138092		[learning rate: 0.0056778]
		[batch 20/20] avg loss: 0.3703033270951066		[learning rate: 0.0056645]
	Learning Rate: 0.00566452
	LOSS [training: 0.3792692180544579 | validation: 1.4678770745856857]
	TIME [epoch: 8.96 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6179467386333137		[learning rate: 0.0056512]
		[batch 20/20] avg loss: 0.3649021513457472		[learning rate: 0.005638]
	Learning Rate: 0.00563797
	LOSS [training: 0.4914244449895304 | validation: 0.7101183632586989]
	TIME [epoch: 8.94 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5249275189767244		[learning rate: 0.0056247]
		[batch 20/20] avg loss: 0.4921135892730698		[learning rate: 0.0056115]
	Learning Rate: 0.00561153
	LOSS [training: 0.5085205541248972 | validation: 0.7004393366076204]
	TIME [epoch: 8.92 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4711066497910757		[learning rate: 0.0055984]
		[batch 20/20] avg loss: 0.5635115932964115		[learning rate: 0.0055852]
	Learning Rate: 0.00558523
	LOSS [training: 0.5173091215437436 | validation: 0.533792189413024]
	TIME [epoch: 8.93 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/20] avg loss: 0.48192737889902093		[learning rate: 0.0055721]
		[batch 20/20] avg loss: 0.4008966561303426		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.44141201751468173 | validation: 0.32165941447367336]
	TIME [epoch: 8.94 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35920270973261814		[learning rate: 0.005546]
		[batch 20/20] avg loss: 0.4897276110195975		[learning rate: 0.005533]
	Learning Rate: 0.00553298
	LOSS [training: 0.42446516037610776 | validation: 0.6679894458057551]
	TIME [epoch: 8.94 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/20] avg loss: 0.48116300574968396		[learning rate: 0.00552]
		[batch 20/20] avg loss: 0.387282588778027		[learning rate: 0.005507]
	Learning Rate: 0.00550704
	LOSS [training: 0.4342227972638556 | validation: 0.6068372847224255]
	TIME [epoch: 8.92 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4011036820057153		[learning rate: 0.0054941]
		[batch 20/20] avg loss: 0.4315900416755817		[learning rate: 0.0054812]
	Learning Rate: 0.00548122
	LOSS [training: 0.4163468618406484 | validation: 0.4974108946503603]
	TIME [epoch: 8.91 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5166404552817461		[learning rate: 0.0054684]
		[batch 20/20] avg loss: 0.34384795187798745		[learning rate: 0.0054555]
	Learning Rate: 0.00545553
	LOSS [training: 0.4302442035798667 | validation: 0.22695453218396308]
	TIME [epoch: 8.91 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3255039240538026		[learning rate: 0.0054427]
		[batch 20/20] avg loss: 0.37400566515908584		[learning rate: 0.00543]
	Learning Rate: 0.00542995
	LOSS [training: 0.3497547946064442 | validation: 0.41029196122384914]
	TIME [epoch: 8.92 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3598735805390894		[learning rate: 0.0054172]
		[batch 20/20] avg loss: 0.4672659569581431		[learning rate: 0.0054045]
	Learning Rate: 0.00540449
	LOSS [training: 0.4135697687486163 | validation: 0.4791380238327077]
	TIME [epoch: 8.95 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4384587353600776		[learning rate: 0.0053918]
		[batch 20/20] avg loss: 0.4777244497528976		[learning rate: 0.0053792]
	Learning Rate: 0.00537916
	LOSS [training: 0.45809159255648757 | validation: 0.3668899084913958]
	TIME [epoch: 8.92 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3400855551589089		[learning rate: 0.0053665]
		[batch 20/20] avg loss: 0.6027203537624055		[learning rate: 0.0053539]
	Learning Rate: 0.00535394
	LOSS [training: 0.47140295446065716 | validation: 0.33871113340640663]
	TIME [epoch: 8.93 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3696564941485439		[learning rate: 0.0053414]
		[batch 20/20] avg loss: 0.46675108606753846		[learning rate: 0.0053288]
	Learning Rate: 0.00532884
	LOSS [training: 0.41820379010804115 | validation: 0.25048499049379574]
	TIME [epoch: 8.92 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34122085304810557		[learning rate: 0.0053163]
		[batch 20/20] avg loss: 0.3746449664766061		[learning rate: 0.0053039]
	Learning Rate: 0.00530386
	LOSS [training: 0.3579329097623558 | validation: 0.46570065399750205]
	TIME [epoch: 8.92 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40402848081002884		[learning rate: 0.0052914]
		[batch 20/20] avg loss: 0.42946537160383214		[learning rate: 0.005279]
	Learning Rate: 0.00527899
	LOSS [training: 0.41674692620693043 | validation: 0.356779803141969]
	TIME [epoch: 8.97 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44548457951671655		[learning rate: 0.0052666]
		[batch 20/20] avg loss: 0.5170967362774389		[learning rate: 0.0052542]
	Learning Rate: 0.00525424
	LOSS [training: 0.4812906578970776 | validation: 0.3284109859709395]
	TIME [epoch: 8.98 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32371006573326083		[learning rate: 0.0052419]
		[batch 20/20] avg loss: 0.4030755587309093		[learning rate: 0.0052296]
	Learning Rate: 0.00522961
	LOSS [training: 0.36339281223208497 | validation: 0.28716079691049434]
	TIME [epoch: 8.97 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33262310763883496		[learning rate: 0.0052173]
		[batch 20/20] avg loss: 0.3405767196251066		[learning rate: 0.0052051]
	Learning Rate: 0.00520509
	LOSS [training: 0.3365999136319707 | validation: 0.5236220646619755]
	TIME [epoch: 8.97 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4128318547572201		[learning rate: 0.0051929]
		[batch 20/20] avg loss: 0.46083919955131447		[learning rate: 0.0051807]
	Learning Rate: 0.00518069
	LOSS [training: 0.4368355271542672 | validation: 0.2961894754480959]
	TIME [epoch: 8.99 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29464471088177646		[learning rate: 0.0051685]
		[batch 20/20] avg loss: 0.377216586684478		[learning rate: 0.0051564]
	Learning Rate: 0.0051564
	LOSS [training: 0.3359306487831272 | validation: 0.39840590534869086]
	TIME [epoch: 8.98 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3919153949952668		[learning rate: 0.0051443]
		[batch 20/20] avg loss: 0.43212090726182034		[learning rate: 0.0051322]
	Learning Rate: 0.00513223
	LOSS [training: 0.41201815112854356 | validation: 0.24080349873215753]
	TIME [epoch: 8.97 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34414505754788655		[learning rate: 0.0051202]
		[batch 20/20] avg loss: 0.3071172980483069		[learning rate: 0.0051082]
	Learning Rate: 0.00510817
	LOSS [training: 0.32563117779809675 | validation: 0.514004351796204]
	TIME [epoch: 8.97 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/20] avg loss: 0.41073858190727003		[learning rate: 0.0050962]
		[batch 20/20] avg loss: 0.3478057640432027		[learning rate: 0.0050842]
	Learning Rate: 0.00508422
	LOSS [training: 0.3792721729752363 | validation: 0.17439325349288431]
	TIME [epoch: 8.97 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_154.pth
	Model improved!!!
EPOCH 155/500:
	Training over batches...
		[batch 10/20] avg loss: 0.45798157280419405		[learning rate: 0.0050723]
		[batch 20/20] avg loss: 0.3934509088735466		[learning rate: 0.0050604]
	Learning Rate: 0.00506039
	LOSS [training: 0.4257162408388703 | validation: 0.253265937700047]
	TIME [epoch: 8.97 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/20] avg loss: 0.304544483757945		[learning rate: 0.0050485]
		[batch 20/20] avg loss: 0.38452692483597956		[learning rate: 0.0050367]
	Learning Rate: 0.00503666
	LOSS [training: 0.34453570429696223 | validation: 0.25196258947675776]
	TIME [epoch: 8.97 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4983808786654208		[learning rate: 0.0050248]
		[batch 20/20] avg loss: 0.36481257223294816		[learning rate: 0.005013]
	Learning Rate: 0.00501305
	LOSS [training: 0.4315967254491846 | validation: 0.6559231568015633]
	TIME [epoch: 8.96 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5414046506141019		[learning rate: 0.0050013]
		[batch 20/20] avg loss: 0.3460612569541139		[learning rate: 0.0049895]
	Learning Rate: 0.00498955
	LOSS [training: 0.44373295378410804 | validation: 0.28751800268910943]
	TIME [epoch: 8.97 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29548868445736015		[learning rate: 0.0049778]
		[batch 20/20] avg loss: 0.4147518068083628		[learning rate: 0.0049662]
	Learning Rate: 0.00496616
	LOSS [training: 0.3551202456328615 | validation: 0.3615118228212295]
	TIME [epoch: 8.98 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/20] avg loss: 0.41409262348225484		[learning rate: 0.0049545]
		[batch 20/20] avg loss: 0.4465354011038323		[learning rate: 0.0049429]
	Learning Rate: 0.00494287
	LOSS [training: 0.43031401229304356 | validation: 0.33856355263414106]
	TIME [epoch: 8.97 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34768821993681104		[learning rate: 0.0049313]
		[batch 20/20] avg loss: 0.4076965516918062		[learning rate: 0.0049197]
	Learning Rate: 0.0049197
	LOSS [training: 0.3776923858143086 | validation: 0.3761227049820838]
	TIME [epoch: 8.97 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34893153811356786		[learning rate: 0.0049082]
		[batch 20/20] avg loss: 0.361801555125723		[learning rate: 0.0048966]
	Learning Rate: 0.00489664
	LOSS [training: 0.35536654661964545 | validation: 0.6061807081132542]
	TIME [epoch: 8.97 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35044720716746247		[learning rate: 0.0048851]
		[batch 20/20] avg loss: 0.28793831731297004		[learning rate: 0.0048737]
	Learning Rate: 0.00487368
	LOSS [training: 0.3191927622402163 | validation: 0.28613399538759793]
	TIME [epoch: 8.98 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3252445009655196		[learning rate: 0.0048622]
		[batch 20/20] avg loss: 0.3341022859693167		[learning rate: 0.0048508]
	Learning Rate: 0.00485083
	LOSS [training: 0.32967339346741814 | validation: 0.18204800927893022]
	TIME [epoch: 8.99 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2872471955382506		[learning rate: 0.0048394]
		[batch 20/20] avg loss: 0.3336438821430781		[learning rate: 0.0048281]
	Learning Rate: 0.00482809
	LOSS [training: 0.31044553884066434 | validation: 0.5519471465112749]
	TIME [epoch: 8.97 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36698036351800417		[learning rate: 0.0048168]
		[batch 20/20] avg loss: 0.42173683370621723		[learning rate: 0.0048055]
	Learning Rate: 0.00480546
	LOSS [training: 0.39435859861211064 | validation: 0.2141635920565201]
	TIME [epoch: 8.96 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4166172481103964		[learning rate: 0.0047942]
		[batch 20/20] avg loss: 0.26807168472261633		[learning rate: 0.0047829]
	Learning Rate: 0.00478293
	LOSS [training: 0.3423444664165064 | validation: 0.11121731452039055]
	TIME [epoch: 8.95 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_167.pth
	Model improved!!!
EPOCH 168/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3790023380624369		[learning rate: 0.0047717]
		[batch 20/20] avg loss: 0.3306301240084505		[learning rate: 0.0047605]
	Learning Rate: 0.00476051
	LOSS [training: 0.3548162310354437 | validation: 0.2503233274969629]
	TIME [epoch: 9 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33076697657584325		[learning rate: 0.0047493]
		[batch 20/20] avg loss: 0.38107389316409734		[learning rate: 0.0047382]
	Learning Rate: 0.00473819
	LOSS [training: 0.35592043486997027 | validation: 0.6137309746090781]
	TIME [epoch: 8.97 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3096285502337929		[learning rate: 0.0047271]
		[batch 20/20] avg loss: 0.40895813197545355		[learning rate: 0.004716]
	Learning Rate: 0.00471597
	LOSS [training: 0.35929334110462324 | validation: 0.3191700963603006]
	TIME [epoch: 8.96 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3244114828704482		[learning rate: 0.0047049]
		[batch 20/20] avg loss: 0.5276943621028568		[learning rate: 0.0046939]
	Learning Rate: 0.00469386
	LOSS [training: 0.42605292248665255 | validation: 0.28333928268062497]
	TIME [epoch: 8.95 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3571081467399879		[learning rate: 0.0046828]
		[batch 20/20] avg loss: 0.3100802368975156		[learning rate: 0.0046719]
	Learning Rate: 0.00467186
	LOSS [training: 0.3335941918187517 | validation: 0.2800883157513151]
	TIME [epoch: 8.97 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3885567479193154		[learning rate: 0.0046609]
		[batch 20/20] avg loss: 0.26109648726147794		[learning rate: 0.00465]
	Learning Rate: 0.00464996
	LOSS [training: 0.32482661759039666 | validation: 0.21400597926853102]
	TIME [epoch: 8.98 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2972068139294294		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.4185118508687296		[learning rate: 0.0046282]
	Learning Rate: 0.00462816
	LOSS [training: 0.35785933239907947 | validation: 0.30009646415369234]
	TIME [epoch: 8.96 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3557191879048127		[learning rate: 0.0046173]
		[batch 20/20] avg loss: 0.2883455891263401		[learning rate: 0.0046065]
	Learning Rate: 0.00460646
	LOSS [training: 0.32203238851557636 | validation: 0.3100473244647807]
	TIME [epoch: 8.96 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/20] avg loss: 0.45982544343522946		[learning rate: 0.0045956]
		[batch 20/20] avg loss: 0.36291941572784436		[learning rate: 0.0045849]
	Learning Rate: 0.00458486
	LOSS [training: 0.4113724295815369 | validation: 0.29491344954067356]
	TIME [epoch: 8.94 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/20] avg loss: 0.39159866730271803		[learning rate: 0.0045741]
		[batch 20/20] avg loss: 0.3607376630128473		[learning rate: 0.0045634]
	Learning Rate: 0.00456337
	LOSS [training: 0.37616816515778273 | validation: 0.23919006497628714]
	TIME [epoch: 8.93 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3314379711855665		[learning rate: 0.0045527]
		[batch 20/20] avg loss: 0.47484030713378667		[learning rate: 0.004542]
	Learning Rate: 0.00454198
	LOSS [training: 0.4031391391596766 | validation: 0.6357986322212633]
	TIME [epoch: 8.94 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36236183602256494		[learning rate: 0.0045313]
		[batch 20/20] avg loss: 0.43302726049865503		[learning rate: 0.0045207]
	Learning Rate: 0.00452068
	LOSS [training: 0.39769454826060996 | validation: 0.32477119292543555]
	TIME [epoch: 8.95 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/20] avg loss: 0.336144074820999		[learning rate: 0.0045101]
		[batch 20/20] avg loss: 0.3256509055784507		[learning rate: 0.0044995]
	Learning Rate: 0.00449949
	LOSS [training: 0.3308974901997248 | validation: 0.3396366053989447]
	TIME [epoch: 8.94 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3000990487013287		[learning rate: 0.0044889]
		[batch 20/20] avg loss: 0.4448638933520567		[learning rate: 0.0044784]
	Learning Rate: 0.0044784
	LOSS [training: 0.3724814710266927 | validation: 0.15839683028620719]
	TIME [epoch: 8.93 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3035126548849396		[learning rate: 0.0044679]
		[batch 20/20] avg loss: 0.29020987877653615		[learning rate: 0.0044574]
	Learning Rate: 0.0044574
	LOSS [training: 0.2968612668307379 | validation: 0.2999019693591947]
	TIME [epoch: 8.97 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3250430515376247		[learning rate: 0.0044469]
		[batch 20/20] avg loss: 0.2438396083268879		[learning rate: 0.0044365]
	Learning Rate: 0.0044365
	LOSS [training: 0.28444132993225624 | validation: 0.294591805004555]
	TIME [epoch: 8.93 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3751089523056656		[learning rate: 0.0044261]
		[batch 20/20] avg loss: 0.41000661623990986		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.39255778427278776 | validation: 0.37931818317598287]
	TIME [epoch: 8.93 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3105600479952089		[learning rate: 0.0044053]
		[batch 20/20] avg loss: 0.2811715868076412		[learning rate: 0.004395]
	Learning Rate: 0.004395
	LOSS [training: 0.29586581740142504 | validation: 0.1921777636687227]
	TIME [epoch: 8.93 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44747386055351457		[learning rate: 0.0043847]
		[batch 20/20] avg loss: 0.2766909156048374		[learning rate: 0.0043744]
	Learning Rate: 0.0043744
	LOSS [training: 0.362082388079176 | validation: 0.5033405761763093]
	TIME [epoch: 8.93 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3190390207690439		[learning rate: 0.0043641]
		[batch 20/20] avg loss: 0.3501317477031333		[learning rate: 0.0043539]
	Learning Rate: 0.00435389
	LOSS [training: 0.33458538423608863 | validation: 0.2574554394272222]
	TIME [epoch: 8.93 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2969347546559403		[learning rate: 0.0043437]
		[batch 20/20] avg loss: 0.2724909785190971		[learning rate: 0.0043335]
	Learning Rate: 0.00433348
	LOSS [training: 0.28471286658751865 | validation: 0.1677195844736916]
	TIME [epoch: 8.91 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2999705994221452		[learning rate: 0.0043233]
		[batch 20/20] avg loss: 0.4428693383944952		[learning rate: 0.0043132]
	Learning Rate: 0.00431316
	LOSS [training: 0.37141996890832024 | validation: 0.18595975266722622]
	TIME [epoch: 8.91 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3124030968250567		[learning rate: 0.004303]
		[batch 20/20] avg loss: 0.3660779005984138		[learning rate: 0.0042929]
	Learning Rate: 0.00429294
	LOSS [training: 0.33924049871173517 | validation: 0.3058798454870256]
	TIME [epoch: 8.92 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31501312515442725		[learning rate: 0.0042829]
		[batch 20/20] avg loss: 0.26575746994838095		[learning rate: 0.0042728]
	Learning Rate: 0.00427282
	LOSS [training: 0.2903852975514041 | validation: 0.28451087154590143]
	TIME [epoch: 8.94 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3264435830642895		[learning rate: 0.0042628]
		[batch 20/20] avg loss: 0.24989073293301045		[learning rate: 0.0042528]
	Learning Rate: 0.00425279
	LOSS [training: 0.28816715799865006 | validation: 0.3317245191881257]
	TIME [epoch: 8.94 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2652468772849116		[learning rate: 0.0042428]
		[batch 20/20] avg loss: 0.27988756485993294		[learning rate: 0.0042328]
	Learning Rate: 0.00423285
	LOSS [training: 0.27256722107242226 | validation: 0.19347499742397944]
	TIME [epoch: 8.93 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/20] avg loss: 0.38418605270183603		[learning rate: 0.0042229]
		[batch 20/20] avg loss: 0.3719136335289494		[learning rate: 0.004213]
	Learning Rate: 0.004213
	LOSS [training: 0.37804984311539264 | validation: 0.2076901005949673]
	TIME [epoch: 8.92 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24147174509674268		[learning rate: 0.0042031]
		[batch 20/20] avg loss: 0.26212924990407227		[learning rate: 0.0041933]
	Learning Rate: 0.00419325
	LOSS [training: 0.25180049750040745 | validation: 0.31545333338520415]
	TIME [epoch: 8.91 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2725786265740066		[learning rate: 0.0041834]
		[batch 20/20] avg loss: 0.3604362102505624		[learning rate: 0.0041736]
	Learning Rate: 0.00417359
	LOSS [training: 0.3165074184122844 | validation: 0.3165815355077927]
	TIME [epoch: 8.93 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3431260253796954		[learning rate: 0.0041638]
		[batch 20/20] avg loss: 0.2987143414799714		[learning rate: 0.004154]
	Learning Rate: 0.00415403
	LOSS [training: 0.32092018342983336 | validation: 0.32037020447264064]
	TIME [epoch: 8.92 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30114835293235126		[learning rate: 0.0041443]
		[batch 20/20] avg loss: 0.33579276105265915		[learning rate: 0.0041346]
	Learning Rate: 0.00413455
	LOSS [training: 0.3184705569925052 | validation: 0.27892784443176266]
	TIME [epoch: 8.92 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26706429210072447		[learning rate: 0.0041249]
		[batch 20/20] avg loss: 0.29406385830481746		[learning rate: 0.0041152]
	Learning Rate: 0.00411517
	LOSS [training: 0.28056407520277094 | validation: 0.21980567801915746]
	TIME [epoch: 8.91 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3242130046293211		[learning rate: 0.0041055]
		[batch 20/20] avg loss: 0.28160496380212463		[learning rate: 0.0040959]
	Learning Rate: 0.00409588
	LOSS [training: 0.3029089842157229 | validation: 0.3868273160059394]
	TIME [epoch: 8.92 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26941683702639235		[learning rate: 0.0040863]
		[batch 20/20] avg loss: 0.4126077783755333		[learning rate: 0.0040767]
	Learning Rate: 0.00407667
	LOSS [training: 0.3410123077009629 | validation: 0.3845087546882009]
	TIME [epoch: 8.96 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3142215300611221		[learning rate: 0.0040671]
		[batch 20/20] avg loss: 0.32925750311954227		[learning rate: 0.0040576]
	Learning Rate: 0.00405756
	LOSS [training: 0.3217395165903322 | validation: 0.3287398713468048]
	TIME [epoch: 8.98 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34899095207076813		[learning rate: 0.004048]
		[batch 20/20] avg loss: 0.24568600859320688		[learning rate: 0.0040385]
	Learning Rate: 0.00403854
	LOSS [training: 0.2973384803319875 | validation: 0.5711301532370914]
	TIME [epoch: 8.97 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2821716530257287		[learning rate: 0.0040291]
		[batch 20/20] avg loss: 0.29767049717770766		[learning rate: 0.0040196]
	Learning Rate: 0.00401961
	LOSS [training: 0.2899210751017182 | validation: 0.32604490376016293]
	TIME [epoch: 8.97 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29246491052722956		[learning rate: 0.0040102]
		[batch 20/20] avg loss: 0.30316045681420684		[learning rate: 0.0040008]
	Learning Rate: 0.00400076
	LOSS [training: 0.29781268367071817 | validation: 0.38340550172853066]
	TIME [epoch: 8.96 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/20] avg loss: 0.47264725469263863		[learning rate: 0.0039914]
		[batch 20/20] avg loss: 0.3282565016475062		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.4004518781700724 | validation: 0.15892239203686662]
	TIME [epoch: 8.98 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24466161044066972		[learning rate: 0.0039727]
		[batch 20/20] avg loss: 0.3235280223408361		[learning rate: 0.0039633]
	Learning Rate: 0.00396334
	LOSS [training: 0.28409481639075296 | validation: 0.23492172811858994]
	TIME [epoch: 8.96 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27100472761717465		[learning rate: 0.003954]
		[batch 20/20] avg loss: 0.33952407004658386		[learning rate: 0.0039448]
	Learning Rate: 0.00394476
	LOSS [training: 0.3052643988318793 | validation: 0.159277485120876]
	TIME [epoch: 8.95 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27691678085645727		[learning rate: 0.0039355]
		[batch 20/20] avg loss: 0.24457879091812962		[learning rate: 0.0039263]
	Learning Rate: 0.00392627
	LOSS [training: 0.2607477858872934 | validation: 0.13660196911566155]
	TIME [epoch: 8.97 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22631400402860832		[learning rate: 0.0039171]
		[batch 20/20] avg loss: 0.29799335199435834		[learning rate: 0.0039079]
	Learning Rate: 0.00390786
	LOSS [training: 0.2621536780114833 | validation: 0.3196520690265484]
	TIME [epoch: 8.97 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34769411916860704		[learning rate: 0.0038987]
		[batch 20/20] avg loss: 0.34077726065832936		[learning rate: 0.0038895]
	Learning Rate: 0.00388954
	LOSS [training: 0.34423568991346826 | validation: 0.24774293149020654]
	TIME [epoch: 8.97 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/20] avg loss: 0.300787144321332		[learning rate: 0.0038804]
		[batch 20/20] avg loss: 0.2788674301858768		[learning rate: 0.0038713]
	Learning Rate: 0.0038713
	LOSS [training: 0.2898272872536044 | validation: 0.2318088637735832]
	TIME [epoch: 8.96 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2763760026175683		[learning rate: 0.0038622]
		[batch 20/20] avg loss: 0.2769291544825295		[learning rate: 0.0038532]
	Learning Rate: 0.00385315
	LOSS [training: 0.27665257855004893 | validation: 0.4744631542861702]
	TIME [epoch: 8.96 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2538042549874337		[learning rate: 0.0038441]
		[batch 20/20] avg loss: 0.21479132585941335		[learning rate: 0.0038351]
	Learning Rate: 0.00383509
	LOSS [training: 0.23429779042342352 | validation: 0.9612550043796998]
	TIME [epoch: 8.96 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3569362837394513		[learning rate: 0.0038261]
		[batch 20/20] avg loss: 0.2900945209821109		[learning rate: 0.0038171]
	Learning Rate: 0.00381711
	LOSS [training: 0.3235154023607811 | validation: 0.22031765406892695]
	TIME [epoch: 8.98 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21926110050476916		[learning rate: 0.0038082]
		[batch 20/20] avg loss: 0.431678464550763		[learning rate: 0.0037992]
	Learning Rate: 0.00379921
	LOSS [training: 0.32546978252776604 | validation: 0.33799988156224336]
	TIME [epoch: 8.97 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3179758295213893		[learning rate: 0.0037903]
		[batch 20/20] avg loss: 0.22453582040056172		[learning rate: 0.0037814]
	Learning Rate: 0.0037814
	LOSS [training: 0.27125582496097544 | validation: 0.14346575986701085]
	TIME [epoch: 8.94 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2366032060336316		[learning rate: 0.0037725]
		[batch 20/20] avg loss: 0.22192763684119812		[learning rate: 0.0037637]
	Learning Rate: 0.00376368
	LOSS [training: 0.22926542143741485 | validation: 0.20575054552678018]
	TIME [epoch: 8.92 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22108231460832517		[learning rate: 0.0037548]
		[batch 20/20] avg loss: 0.25202427299240215		[learning rate: 0.003746]
	Learning Rate: 0.00374603
	LOSS [training: 0.2365532938003637 | validation: 0.2721381805173569]
	TIME [epoch: 8.95 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2808158831488698		[learning rate: 0.0037372]
		[batch 20/20] avg loss: 0.20747354009524543		[learning rate: 0.0037285]
	Learning Rate: 0.00372847
	LOSS [training: 0.24414471162205764 | validation: 0.2974722086235488]
	TIME [epoch: 8.94 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3204881373480347		[learning rate: 0.0037197]
		[batch 20/20] avg loss: 0.21476044261853966		[learning rate: 0.003711]
	Learning Rate: 0.00371099
	LOSS [training: 0.26762428998328713 | validation: 0.27611600044156187]
	TIME [epoch: 8.94 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24602938582277326		[learning rate: 0.0037023]
		[batch 20/20] avg loss: 0.2829618344870289		[learning rate: 0.0036936]
	Learning Rate: 0.00369359
	LOSS [training: 0.2644956101549011 | validation: 0.15830303696132028]
	TIME [epoch: 8.91 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21864194891795424		[learning rate: 0.0036849]
		[batch 20/20] avg loss: 0.21542398599402968		[learning rate: 0.0036763]
	Learning Rate: 0.00367628
	LOSS [training: 0.21703296745599193 | validation: 0.2458078617353155]
	TIME [epoch: 8.94 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32197623742467646		[learning rate: 0.0036676]
		[batch 20/20] avg loss: 0.27738493412039034		[learning rate: 0.003659]
	Learning Rate: 0.00365904
	LOSS [training: 0.29968058577253337 | validation: 0.15916858780575582]
	TIME [epoch: 8.95 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22099051001645406		[learning rate: 0.0036505]
		[batch 20/20] avg loss: 0.2935496814619887		[learning rate: 0.0036419]
	Learning Rate: 0.00364189
	LOSS [training: 0.2572700957392214 | validation: 0.22177086340919944]
	TIME [epoch: 8.94 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24801105564842985		[learning rate: 0.0036333]
		[batch 20/20] avg loss: 0.24794070373382202		[learning rate: 0.0036248]
	Learning Rate: 0.00362481
	LOSS [training: 0.247975879691126 | validation: 0.18739242250611254]
	TIME [epoch: 8.93 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2088200627615863		[learning rate: 0.0036163]
		[batch 20/20] avg loss: 0.2381788790963449		[learning rate: 0.0036078]
	Learning Rate: 0.00360782
	LOSS [training: 0.22349947092896563 | validation: 0.15562458224955697]
	TIME [epoch: 8.95 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22323470915154378		[learning rate: 0.0035994]
		[batch 20/20] avg loss: 0.2339215056785368		[learning rate: 0.0035909]
	Learning Rate: 0.00359091
	LOSS [training: 0.22857810741504028 | validation: 0.4170155892104322]
	TIME [epoch: 8.93 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2936312844924477		[learning rate: 0.0035825]
		[batch 20/20] avg loss: 0.25488386080708797		[learning rate: 0.0035741]
	Learning Rate: 0.00357407
	LOSS [training: 0.27425757264976774 | validation: 0.20100310370871352]
	TIME [epoch: 8.98 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3150832956875298		[learning rate: 0.0035657]
		[batch 20/20] avg loss: 0.2262092548258107		[learning rate: 0.0035573]
	Learning Rate: 0.00355732
	LOSS [training: 0.27064627525667023 | validation: 0.14561023863897296]
	TIME [epoch: 8.94 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20435025822343694		[learning rate: 0.003549]
		[batch 20/20] avg loss: 0.32035031947262055		[learning rate: 0.0035406]
	Learning Rate: 0.00354064
	LOSS [training: 0.26235028884802863 | validation: 0.22390993327818876]
	TIME [epoch: 8.93 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26806549534318347		[learning rate: 0.0035323]
		[batch 20/20] avg loss: 0.21407992086557376		[learning rate: 0.003524]
	Learning Rate: 0.00352404
	LOSS [training: 0.24107270810437859 | validation: 0.17008583870826086]
	TIME [epoch: 8.95 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21702512344718777		[learning rate: 0.0035158]
		[batch 20/20] avg loss: 0.47693206785981535		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.34697859565350153 | validation: 0.5895183102892634]
	TIME [epoch: 8.95 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2995194276808827		[learning rate: 0.0034993]
		[batch 20/20] avg loss: 0.25241932269124134		[learning rate: 0.0034911]
	Learning Rate: 0.00349107
	LOSS [training: 0.275969375186062 | validation: 0.19616192348925246]
	TIME [epoch: 8.96 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3353986927517413		[learning rate: 0.0034829]
		[batch 20/20] avg loss: 0.2635860815673428		[learning rate: 0.0034747]
	Learning Rate: 0.00347471
	LOSS [training: 0.2994923871595421 | validation: 0.24658925106029295]
	TIME [epoch: 8.95 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26166690209028676		[learning rate: 0.0034666]
		[batch 20/20] avg loss: 0.2585090104899356		[learning rate: 0.0034584]
	Learning Rate: 0.00345842
	LOSS [training: 0.2600879562901112 | validation: 0.27109722229551714]
	TIME [epoch: 8.96 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21929798370002346		[learning rate: 0.0034503]
		[batch 20/20] avg loss: 0.21268347523573902		[learning rate: 0.0034422]
	Learning Rate: 0.00344221
	LOSS [training: 0.21599072946788125 | validation: 0.19303085907839412]
	TIME [epoch: 8.93 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23449389250944183		[learning rate: 0.0034341]
		[batch 20/20] avg loss: 0.23093105478188097		[learning rate: 0.0034261]
	Learning Rate: 0.00342607
	LOSS [training: 0.23271247364566144 | validation: 0.1814511323342649]
	TIME [epoch: 8.96 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2259505673920227		[learning rate: 0.003418]
		[batch 20/20] avg loss: 0.2947669356866215		[learning rate: 0.00341]
	Learning Rate: 0.00341001
	LOSS [training: 0.2603587515393221 | validation: 0.22946994342090904]
	TIME [epoch: 8.97 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3121350903828512		[learning rate: 0.003402]
		[batch 20/20] avg loss: 0.26597800567157515		[learning rate: 0.003394]
	Learning Rate: 0.00339402
	LOSS [training: 0.28905654802721314 | validation: 0.2530199270025884]
	TIME [epoch: 8.93 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2648668403363462		[learning rate: 0.0033861]
		[batch 20/20] avg loss: 0.26057393206877033		[learning rate: 0.0033781]
	Learning Rate: 0.00337811
	LOSS [training: 0.26272038620255833 | validation: 0.2649700972794228]
	TIME [epoch: 8.95 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27726745881524895		[learning rate: 0.0033702]
		[batch 20/20] avg loss: 0.20789702466377408		[learning rate: 0.0033623]
	Learning Rate: 0.00336227
	LOSS [training: 0.2425822417395115 | validation: 0.31570085447977014]
	TIME [epoch: 8.94 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22964074116055322		[learning rate: 0.0033544]
		[batch 20/20] avg loss: 0.3418620487475198		[learning rate: 0.0033465]
	Learning Rate: 0.00334651
	LOSS [training: 0.2857513949540365 | validation: 0.12649813495399015]
	TIME [epoch: 8.96 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18472615074522108		[learning rate: 0.0033387]
		[batch 20/20] avg loss: 0.2030451787145887		[learning rate: 0.0033308]
	Learning Rate: 0.00333082
	LOSS [training: 0.19388566472990493 | validation: 0.35400723105483745]
	TIME [epoch: 8.95 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25478067968675766		[learning rate: 0.003323]
		[batch 20/20] avg loss: 0.18502734479774713		[learning rate: 0.0033152]
	Learning Rate: 0.0033152
	LOSS [training: 0.21990401224225242 | validation: 0.11265247592828126]
	TIME [epoch: 8.95 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23821479520576108		[learning rate: 0.0033074]
		[batch 20/20] avg loss: 0.34941613060043886		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.2938154629030999 | validation: 0.3815898013709857]
	TIME [epoch: 8.94 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3728065704090006		[learning rate: 0.0032919]
		[batch 20/20] avg loss: 0.252204532669784		[learning rate: 0.0032842]
	Learning Rate: 0.00328419
	LOSS [training: 0.31250555153939236 | validation: 0.4123875697355047]
	TIME [epoch: 8.94 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3249375181906874		[learning rate: 0.0032765]
		[batch 20/20] avg loss: 0.20185803677432848		[learning rate: 0.0032688]
	Learning Rate: 0.0032688
	LOSS [training: 0.2633977774825079 | validation: 0.14971011955927813]
	TIME [epoch: 8.97 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2562057578776936		[learning rate: 0.0032611]
		[batch 20/20] avg loss: 0.1867068762309457		[learning rate: 0.0032535]
	Learning Rate: 0.00325347
	LOSS [training: 0.22145631705431962 | validation: 0.16265382744438833]
	TIME [epoch: 8.96 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18237673077262834		[learning rate: 0.0032458]
		[batch 20/20] avg loss: 0.20764179795246193		[learning rate: 0.0032382]
	Learning Rate: 0.00323822
	LOSS [training: 0.19500926436254512 | validation: 0.37524482755660044]
	TIME [epoch: 8.95 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21489124663646875		[learning rate: 0.0032306]
		[batch 20/20] avg loss: 0.29983821075687744		[learning rate: 0.003223]
	Learning Rate: 0.00322304
	LOSS [training: 0.25736472869667315 | validation: 0.22248494545512648]
	TIME [epoch: 8.95 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23425023824535546		[learning rate: 0.0032155]
		[batch 20/20] avg loss: 0.1902905347555282		[learning rate: 0.0032079]
	Learning Rate: 0.00320793
	LOSS [training: 0.21227038650044183 | validation: 0.2613664568969493]
	TIME [epoch: 8.95 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/20] avg loss: 0.183879527056234		[learning rate: 0.0032004]
		[batch 20/20] avg loss: 0.215259095438255		[learning rate: 0.0031929]
	Learning Rate: 0.00319289
	LOSS [training: 0.1995693112472445 | validation: 0.18184259843629147]
	TIME [epoch: 8.95 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2209736924152057		[learning rate: 0.0031854]
		[batch 20/20] avg loss: 0.16735007298505747		[learning rate: 0.0031779]
	Learning Rate: 0.00317792
	LOSS [training: 0.19416188270013157 | validation: 0.2056664909012173]
	TIME [epoch: 8.95 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2745405340396227		[learning rate: 0.0031705]
		[batch 20/20] avg loss: 0.1629436169381488		[learning rate: 0.003163]
	Learning Rate: 0.00316302
	LOSS [training: 0.21874207548888572 | validation: 0.14217025681102566]
	TIME [epoch: 8.94 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23474219034825397		[learning rate: 0.0031556]
		[batch 20/20] avg loss: 0.20860799546404288		[learning rate: 0.0031482]
	Learning Rate: 0.00314819
	LOSS [training: 0.22167509290614834 | validation: 0.16766031621291988]
	TIME [epoch: 8.95 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16940486757684417		[learning rate: 0.0031408]
		[batch 20/20] avg loss: 0.2944593662032934		[learning rate: 0.0031334]
	Learning Rate: 0.00313343
	LOSS [training: 0.23193211689006876 | validation: 0.1483676485536442]
	TIME [epoch: 8.95 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22707958489617147		[learning rate: 0.0031261]
		[batch 20/20] avg loss: 0.20508250601196637		[learning rate: 0.0031187]
	Learning Rate: 0.00311874
	LOSS [training: 0.21608104545406892 | validation: 0.25575984085835163]
	TIME [epoch: 8.94 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24992334483752804		[learning rate: 0.0031114]
		[batch 20/20] avg loss: 0.2775461363256362		[learning rate: 0.0031041]
	Learning Rate: 0.00310412
	LOSS [training: 0.26373474058158214 | validation: 0.31116715685742297]
	TIME [epoch: 8.94 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23853533107375763		[learning rate: 0.0030968]
		[batch 20/20] avg loss: 0.2586565918817742		[learning rate: 0.0030896]
	Learning Rate: 0.00308957
	LOSS [training: 0.24859596147776591 | validation: 0.292127707572136]
	TIME [epoch: 8.94 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23253289559006746		[learning rate: 0.0030823]
		[batch 20/20] avg loss: 0.26289879254250936		[learning rate: 0.0030751]
	Learning Rate: 0.00307509
	LOSS [training: 0.24771584406628838 | validation: 0.22344390587233676]
	TIME [epoch: 8.95 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19664733925616207		[learning rate: 0.0030679]
		[batch 20/20] avg loss: 0.24603255494313897		[learning rate: 0.0030607]
	Learning Rate: 0.00306067
	LOSS [training: 0.22133994709965057 | validation: 0.17190352976512485]
	TIME [epoch: 8.96 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31265115988440506		[learning rate: 0.0030535]
		[batch 20/20] avg loss: 0.4225865363482984		[learning rate: 0.0030463]
	Learning Rate: 0.00304632
	LOSS [training: 0.36761884811635176 | validation: 0.3485792800934736]
	TIME [epoch: 8.96 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25751248484022127		[learning rate: 0.0030392]
		[batch 20/20] avg loss: 0.2570187800028822		[learning rate: 0.003032]
	Learning Rate: 0.00303204
	LOSS [training: 0.2572656324215517 | validation: 0.23445497278209948]
	TIME [epoch: 8.96 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24583238252484704		[learning rate: 0.0030249]
		[batch 20/20] avg loss: 0.28816876820370185		[learning rate: 0.0030178]
	Learning Rate: 0.00301782
	LOSS [training: 0.2670005753642745 | validation: 0.15434738785041946]
	TIME [epoch: 8.94 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21952263258222246		[learning rate: 0.0030107]
		[batch 20/20] avg loss: 0.2443325994699538		[learning rate: 0.0030037]
	Learning Rate: 0.00300368
	LOSS [training: 0.23192761602608808 | validation: 0.22858437594766937]
	TIME [epoch: 8.98 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19687022857517805		[learning rate: 0.0029966]
		[batch 20/20] avg loss: 0.200021645262549		[learning rate: 0.0029896]
	Learning Rate: 0.00298959
	LOSS [training: 0.19844593691886353 | validation: 0.24171314307049152]
	TIME [epoch: 8.96 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19753453633326476		[learning rate: 0.0029826]
		[batch 20/20] avg loss: 0.16428658031895585		[learning rate: 0.0029756]
	Learning Rate: 0.00297558
	LOSS [training: 0.1809105583261103 | validation: 0.2610867499701749]
	TIME [epoch: 8.96 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18231382635839144		[learning rate: 0.0029686]
		[batch 20/20] avg loss: 0.17095610495324057		[learning rate: 0.0029616]
	Learning Rate: 0.00296163
	LOSS [training: 0.176634965655816 | validation: 0.21529468377407668]
	TIME [epoch: 8.95 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2643998022490979		[learning rate: 0.0029547]
		[batch 20/20] avg loss: 0.19029184005546623		[learning rate: 0.0029477]
	Learning Rate: 0.00294774
	LOSS [training: 0.22734582115228208 | validation: 0.16857176181729486]
	TIME [epoch: 8.96 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20924532497326315		[learning rate: 0.0029408]
		[batch 20/20] avg loss: 0.2423169994952707		[learning rate: 0.0029339]
	Learning Rate: 0.00293393
	LOSS [training: 0.22578116223426684 | validation: 0.27754570688251223]
	TIME [epoch: 8.99 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2081099889460219		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.19556210560978693		[learning rate: 0.0029202]
	Learning Rate: 0.00292017
	LOSS [training: 0.20183604727790444 | validation: 0.3119175587802712]
	TIME [epoch: 8.98 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2538732593502234		[learning rate: 0.0029133]
		[batch 20/20] avg loss: 0.19342211977075754		[learning rate: 0.0029065]
	Learning Rate: 0.00290648
	LOSS [training: 0.22364768956049047 | validation: 0.21288656797889574]
	TIME [epoch: 8.96 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2106505551755659		[learning rate: 0.0028997]
		[batch 20/20] avg loss: 0.24117399226375422		[learning rate: 0.0028929]
	Learning Rate: 0.00289285
	LOSS [training: 0.2259122737196601 | validation: 0.24920267331141316]
	TIME [epoch: 8.96 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2510822585400726		[learning rate: 0.0028861]
		[batch 20/20] avg loss: 0.23482380124260263		[learning rate: 0.0028793]
	Learning Rate: 0.00287929
	LOSS [training: 0.2429530298913376 | validation: 0.09959577836666599]
	TIME [epoch: 8.95 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_275.pth
	Model improved!!!
EPOCH 276/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1704069275167828		[learning rate: 0.0028725]
		[batch 20/20] avg loss: 0.23438733763767142		[learning rate: 0.0028658]
	Learning Rate: 0.00286579
	LOSS [training: 0.20239713257722708 | validation: 0.2862324257023021]
	TIME [epoch: 8.98 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29880220795197265		[learning rate: 0.0028591]
		[batch 20/20] avg loss: 0.24680463690402976		[learning rate: 0.0028524]
	Learning Rate: 0.00285236
	LOSS [training: 0.2728034224280012 | validation: 0.10782751621144548]
	TIME [epoch: 8.97 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21912476541278098		[learning rate: 0.0028457]
		[batch 20/20] avg loss: 0.18873199357865938		[learning rate: 0.002839]
	Learning Rate: 0.00283899
	LOSS [training: 0.20392837949572015 | validation: 0.09956236786077775]
	TIME [epoch: 8.98 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_278.pth
	Model improved!!!
EPOCH 279/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19504359873298432		[learning rate: 0.0028323]
		[batch 20/20] avg loss: 0.21104479456419495		[learning rate: 0.0028257]
	Learning Rate: 0.00282568
	LOSS [training: 0.20304419664858964 | validation: 0.22673995759090704]
	TIME [epoch: 8.96 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1935824457970859		[learning rate: 0.002819]
		[batch 20/20] avg loss: 0.184657599900914		[learning rate: 0.0028124]
	Learning Rate: 0.00281243
	LOSS [training: 0.18912002284899992 | validation: 0.2504988946620946]
	TIME [epoch: 8.99 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2978180425445803		[learning rate: 0.0028058]
		[batch 20/20] avg loss: 0.2623680041777021		[learning rate: 0.0027992]
	Learning Rate: 0.00279924
	LOSS [training: 0.2800930233611411 | validation: 0.16934332003873298]
	TIME [epoch: 8.98 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1947332923068185		[learning rate: 0.0027927]
		[batch 20/20] avg loss: 0.19328486419204616		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.1940090782494323 | validation: 0.17339825919965188]
	TIME [epoch: 8.97 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1771102199662764		[learning rate: 0.0027796]
		[batch 20/20] avg loss: 0.1462629452772444		[learning rate: 0.0027731]
	Learning Rate: 0.00277306
	LOSS [training: 0.1616865826217604 | validation: 0.13085807607955677]
	TIME [epoch: 8.97 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/20] avg loss: 0.181374852665386		[learning rate: 0.0027666]
		[batch 20/20] avg loss: 0.18986613520889223		[learning rate: 0.0027601]
	Learning Rate: 0.00276006
	LOSS [training: 0.1856204939371391 | validation: 0.19491310512314583]
	TIME [epoch: 8.98 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17790513392498072		[learning rate: 0.0027536]
		[batch 20/20] avg loss: 0.145807669866838		[learning rate: 0.0027471]
	Learning Rate: 0.00274712
	LOSS [training: 0.16185640189590936 | validation: 0.11820437689198379]
	TIME [epoch: 9.01 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20717236804471373		[learning rate: 0.0027407]
		[batch 20/20] avg loss: 0.21447491099267962		[learning rate: 0.0027342]
	Learning Rate: 0.00273424
	LOSS [training: 0.21082363951869665 | validation: 0.16674795806585946]
	TIME [epoch: 8.98 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1521047165502817		[learning rate: 0.0027278]
		[batch 20/20] avg loss: 0.19791606503077516		[learning rate: 0.0027214]
	Learning Rate: 0.00272142
	LOSS [training: 0.17501039079052844 | validation: 0.1258305756104503]
	TIME [epoch: 8.98 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17787078646972895		[learning rate: 0.002715]
		[batch 20/20] avg loss: 0.20453797442595828		[learning rate: 0.0027087]
	Learning Rate: 0.00270866
	LOSS [training: 0.19120438044784366 | validation: 0.1872039656525149]
	TIME [epoch: 8.97 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19120015677064967		[learning rate: 0.0027023]
		[batch 20/20] avg loss: 0.18242012866979948		[learning rate: 0.002696]
	Learning Rate: 0.00269597
	LOSS [training: 0.18681014272022456 | validation: 0.3510195609082399]
	TIME [epoch: 8.97 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/20] avg loss: 0.285317469107636		[learning rate: 0.0026896]
		[batch 20/20] avg loss: 0.1851389160359052		[learning rate: 0.0026833]
	Learning Rate: 0.00268333
	LOSS [training: 0.23522819257177058 | validation: 0.1913305872947033]
	TIME [epoch: 8.99 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21511189571480765		[learning rate: 0.002677]
		[batch 20/20] avg loss: 0.22441970780115175		[learning rate: 0.0026707]
	Learning Rate: 0.00267075
	LOSS [training: 0.21976580175797972 | validation: 0.3190984799826163]
	TIME [epoch: 8.96 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2263447925521999		[learning rate: 0.0026645]
		[batch 20/20] avg loss: 0.21385689788697454		[learning rate: 0.0026582]
	Learning Rate: 0.00265823
	LOSS [training: 0.22010084521958723 | validation: 0.24906581263988437]
	TIME [epoch: 8.97 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20687571573391822		[learning rate: 0.002652]
		[batch 20/20] avg loss: 0.20986820988825916		[learning rate: 0.0026458]
	Learning Rate: 0.00264576
	LOSS [training: 0.20837196281108872 | validation: 0.17096265892673457]
	TIME [epoch: 8.97 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2092457408236544		[learning rate: 0.0026396]
		[batch 20/20] avg loss: 0.21085034501287678		[learning rate: 0.0026334]
	Learning Rate: 0.00263336
	LOSS [training: 0.21004804291826557 | validation: 0.3242651956564435]
	TIME [epoch: 8.98 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21726994449271958		[learning rate: 0.0026272]
		[batch 20/20] avg loss: 0.19138510656059424		[learning rate: 0.002621]
	Learning Rate: 0.00262101
	LOSS [training: 0.20432752552665692 | validation: 0.16558719017041013]
	TIME [epoch: 8.97 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18115040174542835		[learning rate: 0.0026149]
		[batch 20/20] avg loss: 0.21283329387068997		[learning rate: 0.0026087]
	Learning Rate: 0.00260873
	LOSS [training: 0.19699184780805912 | validation: 0.3176053449894469]
	TIME [epoch: 8.97 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20639922772742478		[learning rate: 0.0026026]
		[batch 20/20] avg loss: 0.19497991864708042		[learning rate: 0.0025965]
	Learning Rate: 0.0025965
	LOSS [training: 0.20068957318725258 | validation: 0.10692041130037504]
	TIME [epoch: 8.95 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15593680941372953		[learning rate: 0.0025904]
		[batch 20/20] avg loss: 0.19197633188551882		[learning rate: 0.0025843]
	Learning Rate: 0.00258432
	LOSS [training: 0.1739565706496242 | validation: 0.17633218614914634]
	TIME [epoch: 8.95 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16409572116875284		[learning rate: 0.0025783]
		[batch 20/20] avg loss: 0.17075406299561963		[learning rate: 0.0025722]
	Learning Rate: 0.00257221
	LOSS [training: 0.1674248920821862 | validation: 0.3145396918480964]
	TIME [epoch: 8.98 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21038138022145025		[learning rate: 0.0025662]
		[batch 20/20] avg loss: 0.21354565201594872		[learning rate: 0.0025601]
	Learning Rate: 0.00256015
	LOSS [training: 0.2119635161186995 | validation: 0.14033064223201092]
	TIME [epoch: 8.98 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17344898544126758		[learning rate: 0.0025541]
		[batch 20/20] avg loss: 0.15146534317659427		[learning rate: 0.0025481]
	Learning Rate: 0.00254815
	LOSS [training: 0.1624571643089309 | validation: 0.20937219452280614]
	TIME [epoch: 8.95 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30365145613926237		[learning rate: 0.0025422]
		[batch 20/20] avg loss: 0.16693712162107086		[learning rate: 0.0025362]
	Learning Rate: 0.0025362
	LOSS [training: 0.23529428888016662 | validation: 0.2749688636326023]
	TIME [epoch: 8.96 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1921814412971757		[learning rate: 0.0025302]
		[batch 20/20] avg loss: 0.19650127637437054		[learning rate: 0.0025243]
	Learning Rate: 0.00252431
	LOSS [training: 0.19434135883577305 | validation: 0.15599555643063462]
	TIME [epoch: 8.96 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21848506016100927		[learning rate: 0.0025184]
		[batch 20/20] avg loss: 0.1567797676665405		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.1876324139137749 | validation: 0.12719489034018092]
	TIME [epoch: 8.99 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16683887957261306		[learning rate: 0.0025066]
		[batch 20/20] avg loss: 0.1608085951720636		[learning rate: 0.0025007]
	Learning Rate: 0.0025007
	LOSS [training: 0.1638237373723383 | validation: 0.23181182150009033]
	TIME [epoch: 8.96 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18355994839250567		[learning rate: 0.0024948]
		[batch 20/20] avg loss: 0.1655426022429684		[learning rate: 0.002489]
	Learning Rate: 0.00248897
	LOSS [training: 0.17455127531773704 | validation: 0.1456562730497238]
	TIME [epoch: 8.96 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/20] avg loss: 0.167158167168738		[learning rate: 0.0024831]
		[batch 20/20] avg loss: 0.1434185632033897		[learning rate: 0.0024773]
	Learning Rate: 0.00247731
	LOSS [training: 0.15528836518606381 | validation: 0.14323417241080538]
	TIME [epoch: 8.97 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16592725643787715		[learning rate: 0.0024715]
		[batch 20/20] avg loss: 0.24218557198238305		[learning rate: 0.0024657]
	Learning Rate: 0.00246569
	LOSS [training: 0.20405641421013007 | validation: 0.19486732291012193]
	TIME [epoch: 8.98 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1702070592764762		[learning rate: 0.0024599]
		[batch 20/20] avg loss: 0.17742640429748474		[learning rate: 0.0024541]
	Learning Rate: 0.00245413
	LOSS [training: 0.17381673178698046 | validation: 0.15121258310327623]
	TIME [epoch: 8.94 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18061497195377033		[learning rate: 0.0024484]
		[batch 20/20] avg loss: 0.17067629724323433		[learning rate: 0.0024426]
	Learning Rate: 0.00244263
	LOSS [training: 0.17564563459850233 | validation: 0.17482160830533658]
	TIME [epoch: 8.97 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15805497228043283		[learning rate: 0.0024369]
		[batch 20/20] avg loss: 0.17387453770003444		[learning rate: 0.0024312]
	Learning Rate: 0.00243118
	LOSS [training: 0.16596475499023364 | validation: 0.20149444017086987]
	TIME [epoch: 8.96 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16026736624648424		[learning rate: 0.0024255]
		[batch 20/20] avg loss: 0.16579097065314952		[learning rate: 0.0024198]
	Learning Rate: 0.00241978
	LOSS [training: 0.1630291684498169 | validation: 0.2428705231127915]
	TIME [epoch: 8.95 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1967978704713533		[learning rate: 0.0024141]
		[batch 20/20] avg loss: 0.17483352949836248		[learning rate: 0.0024084]
	Learning Rate: 0.00240843
	LOSS [training: 0.18581569998485792 | validation: 0.24351414955879475]
	TIME [epoch: 8.99 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16995416300378077		[learning rate: 0.0024028]
		[batch 20/20] avg loss: 0.1289393676980815		[learning rate: 0.0023971]
	Learning Rate: 0.00239714
	LOSS [training: 0.14944676535093113 | validation: 0.09346000840430524]
	TIME [epoch: 8.95 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_314.pth
	Model improved!!!
EPOCH 315/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16938213238217537		[learning rate: 0.0023915]
		[batch 20/20] avg loss: 0.23284395076597578		[learning rate: 0.0023859]
	Learning Rate: 0.0023859
	LOSS [training: 0.20111304157407556 | validation: 0.16325074522712404]
	TIME [epoch: 8.93 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17027625470532073		[learning rate: 0.0023803]
		[batch 20/20] avg loss: 0.16119549365900007		[learning rate: 0.0023747]
	Learning Rate: 0.00237472
	LOSS [training: 0.16573587418216043 | validation: 0.16889876795479586]
	TIME [epoch: 8.91 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18983549998315222		[learning rate: 0.0023691]
		[batch 20/20] avg loss: 0.23500924510356228		[learning rate: 0.0023636]
	Learning Rate: 0.00236359
	LOSS [training: 0.21242237254335725 | validation: 0.14710083099483803]
	TIME [epoch: 8.94 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27287298987606445		[learning rate: 0.002358]
		[batch 20/20] avg loss: 0.16889907627329773		[learning rate: 0.0023525]
	Learning Rate: 0.00235251
	LOSS [training: 0.22088603307468105 | validation: 0.1943756288104012]
	TIME [epoch: 8.94 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1456171382281397		[learning rate: 0.002347]
		[batch 20/20] avg loss: 0.18001193091507228		[learning rate: 0.0023415]
	Learning Rate: 0.00234148
	LOSS [training: 0.162814534571606 | validation: 0.4214287815141119]
	TIME [epoch: 8.93 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21700891653046844		[learning rate: 0.002336]
		[batch 20/20] avg loss: 0.18031527813595682		[learning rate: 0.0023305]
	Learning Rate: 0.0023305
	LOSS [training: 0.19866209733321266 | validation: 0.21587610861819378]
	TIME [epoch: 8.92 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15785768909013315		[learning rate: 0.002325]
		[batch 20/20] avg loss: 0.15141825122306202		[learning rate: 0.0023196]
	Learning Rate: 0.00231957
	LOSS [training: 0.15463797015659758 | validation: 0.182536755206107]
	TIME [epoch: 8.93 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1809333261737955		[learning rate: 0.0023141]
		[batch 20/20] avg loss: 0.12636146069677634		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.15364739343528594 | validation: 0.12888128575386598]
	TIME [epoch: 8.95 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14540528659176186		[learning rate: 0.0023033]
		[batch 20/20] avg loss: 0.22203945721025842		[learning rate: 0.0022979]
	Learning Rate: 0.00229788
	LOSS [training: 0.18372237190101012 | validation: 0.1940858876173626]
	TIME [epoch: 8.94 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16940908246683076		[learning rate: 0.0022925]
		[batch 20/20] avg loss: 0.16509069518327327		[learning rate: 0.0022871]
	Learning Rate: 0.0022871
	LOSS [training: 0.167249888825052 | validation: 0.16143440259734726]
	TIME [epoch: 8.93 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12156556947910684		[learning rate: 0.0022817]
		[batch 20/20] avg loss: 0.17197863888467563		[learning rate: 0.0022764]
	Learning Rate: 0.00227638
	LOSS [training: 0.14677210418189124 | validation: 0.23899225576140565]
	TIME [epoch: 8.94 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/20] avg loss: 0.149773447900932		[learning rate: 0.002271]
		[batch 20/20] avg loss: 0.1700953532875326		[learning rate: 0.0022657]
	Learning Rate: 0.00226571
	LOSS [training: 0.15993440059423228 | validation: 0.19712937779388828]
	TIME [epoch: 8.93 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13661010545711064		[learning rate: 0.0022604]
		[batch 20/20] avg loss: 0.17632236877954433		[learning rate: 0.0022551]
	Learning Rate: 0.00225509
	LOSS [training: 0.15646623711832747 | validation: 0.23142707104871052]
	TIME [epoch: 8.96 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17413593004577568		[learning rate: 0.0022498]
		[batch 20/20] avg loss: 0.15640955527438763		[learning rate: 0.0022445]
	Learning Rate: 0.00224451
	LOSS [training: 0.1652727426600816 | validation: 0.1368815454030928]
	TIME [epoch: 8.93 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1596787320729467		[learning rate: 0.0022392]
		[batch 20/20] avg loss: 0.18859665204553427		[learning rate: 0.002234]
	Learning Rate: 0.00223399
	LOSS [training: 0.17413769205924048 | validation: 0.191251482083998]
	TIME [epoch: 8.93 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12567053410358256		[learning rate: 0.0022287]
		[batch 20/20] avg loss: 0.1414772664286586		[learning rate: 0.0022235]
	Learning Rate: 0.00222352
	LOSS [training: 0.1335739002661206 | validation: 0.15372397142922398]
	TIME [epoch: 8.92 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14437867581250247		[learning rate: 0.0022183]
		[batch 20/20] avg loss: 0.21498279611098306		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.17968073596174272 | validation: 0.12035533121077249]
	TIME [epoch: 8.94 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14138276536949887		[learning rate: 0.0022079]
		[batch 20/20] avg loss: 0.12358399474592681		[learning rate: 0.0022027]
	Learning Rate: 0.00220272
	LOSS [training: 0.13248338005771282 | validation: 0.17725651128142744]
	TIME [epoch: 8.93 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/20] avg loss: 0.140911232139378		[learning rate: 0.0021976]
		[batch 20/20] avg loss: 0.15642117585997645		[learning rate: 0.0021924]
	Learning Rate: 0.00219239
	LOSS [training: 0.1486662039996772 | validation: 0.10705214126138984]
	TIME [epoch: 8.91 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14178257133631128		[learning rate: 0.0021872]
		[batch 20/20] avg loss: 0.12358742956955851		[learning rate: 0.0021821]
	Learning Rate: 0.00218211
	LOSS [training: 0.1326850004529349 | validation: 0.28074790640974623]
	TIME [epoch: 8.92 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1625351985292947		[learning rate: 0.002177]
		[batch 20/20] avg loss: 0.11877226346712551		[learning rate: 0.0021719]
	Learning Rate: 0.00217188
	LOSS [training: 0.14065373099821007 | validation: 0.1005136156962441]
	TIME [epoch: 8.91 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1649133266361219		[learning rate: 0.0021668]
		[batch 20/20] avg loss: 0.15660420290367266		[learning rate: 0.0021617]
	Learning Rate: 0.0021617
	LOSS [training: 0.16075876476989734 | validation: 0.14604425614743888]
	TIME [epoch: 8.95 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16560966270591534		[learning rate: 0.0021566]
		[batch 20/20] avg loss: 0.15518702677085255		[learning rate: 0.0021516]
	Learning Rate: 0.00215157
	LOSS [training: 0.16039834473838394 | validation: 0.20349924465099506]
	TIME [epoch: 8.92 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13977419110072947		[learning rate: 0.0021465]
		[batch 20/20] avg loss: 0.196416737801707		[learning rate: 0.0021415]
	Learning Rate: 0.00214148
	LOSS [training: 0.1680954644512182 | validation: 0.11780272602635902]
	TIME [epoch: 8.92 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1587821438926858		[learning rate: 0.0021365]
		[batch 20/20] avg loss: 0.15469370737289076		[learning rate: 0.0021314]
	Learning Rate: 0.00213144
	LOSS [training: 0.15673792563278827 | validation: 0.09294921303873362]
	TIME [epoch: 8.93 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_339.pth
	Model improved!!!
EPOCH 340/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1352638497451554		[learning rate: 0.0021264]
		[batch 20/20] avg loss: 0.18700128741442104		[learning rate: 0.0021214]
	Learning Rate: 0.00212145
	LOSS [training: 0.16113256857978822 | validation: 0.07747696173866578]
	TIME [epoch: 8.93 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_340.pth
	Model improved!!!
EPOCH 341/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16559905251797388		[learning rate: 0.0021165]
		[batch 20/20] avg loss: 0.2161566204044471		[learning rate: 0.0021115]
	Learning Rate: 0.0021115
	LOSS [training: 0.19087783646121048 | validation: 0.14319261414627454]
	TIME [epoch: 8.95 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19045955953057095		[learning rate: 0.0021065]
		[batch 20/20] avg loss: 0.14373459502040908		[learning rate: 0.0021016]
	Learning Rate: 0.0021016
	LOSS [training: 0.16709707727549 | validation: 0.1164254649050693]
	TIME [epoch: 8.93 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15410251461777677		[learning rate: 0.0020967]
		[batch 20/20] avg loss: 0.1387465316614103		[learning rate: 0.0020918]
	Learning Rate: 0.00209175
	LOSS [training: 0.14642452313959353 | validation: 0.15629312454750044]
	TIME [epoch: 8.93 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1668727923273711		[learning rate: 0.0020868]
		[batch 20/20] avg loss: 0.1461864769551054		[learning rate: 0.0020819]
	Learning Rate: 0.00208195
	LOSS [training: 0.15652963464123823 | validation: 0.1138992811224356]
	TIME [epoch: 8.92 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16262256713637735		[learning rate: 0.0020771]
		[batch 20/20] avg loss: 0.15778923048245647		[learning rate: 0.0020722]
	Learning Rate: 0.00207219
	LOSS [training: 0.16020589880941688 | validation: 0.11325576426763843]
	TIME [epoch: 8.94 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13857682732423765		[learning rate: 0.0020673]
		[batch 20/20] avg loss: 0.14067700171723085		[learning rate: 0.0020625]
	Learning Rate: 0.00206247
	LOSS [training: 0.13962691452073425 | validation: 0.1057184605608394]
	TIME [epoch: 8.95 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11119025344184283		[learning rate: 0.0020576]
		[batch 20/20] avg loss: 0.15866120253756627		[learning rate: 0.0020528]
	Learning Rate: 0.0020528
	LOSS [training: 0.13492572798970456 | validation: 0.1259123872861185]
	TIME [epoch: 8.93 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1578960849090679		[learning rate: 0.002048]
		[batch 20/20] avg loss: 0.16767127544837532		[learning rate: 0.0020432]
	Learning Rate: 0.00204318
	LOSS [training: 0.16278368017872163 | validation: 0.16820451858732283]
	TIME [epoch: 8.92 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1838407328938375		[learning rate: 0.0020384]
		[batch 20/20] avg loss: 0.2160591962092723		[learning rate: 0.0020336]
	Learning Rate: 0.0020336
	LOSS [training: 0.19994996455155492 | validation: 0.13341436395678927]
	TIME [epoch: 8.94 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10922215031628665		[learning rate: 0.0020288]
		[batch 20/20] avg loss: 0.13559859423909862		[learning rate: 0.0020241]
	Learning Rate: 0.00202407
	LOSS [training: 0.12241037227769261 | validation: 0.14373780028396343]
	TIME [epoch: 8.95 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/20] avg loss: 0.130756246584671		[learning rate: 0.0020193]
		[batch 20/20] avg loss: 0.15021002972387448		[learning rate: 0.0020146]
	Learning Rate: 0.00201458
	LOSS [training: 0.14048313815427277 | validation: 0.15841111494847412]
	TIME [epoch: 8.93 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14515456571190327		[learning rate: 0.0020098]
		[batch 20/20] avg loss: 0.1450182545498323		[learning rate: 0.0020051]
	Learning Rate: 0.00200513
	LOSS [training: 0.14508641013086773 | validation: 0.13418836288259042]
	TIME [epoch: 8.92 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17709471478826147		[learning rate: 0.0020004]
		[batch 20/20] avg loss: 0.1736202789915806		[learning rate: 0.0019957]
	Learning Rate: 0.00199573
	LOSS [training: 0.17535749688992106 | validation: 0.10380260061890416]
	TIME [epoch: 8.93 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1491563606949806		[learning rate: 0.001991]
		[batch 20/20] avg loss: 0.1347389661218263		[learning rate: 0.0019864]
	Learning Rate: 0.00198637
	LOSS [training: 0.14194766340840342 | validation: 0.12395418598307864]
	TIME [epoch: 8.91 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13407946035438761		[learning rate: 0.0019817]
		[batch 20/20] avg loss: 0.13377898996946988		[learning rate: 0.0019771]
	Learning Rate: 0.00197706
	LOSS [training: 0.13392922516192873 | validation: 0.10969431964202982]
	TIME [epoch: 8.95 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21087399737419948		[learning rate: 0.0019724]
		[batch 20/20] avg loss: 0.13090843964479676		[learning rate: 0.0019678]
	Learning Rate: 0.00196779
	LOSS [training: 0.17089121850949812 | validation: 0.1377591162505244]
	TIME [epoch: 8.94 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1282011649190758		[learning rate: 0.0019632]
		[batch 20/20] avg loss: 0.17398693631291315		[learning rate: 0.0019586]
	Learning Rate: 0.00195857
	LOSS [training: 0.15109405061599449 | validation: 0.2045865585661584]
	TIME [epoch: 8.94 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14013263282502136		[learning rate: 0.001954]
		[batch 20/20] avg loss: 0.13686602803714815		[learning rate: 0.0019494]
	Learning Rate: 0.00194939
	LOSS [training: 0.13849933043108476 | validation: 0.1542941865697292]
	TIME [epoch: 8.92 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12170486296028145		[learning rate: 0.0019448]
		[batch 20/20] avg loss: 0.14124783783782974		[learning rate: 0.0019402]
	Learning Rate: 0.00194025
	LOSS [training: 0.13147635039905559 | validation: 0.1247588396161445]
	TIME [epoch: 8.94 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16118149351740238		[learning rate: 0.0019357]
		[batch 20/20] avg loss: 0.12584009562094717		[learning rate: 0.0019312]
	Learning Rate: 0.00193115
	LOSS [training: 0.14351079456917476 | validation: 0.09623419133016503]
	TIME [epoch: 8.92 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14467188627856797		[learning rate: 0.0019266]
		[batch 20/20] avg loss: 0.1386714657448312		[learning rate: 0.0019221]
	Learning Rate: 0.0019221
	LOSS [training: 0.1416716760116996 | validation: 0.17428556610377785]
	TIME [epoch: 8.93 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12669715667608503		[learning rate: 0.0019176]
		[batch 20/20] avg loss: 0.1904521685833414		[learning rate: 0.0019131]
	Learning Rate: 0.00191309
	LOSS [training: 0.15857466262971318 | validation: 0.15566794568556983]
	TIME [epoch: 8.94 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16353374763509182		[learning rate: 0.0019086]
		[batch 20/20] avg loss: 0.14267842145382312		[learning rate: 0.0019041]
	Learning Rate: 0.00190412
	LOSS [training: 0.15310608454445745 | validation: 0.14530494362121285]
	TIME [epoch: 8.93 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1321633819459813		[learning rate: 0.0018996]
		[batch 20/20] avg loss: 0.11434330854622259		[learning rate: 0.0018952]
	Learning Rate: 0.00189519
	LOSS [training: 0.12325334524610192 | validation: 0.13791029927636547]
	TIME [epoch: 8.95 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11560662965828214		[learning rate: 0.0018907]
		[batch 20/20] avg loss: 0.14296481220977744		[learning rate: 0.0018863]
	Learning Rate: 0.00188631
	LOSS [training: 0.1292857209340298 | validation: 0.225273494706974]
	TIME [epoch: 8.92 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14502666298386596		[learning rate: 0.0018819]
		[batch 20/20] avg loss: 0.16008928631995956		[learning rate: 0.0018775]
	Learning Rate: 0.00187746
	LOSS [training: 0.1525579746519127 | validation: 0.09825592954672202]
	TIME [epoch: 8.94 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17764988401566845		[learning rate: 0.0018731]
		[batch 20/20] avg loss: 0.1465471349391596		[learning rate: 0.0018687]
	Learning Rate: 0.00186866
	LOSS [training: 0.16209850947741403 | validation: 0.1036184200543188]
	TIME [epoch: 8.93 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13613867018105147		[learning rate: 0.0018643]
		[batch 20/20] avg loss: 0.11921102367866085		[learning rate: 0.0018599]
	Learning Rate: 0.0018599
	LOSS [training: 0.12767484692985615 | validation: 0.10795453575656919]
	TIME [epoch: 8.93 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1126778253938959		[learning rate: 0.0018555]
		[batch 20/20] avg loss: 0.12187265469331751		[learning rate: 0.0018512]
	Learning Rate: 0.00185118
	LOSS [training: 0.1172752400436067 | validation: 0.08744583363657381]
	TIME [epoch: 8.97 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1131263007099729		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.12167221201800327		[learning rate: 0.0018425]
	Learning Rate: 0.0018425
	LOSS [training: 0.11739925636398807 | validation: 0.08233912975632254]
	TIME [epoch: 8.93 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12099753547347569		[learning rate: 0.0018382]
		[batch 20/20] avg loss: 0.10681198274281711		[learning rate: 0.0018339]
	Learning Rate: 0.00183386
	LOSS [training: 0.11390475910814639 | validation: 0.0892150293003778]
	TIME [epoch: 8.95 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12535769370346425		[learning rate: 0.0018296]
		[batch 20/20] avg loss: 0.1596352009776258		[learning rate: 0.0018253]
	Learning Rate: 0.00182527
	LOSS [training: 0.14249644734054503 | validation: 0.21867791792125688]
	TIME [epoch: 8.93 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1443650118333583		[learning rate: 0.001821]
		[batch 20/20] avg loss: 0.13733196770416892		[learning rate: 0.0018167]
	Learning Rate: 0.00181671
	LOSS [training: 0.14084848976876363 | validation: 0.08593511842610725]
	TIME [epoch: 8.95 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1513133591680612		[learning rate: 0.0018124]
		[batch 20/20] avg loss: 0.13354159371835755		[learning rate: 0.0018082]
	Learning Rate: 0.00180819
	LOSS [training: 0.1424274764432094 | validation: 0.12359946605540853]
	TIME [epoch: 8.96 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13575802343419033		[learning rate: 0.001804]
		[batch 20/20] avg loss: 0.10348219858818161		[learning rate: 0.0017997]
	Learning Rate: 0.00179972
	LOSS [training: 0.11962011101118593 | validation: 0.1081224545038978]
	TIME [epoch: 8.93 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12920213621520193		[learning rate: 0.0017955]
		[batch 20/20] avg loss: 0.12549509559916852		[learning rate: 0.0017913]
	Learning Rate: 0.00179128
	LOSS [training: 0.12734861590718521 | validation: 0.1630675508410384]
	TIME [epoch: 8.96 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1249049473312314		[learning rate: 0.0017871]
		[batch 20/20] avg loss: 0.12292029009041996		[learning rate: 0.0017829]
	Learning Rate: 0.00178288
	LOSS [training: 0.12391261871082568 | validation: 0.1566925096481158]
	TIME [epoch: 8.95 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1530559793248806		[learning rate: 0.0017787]
		[batch 20/20] avg loss: 0.1198833914113638		[learning rate: 0.0017745]
	Learning Rate: 0.00177452
	LOSS [training: 0.1364696853681222 | validation: 0.09771495846161922]
	TIME [epoch: 8.98 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/20] avg loss: 0.125891868205208		[learning rate: 0.0017704]
		[batch 20/20] avg loss: 0.14409988044652278		[learning rate: 0.0017662]
	Learning Rate: 0.0017662
	LOSS [training: 0.1349958743258654 | validation: 0.15804191069806123]
	TIME [epoch: 8.96 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1445529727538811		[learning rate: 0.0017621]
		[batch 20/20] avg loss: 0.19676808667277026		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.17066052971332568 | validation: 0.1332465517242324]
	TIME [epoch: 8.95 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14708048187334152		[learning rate: 0.0017538]
		[batch 20/20] avg loss: 0.1673759041389552		[learning rate: 0.0017497]
	Learning Rate: 0.00174968
	LOSS [training: 0.15722819300614838 | validation: 0.15893074125094625]
	TIME [epoch: 8.95 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12149659046883907		[learning rate: 0.0017456]
		[batch 20/20] avg loss: 0.1383485779584312		[learning rate: 0.0017415]
	Learning Rate: 0.00174148
	LOSS [training: 0.12992258421363514 | validation: 0.08638594371539833]
	TIME [epoch: 8.94 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12866102963210233		[learning rate: 0.0017374]
		[batch 20/20] avg loss: 0.1350735349836045		[learning rate: 0.0017333]
	Learning Rate: 0.00173331
	LOSS [training: 0.1318672823078534 | validation: 0.10113417755120901]
	TIME [epoch: 8.98 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11771170457498895		[learning rate: 0.0017292]
		[batch 20/20] avg loss: 0.15117814851706482		[learning rate: 0.0017252]
	Learning Rate: 0.00172519
	LOSS [training: 0.13444492654602685 | validation: 0.20868668728058148]
	TIME [epoch: 8.94 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13181697419015495		[learning rate: 0.0017211]
		[batch 20/20] avg loss: 0.1352493841373487		[learning rate: 0.0017171]
	Learning Rate: 0.0017171
	LOSS [training: 0.1335331791637518 | validation: 0.1559516405346239]
	TIME [epoch: 8.95 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12383179685610135		[learning rate: 0.0017131]
		[batch 20/20] avg loss: 0.11384683173080282		[learning rate: 0.0017091]
	Learning Rate: 0.00170905
	LOSS [training: 0.11883931429345207 | validation: 0.07989593038894674]
	TIME [epoch: 8.94 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15160152224727264		[learning rate: 0.001705]
		[batch 20/20] avg loss: 0.13285898616816194		[learning rate: 0.001701]
	Learning Rate: 0.00170104
	LOSS [training: 0.14223025420771726 | validation: 0.17689763787839105]
	TIME [epoch: 8.95 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14677921812921865		[learning rate: 0.001697]
		[batch 20/20] avg loss: 0.1461366427273723		[learning rate: 0.0016931]
	Learning Rate: 0.00169306
	LOSS [training: 0.14645793042829552 | validation: 0.09682444750283019]
	TIME [epoch: 8.96 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1307422377614435		[learning rate: 0.0016891]
		[batch 20/20] avg loss: 0.11023897352022596		[learning rate: 0.0016851]
	Learning Rate: 0.00168513
	LOSS [training: 0.12049060564083473 | validation: 0.11819088809664739]
	TIME [epoch: 8.95 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14212128552505515		[learning rate: 0.0016812]
		[batch 20/20] avg loss: 0.16246699222524602		[learning rate: 0.0016772]
	Learning Rate: 0.00167723
	LOSS [training: 0.1522941388751506 | validation: 0.11498224092525607]
	TIME [epoch: 8.95 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12008076829351436		[learning rate: 0.0016733]
		[batch 20/20] avg loss: 0.13711385590666053		[learning rate: 0.0016694]
	Learning Rate: 0.00166936
	LOSS [training: 0.12859731210008746 | validation: 0.08364994441136782]
	TIME [epoch: 8.94 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13717450063987588		[learning rate: 0.0016654]
		[batch 20/20] avg loss: 0.16869816865935966		[learning rate: 0.0016615]
	Learning Rate: 0.00166154
	LOSS [training: 0.15293633464961773 | validation: 0.18993411226210036]
	TIME [epoch: 8.98 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1535946977835651		[learning rate: 0.0016576]
		[batch 20/20] avg loss: 0.15186463277702117		[learning rate: 0.0016537]
	Learning Rate: 0.00165375
	LOSS [training: 0.15272966528029314 | validation: 0.1447250897557826]
	TIME [epoch: 8.96 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1367854883025305		[learning rate: 0.0016499]
		[batch 20/20] avg loss: 0.1336120151676749		[learning rate: 0.001646]
	Learning Rate: 0.001646
	LOSS [training: 0.13519875173510268 | validation: 0.2043041978754683]
	TIME [epoch: 8.95 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1326508835711139		[learning rate: 0.0016421]
		[batch 20/20] avg loss: 0.11750426234378253		[learning rate: 0.0016383]
	Learning Rate: 0.00163828
	LOSS [training: 0.1250775729574482 | validation: 0.11514865614296103]
	TIME [epoch: 8.96 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10103197861569777		[learning rate: 0.0016344]
		[batch 20/20] avg loss: 0.10743676721403886		[learning rate: 0.0016306]
	Learning Rate: 0.0016306
	LOSS [training: 0.10423437291486833 | validation: 0.09986605080462652]
	TIME [epoch: 8.94 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11290027610345488		[learning rate: 0.0016268]
		[batch 20/20] avg loss: 0.10957250631190663		[learning rate: 0.001623]
	Learning Rate: 0.00162295
	LOSS [training: 0.11123639120768077 | validation: 0.1414259249396635]
	TIME [epoch: 8.96 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1447616454661333		[learning rate: 0.0016191]
		[batch 20/20] avg loss: 0.1104628235542994		[learning rate: 0.0016153]
	Learning Rate: 0.00161535
	LOSS [training: 0.12761223451021636 | validation: 0.1569851233312829]
	TIME [epoch: 8.94 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14167668786076815		[learning rate: 0.0016116]
		[batch 20/20] avg loss: 0.11007320664512718		[learning rate: 0.0016078]
	Learning Rate: 0.00160777
	LOSS [training: 0.1258749472529477 | validation: 0.08215210385355769]
	TIME [epoch: 8.94 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09378339265237139		[learning rate: 0.001604]
		[batch 20/20] avg loss: 0.17991153165103407		[learning rate: 0.0016002]
	Learning Rate: 0.00160023
	LOSS [training: 0.13684746215170268 | validation: 0.1122418406510121]
	TIME [epoch: 8.95 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10612467157005849		[learning rate: 0.0015965]
		[batch 20/20] avg loss: 0.14660310534270163		[learning rate: 0.0015927]
	Learning Rate: 0.00159273
	LOSS [training: 0.12636388845638005 | validation: 0.16789520213369563]
	TIME [epoch: 8.95 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13004674409725803		[learning rate: 0.001589]
		[batch 20/20] avg loss: 0.11190736980817015		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.12097705695271407 | validation: 0.08747134456406325]
	TIME [epoch: 8.96 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14499509479282524		[learning rate: 0.0015815]
		[batch 20/20] avg loss: 0.12451743626869764		[learning rate: 0.0015778]
	Learning Rate: 0.00157783
	LOSS [training: 0.13475626553076145 | validation: 0.1046259857943441]
	TIME [epoch: 8.94 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08637686050286747		[learning rate: 0.0015741]
		[batch 20/20] avg loss: 0.110962694516536		[learning rate: 0.0015704]
	Learning Rate: 0.00157044
	LOSS [training: 0.09866977750970177 | validation: 0.06865209679718769]
	TIME [epoch: 8.94 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_404.pth
	Model improved!!!
EPOCH 405/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13804447588887428		[learning rate: 0.0015668]
		[batch 20/20] avg loss: 0.11371749075575091		[learning rate: 0.0015631]
	Learning Rate: 0.00156307
	LOSS [training: 0.12588098332231262 | validation: 0.16727583289874354]
	TIME [epoch: 8.97 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17137053088456447		[learning rate: 0.0015594]
		[batch 20/20] avg loss: 0.11592657831611393		[learning rate: 0.0015557]
	Learning Rate: 0.00155575
	LOSS [training: 0.1436485546003392 | validation: 0.06601320821275601]
	TIME [epoch: 8.96 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_406.pth
	Model improved!!!
EPOCH 407/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10639033703732019		[learning rate: 0.0015521]
		[batch 20/20] avg loss: 0.10378118003558581		[learning rate: 0.0015485]
	Learning Rate: 0.00154845
	LOSS [training: 0.10508575853645301 | validation: 0.12412929488843494]
	TIME [epoch: 8.97 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13533249672972053		[learning rate: 0.0015448]
		[batch 20/20] avg loss: 0.1557833808856303		[learning rate: 0.0015412]
	Learning Rate: 0.00154119
	LOSS [training: 0.14555793880767542 | validation: 0.12675007749668993]
	TIME [epoch: 8.96 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1284715232435798		[learning rate: 0.0015376]
		[batch 20/20] avg loss: 0.12322231574096046		[learning rate: 0.001534]
	Learning Rate: 0.00153397
	LOSS [training: 0.12584691949227014 | validation: 0.07424148769503049]
	TIME [epoch: 8.95 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1489792542352832		[learning rate: 0.0015304]
		[batch 20/20] avg loss: 0.11700253443887598		[learning rate: 0.0015268]
	Learning Rate: 0.00152678
	LOSS [training: 0.13299089433707956 | validation: 0.09023143297340874]
	TIME [epoch: 8.96 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1306095676631162		[learning rate: 0.0015232]
		[batch 20/20] avg loss: 0.1124298945707487		[learning rate: 0.0015196]
	Learning Rate: 0.00151962
	LOSS [training: 0.12151973111693244 | validation: 0.0951268685842908]
	TIME [epoch: 8.97 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10651530092272202		[learning rate: 0.0015161]
		[batch 20/20] avg loss: 0.15211487572950505		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.12931508832611352 | validation: 0.21182135723931456]
	TIME [epoch: 8.94 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1270136266425793		[learning rate: 0.0015089]
		[batch 20/20] avg loss: 0.13346075758957127		[learning rate: 0.0015054]
	Learning Rate: 0.0015054
	LOSS [training: 0.13023719211607526 | validation: 0.09677715557349412]
	TIME [epoch: 8.95 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14179461748783534		[learning rate: 0.0015019]
		[batch 20/20] avg loss: 0.14229669871664802		[learning rate: 0.0014983]
	Learning Rate: 0.00149835
	LOSS [training: 0.1420456581022417 | validation: 0.13431853119238685]
	TIME [epoch: 8.96 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10227549476693727		[learning rate: 0.0014948]
		[batch 20/20] avg loss: 0.14030985406189075		[learning rate: 0.0014913]
	Learning Rate: 0.00149132
	LOSS [training: 0.121292674414414 | validation: 0.1539905547816905]
	TIME [epoch: 8.97 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16059634913787002		[learning rate: 0.0014878]
		[batch 20/20] avg loss: 0.13334282532257075		[learning rate: 0.0014843]
	Learning Rate: 0.00148433
	LOSS [training: 0.1469695872302204 | validation: 0.11684599918137846]
	TIME [epoch: 8.97 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14261704001665573		[learning rate: 0.0014808]
		[batch 20/20] avg loss: 0.13423779266699945		[learning rate: 0.0014774]
	Learning Rate: 0.00147737
	LOSS [training: 0.1384274163418276 | validation: 0.13111828932863728]
	TIME [epoch: 8.97 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11942532618084745		[learning rate: 0.0014739]
		[batch 20/20] avg loss: 0.11057774944398442		[learning rate: 0.0014704]
	Learning Rate: 0.00147045
	LOSS [training: 0.11500153781241593 | validation: 0.1127805408672786]
	TIME [epoch: 8.96 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13777560876938313		[learning rate: 0.001467]
		[batch 20/20] avg loss: 0.09537702510587526		[learning rate: 0.0014636]
	Learning Rate: 0.00146355
	LOSS [training: 0.11657631693762918 | validation: 0.09829091174075517]
	TIME [epoch: 8.96 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1554949125933926		[learning rate: 0.0014601]
		[batch 20/20] avg loss: 0.1205516747059856		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.13802329364968913 | validation: 0.08022623133675379]
	TIME [epoch: 8.98 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08929100822290023		[learning rate: 0.0014533]
		[batch 20/20] avg loss: 0.12862233030524015		[learning rate: 0.0014499]
	Learning Rate: 0.00144986
	LOSS [training: 0.10895666926407022 | validation: 0.07802921098300186]
	TIME [epoch: 8.95 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12573685454355393		[learning rate: 0.0014465]
		[batch 20/20] avg loss: 0.12568339715385063		[learning rate: 0.0014431]
	Learning Rate: 0.00144306
	LOSS [training: 0.12571012584870228 | validation: 0.060857568573949014]
	TIME [epoch: 8.95 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_422.pth
	Model improved!!!
EPOCH 423/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11879596190619494		[learning rate: 0.0014397]
		[batch 20/20] avg loss: 0.14613020595305495		[learning rate: 0.0014363]
	Learning Rate: 0.0014363
	LOSS [training: 0.13246308392962497 | validation: 0.18822825271610835]
	TIME [epoch: 8.96 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17162679700628286		[learning rate: 0.0014329]
		[batch 20/20] avg loss: 0.1152099600503728		[learning rate: 0.0014296]
	Learning Rate: 0.00142957
	LOSS [training: 0.14341837852832778 | validation: 0.16315344341965765]
	TIME [epoch: 8.97 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11001615462794676		[learning rate: 0.0014262]
		[batch 20/20] avg loss: 0.12243298765183504		[learning rate: 0.0014229]
	Learning Rate: 0.00142286
	LOSS [training: 0.1162245711398909 | validation: 0.11252932575058117]
	TIME [epoch: 8.98 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13879399652194246		[learning rate: 0.0014195]
		[batch 20/20] avg loss: 0.15461380766161392		[learning rate: 0.0014162]
	Learning Rate: 0.00141619
	LOSS [training: 0.14670390209177817 | validation: 0.10817869003836188]
	TIME [epoch: 8.96 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11497557154975606		[learning rate: 0.0014129]
		[batch 20/20] avg loss: 0.14906334893745068		[learning rate: 0.0014096]
	Learning Rate: 0.00140955
	LOSS [training: 0.1320194602436034 | validation: 0.08973526377909827]
	TIME [epoch: 8.97 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11195095497354482		[learning rate: 0.0014062]
		[batch 20/20] avg loss: 0.12821824113808972		[learning rate: 0.0014029]
	Learning Rate: 0.00140295
	LOSS [training: 0.12008459805581728 | validation: 0.10145731161531431]
	TIME [epoch: 8.98 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10473031247929003		[learning rate: 0.0013997]
		[batch 20/20] avg loss: 0.11317613944339314		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.10895322596134158 | validation: 0.1379255399175433]
	TIME [epoch: 9 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12190953022945253		[learning rate: 0.0013931]
		[batch 20/20] avg loss: 0.1516828668634247		[learning rate: 0.0013898]
	Learning Rate: 0.00138982
	LOSS [training: 0.13679619854643862 | validation: 0.14441204635152466]
	TIME [epoch: 8.97 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14461322441468188		[learning rate: 0.0013866]
		[batch 20/20] avg loss: 0.12232840074523366		[learning rate: 0.0013833]
	Learning Rate: 0.00138331
	LOSS [training: 0.13347081257995777 | validation: 0.09769268911813551]
	TIME [epoch: 8.97 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10451708006508331		[learning rate: 0.0013801]
		[batch 20/20] avg loss: 0.09163729693207001		[learning rate: 0.0013768]
	Learning Rate: 0.00137682
	LOSS [training: 0.09807718849857665 | validation: 0.1072879723609542]
	TIME [epoch: 8.96 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12234270062795997		[learning rate: 0.0013736]
		[batch 20/20] avg loss: 0.1065958452100895		[learning rate: 0.0013704]
	Learning Rate: 0.00137037
	LOSS [training: 0.11446927291902473 | validation: 0.08447713902396704]
	TIME [epoch: 8.98 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11565238603423036		[learning rate: 0.0013672]
		[batch 20/20] avg loss: 0.10517428851901837		[learning rate: 0.0013639]
	Learning Rate: 0.00136394
	LOSS [training: 0.11041333727662435 | validation: 0.13626793547893157]
	TIME [epoch: 8.99 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12430251853663957		[learning rate: 0.0013607]
		[batch 20/20] avg loss: 0.1074560854111645		[learning rate: 0.0013575]
	Learning Rate: 0.00135755
	LOSS [training: 0.11587930197390203 | validation: 0.1068960116082342]
	TIME [epoch: 8.99 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08520662778725879		[learning rate: 0.0013544]
		[batch 20/20] avg loss: 0.10657103883030965		[learning rate: 0.0013512]
	Learning Rate: 0.00135118
	LOSS [training: 0.09588883330878421 | validation: 0.11390011565961511]
	TIME [epoch: 8.95 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1280960831780537		[learning rate: 0.001348]
		[batch 20/20] avg loss: 0.0898373201524075		[learning rate: 0.0013448]
	Learning Rate: 0.00134485
	LOSS [training: 0.10896670166523062 | validation: 0.07290919913844063]
	TIME [epoch: 8.97 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10148223588832231		[learning rate: 0.0013417]
		[batch 20/20] avg loss: 0.12181195211249489		[learning rate: 0.0013385]
	Learning Rate: 0.00133854
	LOSS [training: 0.11164709400040862 | validation: 0.07677255933098397]
	TIME [epoch: 8.97 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09754322147723257		[learning rate: 0.0013354]
		[batch 20/20] avg loss: 0.11564914900142746		[learning rate: 0.0013323]
	Learning Rate: 0.00133227
	LOSS [training: 0.10659618523933004 | validation: 0.28369613415946415]
	TIME [epoch: 8.98 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13772119355659554		[learning rate: 0.0013291]
		[batch 20/20] avg loss: 0.11919799532157457		[learning rate: 0.001326]
	Learning Rate: 0.00132602
	LOSS [training: 0.12845959443908508 | validation: 0.13746152139688458]
	TIME [epoch: 8.96 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1461914379014516		[learning rate: 0.0013229]
		[batch 20/20] avg loss: 0.15304866401510978		[learning rate: 0.0013198]
	Learning Rate: 0.00131981
	LOSS [training: 0.14962005095828068 | validation: 0.1742051253274796]
	TIME [epoch: 8.97 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1321924211837068		[learning rate: 0.0013167]
		[batch 20/20] avg loss: 0.1190719569882275		[learning rate: 0.0013136]
	Learning Rate: 0.00131362
	LOSS [training: 0.12563218908596713 | validation: 0.09034772217199108]
	TIME [epoch: 8.96 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10034588017033555		[learning rate: 0.0013105]
		[batch 20/20] avg loss: 0.13913534373183084		[learning rate: 0.0013075]
	Learning Rate: 0.00130746
	LOSS [training: 0.11974061195108321 | validation: 0.10240818365674693]
	TIME [epoch: 8.97 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08992700293879849		[learning rate: 0.0013044]
		[batch 20/20] avg loss: 0.10743222302402419		[learning rate: 0.0013013]
	Learning Rate: 0.00130133
	LOSS [training: 0.09867961298141134 | validation: 0.12470004676103408]
	TIME [epoch: 8.97 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12818303823251548		[learning rate: 0.0012983]
		[batch 20/20] avg loss: 0.12150655113644329		[learning rate: 0.0012952]
	Learning Rate: 0.00129523
	LOSS [training: 0.12484479468447937 | validation: 0.1362593822964782]
	TIME [epoch: 8.95 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12922717059576702		[learning rate: 0.0012922]
		[batch 20/20] avg loss: 0.12250980397834439		[learning rate: 0.0012892]
	Learning Rate: 0.00128916
	LOSS [training: 0.12586848728705569 | validation: 0.11518856081373469]
	TIME [epoch: 8.96 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11728093421802063		[learning rate: 0.0012861]
		[batch 20/20] avg loss: 0.12861719702410862		[learning rate: 0.0012831]
	Learning Rate: 0.00128311
	LOSS [training: 0.12294906562106463 | validation: 0.08139336000150312]
	TIME [epoch: 8.96 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10006952147885276		[learning rate: 0.0012801]
		[batch 20/20] avg loss: 0.14206812585004389		[learning rate: 0.0012771]
	Learning Rate: 0.0012771
	LOSS [training: 0.1210688236644483 | validation: 0.13233969132514478]
	TIME [epoch: 8.99 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11577469035809115		[learning rate: 0.0012741]
		[batch 20/20] avg loss: 0.11401850815893003		[learning rate: 0.0012711]
	Learning Rate: 0.00127111
	LOSS [training: 0.11489659925851056 | validation: 0.1869054319913932]
	TIME [epoch: 8.97 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11996743107599803		[learning rate: 0.0012681]
		[batch 20/20] avg loss: 0.12193144328639463		[learning rate: 0.0012652]
	Learning Rate: 0.00126515
	LOSS [training: 0.12094943718119633 | validation: 0.11522200913450444]
	TIME [epoch: 8.97 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11012684349219597		[learning rate: 0.0012622]
		[batch 20/20] avg loss: 0.13329260307074414		[learning rate: 0.0012592]
	Learning Rate: 0.00125922
	LOSS [training: 0.12170972328147005 | validation: 0.2602332981418736]
	TIME [epoch: 8.97 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13262614421222013		[learning rate: 0.0012563]
		[batch 20/20] avg loss: 0.13431748415585257		[learning rate: 0.0012533]
	Learning Rate: 0.00125332
	LOSS [training: 0.13347181418403634 | validation: 0.11336952052123175]
	TIME [epoch: 8.95 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1062251729249954		[learning rate: 0.0012504]
		[batch 20/20] avg loss: 0.09861085793123162		[learning rate: 0.0012474]
	Learning Rate: 0.00124744
	LOSS [training: 0.1024180154281135 | validation: 0.0867041160399986]
	TIME [epoch: 9 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10862326398405368		[learning rate: 0.0012445]
		[batch 20/20] avg loss: 0.11851538853512182		[learning rate: 0.0012416]
	Learning Rate: 0.00124159
	LOSS [training: 0.11356932625958774 | validation: 0.06864185561059727]
	TIME [epoch: 8.97 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1274586330833827		[learning rate: 0.0012387]
		[batch 20/20] avg loss: 0.12123368161639365		[learning rate: 0.0012358]
	Learning Rate: 0.00123577
	LOSS [training: 0.12434615734988816 | validation: 0.11319220108906988]
	TIME [epoch: 8.96 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10830241566426264		[learning rate: 0.0012329]
		[batch 20/20] avg loss: 0.13710663972975895		[learning rate: 0.00123]
	Learning Rate: 0.00122998
	LOSS [training: 0.12270452769701076 | validation: 0.12105943693131554]
	TIME [epoch: 8.96 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09082462240718436		[learning rate: 0.0012271]
		[batch 20/20] avg loss: 0.11530381300665331		[learning rate: 0.0012242]
	Learning Rate: 0.00122421
	LOSS [training: 0.10306421770691883 | validation: 0.0961588172162021]
	TIME [epoch: 8.99 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09567532059101432		[learning rate: 0.0012213]
		[batch 20/20] avg loss: 0.11981502506967223		[learning rate: 0.0012185]
	Learning Rate: 0.00121847
	LOSS [training: 0.10774517283034327 | validation: 0.2281839341178403]
	TIME [epoch: 8.97 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10765716583374232		[learning rate: 0.0012156]
		[batch 20/20] avg loss: 0.09980557302982404		[learning rate: 0.0012128]
	Learning Rate: 0.00121276
	LOSS [training: 0.10373136943178315 | validation: 0.17402637061853723]
	TIME [epoch: 8.95 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12109869906775558		[learning rate: 0.0012099]
		[batch 20/20] avg loss: 0.10605370033411451		[learning rate: 0.0012071]
	Learning Rate: 0.00120708
	LOSS [training: 0.11357619970093505 | validation: 0.1112394525730984]
	TIME [epoch: 8.96 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0875606495477955		[learning rate: 0.0012042]
		[batch 20/20] avg loss: 0.1084623379262171		[learning rate: 0.0012014]
	Learning Rate: 0.00120142
	LOSS [training: 0.0980114937370063 | validation: 0.11985323695239755]
	TIME [epoch: 8.97 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12802974540090034		[learning rate: 0.0011986]
		[batch 20/20] avg loss: 0.1061575752224992		[learning rate: 0.0011958]
	Learning Rate: 0.00119578
	LOSS [training: 0.11709366031169977 | validation: 0.17046723189109328]
	TIME [epoch: 8.98 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10845711270561405		[learning rate: 0.001193]
		[batch 20/20] avg loss: 0.10990257886623885		[learning rate: 0.0011902]
	Learning Rate: 0.00119018
	LOSS [training: 0.10917984578592646 | validation: 0.09666386281587552]
	TIME [epoch: 8.98 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13593283803137923		[learning rate: 0.0011874]
		[batch 20/20] avg loss: 0.09997392075873368		[learning rate: 0.0011846]
	Learning Rate: 0.0011846
	LOSS [training: 0.11795337939505643 | validation: 0.06533820550345434]
	TIME [epoch: 8.96 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11269582220730676		[learning rate: 0.0011818]
		[batch 20/20] avg loss: 0.12557230453182916		[learning rate: 0.001179]
	Learning Rate: 0.00117905
	LOSS [training: 0.11913406336956797 | validation: 0.11367451850567889]
	TIME [epoch: 8.98 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08747097372747345		[learning rate: 0.0011763]
		[batch 20/20] avg loss: 0.08057902262204694		[learning rate: 0.0011735]
	Learning Rate: 0.00117352
	LOSS [training: 0.08402499817476021 | validation: 0.09338409806508864]
	TIME [epoch: 8.97 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07377104832946063		[learning rate: 0.0011708]
		[batch 20/20] avg loss: 0.0885252672943308		[learning rate: 0.001168]
	Learning Rate: 0.00116802
	LOSS [training: 0.0811481578118957 | validation: 0.1502744181609978]
	TIME [epoch: 8.98 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11616665431897508		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.10278630893282666		[learning rate: 0.0011625]
	Learning Rate: 0.00116254
	LOSS [training: 0.10947648162590087 | validation: 0.0777403655129728]
	TIME [epoch: 8.96 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1030025771453829		[learning rate: 0.0011598]
		[batch 20/20] avg loss: 0.09437641418275546		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.09868949566406916 | validation: 0.05110736117006778]
	TIME [epoch: 8.96 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240214_211946/states/model_tr_study1_469.pth
	Model improved!!!
EPOCH 470/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08122563674656845		[learning rate: 0.0011544]
		[batch 20/20] avg loss: 0.12022207845600186		[learning rate: 0.0011517]
	Learning Rate: 0.00115167
	LOSS [training: 0.10072385760128515 | validation: 0.09376000022322706]
	TIME [epoch: 8.98 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09117046657644164		[learning rate: 0.001149]
		[batch 20/20] avg loss: 0.0986865101787604		[learning rate: 0.0011463]
	Learning Rate: 0.00114627
	LOSS [training: 0.09492848837760101 | validation: 0.09782278126356475]
	TIME [epoch: 9 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07864972520649394		[learning rate: 0.0011436]
		[batch 20/20] avg loss: 0.09306016284277721		[learning rate: 0.0011409]
	Learning Rate: 0.00114089
	LOSS [training: 0.08585494402463556 | validation: 0.08010541500520266]
	TIME [epoch: 8.98 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1059853116151482		[learning rate: 0.0011382]
		[batch 20/20] avg loss: 0.10038360797427268		[learning rate: 0.0011355]
	Learning Rate: 0.00113554
	LOSS [training: 0.10318445979471043 | validation: 0.07721122226227917]
	TIME [epoch: 8.97 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10681846908400242		[learning rate: 0.0011329]
		[batch 20/20] avg loss: 0.09802870618439725		[learning rate: 0.0011302]
	Learning Rate: 0.00113022
	LOSS [training: 0.10242358763419983 | validation: 0.10066695543191452]
	TIME [epoch: 8.98 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08644281097296999		[learning rate: 0.0011276]
		[batch 20/20] avg loss: 0.12158033040972652		[learning rate: 0.0011249]
	Learning Rate: 0.00112492
	LOSS [training: 0.10401157069134825 | validation: 0.1018957342154535]
	TIME [epoch: 8.97 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12268540380674464		[learning rate: 0.0011223]
		[batch 20/20] avg loss: 0.10174756114689516		[learning rate: 0.0011196]
	Learning Rate: 0.00111965
	LOSS [training: 0.11221648247681988 | validation: 0.11685068494586519]
	TIME [epoch: 9.01 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08892876606383596		[learning rate: 0.001117]
		[batch 20/20] avg loss: 0.11149100262110308		[learning rate: 0.0011144]
	Learning Rate: 0.0011144
	LOSS [training: 0.10020988434246951 | validation: 0.07648116617855946]
	TIME [epoch: 8.98 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10088249351577303		[learning rate: 0.0011118]
		[batch 20/20] avg loss: 0.08390551544806325		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.09239400448191812 | validation: 0.07021656072364309]
	TIME [epoch: 8.98 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08672503274135383		[learning rate: 0.0011066]
		[batch 20/20] avg loss: 0.108433214414372		[learning rate: 0.001104]
	Learning Rate: 0.00110397
	LOSS [training: 0.09757912357786293 | validation: 0.1402566071845182]
	TIME [epoch: 8.96 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1264802010579537		[learning rate: 0.0011014]
		[batch 20/20] avg loss: 0.10393733971167433		[learning rate: 0.0010988]
	Learning Rate: 0.0010988
	LOSS [training: 0.11520877038481403 | validation: 0.06964424106077699]
	TIME [epoch: 8.99 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/20] avg loss: 0.079714988459747		[learning rate: 0.0010962]
		[batch 20/20] avg loss: 0.08731460256254019		[learning rate: 0.0010936]
	Learning Rate: 0.00109365
	LOSS [training: 0.08351479551114359 | validation: 0.09387521272008592]
	TIME [epoch: 8.97 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07940293020438462		[learning rate: 0.0010911]
		[batch 20/20] avg loss: 0.0915648899104102		[learning rate: 0.0010885]
	Learning Rate: 0.00108852
	LOSS [training: 0.0854839100573974 | validation: 0.08235131831631066]
	TIME [epoch: 8.97 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09183242755922207		[learning rate: 0.001086]
		[batch 20/20] avg loss: 0.0932211325327379		[learning rate: 0.0010834]
	Learning Rate: 0.00108342
	LOSS [training: 0.09252678004597999 | validation: 0.09475946079298135]
	TIME [epoch: 8.98 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11452075100596552		[learning rate: 0.0010809]
		[batch 20/20] avg loss: 0.09811003128029158		[learning rate: 0.0010783]
	Learning Rate: 0.00107834
	LOSS [training: 0.10631539114312856 | validation: 0.099754130848217]
	TIME [epoch: 8.98 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08289255950130801		[learning rate: 0.0010758]
		[batch 20/20] avg loss: 0.12708924142875377		[learning rate: 0.0010733]
	Learning Rate: 0.00107328
	LOSS [training: 0.1049909004650309 | validation: 0.06833700084137312]
	TIME [epoch: 9 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09498087572814357		[learning rate: 0.0010708]
		[batch 20/20] avg loss: 0.09557803029421795		[learning rate: 0.0010683]
	Learning Rate: 0.00106825
	LOSS [training: 0.09527945301118076 | validation: 0.09714849074754152]
	TIME [epoch: 8.98 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0985652356326088		[learning rate: 0.0010657]
		[batch 20/20] avg loss: 0.09630275555240556		[learning rate: 0.0010632]
	Learning Rate: 0.00106324
	LOSS [training: 0.09743399559250718 | validation: 0.08590486288808591]
	TIME [epoch: 8.96 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1192682782103686		[learning rate: 0.0010607]
		[batch 20/20] avg loss: 0.10844789386827827		[learning rate: 0.0010583]
	Learning Rate: 0.00105826
	LOSS [training: 0.11385808603932343 | validation: 0.13926180875500646]
	TIME [epoch: 8.97 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10110053584824252		[learning rate: 0.0010558]
		[batch 20/20] avg loss: 0.09166666531117196		[learning rate: 0.0010533]
	Learning Rate: 0.0010533
	LOSS [training: 0.09638360057970725 | validation: 0.15162682802108196]
	TIME [epoch: 8.97 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09670012375836663		[learning rate: 0.0010508]
		[batch 20/20] avg loss: 0.08984241302501753		[learning rate: 0.0010484]
	Learning Rate: 0.00104836
	LOSS [training: 0.09327126839169207 | validation: 0.08159296061703264]
	TIME [epoch: 9 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07369099411584376		[learning rate: 0.0010459]
		[batch 20/20] avg loss: 0.1123072983689585		[learning rate: 0.0010434]
	Learning Rate: 0.00104344
	LOSS [training: 0.09299914624240112 | validation: 0.10775853326117975]
	TIME [epoch: 8.97 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1252156174461348		[learning rate: 0.001041]
		[batch 20/20] avg loss: 0.07372334849865438		[learning rate: 0.0010386]
	Learning Rate: 0.00103855
	LOSS [training: 0.09946948297239458 | validation: 0.09374503871764817]
	TIME [epoch: 8.97 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08586425656985211		[learning rate: 0.0010361]
		[batch 20/20] avg loss: 0.12720251967814122		[learning rate: 0.0010337]
	Learning Rate: 0.00103368
	LOSS [training: 0.10653338812399667 | validation: 0.07477046284081512]
	TIME [epoch: 8.96 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/20] avg loss: 0.07306307812386983		[learning rate: 0.0010313]
		[batch 20/20] avg loss: 0.11013454699434108		[learning rate: 0.0010288]
	Learning Rate: 0.00102884
	LOSS [training: 0.09159881255910547 | validation: 0.10694955295893557]
	TIME [epoch: 8.99 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11255297771078965		[learning rate: 0.0010264]
		[batch 20/20] avg loss: 0.09696944507058272		[learning rate: 0.001024]
	Learning Rate: 0.00102401
	LOSS [training: 0.1047612113906862 | validation: 0.06980456651907563]
	TIME [epoch: 8.95 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08535721763822135		[learning rate: 0.0010216]
		[batch 20/20] avg loss: 0.08314324967921385		[learning rate: 0.0010192]
	Learning Rate: 0.00101921
	LOSS [training: 0.08425023365871762 | validation: 0.12229457665346899]
	TIME [epoch: 8.97 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12527863640684916		[learning rate: 0.0010168]
		[batch 20/20] avg loss: 0.10039212709004815		[learning rate: 0.0010144]
	Learning Rate: 0.00101444
	LOSS [training: 0.11283538174844865 | validation: 0.09813201492647305]
	TIME [epoch: 8.97 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09360441052962021		[learning rate: 0.0010121]
		[batch 20/20] avg loss: 0.15228171734839654		[learning rate: 0.0010097]
	Learning Rate: 0.00100968
	LOSS [training: 0.12294306393900838 | validation: 0.12028161428409745]
	TIME [epoch: 8.96 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10442108686049381		[learning rate: 0.0010073]
		[batch 20/20] avg loss: 0.09909049918776187		[learning rate: 0.0010049]
	Learning Rate: 0.00100495
	LOSS [training: 0.10175579302412785 | validation: 0.13457801436201702]
	TIME [epoch: 8.98 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10622212836163214		[learning rate: 0.0010026]
		[batch 20/20] avg loss: 0.09936168073535803		[learning rate: 0.0010002]
	Learning Rate: 0.00100023
	LOSS [training: 0.10279190454849511 | validation: 0.07863254479557744]
	TIME [epoch: 8.96 sec]
Finished training in 4531.908 seconds.
