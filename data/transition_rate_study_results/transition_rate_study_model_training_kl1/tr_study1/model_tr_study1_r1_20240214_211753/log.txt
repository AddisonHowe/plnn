Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r1', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1671207579

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/20] avg loss: 10.227055616378413		[learning rate: 0.01]
		[batch 20/20] avg loss: 9.406676300338559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.816865958358488 | validation: 8.030756347044607]
	TIME [epoch: 47.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/20] avg loss: 7.264487265461997		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.275925933826096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.770206599644046 | validation: 6.271973231917208]
	TIME [epoch: 8.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/20] avg loss: 5.780528291880423		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.479201881336839		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.629865086608632 | validation: 5.455588722292245]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/20] avg loss: 5.16422854055528		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.197789865084243		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.181009202819762 | validation: 5.4034942038701335]
	TIME [epoch: 8.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/20] avg loss: 5.070282494418152		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.12641745491445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0983499746663 | validation: 5.185713169876706]
	TIME [epoch: 8.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 10/20] avg loss: 5.01343011490264		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.857318500606363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.935374307754501 | validation: 5.091772827508264]
	TIME [epoch: 8.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/20] avg loss: 4.8729068692856305		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.871331086482408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8721189778840195 | validation: 5.514538205461467]
	TIME [epoch: 8.7 sec]
EPOCH 8/500:
	Training over batches...
		[batch 10/20] avg loss: 4.9749744581812205		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.740351997630496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.857663227905857 | validation: 5.109893933072726]
	TIME [epoch: 8.67 sec]
EPOCH 9/500:
	Training over batches...
		[batch 10/20] avg loss: 4.391441655985246		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.388973685794132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.390207670889689 | validation: 4.825419605627419]
	TIME [epoch: 8.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 10/20] avg loss: 4.3040061000464185		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.279266772467499		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.291636436256957 | validation: 4.687739434686026]
	TIME [epoch: 8.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 10/20] avg loss: 4.184596250503336		[learning rate: 0.0099789]
		[batch 20/20] avg loss: 4.314241101580277		[learning rate: 0.0099555]
	Learning Rate: 0.00995546
	LOSS [training: 4.249418676041808 | validation: 4.32887737296973]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 10/20] avg loss: 4.730838142017262		[learning rate: 0.0099321]
		[batch 20/20] avg loss: 4.648407520469222		[learning rate: 0.0099088]
	Learning Rate: 0.00990879
	LOSS [training: 4.689622831243242 | validation: 5.429097669488102]
	TIME [epoch: 8.67 sec]
EPOCH 13/500:
	Training over batches...
		[batch 10/20] avg loss: 4.509157436499878		[learning rate: 0.0098855]
		[batch 20/20] avg loss: 4.257477039860712		[learning rate: 0.0098623]
	Learning Rate: 0.00986233
	LOSS [training: 4.383317238180294 | validation: 4.184405157536738]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 10/20] avg loss: 4.030229015145577		[learning rate: 0.0098392]
		[batch 20/20] avg loss: 4.392351206702422		[learning rate: 0.0098161]
	Learning Rate: 0.0098161
	LOSS [training: 4.211290110924 | validation: 5.0368096050568845]
	TIME [epoch: 8.68 sec]
EPOCH 15/500:
	Training over batches...
		[batch 10/20] avg loss: 4.455557623405292		[learning rate: 0.0097931]
		[batch 20/20] avg loss: 3.930144143080711		[learning rate: 0.0097701]
	Learning Rate: 0.00977008
	LOSS [training: 4.192850883243001 | validation: 4.96060869427847]
	TIME [epoch: 8.66 sec]
EPOCH 16/500:
	Training over batches...
		[batch 10/20] avg loss: 3.891784857131131		[learning rate: 0.0097471]
		[batch 20/20] avg loss: 3.953252786092352		[learning rate: 0.0097243]
	Learning Rate: 0.00972427
	LOSS [training: 3.9225188216117424 | validation: 4.460476898128835]
	TIME [epoch: 8.7 sec]
EPOCH 17/500:
	Training over batches...
		[batch 10/20] avg loss: 4.057954877143512		[learning rate: 0.0097015]
		[batch 20/20] avg loss: 4.093005362680232		[learning rate: 0.0096787]
	Learning Rate: 0.00967868
	LOSS [training: 4.075480119911871 | validation: 5.536372689944068]
	TIME [epoch: 8.65 sec]
EPOCH 18/500:
	Training over batches...
		[batch 10/20] avg loss: 4.615268777483744		[learning rate: 0.009656]
		[batch 20/20] avg loss: 3.8532853123926416		[learning rate: 0.0096333]
	Learning Rate: 0.00963331
	LOSS [training: 4.234277044938192 | validation: 4.608308800155263]
	TIME [epoch: 8.65 sec]
EPOCH 19/500:
	Training over batches...
		[batch 10/20] avg loss: 4.226689207435404		[learning rate: 0.0096107]
		[batch 20/20] avg loss: 3.6089062079675527		[learning rate: 0.0095881]
	Learning Rate: 0.00958815
	LOSS [training: 3.917797707701478 | validation: 4.474542609089155]
	TIME [epoch: 8.65 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/20] avg loss: 3.919682008646293		[learning rate: 0.0095656]
		[batch 20/20] avg loss: 4.763494747836894		[learning rate: 0.0095432]
	Learning Rate: 0.0095432
	LOSS [training: 4.341588378241594 | validation: 4.082276681701152]
	TIME [epoch: 8.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 10/20] avg loss: 4.05382501612266		[learning rate: 0.0095208]
		[batch 20/20] avg loss: 3.953127013905598		[learning rate: 0.0094985]
	Learning Rate: 0.00949846
	LOSS [training: 4.003476015014128 | validation: 5.509172039903336]
	TIME [epoch: 8.67 sec]
EPOCH 22/500:
	Training over batches...
		[batch 10/20] avg loss: 4.142175876911906		[learning rate: 0.0094762]
		[batch 20/20] avg loss: 3.9943051303192094		[learning rate: 0.0094539]
	Learning Rate: 0.00945393
	LOSS [training: 4.068240503615558 | validation: 5.000038007393934]
	TIME [epoch: 8.67 sec]
EPOCH 23/500:
	Training over batches...
		[batch 10/20] avg loss: 3.616693412849642		[learning rate: 0.0094317]
		[batch 20/20] avg loss: 3.543954952506371		[learning rate: 0.0094096]
	Learning Rate: 0.00940961
	LOSS [training: 3.5803241826780066 | validation: 3.550704197886404]
	TIME [epoch: 8.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 10/20] avg loss: 3.4321340481181957		[learning rate: 0.0093875]
		[batch 20/20] avg loss: 3.450236279194545		[learning rate: 0.0093655]
	Learning Rate: 0.00936549
	LOSS [training: 3.44118516365637 | validation: 3.575919372752241]
	TIME [epoch: 8.65 sec]
EPOCH 25/500:
	Training over batches...
		[batch 10/20] avg loss: 3.5391092307694514		[learning rate: 0.0093435]
		[batch 20/20] avg loss: 3.3806933599884355		[learning rate: 0.0093216]
	Learning Rate: 0.00932159
	LOSS [training: 3.4599012953789425 | validation: 3.6683773326430797]
	TIME [epoch: 8.67 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/20] avg loss: 3.423911333615332		[learning rate: 0.0092997]
		[batch 20/20] avg loss: 3.3589387622056037		[learning rate: 0.0092779]
	Learning Rate: 0.00927788
	LOSS [training: 3.391425047910468 | validation: 3.542382661565649]
	TIME [epoch: 8.64 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 10/20] avg loss: 3.201360087370009		[learning rate: 0.0092561]
		[batch 20/20] avg loss: 3.4261059122402626		[learning rate: 0.0092344]
	Learning Rate: 0.00923439
	LOSS [training: 3.3137329998051364 | validation: 3.6221782492905232]
	TIME [epoch: 8.65 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/20] avg loss: 3.411090270554073		[learning rate: 0.0092127]
		[batch 20/20] avg loss: 3.1278348650970615		[learning rate: 0.0091911]
	Learning Rate: 0.0091911
	LOSS [training: 3.269462567825567 | validation: 3.5185514295010947]
	TIME [epoch: 8.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 10/20] avg loss: 3.415524991953678		[learning rate: 0.0091695]
		[batch 20/20] avg loss: 3.15204826041776		[learning rate: 0.009148]
	Learning Rate: 0.00914801
	LOSS [training: 3.2837866261857185 | validation: 3.474247151914666]
	TIME [epoch: 8.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 10/20] avg loss: 3.27549394011277		[learning rate: 0.0091265]
		[batch 20/20] avg loss: 3.222797701289317		[learning rate: 0.0091051]
	Learning Rate: 0.00910512
	LOSS [training: 3.2491458207010426 | validation: 3.7162983390073276]
	TIME [epoch: 8.68 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/20] avg loss: 3.2108300400773233		[learning rate: 0.0090838]
		[batch 20/20] avg loss: 3.1780256492517425		[learning rate: 0.0090624]
	Learning Rate: 0.00906243
	LOSS [training: 3.1944278446645327 | validation: 3.4063409416440895]
	TIME [epoch: 8.64 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 10/20] avg loss: 3.5581212060812915		[learning rate: 0.0090412]
		[batch 20/20] avg loss: 3.0180745706810876		[learning rate: 0.0090199]
	Learning Rate: 0.00901995
	LOSS [training: 3.288097888381189 | validation: 3.442593143364145]
	TIME [epoch: 8.65 sec]
EPOCH 33/500:
	Training over batches...
		[batch 10/20] avg loss: 3.0485196268785435		[learning rate: 0.0089988]
		[batch 20/20] avg loss: 3.209744601124244		[learning rate: 0.0089777]
	Learning Rate: 0.00897766
	LOSS [training: 3.129132114001394 | validation: 3.193785225523792]
	TIME [epoch: 8.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 10/20] avg loss: 2.9336799816017933		[learning rate: 0.0089566]
		[batch 20/20] avg loss: 2.64350943506573		[learning rate: 0.0089356]
	Learning Rate: 0.00893557
	LOSS [training: 2.788594708333762 | validation: 3.4575593470854438]
	TIME [epoch: 8.67 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/20] avg loss: 2.8180993226010935		[learning rate: 0.0089146]
		[batch 20/20] avg loss: 2.646807615447839		[learning rate: 0.0088937]
	Learning Rate: 0.00889368
	LOSS [training: 2.7324534690244664 | validation: 2.6655486018834535]
	TIME [epoch: 8.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 10/20] avg loss: 2.643122730042289		[learning rate: 0.0088728]
		[batch 20/20] avg loss: 2.548457219645132		[learning rate: 0.008852]
	Learning Rate: 0.00885199
	LOSS [training: 2.5957899748437105 | validation: 2.6733173978199005]
	TIME [epoch: 8.65 sec]
EPOCH 37/500:
	Training over batches...
		[batch 10/20] avg loss: 2.7231383238108835		[learning rate: 0.0088312]
		[batch 20/20] avg loss: 2.6817458933282916		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.7024421085695876 | validation: 2.703731695860388]
	TIME [epoch: 8.64 sec]
EPOCH 38/500:
	Training over batches...
		[batch 10/20] avg loss: 2.42007039634425		[learning rate: 0.0087898]
		[batch 20/20] avg loss: 2.3908623429019102		[learning rate: 0.0087692]
	Learning Rate: 0.00876918
	LOSS [training: 2.40546636962308 | validation: 2.4804433887358885]
	TIME [epoch: 8.64 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 10/20] avg loss: 1.8787975862390547		[learning rate: 0.0087486]
		[batch 20/20] avg loss: 1.9454760461344889		[learning rate: 0.0087281]
	Learning Rate: 0.00872807
	LOSS [training: 1.9121368161867718 | validation: 1.4857216743519304]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_39.pth
	Model improved!!!
EPOCH 40/500:
	Training over batches...
		[batch 10/20] avg loss: 1.463033355577511		[learning rate: 0.0087076]
		[batch 20/20] avg loss: 1.4726489041971234		[learning rate: 0.0086872]
	Learning Rate: 0.00868715
	LOSS [training: 1.467841129887317 | validation: 1.3622900613556317]
	TIME [epoch: 8.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3446073489255788		[learning rate: 0.0086668]
		[batch 20/20] avg loss: 1.2626599100322848		[learning rate: 0.0086464]
	Learning Rate: 0.00864643
	LOSS [training: 1.303633629478932 | validation: 2.2330533986592984]
	TIME [epoch: 8.67 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/20] avg loss: 1.5249761636722965		[learning rate: 0.0086261]
		[batch 20/20] avg loss: 1.1547074438682896		[learning rate: 0.0086059]
	Learning Rate: 0.00860589
	LOSS [training: 1.339841803770293 | validation: 1.1528770863584055]
	TIME [epoch: 8.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 10/20] avg loss: 1.2900043869875666		[learning rate: 0.0085857]
		[batch 20/20] avg loss: 1.2429378964245088		[learning rate: 0.0085655]
	Learning Rate: 0.00856555
	LOSS [training: 1.2664711417060377 | validation: 1.6330975785185953]
	TIME [epoch: 8.67 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3484213601153376		[learning rate: 0.0085454]
		[batch 20/20] avg loss: 1.127053895440783		[learning rate: 0.0085254]
	Learning Rate: 0.00852539
	LOSS [training: 1.2377376277780603 | validation: 1.348701597300148]
	TIME [epoch: 8.69 sec]
EPOCH 45/500:
	Training over batches...
		[batch 10/20] avg loss: 1.259052832040701		[learning rate: 0.0085054]
		[batch 20/20] avg loss: 1.15762292148587		[learning rate: 0.0084854]
	Learning Rate: 0.00848542
	LOSS [training: 1.2083378767632857 | validation: 0.7875823219229596]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_45.pth
	Model improved!!!
EPOCH 46/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0650456510045718		[learning rate: 0.0084655]
		[batch 20/20] avg loss: 1.1308758226954236		[learning rate: 0.0084456]
	Learning Rate: 0.00844564
	LOSS [training: 1.0979607368499977 | validation: 1.0310853582818063]
	TIME [epoch: 8.67 sec]
EPOCH 47/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1504005295735154		[learning rate: 0.0084258]
		[batch 20/20] avg loss: 1.1091894444722212		[learning rate: 0.008406]
	Learning Rate: 0.00840605
	LOSS [training: 1.1297949870228683 | validation: 1.2020213581594752]
	TIME [epoch: 8.67 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1623767199226376		[learning rate: 0.0083863]
		[batch 20/20] avg loss: 1.3525901467670611		[learning rate: 0.0083666]
	Learning Rate: 0.00836664
	LOSS [training: 1.2574834333448492 | validation: 0.7317225360877891]
	TIME [epoch: 8.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_48.pth
	Model improved!!!
EPOCH 49/500:
	Training over batches...
		[batch 10/20] avg loss: 1.023970124274611		[learning rate: 0.008347]
		[batch 20/20] avg loss: 0.9908552368784559		[learning rate: 0.0083274]
	Learning Rate: 0.00832742
	LOSS [training: 1.0074126805765335 | validation: 1.380338591957208]
	TIME [epoch: 8.7 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/20] avg loss: 1.252967283811278		[learning rate: 0.0083079]
		[batch 20/20] avg loss: 1.4735082547004725		[learning rate: 0.0082884]
	Learning Rate: 0.00828838
	LOSS [training: 1.363237769255875 | validation: 0.8829551806343504]
	TIME [epoch: 8.67 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0142030447119175		[learning rate: 0.0082689]
		[batch 20/20] avg loss: 1.040024575327262		[learning rate: 0.0082495]
	Learning Rate: 0.00824952
	LOSS [training: 1.0271138100195896 | validation: 0.8527833227403407]
	TIME [epoch: 8.67 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1981394582044462		[learning rate: 0.0082302]
		[batch 20/20] avg loss: 1.0141749194365233		[learning rate: 0.0082108]
	Learning Rate: 0.00821084
	LOSS [training: 1.1061571888204846 | validation: 1.1737199932435831]
	TIME [epoch: 8.67 sec]
EPOCH 53/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1145876668714085		[learning rate: 0.0081916]
		[batch 20/20] avg loss: 1.1209205478576572		[learning rate: 0.0081723]
	Learning Rate: 0.00817235
	LOSS [training: 1.117754107364533 | validation: 2.5603337151985532]
	TIME [epoch: 8.65 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/20] avg loss: 1.205641403185863		[learning rate: 0.0081532]
		[batch 20/20] avg loss: 0.9403457215964274		[learning rate: 0.008134]
	Learning Rate: 0.00813404
	LOSS [training: 1.0729935623911457 | validation: 0.9285146914663079]
	TIME [epoch: 8.69 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9246589183598767		[learning rate: 0.0081149]
		[batch 20/20] avg loss: 1.1125816459269544		[learning rate: 0.0080959]
	Learning Rate: 0.0080959
	LOSS [training: 1.0186202821434154 | validation: 0.7085209305031592]
	TIME [epoch: 8.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_55.pth
	Model improved!!!
EPOCH 56/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9823059155108543		[learning rate: 0.0080769]
		[batch 20/20] avg loss: 0.935138091313361		[learning rate: 0.0080579]
	Learning Rate: 0.00805795
	LOSS [training: 0.958722003412108 | validation: 0.8567163301126274]
	TIME [epoch: 8.68 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9810247021286781		[learning rate: 0.008039]
		[batch 20/20] avg loss: 1.0437789067546261		[learning rate: 0.0080202]
	Learning Rate: 0.00802017
	LOSS [training: 1.012401804441652 | validation: 0.7762795699976388]
	TIME [epoch: 8.68 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9743923647300538		[learning rate: 0.0080013]
		[batch 20/20] avg loss: 1.251766454420088		[learning rate: 0.0079826]
	Learning Rate: 0.00798257
	LOSS [training: 1.1130794095750711 | validation: 1.1127675572252531]
	TIME [epoch: 8.72 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0161578360647734		[learning rate: 0.0079638]
		[batch 20/20] avg loss: 1.0027048415915611		[learning rate: 0.0079451]
	Learning Rate: 0.00794515
	LOSS [training: 1.0094313388281673 | validation: 0.7864610306425901]
	TIME [epoch: 8.68 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/20] avg loss: 1.059263745719646		[learning rate: 0.0079265]
		[batch 20/20] avg loss: 0.8548197223598899		[learning rate: 0.0079079]
	Learning Rate: 0.0079079
	LOSS [training: 0.9570417340397679 | validation: 0.73418791038486]
	TIME [epoch: 8.69 sec]
EPOCH 61/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9192062197858712		[learning rate: 0.0078893]
		[batch 20/20] avg loss: 1.0560081340343503		[learning rate: 0.0078708]
	Learning Rate: 0.00787083
	LOSS [training: 0.9876071769101108 | validation: 0.6628203682470823]
	TIME [epoch: 8.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_61.pth
	Model improved!!!
EPOCH 62/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8594936831270346		[learning rate: 0.0078524]
		[batch 20/20] avg loss: 0.9596573767016032		[learning rate: 0.0078339]
	Learning Rate: 0.00783393
	LOSS [training: 0.9095755299143187 | validation: 0.6078256214337665]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1363075498332935		[learning rate: 0.0078155]
		[batch 20/20] avg loss: 0.8915750955680821		[learning rate: 0.0077972]
	Learning Rate: 0.0077972
	LOSS [training: 1.013941322700688 | validation: 0.6550578512994017]
	TIME [epoch: 8.7 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8350011417295526		[learning rate: 0.0077789]
		[batch 20/20] avg loss: 1.0334925393361563		[learning rate: 0.0077606]
	Learning Rate: 0.00776065
	LOSS [training: 0.9342468405328542 | validation: 0.7678171819808974]
	TIME [epoch: 8.66 sec]
EPOCH 65/500:
	Training over batches...
		[batch 10/20] avg loss: 1.267188967361146		[learning rate: 0.0077424]
		[batch 20/20] avg loss: 0.9034228479933418		[learning rate: 0.0077243]
	Learning Rate: 0.00772426
	LOSS [training: 1.085305907677244 | validation: 0.5628757541852878]
	TIME [epoch: 8.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_65.pth
	Model improved!!!
EPOCH 66/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8740198408359303		[learning rate: 0.0077061]
		[batch 20/20] avg loss: 0.9503911227984707		[learning rate: 0.0076881]
	Learning Rate: 0.00768805
	LOSS [training: 0.9122054818172003 | validation: 0.617841973740636]
	TIME [epoch: 8.66 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9308774564214726		[learning rate: 0.00767]
		[batch 20/20] avg loss: 0.9257822744985468		[learning rate: 0.007652]
	Learning Rate: 0.00765201
	LOSS [training: 0.9283298654600097 | validation: 0.699455390252651]
	TIME [epoch: 8.66 sec]
EPOCH 68/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8714627104056328		[learning rate: 0.0076341]
		[batch 20/20] avg loss: 1.0027542104162621		[learning rate: 0.0076161]
	Learning Rate: 0.00761614
	LOSS [training: 0.9371084604109473 | validation: 0.6558705143787269]
	TIME [epoch: 8.69 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0762776904189253		[learning rate: 0.0075983]
		[batch 20/20] avg loss: 1.0747870426881279		[learning rate: 0.0075804]
	Learning Rate: 0.00758043
	LOSS [training: 1.0755323665535266 | validation: 0.7090767281884637]
	TIME [epoch: 8.66 sec]
EPOCH 70/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0014313253134888		[learning rate: 0.0075626]
		[batch 20/20] avg loss: 0.787193336361022		[learning rate: 0.0075449]
	Learning Rate: 0.00754489
	LOSS [training: 0.8943123308372553 | validation: 0.929245676613103]
	TIME [epoch: 8.65 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/20] avg loss: 1.034791435507093		[learning rate: 0.0075272]
		[batch 20/20] avg loss: 0.9234980684860634		[learning rate: 0.0075095]
	Learning Rate: 0.00750952
	LOSS [training: 0.9791447519965784 | validation: 0.759340315661788]
	TIME [epoch: 8.65 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/20] avg loss: 0.883168305315136		[learning rate: 0.0074919]
		[batch 20/20] avg loss: 0.8593650303676654		[learning rate: 0.0074743]
	Learning Rate: 0.00747431
	LOSS [training: 0.8712666678414008 | validation: 0.5682702233097349]
	TIME [epoch: 8.66 sec]
EPOCH 73/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9491862171576091		[learning rate: 0.0074568]
		[batch 20/20] avg loss: 0.8184783425761812		[learning rate: 0.0074393]
	Learning Rate: 0.00743927
	LOSS [training: 0.8838322798668952 | validation: 1.5496806691232263]
	TIME [epoch: 8.68 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8684735921728608		[learning rate: 0.0074218]
		[batch 20/20] avg loss: 0.9291329596850039		[learning rate: 0.0074044]
	Learning Rate: 0.0074044
	LOSS [training: 0.8988032759289324 | validation: 1.1420679787037855]
	TIME [epoch: 8.66 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8522310257474042		[learning rate: 0.007387]
		[batch 20/20] avg loss: 0.9999735477673178		[learning rate: 0.0073697]
	Learning Rate: 0.00736969
	LOSS [training: 0.926102286757361 | validation: 0.8644978822965179]
	TIME [epoch: 8.65 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8371840949379233		[learning rate: 0.0073524]
		[batch 20/20] avg loss: 0.8831216194492238		[learning rate: 0.0073351]
	Learning Rate: 0.00733514
	LOSS [training: 0.8601528571935736 | validation: 0.7724040104372207]
	TIME [epoch: 8.67 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/20] avg loss: 0.866873560127431		[learning rate: 0.0073179]
		[batch 20/20] avg loss: 0.9606263817215913		[learning rate: 0.0073007]
	Learning Rate: 0.00730075
	LOSS [training: 0.9137499709245113 | validation: 0.61093539606249]
	TIME [epoch: 8.68 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8937066290544685		[learning rate: 0.0072836]
		[batch 20/20] avg loss: 0.8383763362008974		[learning rate: 0.0072665]
	Learning Rate: 0.00726652
	LOSS [training: 0.866041482627683 | validation: 0.5804689705748243]
	TIME [epoch: 8.67 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7225069026788696		[learning rate: 0.0072495]
		[batch 20/20] avg loss: 0.8733614763889694		[learning rate: 0.0072325]
	Learning Rate: 0.00723246
	LOSS [training: 0.7979341895339196 | validation: 0.6477968495875676]
	TIME [epoch: 8.66 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7249525473704608		[learning rate: 0.0072155]
		[batch 20/20] avg loss: 0.7715209760026497		[learning rate: 0.0071985]
	Learning Rate: 0.00719855
	LOSS [training: 0.7482367616865553 | validation: 0.7544706671331545]
	TIME [epoch: 8.65 sec]
EPOCH 81/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8207638543767652		[learning rate: 0.0071817]
		[batch 20/20] avg loss: 0.8382392782997223		[learning rate: 0.0071648]
	Learning Rate: 0.0071648
	LOSS [training: 0.8295015663382438 | validation: 0.7898159718814404]
	TIME [epoch: 8.66 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/20] avg loss: 0.730456487246852		[learning rate: 0.007148]
		[batch 20/20] avg loss: 0.902219730651109		[learning rate: 0.0071312]
	Learning Rate: 0.00713121
	LOSS [training: 0.8163381089489803 | validation: 0.7502706683154834]
	TIME [epoch: 8.68 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7814961700103529		[learning rate: 0.0071145]
		[batch 20/20] avg loss: 0.8195435881645468		[learning rate: 0.0070978]
	Learning Rate: 0.00709778
	LOSS [training: 0.8005198790874497 | validation: 0.6352382253199109]
	TIME [epoch: 8.68 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8353838597401019		[learning rate: 0.0070811]
		[batch 20/20] avg loss: 0.9743758882181313		[learning rate: 0.0070645]
	Learning Rate: 0.0070645
	LOSS [training: 0.9048798739791166 | validation: 0.7209668426014681]
	TIME [epoch: 8.66 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7659794661236041		[learning rate: 0.0070479]
		[batch 20/20] avg loss: 0.9893239016264077		[learning rate: 0.0070314]
	Learning Rate: 0.00703138
	LOSS [training: 0.8776516838750059 | validation: 0.6580734202891675]
	TIME [epoch: 8.66 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/20] avg loss: 0.793187614294435		[learning rate: 0.0070149]
		[batch 20/20] avg loss: 0.8685641894081819		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.8308759018513084 | validation: 0.5702682676491833]
	TIME [epoch: 8.66 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7925663595835465		[learning rate: 0.006982]
		[batch 20/20] avg loss: 0.8324651968629821		[learning rate: 0.0069656]
	Learning Rate: 0.00696561
	LOSS [training: 0.8125157782232645 | validation: 0.7800045569508847]
	TIME [epoch: 8.67 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7309920484895711		[learning rate: 0.0069493]
		[batch 20/20] avg loss: 0.7319401039286415		[learning rate: 0.006933]
	Learning Rate: 0.00693295
	LOSS [training: 0.7314660762091064 | validation: 0.47798237031066704]
	TIME [epoch: 8.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_88.pth
	Model improved!!!
EPOCH 89/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7396556489228991		[learning rate: 0.0069167]
		[batch 20/20] avg loss: 0.9407328160020068		[learning rate: 0.0069005]
	Learning Rate: 0.00690045
	LOSS [training: 0.8401942324624532 | validation: 0.5500397979991036]
	TIME [epoch: 8.68 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6797115942496953		[learning rate: 0.0068843]
		[batch 20/20] avg loss: 0.858280857149501		[learning rate: 0.0068681]
	Learning Rate: 0.0068681
	LOSS [training: 0.7689962256995981 | validation: 0.7712979051386767]
	TIME [epoch: 8.69 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7365553515241906		[learning rate: 0.006852]
		[batch 20/20] avg loss: 0.7997301216466596		[learning rate: 0.0068359]
	Learning Rate: 0.0068359
	LOSS [training: 0.7681427365854251 | validation: 0.4257426589027956]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_91.pth
	Model improved!!!
EPOCH 92/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9378683282026896		[learning rate: 0.0068199]
		[batch 20/20] avg loss: 0.7250858929612204		[learning rate: 0.0068039]
	Learning Rate: 0.00680386
	LOSS [training: 0.8314771105819551 | validation: 1.4813236708177218]
	TIME [epoch: 8.73 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8066738879679264		[learning rate: 0.0067879]
		[batch 20/20] avg loss: 0.703518817566209		[learning rate: 0.006772]
	Learning Rate: 0.00677196
	LOSS [training: 0.7550963527670677 | validation: 0.5911167391780547]
	TIME [epoch: 8.71 sec]
EPOCH 94/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6743163400201153		[learning rate: 0.0067561]
		[batch 20/20] avg loss: 0.7954777376619887		[learning rate: 0.0067402]
	Learning Rate: 0.00674021
	LOSS [training: 0.7348970388410521 | validation: 0.47753235383811776]
	TIME [epoch: 8.69 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9101969687264277		[learning rate: 0.0067244]
		[batch 20/20] avg loss: 0.9110159441999267		[learning rate: 0.0067086]
	Learning Rate: 0.00670861
	LOSS [training: 0.9106064564631773 | validation: 0.46146331191769163]
	TIME [epoch: 8.71 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7958212126342504		[learning rate: 0.0066929]
		[batch 20/20] avg loss: 0.7668261963593267		[learning rate: 0.0066772]
	Learning Rate: 0.00667716
	LOSS [training: 0.7813237044967887 | validation: 0.9974465356593607]
	TIME [epoch: 8.72 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7796064146299073		[learning rate: 0.0066615]
		[batch 20/20] avg loss: 0.8477547979068684		[learning rate: 0.0066459]
	Learning Rate: 0.00664586
	LOSS [training: 0.8136806062683878 | validation: 1.106633612133229]
	TIME [epoch: 8.73 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9325005692143348		[learning rate: 0.0066303]
		[batch 20/20] avg loss: 0.8428870835010317		[learning rate: 0.0066147]
	Learning Rate: 0.0066147
	LOSS [training: 0.8876938263576832 | validation: 0.543321103307525]
	TIME [epoch: 8.72 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6704221244886982		[learning rate: 0.0065992]
		[batch 20/20] avg loss: 0.9543521633887648		[learning rate: 0.0065837]
	Learning Rate: 0.00658369
	LOSS [training: 0.8123871439387316 | validation: 1.0913874891841573]
	TIME [epoch: 8.74 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/20] avg loss: 0.785100308740197		[learning rate: 0.0065682]
		[batch 20/20] avg loss: 0.8260051705233563		[learning rate: 0.0065528]
	Learning Rate: 0.00655282
	LOSS [training: 0.8055527396317765 | validation: 0.7749185861759509]
	TIME [epoch: 8.7 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7840822231163307		[learning rate: 0.0065374]
		[batch 20/20] avg loss: 0.7221888591228767		[learning rate: 0.0065221]
	Learning Rate: 0.0065221
	LOSS [training: 0.7531355411196037 | validation: 0.6146358628518455]
	TIME [epoch: 8.72 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8772796065580094		[learning rate: 0.0065068]
		[batch 20/20] avg loss: 0.8086691617176218		[learning rate: 0.0064915]
	Learning Rate: 0.00649153
	LOSS [training: 0.8429743841378157 | validation: 0.5565965764955523]
	TIME [epoch: 8.7 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7581308723788129		[learning rate: 0.0064763]
		[batch 20/20] avg loss: 0.9460826307548018		[learning rate: 0.0064611]
	Learning Rate: 0.0064611
	LOSS [training: 0.8521067515668074 | validation: 0.7343672234775112]
	TIME [epoch: 8.71 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6889024456125892		[learning rate: 0.0064459]
		[batch 20/20] avg loss: 1.073931431072514		[learning rate: 0.0064308]
	Learning Rate: 0.0064308
	LOSS [training: 0.8814169383425516 | validation: 0.7754204978050275]
	TIME [epoch: 8.7 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6719802522402655		[learning rate: 0.0064157]
		[batch 20/20] avg loss: 0.7226558273220755		[learning rate: 0.0064007]
	Learning Rate: 0.00640066
	LOSS [training: 0.6973180397811705 | validation: 0.6700150132756533]
	TIME [epoch: 8.7 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6677602537559719		[learning rate: 0.0063856]
		[batch 20/20] avg loss: 0.7300891938181217		[learning rate: 0.0063706]
	Learning Rate: 0.00637065
	LOSS [training: 0.6989247237870468 | validation: 0.4352961261363768]
	TIME [epoch: 8.73 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7562570178993253		[learning rate: 0.0063557]
		[batch 20/20] avg loss: 0.7613792833059974		[learning rate: 0.0063408]
	Learning Rate: 0.00634078
	LOSS [training: 0.7588181506026613 | validation: 0.5110707743248539]
	TIME [epoch: 8.7 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8685992281286822		[learning rate: 0.0063259]
		[batch 20/20] avg loss: 0.8073163689740523		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.8379577985513673 | validation: 0.6814943118185277]
	TIME [epoch: 8.69 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6987410156268454		[learning rate: 0.0062962]
		[batch 20/20] avg loss: 0.7728916763941774		[learning rate: 0.0062815]
	Learning Rate: 0.00628147
	LOSS [training: 0.7358163460105114 | validation: 0.6245793139555332]
	TIME [epoch: 8.69 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/20] avg loss: 0.691635901497832		[learning rate: 0.0062667]
		[batch 20/20] avg loss: 0.6697757587479659		[learning rate: 0.006252]
	Learning Rate: 0.00625202
	LOSS [training: 0.680705830122899 | validation: 0.3779973179828631]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6642323985789976		[learning rate: 0.0062373]
		[batch 20/20] avg loss: 0.6868263033031916		[learning rate: 0.0062227]
	Learning Rate: 0.00622271
	LOSS [training: 0.6755293509410947 | validation: 1.2105243475205212]
	TIME [epoch: 8.7 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7579210780633241		[learning rate: 0.0062081]
		[batch 20/20] avg loss: 0.6969738765472063		[learning rate: 0.0061935]
	Learning Rate: 0.00619354
	LOSS [training: 0.7274474773052652 | validation: 0.36268863689908537]
	TIME [epoch: 8.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_112.pth
	Model improved!!!
EPOCH 113/500:
	Training over batches...
		[batch 10/20] avg loss: 0.580318207201292		[learning rate: 0.006179]
		[batch 20/20] avg loss: 0.6390492626271866		[learning rate: 0.0061645]
	Learning Rate: 0.0061645
	LOSS [training: 0.6096837349142393 | validation: 1.2080247765095955]
	TIME [epoch: 8.7 sec]
EPOCH 114/500:
	Training over batches...
		[batch 10/20] avg loss: 0.658900137619892		[learning rate: 0.00615]
		[batch 20/20] avg loss: 0.6797503385701682		[learning rate: 0.0061356]
	Learning Rate: 0.0061356
	LOSS [training: 0.6693252380950302 | validation: 0.6380622666610165]
	TIME [epoch: 8.72 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7237057676769381		[learning rate: 0.0061212]
		[batch 20/20] avg loss: 0.7109848323346952		[learning rate: 0.0061068]
	Learning Rate: 0.00610684
	LOSS [training: 0.7173453000058166 | validation: 0.44514613989977436]
	TIME [epoch: 8.71 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5779003742200752		[learning rate: 0.0060925]
		[batch 20/20] avg loss: 0.5949336929389099		[learning rate: 0.0060782]
	Learning Rate: 0.00607821
	LOSS [training: 0.5864170335794924 | validation: 0.6368136716954876]
	TIME [epoch: 8.75 sec]
EPOCH 117/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5886120325154541		[learning rate: 0.0060639]
		[batch 20/20] avg loss: 0.9664817977280519		[learning rate: 0.0060497]
	Learning Rate: 0.00604971
	LOSS [training: 0.7775469151217529 | validation: 0.42997281249433766]
	TIME [epoch: 8.69 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6149042309619823		[learning rate: 0.0060355]
		[batch 20/20] avg loss: 0.6775593645281331		[learning rate: 0.0060213]
	Learning Rate: 0.00602135
	LOSS [training: 0.6462317977450578 | validation: 0.5224957125301994]
	TIME [epoch: 8.69 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6421638380713011		[learning rate: 0.0060072]
		[batch 20/20] avg loss: 0.7093553059632068		[learning rate: 0.0059931]
	Learning Rate: 0.00599312
	LOSS [training: 0.675759572017254 | validation: 0.605973662391067]
	TIME [epoch: 8.68 sec]
EPOCH 120/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6988200642715057		[learning rate: 0.0059791]
		[batch 20/20] avg loss: 0.6174389307155476		[learning rate: 0.005965]
	Learning Rate: 0.00596502
	LOSS [training: 0.6581294974935267 | validation: 0.5291958685733463]
	TIME [epoch: 8.69 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7403695208934122		[learning rate: 0.005951]
		[batch 20/20] avg loss: 0.8051209133064996		[learning rate: 0.0059371]
	Learning Rate: 0.00593706
	LOSS [training: 0.772745217099956 | validation: 0.4114182269773323]
	TIME [epoch: 8.69 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6076012159904812		[learning rate: 0.0059231]
		[batch 20/20] avg loss: 0.5727771930171828		[learning rate: 0.0059092]
	Learning Rate: 0.00590923
	LOSS [training: 0.5901892045038319 | validation: 1.0367244083047917]
	TIME [epoch: 8.67 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5912657859567658		[learning rate: 0.0058954]
		[batch 20/20] avg loss: 0.7247002321052264		[learning rate: 0.0058815]
	Learning Rate: 0.00588152
	LOSS [training: 0.657983009030996 | validation: 0.8696091946242356]
	TIME [epoch: 8.69 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/20] avg loss: 0.631095365016719		[learning rate: 0.0058677]
		[batch 20/20] avg loss: 0.6116692763299298		[learning rate: 0.0058539]
	Learning Rate: 0.00585395
	LOSS [training: 0.6213823206733246 | validation: 0.34978817477117163]
	TIME [epoch: 8.67 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_124.pth
	Model improved!!!
EPOCH 125/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6920348588371049		[learning rate: 0.0058402]
		[batch 20/20] avg loss: 0.6803020493501168		[learning rate: 0.0058265]
	Learning Rate: 0.00582651
	LOSS [training: 0.6861684540936108 | validation: 0.42666435706474837]
	TIME [epoch: 8.72 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/20] avg loss: 0.750284971794098		[learning rate: 0.0058128]
		[batch 20/20] avg loss: 0.7210011516397845		[learning rate: 0.0057992]
	Learning Rate: 0.00579919
	LOSS [training: 0.7356430617169414 | validation: 0.524178044069904]
	TIME [epoch: 8.68 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6376456288944355		[learning rate: 0.0057856]
		[batch 20/20] avg loss: 0.8712246798591415		[learning rate: 0.005772]
	Learning Rate: 0.005772
	LOSS [training: 0.7544351543767887 | validation: 0.728495157092401]
	TIME [epoch: 8.69 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/20] avg loss: 0.594248512672347		[learning rate: 0.0057585]
		[batch 20/20] avg loss: 0.6582816909143566		[learning rate: 0.0057449]
	Learning Rate: 0.00574494
	LOSS [training: 0.6262651017933517 | validation: 0.45258555349429164]
	TIME [epoch: 8.68 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8378803465459885		[learning rate: 0.0057315]
		[batch 20/20] avg loss: 0.7282001005222147		[learning rate: 0.005718]
	Learning Rate: 0.00571801
	LOSS [training: 0.7830402235341016 | validation: 0.5528413210563108]
	TIME [epoch: 8.67 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7395937714920164		[learning rate: 0.0057046]
		[batch 20/20] avg loss: 0.7002831461669692		[learning rate: 0.0056912]
	Learning Rate: 0.0056912
	LOSS [training: 0.7199384588294928 | validation: 0.42996971474602863]
	TIME [epoch: 8.69 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7062387385067292		[learning rate: 0.0056778]
		[batch 20/20] avg loss: 0.6760583583588949		[learning rate: 0.0056645]
	Learning Rate: 0.00566452
	LOSS [training: 0.691148548432812 | validation: 0.4091754168410434]
	TIME [epoch: 8.67 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5603338528336393		[learning rate: 0.0056512]
		[batch 20/20] avg loss: 0.573247806041058		[learning rate: 0.005638]
	Learning Rate: 0.00563797
	LOSS [training: 0.5667908294373485 | validation: 0.5311357991958834]
	TIME [epoch: 8.67 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6663512630995244		[learning rate: 0.0056247]
		[batch 20/20] avg loss: 0.7312551472674091		[learning rate: 0.0056115]
	Learning Rate: 0.00561153
	LOSS [training: 0.6988032051834668 | validation: 0.7201362693206852]
	TIME [epoch: 8.68 sec]
EPOCH 134/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5292015577966981		[learning rate: 0.0055984]
		[batch 20/20] avg loss: 0.6083021180218545		[learning rate: 0.0055852]
	Learning Rate: 0.00558523
	LOSS [training: 0.5687518379092763 | validation: 0.374552223590937]
	TIME [epoch: 8.68 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5588217716105347		[learning rate: 0.0055721]
		[batch 20/20] avg loss: 0.7380675028144081		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.6484446372124715 | validation: 0.8178225594827705]
	TIME [epoch: 8.7 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/20] avg loss: 0.553302954643654		[learning rate: 0.005546]
		[batch 20/20] avg loss: 0.6943994524548064		[learning rate: 0.005533]
	Learning Rate: 0.00553298
	LOSS [training: 0.6238512035492303 | validation: 0.6737271364137496]
	TIME [epoch: 8.69 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6200627225890185		[learning rate: 0.00552]
		[batch 20/20] avg loss: 0.5075897810709964		[learning rate: 0.005507]
	Learning Rate: 0.00550704
	LOSS [training: 0.5638262518300075 | validation: 0.9674454373579898]
	TIME [epoch: 8.7 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/20] avg loss: 0.675318396583568		[learning rate: 0.0054941]
		[batch 20/20] avg loss: 0.6940375403346364		[learning rate: 0.0054812]
	Learning Rate: 0.00548122
	LOSS [training: 0.6846779684591022 | validation: 0.7479424695502278]
	TIME [epoch: 8.69 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6165331870131681		[learning rate: 0.0054684]
		[batch 20/20] avg loss: 0.6216604439928414		[learning rate: 0.0054555]
	Learning Rate: 0.00545553
	LOSS [training: 0.6190968155030048 | validation: 1.3353025031923054]
	TIME [epoch: 8.68 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8006458947782396		[learning rate: 0.0054427]
		[batch 20/20] avg loss: 0.6672024103376993		[learning rate: 0.00543]
	Learning Rate: 0.00542995
	LOSS [training: 0.7339241525579693 | validation: 0.6578942753896475]
	TIME [epoch: 8.72 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5489689878680435		[learning rate: 0.0054172]
		[batch 20/20] avg loss: 0.6856252708687505		[learning rate: 0.0054045]
	Learning Rate: 0.00540449
	LOSS [training: 0.617297129368397 | validation: 0.5679943562148445]
	TIME [epoch: 8.7 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5010005024668323		[learning rate: 0.0053918]
		[batch 20/20] avg loss: 0.6632317612956562		[learning rate: 0.0053792]
	Learning Rate: 0.00537916
	LOSS [training: 0.5821161318812443 | validation: 0.33910084483887254]
	TIME [epoch: 8.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_142.pth
	Model improved!!!
EPOCH 143/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6205745951628472		[learning rate: 0.0053665]
		[batch 20/20] avg loss: 0.5532845678732332		[learning rate: 0.0053539]
	Learning Rate: 0.00535394
	LOSS [training: 0.5869295815180403 | validation: 0.37995528497048514]
	TIME [epoch: 8.66 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6254781743952372		[learning rate: 0.0053414]
		[batch 20/20] avg loss: 0.5973382009842811		[learning rate: 0.0053288]
	Learning Rate: 0.00532884
	LOSS [training: 0.6114081876897592 | validation: 0.6864282282091347]
	TIME [epoch: 8.68 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6656676213610828		[learning rate: 0.0053163]
		[batch 20/20] avg loss: 0.6429320959669995		[learning rate: 0.0053039]
	Learning Rate: 0.00530386
	LOSS [training: 0.6542998586640411 | validation: 0.2979724492300395]
	TIME [epoch: 8.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_145.pth
	Model improved!!!
EPOCH 146/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6900320780859042		[learning rate: 0.0052914]
		[batch 20/20] avg loss: 0.5156096859116285		[learning rate: 0.005279]
	Learning Rate: 0.00527899
	LOSS [training: 0.6028208819987664 | validation: 0.4437739894272957]
	TIME [epoch: 8.65 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5092251135942524		[learning rate: 0.0052666]
		[batch 20/20] avg loss: 0.617968038544854		[learning rate: 0.0052542]
	Learning Rate: 0.00525424
	LOSS [training: 0.5635965760695533 | validation: 1.0436286472676253]
	TIME [epoch: 8.66 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8515663016035628		[learning rate: 0.0052419]
		[batch 20/20] avg loss: 0.6167833419237252		[learning rate: 0.0052296]
	Learning Rate: 0.00522961
	LOSS [training: 0.7341748217636438 | validation: 0.5845796100342981]
	TIME [epoch: 8.66 sec]
EPOCH 149/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6197064465507067		[learning rate: 0.0052173]
		[batch 20/20] avg loss: 0.7507193736392287		[learning rate: 0.0052051]
	Learning Rate: 0.00520509
	LOSS [training: 0.6852129100949677 | validation: 0.642287764772169]
	TIME [epoch: 8.68 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5996314409955472		[learning rate: 0.0051929]
		[batch 20/20] avg loss: 0.518242342521287		[learning rate: 0.0051807]
	Learning Rate: 0.00518069
	LOSS [training: 0.5589368917584171 | validation: 0.4130790282001193]
	TIME [epoch: 8.66 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/20] avg loss: 0.46585706587008485		[learning rate: 0.0051685]
		[batch 20/20] avg loss: 0.6142669635123558		[learning rate: 0.0051564]
	Learning Rate: 0.0051564
	LOSS [training: 0.5400620146912203 | validation: 0.5760896105308234]
	TIME [epoch: 8.66 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5401390937176884		[learning rate: 0.0051443]
		[batch 20/20] avg loss: 0.7665351342129969		[learning rate: 0.0051322]
	Learning Rate: 0.00513223
	LOSS [training: 0.6533371139653428 | validation: 0.9005554316838005]
	TIME [epoch: 8.66 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6626498685050388		[learning rate: 0.0051202]
		[batch 20/20] avg loss: 0.5246519680412401		[learning rate: 0.0051082]
	Learning Rate: 0.00510817
	LOSS [training: 0.5936509182731394 | validation: 0.8410649537235105]
	TIME [epoch: 8.65 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5876210646161628		[learning rate: 0.0050962]
		[batch 20/20] avg loss: 0.6983895055406084		[learning rate: 0.0050842]
	Learning Rate: 0.00508422
	LOSS [training: 0.6430052850783856 | validation: 0.8134129249148992]
	TIME [epoch: 8.68 sec]
EPOCH 155/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5833288688667211		[learning rate: 0.0050723]
		[batch 20/20] avg loss: 0.5357620501839138		[learning rate: 0.0050604]
	Learning Rate: 0.00506039
	LOSS [training: 0.5595454595253174 | validation: 0.3629970501081622]
	TIME [epoch: 8.66 sec]
EPOCH 156/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5509053067353202		[learning rate: 0.0050485]
		[batch 20/20] avg loss: 0.5680457123486613		[learning rate: 0.0050367]
	Learning Rate: 0.00503666
	LOSS [training: 0.5594755095419907 | validation: 0.47081535509809747]
	TIME [epoch: 8.65 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/20] avg loss: 0.46622189746279263		[learning rate: 0.0050248]
		[batch 20/20] avg loss: 0.6011373571499344		[learning rate: 0.005013]
	Learning Rate: 0.00501305
	LOSS [training: 0.5336796273063636 | validation: 0.3121439609173904]
	TIME [epoch: 8.67 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5110891976754662		[learning rate: 0.0050013]
		[batch 20/20] avg loss: 0.8358229804790923		[learning rate: 0.0049895]
	Learning Rate: 0.00498955
	LOSS [training: 0.6734560890772794 | validation: 0.5547678622585788]
	TIME [epoch: 8.65 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5077597211526454		[learning rate: 0.0049778]
		[batch 20/20] avg loss: 0.5032429008270376		[learning rate: 0.0049662]
	Learning Rate: 0.00496616
	LOSS [training: 0.5055013109898415 | validation: 0.32170064933415277]
	TIME [epoch: 8.69 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6119003365184972		[learning rate: 0.0049545]
		[batch 20/20] avg loss: 0.4376467490251648		[learning rate: 0.0049429]
	Learning Rate: 0.00494287
	LOSS [training: 0.524773542771831 | validation: 0.9325446911106541]
	TIME [epoch: 8.65 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7742280754914374		[learning rate: 0.0049313]
		[batch 20/20] avg loss: 0.5247746901957633		[learning rate: 0.0049197]
	Learning Rate: 0.0049197
	LOSS [training: 0.6495013828436003 | validation: 0.39519111399759993]
	TIME [epoch: 8.65 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5440503062158492		[learning rate: 0.0049082]
		[batch 20/20] avg loss: 0.5729352967883323		[learning rate: 0.0048966]
	Learning Rate: 0.00489664
	LOSS [training: 0.5584928015020907 | validation: 0.3979211597665681]
	TIME [epoch: 8.65 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4497927908012486		[learning rate: 0.0048851]
		[batch 20/20] avg loss: 0.5881216439295586		[learning rate: 0.0048737]
	Learning Rate: 0.00487368
	LOSS [training: 0.5189572173654037 | validation: 0.3742032753114981]
	TIME [epoch: 8.65 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44253982532645486		[learning rate: 0.0048622]
		[batch 20/20] avg loss: 0.5581579265494698		[learning rate: 0.0048508]
	Learning Rate: 0.00485083
	LOSS [training: 0.5003488759379623 | validation: 0.4571378542274124]
	TIME [epoch: 8.68 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5120457303013001		[learning rate: 0.0048394]
		[batch 20/20] avg loss: 0.49881379298337025		[learning rate: 0.0048281]
	Learning Rate: 0.00482809
	LOSS [training: 0.5054297616423351 | validation: 0.3097639269470469]
	TIME [epoch: 8.66 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5509175945665555		[learning rate: 0.0048168]
		[batch 20/20] avg loss: 0.5794375170890712		[learning rate: 0.0048055]
	Learning Rate: 0.00480546
	LOSS [training: 0.5651775558278133 | validation: 0.35481543454529213]
	TIME [epoch: 8.67 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/20] avg loss: 0.52417142585004		[learning rate: 0.0047942]
		[batch 20/20] avg loss: 0.49783238683952524		[learning rate: 0.0047829]
	Learning Rate: 0.00478293
	LOSS [training: 0.5110019063447825 | validation: 0.5653639256269231]
	TIME [epoch: 8.65 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/20] avg loss: 0.611121287508723		[learning rate: 0.0047717]
		[batch 20/20] avg loss: 0.618709814996343		[learning rate: 0.0047605]
	Learning Rate: 0.00476051
	LOSS [training: 0.614915551252533 | validation: 0.5484721943990524]
	TIME [epoch: 8.68 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44490441837285954		[learning rate: 0.0047493]
		[batch 20/20] avg loss: 1.0116292951354344		[learning rate: 0.0047382]
	Learning Rate: 0.00473819
	LOSS [training: 0.7282668567541468 | validation: 0.6954334667345576]
	TIME [epoch: 8.67 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5059384660687787		[learning rate: 0.0047271]
		[batch 20/20] avg loss: 0.4248672959049028		[learning rate: 0.004716]
	Learning Rate: 0.00471597
	LOSS [training: 0.46540288098684074 | validation: 0.5842723209087327]
	TIME [epoch: 8.65 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4359339204076852		[learning rate: 0.0047049]
		[batch 20/20] avg loss: 0.40685258965394266		[learning rate: 0.0046939]
	Learning Rate: 0.00469386
	LOSS [training: 0.42139325503081393 | validation: 0.5453025187326269]
	TIME [epoch: 8.65 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5173132216018648		[learning rate: 0.0046828]
		[batch 20/20] avg loss: 0.5822133816486798		[learning rate: 0.0046719]
	Learning Rate: 0.00467186
	LOSS [training: 0.5497633016252721 | validation: 0.35663495701035275]
	TIME [epoch: 8.65 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/20] avg loss: 0.41930165955907545		[learning rate: 0.0046609]
		[batch 20/20] avg loss: 0.398972112203644		[learning rate: 0.00465]
	Learning Rate: 0.00464996
	LOSS [training: 0.4091368858813597 | validation: 0.39115634348698475]
	TIME [epoch: 8.68 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4865734070478968		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.46304470777188095		[learning rate: 0.0046282]
	Learning Rate: 0.00462816
	LOSS [training: 0.4748090574098889 | validation: 0.8447284883487276]
	TIME [epoch: 8.66 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6828508802738913		[learning rate: 0.0046173]
		[batch 20/20] avg loss: 0.6390805558741043		[learning rate: 0.0046065]
	Learning Rate: 0.00460646
	LOSS [training: 0.6609657180739978 | validation: 0.5501640181084323]
	TIME [epoch: 8.65 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5922874532940444		[learning rate: 0.0045956]
		[batch 20/20] avg loss: 0.41133474181683993		[learning rate: 0.0045849]
	Learning Rate: 0.00458486
	LOSS [training: 0.5018110975554422 | validation: 0.7744842123284378]
	TIME [epoch: 8.65 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5353663187765317		[learning rate: 0.0045741]
		[batch 20/20] avg loss: 0.5639737759165133		[learning rate: 0.0045634]
	Learning Rate: 0.00456337
	LOSS [training: 0.5496700473465226 | validation: 0.40462210672535937]
	TIME [epoch: 8.64 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/20] avg loss: 0.46366172253548593		[learning rate: 0.0045527]
		[batch 20/20] avg loss: 0.481058775552696		[learning rate: 0.004542]
	Learning Rate: 0.00454198
	LOSS [training: 0.47236024904409096 | validation: 0.304380226762809]
	TIME [epoch: 8.68 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/20] avg loss: 0.45030219074910693		[learning rate: 0.0045313]
		[batch 20/20] avg loss: 0.5294294352505814		[learning rate: 0.0045207]
	Learning Rate: 0.00452068
	LOSS [training: 0.48986581299984416 | validation: 0.3669817815315918]
	TIME [epoch: 8.66 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5230223368840423		[learning rate: 0.0045101]
		[batch 20/20] avg loss: 0.516752281107336		[learning rate: 0.0044995]
	Learning Rate: 0.00449949
	LOSS [training: 0.5198873089956891 | validation: 0.4240017363022788]
	TIME [epoch: 8.66 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5693786049935228		[learning rate: 0.0044889]
		[batch 20/20] avg loss: 0.4429791402625531		[learning rate: 0.0044784]
	Learning Rate: 0.0044784
	LOSS [training: 0.506178872628038 | validation: 0.3541526179023664]
	TIME [epoch: 8.65 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/20] avg loss: 0.47024155390284605		[learning rate: 0.0044679]
		[batch 20/20] avg loss: 0.44554398789363087		[learning rate: 0.0044574]
	Learning Rate: 0.0044574
	LOSS [training: 0.45789277089823843 | validation: 0.5140765005950656]
	TIME [epoch: 8.65 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/20] avg loss: 0.47894883929553267		[learning rate: 0.0044469]
		[batch 20/20] avg loss: 0.3580346436048487		[learning rate: 0.0044365]
	Learning Rate: 0.0044365
	LOSS [training: 0.4184917414501907 | validation: 0.3520319466506103]
	TIME [epoch: 8.68 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/20] avg loss: 0.49257362817806394		[learning rate: 0.0044261]
		[batch 20/20] avg loss: 0.45055464357806824		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.47156413587806617 | validation: 0.40216583162729386]
	TIME [epoch: 8.65 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5586040851044117		[learning rate: 0.0044053]
		[batch 20/20] avg loss: 0.5094884707585954		[learning rate: 0.004395]
	Learning Rate: 0.004395
	LOSS [training: 0.5340462779315036 | validation: 0.5862887560163819]
	TIME [epoch: 8.66 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/20] avg loss: 0.49396903306554496		[learning rate: 0.0043847]
		[batch 20/20] avg loss: 0.5110811579293616		[learning rate: 0.0043744]
	Learning Rate: 0.0043744
	LOSS [training: 0.5025250954974533 | validation: 0.4843928461791307]
	TIME [epoch: 8.66 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4439184618355596		[learning rate: 0.0043641]
		[batch 20/20] avg loss: 0.3954876919845574		[learning rate: 0.0043539]
	Learning Rate: 0.00435389
	LOSS [training: 0.4197030769100585 | validation: 0.2218038518195637]
	TIME [epoch: 8.65 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_187.pth
	Model improved!!!
EPOCH 188/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4625947839402918		[learning rate: 0.0043437]
		[batch 20/20] avg loss: 0.38344134503089594		[learning rate: 0.0043335]
	Learning Rate: 0.00433348
	LOSS [training: 0.4230180644855938 | validation: 0.4202896710608453]
	TIME [epoch: 8.68 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4855611174430717		[learning rate: 0.0043233]
		[batch 20/20] avg loss: 0.42615255019403964		[learning rate: 0.0043132]
	Learning Rate: 0.00431316
	LOSS [training: 0.45585683381855563 | validation: 0.5150421073074014]
	TIME [epoch: 8.66 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/20] avg loss: 0.41254119737659245		[learning rate: 0.004303]
		[batch 20/20] avg loss: 0.7002954390896341		[learning rate: 0.0042929]
	Learning Rate: 0.00429294
	LOSS [training: 0.5564183182331134 | validation: 0.7808355495172874]
	TIME [epoch: 8.66 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/20] avg loss: 0.49064673317334717		[learning rate: 0.0042829]
		[batch 20/20] avg loss: 0.8346521818990315		[learning rate: 0.0042728]
	Learning Rate: 0.00427282
	LOSS [training: 0.6626494575361893 | validation: 0.5778563951593078]
	TIME [epoch: 8.65 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5876877836554574		[learning rate: 0.0042628]
		[batch 20/20] avg loss: 0.4145578822710358		[learning rate: 0.0042528]
	Learning Rate: 0.00425279
	LOSS [training: 0.5011228329632467 | validation: 0.32111436929941417]
	TIME [epoch: 8.67 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/20] avg loss: 0.622686456734		[learning rate: 0.0042428]
		[batch 20/20] avg loss: 0.4447786055916927		[learning rate: 0.0042328]
	Learning Rate: 0.00423285
	LOSS [training: 0.5337325311628462 | validation: 0.40777547199553477]
	TIME [epoch: 8.68 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3485156455198545		[learning rate: 0.0042229]
		[batch 20/20] avg loss: 0.4224333319201413		[learning rate: 0.004213]
	Learning Rate: 0.004213
	LOSS [training: 0.3854744887199979 | validation: 0.27935474827293405]
	TIME [epoch: 8.65 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40713842552218005		[learning rate: 0.0042031]
		[batch 20/20] avg loss: 0.4351629945402185		[learning rate: 0.0041933]
	Learning Rate: 0.00419325
	LOSS [training: 0.42115071003119925 | validation: 0.2659273071410419]
	TIME [epoch: 8.65 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44279833087288356		[learning rate: 0.0041834]
		[batch 20/20] avg loss: 0.4264158831275999		[learning rate: 0.0041736]
	Learning Rate: 0.00417359
	LOSS [training: 0.43460710700024174 | validation: 1.5952916507728467]
	TIME [epoch: 8.66 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6096991243687485		[learning rate: 0.0041638]
		[batch 20/20] avg loss: 0.3982250983829806		[learning rate: 0.004154]
	Learning Rate: 0.00415403
	LOSS [training: 0.5039621113758647 | validation: 0.32458098817620507]
	TIME [epoch: 8.68 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5892842566127655		[learning rate: 0.0041443]
		[batch 20/20] avg loss: 0.6957499780926518		[learning rate: 0.0041346]
	Learning Rate: 0.00413455
	LOSS [training: 0.6425171173527087 | validation: 0.38178948394625944]
	TIME [epoch: 8.67 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4355415637806191		[learning rate: 0.0041249]
		[batch 20/20] avg loss: 0.43764082702944984		[learning rate: 0.0041152]
	Learning Rate: 0.00411517
	LOSS [training: 0.4365911954050346 | validation: 0.5144826434066332]
	TIME [epoch: 8.67 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35867422185996756		[learning rate: 0.0041055]
		[batch 20/20] avg loss: 0.37246350117069904		[learning rate: 0.0040959]
	Learning Rate: 0.00409588
	LOSS [training: 0.3655688615153333 | validation: 0.6928486782509212]
	TIME [epoch: 8.67 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/20] avg loss: 0.41296578007087203		[learning rate: 0.0040863]
		[batch 20/20] avg loss: 0.3554814990202658		[learning rate: 0.0040767]
	Learning Rate: 0.00407667
	LOSS [training: 0.38422363954556893 | validation: 0.2630103631948387]
	TIME [epoch: 8.67 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36756891755786636		[learning rate: 0.0040671]
		[batch 20/20] avg loss: 0.3623010021250783		[learning rate: 0.0040576]
	Learning Rate: 0.00405756
	LOSS [training: 0.3649349598414724 | validation: 0.3145913652114096]
	TIME [epoch: 8.69 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8204502461710785		[learning rate: 0.004048]
		[batch 20/20] avg loss: 0.3930954237878956		[learning rate: 0.0040385]
	Learning Rate: 0.00403854
	LOSS [training: 0.606772834979487 | validation: 0.23439588297765782]
	TIME [epoch: 8.67 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31101302324504154		[learning rate: 0.0040291]
		[batch 20/20] avg loss: 0.3028086285037195		[learning rate: 0.0040196]
	Learning Rate: 0.00401961
	LOSS [training: 0.3069108258743805 | validation: 0.4087061756077841]
	TIME [epoch: 8.67 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/20] avg loss: 0.459477387660039		[learning rate: 0.0040102]
		[batch 20/20] avg loss: 0.40501864223581513		[learning rate: 0.0040008]
	Learning Rate: 0.00400076
	LOSS [training: 0.432248014947927 | validation: 0.20444132756234396]
	TIME [epoch: 8.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_205.pth
	Model improved!!!
EPOCH 206/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33278107858933625		[learning rate: 0.0039914]
		[batch 20/20] avg loss: 0.32928898531599193		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.331035031952664 | validation: 0.5375917153957478]
	TIME [epoch: 8.66 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4367306994211936		[learning rate: 0.0039727]
		[batch 20/20] avg loss: 0.3744248859632037		[learning rate: 0.0039633]
	Learning Rate: 0.00396334
	LOSS [training: 0.4055777926921986 | validation: 0.25546182752636176]
	TIME [epoch: 8.69 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3477254038941473		[learning rate: 0.003954]
		[batch 20/20] avg loss: 0.34836731528744236		[learning rate: 0.0039448]
	Learning Rate: 0.00394476
	LOSS [training: 0.34804635959079483 | validation: 0.31555039109164335]
	TIME [epoch: 8.66 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4151971049593852		[learning rate: 0.0039355]
		[batch 20/20] avg loss: 0.35488415051430355		[learning rate: 0.0039263]
	Learning Rate: 0.00392627
	LOSS [training: 0.38504062773684444 | validation: 0.5320181404041799]
	TIME [epoch: 8.67 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4891769323136083		[learning rate: 0.0039171]
		[batch 20/20] avg loss: 0.4092152619580854		[learning rate: 0.0039079]
	Learning Rate: 0.00390786
	LOSS [training: 0.4491960971358468 | validation: 0.3277254750554908]
	TIME [epoch: 8.66 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40046223382520996		[learning rate: 0.0038987]
		[batch 20/20] avg loss: 0.433268048001909		[learning rate: 0.0038895]
	Learning Rate: 0.00388954
	LOSS [training: 0.4168651409135594 | validation: 0.4370910592410263]
	TIME [epoch: 8.66 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44419597738730604		[learning rate: 0.0038804]
		[batch 20/20] avg loss: 0.48548670595257554		[learning rate: 0.0038713]
	Learning Rate: 0.0038713
	LOSS [training: 0.4648413416699408 | validation: 0.3927147157211176]
	TIME [epoch: 8.68 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/20] avg loss: 0.46282457428985524		[learning rate: 0.0038622]
		[batch 20/20] avg loss: 0.38657741450154937		[learning rate: 0.0038532]
	Learning Rate: 0.00385315
	LOSS [training: 0.4247009943957023 | validation: 0.6388161544535704]
	TIME [epoch: 8.67 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3260558764131264		[learning rate: 0.0038441]
		[batch 20/20] avg loss: 0.37451712881685284		[learning rate: 0.0038351]
	Learning Rate: 0.00383509
	LOSS [training: 0.3502865026149896 | validation: 0.23748194232488815]
	TIME [epoch: 8.65 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32695321721189746		[learning rate: 0.0038261]
		[batch 20/20] avg loss: 0.3893619186176448		[learning rate: 0.0038171]
	Learning Rate: 0.00381711
	LOSS [training: 0.35815756791477105 | validation: 0.2788238407787772]
	TIME [epoch: 8.66 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4303137747445301		[learning rate: 0.0038082]
		[batch 20/20] avg loss: 0.32858782413596366		[learning rate: 0.0037992]
	Learning Rate: 0.00379921
	LOSS [training: 0.37945079944024684 | validation: 0.2984337842698254]
	TIME [epoch: 8.66 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/20] avg loss: 0.45197451543414724		[learning rate: 0.0037903]
		[batch 20/20] avg loss: 0.3905595034785934		[learning rate: 0.0037814]
	Learning Rate: 0.0037814
	LOSS [training: 0.4212670094563703 | validation: 0.17938920250164578]
	TIME [epoch: 8.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_217.pth
	Model improved!!!
EPOCH 218/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31632760070115784		[learning rate: 0.0037725]
		[batch 20/20] avg loss: 0.3399498922975366		[learning rate: 0.0037637]
	Learning Rate: 0.00376368
	LOSS [training: 0.32813874649934716 | validation: 0.45807647802428625]
	TIME [epoch: 8.68 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4421383305494109		[learning rate: 0.0037548]
		[batch 20/20] avg loss: 0.3567938248819445		[learning rate: 0.003746]
	Learning Rate: 0.00374603
	LOSS [training: 0.39946607771567766 | validation: 0.18188367717914866]
	TIME [epoch: 8.68 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40224941730190433		[learning rate: 0.0037372]
		[batch 20/20] avg loss: 0.396941465458327		[learning rate: 0.0037285]
	Learning Rate: 0.00372847
	LOSS [training: 0.39959544138011566 | validation: 0.20810685309993093]
	TIME [epoch: 8.69 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3096634745749764		[learning rate: 0.0037197]
		[batch 20/20] avg loss: 0.3025457504171422		[learning rate: 0.003711]
	Learning Rate: 0.00371099
	LOSS [training: 0.3061046124960593 | validation: 0.4160243652394145]
	TIME [epoch: 8.71 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33055979538166486		[learning rate: 0.0037023]
		[batch 20/20] avg loss: 0.4112597244974638		[learning rate: 0.0036936]
	Learning Rate: 0.00369359
	LOSS [training: 0.3709097599395643 | validation: 0.27666815114051974]
	TIME [epoch: 8.69 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/20] avg loss: 0.347319563106534		[learning rate: 0.0036849]
		[batch 20/20] avg loss: 0.3531070268042994		[learning rate: 0.0036763]
	Learning Rate: 0.00367628
	LOSS [training: 0.35021329495541675 | validation: 0.41697125469251217]
	TIME [epoch: 8.67 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3658845811305424		[learning rate: 0.0036676]
		[batch 20/20] avg loss: 0.3686733242074604		[learning rate: 0.003659]
	Learning Rate: 0.00365904
	LOSS [training: 0.3672789526690014 | validation: 0.4520628787473374]
	TIME [epoch: 8.68 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35482577431482154		[learning rate: 0.0036505]
		[batch 20/20] avg loss: 0.4605977342898682		[learning rate: 0.0036419]
	Learning Rate: 0.00364189
	LOSS [training: 0.40771175430234496 | validation: 0.4424252424705787]
	TIME [epoch: 8.68 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3478299465306022		[learning rate: 0.0036333]
		[batch 20/20] avg loss: 0.35911855020377137		[learning rate: 0.0036248]
	Learning Rate: 0.00362481
	LOSS [training: 0.35347424836718666 | validation: 0.6103869802338602]
	TIME [epoch: 8.7 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/20] avg loss: 0.500814005858393		[learning rate: 0.0036163]
		[batch 20/20] avg loss: 0.3201391286432645		[learning rate: 0.0036078]
	Learning Rate: 0.00360782
	LOSS [training: 0.4104765672508287 | validation: 0.16147460255032758]
	TIME [epoch: 8.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_227.pth
	Model improved!!!
EPOCH 228/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33892517739975425		[learning rate: 0.0035994]
		[batch 20/20] avg loss: 0.4627163220008875		[learning rate: 0.0035909]
	Learning Rate: 0.00359091
	LOSS [training: 0.4008207497003209 | validation: 0.22734385075795993]
	TIME [epoch: 8.67 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32968663474049464		[learning rate: 0.0035825]
		[batch 20/20] avg loss: 0.3368871220858605		[learning rate: 0.0035741]
	Learning Rate: 0.00357407
	LOSS [training: 0.33328687841317756 | validation: 0.14007603058875767]
	TIME [epoch: 8.66 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_229.pth
	Model improved!!!
EPOCH 230/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2497005709283148		[learning rate: 0.0035657]
		[batch 20/20] avg loss: 0.3503531371859902		[learning rate: 0.0035573]
	Learning Rate: 0.00355732
	LOSS [training: 0.30002685405715257 | validation: 0.20720058990189893]
	TIME [epoch: 8.68 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29704794766638865		[learning rate: 0.003549]
		[batch 20/20] avg loss: 0.3520371358196621		[learning rate: 0.0035406]
	Learning Rate: 0.00354064
	LOSS [training: 0.3245425417430254 | validation: 0.22216175556816664]
	TIME [epoch: 8.71 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/20] avg loss: 0.363807906164261		[learning rate: 0.0035323]
		[batch 20/20] avg loss: 0.39240393811120816		[learning rate: 0.003524]
	Learning Rate: 0.00352404
	LOSS [training: 0.3781059221377344 | validation: 0.3023896035514198]
	TIME [epoch: 8.69 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30847741257988154		[learning rate: 0.0035158]
		[batch 20/20] avg loss: 0.3215741390433046		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.31502577581159313 | validation: 0.9938837766198616]
	TIME [epoch: 8.69 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/20] avg loss: 0.43948153751751723		[learning rate: 0.0034993]
		[batch 20/20] avg loss: 0.40283472831829137		[learning rate: 0.0034911]
	Learning Rate: 0.00349107
	LOSS [training: 0.42115813291790427 | validation: 0.2895362017915648]
	TIME [epoch: 8.69 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5572886516514488		[learning rate: 0.0034829]
		[batch 20/20] avg loss: 0.3248574091199019		[learning rate: 0.0034747]
	Learning Rate: 0.00347471
	LOSS [training: 0.44107303038567525 | validation: 0.5465748997745166]
	TIME [epoch: 8.69 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36195116620058054		[learning rate: 0.0034666]
		[batch 20/20] avg loss: 0.39543734640338213		[learning rate: 0.0034584]
	Learning Rate: 0.00345842
	LOSS [training: 0.3786942563019813 | validation: 0.35588398978149083]
	TIME [epoch: 8.71 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3404796629033057		[learning rate: 0.0034503]
		[batch 20/20] avg loss: 0.3665419117485262		[learning rate: 0.0034422]
	Learning Rate: 0.00344221
	LOSS [training: 0.3535107873259159 | validation: 0.23864788469503026]
	TIME [epoch: 8.7 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/20] avg loss: 0.38427684039733667		[learning rate: 0.0034341]
		[batch 20/20] avg loss: 0.32867976557158374		[learning rate: 0.0034261]
	Learning Rate: 0.00342607
	LOSS [training: 0.35647830298446015 | validation: 0.1811488556512027]
	TIME [epoch: 8.7 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31739930454653825		[learning rate: 0.003418]
		[batch 20/20] avg loss: 0.3590719071040773		[learning rate: 0.00341]
	Learning Rate: 0.00341001
	LOSS [training: 0.33823560582530776 | validation: 0.2531359334072501]
	TIME [epoch: 8.71 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/20] avg loss: 0.42083646913397227		[learning rate: 0.003402]
		[batch 20/20] avg loss: 0.36575688571943954		[learning rate: 0.003394]
	Learning Rate: 0.00339402
	LOSS [training: 0.3932966774267059 | validation: 0.485316556800287]
	TIME [epoch: 8.72 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31302621665000174		[learning rate: 0.0033861]
		[batch 20/20] avg loss: 0.25064920323223217		[learning rate: 0.0033781]
	Learning Rate: 0.00337811
	LOSS [training: 0.281837709941117 | validation: 0.8233123307450871]
	TIME [epoch: 8.72 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35383997576155746		[learning rate: 0.0033702]
		[batch 20/20] avg loss: 0.3302104976421093		[learning rate: 0.0033623]
	Learning Rate: 0.00336227
	LOSS [training: 0.34202523670183343 | validation: 0.40984406414996033]
	TIME [epoch: 8.7 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36613678755478696		[learning rate: 0.0033544]
		[batch 20/20] avg loss: 0.3356782120920439		[learning rate: 0.0033465]
	Learning Rate: 0.00334651
	LOSS [training: 0.35090749982341546 | validation: 0.4024375931919468]
	TIME [epoch: 8.68 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3985177026474137		[learning rate: 0.0033387]
		[batch 20/20] avg loss: 0.25046173265788996		[learning rate: 0.0033308]
	Learning Rate: 0.00333082
	LOSS [training: 0.32448971765265183 | validation: 0.21003745793602793]
	TIME [epoch: 8.69 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/20] avg loss: 0.388961260992342		[learning rate: 0.003323]
		[batch 20/20] avg loss: 0.2528509985723143		[learning rate: 0.0033152]
	Learning Rate: 0.0033152
	LOSS [training: 0.3209061297823282 | validation: 0.22881063787832584]
	TIME [epoch: 8.71 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4366475485863385		[learning rate: 0.0033074]
		[batch 20/20] avg loss: 0.34703022649706283		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.39183888754170065 | validation: 0.3875773032241734]
	TIME [epoch: 8.69 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3991902488436036		[learning rate: 0.0032919]
		[batch 20/20] avg loss: 0.30837489116442496		[learning rate: 0.0032842]
	Learning Rate: 0.00328419
	LOSS [training: 0.3537825700040143 | validation: 0.19859846628914996]
	TIME [epoch: 8.69 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3588018564133491		[learning rate: 0.0032765]
		[batch 20/20] avg loss: 0.3129350255719107		[learning rate: 0.0032688]
	Learning Rate: 0.0032688
	LOSS [training: 0.33586844099262997 | validation: 0.33417117973838417]
	TIME [epoch: 8.7 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3574819803148642		[learning rate: 0.0032611]
		[batch 20/20] avg loss: 0.3629582530481759		[learning rate: 0.0032535]
	Learning Rate: 0.00325347
	LOSS [training: 0.36022011668152 | validation: 0.17566357359399426]
	TIME [epoch: 8.7 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/20] avg loss: 0.39656466293471293		[learning rate: 0.0032458]
		[batch 20/20] avg loss: 0.3759208348174439		[learning rate: 0.0032382]
	Learning Rate: 0.00323822
	LOSS [training: 0.3862427488760784 | validation: 0.37657969712981154]
	TIME [epoch: 8.71 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3842230163466045		[learning rate: 0.0032306]
		[batch 20/20] avg loss: 0.3232773801954978		[learning rate: 0.003223]
	Learning Rate: 0.00322304
	LOSS [training: 0.3537501982710512 | validation: 0.2878550981380485]
	TIME [epoch: 8.69 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3056430278681653		[learning rate: 0.0032155]
		[batch 20/20] avg loss: 0.31274936062424485		[learning rate: 0.0032079]
	Learning Rate: 0.00320793
	LOSS [training: 0.3091961942462051 | validation: 0.2661471351152732]
	TIME [epoch: 8.69 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24563769706097557		[learning rate: 0.0032004]
		[batch 20/20] avg loss: 0.3369347980870783		[learning rate: 0.0031929]
	Learning Rate: 0.00319289
	LOSS [training: 0.2912862475740269 | validation: 0.3821220064372921]
	TIME [epoch: 8.68 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2509651044748333		[learning rate: 0.0031854]
		[batch 20/20] avg loss: 0.32988803902903413		[learning rate: 0.0031779]
	Learning Rate: 0.00317792
	LOSS [training: 0.2904265717519337 | validation: 0.2107948838610022]
	TIME [epoch: 8.69 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36807581821276447		[learning rate: 0.0031705]
		[batch 20/20] avg loss: 0.3320956429723371		[learning rate: 0.003163]
	Learning Rate: 0.00316302
	LOSS [training: 0.3500857305925509 | validation: 0.21450330278529944]
	TIME [epoch: 8.71 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3060517630840258		[learning rate: 0.0031556]
		[batch 20/20] avg loss: 0.3502633736336594		[learning rate: 0.0031482]
	Learning Rate: 0.00314819
	LOSS [training: 0.3281575683588426 | validation: 0.16058012326642684]
	TIME [epoch: 8.69 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2649439956025209		[learning rate: 0.0031408]
		[batch 20/20] avg loss: 0.2508130297185422		[learning rate: 0.0031334]
	Learning Rate: 0.00313343
	LOSS [training: 0.2578785126605315 | validation: 0.27712087446028494]
	TIME [epoch: 8.69 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3353764537983768		[learning rate: 0.0031261]
		[batch 20/20] avg loss: 0.29777338582571516		[learning rate: 0.0031187]
	Learning Rate: 0.00311874
	LOSS [training: 0.316574919812046 | validation: 0.37805016651702117]
	TIME [epoch: 8.69 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31570959164688844		[learning rate: 0.0031114]
		[batch 20/20] avg loss: 0.32714810381202886		[learning rate: 0.0031041]
	Learning Rate: 0.00310412
	LOSS [training: 0.3214288477294586 | validation: 0.287519733842202]
	TIME [epoch: 8.69 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3769369480382071		[learning rate: 0.0030968]
		[batch 20/20] avg loss: 0.2826120942848428		[learning rate: 0.0030896]
	Learning Rate: 0.00308957
	LOSS [training: 0.32977452116152495 | validation: 0.3534127668054445]
	TIME [epoch: 8.71 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34875074262544936		[learning rate: 0.0030823]
		[batch 20/20] avg loss: 0.4179609122942377		[learning rate: 0.0030751]
	Learning Rate: 0.00307509
	LOSS [training: 0.38335582745984353 | validation: 0.5339150511979038]
	TIME [epoch: 8.69 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40109365817874415		[learning rate: 0.0030679]
		[batch 20/20] avg loss: 0.2756153888688921		[learning rate: 0.0030607]
	Learning Rate: 0.00306067
	LOSS [training: 0.3383545235238181 | validation: 0.15423601887916996]
	TIME [epoch: 8.67 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25856245960034296		[learning rate: 0.0030535]
		[batch 20/20] avg loss: 0.3513608105907792		[learning rate: 0.0030463]
	Learning Rate: 0.00304632
	LOSS [training: 0.30496163509556107 | validation: 0.2699303925645995]
	TIME [epoch: 8.68 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30491449736399395		[learning rate: 0.0030392]
		[batch 20/20] avg loss: 0.26032519103415097		[learning rate: 0.003032]
	Learning Rate: 0.00303204
	LOSS [training: 0.2826198441990725 | validation: 0.5083723804193057]
	TIME [epoch: 8.71 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2700020535379234		[learning rate: 0.0030249]
		[batch 20/20] avg loss: 0.356470693465344		[learning rate: 0.0030178]
	Learning Rate: 0.00301782
	LOSS [training: 0.31323637350163364 | validation: 0.25183435458541586]
	TIME [epoch: 8.7 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2867215343203656		[learning rate: 0.0030107]
		[batch 20/20] avg loss: 0.33737379892984803		[learning rate: 0.0030037]
	Learning Rate: 0.00300368
	LOSS [training: 0.31204766662510686 | validation: 0.3403302327019666]
	TIME [epoch: 8.69 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34177708221152875		[learning rate: 0.0029966]
		[batch 20/20] avg loss: 0.26027705381369026		[learning rate: 0.0029896]
	Learning Rate: 0.00298959
	LOSS [training: 0.3010270680126096 | validation: 0.37767455481823176]
	TIME [epoch: 8.69 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2739951872401166		[learning rate: 0.0029826]
		[batch 20/20] avg loss: 0.31012006134833037		[learning rate: 0.0029756]
	Learning Rate: 0.00297558
	LOSS [training: 0.29205762429422355 | validation: 0.2653973462582806]
	TIME [epoch: 8.7 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22405963278301036		[learning rate: 0.0029686]
		[batch 20/20] avg loss: 0.2948188341296304		[learning rate: 0.0029616]
	Learning Rate: 0.00296163
	LOSS [training: 0.25943923345632036 | validation: 0.20644871347221094]
	TIME [epoch: 8.71 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3047109057395443		[learning rate: 0.0029547]
		[batch 20/20] avg loss: 0.3899356263830989		[learning rate: 0.0029477]
	Learning Rate: 0.00294774
	LOSS [training: 0.3473232660613216 | validation: 0.24049273798814094]
	TIME [epoch: 8.69 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2988586610540254		[learning rate: 0.0029408]
		[batch 20/20] avg loss: 0.2960787796747287		[learning rate: 0.0029339]
	Learning Rate: 0.00293393
	LOSS [training: 0.29746872036437705 | validation: 0.14087330258616165]
	TIME [epoch: 8.7 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2692776096967947		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.2518909099200083		[learning rate: 0.0029202]
	Learning Rate: 0.00292017
	LOSS [training: 0.2605842598084015 | validation: 0.13171838210314316]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_272.pth
	Model improved!!!
EPOCH 273/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31204121328629825		[learning rate: 0.0029133]
		[batch 20/20] avg loss: 0.5043410116002548		[learning rate: 0.0029065]
	Learning Rate: 0.00290648
	LOSS [training: 0.40819111244327655 | validation: 0.17843006040954035]
	TIME [epoch: 8.69 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2602168453058582		[learning rate: 0.0028997]
		[batch 20/20] avg loss: 0.3113687900503231		[learning rate: 0.0028929]
	Learning Rate: 0.00289285
	LOSS [training: 0.2857928176780906 | validation: 0.43845122211451387]
	TIME [epoch: 8.71 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36715073865384673		[learning rate: 0.0028861]
		[batch 20/20] avg loss: 0.27245525970380235		[learning rate: 0.0028793]
	Learning Rate: 0.00287929
	LOSS [training: 0.3198029991788246 | validation: 0.15903310173980115]
	TIME [epoch: 8.69 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2609398943494405		[learning rate: 0.0028725]
		[batch 20/20] avg loss: 0.22047449402724412		[learning rate: 0.0028658]
	Learning Rate: 0.00286579
	LOSS [training: 0.2407071941883423 | validation: 0.1896733229668936]
	TIME [epoch: 8.69 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2650490062760634		[learning rate: 0.0028591]
		[batch 20/20] avg loss: 0.23674884367869006		[learning rate: 0.0028524]
	Learning Rate: 0.00285236
	LOSS [training: 0.25089892497737676 | validation: 0.11878941185417913]
	TIME [epoch: 8.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_277.pth
	Model improved!!!
EPOCH 278/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27228153592698784		[learning rate: 0.0028457]
		[batch 20/20] avg loss: 0.3097523139578653		[learning rate: 0.002839]
	Learning Rate: 0.00283899
	LOSS [training: 0.2910169249424266 | validation: 0.4490408997743439]
	TIME [epoch: 8.7 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2619464418278107		[learning rate: 0.0028323]
		[batch 20/20] avg loss: 0.2533392526036259		[learning rate: 0.0028257]
	Learning Rate: 0.00282568
	LOSS [training: 0.2576428472157183 | validation: 0.3424349625036375]
	TIME [epoch: 8.73 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32126459597177304		[learning rate: 0.002819]
		[batch 20/20] avg loss: 0.3371183275282383		[learning rate: 0.0028124]
	Learning Rate: 0.00281243
	LOSS [training: 0.3291914617500057 | validation: 0.22521043930089804]
	TIME [epoch: 8.7 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2408626694446773		[learning rate: 0.0028058]
		[batch 20/20] avg loss: 0.29852806665903736		[learning rate: 0.0027992]
	Learning Rate: 0.00279924
	LOSS [training: 0.26969536805185734 | validation: 0.26080366284191375]
	TIME [epoch: 8.7 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3772586655915271		[learning rate: 0.0027927]
		[batch 20/20] avg loss: 0.27215844582478177		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.3247085557081545 | validation: 0.20669126520807266]
	TIME [epoch: 8.69 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2677496092697159		[learning rate: 0.0027796]
		[batch 20/20] avg loss: 0.24047763959253216		[learning rate: 0.0027731]
	Learning Rate: 0.00277306
	LOSS [training: 0.254113624431124 | validation: 0.31871313749140406]
	TIME [epoch: 8.7 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26224791726254126		[learning rate: 0.0027666]
		[batch 20/20] avg loss: 0.24000552204183823		[learning rate: 0.0027601]
	Learning Rate: 0.00276006
	LOSS [training: 0.25112671965218974 | validation: 0.09759012724279825]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_284.pth
	Model improved!!!
EPOCH 285/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24573801022103403		[learning rate: 0.0027536]
		[batch 20/20] avg loss: 0.2728164276166729		[learning rate: 0.0027471]
	Learning Rate: 0.00274712
	LOSS [training: 0.25927721891885347 | validation: 0.1836764899423234]
	TIME [epoch: 8.69 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2683556918787561		[learning rate: 0.0027407]
		[batch 20/20] avg loss: 0.21649122499681583		[learning rate: 0.0027342]
	Learning Rate: 0.00273424
	LOSS [training: 0.24242345843778593 | validation: 0.37579371129757966]
	TIME [epoch: 8.69 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27044083671458874		[learning rate: 0.0027278]
		[batch 20/20] avg loss: 0.2407490480241742		[learning rate: 0.0027214]
	Learning Rate: 0.00272142
	LOSS [training: 0.25559494236938146 | validation: 0.2077249867084593]
	TIME [epoch: 8.7 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26050064892189123		[learning rate: 0.002715]
		[batch 20/20] avg loss: 0.3078622813614392		[learning rate: 0.0027087]
	Learning Rate: 0.00270866
	LOSS [training: 0.2841814651416653 | validation: 0.36840072710976357]
	TIME [epoch: 8.72 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27450553759132756		[learning rate: 0.0027023]
		[batch 20/20] avg loss: 0.23016024509793268		[learning rate: 0.002696]
	Learning Rate: 0.00269597
	LOSS [training: 0.2523328913446301 | validation: 0.14030226706433568]
	TIME [epoch: 8.7 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2674581494357819		[learning rate: 0.0026896]
		[batch 20/20] avg loss: 0.2029950642462032		[learning rate: 0.0026833]
	Learning Rate: 0.00268333
	LOSS [training: 0.23522660684099256 | validation: 0.1175330312930426]
	TIME [epoch: 8.7 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2710391395007604		[learning rate: 0.002677]
		[batch 20/20] avg loss: 0.2764339432020322		[learning rate: 0.0026707]
	Learning Rate: 0.00267075
	LOSS [training: 0.2737365413513963 | validation: 0.3867186635306521]
	TIME [epoch: 8.7 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30544951715557483		[learning rate: 0.0026645]
		[batch 20/20] avg loss: 0.26968289808962354		[learning rate: 0.0026582]
	Learning Rate: 0.00265823
	LOSS [training: 0.2875662076225992 | validation: 0.4269546934181918]
	TIME [epoch: 8.7 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28119698707344887		[learning rate: 0.002652]
		[batch 20/20] avg loss: 0.20678903452919523		[learning rate: 0.0026458]
	Learning Rate: 0.00264576
	LOSS [training: 0.24399301080132202 | validation: 0.2557494763388354]
	TIME [epoch: 8.72 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/20] avg loss: 0.272361533914367		[learning rate: 0.0026396]
		[batch 20/20] avg loss: 0.2865834705668604		[learning rate: 0.0026334]
	Learning Rate: 0.00263336
	LOSS [training: 0.2794725022406137 | validation: 0.6500382565472849]
	TIME [epoch: 8.7 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/20] avg loss: 0.325344830833819		[learning rate: 0.0026272]
		[batch 20/20] avg loss: 0.23354938308576342		[learning rate: 0.002621]
	Learning Rate: 0.00262101
	LOSS [training: 0.27944710695979125 | validation: 0.242891265021418]
	TIME [epoch: 8.7 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/20] avg loss: 0.291158581943325		[learning rate: 0.0026149]
		[batch 20/20] avg loss: 0.39767607942928096		[learning rate: 0.0026087]
	Learning Rate: 0.00260873
	LOSS [training: 0.3444173306863031 | validation: 0.9292363904211711]
	TIME [epoch: 8.68 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34931273832684406		[learning rate: 0.0026026]
		[batch 20/20] avg loss: 0.2500691537156234		[learning rate: 0.0025965]
	Learning Rate: 0.0025965
	LOSS [training: 0.2996909460212337 | validation: 0.19699357961620362]
	TIME [epoch: 8.69 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21016226293709556		[learning rate: 0.0025904]
		[batch 20/20] avg loss: 0.2192162596801408		[learning rate: 0.0025843]
	Learning Rate: 0.00258432
	LOSS [training: 0.21468926130861815 | validation: 0.3080155111973388]
	TIME [epoch: 8.72 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20709800122605565		[learning rate: 0.0025783]
		[batch 20/20] avg loss: 0.2301905993153856		[learning rate: 0.0025722]
	Learning Rate: 0.00257221
	LOSS [training: 0.21864430027072065 | validation: 0.212807383471972]
	TIME [epoch: 8.68 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2126494000286833		[learning rate: 0.0025662]
		[batch 20/20] avg loss: 0.23376228363905657		[learning rate: 0.0025601]
	Learning Rate: 0.00256015
	LOSS [training: 0.22320584183386996 | validation: 0.111895728778587]
	TIME [epoch: 8.7 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/20] avg loss: 0.255308933159489		[learning rate: 0.0025541]
		[batch 20/20] avg loss: 0.23507936438253357		[learning rate: 0.0025481]
	Learning Rate: 0.00254815
	LOSS [training: 0.24519414877101128 | validation: 0.24032994296925217]
	TIME [epoch: 8.7 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23625347318014814		[learning rate: 0.0025422]
		[batch 20/20] avg loss: 0.22398885762615833		[learning rate: 0.0025362]
	Learning Rate: 0.0025362
	LOSS [training: 0.23012116540315325 | validation: 0.09009261355604153]
	TIME [epoch: 8.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_302.pth
	Model improved!!!
EPOCH 303/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23974707240479143		[learning rate: 0.0025302]
		[batch 20/20] avg loss: 0.26009381403135545		[learning rate: 0.0025243]
	Learning Rate: 0.00252431
	LOSS [training: 0.24992044321807344 | validation: 0.10895676654373224]
	TIME [epoch: 8.72 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2248177588577299		[learning rate: 0.0025184]
		[batch 20/20] avg loss: 0.21256172076329896		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.21868973981051446 | validation: 0.3426996702516958]
	TIME [epoch: 8.7 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29615148953714904		[learning rate: 0.0025066]
		[batch 20/20] avg loss: 0.22166083150039023		[learning rate: 0.0025007]
	Learning Rate: 0.0025007
	LOSS [training: 0.25890616051876963 | validation: 0.20111819444114057]
	TIME [epoch: 8.71 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25993629157190934		[learning rate: 0.0024948]
		[batch 20/20] avg loss: 0.23855933409884028		[learning rate: 0.002489]
	Learning Rate: 0.00248897
	LOSS [training: 0.24924781283537478 | validation: 0.3581452090219297]
	TIME [epoch: 8.71 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2258868460624297		[learning rate: 0.0024831]
		[batch 20/20] avg loss: 0.23351514489826658		[learning rate: 0.0024773]
	Learning Rate: 0.00247731
	LOSS [training: 0.22970099548034817 | validation: 0.16346642910004283]
	TIME [epoch: 8.72 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23203582570124892		[learning rate: 0.0024715]
		[batch 20/20] avg loss: 0.19709349384262848		[learning rate: 0.0024657]
	Learning Rate: 0.00246569
	LOSS [training: 0.21456465977193867 | validation: 0.2814409108668862]
	TIME [epoch: 8.71 sec]
EPOCH 309/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23821305304254073		[learning rate: 0.0024599]
		[batch 20/20] avg loss: 0.3015187117204626		[learning rate: 0.0024541]
	Learning Rate: 0.00245413
	LOSS [training: 0.26986588238150166 | validation: 0.14715656206833283]
	TIME [epoch: 8.71 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20230085731215128		[learning rate: 0.0024484]
		[batch 20/20] avg loss: 0.23866675039189636		[learning rate: 0.0024426]
	Learning Rate: 0.00244263
	LOSS [training: 0.22048380385202376 | validation: 0.21274241172399228]
	TIME [epoch: 8.7 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21687742926966175		[learning rate: 0.0024369]
		[batch 20/20] avg loss: 0.2192809675857415		[learning rate: 0.0024312]
	Learning Rate: 0.00243118
	LOSS [training: 0.2180791984277016 | validation: 0.12931061614686648]
	TIME [epoch: 8.7 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22762893571085135		[learning rate: 0.0024255]
		[batch 20/20] avg loss: 0.291368601771948		[learning rate: 0.0024198]
	Learning Rate: 0.00241978
	LOSS [training: 0.2594987687413997 | validation: 0.2823137964950963]
	TIME [epoch: 8.72 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19981146283422496		[learning rate: 0.0024141]
		[batch 20/20] avg loss: 0.24418055119903764		[learning rate: 0.0024084]
	Learning Rate: 0.00240843
	LOSS [training: 0.22199600701663127 | validation: 0.11758421720712682]
	TIME [epoch: 8.71 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/20] avg loss: 0.254828218276529		[learning rate: 0.0024028]
		[batch 20/20] avg loss: 0.2212735442077666		[learning rate: 0.0023971]
	Learning Rate: 0.00239714
	LOSS [training: 0.2380508812421478 | validation: 0.1097607781818314]
	TIME [epoch: 8.69 sec]
EPOCH 315/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2588740217575617		[learning rate: 0.0023915]
		[batch 20/20] avg loss: 0.20656911972016126		[learning rate: 0.0023859]
	Learning Rate: 0.0023859
	LOSS [training: 0.2327215707388614 | validation: 0.2080673881830309]
	TIME [epoch: 8.7 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20715093134912443		[learning rate: 0.0023803]
		[batch 20/20] avg loss: 0.2941420572995429		[learning rate: 0.0023747]
	Learning Rate: 0.00237472
	LOSS [training: 0.25064649432433367 | validation: 0.22049682277152383]
	TIME [epoch: 8.7 sec]
EPOCH 317/500:
	Training over batches...
		[batch 10/20] avg loss: 0.251029129045449		[learning rate: 0.0023691]
		[batch 20/20] avg loss: 0.23779529518386697		[learning rate: 0.0023636]
	Learning Rate: 0.00236359
	LOSS [training: 0.24441221211465805 | validation: 0.186187266542135]
	TIME [epoch: 8.73 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2735383308829188		[learning rate: 0.002358]
		[batch 20/20] avg loss: 0.24334854170408585		[learning rate: 0.0023525]
	Learning Rate: 0.00235251
	LOSS [training: 0.2584434362935023 | validation: 0.11829731709706859]
	TIME [epoch: 8.72 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17268344205751135		[learning rate: 0.002347]
		[batch 20/20] avg loss: 0.2243040298116384		[learning rate: 0.0023415]
	Learning Rate: 0.00234148
	LOSS [training: 0.19849373593457487 | validation: 0.16286102031708335]
	TIME [epoch: 8.71 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24161793096659562		[learning rate: 0.002336]
		[batch 20/20] avg loss: 0.20940285673399578		[learning rate: 0.0023305]
	Learning Rate: 0.0023305
	LOSS [training: 0.22551039385029567 | validation: 0.21676985284494016]
	TIME [epoch: 8.72 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22515344021378675		[learning rate: 0.002325]
		[batch 20/20] avg loss: 0.2815655266342012		[learning rate: 0.0023196]
	Learning Rate: 0.00231957
	LOSS [training: 0.25335948342399395 | validation: 0.22700637512404878]
	TIME [epoch: 8.72 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21971810194831204		[learning rate: 0.0023141]
		[batch 20/20] avg loss: 0.1373507662664862		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.17853443410739916 | validation: 0.18152331197218094]
	TIME [epoch: 8.73 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2624890496302951		[learning rate: 0.0023033]
		[batch 20/20] avg loss: 0.2916906369520362		[learning rate: 0.0022979]
	Learning Rate: 0.00229788
	LOSS [training: 0.2770898432911656 | validation: 0.13907277356801503]
	TIME [epoch: 8.71 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33160639590038377		[learning rate: 0.0022925]
		[batch 20/20] avg loss: 0.306898778874553		[learning rate: 0.0022871]
	Learning Rate: 0.0022871
	LOSS [training: 0.31925258738746837 | validation: 0.1843578138816864]
	TIME [epoch: 8.7 sec]
EPOCH 325/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22471304881337897		[learning rate: 0.0022817]
		[batch 20/20] avg loss: 0.21159244180782463		[learning rate: 0.0022764]
	Learning Rate: 0.00227638
	LOSS [training: 0.2181527453106018 | validation: 0.10200743210805013]
	TIME [epoch: 8.7 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21602880519403436		[learning rate: 0.002271]
		[batch 20/20] avg loss: 0.32386970440464014		[learning rate: 0.0022657]
	Learning Rate: 0.00226571
	LOSS [training: 0.26994925479933723 | validation: 0.20214972638441148]
	TIME [epoch: 8.71 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17652843517309338		[learning rate: 0.0022604]
		[batch 20/20] avg loss: 0.1715211657682088		[learning rate: 0.0022551]
	Learning Rate: 0.00225509
	LOSS [training: 0.17402480047065108 | validation: 0.20436066152251486]
	TIME [epoch: 8.74 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23840863673139326		[learning rate: 0.0022498]
		[batch 20/20] avg loss: 0.2592230370904646		[learning rate: 0.0022445]
	Learning Rate: 0.00224451
	LOSS [training: 0.248815836910929 | validation: 0.47496685687331924]
	TIME [epoch: 8.71 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2870468012990751		[learning rate: 0.0022392]
		[batch 20/20] avg loss: 0.2594501667555349		[learning rate: 0.002234]
	Learning Rate: 0.00223399
	LOSS [training: 0.273248484027305 | validation: 0.1296444007338525]
	TIME [epoch: 8.7 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1698278290206514		[learning rate: 0.0022287]
		[batch 20/20] avg loss: 0.20926012043864625		[learning rate: 0.0022235]
	Learning Rate: 0.00222352
	LOSS [training: 0.18954397472964885 | validation: 0.1332021180230773]
	TIME [epoch: 8.71 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24155367103849126		[learning rate: 0.0022183]
		[batch 20/20] avg loss: 0.18228371087210626		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.21191869095529875 | validation: 0.3305503222764078]
	TIME [epoch: 8.75 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2416772243603737		[learning rate: 0.0022079]
		[batch 20/20] avg loss: 0.22551726381786005		[learning rate: 0.0022027]
	Learning Rate: 0.00220272
	LOSS [training: 0.23359724408911683 | validation: 0.20019826852450523]
	TIME [epoch: 8.71 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18483200028870533		[learning rate: 0.0021976]
		[batch 20/20] avg loss: 0.16645890054473317		[learning rate: 0.0021924]
	Learning Rate: 0.00219239
	LOSS [training: 0.17564545041671925 | validation: 0.5045920031130208]
	TIME [epoch: 8.71 sec]
EPOCH 334/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2313253917105556		[learning rate: 0.0021872]
		[batch 20/20] avg loss: 0.1873981827188633		[learning rate: 0.0021821]
	Learning Rate: 0.00218211
	LOSS [training: 0.20936178721470947 | validation: 0.2719702754731755]
	TIME [epoch: 8.71 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17736683287516763		[learning rate: 0.002177]
		[batch 20/20] avg loss: 0.27364361989097735		[learning rate: 0.0021719]
	Learning Rate: 0.00217188
	LOSS [training: 0.22550522638307244 | validation: 0.1323837027905976]
	TIME [epoch: 8.71 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27907989267368355		[learning rate: 0.0021668]
		[batch 20/20] avg loss: 0.19646415592055366		[learning rate: 0.0021617]
	Learning Rate: 0.0021617
	LOSS [training: 0.23777202429711863 | validation: 0.29379046207003795]
	TIME [epoch: 8.73 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22703387803651087		[learning rate: 0.0021566]
		[batch 20/20] avg loss: 0.15134238344279086		[learning rate: 0.0021516]
	Learning Rate: 0.00215157
	LOSS [training: 0.18918813073965085 | validation: 0.09351182859526379]
	TIME [epoch: 8.72 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18804524535973483		[learning rate: 0.0021465]
		[batch 20/20] avg loss: 0.24219563121151225		[learning rate: 0.0021415]
	Learning Rate: 0.00214148
	LOSS [training: 0.21512043828562355 | validation: 0.2683590405277841]
	TIME [epoch: 8.71 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2657505068533791		[learning rate: 0.0021365]
		[batch 20/20] avg loss: 0.19431534991479005		[learning rate: 0.0021314]
	Learning Rate: 0.00213144
	LOSS [training: 0.23003292838408457 | validation: 0.3283207024747965]
	TIME [epoch: 8.71 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24834609688746817		[learning rate: 0.0021264]
		[batch 20/20] avg loss: 0.15312089934732293		[learning rate: 0.0021214]
	Learning Rate: 0.00212145
	LOSS [training: 0.20073349811739555 | validation: 0.11107042955543008]
	TIME [epoch: 8.71 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20052171314086156		[learning rate: 0.0021165]
		[batch 20/20] avg loss: 0.2041752155119038		[learning rate: 0.0021115]
	Learning Rate: 0.0021115
	LOSS [training: 0.2023484643263827 | validation: 0.12244973687024928]
	TIME [epoch: 8.74 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16511699593501852		[learning rate: 0.0021065]
		[batch 20/20] avg loss: 0.23119223110671086		[learning rate: 0.0021016]
	Learning Rate: 0.0021016
	LOSS [training: 0.19815461352086472 | validation: 0.1747454760688288]
	TIME [epoch: 8.71 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16686193866148752		[learning rate: 0.0020967]
		[batch 20/20] avg loss: 0.23402274572481807		[learning rate: 0.0020918]
	Learning Rate: 0.00209175
	LOSS [training: 0.20044234219315285 | validation: 0.16436577685811726]
	TIME [epoch: 8.7 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1705260517814597		[learning rate: 0.0020868]
		[batch 20/20] avg loss: 0.16834624735245252		[learning rate: 0.0020819]
	Learning Rate: 0.00208195
	LOSS [training: 0.16943614956695607 | validation: 0.11826182969548621]
	TIME [epoch: 8.7 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18808905200027295		[learning rate: 0.0020771]
		[batch 20/20] avg loss: 0.18912825458543545		[learning rate: 0.0020722]
	Learning Rate: 0.00207219
	LOSS [training: 0.18860865329285423 | validation: 0.15470088733529636]
	TIME [epoch: 8.72 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21219148204723406		[learning rate: 0.0020673]
		[batch 20/20] avg loss: 0.14974606030968113		[learning rate: 0.0020625]
	Learning Rate: 0.00206247
	LOSS [training: 0.1809687711784576 | validation: 0.16298648326392864]
	TIME [epoch: 8.73 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4339569199770149		[learning rate: 0.0020576]
		[batch 20/20] avg loss: 0.207433294830153		[learning rate: 0.0020528]
	Learning Rate: 0.0020528
	LOSS [training: 0.32069510740358387 | validation: 0.3506216704871712]
	TIME [epoch: 8.71 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20966748942358185		[learning rate: 0.002048]
		[batch 20/20] avg loss: 0.18065894343302927		[learning rate: 0.0020432]
	Learning Rate: 0.00204318
	LOSS [training: 0.19516321642830553 | validation: 0.09318633968105945]
	TIME [epoch: 8.71 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16674704672198115		[learning rate: 0.0020384]
		[batch 20/20] avg loss: 0.23498793090894665		[learning rate: 0.0020336]
	Learning Rate: 0.0020336
	LOSS [training: 0.20086748881546393 | validation: 0.16132591291551626]
	TIME [epoch: 8.69 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1852956713652171		[learning rate: 0.0020288]
		[batch 20/20] avg loss: 0.246133915530283		[learning rate: 0.0020241]
	Learning Rate: 0.00202407
	LOSS [training: 0.21571479344775005 | validation: 0.11171860473688736]
	TIME [epoch: 8.7 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19068784080807025		[learning rate: 0.0020193]
		[batch 20/20] avg loss: 0.19560891301671424		[learning rate: 0.0020146]
	Learning Rate: 0.00201458
	LOSS [training: 0.1931483769123922 | validation: 0.14309482851030442]
	TIME [epoch: 8.73 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/20] avg loss: 0.188639393061459		[learning rate: 0.0020098]
		[batch 20/20] avg loss: 0.19731880502877486		[learning rate: 0.0020051]
	Learning Rate: 0.00200513
	LOSS [training: 0.19297909904511695 | validation: 0.11803971373969613]
	TIME [epoch: 8.7 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1740638884778797		[learning rate: 0.0020004]
		[batch 20/20] avg loss: 0.22205915906156407		[learning rate: 0.0019957]
	Learning Rate: 0.00199573
	LOSS [training: 0.19806152376972186 | validation: 0.1921453238551539]
	TIME [epoch: 8.7 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17296284739101048		[learning rate: 0.001991]
		[batch 20/20] avg loss: 0.22713771055838		[learning rate: 0.0019864]
	Learning Rate: 0.00198637
	LOSS [training: 0.20005027897469527 | validation: 0.3657502852418555]
	TIME [epoch: 8.7 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1767076991057694		[learning rate: 0.0019817]
		[batch 20/20] avg loss: 0.2018901525609539		[learning rate: 0.0019771]
	Learning Rate: 0.00197706
	LOSS [training: 0.18929892583336164 | validation: 0.25069417251831805]
	TIME [epoch: 8.73 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19718810906750311		[learning rate: 0.0019724]
		[batch 20/20] avg loss: 0.18112900703205326		[learning rate: 0.0019678]
	Learning Rate: 0.00196779
	LOSS [training: 0.18915855804977819 | validation: 0.10084562694714781]
	TIME [epoch: 8.71 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3115103360988897		[learning rate: 0.0019632]
		[batch 20/20] avg loss: 0.22595856571969936		[learning rate: 0.0019586]
	Learning Rate: 0.00195857
	LOSS [training: 0.26873445090929454 | validation: 0.11856526838750471]
	TIME [epoch: 8.7 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15573477606215996		[learning rate: 0.001954]
		[batch 20/20] avg loss: 0.19024099360380986		[learning rate: 0.0019494]
	Learning Rate: 0.00194939
	LOSS [training: 0.17298788483298494 | validation: 0.24482815205459985]
	TIME [epoch: 8.69 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18982587443777954		[learning rate: 0.0019448]
		[batch 20/20] avg loss: 0.21901131534972623		[learning rate: 0.0019402]
	Learning Rate: 0.00194025
	LOSS [training: 0.20441859489375283 | validation: 0.18242776669929506]
	TIME [epoch: 8.7 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19427803900026505		[learning rate: 0.0019357]
		[batch 20/20] avg loss: 0.20251428573550684		[learning rate: 0.0019312]
	Learning Rate: 0.00193115
	LOSS [training: 0.19839616236788593 | validation: 0.12484927916741503]
	TIME [epoch: 8.71 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23671095575804527		[learning rate: 0.0019266]
		[batch 20/20] avg loss: 0.2149031649123745		[learning rate: 0.0019221]
	Learning Rate: 0.0019221
	LOSS [training: 0.22580706033520995 | validation: 0.19105738259967595]
	TIME [epoch: 8.71 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18546345917242307		[learning rate: 0.0019176]
		[batch 20/20] avg loss: 0.14978675062588637		[learning rate: 0.0019131]
	Learning Rate: 0.00191309
	LOSS [training: 0.16762510489915478 | validation: 0.24881432320277508]
	TIME [epoch: 8.69 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19115852344709452		[learning rate: 0.0019086]
		[batch 20/20] avg loss: 0.19176159358092276		[learning rate: 0.0019041]
	Learning Rate: 0.00190412
	LOSS [training: 0.19146005851400866 | validation: 0.10284846569973453]
	TIME [epoch: 8.69 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22781658206212682		[learning rate: 0.0018996]
		[batch 20/20] avg loss: 0.18238576517072003		[learning rate: 0.0018952]
	Learning Rate: 0.00189519
	LOSS [training: 0.20510117361642344 | validation: 0.07313310032205328]
	TIME [epoch: 8.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_364.pth
	Model improved!!!
EPOCH 365/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1490998643134603		[learning rate: 0.0018907]
		[batch 20/20] avg loss: 0.17170800048859122		[learning rate: 0.0018863]
	Learning Rate: 0.00188631
	LOSS [training: 0.1604039324010258 | validation: 0.14969700266286165]
	TIME [epoch: 8.71 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14912579253813635		[learning rate: 0.0018819]
		[batch 20/20] avg loss: 0.18038764488943493		[learning rate: 0.0018775]
	Learning Rate: 0.00187746
	LOSS [training: 0.16475671871378567 | validation: 0.24674936954824836]
	TIME [epoch: 8.75 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2572216074886424		[learning rate: 0.0018731]
		[batch 20/20] avg loss: 0.1863363222040788		[learning rate: 0.0018687]
	Learning Rate: 0.00186866
	LOSS [training: 0.22177896484636062 | validation: 0.06151414679333179]
	TIME [epoch: 8.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_367.pth
	Model improved!!!
EPOCH 368/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19721014787483923		[learning rate: 0.0018643]
		[batch 20/20] avg loss: 0.1508062391415496		[learning rate: 0.0018599]
	Learning Rate: 0.0018599
	LOSS [training: 0.17400819350819435 | validation: 0.11120793811023157]
	TIME [epoch: 8.7 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1744716599887684		[learning rate: 0.0018555]
		[batch 20/20] avg loss: 0.15133086783022565		[learning rate: 0.0018512]
	Learning Rate: 0.00185118
	LOSS [training: 0.16290126390949697 | validation: 0.24389873837566653]
	TIME [epoch: 8.71 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18672629087001477		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.19707493955232588		[learning rate: 0.0018425]
	Learning Rate: 0.0018425
	LOSS [training: 0.19190061521117036 | validation: 0.11947450635689383]
	TIME [epoch: 8.73 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17877121662351386		[learning rate: 0.0018382]
		[batch 20/20] avg loss: 0.14461328182338426		[learning rate: 0.0018339]
	Learning Rate: 0.00183386
	LOSS [training: 0.16169224922344907 | validation: 0.14485495960336756]
	TIME [epoch: 8.7 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17994088802234787		[learning rate: 0.0018296]
		[batch 20/20] avg loss: 0.14979587813531506		[learning rate: 0.0018253]
	Learning Rate: 0.00182527
	LOSS [training: 0.16486838307883148 | validation: 0.07770376805300183]
	TIME [epoch: 8.71 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15169673755576066		[learning rate: 0.001821]
		[batch 20/20] avg loss: 0.12654316073209917		[learning rate: 0.0018167]
	Learning Rate: 0.00181671
	LOSS [training: 0.13911994914392994 | validation: 0.13965924652977774]
	TIME [epoch: 8.7 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22082473673513775		[learning rate: 0.0018124]
		[batch 20/20] avg loss: 0.16835119880978205		[learning rate: 0.0018082]
	Learning Rate: 0.00180819
	LOSS [training: 0.1945879677724599 | validation: 0.24188290975323004]
	TIME [epoch: 8.75 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18752497509204819		[learning rate: 0.001804]
		[batch 20/20] avg loss: 0.15850624430410332		[learning rate: 0.0017997]
	Learning Rate: 0.00179972
	LOSS [training: 0.17301560969807575 | validation: 0.11313233584767993]
	TIME [epoch: 8.71 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1701892752739251		[learning rate: 0.0017955]
		[batch 20/20] avg loss: 0.12892313503782507		[learning rate: 0.0017913]
	Learning Rate: 0.00179128
	LOSS [training: 0.1495562051558751 | validation: 0.18932934327022907]
	TIME [epoch: 8.71 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24046428845067708		[learning rate: 0.0017871]
		[batch 20/20] avg loss: 0.2379766100407295		[learning rate: 0.0017829]
	Learning Rate: 0.00178288
	LOSS [training: 0.23922044924570324 | validation: 0.1807790580461266]
	TIME [epoch: 8.69 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1424215597221265		[learning rate: 0.0017787]
		[batch 20/20] avg loss: 0.17449132118829655		[learning rate: 0.0017745]
	Learning Rate: 0.00177452
	LOSS [training: 0.1584564404552115 | validation: 0.18651469462504555]
	TIME [epoch: 8.7 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16875065175395215		[learning rate: 0.0017704]
		[batch 20/20] avg loss: 0.20569796849188923		[learning rate: 0.0017662]
	Learning Rate: 0.0017662
	LOSS [training: 0.1872243101229207 | validation: 0.08585446771379589]
	TIME [epoch: 8.72 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16400120150077094		[learning rate: 0.0017621]
		[batch 20/20] avg loss: 0.2232828835542672		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.1936420425275191 | validation: 0.14677151328770408]
	TIME [epoch: 8.7 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1686235864417957		[learning rate: 0.0017538]
		[batch 20/20] avg loss: 0.15933438341487507		[learning rate: 0.0017497]
	Learning Rate: 0.00174968
	LOSS [training: 0.16397898492833535 | validation: 0.12276010764317263]
	TIME [epoch: 8.68 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16100349515834603		[learning rate: 0.0017456]
		[batch 20/20] avg loss: 0.16950802044113997		[learning rate: 0.0017415]
	Learning Rate: 0.00174148
	LOSS [training: 0.165255757799743 | validation: 0.13785698174064243]
	TIME [epoch: 8.67 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2028206629572332		[learning rate: 0.0017374]
		[batch 20/20] avg loss: 0.1695733879904619		[learning rate: 0.0017333]
	Learning Rate: 0.00173331
	LOSS [training: 0.18619702547384753 | validation: 0.10220385474751233]
	TIME [epoch: 8.67 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14073330404064063		[learning rate: 0.0017292]
		[batch 20/20] avg loss: 0.15797247699199082		[learning rate: 0.0017252]
	Learning Rate: 0.00172519
	LOSS [training: 0.1493528905163157 | validation: 0.0778814399421136]
	TIME [epoch: 8.71 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14363788366498567		[learning rate: 0.0017211]
		[batch 20/20] avg loss: 0.12297343935928609		[learning rate: 0.0017171]
	Learning Rate: 0.0017171
	LOSS [training: 0.13330566151213585 | validation: 0.050816402864538056]
	TIME [epoch: 8.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_385.pth
	Model improved!!!
EPOCH 386/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15144873659142116		[learning rate: 0.0017131]
		[batch 20/20] avg loss: 0.1632050389856261		[learning rate: 0.0017091]
	Learning Rate: 0.00170905
	LOSS [training: 0.1573268877885236 | validation: 0.10283431578693522]
	TIME [epoch: 8.74 sec]
EPOCH 387/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16346174501169233		[learning rate: 0.001705]
		[batch 20/20] avg loss: 0.1756280284149334		[learning rate: 0.001701]
	Learning Rate: 0.00170104
	LOSS [training: 0.16954488671331286 | validation: 0.08345007630618954]
	TIME [epoch: 8.73 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14450768541781844		[learning rate: 0.001697]
		[batch 20/20] avg loss: 0.13116336306511409		[learning rate: 0.0016931]
	Learning Rate: 0.00169306
	LOSS [training: 0.13783552424146628 | validation: 0.06989909606170974]
	TIME [epoch: 8.71 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1309381161304388		[learning rate: 0.0016891]
		[batch 20/20] avg loss: 0.18946728029226362		[learning rate: 0.0016851]
	Learning Rate: 0.00168513
	LOSS [training: 0.1602026982113512 | validation: 0.11771994341633935]
	TIME [epoch: 8.74 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11299661916516734		[learning rate: 0.0016812]
		[batch 20/20] avg loss: 0.17196893751655234		[learning rate: 0.0016772]
	Learning Rate: 0.00167723
	LOSS [training: 0.14248277834085982 | validation: 0.1089079781771268]
	TIME [epoch: 8.73 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17700623854797362		[learning rate: 0.0016733]
		[batch 20/20] avg loss: 0.14999881807678042		[learning rate: 0.0016694]
	Learning Rate: 0.00166936
	LOSS [training: 0.16350252831237702 | validation: 0.11386046669709443]
	TIME [epoch: 8.72 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/20] avg loss: 0.262157254108337		[learning rate: 0.0016654]
		[batch 20/20] avg loss: 0.14165963277649124		[learning rate: 0.0016615]
	Learning Rate: 0.00166154
	LOSS [training: 0.20190844344241415 | validation: 0.06829785397969089]
	TIME [epoch: 8.73 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16517282300775787		[learning rate: 0.0016576]
		[batch 20/20] avg loss: 0.24077888824967894		[learning rate: 0.0016537]
	Learning Rate: 0.00165375
	LOSS [training: 0.2029758556287184 | validation: 0.2751892042625374]
	TIME [epoch: 8.73 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18280834300512908		[learning rate: 0.0016499]
		[batch 20/20] avg loss: 0.20607729070972858		[learning rate: 0.001646]
	Learning Rate: 0.001646
	LOSS [training: 0.1944428168574288 | validation: 0.13246058334537572]
	TIME [epoch: 8.75 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16388585472249195		[learning rate: 0.0016421]
		[batch 20/20] avg loss: 0.1650398866339045		[learning rate: 0.0016383]
	Learning Rate: 0.00163828
	LOSS [training: 0.16446287067819823 | validation: 0.21509550347623835]
	TIME [epoch: 8.72 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14556467373913556		[learning rate: 0.0016344]
		[batch 20/20] avg loss: 0.17630149637914821		[learning rate: 0.0016306]
	Learning Rate: 0.0016306
	LOSS [training: 0.16093308505914186 | validation: 0.21962806489590084]
	TIME [epoch: 8.72 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16300656701051539		[learning rate: 0.0016268]
		[batch 20/20] avg loss: 0.16073712208776292		[learning rate: 0.001623]
	Learning Rate: 0.00162295
	LOSS [training: 0.16187184454913917 | validation: 0.09426939036829399]
	TIME [epoch: 8.73 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12133858578038859		[learning rate: 0.0016191]
		[batch 20/20] avg loss: 0.15584570143556747		[learning rate: 0.0016153]
	Learning Rate: 0.00161535
	LOSS [training: 0.13859214360797806 | validation: 0.21629692424283192]
	TIME [epoch: 8.75 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16013979460536676		[learning rate: 0.0016116]
		[batch 20/20] avg loss: 0.11848690607167445		[learning rate: 0.0016078]
	Learning Rate: 0.00160777
	LOSS [training: 0.1393133503385206 | validation: 0.11611614516737839]
	TIME [epoch: 8.73 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1387657468436888		[learning rate: 0.001604]
		[batch 20/20] avg loss: 0.18439050150656616		[learning rate: 0.0016002]
	Learning Rate: 0.00160023
	LOSS [training: 0.1615781241751275 | validation: 0.12284406933008399]
	TIME [epoch: 8.73 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15191735283998434		[learning rate: 0.0015965]
		[batch 20/20] avg loss: 0.13672756265206173		[learning rate: 0.0015927]
	Learning Rate: 0.00159273
	LOSS [training: 0.14432245774602304 | validation: 0.2736366674735053]
	TIME [epoch: 8.72 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18630988493898398		[learning rate: 0.001589]
		[batch 20/20] avg loss: 0.1344601612945632		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.16038502311677355 | validation: 0.16599379746445775]
	TIME [epoch: 8.73 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18602648571028765		[learning rate: 0.0015815]
		[batch 20/20] avg loss: 0.1515970491981708		[learning rate: 0.0015778]
	Learning Rate: 0.00157783
	LOSS [training: 0.16881176745422924 | validation: 0.18969248988662235]
	TIME [epoch: 8.75 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/20] avg loss: 0.201033507860159		[learning rate: 0.0015741]
		[batch 20/20] avg loss: 0.15521931534696712		[learning rate: 0.0015704]
	Learning Rate: 0.00157044
	LOSS [training: 0.17812641160356307 | validation: 0.13534311942949823]
	TIME [epoch: 8.73 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2547301946564514		[learning rate: 0.0015668]
		[batch 20/20] avg loss: 0.11427597625060833		[learning rate: 0.0015631]
	Learning Rate: 0.00156307
	LOSS [training: 0.18450308545352986 | validation: 0.16877782835229604]
	TIME [epoch: 8.73 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14032654025323668		[learning rate: 0.0015594]
		[batch 20/20] avg loss: 0.11893125078211113		[learning rate: 0.0015557]
	Learning Rate: 0.00155575
	LOSS [training: 0.1296288955176739 | validation: 0.15157429507184125]
	TIME [epoch: 8.73 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1383720925284486		[learning rate: 0.0015521]
		[batch 20/20] avg loss: 0.13592599020060397		[learning rate: 0.0015485]
	Learning Rate: 0.00154845
	LOSS [training: 0.1371490413645263 | validation: 0.10698593413734794]
	TIME [epoch: 8.72 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17389014479297796		[learning rate: 0.0015448]
		[batch 20/20] avg loss: 0.12902330017942626		[learning rate: 0.0015412]
	Learning Rate: 0.00154119
	LOSS [training: 0.15145672248620212 | validation: 0.04452772280833182]
	TIME [epoch: 8.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_408.pth
	Model improved!!!
EPOCH 409/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13936972784365728		[learning rate: 0.0015376]
		[batch 20/20] avg loss: 0.12691248748454806		[learning rate: 0.001534]
	Learning Rate: 0.00153397
	LOSS [training: 0.13314110766410267 | validation: 0.08295571122531581]
	TIME [epoch: 8.69 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16615076634711407		[learning rate: 0.0015304]
		[batch 20/20] avg loss: 0.14392528734586427		[learning rate: 0.0015268]
	Learning Rate: 0.00152678
	LOSS [training: 0.15503802684648915 | validation: 0.07622431492158359]
	TIME [epoch: 8.68 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1522804324791566		[learning rate: 0.0015232]
		[batch 20/20] avg loss: 0.11010784352653447		[learning rate: 0.0015196]
	Learning Rate: 0.00151962
	LOSS [training: 0.13119413800284555 | validation: 0.09072152915928644]
	TIME [epoch: 8.69 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12688485906673094		[learning rate: 0.0015161]
		[batch 20/20] avg loss: 0.20432695140191792		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.16560590523432442 | validation: 0.09789365057245836]
	TIME [epoch: 8.69 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17301923580601936		[learning rate: 0.0015089]
		[batch 20/20] avg loss: 0.203236538733994		[learning rate: 0.0015054]
	Learning Rate: 0.0015054
	LOSS [training: 0.18812788727000668 | validation: 0.2649574482952713]
	TIME [epoch: 8.72 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1581888035828604		[learning rate: 0.0015019]
		[batch 20/20] avg loss: 0.16928266275667447		[learning rate: 0.0014983]
	Learning Rate: 0.00149835
	LOSS [training: 0.1637357331697674 | validation: 0.38473246112465925]
	TIME [epoch: 8.69 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22194354168408847		[learning rate: 0.0014948]
		[batch 20/20] avg loss: 0.15311266290600745		[learning rate: 0.0014913]
	Learning Rate: 0.00149132
	LOSS [training: 0.187528102295048 | validation: 0.10552552900665592]
	TIME [epoch: 8.71 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10428404102938241		[learning rate: 0.0014878]
		[batch 20/20] avg loss: 0.19415657652219423		[learning rate: 0.0014843]
	Learning Rate: 0.00148433
	LOSS [training: 0.14922030877578835 | validation: 0.07253356642870218]
	TIME [epoch: 8.69 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24560828191837847		[learning rate: 0.0014808]
		[batch 20/20] avg loss: 0.1231187908505822		[learning rate: 0.0014774]
	Learning Rate: 0.00147737
	LOSS [training: 0.18436353638448036 | validation: 0.09033315545028908]
	TIME [epoch: 8.73 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1696046140001998		[learning rate: 0.0014739]
		[batch 20/20] avg loss: 0.17221817552841057		[learning rate: 0.0014704]
	Learning Rate: 0.00147045
	LOSS [training: 0.1709113947643052 | validation: 0.1556317408807566]
	TIME [epoch: 8.7 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17187485794620988		[learning rate: 0.001467]
		[batch 20/20] avg loss: 0.3493833346920128		[learning rate: 0.0014636]
	Learning Rate: 0.00146355
	LOSS [training: 0.2606290963191113 | validation: 0.2608596327213021]
	TIME [epoch: 8.7 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16090861404070272		[learning rate: 0.0014601]
		[batch 20/20] avg loss: 0.13348183705219127		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.14719522554644698 | validation: 0.1876065402225956]
	TIME [epoch: 8.69 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1487034874836517		[learning rate: 0.0014533]
		[batch 20/20] avg loss: 0.14174805324133838		[learning rate: 0.0014499]
	Learning Rate: 0.00144986
	LOSS [training: 0.145225770362495 | validation: 0.09942477301368018]
	TIME [epoch: 8.7 sec]
EPOCH 422/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1817444379722293		[learning rate: 0.0014465]
		[batch 20/20] avg loss: 0.13788239770934524		[learning rate: 0.0014431]
	Learning Rate: 0.00144306
	LOSS [training: 0.15981341784078723 | validation: 0.22616253365761405]
	TIME [epoch: 8.71 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15511579751187976		[learning rate: 0.0014397]
		[batch 20/20] avg loss: 0.11961898204351536		[learning rate: 0.0014363]
	Learning Rate: 0.0014363
	LOSS [training: 0.13736738977769752 | validation: 0.22426986626618794]
	TIME [epoch: 8.7 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18528302341665073		[learning rate: 0.0014329]
		[batch 20/20] avg loss: 0.13718673333704612		[learning rate: 0.0014296]
	Learning Rate: 0.00142957
	LOSS [training: 0.16123487837684838 | validation: 0.1332548048952929]
	TIME [epoch: 8.69 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1606895359734708		[learning rate: 0.0014262]
		[batch 20/20] avg loss: 0.16196622552305465		[learning rate: 0.0014229]
	Learning Rate: 0.00142286
	LOSS [training: 0.1613278807482627 | validation: 0.06174265413845225]
	TIME [epoch: 8.71 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11571734545727874		[learning rate: 0.0014195]
		[batch 20/20] avg loss: 0.2524480124090609		[learning rate: 0.0014162]
	Learning Rate: 0.00141619
	LOSS [training: 0.1840826789331698 | validation: 0.2588014058346226]
	TIME [epoch: 8.71 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16926983331267226		[learning rate: 0.0014129]
		[batch 20/20] avg loss: 0.1116295362697445		[learning rate: 0.0014096]
	Learning Rate: 0.00140955
	LOSS [training: 0.14044968479120837 | validation: 0.1834159520626478]
	TIME [epoch: 8.73 sec]
EPOCH 428/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15083420837676154		[learning rate: 0.0014062]
		[batch 20/20] avg loss: 0.1485989349804995		[learning rate: 0.0014029]
	Learning Rate: 0.00140295
	LOSS [training: 0.14971657167863053 | validation: 0.10455387216773007]
	TIME [epoch: 8.72 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12029143469766115		[learning rate: 0.0013997]
		[batch 20/20] avg loss: 0.1503956553232634		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.13534354501046225 | validation: 0.10942458606713334]
	TIME [epoch: 8.71 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1186440551381502		[learning rate: 0.0013931]
		[batch 20/20] avg loss: 0.12796154557444733		[learning rate: 0.0013898]
	Learning Rate: 0.00138982
	LOSS [training: 0.12330280035629877 | validation: 0.10781699111267734]
	TIME [epoch: 8.7 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1304603767663699		[learning rate: 0.0013866]
		[batch 20/20] avg loss: 0.11223219970709616		[learning rate: 0.0013833]
	Learning Rate: 0.00138331
	LOSS [training: 0.12134628823673303 | validation: 0.08418959350222208]
	TIME [epoch: 8.69 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1169112549472836		[learning rate: 0.0013801]
		[batch 20/20] avg loss: 0.13757779249509663		[learning rate: 0.0013768]
	Learning Rate: 0.00137682
	LOSS [training: 0.1272445237211901 | validation: 0.07691382024149734]
	TIME [epoch: 8.72 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1682706924396205		[learning rate: 0.0013736]
		[batch 20/20] avg loss: 0.2009043635926387		[learning rate: 0.0013704]
	Learning Rate: 0.00137037
	LOSS [training: 0.1845875280161296 | validation: 0.10048493423925027]
	TIME [epoch: 8.71 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13163173448668775		[learning rate: 0.0013672]
		[batch 20/20] avg loss: 0.16024069030375793		[learning rate: 0.0013639]
	Learning Rate: 0.00136394
	LOSS [training: 0.14593621239522286 | validation: 0.14357980710258988]
	TIME [epoch: 8.7 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13059260907807885		[learning rate: 0.0013607]
		[batch 20/20] avg loss: 0.1265331685161118		[learning rate: 0.0013575]
	Learning Rate: 0.00135755
	LOSS [training: 0.1285628887970953 | validation: 0.08688423685222117]
	TIME [epoch: 8.7 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11820225493566912		[learning rate: 0.0013544]
		[batch 20/20] avg loss: 0.14754890199992687		[learning rate: 0.0013512]
	Learning Rate: 0.00135118
	LOSS [training: 0.132875578467798 | validation: 0.09257245944270157]
	TIME [epoch: 8.69 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19367876373446277		[learning rate: 0.001348]
		[batch 20/20] avg loss: 0.1435203900983081		[learning rate: 0.0013448]
	Learning Rate: 0.00134485
	LOSS [training: 0.16859957691638544 | validation: 0.12401200663831395]
	TIME [epoch: 8.73 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12331400497336872		[learning rate: 0.0013417]
		[batch 20/20] avg loss: 0.12779738163094742		[learning rate: 0.0013385]
	Learning Rate: 0.00133854
	LOSS [training: 0.1255556933021581 | validation: 0.046105178962888016]
	TIME [epoch: 8.68 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14936616624191518		[learning rate: 0.0013354]
		[batch 20/20] avg loss: 0.12710379993752657		[learning rate: 0.0013323]
	Learning Rate: 0.00133227
	LOSS [training: 0.13823498308972088 | validation: 0.10453170355284927]
	TIME [epoch: 8.69 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1408021517085689		[learning rate: 0.0013291]
		[batch 20/20] avg loss: 0.1081083384589212		[learning rate: 0.001326]
	Learning Rate: 0.00132602
	LOSS [training: 0.12445524508374506 | validation: 0.033319867756522605]
	TIME [epoch: 8.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_440.pth
	Model improved!!!
EPOCH 441/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09440324049120323		[learning rate: 0.0013229]
		[batch 20/20] avg loss: 0.11921778068229916		[learning rate: 0.0013198]
	Learning Rate: 0.00131981
	LOSS [training: 0.10681051058675121 | validation: 0.04879932172475751]
	TIME [epoch: 8.73 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09151867591774662		[learning rate: 0.0013167]
		[batch 20/20] avg loss: 0.12447281396903583		[learning rate: 0.0013136]
	Learning Rate: 0.00131362
	LOSS [training: 0.10799574494339123 | validation: 0.16099609542391]
	TIME [epoch: 8.7 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12074993822561489		[learning rate: 0.0013105]
		[batch 20/20] avg loss: 0.1431224705350236		[learning rate: 0.0013075]
	Learning Rate: 0.00130746
	LOSS [training: 0.13193620438031922 | validation: 0.06012442636079564]
	TIME [epoch: 8.71 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13069006657472557		[learning rate: 0.0013044]
		[batch 20/20] avg loss: 0.11574355160665398		[learning rate: 0.0013013]
	Learning Rate: 0.00130133
	LOSS [training: 0.12321680909068977 | validation: 0.052109928011278686]
	TIME [epoch: 8.71 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13147011909803247		[learning rate: 0.0012983]
		[batch 20/20] avg loss: 0.12361781687033677		[learning rate: 0.0012952]
	Learning Rate: 0.00129523
	LOSS [training: 0.12754396798418463 | validation: 0.11594941010687156]
	TIME [epoch: 8.69 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1419035004113887		[learning rate: 0.0012922]
		[batch 20/20] avg loss: 0.2119328563955689		[learning rate: 0.0012892]
	Learning Rate: 0.00128916
	LOSS [training: 0.1769181784034788 | validation: 0.09056049455603837]
	TIME [epoch: 8.73 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11440815626838532		[learning rate: 0.0012861]
		[batch 20/20] avg loss: 0.11202707727984688		[learning rate: 0.0012831]
	Learning Rate: 0.00128311
	LOSS [training: 0.11321761677411608 | validation: 0.09674154949839718]
	TIME [epoch: 8.71 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14754182960259385		[learning rate: 0.0012801]
		[batch 20/20] avg loss: 0.1346309050519022		[learning rate: 0.0012771]
	Learning Rate: 0.0012771
	LOSS [training: 0.14108636732724805 | validation: 0.08818065519065466]
	TIME [epoch: 8.7 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20310261152160058		[learning rate: 0.0012741]
		[batch 20/20] avg loss: 0.14754680867291659		[learning rate: 0.0012711]
	Learning Rate: 0.00127111
	LOSS [training: 0.17532471009725856 | validation: 0.06197042883243619]
	TIME [epoch: 8.69 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11633569301703936		[learning rate: 0.0012681]
		[batch 20/20] avg loss: 0.11776142341998948		[learning rate: 0.0012652]
	Learning Rate: 0.00126515
	LOSS [training: 0.11704855821851443 | validation: 0.12691938176149462]
	TIME [epoch: 8.69 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11741084713324354		[learning rate: 0.0012622]
		[batch 20/20] avg loss: 0.12326522809469494		[learning rate: 0.0012592]
	Learning Rate: 0.00125922
	LOSS [training: 0.12033803761396925 | validation: 0.07884287561696056]
	TIME [epoch: 8.73 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10830528711058715		[learning rate: 0.0012563]
		[batch 20/20] avg loss: 0.10001285251728712		[learning rate: 0.0012533]
	Learning Rate: 0.00125332
	LOSS [training: 0.10415906981393715 | validation: 0.0847961901104634]
	TIME [epoch: 8.7 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17313226261661582		[learning rate: 0.0012504]
		[batch 20/20] avg loss: 0.15638499877209794		[learning rate: 0.0012474]
	Learning Rate: 0.00124744
	LOSS [training: 0.16475863069435687 | validation: 0.16953127912621066]
	TIME [epoch: 8.71 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13288698821755987		[learning rate: 0.0012445]
		[batch 20/20] avg loss: 0.1473472442171038		[learning rate: 0.0012416]
	Learning Rate: 0.00124159
	LOSS [training: 0.14011711621733183 | validation: 0.08310652415505204]
	TIME [epoch: 8.7 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1227996207512394		[learning rate: 0.0012387]
		[batch 20/20] avg loss: 0.11624405494372894		[learning rate: 0.0012358]
	Learning Rate: 0.00123577
	LOSS [training: 0.11952183784748419 | validation: 0.06262869601223413]
	TIME [epoch: 8.7 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13707869833837463		[learning rate: 0.0012329]
		[batch 20/20] avg loss: 0.15680881908400393		[learning rate: 0.00123]
	Learning Rate: 0.00122998
	LOSS [training: 0.1469437587111893 | validation: 0.07105128653831745]
	TIME [epoch: 8.72 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09153974854435767		[learning rate: 0.0012271]
		[batch 20/20] avg loss: 0.15155049568835757		[learning rate: 0.0012242]
	Learning Rate: 0.00122421
	LOSS [training: 0.12154512211635764 | validation: 0.09099752127888304]
	TIME [epoch: 8.72 sec]
EPOCH 458/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12473326702882223		[learning rate: 0.0012213]
		[batch 20/20] avg loss: 0.1369491065065516		[learning rate: 0.0012185]
	Learning Rate: 0.00121847
	LOSS [training: 0.1308411867676869 | validation: 0.13805581712984388]
	TIME [epoch: 8.7 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19739747831574755		[learning rate: 0.0012156]
		[batch 20/20] avg loss: 0.09863191311485761		[learning rate: 0.0012128]
	Learning Rate: 0.00121276
	LOSS [training: 0.14801469571530257 | validation: 0.11921257800026545]
	TIME [epoch: 8.69 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12492922478816919		[learning rate: 0.0012099]
		[batch 20/20] avg loss: 0.1261674764208871		[learning rate: 0.0012071]
	Learning Rate: 0.00120708
	LOSS [training: 0.12554835060452818 | validation: 0.24782916608452166]
	TIME [epoch: 8.71 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11582435699776883		[learning rate: 0.0012042]
		[batch 20/20] avg loss: 0.11110817771636869		[learning rate: 0.0012014]
	Learning Rate: 0.00120142
	LOSS [training: 0.11346626735706877 | validation: 0.09001923031006198]
	TIME [epoch: 8.71 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13699733613740872		[learning rate: 0.0011986]
		[batch 20/20] avg loss: 0.10503866027241926		[learning rate: 0.0011958]
	Learning Rate: 0.00119578
	LOSS [training: 0.12101799820491396 | validation: 0.090434258940648]
	TIME [epoch: 8.7 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10481585740629613		[learning rate: 0.001193]
		[batch 20/20] avg loss: 0.13908740301890107		[learning rate: 0.0011902]
	Learning Rate: 0.00119018
	LOSS [training: 0.12195163021259861 | validation: 0.19155063683131085]
	TIME [epoch: 8.69 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14322899309848927		[learning rate: 0.0011874]
		[batch 20/20] avg loss: 0.13890323044062297		[learning rate: 0.0011846]
	Learning Rate: 0.0011846
	LOSS [training: 0.14106611176955614 | validation: 0.14208255861845642]
	TIME [epoch: 8.69 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13001433677125923		[learning rate: 0.0011818]
		[batch 20/20] avg loss: 0.12396997446805566		[learning rate: 0.001179]
	Learning Rate: 0.00117905
	LOSS [training: 0.12699215561965746 | validation: 0.17213091834887634]
	TIME [epoch: 8.71 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17173495554125953		[learning rate: 0.0011763]
		[batch 20/20] avg loss: 0.10302328260383486		[learning rate: 0.0011735]
	Learning Rate: 0.00117352
	LOSS [training: 0.13737911907254718 | validation: 0.1944906509100529]
	TIME [epoch: 8.7 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11861115057762053		[learning rate: 0.0011708]
		[batch 20/20] avg loss: 0.15186892738074675		[learning rate: 0.001168]
	Learning Rate: 0.00116802
	LOSS [training: 0.13524003897918363 | validation: 0.26494467485699297]
	TIME [epoch: 8.7 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14989848338397455		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.08899794388471008		[learning rate: 0.0011625]
	Learning Rate: 0.00116254
	LOSS [training: 0.11944821363434228 | validation: 0.09641408442887199]
	TIME [epoch: 8.69 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11962075365869658		[learning rate: 0.0011598]
		[batch 20/20] avg loss: 0.10723508895751277		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.11342792130810467 | validation: 0.1072381061296602]
	TIME [epoch: 8.69 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09867591503635813		[learning rate: 0.0011544]
		[batch 20/20] avg loss: 0.12108496573742862		[learning rate: 0.0011517]
	Learning Rate: 0.00115167
	LOSS [training: 0.10988044038689337 | validation: 0.3236454454130088]
	TIME [epoch: 8.72 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13638029742093025		[learning rate: 0.001149]
		[batch 20/20] avg loss: 0.11569143567187117		[learning rate: 0.0011463]
	Learning Rate: 0.00114627
	LOSS [training: 0.1260358665464007 | validation: 0.16873661656671954]
	TIME [epoch: 8.7 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/20] avg loss: 0.141763010644129		[learning rate: 0.0011436]
		[batch 20/20] avg loss: 0.10882625533858528		[learning rate: 0.0011409]
	Learning Rate: 0.00114089
	LOSS [training: 0.12529463299135712 | validation: 0.07610206977764826]
	TIME [epoch: 8.68 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10475406887381733		[learning rate: 0.0011382]
		[batch 20/20] avg loss: 0.12201529201545544		[learning rate: 0.0011355]
	Learning Rate: 0.00113554
	LOSS [training: 0.11338468044463638 | validation: 0.13550182734718885]
	TIME [epoch: 8.69 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17431433253021317		[learning rate: 0.0011329]
		[batch 20/20] avg loss: 0.12259673521199384		[learning rate: 0.0011302]
	Learning Rate: 0.00113022
	LOSS [training: 0.1484555338711035 | validation: 0.05731781907084451]
	TIME [epoch: 8.7 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13237236419569193		[learning rate: 0.0011276]
		[batch 20/20] avg loss: 0.11098699136324483		[learning rate: 0.0011249]
	Learning Rate: 0.00112492
	LOSS [training: 0.12167967777946838 | validation: 0.17624496080881924]
	TIME [epoch: 8.72 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11161182067098567		[learning rate: 0.0011223]
		[batch 20/20] avg loss: 0.07535997021158844		[learning rate: 0.0011196]
	Learning Rate: 0.00111965
	LOSS [training: 0.09348589544128706 | validation: 0.03765623566996904]
	TIME [epoch: 8.7 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11282626708174345		[learning rate: 0.001117]
		[batch 20/20] avg loss: 0.13393700217686752		[learning rate: 0.0011144]
	Learning Rate: 0.0011144
	LOSS [training: 0.12338163462930547 | validation: 0.12188914643398692]
	TIME [epoch: 8.69 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/20] avg loss: 0.117214160570943		[learning rate: 0.0011118]
		[batch 20/20] avg loss: 0.11994916301116028		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.11858166179105165 | validation: 0.13013469733257743]
	TIME [epoch: 8.69 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10628688073572323		[learning rate: 0.0011066]
		[batch 20/20] avg loss: 0.11748798060492464		[learning rate: 0.001104]
	Learning Rate: 0.00110397
	LOSS [training: 0.11188743067032395 | validation: 0.04608766724834539]
	TIME [epoch: 8.69 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/20] avg loss: 0.093059162905882		[learning rate: 0.0011014]
		[batch 20/20] avg loss: 0.10978756677099906		[learning rate: 0.0010988]
	Learning Rate: 0.0010988
	LOSS [training: 0.10142336483844053 | validation: 0.046563538304948686]
	TIME [epoch: 8.71 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1059792988400112		[learning rate: 0.0010962]
		[batch 20/20] avg loss: 0.12774900838265843		[learning rate: 0.0010936]
	Learning Rate: 0.00109365
	LOSS [training: 0.11686415361133481 | validation: 0.08192801894284668]
	TIME [epoch: 8.69 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/20] avg loss: 0.09920132305767948		[learning rate: 0.0010911]
		[batch 20/20] avg loss: 0.114365599977525		[learning rate: 0.0010885]
	Learning Rate: 0.00108852
	LOSS [training: 0.10678346151760224 | validation: 0.07378093916799328]
	TIME [epoch: 8.69 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11389695913598015		[learning rate: 0.001086]
		[batch 20/20] avg loss: 0.08352233985660189		[learning rate: 0.0010834]
	Learning Rate: 0.00108342
	LOSS [training: 0.09870964949629099 | validation: 0.10246268939212136]
	TIME [epoch: 8.7 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16143876588418918		[learning rate: 0.0010809]
		[batch 20/20] avg loss: 0.10565668374396682		[learning rate: 0.0010783]
	Learning Rate: 0.00107834
	LOSS [training: 0.13354772481407798 | validation: 0.09583770938256995]
	TIME [epoch: 8.7 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08838022561828995		[learning rate: 0.0010758]
		[batch 20/20] avg loss: 0.08649458799411648		[learning rate: 0.0010733]
	Learning Rate: 0.00107328
	LOSS [training: 0.08743740680620322 | validation: 0.051716215572236324]
	TIME [epoch: 8.71 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11536363466752815		[learning rate: 0.0010708]
		[batch 20/20] avg loss: 0.06503669621507327		[learning rate: 0.0010683]
	Learning Rate: 0.00106825
	LOSS [training: 0.09020016544130069 | validation: 0.06073225301920419]
	TIME [epoch: 8.69 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0929448299237136		[learning rate: 0.0010657]
		[batch 20/20] avg loss: 0.08973803364619834		[learning rate: 0.0010632]
	Learning Rate: 0.00106324
	LOSS [training: 0.09134143178495596 | validation: 0.0355970814329539]
	TIME [epoch: 8.7 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11536023783419384		[learning rate: 0.0010607]
		[batch 20/20] avg loss: 0.09238898861921327		[learning rate: 0.0010583]
	Learning Rate: 0.00105826
	LOSS [training: 0.10387461322670358 | validation: 0.08949768039748424]
	TIME [epoch: 8.69 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15110799792831295		[learning rate: 0.0010558]
		[batch 20/20] avg loss: 0.11603372861938192		[learning rate: 0.0010533]
	Learning Rate: 0.0010533
	LOSS [training: 0.13357086327384743 | validation: 0.1217695204596406]
	TIME [epoch: 8.73 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12151719401943384		[learning rate: 0.0010508]
		[batch 20/20] avg loss: 0.09379094678468299		[learning rate: 0.0010484]
	Learning Rate: 0.00104836
	LOSS [training: 0.10765407040205839 | validation: 0.24839511206179607]
	TIME [epoch: 8.71 sec]
EPOCH 491/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1103491751700523		[learning rate: 0.0010459]
		[batch 20/20] avg loss: 0.0733377020238373		[learning rate: 0.0010434]
	Learning Rate: 0.00104344
	LOSS [training: 0.09184343859694481 | validation: 0.0532403670222385]
	TIME [epoch: 8.69 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13505618226728783		[learning rate: 0.001041]
		[batch 20/20] avg loss: 0.10498056527545425		[learning rate: 0.0010386]
	Learning Rate: 0.00103855
	LOSS [training: 0.12001837377137103 | validation: 0.03126125947726535]
	TIME [epoch: 8.68 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r1_20240214_211753/states/model_tr_study1_492.pth
	Model improved!!!
EPOCH 493/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10299117138206812		[learning rate: 0.0010361]
		[batch 20/20] avg loss: 0.08919420680812473		[learning rate: 0.0010337]
	Learning Rate: 0.00103368
	LOSS [training: 0.09609268909509641 | validation: 0.1268021091252041]
	TIME [epoch: 8.71 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10939000878857932		[learning rate: 0.0010313]
		[batch 20/20] avg loss: 0.10074646574846353		[learning rate: 0.0010288]
	Learning Rate: 0.00102884
	LOSS [training: 0.10506823726852144 | validation: 0.09301014587526929]
	TIME [epoch: 8.74 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08397010259894354		[learning rate: 0.0010264]
		[batch 20/20] avg loss: 0.0909198827015003		[learning rate: 0.001024]
	Learning Rate: 0.00102401
	LOSS [training: 0.08744499265022192 | validation: 0.30604764827558856]
	TIME [epoch: 8.71 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17936483040309772		[learning rate: 0.0010216]
		[batch 20/20] avg loss: 0.13835752176649896		[learning rate: 0.0010192]
	Learning Rate: 0.00101921
	LOSS [training: 0.15886117608479838 | validation: 0.05638570915983636]
	TIME [epoch: 8.71 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/20] avg loss: 0.08076950695801575		[learning rate: 0.0010168]
		[batch 20/20] avg loss: 0.09598556438850091		[learning rate: 0.0010144]
	Learning Rate: 0.00101444
	LOSS [training: 0.08837753567325833 | validation: 0.052026210019183866]
	TIME [epoch: 8.71 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/20] avg loss: 0.0888767970406017		[learning rate: 0.0010121]
		[batch 20/20] avg loss: 0.13107822542174907		[learning rate: 0.0010097]
	Learning Rate: 0.00100968
	LOSS [training: 0.10997751123117534 | validation: 0.13663760492206864]
	TIME [epoch: 8.71 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10515051450332562		[learning rate: 0.0010073]
		[batch 20/20] avg loss: 0.08297582927801257		[learning rate: 0.0010049]
	Learning Rate: 0.00100495
	LOSS [training: 0.0940631718906691 | validation: 0.07091763103841267]
	TIME [epoch: 8.73 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/20] avg loss: 0.061774322680959545		[learning rate: 0.0010026]
		[batch 20/20] avg loss: 0.11472129244498679		[learning rate: 0.0010002]
	Learning Rate: 0.00100023
	LOSS [training: 0.08824780756297317 | validation: 0.06936019775078858]
	TIME [epoch: 8.7 sec]
Finished training in 4408.078 seconds.
