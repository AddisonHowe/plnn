Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r0', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2941724286

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.100580882213542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.100580882213542 | validation: 9.629531300422805]
	TIME [epoch: 87.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.156787198721844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.156787198721844 | validation: 9.323790878891]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.747044924354835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.747044924354835 | validation: 8.56886995638179]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.801859167057278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.801859167057278 | validation: 7.953470130914324]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.361680067418776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.361680067418776 | validation: 7.566948985630416]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.958950753095609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.958950753095609 | validation: 7.432125496717437]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.694713007823624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.694713007823624 | validation: 7.3666644930727125]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.467511486276354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.467511486276354 | validation: 6.482374624524497]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.03865965646178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.03865965646178 | validation: 6.162545435082393]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.849971222708841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.849971222708841 | validation: 6.337794292495759]
	TIME [epoch: 6.56 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.907114303221594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.907114303221594 | validation: 5.882131623584246]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.529771131776579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.529771131776579 | validation: 5.620641490606094]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.352001772966034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.352001772966034 | validation: 5.603485933276991]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.293933422015657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.293933422015657 | validation: 5.284996849309652]
	TIME [epoch: 6.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.813198890976943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.813198890976943 | validation: 6.218400902533865]
	TIME [epoch: 6.41 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.419216093912903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.419216093912903 | validation: 5.202963235277373]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.948735616752445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.948735616752445 | validation: 4.550079963058697]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.1792820283050585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1792820283050585 | validation: 9.901133959510004]
	TIME [epoch: 6.41 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.6195824127511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.6195824127511 | validation: 5.99034452628929]
	TIME [epoch: 6.4 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6618008292466095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6618008292466095 | validation: 5.382653277704677]
	TIME [epoch: 6.39 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.426569508168301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.426569508168301 | validation: 5.490477601410649]
	TIME [epoch: 6.4 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.267792217380482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.267792217380482 | validation: 5.325564156282983]
	TIME [epoch: 6.41 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.174176467598844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.174176467598844 | validation: 5.217030028987224]
	TIME [epoch: 6.42 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.982066619961954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.982066619961954 | validation: 5.102982031675249]
	TIME [epoch: 6.43 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.729667657376939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.729667657376939 | validation: 4.4963099444545]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.40323216636905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.40323216636905 | validation: 4.143108169863623]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.546738366149799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.546738366149799 | validation: 4.674887011280459]
	TIME [epoch: 6.51 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.225369228855309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.225369228855309 | validation: 4.04698320452137]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1961506515467155		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1961506515467155 | validation: 4.292498069786783]
	TIME [epoch: 6.47 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.076526041744859		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.076526041744859 | validation: 3.88416813385007]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2701913042487165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2701913042487165 | validation: 4.095973378545178]
	TIME [epoch: 6.42 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7661464998799428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7661464998799428 | validation: 3.473730437520294]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6610568048573424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6610568048573424 | validation: 3.5146884138057586]
	TIME [epoch: 6.5 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7669669139085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7669669139085 | validation: 3.874344182974823]
	TIME [epoch: 6.41 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5115616407430976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5115616407430976 | validation: 3.663656791887671]
	TIME [epoch: 6.4 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3340026143956134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3340026143956134 | validation: 3.3591999850627747]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6855153807420575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6855153807420575 | validation: 3.6801044128918123]
	TIME [epoch: 6.44 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9084551178124785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9084551178124785 | validation: 3.40472754801738]
	TIME [epoch: 6.42 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3293952227860295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3293952227860295 | validation: 3.3459711249947914]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1529846963161985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1529846963161985 | validation: 3.2332310317262434]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_40.pth
	Model improved!!!
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3499322767274564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3499322767274564 | validation: 3.5551354311480394]
	TIME [epoch: 6.52 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.533231917929017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.533231917929017 | validation: 3.4636981205882966]
	TIME [epoch: 6.42 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2005187825662453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2005187825662453 | validation: 3.1756507550614335]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.992111745595147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.992111745595147 | validation: 2.9237754107453435]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_44.pth
	Model improved!!!
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0485963277493524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0485963277493524 | validation: 3.1818973199266156]
	TIME [epoch: 6.52 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.931783206175723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.931783206175723 | validation: 3.269966694758683]
	TIME [epoch: 6.4 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1802236399645594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1802236399645594 | validation: 2.981352626730677]
	TIME [epoch: 6.42 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0045683493636197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0045683493636197 | validation: 2.987871727402535]
	TIME [epoch: 6.42 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9994254236814397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9994254236814397 | validation: 2.5988542300071122]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7453738469121203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7453738469121203 | validation: 2.9678256731134423]
	TIME [epoch: 6.4 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.784444990110899		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.784444990110899 | validation: 2.6940201465845046]
	TIME [epoch: 6.44 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5837230428713056		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.5837230428713056 | validation: 2.698669664621831]
	TIME [epoch: 6.41 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.485091926532019		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.485091926532019 | validation: 2.603843090592999]
	TIME [epoch: 6.39 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3756430129813126		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.3756430129813126 | validation: 2.338316025789761]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3195898505166266		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.3195898505166266 | validation: 1.962074119143942]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.324295271986863		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.324295271986863 | validation: 1.8874258287194436]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8108173100732259		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 1.8108173100732259 | validation: 2.4942793214917773]
	TIME [epoch: 6.45 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.462843844208925		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.462843844208925 | validation: 2.0840249455295567]
	TIME [epoch: 6.43 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9505596672594823		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 1.9505596672594823 | validation: 1.9498016690831947]
	TIME [epoch: 6.43 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2233791063848347		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.2233791063848347 | validation: 1.633558846771677]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_60.pth
	Model improved!!!
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6557298257436823		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.6557298257436823 | validation: 2.373609803297952]
	TIME [epoch: 6.52 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0732856284668086		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.0732856284668086 | validation: 1.587448542141122]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1284965295646225		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.1284965295646225 | validation: 1.700076715364174]
	TIME [epoch: 6.42 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8957951693335158		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.8957951693335158 | validation: 1.6453228966084936]
	TIME [epoch: 6.42 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.657973181839946		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.657973181839946 | validation: 2.121739996858839]
	TIME [epoch: 6.47 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8102466886123303		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 1.8102466886123303 | validation: 2.1311857544939765]
	TIME [epoch: 6.45 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8214149064456078		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.8214149064456078 | validation: 2.5540870436878085]
	TIME [epoch: 6.45 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0079870865024905		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.0079870865024905 | validation: 1.7927756630235039]
	TIME [epoch: 6.45 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9230519903162278		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.9230519903162278 | validation: 1.4822764369219958]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.790293271675135		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.790293271675135 | validation: 1.6726860909940455]
	TIME [epoch: 6.5 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7961740148026708		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.7961740148026708 | validation: 1.5030230096324608]
	TIME [epoch: 6.44 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6246778476174633		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.6246778476174633 | validation: 2.0366401019563853]
	TIME [epoch: 6.47 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.964108635486891		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.964108635486891 | validation: 1.6088203153103633]
	TIME [epoch: 6.44 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5437958749098202		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 1.5437958749098202 | validation: 2.870678061786446]
	TIME [epoch: 6.44 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0087592662912916		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.0087592662912916 | validation: 1.3917965437383328]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.78187795674809		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.78187795674809 | validation: 1.4802635765445487]
	TIME [epoch: 6.49 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3910916994298623		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.3910916994298623 | validation: 1.9888678679620964]
	TIME [epoch: 6.43 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8139385116195754		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.8139385116195754 | validation: 1.4193530191812742]
	TIME [epoch: 6.43 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5675219125340811		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.5675219125340811 | validation: 1.3869167575138144]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5107911811161046		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.5107911811161046 | validation: 1.9820015737675902]
	TIME [epoch: 6.51 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8430726176418333		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.8430726176418333 | validation: 2.256966071294455]
	TIME [epoch: 6.42 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8172777301915128		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.8172777301915128 | validation: 1.5229476420513368]
	TIME [epoch: 6.43 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.457924720774827		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.457924720774827 | validation: 1.4170449068795354]
	TIME [epoch: 6.44 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5587841463886614		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.5587841463886614 | validation: 1.3485532752181615]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3786160972250077		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.3786160972250077 | validation: 2.253521043659419]
	TIME [epoch: 6.43 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.630333080764774		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.630333080764774 | validation: 2.307569105238234]
	TIME [epoch: 6.44 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4987880587938078		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.4987880587938078 | validation: 1.393590392360017]
	TIME [epoch: 6.45 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2483499287451876		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.2483499287451876 | validation: 1.1730687861459845]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.518409209770725		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.518409209770725 | validation: 1.7670343001322188]
	TIME [epoch: 6.42 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.361269804915267		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.361269804915267 | validation: 1.2768788695448443]
	TIME [epoch: 6.44 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4404544118266767		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.4404544118266767 | validation: 1.098336306903423]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2564287506098064		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.2564287506098064 | validation: 0.9740781209655438]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.229112693201659		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.229112693201659 | validation: 1.4515026407418652]
	TIME [epoch: 6.44 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6358833081119473		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.6358833081119473 | validation: 1.0701675829495343]
	TIME [epoch: 6.43 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3149745474318977		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.3149745474318977 | validation: 1.5242717950044369]
	TIME [epoch: 6.41 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3193410340231664		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.3193410340231664 | validation: 1.6938660493003244]
	TIME [epoch: 6.41 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4917023539614505		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.4917023539614505 | validation: 1.6984327116057332]
	TIME [epoch: 6.41 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4004140128584193		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.4004140128584193 | validation: 1.017109133534315]
	TIME [epoch: 6.41 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1885149568306004		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.1885149568306004 | validation: 1.4827715801318515]
	TIME [epoch: 6.4 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4460013622056704		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.4460013622056704 | validation: 1.1508179736336144]
	TIME [epoch: 6.42 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3439816604274042		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.3439816604274042 | validation: 1.281306353814632]
	TIME [epoch: 6.43 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.398002675707923		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.398002675707923 | validation: 1.168093167270996]
	TIME [epoch: 6.41 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0590755537173775		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.0590755537173775 | validation: 1.4005568887621602]
	TIME [epoch: 6.41 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.318651553835139		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.318651553835139 | validation: 1.0559274102375098]
	TIME [epoch: 6.39 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.744632603576668		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.744632603576668 | validation: 1.3232593112024973]
	TIME [epoch: 6.42 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1844071348712344		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.1844071348712344 | validation: 3.273625139790606]
	TIME [epoch: 6.39 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9954455828247581		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.9954455828247581 | validation: 0.9274325863080701]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0672879262428268		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.0672879262428268 | validation: 1.0591768446301923]
	TIME [epoch: 6.43 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.223171830591287		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.223171830591287 | validation: 1.482058409714333]
	TIME [epoch: 6.4 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2621685957876831		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.2621685957876831 | validation: 1.9336577887004864]
	TIME [epoch: 6.41 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.293785494510991		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.293785494510991 | validation: 1.3934590907239905]
	TIME [epoch: 6.41 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3256433242749113		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.3256433242749113 | validation: 1.1384243095419408]
	TIME [epoch: 6.41 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0594982475624914		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.0594982475624914 | validation: 2.3412347683423516]
	TIME [epoch: 6.42 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4225452736553719		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.4225452736553719 | validation: 0.9726565547081788]
	TIME [epoch: 6.41 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.080079864910358		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.080079864910358 | validation: 1.0595367183934952]
	TIME [epoch: 6.45 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2912325308774848		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.2912325308774848 | validation: 1.1881703308914526]
	TIME [epoch: 6.42 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0935388736488563		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.0935388736488563 | validation: 0.8030125612994542]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8979117186926587		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 0.8979117186926587 | validation: 2.6780486765572773]
	TIME [epoch: 6.52 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.676176321041497		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.676176321041497 | validation: 1.0581959815798763]
	TIME [epoch: 6.42 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0700961063629486		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.0700961063629486 | validation: 1.245278098631331]
	TIME [epoch: 6.43 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3756403798815817		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.3756403798815817 | validation: 1.0025048718271858]
	TIME [epoch: 6.43 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2250059439668264		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.2250059439668264 | validation: 0.8720180132210834]
	TIME [epoch: 6.47 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.305900697161513		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.305900697161513 | validation: 1.0192610998779152]
	TIME [epoch: 6.44 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.17438886200726		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.17438886200726 | validation: 1.0993058492114895]
	TIME [epoch: 6.43 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2626545053337774		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.2626545053337774 | validation: 1.1724641150244741]
	TIME [epoch: 6.44 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.003349201117248		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.003349201117248 | validation: 1.2367820691112326]
	TIME [epoch: 6.45 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059173264857297		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.059173264857297 | validation: 1.1008846373892858]
	TIME [epoch: 6.44 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1216711219856084		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.1216711219856084 | validation: 1.102260794648007]
	TIME [epoch: 6.44 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9114219009652753		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.9114219009652753 | validation: 0.8524606655304473]
	TIME [epoch: 6.48 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2765235550557104		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 2.2765235550557104 | validation: 1.0973412497991029]
	TIME [epoch: 6.44 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0228788214287945		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.0228788214287945 | validation: 0.8561145084505429]
	TIME [epoch: 6.45 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8695534973697978		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.8695534973697978 | validation: 0.7649284504430661]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0497663097679417		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.0497663097679417 | validation: 0.678447538106015]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0484841298846654		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.0484841298846654 | validation: 0.8653697947635813]
	TIME [epoch: 6.5 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.976265952695887		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.976265952695887 | validation: 1.33357331167693]
	TIME [epoch: 6.43 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9806662812484737		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.9806662812484737 | validation: 1.1535117124661372]
	TIME [epoch: 6.47 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1357672657247562		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.1357672657247562 | validation: 1.6457398331299329]
	TIME [epoch: 6.46 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5309769985403583		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.5309769985403583 | validation: 0.7984943502318927]
	TIME [epoch: 6.45 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0088558222441115		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.0088558222441115 | validation: 0.802661627805147]
	TIME [epoch: 6.46 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1240876888263727		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.1240876888263727 | validation: 1.2764810139700786]
	TIME [epoch: 6.46 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0127966712989929		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.0127966712989929 | validation: 0.8090319972606312]
	TIME [epoch: 6.45 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2137575774487592		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.2137575774487592 | validation: 0.8641563462754165]
	TIME [epoch: 6.45 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0967362634642221		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.0967362634642221 | validation: 0.8049455126996873]
	TIME [epoch: 6.47 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8237591680122929		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.8237591680122929 | validation: 1.0994730122464629]
	TIME [epoch: 6.47 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8788372913120903		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.8788372913120903 | validation: 1.3133160248850198]
	TIME [epoch: 6.46 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9697567799580333		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.9697567799580333 | validation: 1.079669059243654]
	TIME [epoch: 6.45 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8973672047846627		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.8973672047846627 | validation: 1.502316555235425]
	TIME [epoch: 6.46 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0112841439692848		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.0112841439692848 | validation: 0.7103503076706317]
	TIME [epoch: 6.45 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0351021826581395		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.0351021826581395 | validation: 1.5757251760502415]
	TIME [epoch: 6.45 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3137339370730428		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.3137339370730428 | validation: 0.7484741801103857]
	TIME [epoch: 6.46 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8742307673252699		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.8742307673252699 | validation: 0.9743869432049107]
	TIME [epoch: 6.47 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9612393785516005		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.9612393785516005 | validation: 0.7675707271188063]
	TIME [epoch: 6.45 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9963506994746039		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.9963506994746039 | validation: 0.8048568278903637]
	TIME [epoch: 6.46 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.979352145199173		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.979352145199173 | validation: 0.7618439186113242]
	TIME [epoch: 6.45 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.013876821233682		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.013876821233682 | validation: 0.7922401942181461]
	TIME [epoch: 6.44 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9396149207274576		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.9396149207274576 | validation: 0.8754099345723151]
	TIME [epoch: 6.45 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8240178989413174		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.8240178989413174 | validation: 0.7483736143625066]
	TIME [epoch: 6.46 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.937180366796283		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.937180366796283 | validation: 0.8043682158821553]
	TIME [epoch: 6.48 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8759841607697622		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 0.8759841607697622 | validation: 0.7955558791686199]
	TIME [epoch: 6.46 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9939471709872811		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.9939471709872811 | validation: 1.1132675729995904]
	TIME [epoch: 6.44 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8213252984772607		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.8213252984772607 | validation: 0.6856977529847239]
	TIME [epoch: 6.45 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7823835472529931		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.7823835472529931 | validation: 1.4558225945979695]
	TIME [epoch: 6.45 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0951398095001563		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.0951398095001563 | validation: 0.9921190851853442]
	TIME [epoch: 6.44 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2088704747610906		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.2088704747610906 | validation: 1.04196772554442]
	TIME [epoch: 6.45 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0979774398682836		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.0979774398682836 | validation: 0.7428445905208619]
	TIME [epoch: 6.48 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8953937577582715		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.8953937577582715 | validation: 0.8493666095505791]
	TIME [epoch: 6.45 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8960878920286566		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.8960878920286566 | validation: 0.8867191872270539]
	TIME [epoch: 6.46 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8499571730745088		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.8499571730745088 | validation: 0.7392786535084566]
	TIME [epoch: 6.45 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.833693156053294		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.833693156053294 | validation: 0.7660365085771548]
	TIME [epoch: 6.45 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7956357952102288		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.7956357952102288 | validation: 0.9815807340107775]
	TIME [epoch: 6.45 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9114007165314972		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.9114007165314972 | validation: 0.8489560531169361]
	TIME [epoch: 6.45 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8312515555866091		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.8312515555866091 | validation: 0.9138266405228932]
	TIME [epoch: 6.48 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7516537698529021		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 0.7516537698529021 | validation: 0.8183498134693098]
	TIME [epoch: 6.47 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7654155845913831		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.7654155845913831 | validation: 0.6761237899742092]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_174.pth
	Model improved!!!
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7239830449841975		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.7239830449841975 | validation: 0.5405833555406834]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7909365673756146		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.7909365673756146 | validation: 0.7166786688295949]
	TIME [epoch: 6.5 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6738294737940822		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 0.6738294737940822 | validation: 0.674749002516212]
	TIME [epoch: 6.42 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7451348447168901		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.7451348447168901 | validation: 0.7116371255842104]
	TIME [epoch: 6.43 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6290285073434152		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.6290285073434152 | validation: 0.7257313204644703]
	TIME [epoch: 6.48 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6865211033910793		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.6865211033910793 | validation: 0.5327647310050834]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6269439042020415		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.6269439042020415 | validation: 0.8351503628350361]
	TIME [epoch: 6.51 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6706069453648811		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.6706069453648811 | validation: 0.811091599490876]
	TIME [epoch: 6.44 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7349195649272352		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.7349195649272352 | validation: 0.44492836345786074]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7222111226437637		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.7222111226437637 | validation: 1.0304963632458009]
	TIME [epoch: 6.45 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6967329711792819		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.6967329711792819 | validation: 0.5965507568319122]
	TIME [epoch: 6.46 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7841731109769832		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.7841731109769832 | validation: 0.6056726022284146]
	TIME [epoch: 6.49 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6282764195998438		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.6282764195998438 | validation: 0.9094993299539674]
	TIME [epoch: 6.46 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5913664036349334		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5913664036349334 | validation: 0.5426406165297987]
	TIME [epoch: 6.44 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6410531038727201		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.6410531038727201 | validation: 1.0221672706337044]
	TIME [epoch: 6.45 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8723404884899417		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.8723404884899417 | validation: 1.0058456501724446]
	TIME [epoch: 6.46 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8023173404987425		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.8023173404987425 | validation: 0.5639727972720696]
	TIME [epoch: 6.45 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7800718003869204		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.7800718003869204 | validation: 0.7286062058271574]
	TIME [epoch: 6.46 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5394805562788961		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.5394805562788961 | validation: 0.8852782789005529]
	TIME [epoch: 6.47 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.745251371357373		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.745251371357373 | validation: 0.677003139497995]
	TIME [epoch: 6.48 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6701510245387509		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.6701510245387509 | validation: 0.6013396052626849]
	TIME [epoch: 6.44 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6495945668850355		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.6495945668850355 | validation: 0.8566055770114227]
	TIME [epoch: 6.45 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6717833537649095		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.6717833537649095 | validation: 0.594774459191874]
	TIME [epoch: 6.45 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7250007414965877		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.7250007414965877 | validation: 1.014829500924505]
	TIME [epoch: 6.46 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8389601515490663		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.8389601515490663 | validation: 0.6631054713567746]
	TIME [epoch: 6.45 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6439840609800052		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.6439840609800052 | validation: 0.7024641122425044]
	TIME [epoch: 6.46 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8753532778966806		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.8753532778966806 | validation: 1.8992064521560235]
	TIME [epoch: 6.47 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1986918091874375		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 1.1986918091874375 | validation: 1.2468739449363577]
	TIME [epoch: 6.44 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8751684330573171		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.8751684330573171 | validation: 0.7618073004550472]
	TIME [epoch: 6.45 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6435730673180025		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.6435730673180025 | validation: 0.7456403188711711]
	TIME [epoch: 6.44 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6355975118005645		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.6355975118005645 | validation: 0.5496232928175033]
	TIME [epoch: 6.45 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5747179213189728		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.5747179213189728 | validation: 0.4587340820763355]
	TIME [epoch: 6.45 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5919223745162916		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.5919223745162916 | validation: 0.5659482691353862]
	TIME [epoch: 6.45 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6315043860123724		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.6315043860123724 | validation: 0.6006662494559335]
	TIME [epoch: 6.48 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6820231679938268		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.6820231679938268 | validation: 0.8331221690905756]
	TIME [epoch: 6.45 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6411260608391487		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.6411260608391487 | validation: 1.0010444532613567]
	TIME [epoch: 6.44 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7692346966443817		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.7692346966443817 | validation: 0.7384795176779962]
	TIME [epoch: 6.44 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8293776102399614		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.8293776102399614 | validation: 0.587143047824139]
	TIME [epoch: 6.44 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5417929177359128		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.5417929177359128 | validation: 0.5306543552987643]
	TIME [epoch: 6.45 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5396514188567071		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.5396514188567071 | validation: 0.6042146489326438]
	TIME [epoch: 6.45 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8563471709041568		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.8563471709041568 | validation: 0.5148209290852215]
	TIME [epoch: 6.48 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5913733702202626		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.5913733702202626 | validation: 0.44103952010291425]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5516238808913109		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.5516238808913109 | validation: 0.5151203032391966]
	TIME [epoch: 6.5 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5633271361337476		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.5633271361337476 | validation: 0.5984695085963465]
	TIME [epoch: 6.42 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579364841766302		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.5579364841766302 | validation: 0.6373551427674213]
	TIME [epoch: 6.43 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5649034095579982		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.5649034095579982 | validation: 0.5575034046367039]
	TIME [epoch: 6.44 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4437379730944599		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.4437379730944599 | validation: 0.49712567276729397]
	TIME [epoch: 6.44 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5250855938785006		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.5250855938785006 | validation: 0.4660344394223963]
	TIME [epoch: 6.49 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.65328983443418		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.65328983443418 | validation: 0.7336075626014075]
	TIME [epoch: 6.44 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.628251232233546		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.628251232233546 | validation: 0.6627499392515068]
	TIME [epoch: 6.46 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.550129328502406		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.550129328502406 | validation: 0.5099430451165714]
	TIME [epoch: 6.45 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7128249401580605		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.7128249401580605 | validation: 0.7466341847651188]
	TIME [epoch: 6.46 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5381310900778014		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.5381310900778014 | validation: 0.41214022114160964]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_227.pth
	Model improved!!!
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4827694217892955		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.4827694217892955 | validation: 0.5493988826418277]
	TIME [epoch: 6.53 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5398555615806783		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.5398555615806783 | validation: 0.6724607885776724]
	TIME [epoch: 6.48 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4965317102552642		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.4965317102552642 | validation: 0.39453115010796197]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.560523091948705		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.560523091948705 | validation: 0.7577190729585288]
	TIME [epoch: 6.53 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032301726754026		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 1.032301726754026 | validation: 0.5896783312996402]
	TIME [epoch: 6.45 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6790612169024983		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.6790612169024983 | validation: 0.6090168745728497]
	TIME [epoch: 6.45 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4823972149109829		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.4823972149109829 | validation: 0.4837739476757551]
	TIME [epoch: 6.47 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5109521450410255		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.5109521450410255 | validation: 1.7800591048898633]
	TIME [epoch: 6.47 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8554007459403683		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.8554007459403683 | validation: 0.6678216239618449]
	TIME [epoch: 6.49 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.497668523153537		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.497668523153537 | validation: 0.47373219954091284]
	TIME [epoch: 6.48 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.475977047729698		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.475977047729698 | validation: 0.5120807926448715]
	TIME [epoch: 6.45 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44487486735581794		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.44487486735581794 | validation: 0.3220096318506458]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_239.pth
	Model improved!!!
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5155344975362967		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.5155344975362967 | validation: 0.43193181964330285]
	TIME [epoch: 6.51 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3548436170784045		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.3548436170784045 | validation: 0.5027871493902228]
	TIME [epoch: 6.43 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3860428264785088		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.3860428264785088 | validation: 0.9347522173050103]
	TIME [epoch: 6.43 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5144878667312348		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.5144878667312348 | validation: 0.25293508743319054]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3297839827350848		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.3297839827350848 | validation: 0.3127074170221447]
	TIME [epoch: 6.51 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3879632175575498		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.3879632175575498 | validation: 0.3292942293569138]
	TIME [epoch: 6.41 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48173445658102376		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.48173445658102376 | validation: 0.29448079509920533]
	TIME [epoch: 6.4 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6798744632805236		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.6798744632805236 | validation: 0.4366094177771434]
	TIME [epoch: 6.41 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4548445019356044		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.4548445019356044 | validation: 0.40890008380353754]
	TIME [epoch: 6.42 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7711165170595659		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7711165170595659 | validation: 0.48470316370980115]
	TIME [epoch: 6.41 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5569401132482046		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.5569401132482046 | validation: 0.5375349607170459]
	TIME [epoch: 6.44 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45628616269903377		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.45628616269903377 | validation: 0.4472553556391583]
	TIME [epoch: 6.42 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5632336180368078		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.5632336180368078 | validation: 0.3407380250660635]
	TIME [epoch: 6.42 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4378949618449841		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.4378949618449841 | validation: 0.30504987737450223]
	TIME [epoch: 6.43 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4638178093865546		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.4638178093865546 | validation: 0.4444379312908429]
	TIME [epoch: 6.43 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40754754349776684		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.40754754349776684 | validation: 0.3547814327473048]
	TIME [epoch: 6.43 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49023382220049017		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.49023382220049017 | validation: 1.184818068349336]
	TIME [epoch: 6.43 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7593040643054283		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.7593040643054283 | validation: 0.5051795202405613]
	TIME [epoch: 6.44 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4210614081749438		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.4210614081749438 | validation: 0.48250083750150796]
	TIME [epoch: 6.45 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42646705766976367		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.42646705766976367 | validation: 0.4877846167972441]
	TIME [epoch: 6.43 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47002255922845126		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.47002255922845126 | validation: 0.3104197724907142]
	TIME [epoch: 6.43 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4120776020070983		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.4120776020070983 | validation: 0.9664580158286148]
	TIME [epoch: 6.44 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6289264720309738		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.6289264720309738 | validation: 0.5536584260727494]
	TIME [epoch: 6.43 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5429965956042089		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.5429965956042089 | validation: 0.541371017743692]
	TIME [epoch: 6.43 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6075929938382053		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.6075929938382053 | validation: 0.4659733826897546]
	TIME [epoch: 6.44 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3869599672386625		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.3869599672386625 | validation: 0.4497325122995314]
	TIME [epoch: 6.47 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48917679186515584		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.48917679186515584 | validation: 0.3362703683012696]
	TIME [epoch: 6.43 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41979349541379385		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.41979349541379385 | validation: 0.7278392620753025]
	TIME [epoch: 6.43 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43355240872281686		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.43355240872281686 | validation: 0.2952584802070581]
	TIME [epoch: 6.43 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3760726096786135		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.3760726096786135 | validation: 0.33258578852190085]
	TIME [epoch: 6.43 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4845453674051746		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.4845453674051746 | validation: 0.7701406784881485]
	TIME [epoch: 6.44 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4628234746399535		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.4628234746399535 | validation: 0.6024431072685286]
	TIME [epoch: 6.44 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3759293667814557		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.3759293667814557 | validation: 0.4621498652958391]
	TIME [epoch: 6.47 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39230164662485556		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.39230164662485556 | validation: 0.3111653211580404]
	TIME [epoch: 6.44 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36179129305927593		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.36179129305927593 | validation: 0.4000094132533306]
	TIME [epoch: 6.44 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4650991314626559		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.4650991314626559 | validation: 0.7437498519918506]
	TIME [epoch: 6.44 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5195149671795166		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5195149671795166 | validation: 0.3268051243581195]
	TIME [epoch: 6.43 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41916801389376657		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.41916801389376657 | validation: 0.6052160332410921]
	TIME [epoch: 6.44 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4049098092457085		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.4049098092457085 | validation: 0.21697930636886853]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992685977342239		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.3992685977342239 | validation: 0.37225660429284185]
	TIME [epoch: 6.55 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.428816594437869		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.428816594437869 | validation: 0.44528871390500047]
	TIME [epoch: 6.44 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37885570393125134		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.37885570393125134 | validation: 0.38090422210302877]
	TIME [epoch: 6.44 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35516870015418495		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.35516870015418495 | validation: 0.31118262626965026]
	TIME [epoch: 6.44 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2940705840743852		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.2940705840743852 | validation: 0.23440924165230237]
	TIME [epoch: 6.44 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35283933433273434		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.35283933433273434 | validation: 0.5416493144668613]
	TIME [epoch: 6.44 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39213557137422156		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.39213557137422156 | validation: 0.4967009910456923]
	TIME [epoch: 6.44 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3744971157329019		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.3744971157329019 | validation: 0.45268086177203104]
	TIME [epoch: 6.47 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36401478510621366		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.36401478510621366 | validation: 0.24840343999798378]
	TIME [epoch: 6.44 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4163922002034041		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.4163922002034041 | validation: 0.45145148015386627]
	TIME [epoch: 6.44 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4656948197411424		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.4656948197411424 | validation: 0.39055656715123915]
	TIME [epoch: 6.43 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4923980271195961		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.4923980271195961 | validation: 0.2338849171592527]
	TIME [epoch: 6.44 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2802992847053196		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.2802992847053196 | validation: 0.30447588273329745]
	TIME [epoch: 6.45 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42065046459734895		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.42065046459734895 | validation: 0.22168919294384395]
	TIME [epoch: 6.44 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.412878306986885		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.412878306986885 | validation: 0.40120749883060397]
	TIME [epoch: 6.46 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37807843109263367		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.37807843109263367 | validation: 0.2198971598333044]
	TIME [epoch: 6.45 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29110911317598676		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.29110911317598676 | validation: 0.4798876781548707]
	TIME [epoch: 6.44 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3444460452944894		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.3444460452944894 | validation: 0.6536384235055673]
	TIME [epoch: 6.44 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7055813586267972		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.7055813586267972 | validation: 0.8632837624939302]
	TIME [epoch: 6.44 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6085424334637439		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.6085424334637439 | validation: 0.3379628703913579]
	TIME [epoch: 6.44 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3773025805041744		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.3773025805041744 | validation: 0.4875297062582804]
	TIME [epoch: 6.44 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43385274576779476		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.43385274576779476 | validation: 0.20990757714887487]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_300.pth
	Model improved!!!
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29353334058286584		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.29353334058286584 | validation: 0.2442425542586866]
	TIME [epoch: 6.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692998404511417		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.3692998404511417 | validation: 0.19471984335344594]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_302.pth
	Model improved!!!
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3630423618584237		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.3630423618584237 | validation: 0.5089786534971175]
	TIME [epoch: 6.5 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.359609092937446		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.359609092937446 | validation: 0.32141143401916017]
	TIME [epoch: 6.41 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49257893506883477		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.49257893506883477 | validation: 0.47251044137611353]
	TIME [epoch: 6.41 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38101750341140045		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.38101750341140045 | validation: 0.6623840285978884]
	TIME [epoch: 6.41 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5617108973363344		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.5617108973363344 | validation: 0.4759170801442116]
	TIME [epoch: 6.43 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4645060923184514		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.4645060923184514 | validation: 0.36930985547725814]
	TIME [epoch: 6.44 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44762181591683486		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.44762181591683486 | validation: 0.4147903034802992]
	TIME [epoch: 6.42 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34093641012249504		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.34093641012249504 | validation: 0.37615668542854946]
	TIME [epoch: 6.43 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36116079999289		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.36116079999289 | validation: 0.21839382356493894]
	TIME [epoch: 6.42 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.481800885220547		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.481800885220547 | validation: 0.349179260233294]
	TIME [epoch: 6.42 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36678268180261153		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.36678268180261153 | validation: 0.4938198326575055]
	TIME [epoch: 6.42 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3932023727255638		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.3932023727255638 | validation: 0.577231044321001]
	TIME [epoch: 6.42 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4041056550486273		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.4041056550486273 | validation: 0.295104073282858]
	TIME [epoch: 6.45 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2839550691885222		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.2839550691885222 | validation: 0.3053873882689846]
	TIME [epoch: 6.43 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32253564046178285		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.32253564046178285 | validation: 0.632044913966899]
	TIME [epoch: 6.43 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4798746762312054		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.4798746762312054 | validation: 0.36387324941363847]
	TIME [epoch: 6.43 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3886628633751346		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.3886628633751346 | validation: 0.38920637599086166]
	TIME [epoch: 6.43 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4173840866374558		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.4173840866374558 | validation: 0.3927645370804019]
	TIME [epoch: 6.44 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3677007221523978		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.3677007221523978 | validation: 0.36211526585113873]
	TIME [epoch: 6.44 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42823531838640216		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.42823531838640216 | validation: 0.4302795693818962]
	TIME [epoch: 6.47 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30820510224870057		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.30820510224870057 | validation: 0.3868436023029104]
	TIME [epoch: 6.45 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30390779547976726		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.30390779547976726 | validation: 0.24904737897356094]
	TIME [epoch: 6.44 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31184931801556803		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.31184931801556803 | validation: 0.28984182126129954]
	TIME [epoch: 6.44 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3234887049823184		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.3234887049823184 | validation: 0.44916423846073505]
	TIME [epoch: 6.44 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4431572849572274		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.4431572849572274 | validation: 0.37792407845372966]
	TIME [epoch: 6.44 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215405449024979		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.3215405449024979 | validation: 0.645769616414213]
	TIME [epoch: 6.44 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3927103740110934		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.3927103740110934 | validation: 0.20427401641758244]
	TIME [epoch: 6.47 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3876783572126784		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.3876783572126784 | validation: 0.2976161749031402]
	TIME [epoch: 6.45 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24395560850726528		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.24395560850726528 | validation: 0.387028021747267]
	TIME [epoch: 6.44 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6008901685685628		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.6008901685685628 | validation: 0.2945139675205434]
	TIME [epoch: 6.44 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2726942110513875		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.2726942110513875 | validation: 0.2287981196408178]
	TIME [epoch: 6.45 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31316552938523545		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.31316552938523545 | validation: 0.3038295843974522]
	TIME [epoch: 6.45 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38740298911544263		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.38740298911544263 | validation: 0.5105936213484226]
	TIME [epoch: 6.44 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30607497941567047		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.30607497941567047 | validation: 0.19872124555047344]
	TIME [epoch: 6.47 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2801964234142659		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.2801964234142659 | validation: 0.17859211954293958]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_337.pth
	Model improved!!!
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2517340794010321		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.2517340794010321 | validation: 0.16182497349984368]
	TIME [epoch: 6.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2498855057464096		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.2498855057464096 | validation: 0.3060575064282922]
	TIME [epoch: 6.49 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31603112762218755		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.31603112762218755 | validation: 0.3929512866855863]
	TIME [epoch: 6.42 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37204822863597053		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.37204822863597053 | validation: 0.3679366180963755]
	TIME [epoch: 6.43 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.304578455964743		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.304578455964743 | validation: 0.2397038245460746]
	TIME [epoch: 6.44 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34663812872615135		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.34663812872615135 | validation: 0.3436110921439435]
	TIME [epoch: 6.46 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3381051656282022		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.3381051656282022 | validation: 0.43826657715429235]
	TIME [epoch: 6.46 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060808026855446		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.4060808026855446 | validation: 0.35755515515466074]
	TIME [epoch: 6.45 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39959775427655886		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.39959775427655886 | validation: 0.3044059821229276]
	TIME [epoch: 6.45 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2736565646111547		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.2736565646111547 | validation: 0.20809020013394686]
	TIME [epoch: 6.45 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27771106164916143		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.27771106164916143 | validation: 0.30211732798703445]
	TIME [epoch: 6.45 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29486641881631076		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.29486641881631076 | validation: 0.3199550676593729]
	TIME [epoch: 6.46 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2365935994248216		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.2365935994248216 | validation: 0.23003941011274692]
	TIME [epoch: 6.47 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22952274965072103		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.22952274965072103 | validation: 0.18571869569351854]
	TIME [epoch: 6.47 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2935973139694704		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.2935973139694704 | validation: 0.2313876957195249]
	TIME [epoch: 6.45 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31154148531871256		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.31154148531871256 | validation: 0.21775667511342497]
	TIME [epoch: 6.45 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22904051345581697		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.22904051345581697 | validation: 0.1600038418414973]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_354.pth
	Model improved!!!
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274113554169138		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.274113554169138 | validation: 0.3422781634132079]
	TIME [epoch: 6.44 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22266536423278788		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.22266536423278788 | validation: 0.27363755439039295]
	TIME [epoch: 6.44 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2814904164182648		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.2814904164182648 | validation: 0.21743253216943373]
	TIME [epoch: 6.47 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24096697361617675		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.24096697361617675 | validation: 0.22892142676673416]
	TIME [epoch: 6.47 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2344566574417387		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.2344566574417387 | validation: 0.23751854437292794]
	TIME [epoch: 6.46 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3960378597785038		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.3960378597785038 | validation: 0.18939266798348775]
	TIME [epoch: 6.45 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26527122911634626		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.26527122911634626 | validation: 0.14373535388246478]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_361.pth
	Model improved!!!
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18026483747565702		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.18026483747565702 | validation: 0.22719081570006905]
	TIME [epoch: 6.54 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31218861341576065		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.31218861341576065 | validation: 0.17036963093686253]
	TIME [epoch: 6.42 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2570177757553625		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.2570177757553625 | validation: 0.3098506041518817]
	TIME [epoch: 6.44 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29752196472883424		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.29752196472883424 | validation: 0.19430585475124212]
	TIME [epoch: 6.48 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2619798023888059		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.2619798023888059 | validation: 0.5921532704161073]
	TIME [epoch: 6.44 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4253154304429121		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.4253154304429121 | validation: 0.2796916411541219]
	TIME [epoch: 6.44 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34241200974025576		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.34241200974025576 | validation: 0.4373488628225893]
	TIME [epoch: 6.44 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3101109190138025		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.3101109190138025 | validation: 0.21126891547023563]
	TIME [epoch: 6.44 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23796978450776113		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.23796978450776113 | validation: 0.21512055728336574]
	TIME [epoch: 6.44 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2442226886948261		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.2442226886948261 | validation: 0.22331213593079732]
	TIME [epoch: 6.44 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2666001498158951		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.2666001498158951 | validation: 0.2246937210172912]
	TIME [epoch: 6.47 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2587507550902085		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.2587507550902085 | validation: 0.13043843870086844]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21968449310597857		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.21968449310597857 | validation: 0.18196103740388075]
	TIME [epoch: 6.51 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19162916054945126		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.19162916054945126 | validation: 0.20608572466431463]
	TIME [epoch: 6.43 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25256123137685893		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.25256123137685893 | validation: 0.22661153442764737]
	TIME [epoch: 6.44 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20921855832629238		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.20921855832629238 | validation: 0.36491113966478084]
	TIME [epoch: 6.43 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41292296415886043		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.41292296415886043 | validation: 0.13020562811711014]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_378.pth
	Model improved!!!
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3173325860932561		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.3173325860932561 | validation: 0.27625315498585545]
	TIME [epoch: 6.56 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42831217921303727		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.42831217921303727 | validation: 0.4462493718837591]
	TIME [epoch: 6.41 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27750209941089704		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.27750209941089704 | validation: 0.35123224222844757]
	TIME [epoch: 6.43 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38425932535085056		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.38425932535085056 | validation: 0.723977869955072]
	TIME [epoch: 6.43 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46349295175525007		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.46349295175525007 | validation: 0.34871358868125235]
	TIME [epoch: 6.43 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30830618917852737		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.30830618917852737 | validation: 0.31965067674629793]
	TIME [epoch: 6.45 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2182015866593093		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.2182015866593093 | validation: 0.1663378421600452]
	TIME [epoch: 6.45 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2305694534498278		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.2305694534498278 | validation: 0.2901165053831322]
	TIME [epoch: 6.49 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.264758481231376		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.264758481231376 | validation: 0.23322662134624952]
	TIME [epoch: 6.46 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24052952225854968		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.24052952225854968 | validation: 0.24755129933527228]
	TIME [epoch: 6.45 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2598023041196338		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.2598023041196338 | validation: 0.29674083871059764]
	TIME [epoch: 6.46 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2923357943784307		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.2923357943784307 | validation: 0.18141809298970096]
	TIME [epoch: 6.46 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21588140337018066		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.21588140337018066 | validation: 0.36732053164897616]
	TIME [epoch: 6.46 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2945928297793469		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.2945928297793469 | validation: 0.328520986575628]
	TIME [epoch: 6.45 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33146896644704016		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.33146896644704016 | validation: 0.2287924720785197]
	TIME [epoch: 6.49 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2527477235462777		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.2527477235462777 | validation: 0.1511331005662707]
	TIME [epoch: 6.47 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18670715745249208		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.18670715745249208 | validation: 0.2106202209439431]
	TIME [epoch: 6.46 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23245303617178129		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.23245303617178129 | validation: 0.24567349633895497]
	TIME [epoch: 6.46 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.267338488772435		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.267338488772435 | validation: 0.22458373023962933]
	TIME [epoch: 6.46 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22907094026189034		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.22907094026189034 | validation: 0.22995632601757016]
	TIME [epoch: 6.47 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17638767916911058		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.17638767916911058 | validation: 0.2005883785296505]
	TIME [epoch: 6.45 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23892743139041164		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.23892743139041164 | validation: 0.5716096237105857]
	TIME [epoch: 6.48 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.383041700119689		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.383041700119689 | validation: 0.20351264618581583]
	TIME [epoch: 6.49 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18287256650592892		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.18287256650592892 | validation: 0.2385906104867966]
	TIME [epoch: 6.45 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3093625900383034		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.3093625900383034 | validation: 0.16151397623849031]
	TIME [epoch: 6.46 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2812942011591547		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.2812942011591547 | validation: 0.40627192032825377]
	TIME [epoch: 6.45 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37387933624862424		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.37387933624862424 | validation: 0.2630858447969494]
	TIME [epoch: 6.45 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2635258197518747		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.2635258197518747 | validation: 0.12909105931972698]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_406.pth
	Model improved!!!
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1724474110392022		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.1724474110392022 | validation: 0.32073427785776765]
	TIME [epoch: 6.53 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23481931853873328		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.23481931853873328 | validation: 0.27427059339907534]
	TIME [epoch: 6.43 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32473134566525386		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.32473134566525386 | validation: 0.39267197851045765]
	TIME [epoch: 6.42 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3432239467768045		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.3432239467768045 | validation: 0.2698069530745194]
	TIME [epoch: 6.43 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26277647376101587		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.26277647376101587 | validation: 0.42321182619926306]
	TIME [epoch: 6.43 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33121333440614553		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.33121333440614553 | validation: 0.14592453374948203]
	TIME [epoch: 6.43 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21538978690754645		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.21538978690754645 | validation: 0.20319618406609063]
	TIME [epoch: 6.44 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18324941298868713		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.18324941298868713 | validation: 0.20375008651165705]
	TIME [epoch: 6.46 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2012618191314721		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.2012618191314721 | validation: 0.2404253743944612]
	TIME [epoch: 6.47 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790390533654732		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.2790390533654732 | validation: 0.3104425037779136]
	TIME [epoch: 6.45 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27114001413353855		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.27114001413353855 | validation: 0.2902014302182577]
	TIME [epoch: 6.44 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23646879173242408		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.23646879173242408 | validation: 0.4900186118042592]
	TIME [epoch: 6.45 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26845509278754964		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.26845509278754964 | validation: 0.17996239906566955]
	TIME [epoch: 6.45 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26771227358973226		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.26771227358973226 | validation: 0.19181079574890006]
	TIME [epoch: 6.45 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18096787752339827		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.18096787752339827 | validation: 0.17510756648910658]
	TIME [epoch: 6.46 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19175707249189036		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.19175707249189036 | validation: 0.2985992882498394]
	TIME [epoch: 6.49 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2298614209726231		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.2298614209726231 | validation: 0.1037574782185526]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_423.pth
	Model improved!!!
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1620132162205964		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.1620132162205964 | validation: 0.25740515032875927]
	TIME [epoch: 6.5 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2741056829091479		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.2741056829091479 | validation: 0.24367182393565678]
	TIME [epoch: 6.44 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22291875023265134		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.22291875023265134 | validation: 0.28190769229603324]
	TIME [epoch: 6.44 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22576700096658434		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.22576700096658434 | validation: 0.1916019014541169]
	TIME [epoch: 6.44 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21580981426466872		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.21580981426466872 | validation: 0.30574972227876723]
	TIME [epoch: 6.45 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32013864219645716		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.32013864219645716 | validation: 0.18400163978528888]
	TIME [epoch: 6.47 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22466252723741775		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.22466252723741775 | validation: 0.20728914574866175]
	TIME [epoch: 6.45 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2423647343173564		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.2423647343173564 | validation: 0.26108422628415506]
	TIME [epoch: 6.44 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2743400203114755		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.2743400203114755 | validation: 0.12477619432569598]
	TIME [epoch: 6.44 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18385641177529682		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.18385641177529682 | validation: 0.22745571712831086]
	TIME [epoch: 6.44 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2066796435294063		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.2066796435294063 | validation: 0.26475747652099296]
	TIME [epoch: 6.44 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25925637518435335		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.25925637518435335 | validation: 0.2790900738718174]
	TIME [epoch: 6.44 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16379708816411442		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.16379708816411442 | validation: 0.1625835999435946]
	TIME [epoch: 6.48 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1501435055961106		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.1501435055961106 | validation: 0.24694783831885164]
	TIME [epoch: 6.45 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15572705193845088		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.15572705193845088 | validation: 0.5772011884316078]
	TIME [epoch: 6.44 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502074924105544		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.2502074924105544 | validation: 0.1712387503965919]
	TIME [epoch: 6.44 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18270355135450597		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.18270355135450597 | validation: 0.34108085381364744]
	TIME [epoch: 6.45 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21602696505300478		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.21602696505300478 | validation: 0.1614939727084935]
	TIME [epoch: 6.44 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2410866039555289		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.2410866039555289 | validation: 0.2460054791307617]
	TIME [epoch: 6.44 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23243358853328677		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.23243358853328677 | validation: 0.13544102182368925]
	TIME [epoch: 6.47 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.184679107638896		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.184679107638896 | validation: 0.09575964769065981]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_444.pth
	Model improved!!!
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20702170608784007		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.20702170608784007 | validation: 0.08196942137183238]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13211682180153322		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.13211682180153322 | validation: 0.24671512062037415]
	TIME [epoch: 6.41 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1944650016879268		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.1944650016879268 | validation: 0.17259230099167577]
	TIME [epoch: 6.42 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18580887819179842		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.18580887819179842 | validation: 0.24963067631891755]
	TIME [epoch: 6.41 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18749045227568886		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.18749045227568886 | validation: 0.21718179324877335]
	TIME [epoch: 6.42 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21404331071701846		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.21404331071701846 | validation: 0.13889312543113072]
	TIME [epoch: 6.45 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17381860681508293		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.17381860681508293 | validation: 0.1290103447561929]
	TIME [epoch: 6.43 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23794138695517708		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.23794138695517708 | validation: 0.14470406739201724]
	TIME [epoch: 6.43 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13853507091809347		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.13853507091809347 | validation: 0.0964543111150786]
	TIME [epoch: 6.44 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16196842367468473		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.16196842367468473 | validation: 0.12390604954700639]
	TIME [epoch: 6.44 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16435114337857964		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.16435114337857964 | validation: 0.13028912286133693]
	TIME [epoch: 6.43 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876744652077273		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.2876744652077273 | validation: 0.24716176952803884]
	TIME [epoch: 6.43 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17700097079659327		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.17700097079659327 | validation: 0.19247083031730344]
	TIME [epoch: 6.45 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14327569986933666		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.14327569986933666 | validation: 0.16399090938266178]
	TIME [epoch: 6.45 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1693224971301661		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.1693224971301661 | validation: 0.14387117583110487]
	TIME [epoch: 6.44 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16654357273997503		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.16654357273997503 | validation: 0.49431868401607476]
	TIME [epoch: 6.44 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25508130341269375		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.25508130341269375 | validation: 0.09915090147089814]
	TIME [epoch: 6.43 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16573871029201653		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.16573871029201653 | validation: 0.15634517009211796]
	TIME [epoch: 6.43 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2881742014695408		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.2881742014695408 | validation: 0.16681667099135955]
	TIME [epoch: 6.45 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20655286016453434		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.20655286016453434 | validation: 0.14238679221055175]
	TIME [epoch: 6.46 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23149718615180856		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.23149718615180856 | validation: 0.12733322543108408]
	TIME [epoch: 6.46 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16432892272711758		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.16432892272711758 | validation: 0.320929703878458]
	TIME [epoch: 6.45 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16800579615009606		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.16800579615009606 | validation: 0.18883686842835098]
	TIME [epoch: 6.44 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16341783395348247		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.16341783395348247 | validation: 0.17675374379465947]
	TIME [epoch: 6.44 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1692652270821085		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.1692652270821085 | validation: 0.1545194853516665]
	TIME [epoch: 6.44 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16224390984539372		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.16224390984539372 | validation: 0.14455352082764453]
	TIME [epoch: 6.44 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18299108332703057		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.18299108332703057 | validation: 0.2757686068298845]
	TIME [epoch: 6.44 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18263303505298767		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.18263303505298767 | validation: 0.13999138857381624]
	TIME [epoch: 6.47 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21723873154586631		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.21723873154586631 | validation: 0.1823312856189986]
	TIME [epoch: 6.44 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2235508303844557		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.2235508303844557 | validation: 0.15727964310301737]
	TIME [epoch: 6.44 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15930584153153965		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.15930584153153965 | validation: 0.11556061845340083]
	TIME [epoch: 6.44 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15524810483003165		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.15524810483003165 | validation: 0.20519050698785946]
	TIME [epoch: 6.44 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2045667333315516		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.2045667333315516 | validation: 0.3700982206813197]
	TIME [epoch: 6.44 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.206672673758154		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.206672673758154 | validation: 0.10275781555591743]
	TIME [epoch: 6.46 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1424101509406203		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.1424101509406203 | validation: 0.22681655723187355]
	TIME [epoch: 6.49 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19261862352339523		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.19261862352339523 | validation: 0.1818981969734487]
	TIME [epoch: 6.45 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16245474545347965		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.16245474545347965 | validation: 0.3128309689778384]
	TIME [epoch: 6.44 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18979490859656079		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.18979490859656079 | validation: 0.4732280651429373]
	TIME [epoch: 6.44 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28340881056484246		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.28340881056484246 | validation: 0.13936061710861064]
	TIME [epoch: 6.44 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1415994736241838		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.1415994736241838 | validation: 0.15471068726712336]
	TIME [epoch: 6.44 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1355675218571924		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.1355675218571924 | validation: 0.2270367408237699]
	TIME [epoch: 6.44 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21209028707503685		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.21209028707503685 | validation: 0.46061248476231875]
	TIME [epoch: 6.47 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3041240687358423		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.3041240687358423 | validation: 0.24973010664004072]
	TIME [epoch: 6.45 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14196751816576547		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.14196751816576547 | validation: 0.17255102894945581]
	TIME [epoch: 6.46 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542019597429602		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.1542019597429602 | validation: 0.1627941466681753]
	TIME [epoch: 6.45 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12491367424958688		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.12491367424958688 | validation: 0.14989303597216314]
	TIME [epoch: 6.46 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20559465353266904		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.20559465353266904 | validation: 0.12828229244026168]
	TIME [epoch: 6.46 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1761460694932408		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.1761460694932408 | validation: 0.21351871989670074]
	TIME [epoch: 6.46 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23939416876336378		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.23939416876336378 | validation: 0.08635252627500851]
	TIME [epoch: 6.46 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10578869061401788		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.10578869061401788 | validation: 0.11331379364630279]
	TIME [epoch: 6.5 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19472418292995966		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.19472418292995966 | validation: 0.27665366712122547]
	TIME [epoch: 6.45 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21922453161348351		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.21922453161348351 | validation: 0.2117236216877734]
	TIME [epoch: 6.46 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13607144662283058		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.13607144662283058 | validation: 0.15805019970595433]
	TIME [epoch: 6.45 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1553832236759448		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.1553832236759448 | validation: 0.08167953397358865]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_498.pth
	Model improved!!!
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15618549348566993		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.15618549348566993 | validation: 0.39703151243080753]
	TIME [epoch: 6.44 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3483204888183512		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.3483204888183512 | validation: 0.20958663421044804]
	TIME [epoch: 6.47 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13996679174253673		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.13996679174253673 | validation: 0.09943149890792594]
	TIME [epoch: 6.48 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12439703102789883		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.12439703102789883 | validation: 0.1118198589475994]
	TIME [epoch: 6.45 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12449002086408306		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.12449002086408306 | validation: 0.10535532813107328]
	TIME [epoch: 6.45 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12246120159248738		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.12246120159248738 | validation: 0.1374852343168646]
	TIME [epoch: 6.47 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11953688856056621		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.11953688856056621 | validation: 0.09562371209354627]
	TIME [epoch: 6.46 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12557815371015885		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.12557815371015885 | validation: 0.26371023402654215]
	TIME [epoch: 6.46 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1320273582637078		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.1320273582637078 | validation: 0.0901987529932925]
	TIME [epoch: 6.48 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13915047816677384		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.13915047816677384 | validation: 0.057919555152602865]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_508.pth
	Model improved!!!
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19551596560334578		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.19551596560334578 | validation: 0.43125620169946205]
	TIME [epoch: 6.51 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24625488334146414		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.24625488334146414 | validation: 0.17726764639465256]
	TIME [epoch: 6.42 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15069474105515374		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.15069474105515374 | validation: 0.2539648877963831]
	TIME [epoch: 6.43 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19994177550704237		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.19994177550704237 | validation: 0.23602040752427667]
	TIME [epoch: 6.42 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1625587472321808		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.1625587472321808 | validation: 0.15069219181920565]
	TIME [epoch: 6.44 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15366553683663844		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.15366553683663844 | validation: 0.19744387192724744]
	TIME [epoch: 6.44 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14577498723318263		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.14577498723318263 | validation: 0.20119000621876418]
	TIME [epoch: 6.47 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1503173393863372		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.1503173393863372 | validation: 0.14229896205949571]
	TIME [epoch: 6.44 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13869677594222368		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.13869677594222368 | validation: 0.19267254320652036]
	TIME [epoch: 6.44 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17233566554851065		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.17233566554851065 | validation: 0.08973631404239017]
	TIME [epoch: 6.44 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12345795378208743		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.12345795378208743 | validation: 0.10963864944252688]
	TIME [epoch: 6.45 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18626523589969574		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.18626523589969574 | validation: 0.22021569318385317]
	TIME [epoch: 6.45 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28656711887540276		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.28656711887540276 | validation: 0.2434443434410249]
	TIME [epoch: 6.46 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2130030938630612		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.2130030938630612 | validation: 0.24220171261507883]
	TIME [epoch: 6.48 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17265676950486572		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.17265676950486572 | validation: 0.11649880796793934]
	TIME [epoch: 6.45 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432507619684817		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.1432507619684817 | validation: 0.15877520647612878]
	TIME [epoch: 6.45 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14215156757002823		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.14215156757002823 | validation: 0.21648313056250756]
	TIME [epoch: 6.45 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17128400498560703		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.17128400498560703 | validation: 0.0701972088604656]
	TIME [epoch: 6.45 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1239304456531157		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.1239304456531157 | validation: 0.29135172643244417]
	TIME [epoch: 6.46 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19398431367530475		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.19398431367530475 | validation: 0.13626614042389049]
	TIME [epoch: 6.45 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13040630696192743		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.13040630696192743 | validation: 0.20412621511989187]
	TIME [epoch: 6.48 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1798762377015191		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.1798762377015191 | validation: 0.19276042293493448]
	TIME [epoch: 6.46 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20861669139330108		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.20861669139330108 | validation: 0.2512359254597758]
	TIME [epoch: 6.45 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2611291019660769		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.2611291019660769 | validation: 0.23418517850552018]
	TIME [epoch: 6.46 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2748546116834289		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.2748546116834289 | validation: 0.1165065741715592]
	TIME [epoch: 6.45 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13435321362664623		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.13435321362664623 | validation: 0.124722448087823]
	TIME [epoch: 6.46 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16126682212683707		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.16126682212683707 | validation: 0.20804060227474566]
	TIME [epoch: 6.46 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13333471315766143		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.13333471315766143 | validation: 0.14517572823803981]
	TIME [epoch: 6.49 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16015455510375348		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.16015455510375348 | validation: 0.13248385384755945]
	TIME [epoch: 6.46 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1466557349972611		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.1466557349972611 | validation: 0.15418211725362294]
	TIME [epoch: 6.45 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15663652385608404		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.15663652385608404 | validation: 0.1444988096171734]
	TIME [epoch: 6.46 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1638068582702699		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.1638068582702699 | validation: 0.2332185370106005]
	TIME [epoch: 6.45 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19235792611822788		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.19235792611822788 | validation: 0.13328215824899795]
	TIME [epoch: 6.44 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1458936528631746		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.1458936528631746 | validation: 0.11018182384385401]
	TIME [epoch: 6.46 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17778275324904672		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.17778275324904672 | validation: 0.19563387598738868]
	TIME [epoch: 6.47 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1845994578681301		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.1845994578681301 | validation: 0.24915869895717577]
	TIME [epoch: 6.48 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17854971057099078		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.17854971057099078 | validation: 0.2187543852265437]
	TIME [epoch: 6.46 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29341379571497417		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.29341379571497417 | validation: 0.23301385065132096]
	TIME [epoch: 6.45 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1854706562525415		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.1854706562525415 | validation: 0.2067186935157503]
	TIME [epoch: 6.45 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2218768851556824		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.2218768851556824 | validation: 0.2387248936703708]
	TIME [epoch: 6.45 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17407367191291628		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.17407367191291628 | validation: 0.15942914592398422]
	TIME [epoch: 6.44 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14460308002146469		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.14460308002146469 | validation: 0.09983772720328878]
	TIME [epoch: 6.47 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12848996762595816		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.12848996762595816 | validation: 0.13833562790504]
	TIME [epoch: 6.48 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16812861721798597		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.16812861721798597 | validation: 0.15375794149984046]
	TIME [epoch: 6.45 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17367286930095444		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.17367286930095444 | validation: 0.21405256600036332]
	TIME [epoch: 6.45 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12396215964278262		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.12396215964278262 | validation: 0.12554743161142887]
	TIME [epoch: 6.45 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15044558283783796		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.15044558283783796 | validation: 0.1305227978602972]
	TIME [epoch: 6.45 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14218818431627722		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.14218818431627722 | validation: 0.19069599750961483]
	TIME [epoch: 6.46 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13696650756719111		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.13696650756719111 | validation: 0.16983743799624265]
	TIME [epoch: 6.46 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1406015168247641		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.1406015168247641 | validation: 0.11795457042432078]
	TIME [epoch: 6.54 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13078483048178513		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.13078483048178513 | validation: 0.12110909516311136]
	TIME [epoch: 6.47 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13135635811501817		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.13135635811501817 | validation: 0.15443035621470932]
	TIME [epoch: 6.47 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14203419883595111		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.14203419883595111 | validation: 0.10631763493220103]
	TIME [epoch: 6.47 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09909087774434987		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.09909087774434987 | validation: 0.22672527494841418]
	TIME [epoch: 6.51 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1457195445588093		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.1457195445588093 | validation: 0.11836183436208751]
	TIME [epoch: 6.47 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08757022165074713		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.08757022165074713 | validation: 0.1422225393060257]
	TIME [epoch: 6.47 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1225155141289159		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.1225155141289159 | validation: 0.11770823768496108]
	TIME [epoch: 6.5 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12987240629270383		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.12987240629270383 | validation: 0.2518968928975971]
	TIME [epoch: 6.46 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14469640459881697		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.14469640459881697 | validation: 0.1732385529528313]
	TIME [epoch: 6.46 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11190725827469934		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.11190725827469934 | validation: 0.14740413294286442]
	TIME [epoch: 6.45 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13284980783090755		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.13284980783090755 | validation: 0.060668563802112045]
	TIME [epoch: 6.46 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0755253938103169		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.0755253938103169 | validation: 0.27234081215346145]
	TIME [epoch: 6.46 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23378526743153014		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.23378526743153014 | validation: 0.3111992848807104]
	TIME [epoch: 6.45 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1982913003918672		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.1982913003918672 | validation: 0.08166431361629663]
	TIME [epoch: 6.49 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08334220889111107		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.08334220889111107 | validation: 0.08271663152549444]
	TIME [epoch: 6.46 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13303551373382758		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.13303551373382758 | validation: 0.14147541133577568]
	TIME [epoch: 6.46 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13844610605947683		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.13844610605947683 | validation: 0.10462190023733768]
	TIME [epoch: 6.46 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1271540803248696		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.1271540803248696 | validation: 0.09139971319976276]
	TIME [epoch: 6.47 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0827022192834756		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.0827022192834756 | validation: 0.15743031014453576]
	TIME [epoch: 6.47 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14443697614380224		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.14443697614380224 | validation: 0.2093903827530196]
	TIME [epoch: 6.45 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1337474154856761		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.1337474154856761 | validation: 0.10893351093858854]
	TIME [epoch: 6.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13806629679395716		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.13806629679395716 | validation: 0.08848613031419973]
	TIME [epoch: 6.48 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08332604120468544		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.08332604120468544 | validation: 0.09180197442095578]
	TIME [epoch: 6.47 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09888791268039297		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.09888791268039297 | validation: 0.09458884137196939]
	TIME [epoch: 6.45 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13343136240401549		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.13343136240401549 | validation: 0.1161373913590348]
	TIME [epoch: 6.47 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10344294515265966		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.10344294515265966 | validation: 0.138547605628525]
	TIME [epoch: 6.47 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11116300990694525		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.11116300990694525 | validation: 0.08709587255284752]
	TIME [epoch: 6.45 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11668036262553949		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.11668036262553949 | validation: 0.09416282120889762]
	TIME [epoch: 6.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12660061470651623		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.12660061470651623 | validation: 0.10327419167838381]
	TIME [epoch: 6.46 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11249714885626332		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.11249714885626332 | validation: 0.18748780360142767]
	TIME [epoch: 6.46 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16264614446340855		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.16264614446340855 | validation: 0.12358623495648857]
	TIME [epoch: 6.46 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1302779235311072		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.1302779235311072 | validation: 0.10408076815113387]
	TIME [epoch: 6.46 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18563647288475532		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.18563647288475532 | validation: 0.10263305103402828]
	TIME [epoch: 6.47 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10290621133131768		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.10290621133131768 | validation: 0.08937193598093496]
	TIME [epoch: 6.46 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22114368020211958		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.22114368020211958 | validation: 0.10397689362307871]
	TIME [epoch: 6.49 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331707281148969		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.1331707281148969 | validation: 0.14670666496312568]
	TIME [epoch: 6.48 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1342264932714955		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.1342264932714955 | validation: 0.1763834929693254]
	TIME [epoch: 6.46 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18497642645901247		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.18497642645901247 | validation: 0.22561671895108645]
	TIME [epoch: 6.45 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18034994973807422		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.18034994973807422 | validation: 0.12289179712110113]
	TIME [epoch: 6.46 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12378043536924702		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.12378043536924702 | validation: 0.14128304549627183]
	TIME [epoch: 6.46 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17744330448791645		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.17744330448791645 | validation: 0.2110362737891239]
	TIME [epoch: 6.45 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17149246401407742		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.17149246401407742 | validation: 0.17462474478365117]
	TIME [epoch: 6.46 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1354166584672365		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.1354166584672365 | validation: 0.1411167518710861]
	TIME [epoch: 6.49 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15100405463527627		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.15100405463527627 | validation: 0.1336667072946786]
	TIME [epoch: 6.46 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12450794400991935		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.12450794400991935 | validation: 0.14331162658644123]
	TIME [epoch: 6.46 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12145324647801824		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.12145324647801824 | validation: 0.22395207679044007]
	TIME [epoch: 6.45 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14772151667229352		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.14772151667229352 | validation: 0.09945908603013638]
	TIME [epoch: 6.46 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1247993200382919		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.1247993200382919 | validation: 0.14314087865651218]
	TIME [epoch: 6.46 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1409594628812311		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.1409594628812311 | validation: 0.09083489352426946]
	TIME [epoch: 6.46 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12318951818619168		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.12318951818619168 | validation: 0.2606711871358214]
	TIME [epoch: 6.49 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2347095903233159		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.2347095903233159 | validation: 0.13387722497613533]
	TIME [epoch: 6.46 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10764483734913313		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.10764483734913313 | validation: 0.07983454736833184]
	TIME [epoch: 6.47 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09152433394869162		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.09152433394869162 | validation: 0.08333606172112554]
	TIME [epoch: 6.46 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10949626330507209		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.10949626330507209 | validation: 0.12529943838435872]
	TIME [epoch: 6.45 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1373318696685127		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.1373318696685127 | validation: 0.12583989539472604]
	TIME [epoch: 6.46 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11138798064354688		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.11138798064354688 | validation: 0.10771667015553081]
	TIME [epoch: 6.46 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13666507233964592		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.13666507233964592 | validation: 0.0735205045974893]
	TIME [epoch: 6.5 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10068823074885878		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.10068823074885878 | validation: 0.09662548860537133]
	TIME [epoch: 6.46 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10571428247193436		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.10571428247193436 | validation: 0.10222096254942392]
	TIME [epoch: 6.46 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09499964759861083		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.09499964759861083 | validation: 0.055446184284750476]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_618.pth
	Model improved!!!
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09215195294967819		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.09215195294967819 | validation: 0.0717710492503487]
	TIME [epoch: 6.53 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06865077963586996		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.06865077963586996 | validation: 0.05449880161903049]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_620.pth
	Model improved!!!
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1035408062807182		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.1035408062807182 | validation: 0.12321641373657963]
	TIME [epoch: 6.48 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1557925900047222		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.1557925900047222 | validation: 0.11774345157636154]
	TIME [epoch: 6.46 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09416213873849423		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.09416213873849423 | validation: 0.1369097198910676]
	TIME [epoch: 6.42 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10984712450495371		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.10984712450495371 | validation: 0.11780430842863464]
	TIME [epoch: 6.43 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09310799617919131		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.09310799617919131 | validation: 0.08956661895575717]
	TIME [epoch: 6.44 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08592359818810708		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.08592359818810708 | validation: 0.11053708851903843]
	TIME [epoch: 6.44 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1334933425962298		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.1334933425962298 | validation: 0.2177949257308409]
	TIME [epoch: 6.45 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1418872712005037		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.1418872712005037 | validation: 0.15882813693088382]
	TIME [epoch: 6.46 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11819833516506378		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.11819833516506378 | validation: 0.16936802543541976]
	TIME [epoch: 6.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13428754904654294		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.13428754904654294 | validation: 0.13468926318624302]
	TIME [epoch: 6.5 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1216495524525511		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.1216495524525511 | validation: 0.11688569510243371]
	TIME [epoch: 6.47 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14933611585949463		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.14933611585949463 | validation: 0.11358643413726421]
	TIME [epoch: 6.47 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06907720908180262		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.06907720908180262 | validation: 0.0725228241327736]
	TIME [epoch: 6.47 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.080352948158391		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.080352948158391 | validation: 0.2228567093826097]
	TIME [epoch: 6.47 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22948509501986586		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.22948509501986586 | validation: 0.251254728172899]
	TIME [epoch: 6.47 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16503771552277927		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.16503771552277927 | validation: 0.10862159960106428]
	TIME [epoch: 6.51 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09855131485737001		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.09855131485737001 | validation: 0.18236085596130422]
	TIME [epoch: 6.47 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13674175476694156		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.13674175476694156 | validation: 0.05818952837420441]
	TIME [epoch: 6.47 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820183221174283		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.0820183221174283 | validation: 0.07233121359981821]
	TIME [epoch: 6.46 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06612324677704734		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.06612324677704734 | validation: 0.10661934912557844]
	TIME [epoch: 6.46 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11772293262536881		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.11772293262536881 | validation: 0.05109854500666778]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_641.pth
	Model improved!!!
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06500304123120633		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.06500304123120633 | validation: 0.09999380300470664]
	TIME [epoch: 6.52 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0977475702730386		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.0977475702730386 | validation: 0.06253019705039468]
	TIME [epoch: 6.47 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09359755271610139		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.09359755271610139 | validation: 0.19150734161881633]
	TIME [epoch: 6.45 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12018625550631717		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.12018625550631717 | validation: 0.25562137968655696]
	TIME [epoch: 6.44 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16042195742589568		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.16042195742589568 | validation: 0.09362536806774109]
	TIME [epoch: 6.43 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07925347512779826		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.07925347512779826 | validation: 0.11700474069429795]
	TIME [epoch: 6.44 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08893675456068087		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.08893675456068087 | validation: 0.07449725178395226]
	TIME [epoch: 6.44 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10671057594188676		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.10671057594188676 | validation: 0.14687213199403096]
	TIME [epoch: 6.44 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10631786626434334		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.10631786626434334 | validation: 0.11709470467325578]
	TIME [epoch: 6.48 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09966928998256586		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.09966928998256586 | validation: 0.09945524148323755]
	TIME [epoch: 6.47 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09298733336322479		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.09298733336322479 | validation: 0.1309628740868967]
	TIME [epoch: 6.46 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09132030456197632		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.09132030456197632 | validation: 0.1070363450863282]
	TIME [epoch: 6.46 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09741564257488813		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.09741564257488813 | validation: 0.12010107544339295]
	TIME [epoch: 6.44 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16264693272617192		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.16264693272617192 | validation: 0.1438799101610944]
	TIME [epoch: 6.46 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11751797077660114		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.11751797077660114 | validation: 0.05752710303921178]
	TIME [epoch: 6.46 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11285993690843213		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.11285993690843213 | validation: 0.08247986359935204]
	TIME [epoch: 6.46 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13202891795792515		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.13202891795792515 | validation: 0.18659376299903593]
	TIME [epoch: 6.49 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15115487355085		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.15115487355085 | validation: 0.12632202049383434]
	TIME [epoch: 6.46 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12949320771288667		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.12949320771288667 | validation: 0.12674464002749375]
	TIME [epoch: 6.45 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1311348955707848		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.1311348955707848 | validation: 0.21293923010848795]
	TIME [epoch: 6.47 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13081646367517138		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.13081646367517138 | validation: 0.08386694025655579]
	TIME [epoch: 6.45 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09982076045368582		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.09982076045368582 | validation: 0.13097742372549856]
	TIME [epoch: 6.44 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12975446547136443		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.12975446547136443 | validation: 0.15669062797291755]
	TIME [epoch: 6.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1814397845622439		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.1814397845622439 | validation: 0.1285897512906666]
	TIME [epoch: 6.46 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0881168916201811		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.0881168916201811 | validation: 0.05721322580403628]
	TIME [epoch: 6.44 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0913557029316026		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.0913557029316026 | validation: 0.11601134734227539]
	TIME [epoch: 6.43 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08738910356277146		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.08738910356277146 | validation: 0.0937824091003397]
	TIME [epoch: 6.43 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11078662034904777		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.11078662034904777 | validation: 0.1575304052004833]
	TIME [epoch: 6.43 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12779643284530648		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.12779643284530648 | validation: 0.11767779518736916]
	TIME [epoch: 6.43 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10323846617176712		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.10323846617176712 | validation: 0.09783657550945957]
	TIME [epoch: 6.43 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08214972667787823		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.08214972667787823 | validation: 0.0761583640104069]
	TIME [epoch: 6.47 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08481120366201073		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.08481120366201073 | validation: 0.07593338257151329]
	TIME [epoch: 6.44 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09740624502000864		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.09740624502000864 | validation: 0.11885767227130258]
	TIME [epoch: 6.43 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13075845793603785		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.13075845793603785 | validation: 0.11318597974910671]
	TIME [epoch: 6.42 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10959829359696062		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.10959829359696062 | validation: 0.16390403955056787]
	TIME [epoch: 6.43 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10077920869091468		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.10077920869091468 | validation: 0.16363375768887545]
	TIME [epoch: 6.42 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1216224298197563		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.1216224298197563 | validation: 0.07506759541821174]
	TIME [epoch: 6.44 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07163947162924357		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.07163947162924357 | validation: 0.09699077928391502]
	TIME [epoch: 6.47 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10726619089904539		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.10726619089904539 | validation: 0.18277994751352408]
	TIME [epoch: 6.43 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11213737018474747		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.11213737018474747 | validation: 0.06119774139787244]
	TIME [epoch: 6.42 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06561587485292715		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.06561587485292715 | validation: 0.08745168319694037]
	TIME [epoch: 6.43 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0625097421110504		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.0625097421110504 | validation: 0.09004752270826699]
	TIME [epoch: 6.43 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07819821352600742		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.07819821352600742 | validation: 0.13184241533201807]
	TIME [epoch: 6.42 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12454289974117366		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.12454289974117366 | validation: 0.15249462402285777]
	TIME [epoch: 6.42 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17243762517296202		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.17243762517296202 | validation: 0.1975521192620877]
	TIME [epoch: 6.46 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1383237060484462		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1383237060484462 | validation: 0.09690167903758841]
	TIME [epoch: 6.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0873017156751107		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.0873017156751107 | validation: 0.09590243980650452]
	TIME [epoch: 6.44 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08378258830072452		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.08378258830072452 | validation: 0.08524548269500482]
	TIME [epoch: 6.44 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08928956228569204		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.08928956228569204 | validation: 0.08882344026776309]
	TIME [epoch: 6.45 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10381090860449634		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.10381090860449634 | validation: 0.08042857307384446]
	TIME [epoch: 6.44 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12959781991961172		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.12959781991961172 | validation: 0.1213249858023424]
	TIME [epoch: 6.46 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08846879528131162		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.08846879528131162 | validation: 0.06743674038798007]
	TIME [epoch: 6.47 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07530238774334452		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.07530238774334452 | validation: 0.13482618766146304]
	TIME [epoch: 6.49 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12645322616831067		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.12645322616831067 | validation: 0.20337817073803868]
	TIME [epoch: 6.45 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11433751036031498		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.11433751036031498 | validation: 0.12136306947420672]
	TIME [epoch: 6.47 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17593569471396137		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.17593569471396137 | validation: 0.2649109290675478]
	TIME [epoch: 6.45 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15712537130286666		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.15712537130286666 | validation: 0.0759280580261028]
	TIME [epoch: 6.47 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10162733966598499		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.10162733966598499 | validation: 0.12206812142421664]
	TIME [epoch: 6.45 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.091861983458547		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.091861983458547 | validation: 0.09678372862274992]
	TIME [epoch: 6.45 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09804439076756691		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.09804439076756691 | validation: 0.1102082922082354]
	TIME [epoch: 6.49 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12300248132821326		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.12300248132821326 | validation: 0.08484058892734826]
	TIME [epoch: 6.46 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0704752986884346		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.0704752986884346 | validation: 0.1376241547300692]
	TIME [epoch: 6.47 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10253797363996682		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.10253797363996682 | validation: 0.07602859128798099]
	TIME [epoch: 6.47 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060754218223229794		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.060754218223229794 | validation: 0.06133681700900258]
	TIME [epoch: 6.45 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07740615217200512		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.07740615217200512 | validation: 0.11975586928515586]
	TIME [epoch: 6.45 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0824117779167217		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.0824117779167217 | validation: 0.04535018974995209]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06100398595556053		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.06100398595556053 | validation: 0.07415115470248645]
	TIME [epoch: 6.59 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09220432189890841		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.09220432189890841 | validation: 0.054987069007015776]
	TIME [epoch: 6.47 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05142436858492491		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.05142436858492491 | validation: 0.05175277668963936]
	TIME [epoch: 6.47 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06827972908804747		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.06827972908804747 | validation: 0.049724514456979535]
	TIME [epoch: 6.48 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07150333927090588		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.07150333927090588 | validation: 0.06658689867221862]
	TIME [epoch: 6.48 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0713461637432474		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.0713461637432474 | validation: 0.06953829592544962]
	TIME [epoch: 6.48 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08828730416793468		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.08828730416793468 | validation: 0.0979388943020151]
	TIME [epoch: 6.48 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09913327310724633		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.09913327310724633 | validation: 0.09251916880912972]
	TIME [epoch: 6.51 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10648141905201722		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.10648141905201722 | validation: 0.12005557450103366]
	TIME [epoch: 6.48 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11585862304254832		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.11585862304254832 | validation: 0.07345526574641116]
	TIME [epoch: 6.48 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09785644588818872		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.09785644588818872 | validation: 0.07743981778989738]
	TIME [epoch: 6.47 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10048911817261623		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.10048911817261623 | validation: 0.07124827235247136]
	TIME [epoch: 6.48 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10597854373794593		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.10597854373794593 | validation: 0.09724030103921084]
	TIME [epoch: 6.48 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07995683976937554		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.07995683976937554 | validation: 0.07045123665510179]
	TIME [epoch: 6.48 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07936133401806156		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.07936133401806156 | validation: 0.10434743402854092]
	TIME [epoch: 6.51 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08798097366637089		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.08798097366637089 | validation: 0.10159674767473269]
	TIME [epoch: 6.48 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07975010374670034		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.07975010374670034 | validation: 0.07247793183098879]
	TIME [epoch: 6.47 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05388266394033671		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.05388266394033671 | validation: 0.0411362859065355]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07160174745590395		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.07160174745590395 | validation: 0.03744200158359461]
	TIME [epoch: 6.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_726.pth
	Model improved!!!
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06536936445462214		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.06536936445462214 | validation: 0.18243128376695406]
	TIME [epoch: 6.5 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1147702701522741		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.1147702701522741 | validation: 0.12322670509679544]
	TIME [epoch: 6.44 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07911356155364097		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.07911356155364097 | validation: 0.09730536696017186]
	TIME [epoch: 6.48 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08856253595181357		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.08856253595181357 | validation: 0.11964871038024188]
	TIME [epoch: 6.45 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09589999551101486		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.09589999551101486 | validation: 0.07374174576643071]
	TIME [epoch: 6.45 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07641446397017886		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.07641446397017886 | validation: 0.07765588898921118]
	TIME [epoch: 6.46 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10569544633734175		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.10569544633734175 | validation: 0.07715919385272908]
	TIME [epoch: 6.45 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08804810301102158		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.08804810301102158 | validation: 0.06684006362203425]
	TIME [epoch: 6.45 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06995183633862836		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.06995183633862836 | validation: 0.05517194722354797]
	TIME [epoch: 6.46 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0606760460250004		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.0606760460250004 | validation: 0.07962366370329291]
	TIME [epoch: 6.49 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07824542393555348		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.07824542393555348 | validation: 0.102923602463447]
	TIME [epoch: 6.47 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10409167048250227		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.10409167048250227 | validation: 0.1029020571093884]
	TIME [epoch: 6.47 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07561277074999402		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.07561277074999402 | validation: 0.0681941698481897]
	TIME [epoch: 6.47 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1101077759548847		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.1101077759548847 | validation: 0.09999201330008864]
	TIME [epoch: 6.47 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08325619347833565		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.08325619347833565 | validation: 0.13174888137821658]
	TIME [epoch: 6.47 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10781993057190102		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.10781993057190102 | validation: 0.09766879767477094]
	TIME [epoch: 6.47 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07491619403708294		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.07491619403708294 | validation: 0.09553471227629153]
	TIME [epoch: 6.5 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13867362549039758		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.13867362549039758 | validation: 0.09101760083772813]
	TIME [epoch: 6.47 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09632574294346327		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.09632574294346327 | validation: 0.11886360364233252]
	TIME [epoch: 6.47 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09065496964956801		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.09065496964956801 | validation: 0.11926637748039638]
	TIME [epoch: 6.47 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0992928368654701		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.0992928368654701 | validation: 0.0643805096008569]
	TIME [epoch: 6.47 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06716816883257033		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.06716816883257033 | validation: 0.09917491652255567]
	TIME [epoch: 6.47 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08548310617340055		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.08548310617340055 | validation: 0.14652840665567365]
	TIME [epoch: 6.47 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10962736788100369		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.10962736788100369 | validation: 0.10510427391868685]
	TIME [epoch: 6.49 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08817323842929807		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.08817323842929807 | validation: 0.0829023180789115]
	TIME [epoch: 6.49 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05772094102711862		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.05772094102711862 | validation: 0.055447886045534765]
	TIME [epoch: 6.47 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06400013829214704		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.06400013829214704 | validation: 0.0848756222238239]
	TIME [epoch: 6.47 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07328992561019494		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.07328992561019494 | validation: 0.0705207028717797]
	TIME [epoch: 6.46 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0594025140685262		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.0594025140685262 | validation: 0.0510894822256161]
	TIME [epoch: 6.46 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05615793001947229		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.05615793001947229 | validation: 0.042425523670631404]
	TIME [epoch: 6.46 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06008659473438553		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.06008659473438553 | validation: 0.1334189799890089]
	TIME [epoch: 6.48 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1353813554752703		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.1353813554752703 | validation: 0.1928486761820416]
	TIME [epoch: 6.48 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11718777419114693		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.11718777419114693 | validation: 0.05750668311660255]
	TIME [epoch: 6.46 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06069505741302653		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.06069505741302653 | validation: 0.08090708598334512]
	TIME [epoch: 6.45 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07919916500016319		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.07919916500016319 | validation: 0.11073621554376326]
	TIME [epoch: 6.45 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08311530472477868		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.08311530472477868 | validation: 0.05824295344727629]
	TIME [epoch: 6.45 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0661911417084225		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.0661911417084225 | validation: 0.09579095256279825]
	TIME [epoch: 6.45 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0664950636241184		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.0664950636241184 | validation: 0.08074963734716128]
	TIME [epoch: 6.46 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061358944754150116		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.061358944754150116 | validation: 0.11739245677907091]
	TIME [epoch: 6.48 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09284532635146765		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.09284532635146765 | validation: 0.09350512527910089]
	TIME [epoch: 6.45 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07159014122096972		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.07159014122096972 | validation: 0.06425513872161394]
	TIME [epoch: 6.45 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05719160424936763		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.05719160424936763 | validation: 0.04708782622174045]
	TIME [epoch: 6.46 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04409592673675218		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.04409592673675218 | validation: 0.05214039551075308]
	TIME [epoch: 6.46 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06140962210135845		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.06140962210135845 | validation: 0.05514724997883974]
	TIME [epoch: 6.46 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05817284808460646		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.05817284808460646 | validation: 0.06578186524169756]
	TIME [epoch: 6.46 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06261458093961661		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.06261458093961661 | validation: 0.06993821439303466]
	TIME [epoch: 6.48 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.067447081199741		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.067447081199741 | validation: 0.04621968448397578]
	TIME [epoch: 6.45 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05229535002239642		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.05229535002239642 | validation: 0.04780372966001153]
	TIME [epoch: 6.45 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04340997748262322		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.04340997748262322 | validation: 0.04088450124138792]
	TIME [epoch: 6.45 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06239468587434968		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.06239468587434968 | validation: 0.0828940189308262]
	TIME [epoch: 6.45 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06470996081993159		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.06470996081993159 | validation: 0.04653139190874153]
	TIME [epoch: 6.45 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06748121305257744		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.06748121305257744 | validation: 0.0783479079628002]
	TIME [epoch: 6.45 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07093091138215482		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.07093091138215482 | validation: 0.06393126339924826]
	TIME [epoch: 6.49 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06704724616755309		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.06704724616755309 | validation: 0.06267622440327206]
	TIME [epoch: 6.46 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05639793615444651		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.05639793615444651 | validation: 0.0363729541676962]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_781.pth
	Model improved!!!
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09777473902787721		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.09777473902787721 | validation: 0.12195495694284757]
	TIME [epoch: 6.53 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08366307349630808		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.08366307349630808 | validation: 0.04762661747973215]
	TIME [epoch: 6.44 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04361383142790762		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.04361383142790762 | validation: 0.06798204146997514]
	TIME [epoch: 6.44 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06507194712406492		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.06507194712406492 | validation: 0.08927919550228731]
	TIME [epoch: 6.44 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09306641111657882		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.09306641111657882 | validation: 0.11501708249849005]
	TIME [epoch: 6.47 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08892234117201153		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.08892234117201153 | validation: 0.09282965054187833]
	TIME [epoch: 6.45 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14187704877522633		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.14187704877522633 | validation: 0.10519963681166186]
	TIME [epoch: 6.44 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10195832722387328		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.10195832722387328 | validation: 0.09866284647795455]
	TIME [epoch: 6.45 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07627066965977031		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.07627066965977031 | validation: 0.07715990204664885]
	TIME [epoch: 6.45 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11396855821129374		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.11396855821129374 | validation: 0.12612526813198532]
	TIME [epoch: 6.45 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09654674778104337		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.09654674778104337 | validation: 0.08698880601477806]
	TIME [epoch: 6.45 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07346970937863871		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.07346970937863871 | validation: 0.04798684592028818]
	TIME [epoch: 6.48 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05967422814299099		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.05967422814299099 | validation: 0.05911986112940032]
	TIME [epoch: 6.46 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0665410965716832		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.0665410965716832 | validation: 0.0577260869428254]
	TIME [epoch: 6.46 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054492955513084404		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.054492955513084404 | validation: 0.04580012675659952]
	TIME [epoch: 6.46 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04977813661590676		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.04977813661590676 | validation: 0.055781899997208555]
	TIME [epoch: 6.46 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06414795664216144		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.06414795664216144 | validation: 0.06506711372694804]
	TIME [epoch: 6.45 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05743573707240084		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.05743573707240084 | validation: 0.05041933437018534]
	TIME [epoch: 6.46 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06230966414842601		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.06230966414842601 | validation: 0.053962056858169696]
	TIME [epoch: 6.48 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04228622591122226		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.04228622591122226 | validation: 0.10361949412021478]
	TIME [epoch: 6.48 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0674222563717106		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.0674222563717106 | validation: 0.06080707810211068]
	TIME [epoch: 6.46 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06286023222590914		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.06286023222590914 | validation: 0.07279279792841378]
	TIME [epoch: 6.45 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06314649446856219		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.06314649446856219 | validation: 0.07316706670230504]
	TIME [epoch: 6.46 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09186512815817283		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.09186512815817283 | validation: 0.09123885419093775]
	TIME [epoch: 6.45 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08391875223526896		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.08391875223526896 | validation: 0.13045752488415205]
	TIME [epoch: 6.45 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0820119478368004		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.0820119478368004 | validation: 0.09670713515179813]
	TIME [epoch: 6.47 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07504325723356065		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.07504325723356065 | validation: 0.07664045496978467]
	TIME [epoch: 6.48 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07813870988136831		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.07813870988136831 | validation: 0.1931051277739384]
	TIME [epoch: 6.46 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1449067930496445		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.1449067930496445 | validation: 0.09483457882014917]
	TIME [epoch: 6.46 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0795156084255145		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.0795156084255145 | validation: 0.085337587339206]
	TIME [epoch: 6.46 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07425610728089505		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.07425610728089505 | validation: 0.07272779252538926]
	TIME [epoch: 6.46 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06963875557290077		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.06963875557290077 | validation: 0.08107737286764899]
	TIME [epoch: 6.46 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06070843318391905		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.06070843318391905 | validation: 0.0788043001701536]
	TIME [epoch: 6.47 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0803532145562343		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.0803532145562343 | validation: 0.09949843901233163]
	TIME [epoch: 6.49 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07667603216177774		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.07667603216177774 | validation: 0.10920173221414729]
	TIME [epoch: 6.47 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07537291444113209		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.07537291444113209 | validation: 0.06498943759870075]
	TIME [epoch: 6.47 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06359348423501979		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.06359348423501979 | validation: 0.05040634245636863]
	TIME [epoch: 6.46 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05108701120785687		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.05108701120785687 | validation: 0.06413118547531821]
	TIME [epoch: 6.46 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06684173608893212		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.06684173608893212 | validation: 0.06712636820874067]
	TIME [epoch: 6.46 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06944476180364592		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.06944476180364592 | validation: 0.08234788772889762]
	TIME [epoch: 6.46 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07574734441336488		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.07574734441336488 | validation: 0.06889687298458233]
	TIME [epoch: 6.49 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07656267828468359		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.07656267828468359 | validation: 0.05520490484052235]
	TIME [epoch: 6.45 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10134951279258346		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.10134951279258346 | validation: 0.14690641718506928]
	TIME [epoch: 6.46 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08134090682507567		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.08134090682507567 | validation: 0.04225747797854597]
	TIME [epoch: 6.46 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05805222081980092		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.05805222081980092 | validation: 0.08984723302746234]
	TIME [epoch: 6.46 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07485023259595838		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.07485023259595838 | validation: 0.040030557013790526]
	TIME [epoch: 6.45 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03416833976295502		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.03416833976295502 | validation: 0.057991202079509065]
	TIME [epoch: 6.46 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05334727385247836		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.05334727385247836 | validation: 0.08284746398647126]
	TIME [epoch: 6.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06546270838748035		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.06546270838748035 | validation: 0.12831632334756654]
	TIME [epoch: 6.46 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0786088171582633		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.0786088171582633 | validation: 0.05364897898018793]
	TIME [epoch: 6.46 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06333373297890653		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.06333373297890653 | validation: 0.05991130443839603]
	TIME [epoch: 6.46 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04850251500894732		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.04850251500894732 | validation: 0.04390485201996472]
	TIME [epoch: 6.46 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057159727737032456		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.057159727737032456 | validation: 0.07623996011223676]
	TIME [epoch: 6.46 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051031203329098204		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.051031203329098204 | validation: 0.0708532533473282]
	TIME [epoch: 6.46 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06894616190921327		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.06894616190921327 | validation: 0.06976659682054033]
	TIME [epoch: 6.49 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0553942870150232		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.0553942870150232 | validation: 0.0846489358694354]
	TIME [epoch: 6.47 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08542577231586373		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.08542577231586373 | validation: 0.05434098306316403]
	TIME [epoch: 6.45 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04267473855285323		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.04267473855285323 | validation: 0.07541921800647539]
	TIME [epoch: 6.47 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05832731300216456		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.05832731300216456 | validation: 0.04096362484941286]
	TIME [epoch: 6.46 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03287038025091125		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.03287038025091125 | validation: 0.06366787954310724]
	TIME [epoch: 6.46 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052004482350761994		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.052004482350761994 | validation: 0.05004908387597391]
	TIME [epoch: 6.46 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0774894509548542		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.0774894509548542 | validation: 0.04525510157702329]
	TIME [epoch: 6.47 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05843783856947156		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.05843783856947156 | validation: 0.07026224423888013]
	TIME [epoch: 6.47 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05620728505224683		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.05620728505224683 | validation: 0.06911762314900217]
	TIME [epoch: 6.46 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048953377464089065		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.048953377464089065 | validation: 0.08562042519872988]
	TIME [epoch: 6.45 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05861286072603104		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.05861286072603104 | validation: 0.04506962197916244]
	TIME [epoch: 6.45 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0644446188062543		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.0644446188062543 | validation: 0.07096051962358356]
	TIME [epoch: 6.45 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05765536324903761		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.05765536324903761 | validation: 0.05455570775608104]
	TIME [epoch: 6.47 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05524660996967552		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.05524660996967552 | validation: 0.1037337209374151]
	TIME [epoch: 6.47 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06818219534058528		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.06818219534058528 | validation: 0.05318263941317821]
	TIME [epoch: 6.48 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050694866165562416		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.050694866165562416 | validation: 0.0563688148532426]
	TIME [epoch: 6.45 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052481730968381254		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.052481730968381254 | validation: 0.06687332590499141]
	TIME [epoch: 6.46 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07735014578669343		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.07735014578669343 | validation: 0.1307154560523314]
	TIME [epoch: 6.45 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0822615716957378		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.0822615716957378 | validation: 0.051464698855827155]
	TIME [epoch: 6.46 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08119579752092466		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.08119579752092466 | validation: 0.08750867099435837]
	TIME [epoch: 6.46 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06331486531367764		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.06331486531367764 | validation: 0.06295363863675824]
	TIME [epoch: 6.47 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03739465058944118		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.03739465058944118 | validation: 0.07348895371356434]
	TIME [epoch: 6.49 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06176026563807101		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.06176026563807101 | validation: 0.07321291078387905]
	TIME [epoch: 6.47 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04860951615579287		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.04860951615579287 | validation: 0.07031733768263487]
	TIME [epoch: 6.46 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07258219294233992		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.07258219294233992 | validation: 0.05320244472050055]
	TIME [epoch: 6.46 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07176953333435612		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.07176953333435612 | validation: 0.08068358222869294]
	TIME [epoch: 6.46 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06271504791174488		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.06271504791174488 | validation: 0.055803154793215105]
	TIME [epoch: 6.45 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05016697686373446		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.05016697686373446 | validation: 0.08857482409354976]
	TIME [epoch: 6.46 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07007490695123424		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.07007490695123424 | validation: 0.06554195821554204]
	TIME [epoch: 6.5 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06609844258423771		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.06609844258423771 | validation: 0.1202287436745132]
	TIME [epoch: 6.46 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07337763762475077		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.07337763762475077 | validation: 0.06819575051975962]
	TIME [epoch: 6.46 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047733849071040335		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.047733849071040335 | validation: 0.05012636479306507]
	TIME [epoch: 6.46 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061339488104378545		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.061339488104378545 | validation: 0.08159566177323622]
	TIME [epoch: 6.45 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0710193242511683		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.0710193242511683 | validation: 0.05548356871310556]
	TIME [epoch: 6.46 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05961080686488948		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.05961080686488948 | validation: 0.07360567955928975]
	TIME [epoch: 6.45 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0649525437188185		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.0649525437188185 | validation: 0.06929770153132038]
	TIME [epoch: 6.49 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06187963717093803		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.06187963717093803 | validation: 0.06493516889044941]
	TIME [epoch: 6.47 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06291050297158692		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.06291050297158692 | validation: 0.051430233911065874]
	TIME [epoch: 6.45 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05876182992554701		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.05876182992554701 | validation: 0.0691333658238116]
	TIME [epoch: 6.46 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06904486428312538		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.06904486428312538 | validation: 0.06861840605578562]
	TIME [epoch: 6.45 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06638302739632244		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.06638302739632244 | validation: 0.08245676909825422]
	TIME [epoch: 6.46 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06719806920893172		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.06719806920893172 | validation: 0.05727716957503398]
	TIME [epoch: 6.46 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0592452951682451		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.0592452951682451 | validation: 0.06523656476578314]
	TIME [epoch: 6.51 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07635153521162943		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.07635153521162943 | validation: 0.09439234945796222]
	TIME [epoch: 6.48 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059528533723530244		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.059528533723530244 | validation: 0.04131229436331413]
	TIME [epoch: 6.46 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049765952977067936		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.049765952977067936 | validation: 0.053163625263224684]
	TIME [epoch: 6.46 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04577437069324679		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.04577437069324679 | validation: 0.040417358496902804]
	TIME [epoch: 6.46 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05498269397774978		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.05498269397774978 | validation: 0.08157051296744706]
	TIME [epoch: 6.46 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060268975191749216		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.060268975191749216 | validation: 0.12458015593452189]
	TIME [epoch: 6.45 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07629137545616523		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.07629137545616523 | validation: 0.06493464348734819]
	TIME [epoch: 6.49 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06235641507504471		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.06235641507504471 | validation: 0.08042794257166799]
	TIME [epoch: 6.46 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0712670149290842		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.0712670149290842 | validation: 0.06501285960126711]
	TIME [epoch: 6.46 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056912701600534		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.056912701600534 | validation: 0.060590207932242464]
	TIME [epoch: 6.47 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061935681822258226		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.061935681822258226 | validation: 0.06122748231602441]
	TIME [epoch: 6.46 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06098025164960358		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.06098025164960358 | validation: 0.05634621849625746]
	TIME [epoch: 6.46 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07038321366257076		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.07038321366257076 | validation: 0.07451272792682438]
	TIME [epoch: 6.46 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07766415561409243		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.07766415561409243 | validation: 0.1224911284804675]
	TIME [epoch: 6.49 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08215812348742402		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.08215812348742402 | validation: 0.10993349656795687]
	TIME [epoch: 6.49 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07712406608660363		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.07712406608660363 | validation: 0.06953906153784509]
	TIME [epoch: 6.47 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053256262995963914		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.053256262995963914 | validation: 0.06906288561426979]
	TIME [epoch: 6.46 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07998003654013996		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.07998003654013996 | validation: 0.06344315102780393]
	TIME [epoch: 6.46 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06623726278773846		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.06623726278773846 | validation: 0.06750166787889145]
	TIME [epoch: 6.46 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06166544435789899		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.06166544435789899 | validation: 0.04957637145899931]
	TIME [epoch: 6.46 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0536648810454208		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.0536648810454208 | validation: 0.042842338048413475]
	TIME [epoch: 6.48 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0429618608916209		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.0429618608916209 | validation: 0.06659837568893026]
	TIME [epoch: 6.47 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04455168328443912		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.04455168328443912 | validation: 0.04990644306496455]
	TIME [epoch: 6.47 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06095930035736161		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.06095930035736161 | validation: 0.0662746606564479]
	TIME [epoch: 6.45 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04918659490947287		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.04918659490947287 | validation: 0.03612466492523437]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_904.pth
	Model improved!!!
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053368349643761456		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.053368349643761456 | validation: 0.0866013849308102]
	TIME [epoch: 6.53 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058060080497735374		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.058060080497735374 | validation: 0.06644973659788708]
	TIME [epoch: 6.45 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05036777525342569		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.05036777525342569 | validation: 0.049757660409555975]
	TIME [epoch: 6.47 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05929449892728687		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.05929449892728687 | validation: 0.04414143815620402]
	TIME [epoch: 6.48 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04791573293829485		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.04791573293829485 | validation: 0.04481196318843292]
	TIME [epoch: 6.45 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046786075770217934		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.046786075770217934 | validation: 0.04968129687775608]
	TIME [epoch: 6.46 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046446549925655		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.046446549925655 | validation: 0.061067868184648946]
	TIME [epoch: 6.45 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05828889138356125		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.05828889138356125 | validation: 0.08012363993558301]
	TIME [epoch: 6.46 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06478103602631656		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.06478103602631656 | validation: 0.07548208237263081]
	TIME [epoch: 6.46 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06203562365384502		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.06203562365384502 | validation: 0.04259008886512868]
	TIME [epoch: 6.47 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04516273968505303		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.04516273968505303 | validation: 0.04166490129480625]
	TIME [epoch: 6.48 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04663443209493863		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.04663443209493863 | validation: 0.06099370536144622]
	TIME [epoch: 6.47 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05053965926550493		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.05053965926550493 | validation: 0.0672902267475434]
	TIME [epoch: 6.46 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06501578780330754		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.06501578780330754 | validation: 0.09238664261140726]
	TIME [epoch: 6.45 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08786463921695267		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.08786463921695267 | validation: 0.09110873346760638]
	TIME [epoch: 6.45 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08142907768131438		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.08142907768131438 | validation: 0.0971204992438972]
	TIME [epoch: 6.45 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07741292487511506		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.07741292487511506 | validation: 0.07429771057084424]
	TIME [epoch: 6.44 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055312790385571915		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.055312790385571915 | validation: 0.06638946335867217]
	TIME [epoch: 6.5 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054459158077490424		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.054459158077490424 | validation: 0.05625356010541256]
	TIME [epoch: 6.45 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05562821091261432		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.05562821091261432 | validation: 0.06187779517474825]
	TIME [epoch: 6.46 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06372641904824555		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.06372641904824555 | validation: 0.1054084483276157]
	TIME [epoch: 6.45 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10780846045165575		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.10780846045165575 | validation: 0.09773236220322427]
	TIME [epoch: 6.45 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06030231268757642		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.06030231268757642 | validation: 0.05356125023743249]
	TIME [epoch: 6.45 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03865661194684727		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.03865661194684727 | validation: 0.04513079495060853]
	TIME [epoch: 6.45 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04080808467028364		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.04080808467028364 | validation: 0.06603873195484831]
	TIME [epoch: 6.49 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05213570761694807		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.05213570761694807 | validation: 0.05933434287673128]
	TIME [epoch: 6.45 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04883966801959353		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.04883966801959353 | validation: 0.06315274554942285]
	TIME [epoch: 6.45 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047605579287925456		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.047605579287925456 | validation: 0.04677838352508231]
	TIME [epoch: 6.46 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04563500336068427		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.04563500336068427 | validation: 0.06422326924636859]
	TIME [epoch: 6.45 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04859880000351253		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.04859880000351253 | validation: 0.052795705680983664]
	TIME [epoch: 6.45 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0419854344912986		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.0419854344912986 | validation: 0.047374943766960505]
	TIME [epoch: 6.45 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05301919339180941		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.05301919339180941 | validation: 0.032182285638859345]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_936.pth
	Model improved!!!
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056151039779303386		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.056151039779303386 | validation: 0.04696704779160074]
	TIME [epoch: 6.55 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06809692439965136		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.06809692439965136 | validation: 0.08183295552247911]
	TIME [epoch: 6.43 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06782288549867863		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.06782288549867863 | validation: 0.05210338720059255]
	TIME [epoch: 6.45 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04429672427687549		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.04429672427687549 | validation: 0.06641233796386592]
	TIME [epoch: 6.45 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07350793931614452		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.07350793931614452 | validation: 0.0356000007121002]
	TIME [epoch: 6.46 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06583988725267005		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.06583988725267005 | validation: 0.06049381494073977]
	TIME [epoch: 6.46 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051562889788307156		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.051562889788307156 | validation: 0.08097852548774899]
	TIME [epoch: 6.5 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0545418686622754		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.0545418686622754 | validation: 0.051197512255676]
	TIME [epoch: 6.47 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0485078605555281		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.0485078605555281 | validation: 0.05087872366707996]
	TIME [epoch: 6.47 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05810128345697541		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.05810128345697541 | validation: 0.0649528745185447]
	TIME [epoch: 6.46 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06373974413882319		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.06373974413882319 | validation: 0.0979129309517003]
	TIME [epoch: 6.46 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06896418438087829		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.06896418438087829 | validation: 0.058362662498549156]
	TIME [epoch: 6.47 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451660888244355		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.0451660888244355 | validation: 0.0376668936020339]
	TIME [epoch: 6.47 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03528334281379185		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.03528334281379185 | validation: 0.039168816512567865]
	TIME [epoch: 6.47 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041650685871450384		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.041650685871450384 | validation: 0.068865549444866]
	TIME [epoch: 6.48 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06860504700891348		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.06860504700891348 | validation: 0.05152645249840844]
	TIME [epoch: 6.47 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04867077954309009		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.04867077954309009 | validation: 0.06684196116252172]
	TIME [epoch: 6.46 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07209068284197992		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.07209068284197992 | validation: 0.057639920682835175]
	TIME [epoch: 6.46 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0418699194661928		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.0418699194661928 | validation: 0.05800240723524413]
	TIME [epoch: 6.46 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05061701611505813		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.05061701611505813 | validation: 0.07912391782884513]
	TIME [epoch: 6.47 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07955688627678958		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.07955688627678958 | validation: 0.12299915988521366]
	TIME [epoch: 6.48 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08202532423727864		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.08202532423727864 | validation: 0.09087959613776242]
	TIME [epoch: 6.49 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06377596443620205		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.06377596443620205 | validation: 0.05780115904891123]
	TIME [epoch: 6.46 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047014625593853936		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.047014625593853936 | validation: 0.05548277117285748]
	TIME [epoch: 6.46 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04608747589626205		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.04608747589626205 | validation: 0.08111361650877492]
	TIME [epoch: 6.46 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058752290116633306		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.058752290116633306 | validation: 0.05250934815360823]
	TIME [epoch: 6.46 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051504886161201614		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.051504886161201614 | validation: 0.04837481915098396]
	TIME [epoch: 6.46 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04092698884076858		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.04092698884076858 | validation: 0.04568660192247162]
	TIME [epoch: 6.47 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04934105208981758		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.04934105208981758 | validation: 0.10717845566360172]
	TIME [epoch: 6.49 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08594055577717827		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.08594055577717827 | validation: 0.08149678629526261]
	TIME [epoch: 6.46 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07653049441424782		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.07653049441424782 | validation: 0.0780629029080188]
	TIME [epoch: 6.46 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06803766725351969		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.06803766725351969 | validation: 0.06889133518349914]
	TIME [epoch: 6.45 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316082513814236		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.06316082513814236 | validation: 0.058669966833667514]
	TIME [epoch: 6.46 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05030814747207109		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.05030814747207109 | validation: 0.04860104132542528]
	TIME [epoch: 6.47 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0417425936051206		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.0417425936051206 | validation: 0.0676776038201513]
	TIME [epoch: 6.47 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451758548483938		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.0451758548483938 | validation: 0.05255450184474917]
	TIME [epoch: 6.5 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04644406867358992		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.04644406867358992 | validation: 0.04266062273666979]
	TIME [epoch: 6.46 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038403513538086964		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.038403513538086964 | validation: 0.06547523163031375]
	TIME [epoch: 6.46 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04540921373518708		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.04540921373518708 | validation: 0.06355037766118599]
	TIME [epoch: 6.46 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0513538099376442		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.0513538099376442 | validation: 0.05139855431690055]
	TIME [epoch: 6.45 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035132064933921674		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.035132064933921674 | validation: 0.035046474156538866]
	TIME [epoch: 6.44 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042665699140973325		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.042665699140973325 | validation: 0.06529410150611004]
	TIME [epoch: 6.43 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776291999856083		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.0776291999856083 | validation: 0.06643219735750142]
	TIME [epoch: 6.46 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05261761397741905		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.05261761397741905 | validation: 0.046632376322812766]
	TIME [epoch: 6.43 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03516009014577242		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.03516009014577242 | validation: 0.03738439720293697]
	TIME [epoch: 6.42 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03671327627899283		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.03671327627899283 | validation: 0.045533591010864675]
	TIME [epoch: 6.42 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044373778981739886		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.044373778981739886 | validation: 0.04338704527425565]
	TIME [epoch: 6.43 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039630943152399754		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.039630943152399754 | validation: 0.04498797613363872]
	TIME [epoch: 6.42 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03972501799852835		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.03972501799852835 | validation: 0.047618948923255515]
	TIME [epoch: 6.42 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036602057802811123		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.036602057802811123 | validation: 0.03369338143315092]
	TIME [epoch: 6.45 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032527159792241016		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.032527159792241016 | validation: 0.044698517203440494]
	TIME [epoch: 6.43 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04078247828006982		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.04078247828006982 | validation: 0.03597961783421495]
	TIME [epoch: 6.41 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047635729898988524		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.047635729898988524 | validation: 0.06046805360377285]
	TIME [epoch: 6.42 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05352610426068302		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.05352610426068302 | validation: 0.05607852994646523]
	TIME [epoch: 6.43 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05151426555564452		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.05151426555564452 | validation: 0.06120581981473821]
	TIME [epoch: 6.42 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07065711356802443		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.07065711356802443 | validation: 0.10612969167923156]
	TIME [epoch: 6.41 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06982694514742191		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.06982694514742191 | validation: 0.04521307024276897]
	TIME [epoch: 6.44 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05483203483683481		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.05483203483683481 | validation: 0.07850143449568013]
	TIME [epoch: 6.44 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733207908411831		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.04733207908411831 | validation: 0.04828138893438731]
	TIME [epoch: 6.42 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044843219134768984		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.044843219134768984 | validation: 0.05879776342235424]
	TIME [epoch: 6.42 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047412844828321296		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.047412844828321296 | validation: 0.048276870123421994]
	TIME [epoch: 6.42 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049154511203673375		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.049154511203673375 | validation: 0.04303859263116111]
	TIME [epoch: 6.42 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03471117502789017		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.03471117502789017 | validation: 0.044289287481290546]
	TIME [epoch: 6.43 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049961600114755755		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.049961600114755755 | validation: 0.04236263365305747]
	TIME [epoch: 6.46 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042332682121997874		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.042332682121997874 | validation: 0.04046935480152985]
	TIME [epoch: 6.46 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0374247765023972		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.0374247765023972 | validation: 0.04903756822557799]
	TIME [epoch: 6.44 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0372745642918594		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.0372745642918594 | validation: 0.04059945428275166]
	TIME [epoch: 6.45 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03483756031760968		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.03483756031760968 | validation: 0.04640193896476382]
	TIME [epoch: 6.45 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059735653263435745		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.059735653263435745 | validation: 0.041376350390672834]
	TIME [epoch: 6.46 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04103593049473436		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.04103593049473436 | validation: 0.04300199722319438]
	TIME [epoch: 6.47 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03130840559342062		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.03130840559342062 | validation: 0.034217812107062394]
	TIME [epoch: 6.46 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030821644691010088		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.030821644691010088 | validation: 0.05145885578126462]
	TIME [epoch: 6.49 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03622479131558313		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.03622479131558313 | validation: 0.05117620657795224]
	TIME [epoch: 6.47 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05483665670881195		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.05483665670881195 | validation: 0.06777942705231593]
	TIME [epoch: 6.46 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045032902944342146		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.045032902944342146 | validation: 0.05474763652890726]
	TIME [epoch: 6.45 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04433794102219852		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.04433794102219852 | validation: 0.05128299788043412]
	TIME [epoch: 6.46 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0340025606552473		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.0340025606552473 | validation: 0.03672336700317416]
	TIME [epoch: 6.46 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03465216562485843		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.03465216562485843 | validation: 0.044873716095647234]
	TIME [epoch: 6.46 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04112689653670631		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.04112689653670631 | validation: 0.08989611250544628]
	TIME [epoch: 6.49 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04471730937850375		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.04471730937850375 | validation: 0.03984487582309579]
	TIME [epoch: 6.47 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026610087173548774		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.026610087173548774 | validation: 0.05051740038752893]
	TIME [epoch: 6.46 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047057327101800876		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.047057327101800876 | validation: 0.06412673574581657]
	TIME [epoch: 6.46 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04237338398673415		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.04237338398673415 | validation: 0.05779693964037794]
	TIME [epoch: 6.47 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040796093793898466		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.040796093793898466 | validation: 0.04301882065683271]
	TIME [epoch: 6.45 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047157243413549835		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.047157243413549835 | validation: 0.04700134608432361]
	TIME [epoch: 6.47 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05096064625786715		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.05096064625786715 | validation: 0.04528491057058462]
	TIME [epoch: 6.49 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04529532334222013		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.04529532334222013 | validation: 0.06780012602740138]
	TIME [epoch: 6.46 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05103268414852617		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.05103268414852617 | validation: 0.060372598221146705]
	TIME [epoch: 6.46 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04466512966375258		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.04466512966375258 | validation: 0.061761752185602196]
	TIME [epoch: 6.46 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04313678609398061		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.04313678609398061 | validation: 0.05026021930448317]
	TIME [epoch: 6.47 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03879682329400576		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.03879682329400576 | validation: 0.03153052748262751]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1027.pth
	Model improved!!!
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04099906888520946		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.04099906888520946 | validation: 0.04749326147104654]
	TIME [epoch: 6.52 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03792278063618003		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.03792278063618003 | validation: 0.06334873793572672]
	TIME [epoch: 6.47 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07329000718583853		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.07329000718583853 | validation: 0.04190076451149434]
	TIME [epoch: 6.44 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03539917702269799		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.03539917702269799 | validation: 0.02753081251125607]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1031.pth
	Model improved!!!
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03920718165827972		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.03920718165827972 | validation: 0.04197850906376205]
	TIME [epoch: 6.5 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034948803197708246		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.034948803197708246 | validation: 0.05175360879375581]
	TIME [epoch: 6.43 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042546851814588824		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.042546851814588824 | validation: 0.06204545031506635]
	TIME [epoch: 6.42 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04899687535333351		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.04899687535333351 | validation: 0.08443432739571378]
	TIME [epoch: 6.43 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05120178816186389		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.05120178816186389 | validation: 0.05646625732457722]
	TIME [epoch: 6.49 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055325023276400355		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.055325023276400355 | validation: 0.07240366319730883]
	TIME [epoch: 6.42 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05030256729726679		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.05030256729726679 | validation: 0.047124070700344405]
	TIME [epoch: 6.44 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041846779906220835		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.041846779906220835 | validation: 0.04238045297941039]
	TIME [epoch: 6.43 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039973700209161814		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.039973700209161814 | validation: 0.05103242756034435]
	TIME [epoch: 6.44 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04233778931346055		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.04233778931346055 | validation: 0.042953136718597726]
	TIME [epoch: 6.43 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043966031007490566		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.043966031007490566 | validation: 0.06790188827055292]
	TIME [epoch: 6.44 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03577141504106456		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.03577141504106456 | validation: 0.030074227119163792]
	TIME [epoch: 6.46 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030841064404220263		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.030841064404220263 | validation: 0.04403548361139205]
	TIME [epoch: 6.47 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03216798591734429		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.03216798591734429 | validation: 0.05256563277323464]
	TIME [epoch: 6.45 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04614028914858126		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.04614028914858126 | validation: 0.03571180397685578]
	TIME [epoch: 6.45 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318271078498995		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.03318271078498995 | validation: 0.04269378661447625]
	TIME [epoch: 6.45 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03802469805690683		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.03802469805690683 | validation: 0.06677756683750377]
	TIME [epoch: 6.45 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07198575749285452		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.07198575749285452 | validation: 0.07007611382707267]
	TIME [epoch: 6.46 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06078227011774134		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.06078227011774134 | validation: 0.0549969501847791]
	TIME [epoch: 6.47 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04901846314749587		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.04901846314749587 | validation: 0.05225870287939907]
	TIME [epoch: 6.48 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04857116660467774		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.04857116660467774 | validation: 0.05446504783651821]
	TIME [epoch: 6.47 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0479737297045851		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.0479737297045851 | validation: 0.04734110613347497]
	TIME [epoch: 6.46 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05244023267719425		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.05244023267719425 | validation: 0.06216091449505916]
	TIME [epoch: 6.46 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06825186728774729		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.06825186728774729 | validation: 0.06274191331939927]
	TIME [epoch: 6.47 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059924539239088206		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.059924539239088206 | validation: 0.07463853677302418]
	TIME [epoch: 6.45 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057965392437157884		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.057965392437157884 | validation: 0.05945321591934299]
	TIME [epoch: 6.47 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04375963368103564		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.04375963368103564 | validation: 0.03368427031116023]
	TIME [epoch: 6.49 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03683985598742428		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.03683985598742428 | validation: 0.04713683895040744]
	TIME [epoch: 6.46 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03615091347433839		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.03615091347433839 | validation: 0.03792660263359448]
	TIME [epoch: 6.45 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04266382828419021		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.04266382828419021 | validation: 0.06390670193351937]
	TIME [epoch: 6.47 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058194934622182753		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.058194934622182753 | validation: 0.04717620320105256]
	TIME [epoch: 6.45 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044397804906997525		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.044397804906997525 | validation: 0.04245534157832592]
	TIME [epoch: 6.46 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042953276753877744		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.042953276753877744 | validation: 0.04219926085054381]
	TIME [epoch: 6.47 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03797970964443604		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.03797970964443604 | validation: 0.036248003678530774]
	TIME [epoch: 6.48 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04461468125902665		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.04461468125902665 | validation: 0.0697546563234212]
	TIME [epoch: 6.46 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050098112013424095		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.050098112013424095 | validation: 0.059927416042513726]
	TIME [epoch: 6.45 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044660816978357346		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.044660816978357346 | validation: 0.03217846296027404]
	TIME [epoch: 6.45 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04256684877048125		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.04256684877048125 | validation: 0.03888844402727847]
	TIME [epoch: 6.46 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0403863016697754		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.0403863016697754 | validation: 0.024553769873195734]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1070.pth
	Model improved!!!
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03463511451595156		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.03463511451595156 | validation: 0.035643262939114746]
	TIME [epoch: 6.53 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04787682110560604		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.04787682110560604 | validation: 0.04743435737364361]
	TIME [epoch: 6.47 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049826727571536944		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.049826727571536944 | validation: 0.062175957124822594]
	TIME [epoch: 6.43 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06249313968718148		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.06249313968718148 | validation: 0.07819491551815114]
	TIME [epoch: 6.41 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05363687822614387		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.05363687822614387 | validation: 0.05186733474340839]
	TIME [epoch: 6.44 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06773538670561835		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.06773538670561835 | validation: 0.060114659387834654]
	TIME [epoch: 6.42 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04268205336370313		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.04268205336370313 | validation: 0.03155184106388549]
	TIME [epoch: 6.43 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040276779638578314		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.040276779638578314 | validation: 0.03821296737297983]
	TIME [epoch: 6.44 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04007118105597531		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.04007118105597531 | validation: 0.03823002421990186]
	TIME [epoch: 6.48 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037854022508388846		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.037854022508388846 | validation: 0.04871622081370787]
	TIME [epoch: 6.44 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061059571429125395		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.061059571429125395 | validation: 0.06309632500583946]
	TIME [epoch: 6.44 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06658337730425222		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.06658337730425222 | validation: 0.06882395437771041]
	TIME [epoch: 6.44 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054970885673739214		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.054970885673739214 | validation: 0.05679148587392941]
	TIME [epoch: 6.43 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060979028059465396		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.060979028059465396 | validation: 0.06235619962046887]
	TIME [epoch: 6.45 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06632293510379508		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.06632293510379508 | validation: 0.044612562791111685]
	TIME [epoch: 6.44 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04128611237559926		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.04128611237559926 | validation: 0.05332657782653461]
	TIME [epoch: 6.49 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0337232500357456		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.0337232500357456 | validation: 0.04378150134275296]
	TIME [epoch: 6.45 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038819938640440345		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.038819938640440345 | validation: 0.04243815105374257]
	TIME [epoch: 6.44 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040702381390556465		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.040702381390556465 | validation: 0.04413552181620999]
	TIME [epoch: 6.44 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04293309411707818		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.04293309411707818 | validation: 0.0487148529135707]
	TIME [epoch: 6.46 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03630032137689125		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.03630032137689125 | validation: 0.039910811023516714]
	TIME [epoch: 6.47 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03710181243799243		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.03710181243799243 | validation: 0.06844410999579612]
	TIME [epoch: 6.47 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06440901879482505		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.06440901879482505 | validation: 0.0702266457151684]
	TIME [epoch: 6.48 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05175022863909354		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.05175022863909354 | validation: 0.06371506377563604]
	TIME [epoch: 6.47 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05742387182360373		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.05742387182360373 | validation: 0.04107195159806237]
	TIME [epoch: 6.46 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03217752656943595		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.03217752656943595 | validation: 0.040406053562110474]
	TIME [epoch: 6.47 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027870425036845652		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.027870425036845652 | validation: 0.03721197392208061]
	TIME [epoch: 6.46 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032828906047202414		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.032828906047202414 | validation: 0.041521301884284226]
	TIME [epoch: 6.47 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03465933947109682		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.03465933947109682 | validation: 0.03533198126304301]
	TIME [epoch: 6.47 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04004406438641185		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.04004406438641185 | validation: 0.05665079434396089]
	TIME [epoch: 6.49 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04746059954404863		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.04746059954404863 | validation: 0.05190184902707797]
	TIME [epoch: 6.49 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047779662470978326		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.047779662470978326 | validation: 0.05175770840046817]
	TIME [epoch: 6.46 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0451019987871816		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.0451019987871816 | validation: 0.06319575959941225]
	TIME [epoch: 6.45 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03919549583208078		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.03919549583208078 | validation: 0.0646313483671981]
	TIME [epoch: 6.46 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05078253536735172		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.05078253536735172 | validation: 0.04295421883294131]
	TIME [epoch: 6.46 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03786491384169674		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.03786491384169674 | validation: 0.05215951425220324]
	TIME [epoch: 6.46 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040240377732719455		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.040240377732719455 | validation: 0.03092763247429058]
	TIME [epoch: 6.48 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031741634282057285		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.031741634282057285 | validation: 0.04108704739407857]
	TIME [epoch: 6.49 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035355456323374924		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.035355456323374924 | validation: 0.04666468549081653]
	TIME [epoch: 6.47 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03577900378799904		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.03577900378799904 | validation: 0.051386869482526625]
	TIME [epoch: 6.45 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03362997534115375		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.03362997534115375 | validation: 0.036089180176280246]
	TIME [epoch: 6.46 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04587062822459881		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.04587062822459881 | validation: 0.05620116237032706]
	TIME [epoch: 6.45 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0442200728712182		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.0442200728712182 | validation: 0.051382119894933374]
	TIME [epoch: 6.46 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03336212115739036		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.03336212115739036 | validation: 0.039813105036647416]
	TIME [epoch: 6.46 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030862312969928335		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.030862312969928335 | validation: 0.046041703759199686]
	TIME [epoch: 6.49 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03677121195392134		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.03677121195392134 | validation: 0.04497662401044966]
	TIME [epoch: 6.46 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03564391628323051		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.03564391628323051 | validation: 0.03904352074167403]
	TIME [epoch: 6.46 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034774926937762296		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.034774926937762296 | validation: 0.04093834447142206]
	TIME [epoch: 6.45 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03378955725058815		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.03378955725058815 | validation: 0.03530594390511764]
	TIME [epoch: 6.46 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04597648769188907		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.04597648769188907 | validation: 0.06504440472006859]
	TIME [epoch: 6.47 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04463207155681228		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.04463207155681228 | validation: 0.05213095584890681]
	TIME [epoch: 6.46 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03453714377564449		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.03453714377564449 | validation: 0.06129734363513503]
	TIME [epoch: 6.49 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05054603262126674		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.05054603262126674 | validation: 0.0479169562739439]
	TIME [epoch: 6.47 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030812456118229362		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.030812456118229362 | validation: 0.039738453850115193]
	TIME [epoch: 6.45 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033767175917849584		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.033767175917849584 | validation: 0.0509396269737975]
	TIME [epoch: 6.46 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04306614420192482		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.04306614420192482 | validation: 0.04858050673976992]
	TIME [epoch: 6.45 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044776056528508024		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.044776056528508024 | validation: 0.05206637358268969]
	TIME [epoch: 6.46 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04275105467250786		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.04275105467250786 | validation: 0.05347703958551561]
	TIME [epoch: 6.45 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050420012282123464		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.050420012282123464 | validation: 0.049054359354994886]
	TIME [epoch: 6.49 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04367288279469448		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.04367288279469448 | validation: 0.07003267961343808]
	TIME [epoch: 6.46 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05273120989405245		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.05273120989405245 | validation: 0.053790553848008196]
	TIME [epoch: 6.46 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043036457704164796		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.043036457704164796 | validation: 0.04655691255717985]
	TIME [epoch: 6.46 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043396335969291405		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.043396335969291405 | validation: 0.06698224256682556]
	TIME [epoch: 6.45 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04964739112126865		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.04964739112126865 | validation: 0.06487258673587032]
	TIME [epoch: 6.46 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04962551250619603		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.04962551250619603 | validation: 0.05572262261400393]
	TIME [epoch: 6.45 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04887595188308655		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.04887595188308655 | validation: 0.07564213966899896]
	TIME [epoch: 6.5 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05767821637594912		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.05767821637594912 | validation: 0.06560340036740703]
	TIME [epoch: 6.46 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04360388561842739		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.04360388561842739 | validation: 0.0546527423698994]
	TIME [epoch: 6.46 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038392538091716985		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.038392538091716985 | validation: 0.05033569606165616]
	TIME [epoch: 6.46 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05910272330420937		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.05910272330420937 | validation: 0.042340665615874365]
	TIME [epoch: 6.46 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034851446408715826		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.034851446408715826 | validation: 0.03855736759092432]
	TIME [epoch: 6.46 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035865254915847716		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.035865254915847716 | validation: 0.05167515709576548]
	TIME [epoch: 6.45 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04189814989843766		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.04189814989843766 | validation: 0.07655542039572182]
	TIME [epoch: 6.48 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06133020961322839		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.06133020961322839 | validation: 0.07137688761063958]
	TIME [epoch: 6.48 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0501865798779602		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.0501865798779602 | validation: 0.0561279378780719]
	TIME [epoch: 6.47 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04183561229645176		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.04183561229645176 | validation: 0.0494075933374822]
	TIME [epoch: 6.46 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03168992013855044		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.03168992013855044 | validation: 0.037496729028275666]
	TIME [epoch: 6.47 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03581651694212318		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.03581651694212318 | validation: 0.04022082995529694]
	TIME [epoch: 6.45 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028502565090359835		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.028502565090359835 | validation: 0.04345304790378375]
	TIME [epoch: 6.45 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03477364104452452		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.03477364104452452 | validation: 0.04140413936335376]
	TIME [epoch: 6.46 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03323481203166701		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.03323481203166701 | validation: 0.030699128434849725]
	TIME [epoch: 6.44 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02998065132756315		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.02998065132756315 | validation: 0.03822978382640359]
	TIME [epoch: 6.44 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03491824736643642		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.03491824736643642 | validation: 0.04460581232254165]
	TIME [epoch: 6.44 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030546141414497574		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.030546141414497574 | validation: 0.037678993070232245]
	TIME [epoch: 6.43 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035748335687353916		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.035748335687353916 | validation: 0.03574720859848002]
	TIME [epoch: 6.42 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0309479997076181		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.0309479997076181 | validation: 0.04556422396871193]
	TIME [epoch: 6.42 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041398205331145736		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.041398205331145736 | validation: 0.043026352569338185]
	TIME [epoch: 6.42 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032759154606828336		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.032759154606828336 | validation: 0.033562008980981]
	TIME [epoch: 6.48 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025319036230831225		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.025319036230831225 | validation: 0.03558147069273309]
	TIME [epoch: 6.42 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02967698957083814		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.02967698957083814 | validation: 0.04424517253083632]
	TIME [epoch: 6.42 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04071037074648457		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.04071037074648457 | validation: 0.051369012805110546]
	TIME [epoch: 6.42 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04983952991328065		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.04983952991328065 | validation: 0.04920648717437834]
	TIME [epoch: 6.43 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036605860718583356		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.036605860718583356 | validation: 0.06221066346276183]
	TIME [epoch: 6.41 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03787840607003415		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.03787840607003415 | validation: 0.0401687048250938]
	TIME [epoch: 6.44 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03626044284225501		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.03626044284225501 | validation: 0.03530205161403877]
	TIME [epoch: 6.47 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03458817029871894		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.03458817029871894 | validation: 0.040993380414566384]
	TIME [epoch: 6.43 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02560438499420307		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.02560438499420307 | validation: 0.03371815643499966]
	TIME [epoch: 6.43 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023575729408371732		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.023575729408371732 | validation: 0.032627408662663]
	TIME [epoch: 6.43 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030311630620899848		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.030311630620899848 | validation: 0.04311570890498678]
	TIME [epoch: 6.43 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033018492701269476		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.033018492701269476 | validation: 0.03444939050308281]
	TIME [epoch: 6.45 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033399227594444324		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.033399227594444324 | validation: 0.04605459558442917]
	TIME [epoch: 6.44 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03587743139995836		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.03587743139995836 | validation: 0.05195592904664891]
	TIME [epoch: 6.5 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035273912777455875		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.035273912777455875 | validation: 0.03690596757404869]
	TIME [epoch: 6.44 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031113104003484153		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.031113104003484153 | validation: 0.04728366721063068]
	TIME [epoch: 6.45 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032722370465244704		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.032722370465244704 | validation: 0.04145686550987985]
	TIME [epoch: 6.46 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028904531324596968		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.028904531324596968 | validation: 0.028467026145287413]
	TIME [epoch: 6.46 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02504277706038803		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.02504277706038803 | validation: 0.03699652728037904]
	TIME [epoch: 6.45 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03662872708632281		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.03662872708632281 | validation: 0.05499871624260628]
	TIME [epoch: 6.45 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040526420497502845		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.040526420497502845 | validation: 0.03467662714178076]
	TIME [epoch: 6.5 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03204005257060099		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.03204005257060099 | validation: 0.03341985299098099]
	TIME [epoch: 6.46 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03490732382221197		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.03490732382221197 | validation: 0.038796304446645995]
	TIME [epoch: 6.46 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030955532362872566		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.030955532362872566 | validation: 0.04686106253056252]
	TIME [epoch: 6.47 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03442532661829738		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.03442532661829738 | validation: 0.03374380004278029]
	TIME [epoch: 6.47 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028787878292110654		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.028787878292110654 | validation: 0.03812319288586069]
	TIME [epoch: 6.45 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04127089882124469		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.04127089882124469 | validation: 0.043504679724939176]
	TIME [epoch: 6.45 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044229534049032744		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.044229534049032744 | validation: 0.030830954435538026]
	TIME [epoch: 6.47 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03170257750821145		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.03170257750821145 | validation: 0.03540694811861441]
	TIME [epoch: 6.49 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027254818512607068		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.027254818512607068 | validation: 0.04984698446602862]
	TIME [epoch: 6.45 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04187870895551938		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.04187870895551938 | validation: 0.0652709297956951]
	TIME [epoch: 6.46 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04320247406498877		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.04320247406498877 | validation: 0.05064183350933662]
	TIME [epoch: 6.47 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03272114075539719		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.03272114075539719 | validation: 0.04818483362700011]
	TIME [epoch: 6.45 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03497125712219086		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.03497125712219086 | validation: 0.043984284583847406]
	TIME [epoch: 6.45 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566916321902844		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.03566916321902844 | validation: 0.05151450920348543]
	TIME [epoch: 6.47 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03391482130945548		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.03391482130945548 | validation: 0.04604776827263876]
	TIME [epoch: 6.48 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03243688635091279		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.03243688635091279 | validation: 0.039211433781845904]
	TIME [epoch: 6.45 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031240827879789317		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.031240827879789317 | validation: 0.03896475050501217]
	TIME [epoch: 6.45 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025704427666268903		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.025704427666268903 | validation: 0.028116009368062824]
	TIME [epoch: 6.45 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03454160957068934		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.03454160957068934 | validation: 0.049227091701235376]
	TIME [epoch: 6.44 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03416534977217232		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.03416534977217232 | validation: 0.033429732588778675]
	TIME [epoch: 6.45 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03241934261008668		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.03241934261008668 | validation: 0.04089425626645871]
	TIME [epoch: 6.45 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03857321245593887		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.03857321245593887 | validation: 0.04210869271035657]
	TIME [epoch: 6.5 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031835936407775274		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.031835936407775274 | validation: 0.03327041523858889]
	TIME [epoch: 6.46 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03578011716100123		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.03578011716100123 | validation: 0.03553785164276114]
	TIME [epoch: 6.45 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047383224094991835		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.047383224094991835 | validation: 0.043893197401307156]
	TIME [epoch: 6.45 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04022530814852052		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.04022530814852052 | validation: 0.033834913229057115]
	TIME [epoch: 6.45 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03244612326820878		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.03244612326820878 | validation: 0.04464587428787509]
	TIME [epoch: 6.45 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03870751817466836		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.03870751817466836 | validation: 0.04763527153684564]
	TIME [epoch: 6.46 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05364323940754514		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.05364323940754514 | validation: 0.04516620353369702]
	TIME [epoch: 6.48 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037384867679390296		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.037384867679390296 | validation: 0.04103261160106147]
	TIME [epoch: 6.45 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03508201774547684		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.03508201774547684 | validation: 0.03882777630444305]
	TIME [epoch: 6.45 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0404154741994863		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.0404154741994863 | validation: 0.050753305840953174]
	TIME [epoch: 6.44 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03538442076943052		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.03538442076943052 | validation: 0.036662589733322266]
	TIME [epoch: 6.44 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03397163086111961		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.03397163086111961 | validation: 0.034019278768959514]
	TIME [epoch: 6.45 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03359091726348946		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.03359091726348946 | validation: 0.03995951165388899]
	TIME [epoch: 6.44 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03024999464193453		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.03024999464193453 | validation: 0.0402841817382229]
	TIME [epoch: 6.48 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027345031615974354		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.027345031615974354 | validation: 0.030573960907152184]
	TIME [epoch: 6.45 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032221109335255356		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.032221109335255356 | validation: 0.04037870151447367]
	TIME [epoch: 6.45 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595114418112899		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.03595114418112899 | validation: 0.03200551125550852]
	TIME [epoch: 6.46 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031225716240453713		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.031225716240453713 | validation: 0.03278179422817324]
	TIME [epoch: 6.43 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030617717627497962		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.030617717627497962 | validation: 0.023586668931600583]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1220.pth
	Model improved!!!
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030359274565132342		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.030359274565132342 | validation: 0.036822624144427225]
	TIME [epoch: 6.51 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03471819720165847		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.03471819720165847 | validation: 0.041924384069110816]
	TIME [epoch: 6.47 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03251526330640941		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.03251526330640941 | validation: 0.05958637622161169]
	TIME [epoch: 6.44 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0487457675819517		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.0487457675819517 | validation: 0.07009733097819125]
	TIME [epoch: 6.44 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043010540105942595		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.043010540105942595 | validation: 0.05543020281949484]
	TIME [epoch: 6.47 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038156811875519905		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.038156811875519905 | validation: 0.04377642726849566]
	TIME [epoch: 6.45 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03297304955782758		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.03297304955782758 | validation: 0.047389464150393135]
	TIME [epoch: 6.45 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03860996092907714		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.03860996092907714 | validation: 0.035533373257336756]
	TIME [epoch: 6.45 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026721178349926503		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.026721178349926503 | validation: 0.03374572497196963]
	TIME [epoch: 6.48 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031063105020088952		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.031063105020088952 | validation: 0.040786665350278944]
	TIME [epoch: 6.46 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027915550500181935		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.027915550500181935 | validation: 0.041846793264576666]
	TIME [epoch: 6.46 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03493223665649207		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.03493223665649207 | validation: 0.059633645747929176]
	TIME [epoch: 6.46 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03234978896070144		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.03234978896070144 | validation: 0.03995557894434611]
	TIME [epoch: 6.46 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036341996931466516		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.036341996931466516 | validation: 0.04186402429407365]
	TIME [epoch: 6.46 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03289158978337703		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.03289158978337703 | validation: 0.041211865826138644]
	TIME [epoch: 6.46 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028469286307938463		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.028469286307938463 | validation: 0.03669027838988467]
	TIME [epoch: 6.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029585899565430576		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.029585899565430576 | validation: 0.03382620404979769]
	TIME [epoch: 6.47 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0283029867067433		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.0283029867067433 | validation: 0.03479730288171504]
	TIME [epoch: 6.47 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03243176119574001		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.03243176119574001 | validation: 0.030675267786856364]
	TIME [epoch: 6.47 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03862061038785054		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.03862061038785054 | validation: 0.0390499210486788]
	TIME [epoch: 6.47 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031767227511148494		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.031767227511148494 | validation: 0.0397027306596934]
	TIME [epoch: 6.47 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03600711325243981		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.03600711325243981 | validation: 0.036892343056570874]
	TIME [epoch: 6.46 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038546184051687325		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.038546184051687325 | validation: 0.04572563190479574]
	TIME [epoch: 6.48 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04186215015655332		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.04186215015655332 | validation: 0.045815749918475694]
	TIME [epoch: 6.48 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03930349186122563		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.03930349186122563 | validation: 0.036585286579267344]
	TIME [epoch: 6.47 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03707791823892548		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.03707791823892548 | validation: 0.04285678865814539]
	TIME [epoch: 6.46 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03538742164368345		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.03538742164368345 | validation: 0.03422959955927902]
	TIME [epoch: 6.46 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027862957356775454		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.027862957356775454 | validation: 0.02406412629577765]
	TIME [epoch: 6.46 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024715711143583625		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.024715711143583625 | validation: 0.029438163162269104]
	TIME [epoch: 6.46 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026966822365577344		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.026966822365577344 | validation: 0.028760983709371676]
	TIME [epoch: 6.48 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029750560450975537		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.029750560450975537 | validation: 0.03006816783480357]
	TIME [epoch: 6.48 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030863030479771923		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.030863030479771923 | validation: 0.029597627297212638]
	TIME [epoch: 6.47 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03670741869215126		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.03670741869215126 | validation: 0.036806619770132123]
	TIME [epoch: 6.47 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02785251277246666		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.02785251277246666 | validation: 0.03350139778742363]
	TIME [epoch: 6.47 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03116991288013924		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.03116991288013924 | validation: 0.03819119025162678]
	TIME [epoch: 6.47 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031464049956725144		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.031464049956725144 | validation: 0.03471396739471853]
	TIME [epoch: 6.47 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03231363948906374		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.03231363948906374 | validation: 0.03632297918286008]
	TIME [epoch: 6.48 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03284926111382072		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.03284926111382072 | validation: 0.03270670964286526]
	TIME [epoch: 6.51 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029081171776432935		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.029081171776432935 | validation: 0.0379228079670208]
	TIME [epoch: 6.48 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034734759135704424		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.034734759135704424 | validation: 0.03572083211178361]
	TIME [epoch: 6.48 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03461256748378617		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.03461256748378617 | validation: 0.02309178103213946]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1261.pth
	Model improved!!!
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034990538975121124		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.034990538975121124 | validation: 0.03490186385978007]
	TIME [epoch: 6.53 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03560102916909757		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.03560102916909757 | validation: 0.029909943234119312]
	TIME [epoch: 6.45 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02909048349908766		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.02909048349908766 | validation: 0.03203856591972181]
	TIME [epoch: 6.46 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029137395753561553		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.029137395753561553 | validation: 0.028875199123527616]
	TIME [epoch: 6.48 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025469929068714238		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.025469929068714238 | validation: 0.03514498233790629]
	TIME [epoch: 6.45 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02987409411792819		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.02987409411792819 | validation: 0.02607954912228645]
	TIME [epoch: 6.46 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023019303306422236		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.023019303306422236 | validation: 0.030180672503865563]
	TIME [epoch: 6.46 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030734542809974633		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.030734542809974633 | validation: 0.025621511914827103]
	TIME [epoch: 6.46 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027401141503424223		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.027401141503424223 | validation: 0.030543113079605905]
	TIME [epoch: 6.46 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026176175944270325		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.026176175944270325 | validation: 0.039672667165542366]
	TIME [epoch: 6.47 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025191909157989086		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.025191909157989086 | validation: 0.03098417805355424]
	TIME [epoch: 6.5 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03148007812765238		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.03148007812765238 | validation: 0.029771424559770818]
	TIME [epoch: 6.48 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03535833691971547		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.03535833691971547 | validation: 0.0416527486356036]
	TIME [epoch: 6.47 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03411013629074977		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.03411013629074977 | validation: 0.046169247755498403]
	TIME [epoch: 6.46 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0346299473827668		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.0346299473827668 | validation: 0.053775496879333064]
	TIME [epoch: 6.46 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0354309815451735		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.0354309815451735 | validation: 0.04089223910934635]
	TIME [epoch: 6.47 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038993520838455434		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.038993520838455434 | validation: 0.05382957357762447]
	TIME [epoch: 6.47 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03638542655240456		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.03638542655240456 | validation: 0.050819960680343924]
	TIME [epoch: 6.51 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038164202365836744		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.038164202365836744 | validation: 0.042747282230926074]
	TIME [epoch: 6.47 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033974822265191836		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.033974822265191836 | validation: 0.03622381167475334]
	TIME [epoch: 6.47 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02629728774991847		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.02629728774991847 | validation: 0.032183914811637244]
	TIME [epoch: 6.47 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0338100236395484		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.0338100236395484 | validation: 0.028244531474536098]
	TIME [epoch: 6.47 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028754794374341038		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.028754794374341038 | validation: 0.031176353252086276]
	TIME [epoch: 6.47 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029846917872217688		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.029846917872217688 | validation: 0.02701582819481531]
	TIME [epoch: 6.47 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03313349475104969		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.03313349475104969 | validation: 0.03132699509367714]
	TIME [epoch: 6.5 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03438046478799892		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.03438046478799892 | validation: 0.028455168575224878]
	TIME [epoch: 6.48 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025734396997803687		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.025734396997803687 | validation: 0.029424350519581255]
	TIME [epoch: 6.47 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028462926382575193		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.028462926382575193 | validation: 0.03088712208538274]
	TIME [epoch: 6.48 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03325750599768959		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.03325750599768959 | validation: 0.029749939486234594]
	TIME [epoch: 6.48 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03277313620868245		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.03277313620868245 | validation: 0.033666906076381106]
	TIME [epoch: 6.47 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0328971240158677		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.0328971240158677 | validation: 0.02772750160827308]
	TIME [epoch: 6.48 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03136292712698305		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.03136292712698305 | validation: 0.03010749939062394]
	TIME [epoch: 6.51 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03317446763850096		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.03317446763850096 | validation: 0.034337079129355956]
	TIME [epoch: 6.48 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029202963444001813		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.029202963444001813 | validation: 0.03647915615783095]
	TIME [epoch: 6.48 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02994475680713202		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.02994475680713202 | validation: 0.030463431333240632]
	TIME [epoch: 6.48 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02310276114540548		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.02310276114540548 | validation: 0.02666122469115833]
	TIME [epoch: 6.48 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02589593691725074		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.02589593691725074 | validation: 0.037753457498009]
	TIME [epoch: 6.48 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026576718597466863		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.026576718597466863 | validation: 0.03886193295946514]
	TIME [epoch: 6.48 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03538199721189525		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.03538199721189525 | validation: 0.030598099114319877]
	TIME [epoch: 6.49 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03476770111251076		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.03476770111251076 | validation: 0.043492997075131525]
	TIME [epoch: 6.49 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030719221153800255		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.030719221153800255 | validation: 0.03676951500517347]
	TIME [epoch: 6.47 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029605268342298097		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.029605268342298097 | validation: 0.0355119500336628]
	TIME [epoch: 6.47 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025365848935322167		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.025365848935322167 | validation: 0.024592331304118524]
	TIME [epoch: 6.47 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.034334177258785466		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.034334177258785466 | validation: 0.04393405046494072]
	TIME [epoch: 6.47 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041527972869255886		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.041527972869255886 | validation: 0.03955195156932988]
	TIME [epoch: 6.47 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0304478163231678		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.0304478163231678 | validation: 0.03513470070167612]
	TIME [epoch: 6.53 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024678759301276415		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.024678759301276415 | validation: 0.022857288054536955]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1308.pth
	Model improved!!!
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026931749035416386		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.026931749035416386 | validation: 0.02360465195227012]
	TIME [epoch: 6.46 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028671592535610413		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.028671592535610413 | validation: 0.024153501259700155]
	TIME [epoch: 6.47 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033497921724811995		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.033497921724811995 | validation: 0.03367590596074812]
	TIME [epoch: 6.46 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03360082744272813		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.03360082744272813 | validation: 0.03998246844684157]
	TIME [epoch: 6.47 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03281805148205575		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.03281805148205575 | validation: 0.03772335554950543]
	TIME [epoch: 6.47 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0303478352218684		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.0303478352218684 | validation: 0.035686631024710806]
	TIME [epoch: 6.49 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023538920544978543		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.023538920544978543 | validation: 0.04199677787475973]
	TIME [epoch: 6.49 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027226665880265892		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.027226665880265892 | validation: 0.029901733606428067]
	TIME [epoch: 6.46 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025743602795272665		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.025743602795272665 | validation: 0.037350846302564085]
	TIME [epoch: 6.46 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030226898660522902		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.030226898660522902 | validation: 0.04180141773135485]
	TIME [epoch: 6.45 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03225995842465626		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.03225995842465626 | validation: 0.03804318119727097]
	TIME [epoch: 6.46 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03818057889589604		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.03818057889589604 | validation: 0.04367703528603444]
	TIME [epoch: 6.46 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03073162423426849		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.03073162423426849 | validation: 0.024764414927891158]
	TIME [epoch: 6.47 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028325934665082222		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.028325934665082222 | validation: 0.03130089902314325]
	TIME [epoch: 6.49 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02746709476034953		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.02746709476034953 | validation: 0.027002752974691773]
	TIME [epoch: 6.47 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025903466960898243		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.025903466960898243 | validation: 0.03552737225947096]
	TIME [epoch: 6.49 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033625519826253364		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.033625519826253364 | validation: 0.029765457277832974]
	TIME [epoch: 6.47 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026906902448853957		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.026906902448853957 | validation: 0.03431363809853634]
	TIME [epoch: 6.48 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03026142531876676		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.03026142531876676 | validation: 0.03450206218105495]
	TIME [epoch: 6.47 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026577543982799566		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.026577543982799566 | validation: 0.026175779738460955]
	TIME [epoch: 6.48 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026427609394687874		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.026427609394687874 | validation: 0.040487400834214766]
	TIME [epoch: 6.5 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03217171845123705		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.03217171845123705 | validation: 0.03160345290436678]
	TIME [epoch: 6.48 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03612090210449741		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.03612090210449741 | validation: 0.040639208946251226]
	TIME [epoch: 6.47 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03709121909846224		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.03709121909846224 | validation: 0.03911308131782381]
	TIME [epoch: 6.47 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03228271277724197		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.03228271277724197 | validation: 0.030133014776895388]
	TIME [epoch: 6.47 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03318800724260611		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.03318800724260611 | validation: 0.046131918427781686]
	TIME [epoch: 6.48 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026757208383035996		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.026757208383035996 | validation: 0.02396723614559952]
	TIME [epoch: 6.48 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03143199346827229		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.03143199346827229 | validation: 0.034672435299343274]
	TIME [epoch: 6.52 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029763304026387747		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.029763304026387747 | validation: 0.030041069886596904]
	TIME [epoch: 6.48 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0287368555454035		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.0287368555454035 | validation: 0.0358837023601638]
	TIME [epoch: 6.47 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030683953457726162		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.030683953457726162 | validation: 0.029060649638233994]
	TIME [epoch: 6.47 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02798427885001964		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.02798427885001964 | validation: 0.03993266564370261]
	TIME [epoch: 6.47 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030956985027758666		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.030956985027758666 | validation: 0.03611294205518504]
	TIME [epoch: 6.48 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028875253580426957		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.028875253580426957 | validation: 0.04276141109169319]
	TIME [epoch: 6.47 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031865917049137674		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.031865917049137674 | validation: 0.04674475948285578]
	TIME [epoch: 6.51 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033466081041533556		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.033466081041533556 | validation: 0.044532043333752006]
	TIME [epoch: 6.47 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02997378920753341		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.02997378920753341 | validation: 0.03546720026799097]
	TIME [epoch: 6.47 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032501853929152835		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.032501853929152835 | validation: 0.028997346468070548]
	TIME [epoch: 6.47 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0278759959282298		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.0278759959282298 | validation: 0.033463515146925346]
	TIME [epoch: 6.47 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027179498112223248		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.027179498112223248 | validation: 0.037317009791952765]
	TIME [epoch: 6.47 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03127926292738739		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.03127926292738739 | validation: 0.04066325712703575]
	TIME [epoch: 6.46 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933056823845018		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.02933056823845018 | validation: 0.03259155108451133]
	TIME [epoch: 6.48 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033373362872942444		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.033373362872942444 | validation: 0.03705646445794355]
	TIME [epoch: 6.45 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03449092977610516		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.03449092977610516 | validation: 0.042089431088771966]
	TIME [epoch: 6.44 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027704256406759952		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.027704256406759952 | validation: 0.03814641876161713]
	TIME [epoch: 6.43 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026616394338087258		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.026616394338087258 | validation: 0.030904160213364267]
	TIME [epoch: 6.43 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02987112695046819		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.02987112695046819 | validation: 0.03497023428554642]
	TIME [epoch: 6.43 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0271919574121966		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.0271919574121966 | validation: 0.024836336308180114]
	TIME [epoch: 6.43 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03348861857876879		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.03348861857876879 | validation: 0.03920122350916805]
	TIME [epoch: 6.45 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03538604042079756		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.03538604042079756 | validation: 0.04091211268978213]
	TIME [epoch: 6.44 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485171275307013		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.03485171275307013 | validation: 0.03478789131320318]
	TIME [epoch: 6.42 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03532481061725076		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.03532481061725076 | validation: 0.039122231908244334]
	TIME [epoch: 6.43 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02904287674008041		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.02904287674008041 | validation: 0.03183925197607874]
	TIME [epoch: 6.44 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026101185331282806		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.026101185331282806 | validation: 0.03843037608744059]
	TIME [epoch: 6.43 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02416584117526901		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.02416584117526901 | validation: 0.036541886862801506]
	TIME [epoch: 6.44 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029656549203754844		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.029656549203754844 | validation: 0.03104372163052937]
	TIME [epoch: 6.46 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031175550121227913		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.031175550121227913 | validation: 0.04632518822583369]
	TIME [epoch: 6.46 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029886617561729438		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.029886617561729438 | validation: 0.03558726357462273]
	TIME [epoch: 6.44 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02713063713657037		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.02713063713657037 | validation: 0.03640721060770726]
	TIME [epoch: 6.44 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031046342460247546		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.031046342460247546 | validation: 0.02826518791507456]
	TIME [epoch: 6.44 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0267989356867499		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.0267989356867499 | validation: 0.0353688544975474]
	TIME [epoch: 6.44 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024456989745446876		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.024456989745446876 | validation: 0.030525059156780082]
	TIME [epoch: 6.44 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027493845949060493		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.027493845949060493 | validation: 0.03513426246488902]
	TIME [epoch: 6.45 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02527240836339201		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.02527240836339201 | validation: 0.04252986304158099]
	TIME [epoch: 6.47 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03286035534513849		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.03286035534513849 | validation: 0.03545142042984272]
	TIME [epoch: 6.45 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026176526918497693		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.026176526918497693 | validation: 0.039517895999110875]
	TIME [epoch: 6.45 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02647361335520323		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.02647361335520323 | validation: 0.03544519865091577]
	TIME [epoch: 6.45 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02419745946788284		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.02419745946788284 | validation: 0.02791324578355698]
	TIME [epoch: 6.45 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022106649307688114		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.022106649307688114 | validation: 0.03928669059982049]
	TIME [epoch: 6.45 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02651349598444718		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.02651349598444718 | validation: 0.03960312295001321]
	TIME [epoch: 6.46 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02977471624452877		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.02977471624452877 | validation: 0.05062336488256361]
	TIME [epoch: 6.49 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029563168221973232		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.029563168221973232 | validation: 0.03760766230301239]
	TIME [epoch: 6.46 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024961961447536003		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.024961961447536003 | validation: 0.03683323503809359]
	TIME [epoch: 6.46 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030087569102287406		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.030087569102287406 | validation: 0.037513704772324775]
	TIME [epoch: 6.47 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02744767497583445		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.02744767497583445 | validation: 0.03458347098679991]
	TIME [epoch: 6.46 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022929271296907326		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.022929271296907326 | validation: 0.030271872764992463]
	TIME [epoch: 6.47 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02858917583099041		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.02858917583099041 | validation: 0.03840109681615388]
	TIME [epoch: 6.48 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02310916392495707		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.02310916392495707 | validation: 0.045203639109771786]
	TIME [epoch: 6.51 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024745833653112108		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.024745833653112108 | validation: 0.03666061835219502]
	TIME [epoch: 6.48 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025776534298348114		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.025776534298348114 | validation: 0.037486653840087064]
	TIME [epoch: 6.48 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02764682593310772		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.02764682593310772 | validation: 0.026085436641897393]
	TIME [epoch: 6.48 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02473445299111343		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.02473445299111343 | validation: 0.031054214622222017]
	TIME [epoch: 6.48 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023780597434872288		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.023780597434872288 | validation: 0.029766028589697787]
	TIME [epoch: 6.47 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02476688515846534		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.02476688515846534 | validation: 0.034949528852778536]
	TIME [epoch: 6.48 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02991031437499078		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.02991031437499078 | validation: 0.02970326505431659]
	TIME [epoch: 6.52 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023855384415685972		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.023855384415685972 | validation: 0.02755558135721481]
	TIME [epoch: 6.48 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02608796376361909		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.02608796376361909 | validation: 0.03738115304171161]
	TIME [epoch: 6.48 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02244585132414838		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.02244585132414838 | validation: 0.034942212943212744]
	TIME [epoch: 6.47 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02329045658589447		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.02329045658589447 | validation: 0.031844835742057376]
	TIME [epoch: 6.48 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027821023081234558		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.027821023081234558 | validation: 0.0331575093141555]
	TIME [epoch: 6.47 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025571499263301975		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.025571499263301975 | validation: 0.025505936221818005]
	TIME [epoch: 6.47 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02701020440204471		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.02701020440204471 | validation: 0.0331292890958227]
	TIME [epoch: 6.5 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026486163562514563		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.026486163562514563 | validation: 0.030989388375440605]
	TIME [epoch: 6.47 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022725180492621372		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.022725180492621372 | validation: 0.028977107299446282]
	TIME [epoch: 6.47 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022613562304880687		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.022613562304880687 | validation: 0.028319758939842343]
	TIME [epoch: 6.47 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023364928466839005		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.023364928466839005 | validation: 0.03042975081770514]
	TIME [epoch: 6.47 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025192749524712163		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.025192749524712163 | validation: 0.03740817243638798]
	TIME [epoch: 6.47 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02834852169295634		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.02834852169295634 | validation: 0.029173758937215643]
	TIME [epoch: 6.48 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03388081335752773		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.03388081335752773 | validation: 0.025625095609031673]
	TIME [epoch: 6.49 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02681707894375565		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.02681707894375565 | validation: 0.027727202634117577]
	TIME [epoch: 6.49 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025162074685684932		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.025162074685684932 | validation: 0.027296852566450217]
	TIME [epoch: 6.47 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02879508899925958		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.02879508899925958 | validation: 0.033261579672335964]
	TIME [epoch: 6.47 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02836734957954857		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.02836734957954857 | validation: 0.02777528742892838]
	TIME [epoch: 6.47 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02772428113659413		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.02772428113659413 | validation: 0.029341034105213534]
	TIME [epoch: 6.47 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02650547491351484		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.02650547491351484 | validation: 0.029943261759073626]
	TIME [epoch: 6.47 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028974347065933596		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.028974347065933596 | validation: 0.03297765671186054]
	TIME [epoch: 6.49 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025706539846145286		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.025706539846145286 | validation: 0.02923575371777858]
	TIME [epoch: 6.49 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026481209000701052		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.026481209000701052 | validation: 0.03628872575663333]
	TIME [epoch: 6.47 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02708778987050764		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.02708778987050764 | validation: 0.0310992854395868]
	TIME [epoch: 6.47 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022625633237137076		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.022625633237137076 | validation: 0.022421766753810322]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1418.pth
	Model improved!!!
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024266545507732353		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.024266545507732353 | validation: 0.025772213545427563]
	TIME [epoch: 6.54 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024108319175832223		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.024108319175832223 | validation: 0.033936651137804204]
	TIME [epoch: 6.44 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027356067185857254		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.027356067185857254 | validation: 0.027528559284246905]
	TIME [epoch: 6.46 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02837846971225492		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.02837846971225492 | validation: 0.028389382476315818]
	TIME [epoch: 6.46 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024712378652833832		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.024712378652833832 | validation: 0.02744610364087171]
	TIME [epoch: 6.45 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024299357606026008		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.024299357606026008 | validation: 0.022949685927909257]
	TIME [epoch: 6.45 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02575456127611564		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.02575456127611564 | validation: 0.022287310320968468]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1425.pth
	Model improved!!!
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026724378071350315		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.026724378071350315 | validation: 0.028780145788652685]
	TIME [epoch: 6.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02398940259811724		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.02398940259811724 | validation: 0.036243067290456996]
	TIME [epoch: 6.43 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026606086402032166		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.026606086402032166 | validation: 0.033979613469581935]
	TIME [epoch: 6.45 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029352353378049048		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.029352353378049048 | validation: 0.04097531569869136]
	TIME [epoch: 6.44 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03048434946673085		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.03048434946673085 | validation: 0.03516120532346693]
	TIME [epoch: 6.44 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027543658559774954		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.027543658559774954 | validation: 0.03127207715166649]
	TIME [epoch: 6.43 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026806825415255114		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.026806825415255114 | validation: 0.04061639580066376]
	TIME [epoch: 6.44 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025113870476725374		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.025113870476725374 | validation: 0.024545345243028455]
	TIME [epoch: 6.44 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02211673979347363		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.02211673979347363 | validation: 0.022197188658255044]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1434.pth
	Model improved!!!
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02693931965027152		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.02693931965027152 | validation: 0.02824193831179817]
	TIME [epoch: 6.51 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026506634771643243		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.026506634771643243 | validation: 0.03430648834636116]
	TIME [epoch: 6.45 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023725529147635312		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.023725529147635312 | validation: 0.028956922062494814]
	TIME [epoch: 6.43 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023875228763716668		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.023875228763716668 | validation: 0.02763087796300057]
	TIME [epoch: 6.43 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029728002456470216		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.029728002456470216 | validation: 0.046689432015680314]
	TIME [epoch: 6.44 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0318947318668195		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.0318947318668195 | validation: 0.043360051154425365]
	TIME [epoch: 6.45 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03665331921713811		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.03665331921713811 | validation: 0.04675830081266305]
	TIME [epoch: 6.43 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03496790079608618		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.03496790079608618 | validation: 0.03595466375864473]
	TIME [epoch: 6.44 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02905569641252132		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.02905569641252132 | validation: 0.040824185106982845]
	TIME [epoch: 6.46 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03018977071353173		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.03018977071353173 | validation: 0.0462263388366377]
	TIME [epoch: 6.49 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02772910328762912		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.02772910328762912 | validation: 0.04479675840660081]
	TIME [epoch: 6.44 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033794775299979464		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.033794775299979464 | validation: 0.050526337079597]
	TIME [epoch: 6.44 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031920404345405065		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.031920404345405065 | validation: 0.04738597074438504]
	TIME [epoch: 6.44 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02615224054999072		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.02615224054999072 | validation: 0.03814666249390924]
	TIME [epoch: 6.44 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01976023554742637		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.01976023554742637 | validation: 0.021560685591898197]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1449.pth
	Model improved!!!
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022989688800156134		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.022989688800156134 | validation: 0.028968841591916882]
	TIME [epoch: 6.54 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021912539021072933		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.021912539021072933 | validation: 0.03196416762951193]
	TIME [epoch: 6.44 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027119895816715762		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.027119895816715762 | validation: 0.018083355805040186]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r0_20240309_135700/states/model_tr_study1_1452.pth
	Model improved!!!
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024260903872477688		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.024260903872477688 | validation: 0.03986399595440365]
	TIME [epoch: 6.52 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025240690193633484		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.025240690193633484 | validation: 0.023638646015956034]
	TIME [epoch: 6.43 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028597302615296343		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.028597302615296343 | validation: 0.03766377812808307]
	TIME [epoch: 6.42 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02754903479434875		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.02754903479434875 | validation: 0.028022034375036788]
	TIME [epoch: 6.44 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02365927845961193		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.02365927845961193 | validation: 0.02503211687034142]
	TIME [epoch: 6.46 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02495911151108758		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.02495911151108758 | validation: 0.023487772656616612]
	TIME [epoch: 6.43 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02653673051054555		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.02653673051054555 | validation: 0.03397803508989966]
	TIME [epoch: 6.44 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0252333167699176		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.0252333167699176 | validation: 0.034511185185885626]
	TIME [epoch: 6.45 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02460325502545784		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.02460325502545784 | validation: 0.03258787069272396]
	TIME [epoch: 6.45 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03265068437333433		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.03265068437333433 | validation: 0.035962218387899696]
	TIME [epoch: 6.45 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025154671932942765		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.025154671932942765 | validation: 0.027933323545546642]
	TIME [epoch: 6.44 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028092673018995637		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.028092673018995637 | validation: 0.03621899082719532]
	TIME [epoch: 6.47 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029230235149043923		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.029230235149043923 | validation: 0.031219844368712276]
	TIME [epoch: 6.45 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026595887124071876		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.026595887124071876 | validation: 0.03373431826154243]
	TIME [epoch: 6.45 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027001421164610198		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.027001421164610198 | validation: 0.025158937533765826]
	TIME [epoch: 6.47 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03247627984562041		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.03247627984562041 | validation: 0.029557754877273707]
	TIME [epoch: 6.46 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027141623829103477		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.027141623829103477 | validation: 0.02925318428170978]
	TIME [epoch: 6.46 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030242758144661777		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.030242758144661777 | validation: 0.03370799695721525]
	TIME [epoch: 6.46 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027348691314424772		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.027348691314424772 | validation: 0.032058565679268625]
	TIME [epoch: 6.49 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023596459922463613		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.023596459922463613 | validation: 0.03114915836510507]
	TIME [epoch: 6.47 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020485290033185798		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.020485290033185798 | validation: 0.028042786303262828]
	TIME [epoch: 6.46 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0207153697864213		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.0207153697864213 | validation: 0.030334422406168238]
	TIME [epoch: 6.46 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022147480278641878		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.022147480278641878 | validation: 0.029080660608681898]
	TIME [epoch: 6.47 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023302373649596118		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.023302373649596118 | validation: 0.036914540913566316]
	TIME [epoch: 6.47 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024517180579555143		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.024517180579555143 | validation: 0.03308661609276026]
	TIME [epoch: 6.47 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026476657130764455		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.026476657130764455 | validation: 0.0307812972643893]
	TIME [epoch: 6.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028562010729494793		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.028562010729494793 | validation: 0.037310222445492924]
	TIME [epoch: 6.48 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026570120847667994		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.026570120847667994 | validation: 0.030345393997297077]
	TIME [epoch: 6.48 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027187253238293248		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.027187253238293248 | validation: 0.030254328728621084]
	TIME [epoch: 6.47 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02459301678300754		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.02459301678300754 | validation: 0.028591190238038865]
	TIME [epoch: 6.46 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027732430772314347		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.027732430772314347 | validation: 0.0365238694828775]
	TIME [epoch: 6.47 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02952279432339778		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.02952279432339778 | validation: 0.030722336964723054]
	TIME [epoch: 6.47 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028468468902238347		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.028468468902238347 | validation: 0.02714394727004809]
	TIME [epoch: 6.49 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02914975034632437		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.02914975034632437 | validation: 0.031441310213586315]
	TIME [epoch: 6.49 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.032744307112423515		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.032744307112423515 | validation: 0.03915055664161184]
	TIME [epoch: 6.46 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02897161291547458		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.02897161291547458 | validation: 0.03821490519502856]
	TIME [epoch: 6.47 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026343569599484994		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.026343569599484994 | validation: 0.036158725027906916]
	TIME [epoch: 6.48 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029950206940654808		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.029950206940654808 | validation: 0.042366184552002244]
	TIME [epoch: 6.47 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02667469729813319		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.02667469729813319 | validation: 0.03252219102085205]
	TIME [epoch: 6.47 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02724486369861901		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.02724486369861901 | validation: 0.026405662001091616]
	TIME [epoch: 6.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02914554724758898		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.02914554724758898 | validation: 0.03609772324019477]
	TIME [epoch: 6.48 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029320048082585894		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.029320048082585894 | validation: 0.031064043950116995]
	TIME [epoch: 6.47 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02358178572270172		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.02358178572270172 | validation: 0.031125056210376735]
	TIME [epoch: 6.48 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027138304822276978		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.027138304822276978 | validation: 0.029195804457300235]
	TIME [epoch: 6.46 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02753856484694246		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.02753856484694246 | validation: 0.027834792796672714]
	TIME [epoch: 6.47 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023756127136253864		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.023756127136253864 | validation: 0.032859763888905755]
	TIME [epoch: 6.46 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02621925136503846		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.02621925136503846 | validation: 0.027200728219433163]
	TIME [epoch: 6.48 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024577798190320896		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.024577798190320896 | validation: 0.028393689500422835]
	TIME [epoch: 6.51 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027992458541904564		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.027992458541904564 | validation: 0.027449649281422395]
	TIME [epoch: 6.47 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028077968179643212		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.028077968179643212 | validation: 0.03150241954569198]
	TIME [epoch: 6.47 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02711225751987121		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.02711225751987121 | validation: 0.03487991372606311]
	TIME [epoch: 6.47 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02790016976375903		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.02790016976375903 | validation: 0.035570433418534345]
	TIME [epoch: 6.45 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026536199502595312		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.026536199502595312 | validation: 0.026299197831855487]
	TIME [epoch: 6.45 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023480507088375104		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.023480507088375104 | validation: 0.03844486559956381]
	TIME [epoch: 6.47 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02620050395314025		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.02620050395314025 | validation: 0.0304604334155822]
	TIME [epoch: 6.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029013883526760115		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.029013883526760115 | validation: 0.03297890026083178]
	TIME [epoch: 6.47 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027632633392774813		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.027632633392774813 | validation: 0.030119352782978358]
	TIME [epoch: 6.47 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0247965848787668		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.0247965848787668 | validation: 0.03009824637483831]
	TIME [epoch: 6.47 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025858001001694088		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.025858001001694088 | validation: 0.036494964506330704]
	TIME [epoch: 6.46 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025765123651490224		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.025765123651490224 | validation: 0.03733265379504842]
	TIME [epoch: 6.45 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025728502964742536		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.025728502964742536 | validation: 0.02586873168180127]
	TIME [epoch: 6.47 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02466005140578073		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.02466005140578073 | validation: 0.025483067382877388]
	TIME [epoch: 6.51 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02844689992055756		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.02844689992055756 | validation: 0.029543240169819206]
	TIME [epoch: 6.47 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029963645503410297		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.029963645503410297 | validation: 0.03492889709630712]
	TIME [epoch: 6.47 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030151518226261352		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.030151518226261352 | validation: 0.0303952567837747]
	TIME [epoch: 6.48 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026943889703036586		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.026943889703036586 | validation: 0.0294794855791084]
	TIME [epoch: 6.47 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023747264305539133		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.023747264305539133 | validation: 0.03088739963818232]
	TIME [epoch: 6.47 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028875716923202607		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.028875716923202607 | validation: 0.028520768102539635]
	TIME [epoch: 6.47 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027006578260602918		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.027006578260602918 | validation: 0.03458148712668492]
	TIME [epoch: 6.51 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027966494310847634		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.027966494310847634 | validation: 0.04009389102082889]
	TIME [epoch: 6.47 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030455573308233157		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.030455573308233157 | validation: 0.0334557387604836]
	TIME [epoch: 6.47 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028334949273887668		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.028334949273887668 | validation: 0.04080169783417796]
	TIME [epoch: 6.47 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02402957887397482		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.02402957887397482 | validation: 0.03542244227352872]
	TIME [epoch: 6.47 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027126960191620204		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.027126960191620204 | validation: 0.033048091365850615]
	TIME [epoch: 6.48 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028439292362358773		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.028439292362358773 | validation: 0.040847223050927514]
	TIME [epoch: 6.47 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02841172195142564		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.02841172195142564 | validation: 0.037432287530718956]
	TIME [epoch: 6.51 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03147406026055248		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.03147406026055248 | validation: 0.03782511255758448]
	TIME [epoch: 6.48 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03017452146796589		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.03017452146796589 | validation: 0.03484943863042908]
	TIME [epoch: 6.46 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03104263777665954		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.03104263777665954 | validation: 0.03486961781318594]
	TIME [epoch: 6.46 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03256806053579063		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.03256806053579063 | validation: 0.02927839599918073]
	TIME [epoch: 6.47 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026196019972212273		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.026196019972212273 | validation: 0.0351987777317796]
	TIME [epoch: 6.47 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022328806627123016		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.022328806627123016 | validation: 0.0353076658095384]
	TIME [epoch: 6.47 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02263241846955449		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.02263241846955449 | validation: 0.03360457592374387]
	TIME [epoch: 6.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02286212464272147		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.02286212464272147 | validation: 0.03404631610944016]
	TIME [epoch: 6.48 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02536609579345621		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.02536609579345621 | validation: 0.030355111136326177]
	TIME [epoch: 6.48 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02635627841500209		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.02635627841500209 | validation: 0.023115765402649605]
	TIME [epoch: 6.47 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02363500140993578		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.02363500140993578 | validation: 0.028251870418586823]
	TIME [epoch: 6.47 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025469159558921768		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.025469159558921768 | validation: 0.02971927275330539]
	TIME [epoch: 6.47 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026045106124280418		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.026045106124280418 | validation: 0.021356615052688134]
	TIME [epoch: 6.46 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023336064578032622		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.023336064578032622 | validation: 0.029910415628135772]
	TIME [epoch: 6.49 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02633078841818562		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.02633078841818562 | validation: 0.03771768433885878]
	TIME [epoch: 6.49 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028133821875973478		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.028133821875973478 | validation: 0.030608997788709777]
	TIME [epoch: 6.48 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029045912495968756		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.029045912495968756 | validation: 0.031007002090642548]
	TIME [epoch: 6.47 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027243075017814034		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.027243075017814034 | validation: 0.05175665274152234]
	TIME [epoch: 6.48 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029514807393878607		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.029514807393878607 | validation: 0.040538159601762214]
	TIME [epoch: 6.47 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027851966941708734		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.027851966941708734 | validation: 0.04607914598746596]
	TIME [epoch: 6.47 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028001663907996598		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.028001663907996598 | validation: 0.03802847698168863]
	TIME [epoch: 6.48 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02408843972613957		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.02408843972613957 | validation: 0.038828677746170326]
	TIME [epoch: 6.47 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023776073179816053		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.023776073179816053 | validation: 0.028923914775690087]
	TIME [epoch: 6.47 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022573154423335413		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.022573154423335413 | validation: 0.028859631866400885]
	TIME [epoch: 6.45 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022163775181474013		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.022163775181474013 | validation: 0.03304850521252309]
	TIME [epoch: 6.47 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025372506882420796		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.025372506882420796 | validation: 0.030872019337669063]
	TIME [epoch: 6.47 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023205808386672647		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.023205808386672647 | validation: 0.036484322095139014]
	TIME [epoch: 6.45 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02567517524420628		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.02567517524420628 | validation: 0.029456491865812243]
	TIME [epoch: 6.47 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02655917524699656		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.02655917524699656 | validation: 0.03277907762045351]
	TIME [epoch: 6.5 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02634850758870688		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.02634850758870688 | validation: 0.03290841202421991]
	TIME [epoch: 6.47 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024266106969408324		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.024266106969408324 | validation: 0.029791860167839374]
	TIME [epoch: 6.47 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029038040924221672		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.029038040924221672 | validation: 0.029250896904677075]
	TIME [epoch: 6.47 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023066445312650674		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.023066445312650674 | validation: 0.044635867862244216]
	TIME [epoch: 6.47 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02742433357280279		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.02742433357280279 | validation: 0.04380130343284341]
	TIME [epoch: 6.47 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02563168032478881		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.02563168032478881 | validation: 0.04574476197179033]
	TIME [epoch: 6.47 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026831777539295647		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.026831777539295647 | validation: 0.03431559135029454]
	TIME [epoch: 6.5 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02288196074059184		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.02288196074059184 | validation: 0.032673258876122456]
	TIME [epoch: 6.47 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02661459645250789		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.02661459645250789 | validation: 0.02896680166074648]
	TIME [epoch: 6.47 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0261410072172418		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.0261410072172418 | validation: 0.027747632792170056]
	TIME [epoch: 6.46 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02435857457089125		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.02435857457089125 | validation: 0.027216771457397176]
	TIME [epoch: 6.47 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02351527414040798		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.02351527414040798 | validation: 0.04089555564354139]
	TIME [epoch: 6.45 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023481107935651595		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.023481107935651595 | validation: 0.03450293316138717]
	TIME [epoch: 6.46 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023175724564259613		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.023175724564259613 | validation: 0.039453548914157144]
	TIME [epoch: 6.51 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02616727567584895		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.02616727567584895 | validation: 0.03619556896834743]
	TIME [epoch: 6.47 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023963285755644586		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.023963285755644586 | validation: 0.03188743797440639]
	TIME [epoch: 6.46 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024043368159572573		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.024043368159572573 | validation: 0.035730436472974934]
	TIME [epoch: 6.47 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02217573505565716		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.02217573505565716 | validation: 0.03265865611618772]
	TIME [epoch: 6.47 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026149553550618775		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.026149553550618775 | validation: 0.039831520601231796]
	TIME [epoch: 6.46 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027608473170909007		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.027608473170909007 | validation: 0.021074145079981125]
	TIME [epoch: 6.46 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022268443775409673		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.022268443775409673 | validation: 0.04050804586061227]
	TIME [epoch: 6.49 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02679497605212717		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.02679497605212717 | validation: 0.042528814929841716]
	TIME [epoch: 6.47 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02709261748459492		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.02709261748459492 | validation: 0.028348085424606453]
	TIME [epoch: 6.46 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026366294652915765		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.026366294652915765 | validation: 0.029289217241131236]
	TIME [epoch: 6.46 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0267094705130979		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.0267094705130979 | validation: 0.03405395846565103]
	TIME [epoch: 6.46 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023832467453239095		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.023832467453239095 | validation: 0.02720734806089642]
	TIME [epoch: 6.47 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02347493162132651		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.02347493162132651 | validation: 0.02695181591323314]
	TIME [epoch: 6.45 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027718551510589683		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.027718551510589683 | validation: 0.0315408756597233]
	TIME [epoch: 6.52 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025789725198793106		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.025789725198793106 | validation: 0.031949674198251884]
	TIME [epoch: 6.48 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026614502836816503		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.026614502836816503 | validation: 0.028613958156565644]
	TIME [epoch: 6.46 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0224255332111738		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.0224255332111738 | validation: 0.03570000453524641]
	TIME [epoch: 6.47 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0228954506961903		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.0228954506961903 | validation: 0.03076813090788578]
	TIME [epoch: 6.47 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026651588738285013		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.026651588738285013 | validation: 0.0295906737389837]
	TIME [epoch: 6.45 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025833999774819056		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.025833999774819056 | validation: 0.029262180077519014]
	TIME [epoch: 6.46 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02709118230105176		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.02709118230105176 | validation: 0.029130546455845778]
	TIME [epoch: 6.51 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02672629227101298		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.02672629227101298 | validation: 0.036842518055348335]
	TIME [epoch: 6.46 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026275243395848275		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.026275243395848275 | validation: 0.0342362582503967]
	TIME [epoch: 6.47 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029983053446191753		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.029983053446191753 | validation: 0.027741750850270332]
	TIME [epoch: 6.46 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02777204775441551		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.02777204775441551 | validation: 0.03215279394588902]
	TIME [epoch: 6.46 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030210318914018302		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.030210318914018302 | validation: 0.031878943610458656]
	TIME [epoch: 6.46 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02494833807223197		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.02494833807223197 | validation: 0.03347863850720428]
	TIME [epoch: 6.46 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030095623570338972		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.030095623570338972 | validation: 0.02773159347329538]
	TIME [epoch: 6.48 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02750979573434784		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.02750979573434784 | validation: 0.03338787208494519]
	TIME [epoch: 6.48 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03009003228634334		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.03009003228634334 | validation: 0.041762081586697544]
	TIME [epoch: 6.46 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024576601504528946		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.024576601504528946 | validation: 0.028696414159998893]
	TIME [epoch: 6.46 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025112113661097547		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.025112113661097547 | validation: 0.036018622449072134]
	TIME [epoch: 6.46 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028925747925667385		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.028925747925667385 | validation: 0.03173354845051786]
	TIME [epoch: 6.46 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028796400468428462		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.028796400468428462 | validation: 0.034709210910963816]
	TIME [epoch: 6.46 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0250985650376369		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.0250985650376369 | validation: 0.03222566132309481]
	TIME [epoch: 6.48 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028714577742315298		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.028714577742315298 | validation: 0.03217462830371583]
	TIME [epoch: 6.48 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02919126541390351		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.02919126541390351 | validation: 0.03669073059066305]
	TIME [epoch: 6.46 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027199730302523463		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.027199730302523463 | validation: 0.02615319938591314]
	TIME [epoch: 6.46 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02799679639107739		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.02799679639107739 | validation: 0.03607775612056027]
	TIME [epoch: 6.47 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02993928672985319		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.02993928672985319 | validation: 0.028885081812481204]
	TIME [epoch: 6.47 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02394813436585852		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.02394813436585852 | validation: 0.02254073379132618]
	TIME [epoch: 6.47 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023460581940029833		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.023460581940029833 | validation: 0.03577925685282462]
	TIME [epoch: 6.46 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028587941768194902		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.028587941768194902 | validation: 0.03116845003402888]
	TIME [epoch: 6.49 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025661393266920733		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.025661393266920733 | validation: 0.03271793792773709]
	TIME [epoch: 6.46 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02595894813093687		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.02595894813093687 | validation: 0.028052160657422293]
	TIME [epoch: 6.45 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02885793825338417		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.02885793825338417 | validation: 0.0303329803343896]
	TIME [epoch: 6.45 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027563990370349054		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.027563990370349054 | validation: 0.03647325099493187]
	TIME [epoch: 6.46 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024999284505518006		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.024999284505518006 | validation: 0.028286984374981367]
	TIME [epoch: 6.45 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02735921137156294		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.02735921137156294 | validation: 0.027468093615611144]
	TIME [epoch: 6.47 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025742861165248487		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.025742861165248487 | validation: 0.03150376661463396]
	TIME [epoch: 6.49 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02580592464388158		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.02580592464388158 | validation: 0.029345137650385947]
	TIME [epoch: 6.46 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025004261448125203		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.025004261448125203 | validation: 0.034603806750138195]
	TIME [epoch: 6.45 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028834271816433315		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.028834271816433315 | validation: 0.025024739358802006]
	TIME [epoch: 6.46 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029452060963926923		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.029452060963926923 | validation: 0.03452444713245972]
	TIME [epoch: 6.46 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022774960402974075		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.022774960402974075 | validation: 0.03539754790083332]
	TIME [epoch: 6.46 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024588106572641585		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.024588106572641585 | validation: 0.03813045112245601]
	TIME [epoch: 6.47 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023975519272724954		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.023975519272724954 | validation: 0.028378531754844262]
	TIME [epoch: 6.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024282169720354508		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.024282169720354508 | validation: 0.03254809851261341]
	TIME [epoch: 6.47 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02498304920897267		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.02498304920897267 | validation: 0.030678010194006646]
	TIME [epoch: 6.47 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0264780690165034		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.0264780690165034 | validation: 0.03876370327715674]
	TIME [epoch: 6.45 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02372018168151799		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.02372018168151799 | validation: 0.029379792797279817]
	TIME [epoch: 6.47 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025445953060505712		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.025445953060505712 | validation: 0.025350171329345916]
	TIME [epoch: 6.47 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022966341943483487		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.022966341943483487 | validation: 0.025560760727682208]
	TIME [epoch: 6.47 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024435435710832027		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.024435435710832027 | validation: 0.031474902131605934]
	TIME [epoch: 6.49 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029288067906669733		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.029288067906669733 | validation: 0.03446562995259307]
	TIME [epoch: 6.47 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02569122324689083		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.02569122324689083 | validation: 0.03390832633633929]
	TIME [epoch: 6.45 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022846014863598454		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.022846014863598454 | validation: 0.0323516486249433]
	TIME [epoch: 6.47 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02693797636970336		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.02693797636970336 | validation: 0.03333456050976926]
	TIME [epoch: 6.46 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02645387540611792		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.02645387540611792 | validation: 0.03664022118230314]
	TIME [epoch: 6.46 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.031117026066483887		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.031117026066483887 | validation: 0.03867989627997528]
	TIME [epoch: 6.46 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027801269379055152		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.027801269379055152 | validation: 0.0389804388907395]
	TIME [epoch: 6.49 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027342262770835474		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.027342262770835474 | validation: 0.035189591781093876]
	TIME [epoch: 6.46 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027061177108117482		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.027061177108117482 | validation: 0.045047087751462635]
	TIME [epoch: 6.46 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026346907422325937		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.026346907422325937 | validation: 0.03451125595668732]
	TIME [epoch: 6.46 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0282966837610329		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.0282966837610329 | validation: 0.035761055317258136]
	TIME [epoch: 6.45 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02890599150179648		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.02890599150179648 | validation: 0.028966508488468903]
	TIME [epoch: 6.44 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02632260969353688		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.02632260969353688 | validation: 0.03781188841270938]
	TIME [epoch: 6.43 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024919434277326194		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.024919434277326194 | validation: 0.032300404135059343]
	TIME [epoch: 6.44 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025977922608107877		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.025977922608107877 | validation: 0.03379335369058309]
	TIME [epoch: 6.46 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02532034099268043		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.02532034099268043 | validation: 0.030240427031716487]
	TIME [epoch: 6.42 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026743652526045904		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.026743652526045904 | validation: 0.02825271566515705]
	TIME [epoch: 6.43 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02895191472763014		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.02895191472763014 | validation: 0.035016037962463144]
	TIME [epoch: 6.42 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027125623621591547		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.027125623621591547 | validation: 0.030741855247355978]
	TIME [epoch: 6.43 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02857436547681981		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.02857436547681981 | validation: 0.03268191302577399]
	TIME [epoch: 6.42 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025558611001738174		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.025558611001738174 | validation: 0.03194864167228871]
	TIME [epoch: 6.45 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026247910894488153		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.026247910894488153 | validation: 0.035923402814424236]
	TIME [epoch: 6.46 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027027017329611734		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.027027017329611734 | validation: 0.03531453813788533]
	TIME [epoch: 6.44 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026395937242186893		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.026395937242186893 | validation: 0.03347738402460899]
	TIME [epoch: 6.44 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0246694966977291		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.0246694966977291 | validation: 0.03813343523746583]
	TIME [epoch: 6.42 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023910600383863986		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.023910600383863986 | validation: 0.039762089032213295]
	TIME [epoch: 6.43 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02830643469563613		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.02830643469563613 | validation: 0.03255620810064714]
	TIME [epoch: 6.42 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024954020186871727		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.024954020186871727 | validation: 0.03270239428257749]
	TIME [epoch: 6.43 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024007102398941993		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.024007102398941993 | validation: 0.029461973496239774]
	TIME [epoch: 6.47 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02487058442883511		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.02487058442883511 | validation: 0.03258530376975518]
	TIME [epoch: 6.44 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026335863143738418		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.026335863143738418 | validation: 0.036376713404056626]
	TIME [epoch: 6.45 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024264252001530522		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.024264252001530522 | validation: 0.042698506146187025]
	TIME [epoch: 6.44 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02341978995351467		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.02341978995351467 | validation: 0.03818775278535739]
	TIME [epoch: 6.44 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02093536392992845		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.02093536392992845 | validation: 0.028410216671235135]
	TIME [epoch: 6.44 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021392824777195854		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.021392824777195854 | validation: 0.03387422718490664]
	TIME [epoch: 6.46 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025163089572740785		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.025163089572740785 | validation: 0.030375091087660313]
	TIME [epoch: 6.5 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02660601061187213		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.02660601061187213 | validation: 0.03824830858537289]
	TIME [epoch: 6.45 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.030301856149900674		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.030301856149900674 | validation: 0.03272087675624504]
	TIME [epoch: 6.45 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027610995502596585		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.027610995502596585 | validation: 0.03546370895216884]
	TIME [epoch: 6.45 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029942277708262202		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.029942277708262202 | validation: 0.03036983682559729]
	TIME [epoch: 6.46 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026651713616269362		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.026651713616269362 | validation: 0.03592136393867951]
	TIME [epoch: 6.46 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02614518458355517		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.02614518458355517 | validation: 0.03562070760493761]
	TIME [epoch: 6.46 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02500347482920428		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.02500347482920428 | validation: 0.03224403681137645]
	TIME [epoch: 6.51 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028970605627594674		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.028970605627594674 | validation: 0.03909994812702629]
	TIME [epoch: 6.47 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025564154990648437		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.025564154990648437 | validation: 0.03484740436265428]
	TIME [epoch: 6.47 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02483215048921095		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.02483215048921095 | validation: 0.031116171440971493]
	TIME [epoch: 6.47 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028012870139412074		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.028012870139412074 | validation: 0.031251285064631935]
	TIME [epoch: 6.46 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02579699656972091		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.02579699656972091 | validation: 0.03211685988219939]
	TIME [epoch: 6.48 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0260052035833322		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.0260052035833322 | validation: 0.034707883903718144]
	TIME [epoch: 6.46 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022086214792742496		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.022086214792742496 | validation: 0.02844016794836593]
	TIME [epoch: 6.51 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02232318560515167		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.02232318560515167 | validation: 0.027000269771862796]
	TIME [epoch: 6.47 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024235144826213865		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.024235144826213865 | validation: 0.036428983988107115]
	TIME [epoch: 6.48 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024782112532404026		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.024782112532404026 | validation: 0.03149034562370044]
	TIME [epoch: 6.48 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026140667703310645		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.026140667703310645 | validation: 0.0328321783885207]
	TIME [epoch: 6.47 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023844221339676383		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.023844221339676383 | validation: 0.04079296460595255]
	TIME [epoch: 6.47 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027062425559513548		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.027062425559513548 | validation: 0.03088236031689273]
	TIME [epoch: 6.46 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0264082290293762		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.0264082290293762 | validation: 0.02928155456245715]
	TIME [epoch: 6.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024906886852051748		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.024906886852051748 | validation: 0.030129098028123115]
	TIME [epoch: 6.46 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0243375956919265		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.0243375956919265 | validation: 0.02773143175024493]
	TIME [epoch: 6.48 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025478525152180256		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.025478525152180256 | validation: 0.03506152783596895]
	TIME [epoch: 6.46 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020330557428924676		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.020330557428924676 | validation: 0.028018190986676343]
	TIME [epoch: 6.46 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02465726129080026		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.02465726129080026 | validation: 0.038719025343728244]
	TIME [epoch: 6.44 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025712021617583413		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.025712021617583413 | validation: 0.04326936716211007]
	TIME [epoch: 6.44 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022136365474796395		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.022136365474796395 | validation: 0.03264193910107745]
	TIME [epoch: 6.45 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022723423382402574		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.022723423382402574 | validation: 0.03016910435393474]
	TIME [epoch: 6.45 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025392732903853556		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.025392732903853556 | validation: 0.03812459493194216]
	TIME [epoch: 6.44 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026488666796642527		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.026488666796642527 | validation: 0.044721058442827186]
	TIME [epoch: 6.43 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02745267777834217		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.02745267777834217 | validation: 0.03565462961526405]
	TIME [epoch: 6.43 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02933957565085895		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.02933957565085895 | validation: 0.04221149893563446]
	TIME [epoch: 6.43 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028543417609191588		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.028543417609191588 | validation: 0.0416544450471142]
	TIME [epoch: 6.43 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027832348392752032		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.027832348392752032 | validation: 0.048238561629615935]
	TIME [epoch: 6.45 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0265792149745707		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.0265792149745707 | validation: 0.036714086025174605]
	TIME [epoch: 6.46 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029556708867989792		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.029556708867989792 | validation: 0.039240173404325514]
	TIME [epoch: 6.44 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02417721284876776		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.02417721284876776 | validation: 0.04183062872125973]
	TIME [epoch: 6.43 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025163292730601014		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.025163292730601014 | validation: 0.0383611843540822]
	TIME [epoch: 6.44 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022633132850633668		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.022633132850633668 | validation: 0.03399661481025256]
	TIME [epoch: 6.44 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029447358588916086		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.029447358588916086 | validation: 0.036471254358410525]
	TIME [epoch: 6.43 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02565777452678785		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.02565777452678785 | validation: 0.025470989861812045]
	TIME [epoch: 6.45 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026815741398709174		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.026815741398709174 | validation: 0.03787844713761421]
	TIME [epoch: 6.45 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024907363917520693		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.024907363917520693 | validation: 0.03393025776836802]
	TIME [epoch: 6.42 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02704300214061165		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.02704300214061165 | validation: 0.03989540487706531]
	TIME [epoch: 6.42 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02607388322441188		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.02607388322441188 | validation: 0.037205201876430186]
	TIME [epoch: 6.44 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024450194148706982		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.024450194148706982 | validation: 0.03574620651334517]
	TIME [epoch: 6.45 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023751419754647247		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.023751419754647247 | validation: 0.03661469314360195]
	TIME [epoch: 6.45 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02488320787027041		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.02488320787027041 | validation: 0.04354870895341154]
	TIME [epoch: 6.46 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02438468788251127		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.02438468788251127 | validation: 0.036147539511476076]
	TIME [epoch: 6.48 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024159118106095393		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.024159118106095393 | validation: 0.04654091864968903]
	TIME [epoch: 6.46 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02656965829326271		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.02656965829326271 | validation: 0.03703954824232823]
	TIME [epoch: 6.46 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026178263182497292		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.026178263182497292 | validation: 0.03068294414422486]
	TIME [epoch: 6.46 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027235913499345135		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.027235913499345135 | validation: 0.035845355183158255]
	TIME [epoch: 6.46 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02445181016506979		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.02445181016506979 | validation: 0.033577448404600224]
	TIME [epoch: 6.45 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020934446194774733		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.020934446194774733 | validation: 0.03674079990445676]
	TIME [epoch: 6.46 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025711135866950247		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.025711135866950247 | validation: 0.031515177770600936]
	TIME [epoch: 6.5 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02413211455629955		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.02413211455629955 | validation: 0.033436624686696316]
	TIME [epoch: 6.46 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02557206971456431		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.02557206971456431 | validation: 0.031067253912454938]
	TIME [epoch: 6.46 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026538266821632864		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.026538266821632864 | validation: 0.03837292540585799]
	TIME [epoch: 6.46 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02136689015278033		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.02136689015278033 | validation: 0.033702226123285606]
	TIME [epoch: 6.46 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025074806524191834		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.025074806524191834 | validation: 0.030895777838888618]
	TIME [epoch: 6.48 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023889613529462624		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.023889613529462624 | validation: 0.02512726161788508]
	TIME [epoch: 6.48 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024246376092026654		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.024246376092026654 | validation: 0.03849552631659687]
	TIME [epoch: 6.52 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025111000522732206		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.025111000522732206 | validation: 0.03395953470948209]
	TIME [epoch: 6.47 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020144817203802696		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.020144817203802696 | validation: 0.03701413259576627]
	TIME [epoch: 6.46 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024011229597738045		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.024011229597738045 | validation: 0.036117153619127595]
	TIME [epoch: 6.46 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025467663584709588		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.025467663584709588 | validation: 0.028680794294834024]
	TIME [epoch: 6.46 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027750642379256237		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.027750642379256237 | validation: 0.036541104356093985]
	TIME [epoch: 6.46 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022772313817731767		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.022772313817731767 | validation: 0.037013504598656675]
	TIME [epoch: 6.46 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02432148130106041		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.02432148130106041 | validation: 0.04304633066318894]
	TIME [epoch: 6.5 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025808478179998467		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.025808478179998467 | validation: 0.042459501282764114]
	TIME [epoch: 6.46 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026496277661989198		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.026496277661989198 | validation: 0.029237800317030115]
	TIME [epoch: 6.46 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02434983460402278		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.02434983460402278 | validation: 0.0229219358259801]
	TIME [epoch: 6.46 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023407585046992946		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.023407585046992946 | validation: 0.03405841899796983]
	TIME [epoch: 6.45 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024607923815559644		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.024607923815559644 | validation: 0.04238272832934327]
	TIME [epoch: 6.47 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02498477823584625		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.02498477823584625 | validation: 0.028065618213832903]
	TIME [epoch: 6.46 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024335370210952945		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.024335370210952945 | validation: 0.03562283410888867]
	TIME [epoch: 6.47 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02780211199862239		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.02780211199862239 | validation: 0.032778332024283034]
	TIME [epoch: 6.48 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02478041361795376		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.02478041361795376 | validation: 0.0303695708269097]
	TIME [epoch: 6.46 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022467388821627042		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.022467388821627042 | validation: 0.02995350442596007]
	TIME [epoch: 6.46 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022815985181946843		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.022815985181946843 | validation: 0.028292585103563743]
	TIME [epoch: 6.46 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018148281647211596		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.018148281647211596 | validation: 0.03222962098473331]
	TIME [epoch: 6.46 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023727543608190235		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.023727543608190235 | validation: 0.028465739727153806]
	TIME [epoch: 6.46 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022545486482341295		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.022545486482341295 | validation: 0.02975067903233091]
	TIME [epoch: 6.49 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02155813645795352		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.02155813645795352 | validation: 0.030241935862910456]
	TIME [epoch: 6.49 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025716939637761043		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.025716939637761043 | validation: 0.02811230950659201]
	TIME [epoch: 6.46 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022841212124646643		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.022841212124646643 | validation: 0.03530347469972171]
	TIME [epoch: 6.46 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022304915899941047		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.022304915899941047 | validation: 0.028426452315027592]
	TIME [epoch: 6.46 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028854695535537232		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.028854695535537232 | validation: 0.02558378970521683]
	TIME [epoch: 6.46 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020432389885968637		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.020432389885968637 | validation: 0.02509292863911716]
	TIME [epoch: 6.46 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025995242421904034		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.025995242421904034 | validation: 0.03144290452637335]
	TIME [epoch: 6.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02268909971026394		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.02268909971026394 | validation: 0.037334815642752844]
	TIME [epoch: 6.5 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027301865898997742		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.027301865898997742 | validation: 0.031084336620302366]
	TIME [epoch: 6.48 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022988664084158394		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.022988664084158394 | validation: 0.0370047166694288]
	TIME [epoch: 6.48 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023428557534802642		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.023428557534802642 | validation: 0.027036195905769184]
	TIME [epoch: 6.47 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022820107764992187		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.022820107764992187 | validation: 0.01922628565990684]
	TIME [epoch: 6.47 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02295339666052144		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.02295339666052144 | validation: 0.02691946452779835]
	TIME [epoch: 6.46 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02420953786308821		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.02420953786308821 | validation: 0.03264487778682416]
	TIME [epoch: 6.48 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02556547989615878		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.02556547989615878 | validation: 0.026438291483367373]
	TIME [epoch: 6.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02390991201871981		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.02390991201871981 | validation: 0.0234678374702962]
	TIME [epoch: 6.47 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0222760937658374		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.0222760937658374 | validation: 0.027907547846391087]
	TIME [epoch: 6.45 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024334575006758764		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.024334575006758764 | validation: 0.0300620494902939]
	TIME [epoch: 6.46 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027216956055700382		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.027216956055700382 | validation: 0.023212729352221385]
	TIME [epoch: 6.46 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024331578167464896		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.024331578167464896 | validation: 0.029987951183497622]
	TIME [epoch: 6.46 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02324149285688262		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.02324149285688262 | validation: 0.031716912071827225]
	TIME [epoch: 6.47 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021731148053419927		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.021731148053419927 | validation: 0.026324832635898125]
	TIME [epoch: 6.49 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02241119343868593		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.02241119343868593 | validation: 0.021920939911946796]
	TIME [epoch: 6.48 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0211179391475856		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.0211179391475856 | validation: 0.03565351043634472]
	TIME [epoch: 6.47 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021795818419915517		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.021795818419915517 | validation: 0.02276794148081698]
	TIME [epoch: 6.47 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02361673612149455		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.02361673612149455 | validation: 0.026502382537155027]
	TIME [epoch: 6.48 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025578112404678992		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.025578112404678992 | validation: 0.03491673308400778]
	TIME [epoch: 6.47 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023664196501098463		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.023664196501098463 | validation: 0.02827167158292873]
	TIME [epoch: 6.48 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023186077011920676		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.023186077011920676 | validation: 0.0339975904861135]
	TIME [epoch: 6.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023690424680022113		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.023690424680022113 | validation: 0.029128550668881373]
	TIME [epoch: 6.46 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02614334353392871		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.02614334353392871 | validation: 0.03335314287358923]
	TIME [epoch: 6.45 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027294200902295965		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.027294200902295965 | validation: 0.024203183443647535]
	TIME [epoch: 6.47 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02606491560356372		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.02606491560356372 | validation: 0.03234626925980412]
	TIME [epoch: 6.47 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023134756658586032		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.023134756658586032 | validation: 0.03130946288169093]
	TIME [epoch: 6.47 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024161136867398035		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.024161136867398035 | validation: 0.02238860154806851]
	TIME [epoch: 6.47 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022968960194854345		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.022968960194854345 | validation: 0.027074677164867573]
	TIME [epoch: 6.51 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026003922664183506		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.026003922664183506 | validation: 0.029264336038832127]
	TIME [epoch: 6.46 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024825693823008838		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.024825693823008838 | validation: 0.024474502218958746]
	TIME [epoch: 6.45 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02453548292678068		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.02453548292678068 | validation: 0.03236142643448357]
	TIME [epoch: 6.45 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024668590148324586		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.024668590148324586 | validation: 0.03703277917641667]
	TIME [epoch: 6.47 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02783358459754165		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.02783358459754165 | validation: 0.02914991948874986]
	TIME [epoch: 6.47 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019893842336851902		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.019893842336851902 | validation: 0.03511896895207591]
	TIME [epoch: 6.47 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023031263388696932		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.023031263388696932 | validation: 0.0369373540989212]
	TIME [epoch: 6.52 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020938451122879564		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.020938451122879564 | validation: 0.03735238360109238]
	TIME [epoch: 6.46 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026448340609459553		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.026448340609459553 | validation: 0.025043413009423525]
	TIME [epoch: 6.47 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024130355876836998		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.024130355876836998 | validation: 0.024995131644673766]
	TIME [epoch: 6.47 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022311314166629757		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.022311314166629757 | validation: 0.027358280330093267]
	TIME [epoch: 6.47 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02661940751053706		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.02661940751053706 | validation: 0.02808453031384705]
	TIME [epoch: 6.46 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025277358856189668		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.025277358856189668 | validation: 0.03841659701166446]
	TIME [epoch: 6.46 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023133047779831287		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.023133047779831287 | validation: 0.02872000942502028]
	TIME [epoch: 6.49 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025453703465619957		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.025453703465619957 | validation: 0.034428417828513184]
	TIME [epoch: 6.48 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02859046072391498		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.02859046072391498 | validation: 0.03289268470351186]
	TIME [epoch: 6.46 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02153914429992616		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.02153914429992616 | validation: 0.03620438036793209]
	TIME [epoch: 6.46 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02207632496918318		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.02207632496918318 | validation: 0.030783875567430573]
	TIME [epoch: 6.46 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025295426101339634		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.025295426101339634 | validation: 0.03468949346523907]
	TIME [epoch: 6.44 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025123417752657282		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.025123417752657282 | validation: 0.02797432200014141]
	TIME [epoch: 6.46 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02295076909278324		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.02295076909278324 | validation: 0.025775659337534115]
	TIME [epoch: 6.48 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022111001632380743		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.022111001632380743 | validation: 0.022580864325734563]
	TIME [epoch: 6.48 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029161129267440085		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.029161129267440085 | validation: 0.036699417395760124]
	TIME [epoch: 6.46 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.016729213439350236		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.016729213439350236 | validation: 0.02660594132907687]
	TIME [epoch: 6.46 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026992012112380587		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.026992012112380587 | validation: 0.041456428449818096]
	TIME [epoch: 6.43 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02604209596486328		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.02604209596486328 | validation: 0.03365635189386226]
	TIME [epoch: 6.46 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023547114478781463		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.023547114478781463 | validation: 0.03527320127215261]
	TIME [epoch: 6.45 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025287599314890823		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.025287599314890823 | validation: 0.026108138895231045]
	TIME [epoch: 6.47 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024652426249852224		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.024652426249852224 | validation: 0.024565533973568105]
	TIME [epoch: 6.47 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028528245083962456		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.028528245083962456 | validation: 0.03587685509078585]
	TIME [epoch: 6.46 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023019565551506638		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.023019565551506638 | validation: 0.024510167550991033]
	TIME [epoch: 6.45 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025154231367731806		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.025154231367731806 | validation: 0.02463136703799102]
	TIME [epoch: 6.44 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027497728362796875		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.027497728362796875 | validation: 0.02469924618959846]
	TIME [epoch: 6.45 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02092674034430622		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.02092674034430622 | validation: 0.0313979667322789]
	TIME [epoch: 6.46 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023379404171785845		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.023379404171785845 | validation: 0.024758894549708536]
	TIME [epoch: 6.47 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02415991029347799		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.02415991029347799 | validation: 0.02902278828575777]
	TIME [epoch: 6.5 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023460155410030138		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.023460155410030138 | validation: 0.03263306682671121]
	TIME [epoch: 6.45 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0229738305827422		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.0229738305827422 | validation: 0.03586461467983159]
	TIME [epoch: 6.47 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020496161428808793		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.020496161428808793 | validation: 0.026970050688845216]
	TIME [epoch: 6.45 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.028157933527276687		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.028157933527276687 | validation: 0.028343821479524273]
	TIME [epoch: 6.46 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022945744449757596		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.022945744449757596 | validation: 0.0330553972537493]
	TIME [epoch: 6.44 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02523928999638813		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.02523928999638813 | validation: 0.02975937841648922]
	TIME [epoch: 6.45 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02314447269975032		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.02314447269975032 | validation: 0.02777391228475923]
	TIME [epoch: 6.49 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024335282002835152		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.024335282002835152 | validation: 0.021451383263163922]
	TIME [epoch: 6.46 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025530990585749855		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.025530990585749855 | validation: 0.02577119612997116]
	TIME [epoch: 6.45 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023660615122267456		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.023660615122267456 | validation: 0.019566085891934787]
	TIME [epoch: 6.46 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020527380539119205		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.020527380539119205 | validation: 0.03815678492314905]
	TIME [epoch: 6.46 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019800564719439938		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.019800564719439938 | validation: 0.022697563349471178]
	TIME [epoch: 6.47 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02197331424825516		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.02197331424825516 | validation: 0.03246266011388717]
	TIME [epoch: 6.45 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01791197770629756		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.01791197770629756 | validation: 0.03643376851170922]
	TIME [epoch: 6.48 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025370379506825972		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.025370379506825972 | validation: 0.03912043728178559]
	TIME [epoch: 6.45 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023450472286848274		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.023450472286848274 | validation: 0.02999108938026485]
	TIME [epoch: 6.43 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024313883372116558		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.024313883372116558 | validation: 0.0345010012057074]
	TIME [epoch: 6.44 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023382569030654585		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.023382569030654585 | validation: 0.03915955711417033]
	TIME [epoch: 6.44 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0255974196155151		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.0255974196155151 | validation: 0.033151160306805365]
	TIME [epoch: 6.44 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022974458115934737		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.022974458115934737 | validation: 0.03458465317832831]
	TIME [epoch: 6.45 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026299350043710742		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.026299350043710742 | validation: 0.0332031635833474]
	TIME [epoch: 6.46 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02311543551091321		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.02311543551091321 | validation: 0.03280715428624772]
	TIME [epoch: 6.45 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022367012831572143		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.022367012831572143 | validation: 0.029450990780053195]
	TIME [epoch: 6.45 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023073611718674836		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.023073611718674836 | validation: 0.038121818510867066]
	TIME [epoch: 6.45 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02639514535458241		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.02639514535458241 | validation: 0.033092015915497805]
	TIME [epoch: 6.43 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02552777395278827		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.02552777395278827 | validation: 0.038595675480647816]
	TIME [epoch: 6.43 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022457211303550186		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.022457211303550186 | validation: 0.024789313207977122]
	TIME [epoch: 6.46 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024984263704945227		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.024984263704945227 | validation: 0.03024033531810104]
	TIME [epoch: 6.49 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02541124151833919		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.02541124151833919 | validation: 0.029318045348638355]
	TIME [epoch: 6.44 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02203166324609405		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.02203166324609405 | validation: 0.03304858944685701]
	TIME [epoch: 6.45 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02553642016326097		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.02553642016326097 | validation: 0.042057346584720316]
	TIME [epoch: 6.45 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02441741890187399		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.02441741890187399 | validation: 0.03437306390761762]
	TIME [epoch: 6.46 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026132277014711387		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.026132277014711387 | validation: 0.025910216564547818]
	TIME [epoch: 6.46 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025823273242602283		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.025823273242602283 | validation: 0.036522239628671724]
	TIME [epoch: 6.47 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025421327720260463		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.025421327720260463 | validation: 0.03164781217039506]
	TIME [epoch: 6.49 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029664405622942522		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.029664405622942522 | validation: 0.03629417642831709]
	TIME [epoch: 6.5 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025108264775368178		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.025108264775368178 | validation: 0.03521090529419525]
	TIME [epoch: 6.46 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024569462592710527		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.024569462592710527 | validation: 0.03155501890041619]
	TIME [epoch: 6.47 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02712107571846057		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.02712107571846057 | validation: 0.031121595028457884]
	TIME [epoch: 6.47 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022317492661259708		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.022317492661259708 | validation: 0.03346931432507441]
	TIME [epoch: 6.46 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02744867424121508		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.02744867424121508 | validation: 0.04169470446420204]
	TIME [epoch: 6.46 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02472631030624104		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.02472631030624104 | validation: 0.029504190020289194]
	TIME [epoch: 6.49 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0239024238002501		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.0239024238002501 | validation: 0.02873222164388232]
	TIME [epoch: 6.5 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02822232348244069		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.02822232348244069 | validation: 0.03338756060297968]
	TIME [epoch: 6.47 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023005747751430834		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.023005747751430834 | validation: 0.024766398789686308]
	TIME [epoch: 6.46 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02052562472768368		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.02052562472768368 | validation: 0.025592883038955724]
	TIME [epoch: 6.46 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023757643999795422		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.023757643999795422 | validation: 0.030494019164572932]
	TIME [epoch: 6.46 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.029323107473798772		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.029323107473798772 | validation: 0.03826844554689099]
	TIME [epoch: 6.48 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023331214566852727		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.023331214566852727 | validation: 0.03165976589050012]
	TIME [epoch: 6.47 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023743455095211065		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.023743455095211065 | validation: 0.03492375766842754]
	TIME [epoch: 6.49 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027805168122461074		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.027805168122461074 | validation: 0.033077292165335434]
	TIME [epoch: 6.48 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022174737739526402		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.022174737739526402 | validation: 0.030999548499433722]
	TIME [epoch: 6.47 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024595303025092084		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.024595303025092084 | validation: 0.02476792305282037]
	TIME [epoch: 6.47 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023682080517266488		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.023682080517266488 | validation: 0.03360904513581338]
	TIME [epoch: 6.48 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0224115400271607		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.0224115400271607 | validation: 0.032724000845344936]
	TIME [epoch: 6.47 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02384515250872537		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.02384515250872537 | validation: 0.025613073610144303]
	TIME [epoch: 6.46 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026900035229704793		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.026900035229704793 | validation: 0.02643325618461438]
	TIME [epoch: 6.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02215042575568047		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.02215042575568047 | validation: 0.04028242255616538]
	TIME [epoch: 6.47 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02471091018800393		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.02471091018800393 | validation: 0.03442113485527682]
	TIME [epoch: 6.47 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02404800759542505		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.02404800759542505 | validation: 0.030486496104464807]
	TIME [epoch: 6.46 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019881292212436813		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.019881292212436813 | validation: 0.03160622541117525]
	TIME [epoch: 6.46 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023398352288603014		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.023398352288603014 | validation: 0.03206661240091695]
	TIME [epoch: 6.46 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02369501493780403		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.02369501493780403 | validation: 0.032802900408576134]
	TIME [epoch: 6.46 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026251606791767884		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.026251606791767884 | validation: 0.030492958161248432]
	TIME [epoch: 6.5 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02250037675346673		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.02250037675346673 | validation: 0.02303845886180029]
	TIME [epoch: 6.46 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024586392778666224		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.024586392778666224 | validation: 0.03292845237666484]
	TIME [epoch: 6.47 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022372497351756393		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.022372497351756393 | validation: 0.03017889674787294]
	TIME [epoch: 6.46 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025062843871574647		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.025062843871574647 | validation: 0.031226609919750122]
	TIME [epoch: 6.46 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025553655774931364		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.025553655774931364 | validation: 0.031149090282195164]
	TIME [epoch: 6.47 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021989397660439572		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.021989397660439572 | validation: 0.03231056554939736]
	TIME [epoch: 6.46 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01933163522723288		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.01933163522723288 | validation: 0.02203415026928487]
	TIME [epoch: 6.5 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02259735527376091		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.02259735527376091 | validation: 0.028632111957753933]
	TIME [epoch: 6.46 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026987021153614954		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.026987021153614954 | validation: 0.035584386841868376]
	TIME [epoch: 6.47 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024060237715631812		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.024060237715631812 | validation: 0.033611616915859524]
	TIME [epoch: 6.46 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020189388885565346		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.020189388885565346 | validation: 0.028493307500901843]
	TIME [epoch: 6.47 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01810295645648235		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.01810295645648235 | validation: 0.02897408356982473]
	TIME [epoch: 6.46 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023828381433078978		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.023828381433078978 | validation: 0.031346185718092306]
	TIME [epoch: 6.46 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024904361602234186		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.024904361602234186 | validation: 0.0304887023374486]
	TIME [epoch: 6.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02773133375007		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.02773133375007 | validation: 0.026850202193652337]
	TIME [epoch: 6.47 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02320290166938535		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.02320290166938535 | validation: 0.03633196743663099]
	TIME [epoch: 6.46 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025164710233383188		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.025164710233383188 | validation: 0.030558921269681384]
	TIME [epoch: 6.46 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021387069228137434		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.021387069228137434 | validation: 0.02524113573916813]
	TIME [epoch: 6.46 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021775278673596316		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.021775278673596316 | validation: 0.034045723501979736]
	TIME [epoch: 6.47 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02125754273451705		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.02125754273451705 | validation: 0.024110316744513974]
	TIME [epoch: 6.46 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022627931385397444		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.022627931385397444 | validation: 0.03129539130546616]
	TIME [epoch: 6.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025985500097086923		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.025985500097086923 | validation: 0.03545719991315855]
	TIME [epoch: 6.46 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024197546862079436		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.024197546862079436 | validation: 0.025555228551415256]
	TIME [epoch: 6.47 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023693290320791077		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.023693290320791077 | validation: 0.030433790289634156]
	TIME [epoch: 6.45 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02555956623576147		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.02555956623576147 | validation: 0.029587302602141347]
	TIME [epoch: 6.48 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019409679142275572		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.019409679142275572 | validation: 0.03128312731805209]
	TIME [epoch: 6.46 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024006327777744557		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.024006327777744557 | validation: 0.03235074632431025]
	TIME [epoch: 6.46 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02557450709626389		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.02557450709626389 | validation: 0.02184757837203875]
	TIME [epoch: 6.48 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025137699303824014		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.025137699303824014 | validation: 0.02765677163948369]
	TIME [epoch: 6.49 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026227869989089696		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.026227869989089696 | validation: 0.0330563052291135]
	TIME [epoch: 6.46 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021452050379863193		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.021452050379863193 | validation: 0.023591985131442977]
	TIME [epoch: 6.46 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02286889501236018		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.02286889501236018 | validation: 0.03319664955712136]
	TIME [epoch: 6.46 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027079544847790248		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.027079544847790248 | validation: 0.027362234431109356]
	TIME [epoch: 6.46 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022787548601337883		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.022787548601337883 | validation: 0.024209279187394666]
	TIME [epoch: 6.46 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02714739649093434		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.02714739649093434 | validation: 0.0287950581859283]
	TIME [epoch: 6.48 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020722928316908043		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.020722928316908043 | validation: 0.02814911315406822]
	TIME [epoch: 6.48 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023954484929037352		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.023954484929037352 | validation: 0.022678108412771413]
	TIME [epoch: 6.46 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021295105760285666		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.021295105760285666 | validation: 0.02283845338650554]
	TIME [epoch: 6.45 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023004420717450284		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.023004420717450284 | validation: 0.0298281326644147]
	TIME [epoch: 6.46 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02117509805919689		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.02117509805919689 | validation: 0.03042653846686176]
	TIME [epoch: 6.46 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023966330756998805		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.023966330756998805 | validation: 0.02784080602943871]
	TIME [epoch: 6.46 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02114659778951117		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.02114659778951117 | validation: 0.027227109411018597]
	TIME [epoch: 6.46 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025310553864153047		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.025310553864153047 | validation: 0.03796637975438403]
	TIME [epoch: 6.48 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025131400645773863		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.025131400645773863 | validation: 0.03217350622258122]
	TIME [epoch: 6.46 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025806826973989734		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.025806826973989734 | validation: 0.0208757687186854]
	TIME [epoch: 6.45 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024841928537294097		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.024841928537294097 | validation: 0.023204201433952906]
	TIME [epoch: 6.46 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023496630119392625		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.023496630119392625 | validation: 0.023969937505657835]
	TIME [epoch: 6.46 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020835703999998807		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.020835703999998807 | validation: 0.03424728283446085]
	TIME [epoch: 6.46 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02314510162440743		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.02314510162440743 | validation: 0.027008686754251957]
	TIME [epoch: 6.46 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021855476342038375		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.021855476342038375 | validation: 0.03156111841345096]
	TIME [epoch: 6.49 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.01869918052688144		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.01869918052688144 | validation: 0.030025624381043912]
	TIME [epoch: 6.46 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02174848911497291		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.02174848911497291 | validation: 0.02898694394863023]
	TIME [epoch: 6.45 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021985762153308427		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.021985762153308427 | validation: 0.02919751484972335]
	TIME [epoch: 6.46 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026025500279558154		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.026025500279558154 | validation: 0.022132961741938996]
	TIME [epoch: 6.45 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02127615108569223		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.02127615108569223 | validation: 0.02765520415772087]
	TIME [epoch: 6.46 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02398926835496587		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.02398926835496587 | validation: 0.028212671562603427]
	TIME [epoch: 6.46 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023186662429436577		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.023186662429436577 | validation: 0.023135322208918657]
	TIME [epoch: 6.5 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023102800562398662		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.023102800562398662 | validation: 0.03191762119378585]
	TIME [epoch: 6.47 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024633842880776677		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.024633842880776677 | validation: 0.0232680042982841]
	TIME [epoch: 6.46 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02093685939025197		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.02093685939025197 | validation: 0.02237615128396862]
	TIME [epoch: 6.46 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023255245639206418		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.023255245639206418 | validation: 0.03482758058789719]
	TIME [epoch: 6.46 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020524375299458192		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.020524375299458192 | validation: 0.033751470305479814]
	TIME [epoch: 6.46 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024434898733383975		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.024434898733383975 | validation: 0.02414981691040702]
	TIME [epoch: 6.46 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023675021788091225		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.023675021788091225 | validation: 0.035323427954365536]
	TIME [epoch: 6.49 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.019769760340907883		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.019769760340907883 | validation: 0.027466617056905698]
	TIME [epoch: 6.46 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024318705074373132		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.024318705074373132 | validation: 0.027807476697070902]
	TIME [epoch: 6.47 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02297496476318274		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.02297496476318274 | validation: 0.02611213358956591]
	TIME [epoch: 6.46 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02138139192151107		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.02138139192151107 | validation: 0.02414630133559907]
	TIME [epoch: 6.45 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023275051692013184		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.023275051692013184 | validation: 0.03392376223096888]
	TIME [epoch: 6.45 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023393217976328835		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.023393217976328835 | validation: 0.033939977184203864]
	TIME [epoch: 6.45 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024619441229905767		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.024619441229905767 | validation: 0.024369401447597677]
	TIME [epoch: 6.49 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022006686542932766		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.022006686542932766 | validation: 0.028348560222271505]
	TIME [epoch: 6.46 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020925546147992347		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.020925546147992347 | validation: 0.027861759701083594]
	TIME [epoch: 6.46 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022914333343906104		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.022914333343906104 | validation: 0.025447792466312572]
	TIME [epoch: 6.45 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02580440474011542		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.02580440474011542 | validation: 0.0285829622705901]
	TIME [epoch: 6.47 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02307089329896231		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.02307089329896231 | validation: 0.027989097565942506]
	TIME [epoch: 6.46 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024245170897447405		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.024245170897447405 | validation: 0.03400590535462917]
	TIME [epoch: 6.47 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0242921759334518		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.0242921759334518 | validation: 0.025777912349237323]
	TIME [epoch: 6.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02585116094680271		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.02585116094680271 | validation: 0.02315999153047196]
	TIME [epoch: 6.46 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025063918548950154		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.025063918548950154 | validation: 0.022053199864913747]
	TIME [epoch: 6.47 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022022274209274426		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.022022274209274426 | validation: 0.029288231893549406]
	TIME [epoch: 6.47 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.027010143537469444		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.027010143537469444 | validation: 0.03202866882666244]
	TIME [epoch: 6.46 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021903819557562675		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.021903819557562675 | validation: 0.041013385166774635]
	TIME [epoch: 6.46 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02421231403595317		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.02421231403595317 | validation: 0.03503932225195729]
	TIME [epoch: 6.46 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02263019051020096		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.02263019051020096 | validation: 0.03143598035013064]
	TIME [epoch: 6.48 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023416038287852856		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.023416038287852856 | validation: 0.026676033869562354]
	TIME [epoch: 6.49 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.021850425380643548		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.021850425380643548 | validation: 0.031028278255926543]
	TIME [epoch: 6.46 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024216823582804636		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.024216823582804636 | validation: 0.033135798194723266]
	TIME [epoch: 6.46 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023500125362964953		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.023500125362964953 | validation: 0.030898543590962158]
	TIME [epoch: 6.46 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02415700983184255		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.02415700983184255 | validation: 0.0359477960762865]
	TIME [epoch: 6.47 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02058380737906687		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.02058380737906687 | validation: 0.02777572408670529]
	TIME [epoch: 6.46 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020833242831466252		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.020833242831466252 | validation: 0.02831916981606194]
	TIME [epoch: 6.48 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.025672029449356103		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.025672029449356103 | validation: 0.027559414813333422]
	TIME [epoch: 6.48 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023406463442627066		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.023406463442627066 | validation: 0.02957406579752516]
	TIME [epoch: 6.47 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02355081872569919		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.02355081872569919 | validation: 0.030895655042143623]
	TIME [epoch: 6.46 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02479385225868902		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.02479385225868902 | validation: 0.03292127752315654]
	TIME [epoch: 6.47 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.018373933672537816		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.018373933672537816 | validation: 0.028886668294666445]
	TIME [epoch: 6.46 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02607007775239417		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.02607007775239417 | validation: 0.02348195958529714]
	TIME [epoch: 6.46 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.024982701491420276		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.024982701491420276 | validation: 0.030556184426485864]
	TIME [epoch: 6.47 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023989710805707866		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.023989710805707866 | validation: 0.03074597507462711]
	TIME [epoch: 6.48 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02500470293873055		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.02500470293873055 | validation: 0.027187210344061408]
	TIME [epoch: 6.46 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.020934516561442136		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.020934516561442136 | validation: 0.040263049005768395]
	TIME [epoch: 6.47 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026911297311545797		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.026911297311545797 | validation: 0.03479151647668388]
	TIME [epoch: 6.46 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.023390338776335638		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.023390338776335638 | validation: 0.029324162144877142]
	TIME [epoch: 6.48 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.022511068970369662		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.022511068970369662 | validation: 0.040345097066994635]
	TIME [epoch: 6.48 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.026987465104496365		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.026987465104496365 | validation: 0.0329281068115076]
	TIME [epoch: 6.47 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02589905832244713		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.02589905832244713 | validation: 0.025823731441828805]
	TIME [epoch: 6.5 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.02480032530325088		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.02480032530325088 | validation: 0.026116365519328638]
	TIME [epoch: 6.47 sec]
Finished training in 13576.775 seconds.
