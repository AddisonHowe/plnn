Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r2', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 776259337

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 11.950919961410134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 11.950919961410134 | validation: 11.292176262672799]
	TIME [epoch: 80.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.51613703417095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.51613703417095 | validation: 8.781162443046213]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 9.655539947883415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.655539947883415 | validation: 9.061260549668228]
	TIME [epoch: 6.46 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.349536570769708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.349536570769708 | validation: 7.715791931050225]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.704443342326889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.704443342326889 | validation: 7.687963560411244]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.355537824095926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.355537824095926 | validation: 7.308307420656978]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.22486770230539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.22486770230539 | validation: 6.985420045878915]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.774245989846941		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.774245989846941 | validation: 6.907229446801758]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.658311085872355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.658311085872355 | validation: 6.893269256868948]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.681703700772779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.681703700772779 | validation: 6.907203185250246]
	TIME [epoch: 6.46 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.706748766222427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.706748766222427 | validation: 6.776607188867577]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.65065678261044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.65065678261044 | validation: 6.7447912488097685]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.409761812291004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.409761812291004 | validation: 6.757970683944722]
	TIME [epoch: 6.44 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.548237542852058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.548237542852058 | validation: 7.096647635681007]
	TIME [epoch: 6.44 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.570558544909693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.570558544909693 | validation: 6.6694788029583245]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.405678684967893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.405678684967893 | validation: 6.69172621795808]
	TIME [epoch: 6.47 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.214289147244228		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.214289147244228 | validation: 6.833716895025109]
	TIME [epoch: 6.44 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.3099578194433965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3099578194433965 | validation: 6.744720931491161]
	TIME [epoch: 6.44 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.088095758510068		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.088095758510068 | validation: 6.863060669164732]
	TIME [epoch: 6.44 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.037986220704298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.037986220704298 | validation: 6.567812159237239]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.946395715273281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.946395715273281 | validation: 6.172838103517559]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.0964090714503225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.0964090714503225 | validation: 6.553065321594115]
	TIME [epoch: 6.45 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6043271915220485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6043271915220485 | validation: 6.028241835085886]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.466605210002032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.466605210002032 | validation: 5.627050585716686]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.009708398397035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.009708398397035 | validation: 5.856653940046329]
	TIME [epoch: 6.43 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.282929047421496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.282929047421496 | validation: 5.361367699968981]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.6284629254292335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6284629254292335 | validation: 4.755529347424246]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.104827173597826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.104827173597826 | validation: 5.293851676615573]
	TIME [epoch: 6.45 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.663081783527414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.663081783527414 | validation: 5.170253950092689]
	TIME [epoch: 6.45 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1307850738446295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1307850738446295 | validation: 4.490058027258157]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.2902770919113316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.2902770919113316 | validation: 5.055273300597535]
	TIME [epoch: 6.43 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1621793064399135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1621793064399135 | validation: 4.158687685903453]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6888777436151168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6888777436151168 | validation: 4.291380799510231]
	TIME [epoch: 6.43 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.887681008837678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.887681008837678 | validation: 4.10366970239199]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.536768628880345		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.536768628880345 | validation: 3.7663128040618474]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8610681975521306		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8610681975521306 | validation: 3.9861792413648276]
	TIME [epoch: 6.44 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.717838240835808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.717838240835808 | validation: 3.932581326193587]
	TIME [epoch: 6.43 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.241952202835777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.241952202835777 | validation: 3.7616723542792845]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4435154067089715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4435154067089715 | validation: 3.2317613922709656]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.430492589947357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.430492589947357 | validation: 3.6960138809153795]
	TIME [epoch: 6.44 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.204570416710901		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.204570416710901 | validation: 3.5497236126802374]
	TIME [epoch: 6.44 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.911622684370782		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.911622684370782 | validation: 3.0060371469205625]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.09198748282006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.09198748282006 | validation: 2.9771471209275853]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9195806682273333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9195806682273333 | validation: 3.6157254840421515]
	TIME [epoch: 6.44 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.390551543488199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.390551543488199 | validation: 3.303402137506081]
	TIME [epoch: 6.43 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.492364628687343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.492364628687343 | validation: 3.2444704890058826]
	TIME [epoch: 6.43 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9218235064415974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9218235064415974 | validation: 2.923782848521984]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6075710508325605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6075710508325605 | validation: 3.8308713078925956]
	TIME [epoch: 6.48 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0273605632119325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0273605632119325 | validation: 4.249269521414118]
	TIME [epoch: 6.44 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0365422079666957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0365422079666957 | validation: 2.776049198266303]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.45313621263449		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.45313621263449 | validation: 3.8066765307171564]
	TIME [epoch: 6.44 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.076090103017638		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.076090103017638 | validation: 2.5545491342336897]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_52.pth
	Model improved!!!
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.383027781693835		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.383027781693835 | validation: 4.170901221015212]
	TIME [epoch: 6.44 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5046543629437803		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 2.5046543629437803 | validation: 3.058610421793709]
	TIME [epoch: 6.44 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5555605459973063		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.5555605459973063 | validation: 3.0609961987228496]
	TIME [epoch: 6.45 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.481818614780612		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.481818614780612 | validation: 2.3256214749444974]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.577763608983471		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.577763608983471 | validation: 2.7303788089932755]
	TIME [epoch: 6.44 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3306736614325465		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 2.3306736614325465 | validation: 2.6151445236405664]
	TIME [epoch: 6.44 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4446285944838517		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.4446285944838517 | validation: 2.5306685932262067]
	TIME [epoch: 6.44 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2801650132955213		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 2.2801650132955213 | validation: 4.390367810723261]
	TIME [epoch: 6.45 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8595574495484466		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.8595574495484466 | validation: 2.7081066149405904]
	TIME [epoch: 6.44 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8111256045506243		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 1.8111256045506243 | validation: 2.2433206324803727]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_62.pth
	Model improved!!!
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3989933574649736		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.3989933574649736 | validation: 2.174985860486547]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1533945092173146		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.1533945092173146 | validation: 2.4487221739370946]
	TIME [epoch: 6.45 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.084991523893726		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 2.084991523893726 | validation: 2.987230597037975]
	TIME [epoch: 6.44 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.353995835621929		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.353995835621929 | validation: 3.1142782043197315]
	TIME [epoch: 6.44 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.216706421443961		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.216706421443961 | validation: 2.3348114575493604]
	TIME [epoch: 6.44 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.246778528964596		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.246778528964596 | validation: 2.654862813562138]
	TIME [epoch: 6.44 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.020232287361565		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.020232287361565 | validation: 3.5635110980352103]
	TIME [epoch: 6.46 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4906563371962953		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.4906563371962953 | validation: 2.348292016505136]
	TIME [epoch: 6.44 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8198592505075777		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.8198592505075777 | validation: 3.5014942818859764]
	TIME [epoch: 6.45 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3635195994614615		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.3635195994614615 | validation: 2.8711140694887867]
	TIME [epoch: 6.44 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0179812629048874		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.0179812629048874 | validation: 2.94175476188722]
	TIME [epoch: 6.44 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1226915200329133		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.1226915200329133 | validation: 2.719974710290675]
	TIME [epoch: 6.44 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8934829101947726		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.8934829101947726 | validation: 3.347465806064704]
	TIME [epoch: 6.44 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9688668940451055		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.9688668940451055 | validation: 2.258022120699114]
	TIME [epoch: 6.48 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9956082384568252		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.9956082384568252 | validation: 2.542520906540144]
	TIME [epoch: 6.44 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.02526935641175		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.02526935641175 | validation: 2.3936893014125036]
	TIME [epoch: 6.44 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.874722218299698		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.874722218299698 | validation: 2.5042260052601693]
	TIME [epoch: 6.44 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7931704552791727		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.7931704552791727 | validation: 1.9921041886488957]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_80.pth
	Model improved!!!
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8981663685535934		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.8981663685535934 | validation: 2.296053204958275]
	TIME [epoch: 6.44 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.791767476539821		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.791767476539821 | validation: 2.5903990056258848]
	TIME [epoch: 6.44 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9145407993604007		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.9145407993604007 | validation: 2.493928137472395]
	TIME [epoch: 6.46 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7731361789737494		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.7731361789737494 | validation: 2.7696842019619825]
	TIME [epoch: 6.44 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9508995940939313		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.9508995940939313 | validation: 1.9578045689700765]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6358556161541333		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.6358556161541333 | validation: 2.352295759926309]
	TIME [epoch: 6.44 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7475443806296365		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.7475443806296365 | validation: 1.7723345858028132]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8041871504777058		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.8041871504777058 | validation: 2.1461637909957685]
	TIME [epoch: 6.44 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8259794982975666		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.8259794982975666 | validation: 2.0970729168330915]
	TIME [epoch: 6.44 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.699029831290125		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.699029831290125 | validation: 2.1776166363663085]
	TIME [epoch: 6.47 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8293699033395918		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.8293699033395918 | validation: 1.745719135217672]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.146993538730735		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.146993538730735 | validation: 2.0923358439276702]
	TIME [epoch: 6.5 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6265232840072887		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.6265232840072887 | validation: 1.9494938997449378]
	TIME [epoch: 6.43 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7183765045654291		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.7183765045654291 | validation: 2.121747335750249]
	TIME [epoch: 6.43 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0349018074170466		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.0349018074170466 | validation: 2.4450922500092664]
	TIME [epoch: 6.44 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.900206012945692		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.900206012945692 | validation: 2.4944128515359503]
	TIME [epoch: 6.44 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.536235677636052		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 4.536235677636052 | validation: 2.8226116246504933]
	TIME [epoch: 6.46 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.398327784059256		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.398327784059256 | validation: 2.375493363381596]
	TIME [epoch: 6.45 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.726921497349562		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.726921497349562 | validation: 3.333163423715388]
	TIME [epoch: 6.46 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2429030686140634		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.2429030686140634 | validation: 3.1947406651986996]
	TIME [epoch: 6.45 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2945537453469913		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.2945537453469913 | validation: 2.5385263680013046]
	TIME [epoch: 6.44 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6913054428686607		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.6913054428686607 | validation: 2.240179005601539]
	TIME [epoch: 6.45 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.829816757873543		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.829816757873543 | validation: 1.9709217601494817]
	TIME [epoch: 6.45 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6521789176210704		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.6521789176210704 | validation: 2.2292144187697938]
	TIME [epoch: 6.48 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.683346955436045		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.683346955436045 | validation: 2.074452370506644]
	TIME [epoch: 6.45 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6188516860569364		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.6188516860569364 | validation: 2.335117770437154]
	TIME [epoch: 6.45 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8457848647673152		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.8457848647673152 | validation: 1.9573022573016579]
	TIME [epoch: 6.45 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7716225724864072		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.7716225724864072 | validation: 2.091971209069418]
	TIME [epoch: 6.45 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.909390988472648		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.909390988472648 | validation: 2.2312263060643556]
	TIME [epoch: 6.45 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5882077359385307		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.5882077359385307 | validation: 1.9644532867561664]
	TIME [epoch: 6.48 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6929576230144001		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.6929576230144001 | validation: 2.2903232945176994]
	TIME [epoch: 6.46 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6591820456428694		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.6591820456428694 | validation: 2.5305727358589345]
	TIME [epoch: 6.45 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.469393398700748		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.469393398700748 | validation: 3.4477382320452836]
	TIME [epoch: 6.45 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3069072011652887		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 2.3069072011652887 | validation: 2.775981188433616]
	TIME [epoch: 6.44 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5914292071266676		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.5914292071266676 | validation: 2.4844068496671077]
	TIME [epoch: 6.44 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.848573691580086		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.848573691580086 | validation: 2.1846298450842165]
	TIME [epoch: 6.44 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6387132967944391		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.6387132967944391 | validation: 2.2170802401781855]
	TIME [epoch: 6.48 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.576695566749445		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.576695566749445 | validation: 1.928050653136184]
	TIME [epoch: 6.45 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6259050967306197		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.6259050967306197 | validation: 1.835296531987491]
	TIME [epoch: 6.45 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4654766295026707		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.4654766295026707 | validation: 2.0864143473990517]
	TIME [epoch: 6.45 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5237340864940463		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.5237340864940463 | validation: 2.243740079801884]
	TIME [epoch: 6.46 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4614339623320483		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.4614339623320483 | validation: 1.8960292844133857]
	TIME [epoch: 6.45 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6100228381598485		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.6100228381598485 | validation: 2.300705498243174]
	TIME [epoch: 6.47 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5238660366574799		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.5238660366574799 | validation: 1.7905782077642942]
	TIME [epoch: 6.47 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4379600761358624		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.4379600761358624 | validation: 1.5448329898174376]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5413683845360031		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.5413683845360031 | validation: 2.0036015136814336]
	TIME [epoch: 6.45 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.290878465090461		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.290878465090461 | validation: 1.5897859947725608]
	TIME [epoch: 6.44 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3763113178658317		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.3763113178658317 | validation: 2.728869773753822]
	TIME [epoch: 6.45 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6600369147771836		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.6600369147771836 | validation: 1.728777369990214]
	TIME [epoch: 6.43 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2824619384180764		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.2824619384180764 | validation: 1.6622915712186859]
	TIME [epoch: 6.45 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3462659332065599		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.3462659332065599 | validation: 2.395579369391675]
	TIME [epoch: 6.48 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4882855480231159		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.4882855480231159 | validation: 2.5616964050850966]
	TIME [epoch: 6.45 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5915227658300561		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.5915227658300561 | validation: 1.7225005850172839]
	TIME [epoch: 6.45 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.345760504771234		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.345760504771234 | validation: 1.7517102517349121]
	TIME [epoch: 6.44 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4040304780295307		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.4040304780295307 | validation: 1.7203077516408252]
	TIME [epoch: 6.45 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5151486099428004		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.5151486099428004 | validation: 1.6723525674506237]
	TIME [epoch: 6.44 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3311109918082618		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.3311109918082618 | validation: 2.159798948192845]
	TIME [epoch: 6.46 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4887952112692124		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.4887952112692124 | validation: 1.7530411232675545]
	TIME [epoch: 6.49 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3587408709075794		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.3587408709075794 | validation: 1.5042996674276157]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.352012207940713		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.352012207940713 | validation: 1.2165186885472892]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2656396160268613		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.2656396160268613 | validation: 1.8435078858271698]
	TIME [epoch: 6.45 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3690456134352718		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.3690456134352718 | validation: 1.4161891815292296]
	TIME [epoch: 6.46 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1156462800815543		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.1156462800815543 | validation: 1.2166453636800811]
	TIME [epoch: 6.45 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.260799683552428		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.260799683552428 | validation: 2.3371006417508604]
	TIME [epoch: 6.46 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6678503537450045		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.6678503537450045 | validation: 1.5710744657735856]
	TIME [epoch: 6.48 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.413642204431191		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.413642204431191 | validation: 1.5111456789337978]
	TIME [epoch: 6.45 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2895364309006307		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.2895364309006307 | validation: 1.5640869056131141]
	TIME [epoch: 6.45 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.099019649516882		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.099019649516882 | validation: 1.418407167979092]
	TIME [epoch: 6.45 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3746494092942996		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.3746494092942996 | validation: 1.5591525041324878]
	TIME [epoch: 6.45 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1333720831268148		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.1333720831268148 | validation: 1.4452581806218927]
	TIME [epoch: 6.45 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1521656027071645		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.1521656027071645 | validation: 1.836187387854164]
	TIME [epoch: 6.45 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3880076487564401		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.3880076487564401 | validation: 1.1871150362576894]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9685170417358279		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.9685170417358279 | validation: 3.598262354781746]
	TIME [epoch: 6.46 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.644714979298829		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.644714979298829 | validation: 1.7151261723724378]
	TIME [epoch: 6.72 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2207491702315536		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.2207491702315536 | validation: 1.6880984087146667]
	TIME [epoch: 6.45 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2942051632980531		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.2942051632980531 | validation: 1.7832406310068991]
	TIME [epoch: 6.44 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3466888740677303		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.3466888740677303 | validation: 1.3004515243302217]
	TIME [epoch: 6.44 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1489652210402197		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 1.1489652210402197 | validation: 1.9506357771452076]
	TIME [epoch: 6.44 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.360707841082507		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.360707841082507 | validation: 1.345847257203775]
	TIME [epoch: 6.47 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.376507624274696		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.376507624274696 | validation: 2.3209995696270465]
	TIME [epoch: 6.45 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5297664476035235		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 1.5297664476035235 | validation: 1.5023840637128842]
	TIME [epoch: 6.44 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0772565332808708		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.0772565332808708 | validation: 1.7757276352151599]
	TIME [epoch: 6.45 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.283635873484894		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.283635873484894 | validation: 1.1629358462840909]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0514464655163471		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 1.0514464655163471 | validation: 1.693913687223606]
	TIME [epoch: 6.45 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4165476670021186		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 1.4165476670021186 | validation: 1.6718977449097288]
	TIME [epoch: 6.44 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2186545113732363		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 1.2186545113732363 | validation: 1.54072998392226]
	TIME [epoch: 6.46 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5859702917842455		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.5859702917842455 | validation: 1.4168291053517539]
	TIME [epoch: 6.45 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1690581935919646		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.1690581935919646 | validation: 1.4603661375969352]
	TIME [epoch: 6.44 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3410843870026694		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.3410843870026694 | validation: 1.0917375920578969]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_169.pth
	Model improved!!!
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0771735137671596		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.0771735137671596 | validation: 1.3200972349618514]
	TIME [epoch: 6.44 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0701207588694701		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.0701207588694701 | validation: 1.6989269595476133]
	TIME [epoch: 6.45 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2381565039414955		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.2381565039414955 | validation: 1.2862135139253057]
	TIME [epoch: 6.44 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0609946252237217		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.0609946252237217 | validation: 2.0451766303867767]
	TIME [epoch: 6.47 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3181372357547427		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.3181372357547427 | validation: 1.1428515954129363]
	TIME [epoch: 6.45 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2816559677345594		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.2816559677345594 | validation: 1.2898814356202828]
	TIME [epoch: 6.44 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.154882565620528		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 1.154882565620528 | validation: 1.0803254362118098]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_176.pth
	Model improved!!!
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0964137603003135		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.0964137603003135 | validation: 1.1115498253448726]
	TIME [epoch: 6.44 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9739300889444911		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.9739300889444911 | validation: 1.1112191682918515]
	TIME [epoch: 6.44 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.121589058618157		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.121589058618157 | validation: 0.9064980264778731]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0490663715277362		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.0490663715277362 | validation: 3.27659551043276]
	TIME [epoch: 6.47 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9538976352235489		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 1.9538976352235489 | validation: 1.1588233890780604]
	TIME [epoch: 6.44 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0916742078615598		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.0916742078615598 | validation: 0.920657053269664]
	TIME [epoch: 6.45 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2794120929667345		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.2794120929667345 | validation: 1.1546888113697584]
	TIME [epoch: 6.44 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9890795542222333		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.9890795542222333 | validation: 0.8746929187292972]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_184.pth
	Model improved!!!
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022872209620071		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.022872209620071 | validation: 0.9747632559015754]
	TIME [epoch: 6.45 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7599607060306284		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 1.7599607060306284 | validation: 0.9937325324885938]
	TIME [epoch: 6.43 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.239791449698602		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.239791449698602 | validation: 1.2264859815545985]
	TIME [epoch: 6.47 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1139283606187025		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.1139283606187025 | validation: 1.0049307189615726]
	TIME [epoch: 6.44 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0265841046871036		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.0265841046871036 | validation: 1.107828353442428]
	TIME [epoch: 6.44 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9305269339403524		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 0.9305269339403524 | validation: 1.0686691702298394]
	TIME [epoch: 6.44 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.187579064254808		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.187579064254808 | validation: 1.6932866356723597]
	TIME [epoch: 6.44 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0779253415926076		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.0779253415926076 | validation: 0.9203917466709249]
	TIME [epoch: 6.44 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0697027111097477		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.0697027111097477 | validation: 0.8517761170908545]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.168373925441749		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.168373925441749 | validation: 2.9628010662306354]
	TIME [epoch: 6.46 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5809465394201467		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.5809465394201467 | validation: 0.9515533117857916]
	TIME [epoch: 6.45 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9777097782598192		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.9777097782598192 | validation: 1.5483840689386694]
	TIME [epoch: 6.45 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029625549691506		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 1.029625549691506 | validation: 1.1771319946975778]
	TIME [epoch: 6.44 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9195122969653448		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.9195122969653448 | validation: 1.4382244782884204]
	TIME [epoch: 6.45 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2192354896144533		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 1.2192354896144533 | validation: 1.074182401551443]
	TIME [epoch: 6.44 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.871938730522966		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.871938730522966 | validation: 1.3554370077697377]
	TIME [epoch: 6.45 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0381757741990048		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.0381757741990048 | validation: 0.8089051841839606]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9801018534483318		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.9801018534483318 | validation: 1.238438783323798]
	TIME [epoch: 6.47 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0039783739994153		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.0039783739994153 | validation: 1.0160245310178073]
	TIME [epoch: 6.46 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9936112373545678		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.9936112373545678 | validation: 1.2864094680000477]
	TIME [epoch: 6.46 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2032012452154928		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 1.2032012452154928 | validation: 0.7730950940876707]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_205.pth
	Model improved!!!
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8684724715455443		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.8684724715455443 | validation: 1.1009237046054339]
	TIME [epoch: 6.45 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1764126394218155		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.1764126394218155 | validation: 1.0192315678844457]
	TIME [epoch: 6.45 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8919484354769901		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.8919484354769901 | validation: 0.7973824461012268]
	TIME [epoch: 6.47 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8419073925768681		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.8419073925768681 | validation: 0.906560711836948]
	TIME [epoch: 6.47 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.008326453250659		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 1.008326453250659 | validation: 0.844010053579851]
	TIME [epoch: 6.45 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0394384266994838		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 1.0394384266994838 | validation: 1.7922727380929824]
	TIME [epoch: 6.45 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1926770903951576		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.1926770903951576 | validation: 0.9615260816784406]
	TIME [epoch: 6.49 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8275222441570287		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.8275222441570287 | validation: 0.7794913749954168]
	TIME [epoch: 6.46 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7776775750511731		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.7776775750511731 | validation: 1.2953110517927444]
	TIME [epoch: 6.46 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0681447277781098		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 1.0681447277781098 | validation: 1.2448523220387744]
	TIME [epoch: 6.46 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2136173006751403		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.2136173006751403 | validation: 1.0522296026103661]
	TIME [epoch: 6.49 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8902492196336768		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.8902492196336768 | validation: 1.186147785890903]
	TIME [epoch: 6.46 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.003067788565541		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 1.003067788565541 | validation: 0.7843137106762104]
	TIME [epoch: 6.45 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.044218894578272		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.044218894578272 | validation: 0.7380605947066273]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1134232297763278		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 1.1134232297763278 | validation: 1.376207960845171]
	TIME [epoch: 6.45 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0041329274828352		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.0041329274828352 | validation: 1.9379967135468967]
	TIME [epoch: 6.45 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6555421254021827		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.6555421254021827 | validation: 2.0294576819466337]
	TIME [epoch: 6.45 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2621984699340274		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.2621984699340274 | validation: 1.0289494284237852]
	TIME [epoch: 6.48 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9438937418758447		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.9438937418758447 | validation: 0.8585166084594639]
	TIME [epoch: 6.46 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.868140238957988		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.868140238957988 | validation: 1.2663037871638985]
	TIME [epoch: 6.46 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8130440645922741		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.8130440645922741 | validation: 0.657462970778258]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_226.pth
	Model improved!!!
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.988546048916263		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.988546048916263 | validation: 0.8635264100056079]
	TIME [epoch: 6.46 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.766279373881932		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.766279373881932 | validation: 0.8564263785384272]
	TIME [epoch: 6.45 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8599441829143641		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8599441829143641 | validation: 0.8253652938165215]
	TIME [epoch: 6.46 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9378835283832199		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.9378835283832199 | validation: 0.7488882953145074]
	TIME [epoch: 6.48 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.78827020540047		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.78827020540047 | validation: 0.755380383489597]
	TIME [epoch: 6.46 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9251143075024899		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.9251143075024899 | validation: 0.8781147784566821]
	TIME [epoch: 6.45 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8467803250037639		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.8467803250037639 | validation: 0.8595635794316775]
	TIME [epoch: 6.46 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.872728958887701		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.872728958887701 | validation: 0.8821454045252426]
	TIME [epoch: 6.46 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.069713101914171		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 1.069713101914171 | validation: 0.7285829399076584]
	TIME [epoch: 6.45 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7898835981155037		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.7898835981155037 | validation: 0.6780936590154317]
	TIME [epoch: 6.46 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9183758824873575		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.9183758824873575 | validation: 1.0474182829891006]
	TIME [epoch: 6.48 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0967361468004642		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 1.0967361468004642 | validation: 0.8065143771101796]
	TIME [epoch: 6.46 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.029322460536448		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 1.029322460536448 | validation: 0.7733719093338733]
	TIME [epoch: 6.45 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170651372884346		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.7170651372884346 | validation: 0.8072476342025462]
	TIME [epoch: 6.46 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8431166512791661		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.8431166512791661 | validation: 0.7596645703435141]
	TIME [epoch: 6.45 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8340682352935428		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.8340682352935428 | validation: 0.7892293615441931]
	TIME [epoch: 6.45 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7086649761690565		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.7086649761690565 | validation: 0.644817405417409]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_243.pth
	Model improved!!!
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7611570953852205		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.7611570953852205 | validation: 1.2003082018765334]
	TIME [epoch: 6.49 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.792006734831129		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.792006734831129 | validation: 0.9161378314011305]
	TIME [epoch: 6.46 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8129603367293301		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.8129603367293301 | validation: 0.7096755692620912]
	TIME [epoch: 6.46 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8095569281700643		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.8095569281700643 | validation: 1.0243956461189199]
	TIME [epoch: 6.46 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9566912933517233		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.9566912933517233 | validation: 0.7785297774461796]
	TIME [epoch: 6.46 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7749979653889526		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.7749979653889526 | validation: 0.7615816213234256]
	TIME [epoch: 6.46 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7529758375683084		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.7529758375683084 | validation: 1.0468453790535193]
	TIME [epoch: 6.46 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.879400149032943		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.879400149032943 | validation: 0.9144797899164959]
	TIME [epoch: 6.46 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9227972845385961		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.9227972845385961 | validation: 0.8924484780816352]
	TIME [epoch: 6.45 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7479266617061586		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.7479266617061586 | validation: 0.6367299455748848]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_253.pth
	Model improved!!!
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8077035733237528		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.8077035733237528 | validation: 1.146784021222799]
	TIME [epoch: 6.44 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7839013483692477		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.7839013483692477 | validation: 0.8190968255537945]
	TIME [epoch: 6.43 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7842200861625234		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7842200861625234 | validation: 0.7053009068930658]
	TIME [epoch: 6.43 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8104189918765552		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.8104189918765552 | validation: 1.1444566218482675]
	TIME [epoch: 6.44 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6729734892152903		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.6729734892152903 | validation: 0.6760890359585519]
	TIME [epoch: 6.45 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7228607237647098		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.7228607237647098 | validation: 0.9567509186215193]
	TIME [epoch: 6.46 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8893353985171222		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.8893353985171222 | validation: 1.9638515347411576]
	TIME [epoch: 6.43 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2857070447867078		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 1.2857070447867078 | validation: 0.8619856108002037]
	TIME [epoch: 6.44 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.829524969732281		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.829524969732281 | validation: 0.7482360789082975]
	TIME [epoch: 6.44 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7538446884771707		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.7538446884771707 | validation: 0.8111724134939572]
	TIME [epoch: 6.44 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190851395503135		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.7190851395503135 | validation: 0.7551128068923021]
	TIME [epoch: 6.43 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.777694838302684		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.777694838302684 | validation: 0.9673143835731353]
	TIME [epoch: 6.45 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694960409613379		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.694960409613379 | validation: 0.6509840278749951]
	TIME [epoch: 6.47 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8105016573247942		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.8105016573247942 | validation: 0.8254772824378099]
	TIME [epoch: 6.44 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8126445904657634		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.8126445904657634 | validation: 0.5555532010377485]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701267928595852		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.701267928595852 | validation: 0.6541544873005708]
	TIME [epoch: 6.46 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8177948292963523		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.8177948292963523 | validation: 0.6356819533184601]
	TIME [epoch: 6.45 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7038467948091456		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.7038467948091456 | validation: 0.5004652817768258]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7508864442274613		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7508864442274613 | validation: 0.705942315148724]
	TIME [epoch: 6.47 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7016325502974706		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.7016325502974706 | validation: 1.3094774873608148]
	TIME [epoch: 6.47 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9817479032286925		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.9817479032286925 | validation: 0.841888680858086]
	TIME [epoch: 6.45 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7662978098188051		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.7662978098188051 | validation: 0.5365831070477095]
	TIME [epoch: 6.46 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931241530497745		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.6931241530497745 | validation: 0.8759739601052621]
	TIME [epoch: 6.44 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7875939353536352		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.7875939353536352 | validation: 0.6768582901830071]
	TIME [epoch: 6.45 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6468706096741177		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.6468706096741177 | validation: 0.6303382150545263]
	TIME [epoch: 6.46 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6325560506198896		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6325560506198896 | validation: 0.5968566529750774]
	TIME [epoch: 6.47 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7036162966256653		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.7036162966256653 | validation: 0.9237567628585143]
	TIME [epoch: 6.5 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7550932379920843		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.7550932379920843 | validation: 0.8741485738938601]
	TIME [epoch: 6.47 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7626093252084098		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7626093252084098 | validation: 0.9153116531224629]
	TIME [epoch: 6.46 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9685667515647812		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.9685667515647812 | validation: 2.5204180737475417]
	TIME [epoch: 6.45 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6980435255911535		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 1.6980435255911535 | validation: 0.6188703848695728]
	TIME [epoch: 6.46 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7031228105957583		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.7031228105957583 | validation: 0.6690116666561857]
	TIME [epoch: 6.45 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6385269348587986		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.6385269348587986 | validation: 0.6869021975138812]
	TIME [epoch: 6.46 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6497075058457012		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6497075058457012 | validation: 0.504995453345879]
	TIME [epoch: 6.48 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.663122269394886		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.663122269394886 | validation: 0.6820839533838892]
	TIME [epoch: 6.47 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6472258353187142		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.6472258353187142 | validation: 0.43309625083513864]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7953720974022913		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.7953720974022913 | validation: 0.7621696575713867]
	TIME [epoch: 6.45 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681742437001113		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.681742437001113 | validation: 0.7298664472625979]
	TIME [epoch: 6.46 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5975515545958088		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.5975515545958088 | validation: 1.3814795088400715]
	TIME [epoch: 6.45 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8106931397245954		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.8106931397245954 | validation: 0.44124299701215364]
	TIME [epoch: 6.46 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6536145655523284		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.6536145655523284 | validation: 0.5500548010272259]
	TIME [epoch: 6.5 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6332513495136922		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.6332513495136922 | validation: 1.0161965689384242]
	TIME [epoch: 6.46 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701704948433858		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.701704948433858 | validation: 0.5736027243228339]
	TIME [epoch: 6.46 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6727979124033008		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.6727979124033008 | validation: 0.7231556297922372]
	TIME [epoch: 6.46 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993523770927379		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.6993523770927379 | validation: 0.9199856852588946]
	TIME [epoch: 6.46 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6232182909826569		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.6232182909826569 | validation: 0.7355638651494517]
	TIME [epoch: 6.45 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6946465161644615		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.6946465161644615 | validation: 0.5741685705156386]
	TIME [epoch: 6.46 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5021320624848724		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.5021320624848724 | validation: 1.0514295455601348]
	TIME [epoch: 6.5 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7845319645884299		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.7845319645884299 | validation: 0.5187316754749068]
	TIME [epoch: 6.47 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6027569827222933		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.6027569827222933 | validation: 0.7777187454439098]
	TIME [epoch: 6.46 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.668626579213505		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.668626579213505 | validation: 0.8628460043492048]
	TIME [epoch: 6.47 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7328910554898465		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.7328910554898465 | validation: 0.5282530475204688]
	TIME [epoch: 6.46 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.780669892659452		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.780669892659452 | validation: 0.5556071239541184]
	TIME [epoch: 6.46 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.771476967419411		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.771476967419411 | validation: 0.5903171064218483]
	TIME [epoch: 6.46 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6211729387634916		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.6211729387634916 | validation: 0.5650980907877661]
	TIME [epoch: 6.49 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5994364577052907		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.5994364577052907 | validation: 0.6250673642046961]
	TIME [epoch: 6.47 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6386751472276267		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.6386751472276267 | validation: 0.652273148347223]
	TIME [epoch: 6.47 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6124552676476902		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6124552676476902 | validation: 0.5721317615156974]
	TIME [epoch: 6.46 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7058150410651838		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.7058150410651838 | validation: 0.7728053624367379]
	TIME [epoch: 6.46 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7277179698450684		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.7277179698450684 | validation: 0.4678219827746001]
	TIME [epoch: 6.45 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507826613616107		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5507826613616107 | validation: 0.5495348387285084]
	TIME [epoch: 6.47 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7545719106712727		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.7545719106712727 | validation: 0.5368539111049391]
	TIME [epoch: 6.49 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6989056298434758		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.6989056298434758 | validation: 0.5512418366947344]
	TIME [epoch: 6.46 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.610419166641852		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.610419166641852 | validation: 0.4537263859487237]
	TIME [epoch: 6.47 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4939163279433245		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.4939163279433245 | validation: 0.6378815469371989]
	TIME [epoch: 6.46 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5139807865928782		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.5139807865928782 | validation: 0.7247929171234816]
	TIME [epoch: 6.46 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6540546566088064		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.6540546566088064 | validation: 0.8160727937351311]
	TIME [epoch: 6.45 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7876350556151225		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.7876350556151225 | validation: 0.6706654220895143]
	TIME [epoch: 6.45 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5745897818763909		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5745897818763909 | validation: 0.8146086938310184]
	TIME [epoch: 6.47 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7157200961519032		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7157200961519032 | validation: 0.6268339552576702]
	TIME [epoch: 6.48 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6736212907998079		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.6736212907998079 | validation: 1.0004259385404537]
	TIME [epoch: 6.46 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.685957366190126		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.685957366190126 | validation: 0.6203446640589778]
	TIME [epoch: 6.46 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5828635305403749		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5828635305403749 | validation: 0.9951664927247384]
	TIME [epoch: 6.47 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8405605635510573		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.8405605635510573 | validation: 1.3612663380439802]
	TIME [epoch: 6.46 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732724914071828		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.732724914071828 | validation: 0.8621750240691697]
	TIME [epoch: 6.46 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5886557268826453		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.5886557268826453 | validation: 0.6926398105463645]
	TIME [epoch: 6.47 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.572417454150854		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.572417454150854 | validation: 0.38818086257183665]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_330.pth
	Model improved!!!
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8150696975748842		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.8150696975748842 | validation: 0.9539908333492011]
	TIME [epoch: 6.46 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8431393528956761		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8431393528956761 | validation: 0.5315960281977743]
	TIME [epoch: 6.45 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421751305008617		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.6421751305008617 | validation: 0.42519273016722636]
	TIME [epoch: 6.45 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4859247319530275		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.4859247319530275 | validation: 0.5087764547973326]
	TIME [epoch: 6.45 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5448021843918494		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5448021843918494 | validation: 0.5353395371686415]
	TIME [epoch: 6.46 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6011592757621275		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.6011592757621275 | validation: 0.4368234269553963]
	TIME [epoch: 6.46 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7216872205698934		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7216872205698934 | validation: 0.542022564163962]
	TIME [epoch: 6.49 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6205101621333089		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.6205101621333089 | validation: 0.3874046079550552]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6155459028146089		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.6155459028146089 | validation: 0.4285127863115711]
	TIME [epoch: 6.46 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293726272849348		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.5293726272849348 | validation: 0.47896331741946063]
	TIME [epoch: 6.45 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.854359189912369		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.854359189912369 | validation: 0.934202580000895]
	TIME [epoch: 6.44 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6118312840841067		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.6118312840841067 | validation: 0.46665789348801695]
	TIME [epoch: 6.45 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5547752393327035		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.5547752393327035 | validation: 0.6196749521551038]
	TIME [epoch: 6.46 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5733304483887699		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.5733304483887699 | validation: 1.3076032800382935]
	TIME [epoch: 6.49 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9253402857910616		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.9253402857910616 | validation: 0.445719059157975]
	TIME [epoch: 6.46 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5682035539727348		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.5682035539727348 | validation: 0.795498529339879]
	TIME [epoch: 6.47 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6309480468804292		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.6309480468804292 | validation: 0.6047468923477958]
	TIME [epoch: 6.46 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5216462993657676		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.5216462993657676 | validation: 0.402136021373876]
	TIME [epoch: 6.47 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5696751903245685		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.5696751903245685 | validation: 0.675870551915867]
	TIME [epoch: 6.46 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5572577424397591		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.5572577424397591 | validation: 0.64501085396779]
	TIME [epoch: 6.46 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4975259629821545		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.4975259629821545 | validation: 0.8067719588435104]
	TIME [epoch: 6.49 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7266675008612823		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.7266675008612823 | validation: 0.5943839083481111]
	TIME [epoch: 6.47 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6387848594203467		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.6387848594203467 | validation: 0.4349967792159093]
	TIME [epoch: 6.45 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.509371123840352		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.509371123840352 | validation: 0.6593888130829814]
	TIME [epoch: 6.46 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5172340708114335		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5172340708114335 | validation: 0.8299791133598186]
	TIME [epoch: 6.45 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5994581521135076		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.5994581521135076 | validation: 0.6522468172464718]
	TIME [epoch: 6.46 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5682310987566337		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.5682310987566337 | validation: 0.6187106663387367]
	TIME [epoch: 6.44 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936470190111938		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.5936470190111938 | validation: 0.4031554546610325]
	TIME [epoch: 6.49 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.486431652327545		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.486431652327545 | validation: 0.48670239818704875]
	TIME [epoch: 6.46 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5492227007342806		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5492227007342806 | validation: 0.5538097872722786]
	TIME [epoch: 6.47 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5142215531344134		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.5142215531344134 | validation: 0.590017632952245]
	TIME [epoch: 6.45 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5567611402459336		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.5567611402459336 | validation: 0.5834702619636741]
	TIME [epoch: 6.47 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5700379619400531		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.5700379619400531 | validation: 0.5764759352123724]
	TIME [epoch: 6.45 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5685461986480828		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.5685461986480828 | validation: 0.8496428044361654]
	TIME [epoch: 6.46 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5425327578017592		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.5425327578017592 | validation: 0.6971958089010838]
	TIME [epoch: 6.5 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5549821097411997		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.5549821097411997 | validation: 0.5753960630484026]
	TIME [epoch: 6.47 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4959548018227741		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.4959548018227741 | validation: 0.33049428577439555]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47829687568562096		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.47829687568562096 | validation: 0.7744546492066311]
	TIME [epoch: 6.46 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6452365437575224		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.6452365437575224 | validation: 0.8840890468981083]
	TIME [epoch: 6.46 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5631984971969257		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.5631984971969257 | validation: 0.9316010421305471]
	TIME [epoch: 6.45 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5185960076345022		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.5185960076345022 | validation: 0.42236946823076055]
	TIME [epoch: 6.47 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5691846261133123		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.5691846261133123 | validation: 0.3656360949214719]
	TIME [epoch: 6.49 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6382737783442289		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.6382737783442289 | validation: 0.9929998956038703]
	TIME [epoch: 6.46 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.619104438296144		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.619104438296144 | validation: 0.4043232780754481]
	TIME [epoch: 6.45 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.436094455821168		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.436094455821168 | validation: 0.5670221248791016]
	TIME [epoch: 6.46 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5612238082442758		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.5612238082442758 | validation: 0.4781145426717106]
	TIME [epoch: 6.46 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.578660222570656		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.578660222570656 | validation: 0.6289494241234566]
	TIME [epoch: 6.46 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8471484150870854		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.8471484150870854 | validation: 0.5215431502728479]
	TIME [epoch: 6.46 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4773473147582752		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.4773473147582752 | validation: 0.39737148190799076]
	TIME [epoch: 6.47 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5072405156584737		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.5072405156584737 | validation: 0.6392938521684565]
	TIME [epoch: 6.48 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8657496059795508		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.8657496059795508 | validation: 0.5865259358601267]
	TIME [epoch: 6.46 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5380079038819741		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.5380079038819741 | validation: 0.531837752460215]
	TIME [epoch: 6.45 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5732564789079488		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.5732564789079488 | validation: 0.35193155075481175]
	TIME [epoch: 6.45 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4781688360743801		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.4781688360743801 | validation: 0.5843506410275409]
	TIME [epoch: 6.47 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.806911249626187		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.806911249626187 | validation: 0.40064339060026455]
	TIME [epoch: 6.45 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.500362501705024		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.500362501705024 | validation: 0.6508153857779585]
	TIME [epoch: 6.47 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6265490010428774		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.6265490010428774 | validation: 0.49967828172954415]
	TIME [epoch: 6.47 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6106094229349419		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.6106094229349419 | validation: 0.3932605162607343]
	TIME [epoch: 6.46 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46894070664879967		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.46894070664879967 | validation: 0.6944140137753277]
	TIME [epoch: 6.44 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6059964478042422		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.6059964478042422 | validation: 0.4206615665933929]
	TIME [epoch: 6.45 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404860876663356		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.4404860876663356 | validation: 0.3944922413066406]
	TIME [epoch: 6.45 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5483141936973681		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.5483141936973681 | validation: 0.49684074190842337]
	TIME [epoch: 6.45 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.510025290872227		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.510025290872227 | validation: 0.5746916462914112]
	TIME [epoch: 6.47 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4891469898537205		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.4891469898537205 | validation: 0.41870666719753596]
	TIME [epoch: 6.48 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.563931740670915		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.563931740670915 | validation: 0.7008525538676803]
	TIME [epoch: 6.46 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.576179349086202		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.576179349086202 | validation: 0.4501358055034483]
	TIME [epoch: 6.46 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5319725151017791		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5319725151017791 | validation: 0.5069556264416717]
	TIME [epoch: 6.46 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4354745814391336		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.4354745814391336 | validation: 0.8380781462880253]
	TIME [epoch: 6.46 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6301700007299827		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.6301700007299827 | validation: 0.4373314083373023]
	TIME [epoch: 6.45 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47120914861487884		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.47120914861487884 | validation: 0.5322578827936504]
	TIME [epoch: 6.46 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.528350148334944		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.528350148334944 | validation: 0.4741304905564539]
	TIME [epoch: 6.48 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46884876076998855		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.46884876076998855 | validation: 0.5794529403074423]
	TIME [epoch: 6.46 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7446524194884987		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.7446524194884987 | validation: 1.0544971365797124]
	TIME [epoch: 6.46 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8336507331620443		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.8336507331620443 | validation: 0.5896242011803218]
	TIME [epoch: 6.46 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6091537449922012		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.6091537449922012 | validation: 0.5872304560015443]
	TIME [epoch: 6.45 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5908246591108517		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.5908246591108517 | validation: 0.7126250036130768]
	TIME [epoch: 6.45 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5624574903239146		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5624574903239146 | validation: 0.38508736580146063]
	TIME [epoch: 6.46 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4838277050663984		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.4838277050663984 | validation: 0.5342868833184085]
	TIME [epoch: 6.49 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5390279506162987		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.5390279506162987 | validation: 0.37791932398275285]
	TIME [epoch: 6.45 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5142314314296931		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.5142314314296931 | validation: 0.41062921432671673]
	TIME [epoch: 6.45 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49924831677313686		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.49924831677313686 | validation: 0.4332977652414702]
	TIME [epoch: 6.46 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5089723882213498		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.5089723882213498 | validation: 0.35509858620253965]
	TIME [epoch: 6.46 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46610180427351705		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.46610180427351705 | validation: 0.5696148683390848]
	TIME [epoch: 6.46 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49259265155655296		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.49259265155655296 | validation: 0.5731071266578914]
	TIME [epoch: 6.45 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49013962942812705		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.49013962942812705 | validation: 0.4048717473913115]
	TIME [epoch: 6.49 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.539089639993534		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.539089639993534 | validation: 0.5102175961985878]
	TIME [epoch: 6.46 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5488683349910278		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.5488683349910278 | validation: 0.5060021652632356]
	TIME [epoch: 6.45 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4900101705448069		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.4900101705448069 | validation: 0.48276941415912666]
	TIME [epoch: 6.46 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4714448806011278		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.4714448806011278 | validation: 0.590886262492915]
	TIME [epoch: 6.46 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4723496924354643		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.4723496924354643 | validation: 0.5236470785188435]
	TIME [epoch: 6.45 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.460478064288001		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.460478064288001 | validation: 0.3520039668122293]
	TIME [epoch: 6.45 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44776831828423497		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.44776831828423497 | validation: 0.4664927287625364]
	TIME [epoch: 6.49 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45910452729635925		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.45910452729635925 | validation: 0.7037198904620653]
	TIME [epoch: 6.46 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5939610730412233		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.5939610730412233 | validation: 0.47170374395024484]
	TIME [epoch: 6.45 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4293867987528081		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.4293867987528081 | validation: 0.6464214676622263]
	TIME [epoch: 6.45 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4414658873382595		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.4414658873382595 | validation: 0.3613731120567483]
	TIME [epoch: 6.45 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4138722980862678		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.4138722980862678 | validation: 0.40066159608893115]
	TIME [epoch: 6.46 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4761069328922065		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.4761069328922065 | validation: 0.4248701311453187]
	TIME [epoch: 6.45 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4358765706165518		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.4358765706165518 | validation: 0.4528760013314543]
	TIME [epoch: 6.47 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4506198647666032		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.4506198647666032 | validation: 0.9701392547318434]
	TIME [epoch: 6.47 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5882781423447577		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.5882781423447577 | validation: 0.4260834219185831]
	TIME [epoch: 6.45 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5313997104012438		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.5313997104012438 | validation: 0.35514239770755396]
	TIME [epoch: 6.45 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43571239155997565		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.43571239155997565 | validation: 0.3346302692457484]
	TIME [epoch: 6.45 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4233744955556193		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.4233744955556193 | validation: 0.41056634030091876]
	TIME [epoch: 6.45 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5386035348064038		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.5386035348064038 | validation: 0.9439795738783644]
	TIME [epoch: 6.45 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6783094748620186		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.6783094748620186 | validation: 0.370847691640318]
	TIME [epoch: 6.47 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6617848149736494		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.6617848149736494 | validation: 0.40556305149996336]
	TIME [epoch: 6.47 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4464582222940797		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.4464582222940797 | validation: 0.5415873762237132]
	TIME [epoch: 6.46 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45460062287128317		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.45460062287128317 | validation: 0.388767772171275]
	TIME [epoch: 6.46 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704150183784441		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.3704150183784441 | validation: 0.34741865641335856]
	TIME [epoch: 6.45 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4175801211635004		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.4175801211635004 | validation: 0.5788484072506969]
	TIME [epoch: 6.46 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4220035487334469		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.4220035487334469 | validation: 0.2859263959020693]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_442.pth
	Model improved!!!
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5334148636290044		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.5334148636290044 | validation: 0.47707417491764326]
	TIME [epoch: 6.46 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43091153012325567		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.43091153012325567 | validation: 0.34213783282782095]
	TIME [epoch: 6.49 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5262775453349366		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5262775453349366 | validation: 0.36528185486394676]
	TIME [epoch: 6.47 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929290755303473		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.3929290755303473 | validation: 0.33247048725724454]
	TIME [epoch: 6.45 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35335893284089265		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.35335893284089265 | validation: 0.5448292957936541]
	TIME [epoch: 6.46 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.472323821532064		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.472323821532064 | validation: 0.36050972695518824]
	TIME [epoch: 6.54 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4001658110049839		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.4001658110049839 | validation: 0.55318911146476]
	TIME [epoch: 6.46 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3994371129046597		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.3994371129046597 | validation: 0.23997214845327833]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_450.pth
	Model improved!!!
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40547594062322556		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.40547594062322556 | validation: 0.38061908063000816]
	TIME [epoch: 6.48 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40506521431370196		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.40506521431370196 | validation: 0.4784332540426008]
	TIME [epoch: 6.46 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3707478317636044		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.3707478317636044 | validation: 0.6315376998066387]
	TIME [epoch: 6.46 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4607383472526977		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.4607383472526977 | validation: 0.430354853381683]
	TIME [epoch: 6.45 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4210614342025296		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.4210614342025296 | validation: 0.364423860553229]
	TIME [epoch: 6.46 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5441109129533191		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.5441109129533191 | validation: 0.39294279024856255]
	TIME [epoch: 6.45 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38190928770308846		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.38190928770308846 | validation: 0.464807408241861]
	TIME [epoch: 6.46 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4064414866345604		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.4064414866345604 | validation: 0.3268176425071214]
	TIME [epoch: 6.49 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.535934373518078		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.535934373518078 | validation: 0.28484874897731693]
	TIME [epoch: 6.47 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.342341690867373		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.342341690867373 | validation: 0.3629912104391107]
	TIME [epoch: 6.45 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3510754935018645		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.3510754935018645 | validation: 0.4211680772989816]
	TIME [epoch: 6.46 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35042409241762656		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.35042409241762656 | validation: 0.29773826613654036]
	TIME [epoch: 6.46 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35130717305413045		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.35130717305413045 | validation: 0.40785503112884625]
	TIME [epoch: 6.46 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3913863391305772		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.3913863391305772 | validation: 0.37550921909753554]
	TIME [epoch: 6.45 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3793640141373156		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.3793640141373156 | validation: 0.2936620586175048]
	TIME [epoch: 6.49 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39052402238038897		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.39052402238038897 | validation: 0.28321460939347215]
	TIME [epoch: 6.46 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37747935829429363		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.37747935829429363 | validation: 0.41118364685561376]
	TIME [epoch: 6.47 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39369973918933127		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.39369973918933127 | validation: 0.2567569096745673]
	TIME [epoch: 6.45 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3134830828554454		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.3134830828554454 | validation: 0.3648727062842525]
	TIME [epoch: 6.47 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3465715676792901		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.3465715676792901 | validation: 0.4689356377052921]
	TIME [epoch: 6.45 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36399387651776494		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.36399387651776494 | validation: 0.6792585298684574]
	TIME [epoch: 6.46 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4214210908074304		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.4214210908074304 | validation: 0.2066557078645816]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_472.pth
	Model improved!!!
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3131121971767613		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.3131121971767613 | validation: 0.289569625665214]
	TIME [epoch: 6.47 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3439943221074818		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.3439943221074818 | validation: 0.689955836676781]
	TIME [epoch: 6.45 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5812461212489539		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.5812461212489539 | validation: 0.36732404045412553]
	TIME [epoch: 6.45 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43220579327983644		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.43220579327983644 | validation: 0.231488049404482]
	TIME [epoch: 6.46 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3802171513485328		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.3802171513485328 | validation: 0.3047074256739361]
	TIME [epoch: 6.46 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3322090790040602		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.3322090790040602 | validation: 0.3316135108803676]
	TIME [epoch: 6.46 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3165315553176337		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.3165315553176337 | validation: 0.2444487893698112]
	TIME [epoch: 6.49 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3726728981446361		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.3726728981446361 | validation: 0.2652040053375712]
	TIME [epoch: 6.47 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28554737780083855		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.28554737780083855 | validation: 0.36800370722086967]
	TIME [epoch: 6.45 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33474480223841174		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.33474480223841174 | validation: 0.2705186622368885]
	TIME [epoch: 6.46 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27098227719327134		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.27098227719327134 | validation: 0.2675543373342966]
	TIME [epoch: 6.46 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2956072119974916		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.2956072119974916 | validation: 0.16475748569805126]
	TIME [epoch: 6.45 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_484.pth
	Model improved!!!
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2965942939108613		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.2965942939108613 | validation: 0.14040456256745387]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_485.pth
	Model improved!!!
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39056936062732406		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.39056936062732406 | validation: 0.3192062471806695]
	TIME [epoch: 6.49 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35376412487159453		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.35376412487159453 | validation: 0.20963784690900325]
	TIME [epoch: 6.48 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35720596706547536		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.35720596706547536 | validation: 0.2977197575565914]
	TIME [epoch: 6.45 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28411288894923187		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.28411288894923187 | validation: 0.4156416420597238]
	TIME [epoch: 6.47 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36271904363601604		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.36271904363601604 | validation: 0.26967019581090823]
	TIME [epoch: 6.47 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31895792754922897		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.31895792754922897 | validation: 0.28423903943774587]
	TIME [epoch: 6.46 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3020628173575327		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.3020628173575327 | validation: 0.291910040868708]
	TIME [epoch: 6.46 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27234327136366326		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.27234327136366326 | validation: 0.3372409193325035]
	TIME [epoch: 6.48 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34599379497425053		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.34599379497425053 | validation: 0.2445715288351314]
	TIME [epoch: 6.48 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3431533663805999		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.3431533663805999 | validation: 0.17820280368535732]
	TIME [epoch: 6.47 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24555709191768693		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.24555709191768693 | validation: 0.24406545587057055]
	TIME [epoch: 6.46 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26271593264351323		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.26271593264351323 | validation: 0.2605868226964245]
	TIME [epoch: 6.46 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28095823453501		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.28095823453501 | validation: 0.3189006907231873]
	TIME [epoch: 6.47 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3112729874236002		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.3112729874236002 | validation: 0.31024755534062354]
	TIME [epoch: 6.46 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34422419655190994		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.34422419655190994 | validation: 0.41131643299447623]
	TIME [epoch: 6.49 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26162073998180985		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.26162073998180985 | validation: 0.2066880802244785]
	TIME [epoch: 6.48 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20051051721173455		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.20051051721173455 | validation: 0.2843938181427855]
	TIME [epoch: 6.46 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3318726589627433		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.3318726589627433 | validation: 0.3300699711089069]
	TIME [epoch: 6.45 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40057493483563217		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.40057493483563217 | validation: 0.3979051773064295]
	TIME [epoch: 6.44 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.276283861704565		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.276283861704565 | validation: 0.2999999754293945]
	TIME [epoch: 6.45 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34989825286527576		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.34989825286527576 | validation: 0.2478389824593719]
	TIME [epoch: 6.44 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19935465433212282		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.19935465433212282 | validation: 0.23783326643905311]
	TIME [epoch: 6.45 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2126936651315486		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.2126936651315486 | validation: 0.49669943038525033]
	TIME [epoch: 6.46 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2856571625134324		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.2856571625134324 | validation: 0.2876671441635427]
	TIME [epoch: 6.44 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25804224434803275		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.25804224434803275 | validation: 0.28318910185119217]
	TIME [epoch: 6.44 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24974061775096412		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.24974061775096412 | validation: 0.18917699479070924]
	TIME [epoch: 6.44 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22339032635984085		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.22339032635984085 | validation: 0.32605927296302484]
	TIME [epoch: 6.44 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22556064674441306		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.22556064674441306 | validation: 0.19210029730724176]
	TIME [epoch: 6.44 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26081063811599353		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.26081063811599353 | validation: 0.1470609914065268]
	TIME [epoch: 6.45 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3391559560693757		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.3391559560693757 | validation: 0.20217834211172772]
	TIME [epoch: 6.49 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22333730148980893		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.22333730148980893 | validation: 0.20462570442765723]
	TIME [epoch: 6.46 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2089019159888998		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.2089019159888998 | validation: 0.22062628986679053]
	TIME [epoch: 6.46 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2365575009800352		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.2365575009800352 | validation: 0.27686517252673787]
	TIME [epoch: 6.46 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22140397071020346		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.22140397071020346 | validation: 0.89991607136774]
	TIME [epoch: 6.46 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4523123917137139		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.4523123917137139 | validation: 0.22971119045798913]
	TIME [epoch: 6.45 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2734832655176882		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.2734832655176882 | validation: 0.1914060057210568]
	TIME [epoch: 6.46 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22000190826131288		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.22000190826131288 | validation: 0.17839871001089974]
	TIME [epoch: 6.49 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23783078980449107		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.23783078980449107 | validation: 0.2723830432518684]
	TIME [epoch: 6.46 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2519451023819678		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.2519451023819678 | validation: 0.42741209840952094]
	TIME [epoch: 6.45 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3109269019047414		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.3109269019047414 | validation: 0.15258105655778498]
	TIME [epoch: 6.44 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1948066095446079		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.1948066095446079 | validation: 0.3394940573478405]
	TIME [epoch: 6.45 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23550717573036087		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.23550717573036087 | validation: 0.28934759816721406]
	TIME [epoch: 6.45 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2593607152585258		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.2593607152585258 | validation: 0.18345761501528954]
	TIME [epoch: 6.45 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2301018541219253		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.2301018541219253 | validation: 0.12321478958410023]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_529.pth
	Model improved!!!
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24644871771921217		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.24644871771921217 | validation: 0.3634202374723348]
	TIME [epoch: 6.46 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3215393543193451		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.3215393543193451 | validation: 0.19284939778352558]
	TIME [epoch: 6.46 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29213923911507944		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.29213923911507944 | validation: 0.17286213235421577]
	TIME [epoch: 6.45 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19320173490317874		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.19320173490317874 | validation: 0.17339099372206399]
	TIME [epoch: 6.46 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23118745992875392		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.23118745992875392 | validation: 0.188588237130519]
	TIME [epoch: 6.45 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2557995162270187		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.2557995162270187 | validation: 0.23897873470246844]
	TIME [epoch: 6.46 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27633564245823905		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.27633564245823905 | validation: 0.22191597853133138]
	TIME [epoch: 6.49 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26005808717139084		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.26005808717139084 | validation: 0.1531025182453387]
	TIME [epoch: 6.47 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28045470742222295		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.28045470742222295 | validation: 0.22930548158541125]
	TIME [epoch: 6.46 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24404747261358217		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.24404747261358217 | validation: 0.4906745380310665]
	TIME [epoch: 6.45 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26023641828287203		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.26023641828287203 | validation: 0.16346431080043403]
	TIME [epoch: 6.46 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12927744017195703		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.12927744017195703 | validation: 0.22313973799678605]
	TIME [epoch: 6.46 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22656717589111566		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.22656717589111566 | validation: 0.36287391820177706]
	TIME [epoch: 6.46 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29586058465553416		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.29586058465553416 | validation: 0.3040071811563319]
	TIME [epoch: 6.49 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20395825037017823		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.20395825037017823 | validation: 0.16589303142986297]
	TIME [epoch: 6.47 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25287163161643594		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.25287163161643594 | validation: 0.27792098849138636]
	TIME [epoch: 6.47 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25535789054525115		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.25535789054525115 | validation: 0.2543753379637694]
	TIME [epoch: 6.46 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2693582655680815		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.2693582655680815 | validation: 0.12599564755037093]
	TIME [epoch: 6.47 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23278696364271884		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.23278696364271884 | validation: 0.36806506049811655]
	TIME [epoch: 6.46 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20327511110288596		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.20327511110288596 | validation: 0.10142438612190045]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_549.pth
	Model improved!!!
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2996801691637806		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.2996801691637806 | validation: 0.3357217868120037]
	TIME [epoch: 6.5 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3890044596360802		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.3890044596360802 | validation: 0.19146672220451802]
	TIME [epoch: 6.47 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18705614907008655		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.18705614907008655 | validation: 0.139868514571142]
	TIME [epoch: 6.47 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18567469401306225		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.18567469401306225 | validation: 0.12179407093819462]
	TIME [epoch: 6.46 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.187079816792095		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.187079816792095 | validation: 0.14682552631848422]
	TIME [epoch: 6.47 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15907973675619752		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.15907973675619752 | validation: 0.19756673706717087]
	TIME [epoch: 6.47 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2501451334720541		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.2501451334720541 | validation: 0.2318795825865098]
	TIME [epoch: 6.47 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26764392287254213		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.26764392287254213 | validation: 0.1544708451099069]
	TIME [epoch: 6.48 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19865269035587574		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.19865269035587574 | validation: 0.1317208963954296]
	TIME [epoch: 6.49 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19319257792424016		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.19319257792424016 | validation: 0.17055942048176026]
	TIME [epoch: 6.47 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13622600326109183		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.13622600326109183 | validation: 0.17044713412860957]
	TIME [epoch: 6.47 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22752079259033772		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.22752079259033772 | validation: 0.30851548498966086]
	TIME [epoch: 6.47 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18561085230320323		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.18561085230320323 | validation: 0.19266268324104716]
	TIME [epoch: 6.46 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15522718807023939		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.15522718807023939 | validation: 0.1710767614573709]
	TIME [epoch: 6.47 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1437089293637365		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.1437089293637365 | validation: 0.19911999155921878]
	TIME [epoch: 6.48 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14810655069927822		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.14810655069927822 | validation: 0.07618090466307006]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_565.pth
	Model improved!!!
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33108810986664894		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.33108810986664894 | validation: 0.1749001510157485]
	TIME [epoch: 6.47 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6152069964386824		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.6152069964386824 | validation: 0.4259934494490783]
	TIME [epoch: 6.46 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20598057498711808		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.20598057498711808 | validation: 0.16595532695813062]
	TIME [epoch: 6.47 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1612810516361167		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.1612810516361167 | validation: 0.336973375954164]
	TIME [epoch: 6.46 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21990089122374307		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.21990089122374307 | validation: 0.1891930850153045]
	TIME [epoch: 6.47 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18365902267769338		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.18365902267769338 | validation: 0.1711318227920526]
	TIME [epoch: 6.48 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18479129404966915		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.18479129404966915 | validation: 0.3959021430577587]
	TIME [epoch: 6.49 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25415025451307416		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.25415025451307416 | validation: 0.2173536961428475]
	TIME [epoch: 6.47 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20539576410331467		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.20539576410331467 | validation: 0.208909665521671]
	TIME [epoch: 6.46 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22749873775729365		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.22749873775729365 | validation: 0.19130325197997394]
	TIME [epoch: 6.47 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1727902014499716		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.1727902014499716 | validation: 0.10626633147763322]
	TIME [epoch: 6.46 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17638633808129356		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.17638633808129356 | validation: 0.16568870846816744]
	TIME [epoch: 6.47 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21275427225785642		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.21275427225785642 | validation: 0.20828479352362997]
	TIME [epoch: 6.47 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22853697468043524		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.22853697468043524 | validation: 0.4757913404515189]
	TIME [epoch: 6.5 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26447692669045103		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.26447692669045103 | validation: 0.12442255858191599]
	TIME [epoch: 6.47 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16613453007601386		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.16613453007601386 | validation: 0.14792947092016173]
	TIME [epoch: 6.46 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21339900180807764		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.21339900180807764 | validation: 0.24771952936048686]
	TIME [epoch: 6.47 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1683829515014091		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.1683829515014091 | validation: 0.1236625433432118]
	TIME [epoch: 6.47 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15787184542915234		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.15787184542915234 | validation: 0.1449424088133792]
	TIME [epoch: 6.47 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29885209324621187		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.29885209324621187 | validation: 0.5594656314330407]
	TIME [epoch: 6.46 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35156486231065065		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.35156486231065065 | validation: 0.435150788791086]
	TIME [epoch: 6.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20470239516750766		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.20470239516750766 | validation: 0.118802338459193]
	TIME [epoch: 6.47 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17442407365800355		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.17442407365800355 | validation: 0.24213349690992805]
	TIME [epoch: 6.47 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19447651788946305		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.19447651788946305 | validation: 0.277998304451816]
	TIME [epoch: 6.47 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2312994680357958		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.2312994680357958 | validation: 0.2323765783460184]
	TIME [epoch: 6.46 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25102409615161486		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.25102409615161486 | validation: 0.1298292001853502]
	TIME [epoch: 6.47 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15903994456395507		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.15903994456395507 | validation: 0.20726366973159085]
	TIME [epoch: 6.46 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19171063055605878		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.19171063055605878 | validation: 0.3269802622215179]
	TIME [epoch: 6.5 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26593047626834426		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.26593047626834426 | validation: 0.1855036593061582]
	TIME [epoch: 6.47 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1995182312612937		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.1995182312612937 | validation: 0.14856634852577263]
	TIME [epoch: 6.46 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14688023558543445		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.14688023558543445 | validation: 0.20606019835557796]
	TIME [epoch: 6.47 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18339761126739995		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.18339761126739995 | validation: 0.16393246622015653]
	TIME [epoch: 6.47 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20307101129715374		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.20307101129715374 | validation: 0.23164982307919446]
	TIME [epoch: 6.47 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21069318730148326		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.21069318730148326 | validation: 0.1817661746187912]
	TIME [epoch: 6.46 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19505159274182188		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.19505159274182188 | validation: 0.26225561884157605]
	TIME [epoch: 6.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21105189580190292		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.21105189580190292 | validation: 0.1968613528071424]
	TIME [epoch: 6.47 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17914891016784573		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.17914891016784573 | validation: 0.11077735021972514]
	TIME [epoch: 6.47 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2148320266429635		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.2148320266429635 | validation: 0.25955111315091073]
	TIME [epoch: 6.46 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18286795728638514		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.18286795728638514 | validation: 0.3737944998210951]
	TIME [epoch: 6.46 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2413966815726151		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.2413966815726151 | validation: 0.12375865914235679]
	TIME [epoch: 6.46 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.185045599313502		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.185045599313502 | validation: 0.4190762529295157]
	TIME [epoch: 6.46 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22996404006622373		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.22996404006622373 | validation: 0.1880222448747258]
	TIME [epoch: 6.51 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17629108664617973		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.17629108664617973 | validation: 0.20491963312000558]
	TIME [epoch: 6.47 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20057686949716313		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.20057686949716313 | validation: 0.20827377588800286]
	TIME [epoch: 6.47 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18259733182635007		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.18259733182635007 | validation: 0.09840202715573808]
	TIME [epoch: 6.46 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12462592082602705		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.12462592082602705 | validation: 0.10421077078452747]
	TIME [epoch: 6.47 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1346562734675891		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.1346562734675891 | validation: 0.25540373632453944]
	TIME [epoch: 6.46 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16799381369074043		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.16799381369074043 | validation: 0.10772837734433832]
	TIME [epoch: 6.46 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15222052747634715		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.15222052747634715 | validation: 0.16931669176254832]
	TIME [epoch: 6.48 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23776301010850548		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.23776301010850548 | validation: 0.13607556359459563]
	TIME [epoch: 6.48 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22903595706072924		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.22903595706072924 | validation: 0.1292719039728134]
	TIME [epoch: 6.47 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17693851949130093		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.17693851949130093 | validation: 0.2637203025601576]
	TIME [epoch: 6.46 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21634554649999096		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.21634554649999096 | validation: 0.17881703827300577]
	TIME [epoch: 6.46 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14681667414559044		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.14681667414559044 | validation: 0.14715452422852335]
	TIME [epoch: 6.46 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1420008061208727		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.1420008061208727 | validation: 0.15349401886424105]
	TIME [epoch: 6.46 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17236078748852313		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.17236078748852313 | validation: 0.1439833112698685]
	TIME [epoch: 6.48 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1817918511409513		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.1817918511409513 | validation: 0.13316296792022791]
	TIME [epoch: 6.48 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1663306795827872		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.1663306795827872 | validation: 0.09917552133353595]
	TIME [epoch: 6.47 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1305658029457174		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.1305658029457174 | validation: 0.08749118139432646]
	TIME [epoch: 6.46 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11690215918376397		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.11690215918376397 | validation: 0.16802492002108207]
	TIME [epoch: 6.46 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18147837716457157		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.18147837716457157 | validation: 0.12137320738879563]
	TIME [epoch: 6.47 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13515547163057884		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.13515547163057884 | validation: 0.25071015113451495]
	TIME [epoch: 6.46 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17036181038447154		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.17036181038447154 | validation: 0.15720251956568274]
	TIME [epoch: 6.47 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16181182192679158		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.16181182192679158 | validation: 0.17444957105818037]
	TIME [epoch: 6.5 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1811110038749042		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.1811110038749042 | validation: 0.1935610276672403]
	TIME [epoch: 6.47 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17887964122726885		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.17887964122726885 | validation: 0.11258982136867272]
	TIME [epoch: 6.46 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14030538905858542		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.14030538905858542 | validation: 0.257939335496568]
	TIME [epoch: 6.47 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2104580146721302		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.2104580146721302 | validation: 0.1784791578188207]
	TIME [epoch: 6.46 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18803949074679555		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.18803949074679555 | validation: 0.0901752332665759]
	TIME [epoch: 6.48 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17192125060198607		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.17192125060198607 | validation: 0.15343844234701762]
	TIME [epoch: 6.47 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15119097333133252		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.15119097333133252 | validation: 0.1550769125071962]
	TIME [epoch: 6.5 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18621083347929615		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.18621083347929615 | validation: 0.2688656185064856]
	TIME [epoch: 6.47 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1799015578586153		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.1799015578586153 | validation: 0.2561863911124973]
	TIME [epoch: 6.46 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17917314392512967		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.17917314392512967 | validation: 0.16999423738362646]
	TIME [epoch: 6.47 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16860885750848692		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.16860885750848692 | validation: 0.1944085638720367]
	TIME [epoch: 6.46 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1432853873750778		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.1432853873750778 | validation: 0.17560235137270128]
	TIME [epoch: 6.46 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.178375010516669		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.178375010516669 | validation: 0.13664620639423178]
	TIME [epoch: 6.46 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14931434148385156		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.14931434148385156 | validation: 0.1668577271791966]
	TIME [epoch: 6.5 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14231104851353782		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.14231104851353782 | validation: 0.25368796549336375]
	TIME [epoch: 6.47 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19320465846911156		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.19320465846911156 | validation: 0.11645525021773832]
	TIME [epoch: 6.46 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18095486793687382		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.18095486793687382 | validation: 0.1751129677211134]
	TIME [epoch: 6.47 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23808289164913304		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.23808289164913304 | validation: 0.2858983641322791]
	TIME [epoch: 6.46 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23197510334542104		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.23197510334542104 | validation: 0.15730628632507188]
	TIME [epoch: 6.47 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13456922121014786		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.13456922121014786 | validation: 0.14425471584055916]
	TIME [epoch: 6.46 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11604749623899352		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.11604749623899352 | validation: 0.2071965411407421]
	TIME [epoch: 6.5 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332788740506826		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.2332788740506826 | validation: 0.08124636316869717]
	TIME [epoch: 6.47 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12517287997114956		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.12517287997114956 | validation: 0.14859896116291801]
	TIME [epoch: 6.46 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1878866058998702		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.1878866058998702 | validation: 0.18562332790002664]
	TIME [epoch: 6.47 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15399800891030213		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.15399800891030213 | validation: 0.373825515503403]
	TIME [epoch: 6.47 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2644274848442313		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.2644274848442313 | validation: 0.24102270474310522]
	TIME [epoch: 6.47 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1659327759796442		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.1659327759796442 | validation: 0.23948757060971063]
	TIME [epoch: 6.46 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19011875342960843		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.19011875342960843 | validation: 0.09481507003339981]
	TIME [epoch: 6.5 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12417099309029547		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.12417099309029547 | validation: 0.10814090976720593]
	TIME [epoch: 6.47 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14150965149067254		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.14150965149067254 | validation: 0.3961191003169051]
	TIME [epoch: 6.46 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31336628218538376		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.31336628218538376 | validation: 0.24972889467051018]
	TIME [epoch: 6.47 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.166787650812516		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.166787650812516 | validation: 0.11303293324812275]
	TIME [epoch: 6.47 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17164826497039593		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.17164826497039593 | validation: 0.19024474318248658]
	TIME [epoch: 6.47 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20344931925880233		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.20344931925880233 | validation: 0.2992435459455027]
	TIME [epoch: 6.46 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17311685968531887		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.17311685968531887 | validation: 0.18319185306241573]
	TIME [epoch: 6.5 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1408345160798203		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.1408345160798203 | validation: 0.13755277487163717]
	TIME [epoch: 6.48 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1851832802644368		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.1851832802644368 | validation: 0.2150847134381589]
	TIME [epoch: 6.47 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542102357779514		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.1542102357779514 | validation: 0.13067664055401093]
	TIME [epoch: 6.47 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10627210739412211		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.10627210739412211 | validation: 0.11550257286091825]
	TIME [epoch: 6.46 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1359594442077084		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.1359594442077084 | validation: 0.14174374033174156]
	TIME [epoch: 6.47 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1629561081093588		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.1629561081093588 | validation: 0.15138059086997854]
	TIME [epoch: 6.46 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23679380415495122		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.23679380415495122 | validation: 0.24512863181698485]
	TIME [epoch: 6.48 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1582519279504764		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.1582519279504764 | validation: 0.12553706981714982]
	TIME [epoch: 6.48 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14953346419645847		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.14953346419645847 | validation: 0.1903911086326518]
	TIME [epoch: 6.47 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21142122756135506		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.21142122756135506 | validation: 0.23089681822892374]
	TIME [epoch: 6.47 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17999043712618215		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.17999043712618215 | validation: 0.1620245974591235]
	TIME [epoch: 6.47 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16405201214685297		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.16405201214685297 | validation: 0.10158720782651934]
	TIME [epoch: 6.47 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11121048338962614		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.11121048338962614 | validation: 0.06398410273909522]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_677.pth
	Model improved!!!
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11612996533636803		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.11612996533636803 | validation: 0.20567392804454593]
	TIME [epoch: 6.49 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1849800816675431		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.1849800816675431 | validation: 0.12142889273198496]
	TIME [epoch: 6.48 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13834113028446732		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.13834113028446732 | validation: 0.1418277658573808]
	TIME [epoch: 6.47 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14408834395216405		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.14408834395216405 | validation: 0.11293837728822329]
	TIME [epoch: 6.47 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14477075432168934		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.14477075432168934 | validation: 0.1165537043016058]
	TIME [epoch: 6.46 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14439820637880008		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.14439820637880008 | validation: 0.1551827140747597]
	TIME [epoch: 6.47 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14002813456226812		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.14002813456226812 | validation: 0.14965964721821343]
	TIME [epoch: 6.47 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16390074544220962		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.16390074544220962 | validation: 0.15639016374483342]
	TIME [epoch: 6.48 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13034780796092993		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.13034780796092993 | validation: 0.13575404946543368]
	TIME [epoch: 6.49 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12800938517018695		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.12800938517018695 | validation: 0.17763754780399907]
	TIME [epoch: 6.47 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11891587227346548		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.11891587227346548 | validation: 0.2765933804432976]
	TIME [epoch: 6.47 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2076480304034148		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.2076480304034148 | validation: 0.3521004710216132]
	TIME [epoch: 6.46 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2039039362605475		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.2039039362605475 | validation: 0.2683140918462467]
	TIME [epoch: 6.47 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16007206592777387		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.16007206592777387 | validation: 0.10907256671228584]
	TIME [epoch: 6.47 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15345498906073451		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.15345498906073451 | validation: 0.2823082366942656]
	TIME [epoch: 6.47 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2008896057964762		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.2008896057964762 | validation: 0.22410153663537136]
	TIME [epoch: 6.5 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680312769833364		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.1680312769833364 | validation: 0.1356319879036216]
	TIME [epoch: 6.47 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11714408461822251		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.11714408461822251 | validation: 0.1335611497923396]
	TIME [epoch: 6.47 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10033120804001432		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.10033120804001432 | validation: 0.13563116315987317]
	TIME [epoch: 6.46 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13671698932951534		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.13671698932951534 | validation: 0.13386813243706944]
	TIME [epoch: 6.47 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13629543125721513		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.13629543125721513 | validation: 0.1844209999390631]
	TIME [epoch: 6.47 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20028073048202644		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.20028073048202644 | validation: 0.5043189176227927]
	TIME [epoch: 6.47 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.267276750956495		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.267276750956495 | validation: 0.17465281208002595]
	TIME [epoch: 6.49 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16815999689318567		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.16815999689318567 | validation: 0.1465065251549937]
	TIME [epoch: 6.47 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11820094970501786		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.11820094970501786 | validation: 0.09822569191585931]
	TIME [epoch: 6.54 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12712459061449943		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.12712459061449943 | validation: 0.16473540439459952]
	TIME [epoch: 6.47 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1721934123381616		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.1721934123381616 | validation: 0.07431011389089838]
	TIME [epoch: 6.47 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16630553145032673		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.16630553145032673 | validation: 0.15910699534310044]
	TIME [epoch: 6.46 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11785786948843821		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.11785786948843821 | validation: 0.13350963952184433]
	TIME [epoch: 6.47 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11712501501323166		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.11712501501323166 | validation: 0.3445236312432652]
	TIME [epoch: 6.5 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23467044486660432		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.23467044486660432 | validation: 0.11133737501110705]
	TIME [epoch: 6.47 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10685156502897791		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.10685156502897791 | validation: 0.15931359646412474]
	TIME [epoch: 6.47 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18385392825715624		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.18385392825715624 | validation: 0.2738838046978519]
	TIME [epoch: 6.47 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16265875110603337		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.16265875110603337 | validation: 0.15763056531749742]
	TIME [epoch: 6.47 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1168362513094826		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.1168362513094826 | validation: 0.11181532666287577]
	TIME [epoch: 6.47 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11342552363760311		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.11342552363760311 | validation: 0.13330938753665839]
	TIME [epoch: 6.47 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11796534094920007		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.11796534094920007 | validation: 0.11571473343244794]
	TIME [epoch: 6.49 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1569922899213095		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.1569922899213095 | validation: 0.18351393713654254]
	TIME [epoch: 6.47 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14899246146791156		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.14899246146791156 | validation: 0.1903488432206306]
	TIME [epoch: 6.46 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19584851324844646		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.19584851324844646 | validation: 0.18222632145914072]
	TIME [epoch: 6.47 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19632025482255933		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.19632025482255933 | validation: 0.1542196833253245]
	TIME [epoch: 6.47 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15789969897084163		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.15789969897084163 | validation: 0.11500655259037901]
	TIME [epoch: 6.47 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13490059924786646		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.13490059924786646 | validation: 0.15894899440198892]
	TIME [epoch: 6.47 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1521380344438933		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.1521380344438933 | validation: 0.17206788332288972]
	TIME [epoch: 6.5 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1710449033470977		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.1710449033470977 | validation: 0.16633146314874858]
	TIME [epoch: 6.48 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15472863980800822		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.15472863980800822 | validation: 0.13669543565312256]
	TIME [epoch: 6.46 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15215844605652099		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.15215844605652099 | validation: 0.11327763819656433]
	TIME [epoch: 6.47 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18329879881968617		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.18329879881968617 | validation: 0.27939229445080216]
	TIME [epoch: 6.47 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15788729254859868		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.15788729254859868 | validation: 0.08784807817492542]
	TIME [epoch: 6.46 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.148325921621947		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.148325921621947 | validation: 0.09111965208778325]
	TIME [epoch: 6.47 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11268227525050817		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.11268227525050817 | validation: 0.08553775854815061]
	TIME [epoch: 6.48 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10364316640695105		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.10364316640695105 | validation: 0.07989091239105918]
	TIME [epoch: 6.48 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1348998532998415		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.1348998532998415 | validation: 0.1430995746499175]
	TIME [epoch: 6.47 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11344783081626941		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.11344783081626941 | validation: 0.11649881555302667]
	TIME [epoch: 6.47 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10216319701836502		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.10216319701836502 | validation: 0.0739134565218836]
	TIME [epoch: 6.46 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14803484993832394		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.14803484993832394 | validation: 0.23195402036427837]
	TIME [epoch: 6.47 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11661689148362762		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.11661689148362762 | validation: 0.0898033565019911]
	TIME [epoch: 6.46 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14055087491063972		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.14055087491063972 | validation: 0.11112648846086892]
	TIME [epoch: 6.48 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11705139415987698		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.11705139415987698 | validation: 0.0686268677896848]
	TIME [epoch: 6.49 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10449805162661524		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.10449805162661524 | validation: 0.2864039775079445]
	TIME [epoch: 6.46 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14401913747016754		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.14401913747016754 | validation: 0.07736852498785973]
	TIME [epoch: 6.47 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11042371914269106		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.11042371914269106 | validation: 0.07243706925477643]
	TIME [epoch: 6.46 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09869437769070713		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.09869437769070713 | validation: 0.13157625488750432]
	TIME [epoch: 6.47 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1350525199560482		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.1350525199560482 | validation: 0.15577387109407348]
	TIME [epoch: 6.47 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12473335942854107		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.12473335942854107 | validation: 0.1877785184838683]
	TIME [epoch: 6.48 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15205184084542306		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.15205184084542306 | validation: 0.2027250182622229]
	TIME [epoch: 6.48 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1217386325248035		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.1217386325248035 | validation: 0.14070786403296257]
	TIME [epoch: 6.47 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11997873711341173		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.11997873711341173 | validation: 0.30891506757833737]
	TIME [epoch: 6.47 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2006860283111751		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.2006860283111751 | validation: 0.07531851714511846]
	TIME [epoch: 6.46 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16303591971889808		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.16303591971889808 | validation: 0.3308545710794553]
	TIME [epoch: 6.46 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1580912546244419		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.1580912546244419 | validation: 0.11047534234214082]
	TIME [epoch: 6.46 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12385122432363409		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.12385122432363409 | validation: 0.1352613403405591]
	TIME [epoch: 6.47 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15242926003267857		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.15242926003267857 | validation: 0.10450826112971946]
	TIME [epoch: 6.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1078668940895662		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.1078668940895662 | validation: 0.13378388318185916]
	TIME [epoch: 6.46 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1168361882948496		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.1168361882948496 | validation: 0.078847922615599]
	TIME [epoch: 6.47 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10132965507095452		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.10132965507095452 | validation: 0.11173070198457197]
	TIME [epoch: 6.47 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10428400152354034		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.10428400152354034 | validation: 0.14342011117258424]
	TIME [epoch: 6.47 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14072634865317196		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.14072634865317196 | validation: 0.0908479189304872]
	TIME [epoch: 6.47 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12419231952774971		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.12419231952774971 | validation: 0.09375718407625513]
	TIME [epoch: 6.47 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13340728211560632		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.13340728211560632 | validation: 0.09362721166461153]
	TIME [epoch: 6.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09305259676189542		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.09305259676189542 | validation: 0.11583070084051268]
	TIME [epoch: 6.47 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13890698198226054		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.13890698198226054 | validation: 0.1538861585214678]
	TIME [epoch: 6.47 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11676264016545151		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.11676264016545151 | validation: 0.08919883308264073]
	TIME [epoch: 6.46 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10528479839627645		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.10528479839627645 | validation: 0.08456541241754613]
	TIME [epoch: 6.47 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12668249519246494		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.12668249519246494 | validation: 0.1216168162457409]
	TIME [epoch: 6.46 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1429639814807469		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.1429639814807469 | validation: 0.16643578436259812]
	TIME [epoch: 6.47 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14519751331338737		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.14519751331338737 | validation: 0.0897441571119108]
	TIME [epoch: 6.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10317721904283542		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.10317721904283542 | validation: 0.11125826169120134]
	TIME [epoch: 6.46 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11107382640169641		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.11107382640169641 | validation: 0.19104723459250467]
	TIME [epoch: 6.47 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12634752474756009		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.12634752474756009 | validation: 0.11112954961276764]
	TIME [epoch: 6.47 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09321498992705785		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.09321498992705785 | validation: 0.08213498586772332]
	TIME [epoch: 6.46 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1410454884628293		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.1410454884628293 | validation: 0.1937687977925622]
	TIME [epoch: 6.46 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14561995460425634		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.14561995460425634 | validation: 0.10185671801437848]
	TIME [epoch: 6.46 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10353789318901482		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.10353789318901482 | validation: 0.09943597815979396]
	TIME [epoch: 6.48 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1326343196077733		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.1326343196077733 | validation: 0.09998042243056258]
	TIME [epoch: 6.45 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10485533716552925		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.10485533716552925 | validation: 0.17513829372382061]
	TIME [epoch: 6.45 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12557857441042308		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.12557857441042308 | validation: 0.12130037692745414]
	TIME [epoch: 6.44 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11715127974086872		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.11715127974086872 | validation: 0.09678659197742587]
	TIME [epoch: 6.44 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1141888839041709		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.1141888839041709 | validation: 0.09271608778910999]
	TIME [epoch: 6.45 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09994875643270383		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.09994875643270383 | validation: 0.1686500430866824]
	TIME [epoch: 6.45 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15672020726086133		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.15672020726086133 | validation: 0.1530076108518354]
	TIME [epoch: 6.47 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13096073273089176		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.13096073273089176 | validation: 0.12527866206783958]
	TIME [epoch: 6.45 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.100813772283963		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.100813772283963 | validation: 0.15022478426173524]
	TIME [epoch: 6.46 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1161130513349425		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.1161130513349425 | validation: 0.08700107377979747]
	TIME [epoch: 6.45 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12616515444410592		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.12616515444410592 | validation: 0.12165456573120882]
	TIME [epoch: 6.46 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10799219001855356		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.10799219001855356 | validation: 0.1464576482996662]
	TIME [epoch: 6.46 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10929449292142088		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.10929449292142088 | validation: 0.10491409096489537]
	TIME [epoch: 6.46 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10380360520753333		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.10380360520753333 | validation: 0.07298952109732701]
	TIME [epoch: 6.47 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09732198947937462		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.09732198947937462 | validation: 0.1510095912183034]
	TIME [epoch: 6.48 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11476708624029705		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.11476708624029705 | validation: 0.17443120055282188]
	TIME [epoch: 6.46 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21231959756744095		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.21231959756744095 | validation: 0.10421427210756276]
	TIME [epoch: 6.45 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09792936700813426		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.09792936700813426 | validation: 0.0752642239973979]
	TIME [epoch: 6.46 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1091402549219807		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.1091402549219807 | validation: 0.0873298063497557]
	TIME [epoch: 6.46 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10087944749948777		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.10087944749948777 | validation: 0.1433247444944991]
	TIME [epoch: 6.46 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12703208702998187		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.12703208702998187 | validation: 0.09563837664307855]
	TIME [epoch: 6.47 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10944333572289539		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.10944333572289539 | validation: 0.12292496450908154]
	TIME [epoch: 6.47 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09698077353135406		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.09698077353135406 | validation: 0.1325767863312885]
	TIME [epoch: 6.46 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09784392875881534		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.09784392875881534 | validation: 0.12390343717837103]
	TIME [epoch: 6.47 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11573055555248912		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.11573055555248912 | validation: 0.10443381604825731]
	TIME [epoch: 6.47 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10773095374265246		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.10773095374265246 | validation: 0.08189295685776259]
	TIME [epoch: 6.46 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11015454143301859		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.11015454143301859 | validation: 0.09569813036331548]
	TIME [epoch: 6.47 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0868408984713396		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.0868408984713396 | validation: 0.05313167085396469]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_799.pth
	Model improved!!!
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09710838599044444		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.09710838599044444 | validation: 0.14647724308291754]
	TIME [epoch: 6.5 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1215460568173657		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.1215460568173657 | validation: 0.12433187130811767]
	TIME [epoch: 6.47 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09409095854688895		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.09409095854688895 | validation: 0.08815266946152861]
	TIME [epoch: 6.47 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09551927304928157		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.09551927304928157 | validation: 0.07294946067926865]
	TIME [epoch: 6.47 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09150266538755553		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.09150266538755553 | validation: 0.10897909365082044]
	TIME [epoch: 6.46 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09419236126191881		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.09419236126191881 | validation: 0.07532242353791448]
	TIME [epoch: 6.47 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11279672111099764		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.11279672111099764 | validation: 0.08620843609429195]
	TIME [epoch: 6.47 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1054351457361375		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.1054351457361375 | validation: 0.11092034918945885]
	TIME [epoch: 6.5 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08347934400961018		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.08347934400961018 | validation: 0.09898061774265181]
	TIME [epoch: 6.47 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1141142499103463		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.1141142499103463 | validation: 0.09816792853110885]
	TIME [epoch: 6.46 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11230898827096328		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.11230898827096328 | validation: 0.09495408654078843]
	TIME [epoch: 6.47 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09477465540650407		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.09477465540650407 | validation: 0.09029625088510905]
	TIME [epoch: 6.46 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0986240859861299		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.0986240859861299 | validation: 0.07885164485006745]
	TIME [epoch: 6.46 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08706786708445716		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.08706786708445716 | validation: 0.10839136644841524]
	TIME [epoch: 6.47 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08604800166991874		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.08604800166991874 | validation: 0.0710398785262941]
	TIME [epoch: 6.5 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09115215713456754		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.09115215713456754 | validation: 0.09709244156215224]
	TIME [epoch: 6.47 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10379840990720246		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.10379840990720246 | validation: 0.0995453013127647]
	TIME [epoch: 6.47 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12752568816052579		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.12752568816052579 | validation: 0.06347004117121952]
	TIME [epoch: 6.46 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13154902083860304		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.13154902083860304 | validation: 0.15054005186765404]
	TIME [epoch: 6.46 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12494414477612129		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.12494414477612129 | validation: 0.07918885438966225]
	TIME [epoch: 6.47 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0839416549146706		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.0839416549146706 | validation: 0.09630344676637545]
	TIME [epoch: 6.46 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09341204398025751		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.09341204398025751 | validation: 0.11038678444581138]
	TIME [epoch: 6.5 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10002840225983715		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.10002840225983715 | validation: 0.1431372816593344]
	TIME [epoch: 6.47 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1100500603418054		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.1100500603418054 | validation: 0.05949894565881968]
	TIME [epoch: 6.46 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15189242147484533		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.15189242147484533 | validation: 0.23342846170828402]
	TIME [epoch: 6.46 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13803833123580042		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.13803833123580042 | validation: 0.14994528091293394]
	TIME [epoch: 6.46 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10704571818308456		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.10704571818308456 | validation: 0.06346631382873497]
	TIME [epoch: 6.46 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08653186913928013		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.08653186913928013 | validation: 0.07750541324269301]
	TIME [epoch: 6.46 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09093879275592609		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.09093879275592609 | validation: 0.08987509049177295]
	TIME [epoch: 6.49 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0887964925951569		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.0887964925951569 | validation: 0.06981173157014889]
	TIME [epoch: 6.47 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08840305661147185		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.08840305661147185 | validation: 0.06867927300947423]
	TIME [epoch: 6.46 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07428777756001502		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.07428777756001502 | validation: 0.05351917335633379]
	TIME [epoch: 6.46 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08360352416620584		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.08360352416620584 | validation: 0.05316048707783152]
	TIME [epoch: 6.47 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09129200494803355		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.09129200494803355 | validation: 0.09624858461675662]
	TIME [epoch: 6.46 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14186542696625765		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.14186542696625765 | validation: 0.16635533078998202]
	TIME [epoch: 6.46 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11826090718421653		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.11826090718421653 | validation: 0.1135317034065401]
	TIME [epoch: 6.5 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12255287725346903		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.12255287725346903 | validation: 0.0503102965596552]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_836.pth
	Model improved!!!
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08061473655422784		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.08061473655422784 | validation: 0.0698338052871217]
	TIME [epoch: 6.47 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08691634802929135		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.08691634802929135 | validation: 0.09447393309371346]
	TIME [epoch: 6.46 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07934622498532028		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.07934622498532028 | validation: 0.05633337031116449]
	TIME [epoch: 6.46 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07521144094660992		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.07521144094660992 | validation: 0.08515537429321446]
	TIME [epoch: 6.46 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19691088117787992		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.19691088117787992 | validation: 0.10026290253966263]
	TIME [epoch: 6.46 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09280818063111868		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.09280818063111868 | validation: 0.0794359237185593]
	TIME [epoch: 6.49 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0747562804212213		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.0747562804212213 | validation: 0.09739916362028828]
	TIME [epoch: 6.47 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10202979568190941		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.10202979568190941 | validation: 0.14727853916663533]
	TIME [epoch: 6.46 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13402480805465233		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.13402480805465233 | validation: 0.09897300480900455]
	TIME [epoch: 6.46 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08167077477966816		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.08167077477966816 | validation: 0.09817678926644087]
	TIME [epoch: 6.46 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07684967414887431		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.07684967414887431 | validation: 0.13970420792315302]
	TIME [epoch: 6.46 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09498797521952648		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.09498797521952648 | validation: 0.09798854953065365]
	TIME [epoch: 6.46 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07363702651989627		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.07363702651989627 | validation: 0.08569263168553853]
	TIME [epoch: 6.48 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07239864639465413		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.07239864639465413 | validation: 0.06492701602854835]
	TIME [epoch: 6.48 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09169321016844328		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.09169321016844328 | validation: 0.07712276427108357]
	TIME [epoch: 6.47 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12523983375323075		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.12523983375323075 | validation: 0.10710892702214929]
	TIME [epoch: 6.46 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10262228886271153		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.10262228886271153 | validation: 0.12967635374300146]
	TIME [epoch: 6.47 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10693092447707811		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.10693092447707811 | validation: 0.14095206816105257]
	TIME [epoch: 6.46 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12120239922572296		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.12120239922572296 | validation: 0.12940737221681267]
	TIME [epoch: 6.46 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10849837382628419		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.10849837382628419 | validation: 0.15296245990808088]
	TIME [epoch: 6.48 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11599689375155395		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.11599689375155395 | validation: 0.09579628807446486]
	TIME [epoch: 6.48 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08412195555159327		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.08412195555159327 | validation: 0.08621062579076323]
	TIME [epoch: 6.47 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08943581500741715		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.08943581500741715 | validation: 0.0829327207652107]
	TIME [epoch: 6.47 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07872845016247632		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.07872845016247632 | validation: 0.12255504896978227]
	TIME [epoch: 6.46 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1058098733625954		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.1058098733625954 | validation: 0.1226078575635985]
	TIME [epoch: 6.47 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10306988659689187		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.10306988659689187 | validation: 0.0587990079508797]
	TIME [epoch: 6.46 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07198899012923277		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.07198899012923277 | validation: 0.1279426045922214]
	TIME [epoch: 6.47 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11248388032702761		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.11248388032702761 | validation: 0.11030697991534696]
	TIME [epoch: 6.49 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08523718226080605		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.08523718226080605 | validation: 0.11079020811372363]
	TIME [epoch: 6.47 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10241113394580481		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.10241113394580481 | validation: 0.12550539334589675]
	TIME [epoch: 6.46 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09315109736203894		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.09315109736203894 | validation: 0.1146056201017695]
	TIME [epoch: 6.46 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10805292085935173		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.10805292085935173 | validation: 0.07179012517163132]
	TIME [epoch: 6.46 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08475338808165316		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.08475338808165316 | validation: 0.14693943032923118]
	TIME [epoch: 6.47 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11545142136052056		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.11545142136052056 | validation: 0.11289251843873738]
	TIME [epoch: 6.46 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10082604252365686		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.10082604252365686 | validation: 0.11210778936207628]
	TIME [epoch: 6.49 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09002725614690239		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.09002725614690239 | validation: 0.07194720328958899]
	TIME [epoch: 6.47 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14126834951357442		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.14126834951357442 | validation: 0.11846850069781553]
	TIME [epoch: 6.46 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09271828350012899		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.09271828350012899 | validation: 0.08752463589563275]
	TIME [epoch: 6.46 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08028315645597268		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.08028315645597268 | validation: 0.1056561532086841]
	TIME [epoch: 6.46 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09721649663269996		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.09721649663269996 | validation: 0.17018182534631582]
	TIME [epoch: 6.47 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17021969493668165		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.17021969493668165 | validation: 0.1532296328007854]
	TIME [epoch: 6.46 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10493825154410302		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.10493825154410302 | validation: 0.1007393094898686]
	TIME [epoch: 6.5 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08814799987264944		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.08814799987264944 | validation: 0.10277257270489053]
	TIME [epoch: 6.47 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09453270466378592		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.09453270466378592 | validation: 0.11892560202251598]
	TIME [epoch: 6.46 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11703636281730428		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.11703636281730428 | validation: 0.0897228508291834]
	TIME [epoch: 6.47 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10103393860066366		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.10103393860066366 | validation: 0.10711525505966635]
	TIME [epoch: 6.46 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07028595004992605		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.07028595004992605 | validation: 0.06911780987707075]
	TIME [epoch: 6.47 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07431514870318298		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.07431514870318298 | validation: 0.07296861206268147]
	TIME [epoch: 6.46 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07080577528752859		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.07080577528752859 | validation: 0.10230328061626484]
	TIME [epoch: 6.5 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1108613126588992		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.1108613126588992 | validation: 0.11834482378613136]
	TIME [epoch: 6.47 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1211765932955875		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.1211765932955875 | validation: 0.10915423051163266]
	TIME [epoch: 6.46 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08617469458101937		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.08617469458101937 | validation: 0.08515146660179788]
	TIME [epoch: 6.47 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0746643155526432		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.0746643155526432 | validation: 0.10840769112805422]
	TIME [epoch: 6.46 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11390953707925983		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.11390953707925983 | validation: 0.10187637642155238]
	TIME [epoch: 6.46 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09580537752605628		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.09580537752605628 | validation: 0.06775248493562806]
	TIME [epoch: 6.46 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0734556191191672		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.0734556191191672 | validation: 0.06885619455310545]
	TIME [epoch: 6.49 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08910635529540668		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.08910635529540668 | validation: 0.12647539064770652]
	TIME [epoch: 6.47 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09449135624056065		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.09449135624056065 | validation: 0.13201769103038227]
	TIME [epoch: 6.46 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1111289604476439		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.1111289604476439 | validation: 0.08298331806823164]
	TIME [epoch: 6.46 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08328420243071004		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.08328420243071004 | validation: 0.09440143602518493]
	TIME [epoch: 6.46 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0883785517553571		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.0883785517553571 | validation: 0.13905724842107461]
	TIME [epoch: 6.46 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09743272955536668		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.09743272955536668 | validation: 0.08826390621872421]
	TIME [epoch: 6.46 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09635494809222406		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.09635494809222406 | validation: 0.11002910339196607]
	TIME [epoch: 6.49 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12593331959546972		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.12593331959546972 | validation: 0.0685232079529294]
	TIME [epoch: 6.47 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09208978192070322		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.09208978192070322 | validation: 0.09614245529414855]
	TIME [epoch: 6.47 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0949307822293072		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.0949307822293072 | validation: 0.06797396335262722]
	TIME [epoch: 6.46 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06966806227571631		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.06966806227571631 | validation: 0.05766681482233004]
	TIME [epoch: 6.46 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09050282723743087		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.09050282723743087 | validation: 0.07708549503007255]
	TIME [epoch: 6.46 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08214178899031317		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.08214178899031317 | validation: 0.10236069051256681]
	TIME [epoch: 6.46 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10770121648763269		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.10770121648763269 | validation: 0.06050519570748609]
	TIME [epoch: 6.48 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0793660219837534		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.0793660219837534 | validation: 0.13918037967465677]
	TIME [epoch: 6.48 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09317261510211972		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.09317261510211972 | validation: 0.1267155132186407]
	TIME [epoch: 6.46 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13037691890774097		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.13037691890774097 | validation: 0.07309912636006259]
	TIME [epoch: 6.46 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07408351070574759		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.07408351070574759 | validation: 0.09999510176824235]
	TIME [epoch: 6.47 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07168169759575868		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.07168169759575868 | validation: 0.047182977418491596]
	TIME [epoch: 6.47 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_911.pth
	Model improved!!!
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07319618293858368		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.07319618293858368 | validation: 0.07372024161366948]
	TIME [epoch: 6.47 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08829506644202788		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.08829506644202788 | validation: 0.10135573045331761]
	TIME [epoch: 6.49 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09153615303754604		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.09153615303754604 | validation: 0.09090952174446466]
	TIME [epoch: 6.49 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10620332478721191		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.10620332478721191 | validation: 0.09546612359435802]
	TIME [epoch: 6.47 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08702037170464202		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.08702037170464202 | validation: 0.09350531105382967]
	TIME [epoch: 6.47 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10148098372108194		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.10148098372108194 | validation: 0.16143759806024366]
	TIME [epoch: 6.46 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.100091762915812		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.100091762915812 | validation: 0.06190805730711007]
	TIME [epoch: 6.47 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.067625198019747		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.067625198019747 | validation: 0.09498607276937024]
	TIME [epoch: 6.47 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07718338956579798		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.07718338956579798 | validation: 0.08113889318130145]
	TIME [epoch: 6.48 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08199536421857956		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.08199536421857956 | validation: 0.05864121248328272]
	TIME [epoch: 6.48 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08928136797459292		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.08928136797459292 | validation: 0.08028261002585396]
	TIME [epoch: 6.46 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10385816994499096		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.10385816994499096 | validation: 0.05849835865072518]
	TIME [epoch: 6.45 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07650958467953645		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.07650958467953645 | validation: 0.11004592731635991]
	TIME [epoch: 6.45 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0915171645543508		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.0915171645543508 | validation: 0.08828951169908195]
	TIME [epoch: 6.45 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08337141518979792		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.08337141518979792 | validation: 0.0784078277381821]
	TIME [epoch: 6.44 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07835521498867899		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.07835521498867899 | validation: 0.07912761302156929]
	TIME [epoch: 6.45 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07003611303863252		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.07003611303863252 | validation: 0.08965125420529528]
	TIME [epoch: 6.47 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.084189160771037		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.084189160771037 | validation: 0.12770842683794562]
	TIME [epoch: 6.45 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09314370238445445		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.09314370238445445 | validation: 0.08971175948389586]
	TIME [epoch: 6.45 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08564271996851253		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.08564271996851253 | validation: 0.0841875282989196]
	TIME [epoch: 6.45 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08262391312592643		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.08262391312592643 | validation: 0.10342935513675373]
	TIME [epoch: 6.46 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07494022294983967		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.07494022294983967 | validation: 0.06323869240721647]
	TIME [epoch: 6.45 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08207950828016586		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.08207950828016586 | validation: 0.08340823037577456]
	TIME [epoch: 6.46 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07234006240629423		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.07234006240629423 | validation: 0.06684772608474682]
	TIME [epoch: 6.48 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0752499372366601		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.0752499372366601 | validation: 0.08381068944696103]
	TIME [epoch: 6.46 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07443319815119914		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.07443319815119914 | validation: 0.07836077159547991]
	TIME [epoch: 6.46 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07630275600861434		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.07630275600861434 | validation: 0.12296012397638599]
	TIME [epoch: 6.46 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0838389764212268		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.0838389764212268 | validation: 0.07968144106546365]
	TIME [epoch: 6.46 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14011264081013095		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.14011264081013095 | validation: 0.11346181678141717]
	TIME [epoch: 6.46 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1067147815698103		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.1067147815698103 | validation: 0.0721990149345163]
	TIME [epoch: 6.46 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08913712714246187		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.08913712714246187 | validation: 0.0924277828560759]
	TIME [epoch: 6.5 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401953103179002		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.08401953103179002 | validation: 0.062154366316037754]
	TIME [epoch: 6.47 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08108021470899107		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.08108021470899107 | validation: 0.09093099471283388]
	TIME [epoch: 6.47 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07980160950937092		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.07980160950937092 | validation: 0.12200695366850983]
	TIME [epoch: 6.46 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1089886770366736		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.1089886770366736 | validation: 0.10316527166581065]
	TIME [epoch: 6.47 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0860751349142109		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.0860751349142109 | validation: 0.08665799912825925]
	TIME [epoch: 6.47 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08490023871943111		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.08490023871943111 | validation: 0.09224655122656764]
	TIME [epoch: 6.47 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0979427207305051		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.0979427207305051 | validation: 0.07052936215221019]
	TIME [epoch: 6.5 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07370120602428379		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.07370120602428379 | validation: 0.08174790991484779]
	TIME [epoch: 6.47 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0787713908708048		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.0787713908708048 | validation: 0.06854989453889179]
	TIME [epoch: 6.47 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11836295733181401		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.11836295733181401 | validation: 0.14629318091932203]
	TIME [epoch: 6.48 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1331015061096192		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.1331015061096192 | validation: 0.09142864377438689]
	TIME [epoch: 6.47 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08908527628950332		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.08908527628950332 | validation: 0.053093031996264896]
	TIME [epoch: 6.47 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08358815645607443		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.08358815645607443 | validation: 0.07113738473855687]
	TIME [epoch: 6.47 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06844713978512937		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.06844713978512937 | validation: 0.05774686514970794]
	TIME [epoch: 6.5 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0670930234923241		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.0670930234923241 | validation: 0.0828310553658886]
	TIME [epoch: 6.48 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08924968038913453		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.08924968038913453 | validation: 0.09673535226629822]
	TIME [epoch: 6.47 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07911452587061382		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.07911452587061382 | validation: 0.06383401171184834]
	TIME [epoch: 6.47 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08164965889241084		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.08164965889241084 | validation: 0.0693782242129302]
	TIME [epoch: 6.47 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07966160701149884		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.07966160701149884 | validation: 0.06874611587499711]
	TIME [epoch: 6.47 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07734250789218032		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.07734250789218032 | validation: 0.06980822840908064]
	TIME [epoch: 6.47 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08405055582090883		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.08405055582090883 | validation: 0.079744617483896]
	TIME [epoch: 6.5 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07743899441028122		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.07743899441028122 | validation: 0.13351017876523247]
	TIME [epoch: 6.48 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10054967989212976		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.10054967989212976 | validation: 0.10932329024570664]
	TIME [epoch: 6.47 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10104067906431233		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.10104067906431233 | validation: 0.13612885017602291]
	TIME [epoch: 6.47 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09906124850775522		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.09906124850775522 | validation: 0.07514777438863023]
	TIME [epoch: 6.47 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690960658133994		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.07690960658133994 | validation: 0.06036884732694588]
	TIME [epoch: 6.47 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0847523647391702		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.0847523647391702 | validation: 0.08505151589014569]
	TIME [epoch: 6.47 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0957352250821085		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.0957352250821085 | validation: 0.05230530331469065]
	TIME [epoch: 6.48 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06009508637325428		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.06009508637325428 | validation: 0.06928729526377309]
	TIME [epoch: 6.49 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06802994131725687		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.06802994131725687 | validation: 0.07510525064450524]
	TIME [epoch: 6.47 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07819137029917742		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.07819137029917742 | validation: 0.11852763715892842]
	TIME [epoch: 6.47 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09521674348479742		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.09521674348479742 | validation: 0.09001531663086898]
	TIME [epoch: 6.47 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08672692462828673		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.08672692462828673 | validation: 0.06450235346121834]
	TIME [epoch: 6.47 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07510684509616293		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.07510684509616293 | validation: 0.08874088855468297]
	TIME [epoch: 6.47 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08991145080338592		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.08991145080338592 | validation: 0.08076692689422167]
	TIME [epoch: 6.48 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0791448909471211		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.0791448909471211 | validation: 0.09108039975329561]
	TIME [epoch: 6.49 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07214263796401876		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.07214263796401876 | validation: 0.08153307274266236]
	TIME [epoch: 6.47 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0785423491085932		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.0785423491085932 | validation: 0.07613208372412057]
	TIME [epoch: 6.47 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06521077078638648		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.06521077078638648 | validation: 0.07926893863787812]
	TIME [epoch: 6.46 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0749054119489179		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.0749054119489179 | validation: 0.09327401063828336]
	TIME [epoch: 6.47 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0980575152649493		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.0980575152649493 | validation: 0.08247419263053224]
	TIME [epoch: 6.47 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08643176123188584		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.08643176123188584 | validation: 0.0924647959879896]
	TIME [epoch: 6.47 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0714468955191514		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.0714468955191514 | validation: 0.07950270826034708]
	TIME [epoch: 6.5 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06503273265081091		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.06503273265081091 | validation: 0.06390899127693517]
	TIME [epoch: 6.47 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10886865029228973		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.10886865029228973 | validation: 0.07415044045320927]
	TIME [epoch: 6.47 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08040697091278486		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.08040697091278486 | validation: 0.09818673621675476]
	TIME [epoch: 6.46 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1112690928906903		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.1112690928906903 | validation: 0.09433834960137479]
	TIME [epoch: 6.47 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.097386947171319		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.097386947171319 | validation: 0.1279855211510053]
	TIME [epoch: 6.47 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1049360697135345		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.1049360697135345 | validation: 0.0655160876423213]
	TIME [epoch: 6.47 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07027780562177051		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.07027780562177051 | validation: 0.09348504189116089]
	TIME [epoch: 6.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07077593420369513		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.07077593420369513 | validation: 0.08577937130208138]
	TIME [epoch: 6.47 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0761137038571924		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.0761137038571924 | validation: 0.10521000707434834]
	TIME [epoch: 6.47 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08604273350703126		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.08604273350703126 | validation: 0.08435955085133966]
	TIME [epoch: 6.47 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08785863434679775		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.08785863434679775 | validation: 0.1413937870622991]
	TIME [epoch: 6.47 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12861151965709927		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.12861151965709927 | validation: 0.1059803366526748]
	TIME [epoch: 6.47 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07974553135507664		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.07974553135507664 | validation: 0.07002271345502764]
	TIME [epoch: 6.47 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07648137963995491		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.07648137963995491 | validation: 0.09560281627787419]
	TIME [epoch: 6.5 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07049275982527964		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.07049275982527964 | validation: 0.12617597364250135]
	TIME [epoch: 6.47 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11368228455967086		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.11368228455967086 | validation: 0.09655797832555013]
	TIME [epoch: 6.47 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08653443552453341		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.08653443552453341 | validation: 0.11808487545569922]
	TIME [epoch: 6.47 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0796819429481869		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.0796819429481869 | validation: 0.0780434134511391]
	TIME [epoch: 6.47 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07396250835305127		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.07396250835305127 | validation: 0.10814375777128515]
	TIME [epoch: 6.46 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08157298778847598		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.08157298778847598 | validation: 0.06740772200750983]
	TIME [epoch: 6.47 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07299977051377259		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.07299977051377259 | validation: 0.06796086685370364]
	TIME [epoch: 6.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07818830643672127		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.07818830643672127 | validation: 0.05892853940583516]
	TIME [epoch: 6.47 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07411537065757628		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.07411537065757628 | validation: 0.08452332881084283]
	TIME [epoch: 6.47 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07505031164383984		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.07505031164383984 | validation: 0.08359416390073023]
	TIME [epoch: 6.46 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08747850039647372		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.08747850039647372 | validation: 0.06972937329285282]
	TIME [epoch: 6.47 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07065735234020293		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.07065735234020293 | validation: 0.046379934286538235]
	TIME [epoch: 6.46 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_1011.pth
	Model improved!!!
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06430722444149925		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.06430722444149925 | validation: 0.09266580041949704]
	TIME [epoch: 6.47 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10307806864305083		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.10307806864305083 | validation: 0.07547264853647845]
	TIME [epoch: 6.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07246588314034337		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.07246588314034337 | validation: 0.08444706655960064]
	TIME [epoch: 6.47 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07701389134022493		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.07701389134022493 | validation: 0.0819318893789391]
	TIME [epoch: 6.47 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10631520589880435		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.10631520589880435 | validation: 0.14553854700681107]
	TIME [epoch: 6.47 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08945111684083387		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.08945111684083387 | validation: 0.07343957897812035]
	TIME [epoch: 6.47 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09091181391279726		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.09091181391279726 | validation: 0.0862165377342171]
	TIME [epoch: 6.46 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0860090643807124		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.0860090643807124 | validation: 0.0748385141597565]
	TIME [epoch: 6.47 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07519167342332128		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.07519167342332128 | validation: 0.08383589136534184]
	TIME [epoch: 6.49 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08269936840105552		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.08269936840105552 | validation: 0.07834786265253972]
	TIME [epoch: 6.48 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07217919130981472		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.07217919130981472 | validation: 0.11465720667824787]
	TIME [epoch: 6.46 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07901028550695564		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.07901028550695564 | validation: 0.06587169646843231]
	TIME [epoch: 6.46 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06707055732760525		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.06707055732760525 | validation: 0.07078835286558757]
	TIME [epoch: 6.47 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07855671907664687		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.07855671907664687 | validation: 0.09736927029484099]
	TIME [epoch: 6.47 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07948195697935342		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.07948195697935342 | validation: 0.0775906178435932]
	TIME [epoch: 6.47 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07954284674802178		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.07954284674802178 | validation: 0.08020797061485159]
	TIME [epoch: 6.49 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08000776684759472		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.08000776684759472 | validation: 0.06499404499648243]
	TIME [epoch: 6.47 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08531490488314541		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.08531490488314541 | validation: 0.1258447610637247]
	TIME [epoch: 6.47 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07710221376152859		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.07710221376152859 | validation: 0.10721549524551226]
	TIME [epoch: 6.47 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09088921699937619		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.09088921699937619 | validation: 0.12685953506428863]
	TIME [epoch: 6.47 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08327155487119044		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.08327155487119044 | validation: 0.1169198926651242]
	TIME [epoch: 6.46 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07576482307052777		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.07576482307052777 | validation: 0.09508644015999852]
	TIME [epoch: 6.47 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07329524353986491		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.07329524353986491 | validation: 0.1187663149049983]
	TIME [epoch: 6.48 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08532471080110482		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.08532471080110482 | validation: 0.11195248569052524]
	TIME [epoch: 6.49 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08085449192025676		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.08085449192025676 | validation: 0.1340391122095287]
	TIME [epoch: 6.46 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09530428001957664		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.09530428001957664 | validation: 0.11834419818465942]
	TIME [epoch: 6.47 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08516330723757384		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.08516330723757384 | validation: 0.05830543844767635]
	TIME [epoch: 6.46 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06493166422687209		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.06493166422687209 | validation: 0.06255432529253013]
	TIME [epoch: 6.47 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07033628080965061		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.07033628080965061 | validation: 0.0959494300845785]
	TIME [epoch: 6.47 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07408721860883422		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.07408721860883422 | validation: 0.11705827374450556]
	TIME [epoch: 6.48 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09673127747681075		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.09673127747681075 | validation: 0.15052248947133862]
	TIME [epoch: 6.48 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09131680594217226		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.09131680594217226 | validation: 0.0736210056933228]
	TIME [epoch: 6.47 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06090436487120826		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.06090436487120826 | validation: 0.07685765941371435]
	TIME [epoch: 6.47 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09270606098236739		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.09270606098236739 | validation: 0.11805179655881382]
	TIME [epoch: 6.47 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07529260335928778		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.07529260335928778 | validation: 0.09157997888688951]
	TIME [epoch: 6.46 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07500686106715264		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.07500686106715264 | validation: 0.08470894188819368]
	TIME [epoch: 6.47 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07408830452417392		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.07408830452417392 | validation: 0.10685866238670876]
	TIME [epoch: 6.47 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0837677178655194		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.0837677178655194 | validation: 0.11426865600000888]
	TIME [epoch: 6.5 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0647396013902628		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.0647396013902628 | validation: 0.07422018242615129]
	TIME [epoch: 6.47 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059795584857326965		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.059795584857326965 | validation: 0.07531671226139085]
	TIME [epoch: 6.47 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06242492561684688		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.06242492561684688 | validation: 0.06173570325944175]
	TIME [epoch: 6.47 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06706118679502399		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.06706118679502399 | validation: 0.10870242604695773]
	TIME [epoch: 6.47 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12209036344521583		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.12209036344521583 | validation: 0.11562046808508197]
	TIME [epoch: 6.47 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0790247619066579		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.0790247619066579 | validation: 0.07998938338900648]
	TIME [epoch: 6.47 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09191446302495287		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.09191446302495287 | validation: 0.11172608538222306]
	TIME [epoch: 6.5 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08532376176390409		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.08532376176390409 | validation: 0.09407719988949223]
	TIME [epoch: 6.47 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0779289460686431		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0779289460686431 | validation: 0.08872303052191764]
	TIME [epoch: 6.47 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776961153656543		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.0776961153656543 | validation: 0.0760293099831212]
	TIME [epoch: 6.47 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06809717397305873		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.06809717397305873 | validation: 0.07844160310696634]
	TIME [epoch: 6.46 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07994184091889575		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.07994184091889575 | validation: 0.07151846243491036]
	TIME [epoch: 6.47 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06258255823416609		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.06258255823416609 | validation: 0.05651361320765241]
	TIME [epoch: 6.46 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08122892593580944		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.08122892593580944 | validation: 0.09222579879681732]
	TIME [epoch: 6.5 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07540466699880166		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.07540466699880166 | validation: 0.1014788874172799]
	TIME [epoch: 6.47 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06426838007313593		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.06426838007313593 | validation: 0.06867445073223703]
	TIME [epoch: 6.46 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06139341466557803		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.06139341466557803 | validation: 0.061644800724226984]
	TIME [epoch: 6.47 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07194074784788382		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.07194074784788382 | validation: 0.07108355802028213]
	TIME [epoch: 6.47 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06119153464845789		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.06119153464845789 | validation: 0.05811639726649483]
	TIME [epoch: 6.47 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06318361559949218		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.06318361559949218 | validation: 0.0704932326170069]
	TIME [epoch: 6.46 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08401380345318261		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.08401380345318261 | validation: 0.09303895920116087]
	TIME [epoch: 6.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07058801150824505		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.07058801150824505 | validation: 0.052635846461306514]
	TIME [epoch: 6.47 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05781057524997732		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.05781057524997732 | validation: 0.08101753659454435]
	TIME [epoch: 6.47 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07672635137328053		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.07672635137328053 | validation: 0.08307830595603267]
	TIME [epoch: 6.47 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07478312586897579		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.07478312586897579 | validation: 0.08363990325046697]
	TIME [epoch: 6.46 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08073109319216154		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.08073109319216154 | validation: 0.07099755550423925]
	TIME [epoch: 6.47 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07679431881925416		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.07679431881925416 | validation: 0.07030034380987704]
	TIME [epoch: 6.46 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07029567113762662		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.07029567113762662 | validation: 0.06009778530179217]
	TIME [epoch: 6.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08270078462941591		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.08270078462941591 | validation: 0.0515259120699515]
	TIME [epoch: 6.47 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07600544049883674		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.07600544049883674 | validation: 0.08962130397156141]
	TIME [epoch: 6.47 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07651083696633143		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.07651083696633143 | validation: 0.07060130088389152]
	TIME [epoch: 6.46 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06316875863615037		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.06316875863615037 | validation: 0.08156083869484144]
	TIME [epoch: 6.47 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08104338680654508		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.08104338680654508 | validation: 0.07807064447848946]
	TIME [epoch: 6.47 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06885216295979465		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.06885216295979465 | validation: 0.06615837500670878]
	TIME [epoch: 6.46 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08282723075578101		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.08282723075578101 | validation: 0.07092883578439928]
	TIME [epoch: 6.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07486660162846534		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.07486660162846534 | validation: 0.05139285511068489]
	TIME [epoch: 6.48 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07250755406094352		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.07250755406094352 | validation: 0.05846477523919425]
	TIME [epoch: 6.47 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06682379163513344		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.06682379163513344 | validation: 0.08026228145892617]
	TIME [epoch: 6.46 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08571303462595144		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.08571303462595144 | validation: 0.07447011066034491]
	TIME [epoch: 6.47 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.078991269055332		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.078991269055332 | validation: 0.07100683531787945]
	TIME [epoch: 6.46 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06934993299040118		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.06934993299040118 | validation: 0.07085082668076863]
	TIME [epoch: 6.47 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05597698180182393		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.05597698180182393 | validation: 0.06572287921781698]
	TIME [epoch: 6.48 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059960595315962026		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.059960595315962026 | validation: 0.06709833381435841]
	TIME [epoch: 6.48 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06697903959778032		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.06697903959778032 | validation: 0.05194335852061043]
	TIME [epoch: 6.47 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056169182036295874		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.056169182036295874 | validation: 0.06534267188094865]
	TIME [epoch: 6.46 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07660072023510567		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.07660072023510567 | validation: 0.06553218717421604]
	TIME [epoch: 6.47 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07297755338821701		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.07297755338821701 | validation: 0.08726192744509603]
	TIME [epoch: 6.46 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06909928075208414		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.06909928075208414 | validation: 0.06112414715802568]
	TIME [epoch: 6.47 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07169224014987584		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.07169224014987584 | validation: 0.06440754716960198]
	TIME [epoch: 6.48 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058440652718448005		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.058440652718448005 | validation: 0.06703196787167512]
	TIME [epoch: 6.49 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0703616213631373		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.0703616213631373 | validation: 0.062100571444246085]
	TIME [epoch: 6.47 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061963253668141746		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.061963253668141746 | validation: 0.05834189272723106]
	TIME [epoch: 6.47 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05768372379622852		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.05768372379622852 | validation: 0.05350437594559133]
	TIME [epoch: 6.47 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059530385353499096		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.059530385353499096 | validation: 0.06051305063275818]
	TIME [epoch: 6.47 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06458870641276793		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.06458870641276793 | validation: 0.06395404662338892]
	TIME [epoch: 6.47 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06746306118748502		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.06746306118748502 | validation: 0.07435996655360469]
	TIME [epoch: 6.47 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0608880493613556		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.0608880493613556 | validation: 0.0780437620801201]
	TIME [epoch: 6.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06556978185172121		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.06556978185172121 | validation: 0.09322322609297785]
	TIME [epoch: 6.47 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0764601092074794		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.0764601092074794 | validation: 0.07970269943552541]
	TIME [epoch: 6.47 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06982687025902393		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.06982687025902393 | validation: 0.08291474452090368]
	TIME [epoch: 6.47 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08055213974750887		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.08055213974750887 | validation: 0.06452127444029004]
	TIME [epoch: 6.46 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055915969389346065		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.055915969389346065 | validation: 0.06668840828064415]
	TIME [epoch: 6.47 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06472740345638857		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.06472740345638857 | validation: 0.07813063857566475]
	TIME [epoch: 6.47 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06511338241490139		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.06511338241490139 | validation: 0.09359255505553915]
	TIME [epoch: 6.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06638584657653024		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.06638584657653024 | validation: 0.05460410009892806]
	TIME [epoch: 6.48 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05627376930790223		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.05627376930790223 | validation: 0.05670184654979222]
	TIME [epoch: 6.47 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07009547612875516		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.07009547612875516 | validation: 0.048161667168165875]
	TIME [epoch: 6.49 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06054646158527832		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.06054646158527832 | validation: 0.05218501318759948]
	TIME [epoch: 6.48 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05540539324884003		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.05540539324884003 | validation: 0.05230551984973238]
	TIME [epoch: 6.47 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05991906250861233		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.05991906250861233 | validation: 0.057826624122798]
	TIME [epoch: 6.46 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06467879049820954		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.06467879049820954 | validation: 0.07470203379244138]
	TIME [epoch: 6.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06962468370130448		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.06962468370130448 | validation: 0.055811882496916994]
	TIME [epoch: 6.47 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06319130163507579		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.06319130163507579 | validation: 0.04860064201979974]
	TIME [epoch: 6.46 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05968806810100469		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.05968806810100469 | validation: 0.056834810467879165]
	TIME [epoch: 6.47 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061897045113307236		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.061897045113307236 | validation: 0.08102463356245986]
	TIME [epoch: 6.46 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07690055794577438		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.07690055794577438 | validation: 0.06281033645293353]
	TIME [epoch: 6.47 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05578322590881201		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.05578322590881201 | validation: 0.06683512832259514]
	TIME [epoch: 6.46 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060575173327564076		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.060575173327564076 | validation: 0.06814514391839126]
	TIME [epoch: 6.51 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06799181198877761		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.06799181198877761 | validation: 0.11571246673517382]
	TIME [epoch: 6.47 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10356688012550624		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.10356688012550624 | validation: 0.10456908653803418]
	TIME [epoch: 6.46 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07383105843456997		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.07383105843456997 | validation: 0.07369796616467184]
	TIME [epoch: 6.46 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057729614886944725		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.057729614886944725 | validation: 0.07579606697322556]
	TIME [epoch: 6.46 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08200521997983842		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.08200521997983842 | validation: 0.07208307004580258]
	TIME [epoch: 6.46 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10025748521742159		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.10025748521742159 | validation: 0.06353640326035466]
	TIME [epoch: 6.45 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07285371621438864		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.07285371621438864 | validation: 0.0962280354199373]
	TIME [epoch: 6.48 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08385153964681624		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.08385153964681624 | validation: 0.12260380820930859]
	TIME [epoch: 6.46 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07180479409377667		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.07180479409377667 | validation: 0.08685986374321035]
	TIME [epoch: 6.46 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08471566642256514		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.08471566642256514 | validation: 0.08816111858131823]
	TIME [epoch: 6.46 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06395347492604858		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.06395347492604858 | validation: 0.07944799630308085]
	TIME [epoch: 6.46 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06859431655550598		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.06859431655550598 | validation: 0.08536212350950902]
	TIME [epoch: 6.46 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06533905347793122		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.06533905347793122 | validation: 0.08555968358788332]
	TIME [epoch: 6.46 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06550145699540637		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.06550145699540637 | validation: 0.10505060669161372]
	TIME [epoch: 6.5 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07292046624990384		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.07292046624990384 | validation: 0.08708840293591934]
	TIME [epoch: 6.47 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06193003928337208		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.06193003928337208 | validation: 0.07672641581258374]
	TIME [epoch: 6.47 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0648667799599924		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.0648667799599924 | validation: 0.06789781756512701]
	TIME [epoch: 6.47 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05924458883413879		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.05924458883413879 | validation: 0.08348188897830848]
	TIME [epoch: 6.47 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05858697291354879		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.05858697291354879 | validation: 0.07079112810125208]
	TIME [epoch: 6.48 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05751640931678354		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.05751640931678354 | validation: 0.0684275500647292]
	TIME [epoch: 6.48 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06553897610644392		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.06553897610644392 | validation: 0.06770092583245367]
	TIME [epoch: 6.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05372567456050383		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.05372567456050383 | validation: 0.0675466099089007]
	TIME [epoch: 6.5 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05528010023164903		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.05528010023164903 | validation: 0.054532300735075]
	TIME [epoch: 6.49 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05943389409817272		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.05943389409817272 | validation: 0.07797055442009794]
	TIME [epoch: 6.48 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0751187342330101		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.0751187342330101 | validation: 0.062172394758683254]
	TIME [epoch: 6.48 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06006585755382663		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.06006585755382663 | validation: 0.06919679688762212]
	TIME [epoch: 6.48 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05879277878192041		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.05879277878192041 | validation: 0.06813837899871711]
	TIME [epoch: 6.48 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05836025391515347		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.05836025391515347 | validation: 0.06296103553109414]
	TIME [epoch: 6.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05508957341824803		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.05508957341824803 | validation: 0.07344432254506128]
	TIME [epoch: 6.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052696766277026644		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.052696766277026644 | validation: 0.06256790861046245]
	TIME [epoch: 6.49 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0564349473362822		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.0564349473362822 | validation: 0.06115609511123777]
	TIME [epoch: 6.49 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06098836850523802		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.06098836850523802 | validation: 0.058630673034254135]
	TIME [epoch: 6.48 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0537646734773328		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.0537646734773328 | validation: 0.06426211030916539]
	TIME [epoch: 6.49 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05662205211627672		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.05662205211627672 | validation: 0.09252781514017042]
	TIME [epoch: 6.48 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06512152046212222		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.06512152046212222 | validation: 0.0691516867296574]
	TIME [epoch: 6.49 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055727466562254024		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.055727466562254024 | validation: 0.0914373443001527]
	TIME [epoch: 6.51 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06639943514947666		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.06639943514947666 | validation: 0.08176114054046789]
	TIME [epoch: 6.49 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07509721633087849		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.07509721633087849 | validation: 0.07421566427201137]
	TIME [epoch: 6.48 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059246739992626904		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.059246739992626904 | validation: 0.07037266715864507]
	TIME [epoch: 6.49 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05178230448651554		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.05178230448651554 | validation: 0.050238533501662276]
	TIME [epoch: 6.49 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05220864799608201		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.05220864799608201 | validation: 0.05780940188928033]
	TIME [epoch: 6.49 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054501253919941546		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.054501253919941546 | validation: 0.058764200909354296]
	TIME [epoch: 6.49 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05724233831877459		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.05724233831877459 | validation: 0.06735355901240173]
	TIME [epoch: 6.52 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05601771925366625		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.05601771925366625 | validation: 0.0859596892498139]
	TIME [epoch: 6.49 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06859912620405957		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.06859912620405957 | validation: 0.07455655474388538]
	TIME [epoch: 6.49 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06611639044851811		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.06611639044851811 | validation: 0.05581369175335388]
	TIME [epoch: 6.48 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05107211380283094		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.05107211380283094 | validation: 0.04956065597650151]
	TIME [epoch: 6.48 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061424240645822574		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.061424240645822574 | validation: 0.0638303873391887]
	TIME [epoch: 6.49 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060158897197576264		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.060158897197576264 | validation: 0.055375282935007306]
	TIME [epoch: 6.49 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061338151172760993		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.061338151172760993 | validation: 0.0514062180755602]
	TIME [epoch: 6.52 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05531434432622713		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.05531434432622713 | validation: 0.05812775966662123]
	TIME [epoch: 6.49 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059487171200514534		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.059487171200514534 | validation: 0.04502275043492956]
	TIME [epoch: 6.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_1179.pth
	Model improved!!!
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05517910177013266		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.05517910177013266 | validation: 0.05857203695253315]
	TIME [epoch: 6.48 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06496367328188836		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.06496367328188836 | validation: 0.07866365772278062]
	TIME [epoch: 6.48 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08148691877735406		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.08148691877735406 | validation: 0.08719696006582797]
	TIME [epoch: 6.48 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06529309538715757		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.06529309538715757 | validation: 0.06363896280298705]
	TIME [epoch: 6.48 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052624182304886094		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.052624182304886094 | validation: 0.06650787446642999]
	TIME [epoch: 6.51 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05467007165197042		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.05467007165197042 | validation: 0.058375868681119894]
	TIME [epoch: 6.48 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05900960724614261		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.05900960724614261 | validation: 0.06369916540527688]
	TIME [epoch: 6.48 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05827137305398772		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.05827137305398772 | validation: 0.05636885285448871]
	TIME [epoch: 6.48 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051004802497625235		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.051004802497625235 | validation: 0.0713735894158023]
	TIME [epoch: 6.48 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05848919985060225		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.05848919985060225 | validation: 0.06737094987396713]
	TIME [epoch: 6.48 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06130038546321312		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.06130038546321312 | validation: 0.07331811095704915]
	TIME [epoch: 6.48 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058026409030971574		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.058026409030971574 | validation: 0.07417558244577903]
	TIME [epoch: 6.51 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05786464462892284		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.05786464462892284 | validation: 0.05870258417053514]
	TIME [epoch: 6.48 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062172251950953335		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.062172251950953335 | validation: 0.05591802166373817]
	TIME [epoch: 6.48 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053192888516543205		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.053192888516543205 | validation: 0.05040370183131127]
	TIME [epoch: 6.48 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05045660644205173		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.05045660644205173 | validation: 0.05746679610249531]
	TIME [epoch: 6.48 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049130696101632135		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.049130696101632135 | validation: 0.05839831110475533]
	TIME [epoch: 6.48 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0530474409106719		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.0530474409106719 | validation: 0.074799738231936]
	TIME [epoch: 6.48 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06440386593378276		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.06440386593378276 | validation: 0.0911583918882222]
	TIME [epoch: 6.52 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06705759213180652		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.06705759213180652 | validation: 0.08043795429588702]
	TIME [epoch: 6.48 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06330317051311705		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.06330317051311705 | validation: 0.0754873558747694]
	TIME [epoch: 6.48 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06344055922246294		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.06344055922246294 | validation: 0.06954751967588317]
	TIME [epoch: 6.48 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05478157094883649		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.05478157094883649 | validation: 0.0649044872490183]
	TIME [epoch: 6.48 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05661066176548318		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.05661066176548318 | validation: 0.06848035462744693]
	TIME [epoch: 6.48 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05320158911254198		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.05320158911254198 | validation: 0.07975776589271637]
	TIME [epoch: 6.47 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06612777458022996		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.06612777458022996 | validation: 0.05877294357817532]
	TIME [epoch: 6.51 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05691199324292892		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.05691199324292892 | validation: 0.05868594083088983]
	TIME [epoch: 6.48 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07282689756181479		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.07282689756181479 | validation: 0.08893867184348932]
	TIME [epoch: 6.48 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06519866675975644		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.06519866675975644 | validation: 0.05731901800629778]
	TIME [epoch: 6.48 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05001001209354642		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.05001001209354642 | validation: 0.05061731455741722]
	TIME [epoch: 6.48 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05603524542953253		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.05603524542953253 | validation: 0.06333550561525927]
	TIME [epoch: 6.48 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05388813089462484		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.05388813089462484 | validation: 0.05959683793910309]
	TIME [epoch: 6.48 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055442820138944124		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.055442820138944124 | validation: 0.057032882247940266]
	TIME [epoch: 6.51 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05226513993365048		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.05226513993365048 | validation: 0.06422514944992805]
	TIME [epoch: 6.48 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05517119681107947		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.05517119681107947 | validation: 0.057582363788691054]
	TIME [epoch: 6.48 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055814353140257435		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.055814353140257435 | validation: 0.05812966118474239]
	TIME [epoch: 6.48 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057351464922110074		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.057351464922110074 | validation: 0.07242186375461936]
	TIME [epoch: 6.48 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06769899587827514		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.06769899587827514 | validation: 0.06463090945855461]
	TIME [epoch: 6.48 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05648505910737933		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.05648505910737933 | validation: 0.07337292381499261]
	TIME [epoch: 6.48 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06382923630022139		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.06382923630022139 | validation: 0.0765983908116251]
	TIME [epoch: 6.51 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06620103077283464		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.06620103077283464 | validation: 0.06902704039959791]
	TIME [epoch: 6.48 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05601272039140239		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.05601272039140239 | validation: 0.060341544586104]
	TIME [epoch: 6.48 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06950974217034762		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.06950974217034762 | validation: 0.06872888484337235]
	TIME [epoch: 6.48 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0754182112807062		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.0754182112807062 | validation: 0.06983403171173157]
	TIME [epoch: 6.48 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0592656650344003		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.0592656650344003 | validation: 0.06731655243328222]
	TIME [epoch: 6.48 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05801016737084416		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.05801016737084416 | validation: 0.07455494223524875]
	TIME [epoch: 6.48 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0581650366273884		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.0581650366273884 | validation: 0.05454252506097909]
	TIME [epoch: 6.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059685824106882696		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.059685824106882696 | validation: 0.08144727208681257]
	TIME [epoch: 6.5 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05885342824380865		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.05885342824380865 | validation: 0.07788929335031698]
	TIME [epoch: 6.48 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061369480792777334		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.061369480792777334 | validation: 0.0824578134952562]
	TIME [epoch: 6.48 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07075667785720896		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.07075667785720896 | validation: 0.08554754855355526]
	TIME [epoch: 6.48 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0602389391550866		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.0602389391550866 | validation: 0.07448027942677689]
	TIME [epoch: 6.48 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053337519221515785		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.053337519221515785 | validation: 0.06640174810566218]
	TIME [epoch: 6.48 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05512330674950295		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.05512330674950295 | validation: 0.06756462914084166]
	TIME [epoch: 6.5 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06014307710496411		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.06014307710496411 | validation: 0.07200879095275821]
	TIME [epoch: 6.5 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06742264474075174		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.06742264474075174 | validation: 0.07348867169819202]
	TIME [epoch: 6.48 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06194648219987029		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.06194648219987029 | validation: 0.06381253733845264]
	TIME [epoch: 6.48 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06307950901358814		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.06307950901358814 | validation: 0.06954648605297586]
	TIME [epoch: 6.48 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0741216522091584		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.0741216522091584 | validation: 0.11144018431162207]
	TIME [epoch: 6.48 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08737727956712106		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.08737727956712106 | validation: 0.07784418188110373]
	TIME [epoch: 6.48 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023694807502461		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.06023694807502461 | validation: 0.06580113191530193]
	TIME [epoch: 6.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05446624828125939		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.05446624828125939 | validation: 0.07529108957004987]
	TIME [epoch: 6.49 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07855374889627922		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.07855374889627922 | validation: 0.07460121035142672]
	TIME [epoch: 6.48 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06763392695641104		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.06763392695641104 | validation: 0.06501040364576169]
	TIME [epoch: 6.48 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056525554875419104		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.056525554875419104 | validation: 0.06990814272530045]
	TIME [epoch: 6.48 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05896185646071891		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.05896185646071891 | validation: 0.062155314225760386]
	TIME [epoch: 6.48 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05443796664380215		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.05443796664380215 | validation: 0.05476786075519423]
	TIME [epoch: 6.48 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05469311893399675		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.05469311893399675 | validation: 0.06771950317028318]
	TIME [epoch: 6.48 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05017094534353696		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.05017094534353696 | validation: 0.051531459738132085]
	TIME [epoch: 6.51 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05258281795419127		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.05258281795419127 | validation: 0.05860640865913041]
	TIME [epoch: 6.48 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05392847734368534		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.05392847734368534 | validation: 0.06912919703530608]
	TIME [epoch: 6.47 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05542916499166817		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.05542916499166817 | validation: 0.08689395076172947]
	TIME [epoch: 6.48 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0702344082696027		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.0702344082696027 | validation: 0.09500569424076404]
	TIME [epoch: 6.48 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06569492941347976		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.06569492941347976 | validation: 0.060105215158870386]
	TIME [epoch: 6.48 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051022153942154765		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.051022153942154765 | validation: 0.050857836534299705]
	TIME [epoch: 6.48 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05489203946623442		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.05489203946623442 | validation: 0.05601446767320951]
	TIME [epoch: 6.51 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054524378704289944		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.054524378704289944 | validation: 0.05720167893998908]
	TIME [epoch: 6.48 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059503539803101524		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.059503539803101524 | validation: 0.054789908107548566]
	TIME [epoch: 6.48 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05531894425895853		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.05531894425895853 | validation: 0.05926175920561469]
	TIME [epoch: 6.48 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06242948429924075		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.06242948429924075 | validation: 0.0723038931535518]
	TIME [epoch: 6.48 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06451495592269729		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.06451495592269729 | validation: 0.07056029659498372]
	TIME [epoch: 6.48 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05393936673108888		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.05393936673108888 | validation: 0.050066694807310186]
	TIME [epoch: 6.48 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053467909107248225		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.053467909107248225 | validation: 0.06278008731755252]
	TIME [epoch: 6.51 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05776085908640631		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.05776085908640631 | validation: 0.0669322466208269]
	TIME [epoch: 6.48 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05835726122879255		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.05835726122879255 | validation: 0.05829114317459396]
	TIME [epoch: 6.48 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058551342289816156		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.058551342289816156 | validation: 0.0638963261536359]
	TIME [epoch: 6.48 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05588845026619244		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.05588845026619244 | validation: 0.060687428055245664]
	TIME [epoch: 6.48 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05640944486280462		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.05640944486280462 | validation: 0.05591195638440391]
	TIME [epoch: 6.48 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06563698270114		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.06563698270114 | validation: 0.06476390155378545]
	TIME [epoch: 6.48 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06455268847022096		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.06455268847022096 | validation: 0.05028014071552981]
	TIME [epoch: 6.51 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05762317352592393		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.05762317352592393 | validation: 0.06160063592666067]
	TIME [epoch: 6.49 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061763759984353364		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.061763759984353364 | validation: 0.054133193774323025]
	TIME [epoch: 6.47 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05412265645624395		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.05412265645624395 | validation: 0.0584767706121293]
	TIME [epoch: 6.48 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05477542558870878		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.05477542558870878 | validation: 0.05736729580245756]
	TIME [epoch: 6.47 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05208395893954889		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.05208395893954889 | validation: 0.05886748334477843]
	TIME [epoch: 6.47 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052841928325882324		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.052841928325882324 | validation: 0.05865730620158494]
	TIME [epoch: 6.48 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05086470441581731		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.05086470441581731 | validation: 0.061500305735585355]
	TIME [epoch: 6.51 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05760638303666611		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.05760638303666611 | validation: 0.07988465097630867]
	TIME [epoch: 6.48 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059853763415939065		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.059853763415939065 | validation: 0.07258772769327708]
	TIME [epoch: 6.48 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062457141371749014		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.062457141371749014 | validation: 0.07062770560979469]
	TIME [epoch: 6.48 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05279060042262608		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.05279060042262608 | validation: 0.06728881630512727]
	TIME [epoch: 6.48 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057572895778082354		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.057572895778082354 | validation: 0.06570527957207581]
	TIME [epoch: 6.47 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06016282779770932		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.06016282779770932 | validation: 0.07033432747848581]
	TIME [epoch: 6.48 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0568349304962286		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.0568349304962286 | validation: 0.07487894022712255]
	TIME [epoch: 6.51 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054877722267229194		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.054877722267229194 | validation: 0.06815922650950988]
	TIME [epoch: 6.49 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0612743108833537		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.0612743108833537 | validation: 0.08050268658133039]
	TIME [epoch: 6.48 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05534146308058005		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.05534146308058005 | validation: 0.07499100079874213]
	TIME [epoch: 6.48 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05734985647881049		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.05734985647881049 | validation: 0.0858706342361856]
	TIME [epoch: 6.48 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058865015272911894		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.058865015272911894 | validation: 0.07957703911937289]
	TIME [epoch: 6.48 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05953954101330854		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.05953954101330854 | validation: 0.06175633856564156]
	TIME [epoch: 6.47 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06010814745020695		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.06010814745020695 | validation: 0.06023166416293438]
	TIME [epoch: 6.49 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06573071666478209		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.06573071666478209 | validation: 0.07362421393070745]
	TIME [epoch: 6.49 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060174792463756656		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.060174792463756656 | validation: 0.07466449740739377]
	TIME [epoch: 6.48 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06312833467702769		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.06312833467702769 | validation: 0.07835793992328201]
	TIME [epoch: 6.47 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0619914559620499		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.0619914559620499 | validation: 0.06221910693568551]
	TIME [epoch: 6.48 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05853067748562477		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.05853067748562477 | validation: 0.1153671807451202]
	TIME [epoch: 6.47 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06517257239169913		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.06517257239169913 | validation: 0.071481506142041]
	TIME [epoch: 6.47 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04980620299598834		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.04980620299598834 | validation: 0.06489286737580889]
	TIME [epoch: 6.49 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06015580781109689		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.06015580781109689 | validation: 0.06371843523263172]
	TIME [epoch: 6.5 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04832861533692184		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.04832861533692184 | validation: 0.05841205555881147]
	TIME [epoch: 6.48 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05180193923417557		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.05180193923417557 | validation: 0.05019887583238584]
	TIME [epoch: 6.48 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05602504499727054		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.05602504499727054 | validation: 0.05714038500484154]
	TIME [epoch: 6.48 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054779575192950375		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.054779575192950375 | validation: 0.08684675877870163]
	TIME [epoch: 6.47 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07590801857072223		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.07590801857072223 | validation: 0.06938306633672242]
	TIME [epoch: 6.48 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06821452886717372		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.06821452886717372 | validation: 0.06133149839450264]
	TIME [epoch: 6.49 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259865648632229		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.06259865648632229 | validation: 0.0684851078431095]
	TIME [epoch: 6.49 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06962051771993587		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.06962051771993587 | validation: 0.074170936695928]
	TIME [epoch: 6.48 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06869970938987435		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.06869970938987435 | validation: 0.06093443767490056]
	TIME [epoch: 6.48 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05423154947663933		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.05423154947663933 | validation: 0.04872980459722936]
	TIME [epoch: 6.48 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057621399101601065		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.057621399101601065 | validation: 0.06513954140911458]
	TIME [epoch: 6.47 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052428891342993805		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.052428891342993805 | validation: 0.054068473077532174]
	TIME [epoch: 6.48 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05129729143452767		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.05129729143452767 | validation: 0.04744546607802503]
	TIME [epoch: 6.48 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0522760454846442		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.0522760454846442 | validation: 0.06828559901786775]
	TIME [epoch: 6.51 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05255540978300469		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.05255540978300469 | validation: 0.05272551608254249]
	TIME [epoch: 6.48 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05214707331292912		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.05214707331292912 | validation: 0.06680938264225826]
	TIME [epoch: 6.48 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05716235907977682		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.05716235907977682 | validation: 0.05363462012121122]
	TIME [epoch: 6.48 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05851443482356595		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.05851443482356595 | validation: 0.044126063534325265]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_1316.pth
	Model improved!!!
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06549451345882842		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.06549451345882842 | validation: 0.04951698436226524]
	TIME [epoch: 6.47 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05937167360873951		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.05937167360873951 | validation: 0.05009058235212214]
	TIME [epoch: 6.48 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05294264497863946		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.05294264497863946 | validation: 0.045277972814670976]
	TIME [epoch: 6.51 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060837749476689164		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.060837749476689164 | validation: 0.06249635090645538]
	TIME [epoch: 6.48 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056750273142925474		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.056750273142925474 | validation: 0.05944926963566065]
	TIME [epoch: 6.48 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05142559931448652		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.05142559931448652 | validation: 0.046534281663971826]
	TIME [epoch: 6.47 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05768715551281662		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.05768715551281662 | validation: 0.044238468919443615]
	TIME [epoch: 6.48 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058696897484359065		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.058696897484359065 | validation: 0.05507748598252857]
	TIME [epoch: 6.47 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05431372335086052		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.05431372335086052 | validation: 0.052604022324244736]
	TIME [epoch: 6.48 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05835501733903803		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.05835501733903803 | validation: 0.0523321858873677]
	TIME [epoch: 6.5 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04990648723382109		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.04990648723382109 | validation: 0.054096080785009076]
	TIME [epoch: 6.48 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05371926885849026		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.05371926885849026 | validation: 0.05648045128824523]
	TIME [epoch: 6.47 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04925977560941527		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.04925977560941527 | validation: 0.055621723537513344]
	TIME [epoch: 6.48 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05206131025322561		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.05206131025322561 | validation: 0.05567284050083906]
	TIME [epoch: 6.48 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046818438312100766		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.046818438312100766 | validation: 0.0553552417341324]
	TIME [epoch: 6.47 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051302782326515126		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.051302782326515126 | validation: 0.0549064759183189]
	TIME [epoch: 6.47 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05038126907913505		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.05038126907913505 | validation: 0.05572056834461935]
	TIME [epoch: 6.51 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05245097995843928		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.05245097995843928 | validation: 0.056255111896789035]
	TIME [epoch: 6.48 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04997808126951869		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.04997808126951869 | validation: 0.059279564653697325]
	TIME [epoch: 6.47 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04689591779426286		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.04689591779426286 | validation: 0.0504904808779619]
	TIME [epoch: 6.48 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055773029316587994		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.055773029316587994 | validation: 0.05536137678590448]
	TIME [epoch: 6.48 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05040674726610592		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.05040674726610592 | validation: 0.04510686234422572]
	TIME [epoch: 6.47 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05288245188990017		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.05288245188990017 | validation: 0.056621457930924095]
	TIME [epoch: 6.48 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05390615117118151		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.05390615117118151 | validation: 0.06968180392945779]
	TIME [epoch: 6.51 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055871798135762075		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.055871798135762075 | validation: 0.0632902256293818]
	TIME [epoch: 6.48 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056336000372810474		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.056336000372810474 | validation: 0.06713318897731167]
	TIME [epoch: 6.47 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05994583182668867		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.05994583182668867 | validation: 0.06471849580494686]
	TIME [epoch: 6.48 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05314425499250349		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.05314425499250349 | validation: 0.04835797365133868]
	TIME [epoch: 6.48 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05517659764184725		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.05517659764184725 | validation: 0.05724283275101021]
	TIME [epoch: 6.48 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054736003310336165		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.054736003310336165 | validation: 0.056847982097556836]
	TIME [epoch: 6.47 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05680489158802478		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.05680489158802478 | validation: 0.06017405119311835]
	TIME [epoch: 6.51 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06055818085994987		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.06055818085994987 | validation: 0.05789187263120943]
	TIME [epoch: 6.48 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06293030629977327		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.06293030629977327 | validation: 0.05121450277216846]
	TIME [epoch: 6.47 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05868863644940576		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.05868863644940576 | validation: 0.05595731952464052]
	TIME [epoch: 6.48 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05529866496503308		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.05529866496503308 | validation: 0.05201766108647093]
	TIME [epoch: 6.48 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059672588002411237		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.059672588002411237 | validation: 0.06003032133995895]
	TIME [epoch: 6.48 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05822663208231226		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.05822663208231226 | validation: 0.06391340154878634]
	TIME [epoch: 6.47 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05549375932069603		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.05549375932069603 | validation: 0.050351519857494476]
	TIME [epoch: 6.51 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0509963543462322		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.0509963543462322 | validation: 0.04807324988068142]
	TIME [epoch: 6.48 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04622430755766179		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.04622430755766179 | validation: 0.0465906414414688]
	TIME [epoch: 6.48 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590868216645844		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.04590868216645844 | validation: 0.05189025033858687]
	TIME [epoch: 6.48 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04809154089775988		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.04809154089775988 | validation: 0.06073193077712261]
	TIME [epoch: 6.47 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06217766378442837		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.06217766378442837 | validation: 0.06191701310243399]
	TIME [epoch: 6.48 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05360816977636717		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.05360816977636717 | validation: 0.05621231994241903]
	TIME [epoch: 6.47 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058292768791166016		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.058292768791166016 | validation: 0.07661781032244284]
	TIME [epoch: 6.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057243054086051515		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.057243054086051515 | validation: 0.06580969783832784]
	TIME [epoch: 6.48 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05425643507558693		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.05425643507558693 | validation: 0.05913904855419119]
	TIME [epoch: 6.48 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04706489381672392		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.04706489381672392 | validation: 0.04745035939050595]
	TIME [epoch: 6.47 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04950627438719378		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.04950627438719378 | validation: 0.057401698336924864]
	TIME [epoch: 6.47 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046560275144458096		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.046560275144458096 | validation: 0.053934852575736505]
	TIME [epoch: 6.47 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04597833196310864		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.04597833196310864 | validation: 0.04998302892864837]
	TIME [epoch: 6.47 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0473582554157911		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.0473582554157911 | validation: 0.059736103429343546]
	TIME [epoch: 6.49 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05136154404595363		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.05136154404595363 | validation: 0.06795155725729594]
	TIME [epoch: 6.5 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05263545258463029		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.05263545258463029 | validation: 0.06188490725383292]
	TIME [epoch: 6.48 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05368329574684548		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.05368329574684548 | validation: 0.05226792647253186]
	TIME [epoch: 6.47 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049569185112090824		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.049569185112090824 | validation: 0.04499562968034716]
	TIME [epoch: 6.47 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04882898329750255		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.04882898329750255 | validation: 0.05738274395496271]
	TIME [epoch: 6.47 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05727639591450482		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.05727639591450482 | validation: 0.05889838191082223]
	TIME [epoch: 6.47 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04900326475157693		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.04900326475157693 | validation: 0.050317421776765764]
	TIME [epoch: 6.5 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04968421946582873		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.04968421946582873 | validation: 0.05699321986734602]
	TIME [epoch: 6.5 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590075893827841		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.04590075893827841 | validation: 0.05463061242611413]
	TIME [epoch: 6.48 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05070149273952572		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.05070149273952572 | validation: 0.05857493141345216]
	TIME [epoch: 6.48 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04757207894858889		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.04757207894858889 | validation: 0.06450446928233466]
	TIME [epoch: 6.48 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049682521944215526		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.049682521944215526 | validation: 0.05538243179558999]
	TIME [epoch: 6.48 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05366211566688215		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.05366211566688215 | validation: 0.0625294881775462]
	TIME [epoch: 6.47 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04977143460479911		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.04977143460479911 | validation: 0.05216594785518064]
	TIME [epoch: 6.49 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04798371881904505		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.04798371881904505 | validation: 0.0622536901302262]
	TIME [epoch: 6.49 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057700366993489224		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.057700366993489224 | validation: 0.06942329937926976]
	TIME [epoch: 6.48 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053462037403997215		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.053462037403997215 | validation: 0.06451588374198822]
	TIME [epoch: 6.48 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05073414476811162		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.05073414476811162 | validation: 0.06348880759532179]
	TIME [epoch: 6.48 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050818736863261875		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.050818736863261875 | validation: 0.07212936491650773]
	TIME [epoch: 6.47 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05400397959515821		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.05400397959515821 | validation: 0.06759949578463717]
	TIME [epoch: 6.48 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04948229305166324		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.04948229305166324 | validation: 0.06146064460676112]
	TIME [epoch: 6.48 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054624413826844596		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.054624413826844596 | validation: 0.07239323921488283]
	TIME [epoch: 6.51 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05926082093841836		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.05926082093841836 | validation: 0.06799335181156801]
	TIME [epoch: 6.48 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05298245077905517		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.05298245077905517 | validation: 0.05307256888762264]
	TIME [epoch: 6.48 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04963048656440194		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.04963048656440194 | validation: 0.05263295873133965]
	TIME [epoch: 6.48 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04928396819796072		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.04928396819796072 | validation: 0.06673740023225148]
	TIME [epoch: 6.48 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04827091040693933		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.04827091040693933 | validation: 0.05939789429228755]
	TIME [epoch: 6.47 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04949591961212524		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.04949591961212524 | validation: 0.06332535220511903]
	TIME [epoch: 6.48 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04930179895483088		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.04930179895483088 | validation: 0.06328290454442285]
	TIME [epoch: 6.51 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04953060494008383		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.04953060494008383 | validation: 0.061887150968606745]
	TIME [epoch: 6.48 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05064924037218745		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.05064924037218745 | validation: 0.05193387524080979]
	TIME [epoch: 6.47 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045503100766748836		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.045503100766748836 | validation: 0.06404012659062612]
	TIME [epoch: 6.48 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04772975622903733		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.04772975622903733 | validation: 0.0583748327462876]
	TIME [epoch: 6.48 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048003059006738846		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.048003059006738846 | validation: 0.0562398737556018]
	TIME [epoch: 6.47 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04993529613663272		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.04993529613663272 | validation: 0.07295066297204754]
	TIME [epoch: 6.48 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054086458387004134		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.054086458387004134 | validation: 0.052423509389441895]
	TIME [epoch: 6.51 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04889540926784871		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.04889540926784871 | validation: 0.052776905363429966]
	TIME [epoch: 6.48 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04970787026573392		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.04970787026573392 | validation: 0.0551020000526205]
	TIME [epoch: 6.47 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05324147976804013		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.05324147976804013 | validation: 0.04810932133943181]
	TIME [epoch: 6.48 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04480574281824771		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.04480574281824771 | validation: 0.051956169991430906]
	TIME [epoch: 6.48 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05204238319167527		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.05204238319167527 | validation: 0.0655693487044341]
	TIME [epoch: 6.48 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051460477990010904		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.051460477990010904 | validation: 0.06498716694766475]
	TIME [epoch: 6.48 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04926024635623125		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.04926024635623125 | validation: 0.06182195298304622]
	TIME [epoch: 6.52 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04970858140723153		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.04970858140723153 | validation: 0.07265654999342326]
	TIME [epoch: 6.48 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04752340032722695		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.04752340032722695 | validation: 0.049297187829770196]
	TIME [epoch: 6.48 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05158886098129986		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.05158886098129986 | validation: 0.05952561253938919]
	TIME [epoch: 6.48 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04854034698648472		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.04854034698648472 | validation: 0.06493949440960278]
	TIME [epoch: 6.48 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049459325603475233		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.049459325603475233 | validation: 0.059349659426650936]
	TIME [epoch: 6.47 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05193542033589078		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.05193542033589078 | validation: 0.053677900276305146]
	TIME [epoch: 6.48 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05087951012528754		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.05087951012528754 | validation: 0.058077492933810315]
	TIME [epoch: 6.51 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049279931363742674		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.049279931363742674 | validation: 0.0652959746923309]
	TIME [epoch: 6.49 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05154211768343274		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.05154211768343274 | validation: 0.0641529883138326]
	TIME [epoch: 6.48 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05078699635395993		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.05078699635395993 | validation: 0.06388311933576647]
	TIME [epoch: 6.48 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05084178091669637		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.05084178091669637 | validation: 0.05282438021034386]
	TIME [epoch: 6.48 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050807813922168495		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.050807813922168495 | validation: 0.060571429315234494]
	TIME [epoch: 6.48 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05089917690070549		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.05089917690070549 | validation: 0.05836277296497709]
	TIME [epoch: 6.48 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04991101136295379		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.04991101136295379 | validation: 0.06089903432242938]
	TIME [epoch: 6.51 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04967312076060811		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.04967312076060811 | validation: 0.0632249867676457]
	TIME [epoch: 6.49 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05821649573039758		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.05821649573039758 | validation: 0.08728778100728421]
	TIME [epoch: 6.48 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05692687358672559		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.05692687358672559 | validation: 0.07043783517101536]
	TIME [epoch: 6.48 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04761790955632961		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.04761790955632961 | validation: 0.05183967246121064]
	TIME [epoch: 6.48 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04887811907471966		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.04887811907471966 | validation: 0.05732475113518647]
	TIME [epoch: 6.48 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04765232780842186		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.04765232780842186 | validation: 0.06120802475384581]
	TIME [epoch: 6.48 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0462873999106901		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.0462873999106901 | validation: 0.06094118489368155]
	TIME [epoch: 6.5 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049834329892593655		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.049834329892593655 | validation: 0.05691980753938359]
	TIME [epoch: 6.49 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699472654470672		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.05699472654470672 | validation: 0.06265715863950097]
	TIME [epoch: 6.48 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05370907674280735		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.05370907674280735 | validation: 0.06219143033476611]
	TIME [epoch: 6.48 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05085839919744492		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.05085839919744492 | validation: 0.062212787943163955]
	TIME [epoch: 6.48 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05065793252486289		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.05065793252486289 | validation: 0.061291184826540376]
	TIME [epoch: 6.48 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0504614241641738		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.0504614241641738 | validation: 0.0635365359448455]
	TIME [epoch: 6.48 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05069290270799992		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.05069290270799992 | validation: 0.06042617524653496]
	TIME [epoch: 6.49 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04791837582150667		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.04791837582150667 | validation: 0.05401692206303402]
	TIME [epoch: 6.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04970540175072097		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.04970540175072097 | validation: 0.06155557333291364]
	TIME [epoch: 6.48 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042829741989025935		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.042829741989025935 | validation: 0.059119305336296384]
	TIME [epoch: 6.48 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04922999613383043		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.04922999613383043 | validation: 0.06999009837322405]
	TIME [epoch: 6.48 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04661419423914641		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.04661419423914641 | validation: 0.065696777678681]
	TIME [epoch: 6.47 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046033718878128405		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.046033718878128405 | validation: 0.06280332957626723]
	TIME [epoch: 6.48 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0445823325792193		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.0445823325792193 | validation: 0.056770202737164814]
	TIME [epoch: 6.49 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045791838903927455		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.045791838903927455 | validation: 0.06058496667449553]
	TIME [epoch: 6.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04769067858352987		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.04769067858352987 | validation: 0.06500314203142916]
	TIME [epoch: 6.48 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04941091687810131		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.04941091687810131 | validation: 0.061973950262578015]
	TIME [epoch: 6.48 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05102908035179173		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.05102908035179173 | validation: 0.06404791357148637]
	TIME [epoch: 6.48 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050826435153301236		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.050826435153301236 | validation: 0.056689366315186444]
	TIME [epoch: 6.48 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04472491324954919		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.04472491324954919 | validation: 0.06612428040683123]
	TIME [epoch: 6.48 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049918164156174935		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.049918164156174935 | validation: 0.05548259215558982]
	TIME [epoch: 6.48 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045485161916079625		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.045485161916079625 | validation: 0.06542057833178254]
	TIME [epoch: 6.51 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054914766087473615		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.054914766087473615 | validation: 0.06854461745770066]
	TIME [epoch: 6.48 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04922365801967909		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.04922365801967909 | validation: 0.06782196028952524]
	TIME [epoch: 6.48 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04769116533889288		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.04769116533889288 | validation: 0.06014707494583904]
	TIME [epoch: 6.48 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04660532429386342		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.04660532429386342 | validation: 0.05807669054343432]
	TIME [epoch: 6.48 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043676299384104084		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.043676299384104084 | validation: 0.05651446878184691]
	TIME [epoch: 6.48 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046448125650274855		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.046448125650274855 | validation: 0.060877242387739956]
	TIME [epoch: 6.48 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04556959653268791		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.04556959653268791 | validation: 0.055947390237781336]
	TIME [epoch: 6.51 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467127753127557		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.04467127753127557 | validation: 0.05221102912924644]
	TIME [epoch: 6.48 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04915628445105162		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.04915628445105162 | validation: 0.0499581180710669]
	TIME [epoch: 6.48 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04767918981332932		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.04767918981332932 | validation: 0.060341270480281164]
	TIME [epoch: 6.48 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051590441155005995		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.051590441155005995 | validation: 0.07958150248548665]
	TIME [epoch: 6.48 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05290722668879945		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.05290722668879945 | validation: 0.07386057928864259]
	TIME [epoch: 6.48 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056414520096022054		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.056414520096022054 | validation: 0.07601232233006859]
	TIME [epoch: 6.48 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048574304106151045		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.048574304106151045 | validation: 0.06613475766799201]
	TIME [epoch: 6.51 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04943035736998293		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.04943035736998293 | validation: 0.049226633588139015]
	TIME [epoch: 6.48 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05166859848951688		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.05166859848951688 | validation: 0.05862519141107808]
	TIME [epoch: 6.48 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04908168474460195		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.04908168474460195 | validation: 0.05722680105487106]
	TIME [epoch: 6.48 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04672195256501389		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.04672195256501389 | validation: 0.05238702507930125]
	TIME [epoch: 6.48 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0427807159511208		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.0427807159511208 | validation: 0.053043093159772514]
	TIME [epoch: 6.48 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046436784952211194		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.046436784952211194 | validation: 0.06149785729710667]
	TIME [epoch: 6.48 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0464430054307101		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.0464430054307101 | validation: 0.05942337492955198]
	TIME [epoch: 6.51 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04967685865916369		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.04967685865916369 | validation: 0.06581016504450884]
	TIME [epoch: 6.48 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05087943978493485		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.05087943978493485 | validation: 0.053581867970861764]
	TIME [epoch: 6.48 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05176033623040889		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.05176033623040889 | validation: 0.0620931257976773]
	TIME [epoch: 6.48 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049136167525153825		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.049136167525153825 | validation: 0.052362455440962935]
	TIME [epoch: 6.48 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05225411867890576		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.05225411867890576 | validation: 0.053256511122761065]
	TIME [epoch: 6.47 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04964383957185667		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.04964383957185667 | validation: 0.0575547335563535]
	TIME [epoch: 6.48 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051297033641407565		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.051297033641407565 | validation: 0.05235236625082575]
	TIME [epoch: 6.51 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052834082778239616		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.052834082778239616 | validation: 0.053596633677999814]
	TIME [epoch: 6.48 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05701902130742578		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.05701902130742578 | validation: 0.05351978651041565]
	TIME [epoch: 6.48 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05908715501913227		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.05908715501913227 | validation: 0.056796441823213854]
	TIME [epoch: 6.48 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04999686781608799		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.04999686781608799 | validation: 0.054799001931915524]
	TIME [epoch: 6.48 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04639523433798718		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.04639523433798718 | validation: 0.04977954923597794]
	TIME [epoch: 6.48 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04743343205032994		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.04743343205032994 | validation: 0.05634548423903975]
	TIME [epoch: 6.48 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04569698864798673		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.04569698864798673 | validation: 0.046502460998386876]
	TIME [epoch: 6.51 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04760129352162651		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.04760129352162651 | validation: 0.0495179068469307]
	TIME [epoch: 6.49 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05043500051786742		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.05043500051786742 | validation: 0.050076147152352084]
	TIME [epoch: 6.48 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05543250130167701		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.05543250130167701 | validation: 0.057699021468352145]
	TIME [epoch: 6.48 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05195603246098002		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.05195603246098002 | validation: 0.04890908782081641]
	TIME [epoch: 6.48 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05116884321966172		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.05116884321966172 | validation: 0.03928679149492263]
	TIME [epoch: 6.48 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_1494.pth
	Model improved!!!
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0513608394569659		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.0513608394569659 | validation: 0.0453585806966355]
	TIME [epoch: 6.47 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05565769998656222		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.05565769998656222 | validation: 0.046796884681247264]
	TIME [epoch: 6.51 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049263229017439444		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.049263229017439444 | validation: 0.047101106618993666]
	TIME [epoch: 6.49 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04494410053492737		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.04494410053492737 | validation: 0.0453609852725923]
	TIME [epoch: 6.47 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04698354692324745		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.04698354692324745 | validation: 0.042670782868153435]
	TIME [epoch: 6.48 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04886539188008596		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.04886539188008596 | validation: 0.0584420169498368]
	TIME [epoch: 6.48 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04739939315577987		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.04739939315577987 | validation: 0.05049224880438771]
	TIME [epoch: 6.47 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054103377404097486		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.054103377404097486 | validation: 0.04284763621818522]
	TIME [epoch: 6.48 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04628860864454021		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.04628860864454021 | validation: 0.05637849746626304]
	TIME [epoch: 6.51 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04670833690226161		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.04670833690226161 | validation: 0.05474581995192253]
	TIME [epoch: 6.48 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04786156851646041		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.04786156851646041 | validation: 0.05240606493395771]
	TIME [epoch: 6.48 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05094117395355058		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.05094117395355058 | validation: 0.04373972430799514]
	TIME [epoch: 6.48 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04714435992259655		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.04714435992259655 | validation: 0.043355482646093096]
	TIME [epoch: 6.47 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04576177578865634		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.04576177578865634 | validation: 0.04246127477340133]
	TIME [epoch: 6.47 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048582236002519846		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.048582236002519846 | validation: 0.05745577459881343]
	TIME [epoch: 6.48 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04815669019277356		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.04815669019277356 | validation: 0.05608473227149696]
	TIME [epoch: 6.49 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05861955254517817		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.05861955254517817 | validation: 0.07003341176615922]
	TIME [epoch: 6.49 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05269136325481453		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.05269136325481453 | validation: 0.05365624604196453]
	TIME [epoch: 6.47 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051638650727610445		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.051638650727610445 | validation: 0.047856996338903654]
	TIME [epoch: 6.47 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05072193966227599		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.05072193966227599 | validation: 0.04931776240882247]
	TIME [epoch: 6.47 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050073315442020074		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.050073315442020074 | validation: 0.05503050186217814]
	TIME [epoch: 6.48 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049945859484564085		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.049945859484564085 | validation: 0.05215185807087895]
	TIME [epoch: 6.47 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04694765724941697		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.04694765724941697 | validation: 0.041752741344449604]
	TIME [epoch: 6.49 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0485021477195931		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.0485021477195931 | validation: 0.04664189366277359]
	TIME [epoch: 6.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05068665207685804		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.05068665207685804 | validation: 0.05320714944511401]
	TIME [epoch: 6.48 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050107728585706064		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.050107728585706064 | validation: 0.05251329646918917]
	TIME [epoch: 6.48 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049324447239426084		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.049324447239426084 | validation: 0.06189793760317437]
	TIME [epoch: 6.48 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056299477950706306		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.056299477950706306 | validation: 0.05026415008435778]
	TIME [epoch: 6.47 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049959068133583875		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.049959068133583875 | validation: 0.04951475476140797]
	TIME [epoch: 6.48 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050859741331777515		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.050859741331777515 | validation: 0.050211028077916726]
	TIME [epoch: 6.49 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04983202565261707		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.04983202565261707 | validation: 0.053292105502507105]
	TIME [epoch: 6.49 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04721283314816349		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.04721283314816349 | validation: 0.05436365874692818]
	TIME [epoch: 6.48 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04696789495340291		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.04696789495340291 | validation: 0.056524176221932065]
	TIME [epoch: 6.48 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050993719675001534		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.050993719675001534 | validation: 0.05724117342603575]
	TIME [epoch: 6.47 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05075178745478235		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.05075178745478235 | validation: 0.04870795120626126]
	TIME [epoch: 6.48 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05201023297214291		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.05201023297214291 | validation: 0.048831820163009625]
	TIME [epoch: 6.48 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0508484645407515		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.0508484645407515 | validation: 0.04770450716615154]
	TIME [epoch: 6.48 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04770522573815757		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.04770522573815757 | validation: 0.046858945447413]
	TIME [epoch: 6.51 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05035229386564937		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.05035229386564937 | validation: 0.04635184960806367]
	TIME [epoch: 6.48 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048105115495487516		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.048105115495487516 | validation: 0.055905959892266884]
	TIME [epoch: 6.48 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04998379708750482		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.04998379708750482 | validation: 0.045896670999447185]
	TIME [epoch: 6.48 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04665728654269137		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.04665728654269137 | validation: 0.041965426013682444]
	TIME [epoch: 6.47 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04924821721601502		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.04924821721601502 | validation: 0.060443553159792364]
	TIME [epoch: 6.48 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048993283518561186		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.048993283518561186 | validation: 0.058993795675059996]
	TIME [epoch: 6.48 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549666717022167		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.04549666717022167 | validation: 0.04471380650392589]
	TIME [epoch: 6.51 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048532812921015786		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.048532812921015786 | validation: 0.048472323389405825]
	TIME [epoch: 6.48 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04618286577024721		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.04618286577024721 | validation: 0.04929363264403225]
	TIME [epoch: 6.48 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04902193720885867		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.04902193720885867 | validation: 0.04747367399508029]
	TIME [epoch: 6.48 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04902213367650679		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.04902213367650679 | validation: 0.05626379392339195]
	TIME [epoch: 6.48 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04712146472903847		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.04712146472903847 | validation: 0.05253932381108602]
	TIME [epoch: 6.48 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05182582234056595		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.05182582234056595 | validation: 0.04750162498027789]
	TIME [epoch: 6.48 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05136213475291487		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.05136213475291487 | validation: 0.04285596981645523]
	TIME [epoch: 6.51 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04617873706431857		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.04617873706431857 | validation: 0.050276717049386035]
	TIME [epoch: 6.48 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04812067156365023		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.04812067156365023 | validation: 0.04858213255320521]
	TIME [epoch: 6.47 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05190853643584993		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.05190853643584993 | validation: 0.05398061541476119]
	TIME [epoch: 6.47 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04906845425043578		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.04906845425043578 | validation: 0.0496722710187506]
	TIME [epoch: 6.48 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05119391532274351		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.05119391532274351 | validation: 0.053457720278492216]
	TIME [epoch: 6.47 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04555190230593843		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.04555190230593843 | validation: 0.04903478099635929]
	TIME [epoch: 6.47 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04483623080827663		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.04483623080827663 | validation: 0.055899869191626074]
	TIME [epoch: 6.51 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04568710828634975		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.04568710828634975 | validation: 0.051198660150537235]
	TIME [epoch: 6.48 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04824264428147536		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.04824264428147536 | validation: 0.043599103619748884]
	TIME [epoch: 6.48 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04529860054594506		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.04529860054594506 | validation: 0.05891902882704735]
	TIME [epoch: 6.48 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04765914213537034		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.04765914213537034 | validation: 0.04629877458519488]
	TIME [epoch: 6.47 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04705623369549135		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.04705623369549135 | validation: 0.04720187748661058]
	TIME [epoch: 6.48 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049485506341613146		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.049485506341613146 | validation: 0.04680441066225066]
	TIME [epoch: 6.48 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050295303192977925		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.050295303192977925 | validation: 0.0523132150597149]
	TIME [epoch: 6.51 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045661919437014066		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.045661919437014066 | validation: 0.04988283038552147]
	TIME [epoch: 6.48 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04666206319650812		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.04666206319650812 | validation: 0.0525879433433207]
	TIME [epoch: 6.48 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04761936951523421		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.04761936951523421 | validation: 0.05313766417740848]
	TIME [epoch: 6.47 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043583593866908174		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.043583593866908174 | validation: 0.04741628858543863]
	TIME [epoch: 6.47 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043956871409894654		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.043956871409894654 | validation: 0.04574382526678173]
	TIME [epoch: 6.48 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04914157607799891		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.04914157607799891 | validation: 0.06578815813504738]
	TIME [epoch: 6.48 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046497500635796774		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.046497500635796774 | validation: 0.05462524661762365]
	TIME [epoch: 6.5 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048992778033709855		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.048992778033709855 | validation: 0.04659851565999383]
	TIME [epoch: 6.48 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046160148253495244		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.046160148253495244 | validation: 0.05434596756569607]
	TIME [epoch: 6.47 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05122353574245289		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.05122353574245289 | validation: 0.058350964335353084]
	TIME [epoch: 6.47 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05040299610942714		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.05040299610942714 | validation: 0.051797670165832005]
	TIME [epoch: 6.48 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05207088989574653		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.05207088989574653 | validation: 0.0522957785183098]
	TIME [epoch: 6.48 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04598429439337294		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.04598429439337294 | validation: 0.0571016742403852]
	TIME [epoch: 6.48 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04662999341304529		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.04662999341304529 | validation: 0.05834779288671582]
	TIME [epoch: 6.51 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05045976480960133		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.05045976480960133 | validation: 0.0543528627999698]
	TIME [epoch: 6.48 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054357322066445585		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.054357322066445585 | validation: 0.061476300567419456]
	TIME [epoch: 6.48 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05061428788228456		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.05061428788228456 | validation: 0.05895437140243634]
	TIME [epoch: 6.47 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05231067943029241		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.05231067943029241 | validation: 0.04477720866795167]
	TIME [epoch: 6.47 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051287395576439666		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.051287395576439666 | validation: 0.047675810297322666]
	TIME [epoch: 6.47 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04826506648149869		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.04826506648149869 | validation: 0.05024536001225639]
	TIME [epoch: 6.47 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047368856814435374		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.047368856814435374 | validation: 0.05679233017165688]
	TIME [epoch: 6.49 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04600484106896143		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.04600484106896143 | validation: 0.05575947317676963]
	TIME [epoch: 6.49 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04686031295918967		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.04686031295918967 | validation: 0.06331580079944836]
	TIME [epoch: 6.48 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04749773098206388		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.04749773098206388 | validation: 0.05287159759246993]
	TIME [epoch: 6.47 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048131126269893076		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.048131126269893076 | validation: 0.05730108777114226]
	TIME [epoch: 6.47 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05256418626005059		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.05256418626005059 | validation: 0.043000160304437415]
	TIME [epoch: 6.48 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048057143580165676		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.048057143580165676 | validation: 0.04732552095683374]
	TIME [epoch: 6.48 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052981406442345134		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.052981406442345134 | validation: 0.053659623023394824]
	TIME [epoch: 6.49 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05049682644413325		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.05049682644413325 | validation: 0.05060899477422765]
	TIME [epoch: 6.5 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046790465675374426		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.046790465675374426 | validation: 0.05471606378831134]
	TIME [epoch: 6.48 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043970532062938605		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.043970532062938605 | validation: 0.050038948304317314]
	TIME [epoch: 6.48 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04732752279737398		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.04732752279737398 | validation: 0.047165795727606805]
	TIME [epoch: 6.48 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044858499118425085		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.044858499118425085 | validation: 0.049040477352814076]
	TIME [epoch: 6.48 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04464214726713549		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.04464214726713549 | validation: 0.05650781121782814]
	TIME [epoch: 6.48 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467326911284114		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.04467326911284114 | validation: 0.053011008744922664]
	TIME [epoch: 6.49 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047433912134443784		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.047433912134443784 | validation: 0.04852270397361774]
	TIME [epoch: 6.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04698595446434148		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.04698595446434148 | validation: 0.0585328734754196]
	TIME [epoch: 6.47 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05185748334294436		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.05185748334294436 | validation: 0.051997324369759367]
	TIME [epoch: 6.48 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045769421588532144		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.045769421588532144 | validation: 0.05787776371161277]
	TIME [epoch: 6.47 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04372387005154701		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.04372387005154701 | validation: 0.0531056587809531]
	TIME [epoch: 6.48 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042653009492969504		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.042653009492969504 | validation: 0.05585812516042946]
	TIME [epoch: 6.47 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04317990809699175		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.04317990809699175 | validation: 0.0493928958765742]
	TIME [epoch: 6.48 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046119025782331693		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.046119025782331693 | validation: 0.059288179572809394]
	TIME [epoch: 6.51 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043390347697526074		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.043390347697526074 | validation: 0.0653490402523005]
	TIME [epoch: 6.48 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048272671944567136		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.048272671944567136 | validation: 0.06491490326585662]
	TIME [epoch: 6.48 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04415150106814125		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.04415150106814125 | validation: 0.05926780387186582]
	TIME [epoch: 6.48 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048554460893969115		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.048554460893969115 | validation: 0.05911634003359182]
	TIME [epoch: 6.48 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046819786958458426		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.046819786958458426 | validation: 0.04736153904646234]
	TIME [epoch: 6.47 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045820102352842285		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.045820102352842285 | validation: 0.04605978012839517]
	TIME [epoch: 6.48 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04656280377679296		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.04656280377679296 | validation: 0.05108424889516728]
	TIME [epoch: 6.51 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049290356038960995		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.049290356038960995 | validation: 0.06175249002010446]
	TIME [epoch: 6.48 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04540031704546568		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.04540031704546568 | validation: 0.05026594668079334]
	TIME [epoch: 6.48 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04262056703127846		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.04262056703127846 | validation: 0.053787741622912194]
	TIME [epoch: 6.48 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04228710000591938		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.04228710000591938 | validation: 0.06064518370460329]
	TIME [epoch: 6.48 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045059189933262814		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.045059189933262814 | validation: 0.046939390655627716]
	TIME [epoch: 6.47 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04411696865510824		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.04411696865510824 | validation: 0.051671212503175974]
	TIME [epoch: 6.48 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044531681669966725		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.044531681669966725 | validation: 0.06175853282819833]
	TIME [epoch: 6.51 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0480513548673077		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.0480513548673077 | validation: 0.05640216621921624]
	TIME [epoch: 6.48 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04341012136586299		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.04341012136586299 | validation: 0.05764495622862494]
	TIME [epoch: 6.47 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04507182645008642		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.04507182645008642 | validation: 0.05322743459301377]
	TIME [epoch: 6.48 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047843861987766495		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.047843861987766495 | validation: 0.050606579682406824]
	TIME [epoch: 6.48 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05051720460050787		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.05051720460050787 | validation: 0.05237816204845343]
	TIME [epoch: 6.48 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04536607756876503		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.04536607756876503 | validation: 0.05516765993635565]
	TIME [epoch: 6.47 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04667950781490402		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.04667950781490402 | validation: 0.05034877672986463]
	TIME [epoch: 6.51 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0491330669411237		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.0491330669411237 | validation: 0.05861539285480314]
	TIME [epoch: 6.48 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0490999052988832		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.0490999052988832 | validation: 0.05720674997385016]
	TIME [epoch: 6.48 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04648318169416028		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.04648318169416028 | validation: 0.06222447924410931]
	TIME [epoch: 6.48 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0465113161420066		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.0465113161420066 | validation: 0.05290595249512306]
	TIME [epoch: 6.48 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045317987523218486		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.045317987523218486 | validation: 0.04761492305895262]
	TIME [epoch: 6.48 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045373567279170635		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.045373567279170635 | validation: 0.04190732296629704]
	TIME [epoch: 6.48 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04961719087367821		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.04961719087367821 | validation: 0.0471482209025629]
	TIME [epoch: 6.51 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04767712918824271		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.04767712918824271 | validation: 0.05294608601202931]
	TIME [epoch: 6.48 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04772267342619983		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.04772267342619983 | validation: 0.05102567507977967]
	TIME [epoch: 6.48 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05188568807952451		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.05188568807952451 | validation: 0.05985553439898146]
	TIME [epoch: 6.48 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04726495891174108		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.04726495891174108 | validation: 0.04412930162903828]
	TIME [epoch: 6.48 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044386709686485254		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.044386709686485254 | validation: 0.045508364740667585]
	TIME [epoch: 6.48 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03982296334605393		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.03982296334605393 | validation: 0.0543327956877571]
	TIME [epoch: 6.48 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0449505496169995		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.0449505496169995 | validation: 0.052572608217889456]
	TIME [epoch: 6.51 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046122400494909045		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.046122400494909045 | validation: 0.049657227265600436]
	TIME [epoch: 6.48 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051079008700335715		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.051079008700335715 | validation: 0.055464472622121515]
	TIME [epoch: 6.48 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046939619309303585		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.046939619309303585 | validation: 0.04839521055887288]
	TIME [epoch: 6.48 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054708228783331564		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.054708228783331564 | validation: 0.05748738988472188]
	TIME [epoch: 6.48 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04817029493210247		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.04817029493210247 | validation: 0.05074129198900566]
	TIME [epoch: 6.48 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0494461214932606		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.0494461214932606 | validation: 0.049709185320939646]
	TIME [epoch: 6.48 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04794595644784839		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.04794595644784839 | validation: 0.03877365342850299]
	TIME [epoch: 6.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_1645.pth
	Model improved!!!
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047646509952333285		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.047646509952333285 | validation: 0.050933368639121304]
	TIME [epoch: 6.48 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04702101752866455		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.04702101752866455 | validation: 0.057313060975719136]
	TIME [epoch: 6.48 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04588845455937807		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.04588845455937807 | validation: 0.05612921425628215]
	TIME [epoch: 6.48 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04434561322395455		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.04434561322395455 | validation: 0.04636785546765423]
	TIME [epoch: 6.48 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04660695014513609		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.04660695014513609 | validation: 0.052120943916321494]
	TIME [epoch: 6.48 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04670048139133874		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.04670048139133874 | validation: 0.05403044021470405]
	TIME [epoch: 6.48 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0437158536224747		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.0437158536224747 | validation: 0.05162235637075538]
	TIME [epoch: 6.51 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0465165044379645		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.0465165044379645 | validation: 0.04499065716530252]
	TIME [epoch: 6.48 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0488131824337389		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.0488131824337389 | validation: 0.048892000899351]
	TIME [epoch: 6.48 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04557086845887737		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.04557086845887737 | validation: 0.047168859191130855]
	TIME [epoch: 6.48 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047597680784083725		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.047597680784083725 | validation: 0.05040807759348234]
	TIME [epoch: 6.48 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042945387499965675		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.042945387499965675 | validation: 0.054985403196978845]
	TIME [epoch: 6.48 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04242236577536565		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.04242236577536565 | validation: 0.046292157065280816]
	TIME [epoch: 6.48 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0419253164340621		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.0419253164340621 | validation: 0.06161337053804124]
	TIME [epoch: 6.49 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04582849624968158		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.04582849624968158 | validation: 0.062392043682628774]
	TIME [epoch: 6.49 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046915386532687425		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.046915386532687425 | validation: 0.0559165109460989]
	TIME [epoch: 6.48 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04591756059338977		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.04591756059338977 | validation: 0.05550554936534047]
	TIME [epoch: 6.48 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05049871104243905		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.05049871104243905 | validation: 0.05761504394357861]
	TIME [epoch: 6.48 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04738116462443491		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.04738116462443491 | validation: 0.046145098198053874]
	TIME [epoch: 6.48 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046997140006023196		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.046997140006023196 | validation: 0.05337409000311853]
	TIME [epoch: 6.47 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04508479673245881		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.04508479673245881 | validation: 0.0547085097831078]
	TIME [epoch: 6.49 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044409254439534		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.044409254439534 | validation: 0.05453055594398664]
	TIME [epoch: 6.49 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04608787479298927		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.04608787479298927 | validation: 0.06184536977278453]
	TIME [epoch: 6.48 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044550410069338166		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.044550410069338166 | validation: 0.05883150840820256]
	TIME [epoch: 6.48 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042871977202477284		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.042871977202477284 | validation: 0.06434158497483107]
	TIME [epoch: 6.48 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04497069017577344		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.04497069017577344 | validation: 0.05115163062992677]
	TIME [epoch: 6.48 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04734560802035349		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.04734560802035349 | validation: 0.04244029410063794]
	TIME [epoch: 6.48 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04620227762341537		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.04620227762341537 | validation: 0.04780225459942188]
	TIME [epoch: 6.49 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04542487628837935		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.04542487628837935 | validation: 0.05046814761195584]
	TIME [epoch: 6.5 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047732939180874574		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.047732939180874574 | validation: 0.0520243662120115]
	TIME [epoch: 6.48 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04734527321288805		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.04734527321288805 | validation: 0.05320762133860767]
	TIME [epoch: 6.48 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045907617844495784		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.045907617844495784 | validation: 0.05849308753346881]
	TIME [epoch: 6.48 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04631444851138736		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.04631444851138736 | validation: 0.055358181294161944]
	TIME [epoch: 6.48 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04799633591932559		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.04799633591932559 | validation: 0.04944154391802867]
	TIME [epoch: 6.48 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04291332661526542		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.04291332661526542 | validation: 0.045618644447518196]
	TIME [epoch: 6.48 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044108863185397765		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.044108863185397765 | validation: 0.04910267033680029]
	TIME [epoch: 6.51 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04530295671030891		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.04530295671030891 | validation: 0.051567215998223156]
	TIME [epoch: 6.47 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050613728510753284		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.050613728510753284 | validation: 0.05547063997648989]
	TIME [epoch: 6.48 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04967188329993624		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.04967188329993624 | validation: 0.06153651234497699]
	TIME [epoch: 6.47 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04662392854598878		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.04662392854598878 | validation: 0.04936057737101607]
	TIME [epoch: 6.48 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04288938553610976		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.04288938553610976 | validation: 0.0535847899715241]
	TIME [epoch: 6.48 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04624937101248467		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.04624937101248467 | validation: 0.04637000018738736]
	TIME [epoch: 6.47 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04991242226445992		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.04991242226445992 | validation: 0.054856901071998386]
	TIME [epoch: 6.51 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04572044674582125		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.04572044674582125 | validation: 0.051203875024038385]
	TIME [epoch: 6.48 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04481047788909392		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.04481047788909392 | validation: 0.04951120698742026]
	TIME [epoch: 6.48 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04768884717314902		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.04768884717314902 | validation: 0.05599156472237971]
	TIME [epoch: 6.47 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0505563877445769		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.0505563877445769 | validation: 0.05094222219801592]
	TIME [epoch: 6.48 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045842430618467364		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.045842430618467364 | validation: 0.054354377756554016]
	TIME [epoch: 6.48 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04852124404465809		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.04852124404465809 | validation: 0.052649339385064414]
	TIME [epoch: 6.48 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04371878991266945		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.04371878991266945 | validation: 0.05563184376496661]
	TIME [epoch: 6.51 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04431795355570216		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.04431795355570216 | validation: 0.055268089502970776]
	TIME [epoch: 6.48 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04719694376693213		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.04719694376693213 | validation: 0.054918618452173266]
	TIME [epoch: 6.47 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04331563438069637		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.04331563438069637 | validation: 0.05388895755153492]
	TIME [epoch: 6.48 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04590840335956408		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.04590840335956408 | validation: 0.04978877170937212]
	TIME [epoch: 6.48 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04852869648308495		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.04852869648308495 | validation: 0.0546674128929634]
	TIME [epoch: 6.48 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04794445593876728		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.04794445593876728 | validation: 0.05336228108019914]
	TIME [epoch: 6.47 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0504637134287839		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.0504637134287839 | validation: 0.061688279668250426]
	TIME [epoch: 6.51 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04682677542388991		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.04682677542388991 | validation: 0.05613271259181613]
	TIME [epoch: 6.48 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04702776191127599		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.04702776191127599 | validation: 0.051973131417340036]
	TIME [epoch: 6.48 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04786399878164396		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.04786399878164396 | validation: 0.051164802085841544]
	TIME [epoch: 6.48 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04778060023892421		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.04778060023892421 | validation: 0.053429175397156414]
	TIME [epoch: 6.47 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051067705779410826		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.051067705779410826 | validation: 0.05042822240870506]
	TIME [epoch: 6.47 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04929518503041822		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.04929518503041822 | validation: 0.04913811627223922]
	TIME [epoch: 6.47 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045622404381429435		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.045622404381429435 | validation: 0.04991318931102712]
	TIME [epoch: 6.51 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044764705524034276		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.044764705524034276 | validation: 0.05419068585820083]
	TIME [epoch: 6.48 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04618684837473369		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.04618684837473369 | validation: 0.061414824910306316]
	TIME [epoch: 6.48 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046960047156129336		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.046960047156129336 | validation: 0.04875010311518937]
	TIME [epoch: 6.48 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04743447050415142		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.04743447050415142 | validation: 0.05079554770688027]
	TIME [epoch: 6.48 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04740253677413421		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.04740253677413421 | validation: 0.04423539635276689]
	TIME [epoch: 6.48 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045548573801623186		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.045548573801623186 | validation: 0.047378211439063254]
	TIME [epoch: 6.47 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044461771305411665		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.044461771305411665 | validation: 0.050773516766871904]
	TIME [epoch: 6.51 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04807346568397068		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.04807346568397068 | validation: 0.051640692763732385]
	TIME [epoch: 6.48 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04486563601358122		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.04486563601358122 | validation: 0.047597302158983966]
	TIME [epoch: 6.48 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04535414222948948		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.04535414222948948 | validation: 0.05057828351172163]
	TIME [epoch: 6.47 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04696649898910914		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.04696649898910914 | validation: 0.044362460543394724]
	TIME [epoch: 6.48 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047232155492319926		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.047232155492319926 | validation: 0.04738875624863287]
	TIME [epoch: 6.48 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04805306004090892		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.04805306004090892 | validation: 0.05694490955691281]
	TIME [epoch: 6.47 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04897668482135269		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.04897668482135269 | validation: 0.05345301443108463]
	TIME [epoch: 6.51 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0486105718938829		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.0486105718938829 | validation: 0.04767280670131341]
	TIME [epoch: 6.48 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04399800221205903		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.04399800221205903 | validation: 0.04237285316164174]
	TIME [epoch: 6.47 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04017298025525145		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.04017298025525145 | validation: 0.045382361749332745]
	TIME [epoch: 6.48 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04588246497549189		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.04588246497549189 | validation: 0.04325066522137318]
	TIME [epoch: 6.47 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04271920402573		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.04271920402573 | validation: 0.05790513473403152]
	TIME [epoch: 6.47 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04573887883916725		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.04573887883916725 | validation: 0.04010988238243492]
	TIME [epoch: 6.48 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04455827476288125		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.04455827476288125 | validation: 0.042718829949943124]
	TIME [epoch: 6.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0463366595076603		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.0463366595076603 | validation: 0.04965937060089809]
	TIME [epoch: 6.48 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049435133671877074		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.049435133671877074 | validation: 0.05041654061081935]
	TIME [epoch: 6.48 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04338271979918154		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.04338271979918154 | validation: 0.0466015021364068]
	TIME [epoch: 6.47 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045265066102238405		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.045265066102238405 | validation: 0.05719319582731519]
	TIME [epoch: 6.47 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044219447434259096		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.044219447434259096 | validation: 0.04605535643068942]
	TIME [epoch: 6.47 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04585356649963421		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.04585356649963421 | validation: 0.049210113753097605]
	TIME [epoch: 6.48 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043858442324069165		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.043858442324069165 | validation: 0.04307608585829738]
	TIME [epoch: 6.49 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04403710564279461		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.04403710564279461 | validation: 0.04291867950041398]
	TIME [epoch: 6.49 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04718056643612341		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.04718056643612341 | validation: 0.04955420933632864]
	TIME [epoch: 6.48 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04789799473573536		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.04789799473573536 | validation: 0.05118459480328657]
	TIME [epoch: 6.47 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045764004287064314		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.045764004287064314 | validation: 0.052418473962731874]
	TIME [epoch: 6.48 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046184831887876705		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.046184831887876705 | validation: 0.055951120489473184]
	TIME [epoch: 6.48 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04235499163624297		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.04235499163624297 | validation: 0.05215519655664455]
	TIME [epoch: 6.48 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04784281480649132		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.04784281480649132 | validation: 0.051144364471871276]
	TIME [epoch: 6.49 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05244278511761369		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.05244278511761369 | validation: 0.047355501018583955]
	TIME [epoch: 6.5 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04552713442929399		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.04552713442929399 | validation: 0.04902144072165406]
	TIME [epoch: 6.48 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048011734811450504		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.048011734811450504 | validation: 0.0485159027423053]
	TIME [epoch: 6.47 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04982772856761753		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.04982772856761753 | validation: 0.06160348997958172]
	TIME [epoch: 6.48 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04817370029715686		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.04817370029715686 | validation: 0.059060360771579855]
	TIME [epoch: 6.47 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05173378855298103		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.05173378855298103 | validation: 0.061781958747534345]
	TIME [epoch: 6.48 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04701437020032778		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.04701437020032778 | validation: 0.05298903114925281]
	TIME [epoch: 6.49 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054180526797035895		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.054180526797035895 | validation: 0.06671362387567258]
	TIME [epoch: 6.5 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048055735566902937		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.048055735566902937 | validation: 0.05544089000103566]
	TIME [epoch: 6.48 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05015282916993276		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.05015282916993276 | validation: 0.04896138827070869]
	TIME [epoch: 6.48 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04765964186839773		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.04765964186839773 | validation: 0.05965480406734612]
	TIME [epoch: 6.47 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04557485486031074		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.04557485486031074 | validation: 0.0470082291302403]
	TIME [epoch: 6.48 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549093382135152		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.04549093382135152 | validation: 0.06408736334391969]
	TIME [epoch: 6.47 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04540635030812692		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.04540635030812692 | validation: 0.05153015375381036]
	TIME [epoch: 6.48 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04520698257602769		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.04520698257602769 | validation: 0.055340149730939495]
	TIME [epoch: 6.51 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045612334307968114		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.045612334307968114 | validation: 0.04954965404324249]
	TIME [epoch: 6.48 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050068104803098805		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.050068104803098805 | validation: 0.046082930580728355]
	TIME [epoch: 6.48 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04734567894107172		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.04734567894107172 | validation: 0.04938634309482065]
	TIME [epoch: 6.47 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05078624430047152		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.05078624430047152 | validation: 0.05779174225367055]
	TIME [epoch: 6.48 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05036392698601893		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.05036392698601893 | validation: 0.04895527468381628]
	TIME [epoch: 6.48 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045350456072236006		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.045350456072236006 | validation: 0.05179748558303064]
	TIME [epoch: 6.47 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04514761049604511		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.04514761049604511 | validation: 0.04562210474077575]
	TIME [epoch: 6.51 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05122303852899493		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.05122303852899493 | validation: 0.057694240765551845]
	TIME [epoch: 6.48 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04898000794900178		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.04898000794900178 | validation: 0.05203821749835779]
	TIME [epoch: 6.47 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04044712143371667		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.04044712143371667 | validation: 0.05105552039769146]
	TIME [epoch: 6.48 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04091749450256587		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.04091749450256587 | validation: 0.055407602740533884]
	TIME [epoch: 6.47 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04434471046183306		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.04434471046183306 | validation: 0.04173099382147957]
	TIME [epoch: 6.48 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04595257758813283		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.04595257758813283 | validation: 0.05396828634350485]
	TIME [epoch: 6.47 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0433683675554886		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.0433683675554886 | validation: 0.06107489287698438]
	TIME [epoch: 6.51 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04360222038430549		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.04360222038430549 | validation: 0.05054501792267287]
	TIME [epoch: 6.48 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04449944871016338		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.04449944871016338 | validation: 0.04189254004794091]
	TIME [epoch: 6.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04566590390307198		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.04566590390307198 | validation: 0.03990351415729572]
	TIME [epoch: 6.48 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044572737470622445		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.044572737470622445 | validation: 0.049884687457571845]
	TIME [epoch: 6.47 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04620832730973833		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.04620832730973833 | validation: 0.04889568748190524]
	TIME [epoch: 6.48 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04239562891594004		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.04239562891594004 | validation: 0.04900415467965241]
	TIME [epoch: 6.48 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04383386834256699		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.04383386834256699 | validation: 0.040265877093873706]
	TIME [epoch: 6.51 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04529412173022941		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.04529412173022941 | validation: 0.050945618187203494]
	TIME [epoch: 6.48 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044980025520225654		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.044980025520225654 | validation: 0.049910308605459947]
	TIME [epoch: 6.48 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467920598857959		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.04467920598857959 | validation: 0.04944077902839867]
	TIME [epoch: 6.48 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043718580612877984		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.043718580612877984 | validation: 0.04829731704389447]
	TIME [epoch: 6.48 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04552346915498042		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.04552346915498042 | validation: 0.055270272326579994]
	TIME [epoch: 6.47 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047197198760459066		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.047197198760459066 | validation: 0.04345600988476472]
	TIME [epoch: 6.48 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042483843564784636		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.042483843564784636 | validation: 0.04611166216809341]
	TIME [epoch: 6.51 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04337025500285091		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.04337025500285091 | validation: 0.04663175914012968]
	TIME [epoch: 6.48 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04596236635800837		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.04596236635800837 | validation: 0.052245057041295145]
	TIME [epoch: 6.48 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045270171919675375		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.045270171919675375 | validation: 0.051822867191749264]
	TIME [epoch: 6.48 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04631026292892032		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.04631026292892032 | validation: 0.049831183781634696]
	TIME [epoch: 6.48 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04422518842301911		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.04422518842301911 | validation: 0.050913589711125855]
	TIME [epoch: 6.48 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04190072262482187		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.04190072262482187 | validation: 0.04800715069063717]
	TIME [epoch: 6.47 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044824568856315784		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.044824568856315784 | validation: 0.04833022653765465]
	TIME [epoch: 6.51 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04138872620982556		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.04138872620982556 | validation: 0.053908037318892044]
	TIME [epoch: 6.48 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042618996485227906		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.042618996485227906 | validation: 0.05007971580435578]
	TIME [epoch: 6.47 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04507575008625893		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.04507575008625893 | validation: 0.04429465781920717]
	TIME [epoch: 6.48 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04229729580701658		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.04229729580701658 | validation: 0.04905407297145532]
	TIME [epoch: 6.48 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0412149427850699		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.0412149427850699 | validation: 0.047004039360067154]
	TIME [epoch: 6.47 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046409166181895264		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.046409166181895264 | validation: 0.05357519967793593]
	TIME [epoch: 6.48 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04622228575622293		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.04622228575622293 | validation: 0.0560066359988951]
	TIME [epoch: 6.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04531001154736712		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.04531001154736712 | validation: 0.057541022165227586]
	TIME [epoch: 6.48 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04192524518521172		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.04192524518521172 | validation: 0.04665999724833251]
	TIME [epoch: 6.47 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040614274214745935		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.040614274214745935 | validation: 0.04691141456716971]
	TIME [epoch: 6.48 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04755261593618916		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.04755261593618916 | validation: 0.05008614800960107]
	TIME [epoch: 6.48 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04554743108046873		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.04554743108046873 | validation: 0.05984768391880303]
	TIME [epoch: 6.47 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044884576990838976		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.044884576990838976 | validation: 0.05031812455271689]
	TIME [epoch: 6.47 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04417831474730936		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.04417831474730936 | validation: 0.05591588681353708]
	TIME [epoch: 6.49 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04736659071224682		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.04736659071224682 | validation: 0.06277490791977051]
	TIME [epoch: 6.49 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04483536561293039		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.04483536561293039 | validation: 0.05614406661958538]
	TIME [epoch: 6.48 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04356330160093521		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.04356330160093521 | validation: 0.05414755382357298]
	TIME [epoch: 6.47 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04623419454294192		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.04623419454294192 | validation: 0.05341002577539201]
	TIME [epoch: 6.48 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04807724711514573		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.04807724711514573 | validation: 0.05738164572738692]
	TIME [epoch: 6.47 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04396640891510866		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.04396640891510866 | validation: 0.05233333514521807]
	TIME [epoch: 6.48 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044683900397564064		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.044683900397564064 | validation: 0.04978334950721543]
	TIME [epoch: 6.49 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04262689508643655		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.04262689508643655 | validation: 0.05300837681043671]
	TIME [epoch: 6.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047248011475344354		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.047248011475344354 | validation: 0.05709400337463298]
	TIME [epoch: 6.48 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04520205415954866		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.04520205415954866 | validation: 0.05182182955548026]
	TIME [epoch: 6.48 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04509231412995074		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.04509231412995074 | validation: 0.056337111374344565]
	TIME [epoch: 6.47 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0412220989037617		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.0412220989037617 | validation: 0.058236437198608326]
	TIME [epoch: 6.48 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044809630933489705		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.044809630933489705 | validation: 0.05648929450696277]
	TIME [epoch: 6.47 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045841388536971		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.045841388536971 | validation: 0.04902129623373565]
	TIME [epoch: 6.49 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04538652200333333		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.04538652200333333 | validation: 0.053094006948168494]
	TIME [epoch: 6.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04304870193795304		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.04304870193795304 | validation: 0.0481852350263452]
	TIME [epoch: 6.48 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04528957020794723		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.04528957020794723 | validation: 0.05035763420647106]
	TIME [epoch: 6.48 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04616699289534869		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.04616699289534869 | validation: 0.05629101000379553]
	TIME [epoch: 6.48 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04674626495227112		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.04674626495227112 | validation: 0.05154244395410475]
	TIME [epoch: 6.47 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04671476736369307		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.04671476736369307 | validation: 0.044587510942248845]
	TIME [epoch: 6.48 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042934881507109564		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.042934881507109564 | validation: 0.05012722160970015]
	TIME [epoch: 6.48 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041798427497313044		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.041798427497313044 | validation: 0.04408915107046238]
	TIME [epoch: 6.5 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04246984628781199		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.04246984628781199 | validation: 0.047988700296744416]
	TIME [epoch: 6.48 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04085223844192663		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.04085223844192663 | validation: 0.04608192866489866]
	TIME [epoch: 6.48 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04179294922871718		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.04179294922871718 | validation: 0.05339581438447201]
	TIME [epoch: 6.47 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044979710545087814		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.044979710545087814 | validation: 0.054243819394712185]
	TIME [epoch: 6.47 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046914754009385995		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.046914754009385995 | validation: 0.05039879211183029]
	TIME [epoch: 6.48 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043920103799884036		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.043920103799884036 | validation: 0.046973516657237355]
	TIME [epoch: 6.48 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04448062314713693		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.04448062314713693 | validation: 0.03662619514079288]
	TIME [epoch: 6.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240309_135700/states/model_tr_study1_1837.pth
	Model improved!!!
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046721423654236774		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.046721423654236774 | validation: 0.04532471671217123]
	TIME [epoch: 6.48 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04065370448267941		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.04065370448267941 | validation: 0.05784655746173643]
	TIME [epoch: 6.47 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042201044109912704		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.042201044109912704 | validation: 0.04940953598337547]
	TIME [epoch: 6.47 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046303875751596724		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.046303875751596724 | validation: 0.052149844350918954]
	TIME [epoch: 6.48 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040715719837648524		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.040715719837648524 | validation: 0.05565655280792604]
	TIME [epoch: 6.48 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04696445311700219		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.04696445311700219 | validation: 0.04807059990994385]
	TIME [epoch: 6.48 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046709335747095786		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.046709335747095786 | validation: 0.0527560455005505]
	TIME [epoch: 6.51 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047684040416310455		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.047684040416310455 | validation: 0.05811473405742884]
	TIME [epoch: 6.48 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0467659049833575		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.0467659049833575 | validation: 0.053235607798333744]
	TIME [epoch: 6.47 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04775911197217999		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.04775911197217999 | validation: 0.05572697807406284]
	TIME [epoch: 6.48 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046946002728187386		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.046946002728187386 | validation: 0.04906195155060616]
	TIME [epoch: 6.48 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04666414778707559		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.04666414778707559 | validation: 0.04928920625912931]
	TIME [epoch: 6.48 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04584208872229733		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.04584208872229733 | validation: 0.04206029044855906]
	TIME [epoch: 6.48 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03583110397800006		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.03583110397800006 | validation: 0.049489516933365785]
	TIME [epoch: 6.51 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04808560232666778		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.04808560232666778 | validation: 0.04929424238152409]
	TIME [epoch: 6.48 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04482334264645254		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.04482334264645254 | validation: 0.05037625560901224]
	TIME [epoch: 6.48 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043310520241165405		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.043310520241165405 | validation: 0.051393598228367934]
	TIME [epoch: 6.48 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04536190210553395		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.04536190210553395 | validation: 0.04406170739024378]
	TIME [epoch: 6.48 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045956734412696154		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.045956734412696154 | validation: 0.05538220064582751]
	TIME [epoch: 6.48 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042046223318542846		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.042046223318542846 | validation: 0.04610900643750457]
	TIME [epoch: 6.47 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045311111068199246		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.045311111068199246 | validation: 0.05852536419757737]
	TIME [epoch: 6.51 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414891226496059		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.0414891226496059 | validation: 0.053802525464122244]
	TIME [epoch: 6.48 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04587761787300778		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.04587761787300778 | validation: 0.05954554734995654]
	TIME [epoch: 6.47 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04733652552517532		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.04733652552517532 | validation: 0.05656669322427765]
	TIME [epoch: 6.48 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04830283050306089		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.04830283050306089 | validation: 0.053875226688889395]
	TIME [epoch: 6.48 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04816213732973954		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.04816213732973954 | validation: 0.04885950669584064]
	TIME [epoch: 6.47 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04466939800290954		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.04466939800290954 | validation: 0.05909845464275193]
	TIME [epoch: 6.47 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045599529912131065		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.045599529912131065 | validation: 0.05669947496576878]
	TIME [epoch: 6.51 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04742301887088497		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.04742301887088497 | validation: 0.06459429321893534]
	TIME [epoch: 6.48 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046189793045136714		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.046189793045136714 | validation: 0.05263341619641471]
	TIME [epoch: 6.48 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045383648140701685		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.045383648140701685 | validation: 0.05252495268214245]
	TIME [epoch: 6.47 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04676658113854999		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.04676658113854999 | validation: 0.04494366858372466]
	TIME [epoch: 6.47 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045717374268185465		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.045717374268185465 | validation: 0.054212147063866956]
	TIME [epoch: 6.48 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04641478302772556		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.04641478302772556 | validation: 0.048407296319898596]
	TIME [epoch: 6.47 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04616979228101621		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.04616979228101621 | validation: 0.04530456221476811]
	TIME [epoch: 6.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04830471055285189		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.04830471055285189 | validation: 0.0477707781579941]
	TIME [epoch: 6.48 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04642818463036291		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.04642818463036291 | validation: 0.0587205300156489]
	TIME [epoch: 6.47 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045590806154721816		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.045590806154721816 | validation: 0.05518350267952874]
	TIME [epoch: 6.48 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043902600178439534		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.043902600178439534 | validation: 0.05871750291991167]
	TIME [epoch: 6.48 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045686532999218724		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.045686532999218724 | validation: 0.04153398542083751]
	TIME [epoch: 6.48 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04337841830657081		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.04337841830657081 | validation: 0.05363866650548475]
	TIME [epoch: 6.47 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04408133123532158		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.04408133123532158 | validation: 0.05164764421712285]
	TIME [epoch: 6.51 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04839587019877373		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.04839587019877373 | validation: 0.05103628398482035]
	TIME [epoch: 6.48 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042006417508612046		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.042006417508612046 | validation: 0.05716168715339148]
	TIME [epoch: 6.48 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04395209645878409		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.04395209645878409 | validation: 0.04582917760932031]
	TIME [epoch: 6.48 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043364425168274004		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.043364425168274004 | validation: 0.054588684969316716]
	TIME [epoch: 6.48 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0452339999232936		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.0452339999232936 | validation: 0.047191269630668206]
	TIME [epoch: 6.47 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04514510515058514		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.04514510515058514 | validation: 0.052403468807733534]
	TIME [epoch: 6.48 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04321555443767087		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.04321555443767087 | validation: 0.04754775549529689]
	TIME [epoch: 6.51 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045823460202173864		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.045823460202173864 | validation: 0.0541765453179754]
	TIME [epoch: 6.48 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04439279102903666		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.04439279102903666 | validation: 0.051281010152443955]
	TIME [epoch: 6.48 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04139711417892247		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.04139711417892247 | validation: 0.05346561059567442]
	TIME [epoch: 6.48 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04611717446794547		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.04611717446794547 | validation: 0.04824952771571111]
	TIME [epoch: 6.48 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046108666151027204		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.046108666151027204 | validation: 0.052519429420143655]
	TIME [epoch: 6.48 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04184304281999258		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.04184304281999258 | validation: 0.04927545834264157]
	TIME [epoch: 6.47 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04674735701355528		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.04674735701355528 | validation: 0.04200875312619974]
	TIME [epoch: 6.49 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042617681488750336		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.042617681488750336 | validation: 0.05067416082014996]
	TIME [epoch: 6.5 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04319063527672906		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.04319063527672906 | validation: 0.04916806870995268]
	TIME [epoch: 6.48 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04456558196333223		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.04456558196333223 | validation: 0.06049553519293498]
	TIME [epoch: 6.48 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040194011926142005		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.040194011926142005 | validation: 0.056631587764142836]
	TIME [epoch: 6.47 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04779395550471459		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.04779395550471459 | validation: 0.057756356112290186]
	TIME [epoch: 6.48 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044006750102742444		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.044006750102742444 | validation: 0.05782152595495503]
	TIME [epoch: 6.47 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04483925767874911		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.04483925767874911 | validation: 0.06325436204627774]
	TIME [epoch: 6.49 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04305993749028887		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.04305993749028887 | validation: 0.053233771342110894]
	TIME [epoch: 6.5 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04947872418789191		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.04947872418789191 | validation: 0.06066046991260555]
	TIME [epoch: 6.48 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04334303467145131		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.04334303467145131 | validation: 0.054053814071877614]
	TIME [epoch: 6.47 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04745630479495935		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.04745630479495935 | validation: 0.05766991074172835]
	TIME [epoch: 6.47 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04625848043851077		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.04625848043851077 | validation: 0.05475935758509725]
	TIME [epoch: 6.48 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0450286910535872		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.0450286910535872 | validation: 0.05317582008890579]
	TIME [epoch: 6.47 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04493175610324528		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.04493175610324528 | validation: 0.058900826354510716]
	TIME [epoch: 6.49 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044185688881370984		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.044185688881370984 | validation: 0.05515694797970366]
	TIME [epoch: 6.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04298774606554006		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.04298774606554006 | validation: 0.059740363710378164]
	TIME [epoch: 6.48 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046938864492657204		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.046938864492657204 | validation: 0.0441804370650169]
	TIME [epoch: 6.48 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04644942081775215		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.04644942081775215 | validation: 0.05675484242194499]
	TIME [epoch: 6.47 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044494348515960645		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.044494348515960645 | validation: 0.05944391761726914]
	TIME [epoch: 6.48 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04443917120136227		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.04443917120136227 | validation: 0.04407454578719485]
	TIME [epoch: 6.47 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04799094513017444		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.04799094513017444 | validation: 0.061515366993730176]
	TIME [epoch: 6.48 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045952041154047864		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.045952041154047864 | validation: 0.05391591488482051]
	TIME [epoch: 6.51 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04309841596569257		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.04309841596569257 | validation: 0.05068685752334234]
	TIME [epoch: 6.48 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04684178248978166		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.04684178248978166 | validation: 0.05758504308384037]
	TIME [epoch: 6.47 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04379449521816048		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.04379449521816048 | validation: 0.050270496455078584]
	TIME [epoch: 6.48 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04209827088284511		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.04209827088284511 | validation: 0.049352408236161924]
	TIME [epoch: 6.48 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042264136547107874		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.042264136547107874 | validation: 0.05812380844777721]
	TIME [epoch: 6.48 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04237305923655495		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.04237305923655495 | validation: 0.05856148681848183]
	TIME [epoch: 6.48 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045110977521433386		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.045110977521433386 | validation: 0.04919138546174257]
	TIME [epoch: 6.51 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05126195889550722		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.05126195889550722 | validation: 0.050803479369898936]
	TIME [epoch: 6.48 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04642000853384011		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.04642000853384011 | validation: 0.04392407192710466]
	TIME [epoch: 6.47 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04679692517644292		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.04679692517644292 | validation: 0.04753270060221542]
	TIME [epoch: 6.47 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04293976793800419		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.04293976793800419 | validation: 0.05330645560767053]
	TIME [epoch: 6.47 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042337567065767204		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.042337567065767204 | validation: 0.05459735173025109]
	TIME [epoch: 6.48 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045330373102743494		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.045330373102743494 | validation: 0.05625793837906107]
	TIME [epoch: 6.48 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04289522861237029		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.04289522861237029 | validation: 0.05411895318081978]
	TIME [epoch: 6.51 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04738648581399902		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.04738648581399902 | validation: 0.050819750026555435]
	TIME [epoch: 6.48 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04271288126752884		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.04271288126752884 | validation: 0.05083714974282067]
	TIME [epoch: 6.47 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04520627022778245		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.04520627022778245 | validation: 0.04662288655746545]
	TIME [epoch: 6.48 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04527785811089357		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.04527785811089357 | validation: 0.0470122549043284]
	TIME [epoch: 6.47 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04162828283635006		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.04162828283635006 | validation: 0.04698235769546475]
	TIME [epoch: 6.48 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04548751325284516		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.04548751325284516 | validation: 0.04996431473891653]
	TIME [epoch: 6.47 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04397408523659108		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.04397408523659108 | validation: 0.05503815481802786]
	TIME [epoch: 6.51 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041521710468083534		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.041521710468083534 | validation: 0.051690585906768796]
	TIME [epoch: 6.48 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044182046759425365		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.044182046759425365 | validation: 0.04843101218090353]
	TIME [epoch: 6.48 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04269577619261777		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.04269577619261777 | validation: 0.053192532153702475]
	TIME [epoch: 6.48 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043624122863270776		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.043624122863270776 | validation: 0.04905738601071505]
	TIME [epoch: 6.48 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04274639015516429		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.04274639015516429 | validation: 0.053135272025471476]
	TIME [epoch: 6.47 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045008368563150276		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.045008368563150276 | validation: 0.04848912372199598]
	TIME [epoch: 6.48 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04797318399930467		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.04797318399930467 | validation: 0.058408277786897535]
	TIME [epoch: 6.51 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04476612307499993		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.04476612307499993 | validation: 0.04418790213925585]
	TIME [epoch: 6.47 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038079704646317325		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.038079704646317325 | validation: 0.04116005700057416]
	TIME [epoch: 6.48 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04568013966941814		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.04568013966941814 | validation: 0.04341379198561849]
	TIME [epoch: 6.47 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04491838624325175		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.04491838624325175 | validation: 0.050992138011431286]
	TIME [epoch: 6.47 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04446479065177565		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.04446479065177565 | validation: 0.057778613321369944]
	TIME [epoch: 6.47 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04326761905635181		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.04326761905635181 | validation: 0.05003075718544024]
	TIME [epoch: 6.47 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047372081586681714		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.047372081586681714 | validation: 0.04977476970430332]
	TIME [epoch: 6.51 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047971508177103654		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.047971508177103654 | validation: 0.046666122715738716]
	TIME [epoch: 6.48 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045015823596790766		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.045015823596790766 | validation: 0.04709855812252478]
	TIME [epoch: 6.47 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043617671326955446		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.043617671326955446 | validation: 0.05477288465856374]
	TIME [epoch: 6.48 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046337645419422216		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.046337645419422216 | validation: 0.047462335794640396]
	TIME [epoch: 6.48 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044771052828721014		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.044771052828721014 | validation: 0.053637479562149246]
	TIME [epoch: 6.47 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04534514451129143		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.04534514451129143 | validation: 0.04596957603092427]
	TIME [epoch: 6.47 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043291600424259016		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.043291600424259016 | validation: 0.05304278657755178]
	TIME [epoch: 6.5 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04367301022580139		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.04367301022580139 | validation: 0.04937859345285684]
	TIME [epoch: 6.48 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046065236275327354		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.046065236275327354 | validation: 0.05572285971145994]
	TIME [epoch: 6.48 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04377272511769153		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.04377272511769153 | validation: 0.04894740253809287]
	TIME [epoch: 6.48 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04356814356390358		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.04356814356390358 | validation: 0.04862459417847303]
	TIME [epoch: 6.47 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04527522514771344		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.04527522514771344 | validation: 0.04635801376275765]
	TIME [epoch: 6.47 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04443144969103432		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.04443144969103432 | validation: 0.05297958721413156]
	TIME [epoch: 6.47 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04317781873485395		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.04317781873485395 | validation: 0.04774367059702126]
	TIME [epoch: 6.51 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04293955851482379		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.04293955851482379 | validation: 0.05653741634635659]
	TIME [epoch: 6.48 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044963004051932376		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.044963004051932376 | validation: 0.05289258165895466]
	TIME [epoch: 6.48 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04699559150429298		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.04699559150429298 | validation: 0.05632469022331641]
	TIME [epoch: 6.47 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042713253525884114		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.042713253525884114 | validation: 0.05422473199746793]
	TIME [epoch: 6.47 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04434663986041168		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.04434663986041168 | validation: 0.05002130996757223]
	TIME [epoch: 6.47 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04216812760532006		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.04216812760532006 | validation: 0.05375545837733645]
	TIME [epoch: 6.48 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043965642972713374		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.043965642972713374 | validation: 0.05049736622651649]
	TIME [epoch: 6.49 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04387114518257222		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.04387114518257222 | validation: 0.054984165069366875]
	TIME [epoch: 6.5 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04232006177158455		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.04232006177158455 | validation: 0.04695778696158666]
	TIME [epoch: 6.48 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049121311420867265		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.049121311420867265 | validation: 0.053088965589298626]
	TIME [epoch: 6.48 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042702417961019735		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.042702417961019735 | validation: 0.04205423156434883]
	TIME [epoch: 6.48 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04587790995430655		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.04587790995430655 | validation: 0.0556582367450214]
	TIME [epoch: 6.48 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04299547952613182		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.04299547952613182 | validation: 0.04665069136384049]
	TIME [epoch: 6.47 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04137441560616589		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.04137441560616589 | validation: 0.0504831703807589]
	TIME [epoch: 6.49 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045359862747059346		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.045359862747059346 | validation: 0.060265458698686845]
	TIME [epoch: 6.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04423144361800614		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.04423144361800614 | validation: 0.05075911588456645]
	TIME [epoch: 6.48 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04470632736386698		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.04470632736386698 | validation: 0.048132795774762455]
	TIME [epoch: 6.47 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04547592331299739		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.04547592331299739 | validation: 0.0543013553040942]
	TIME [epoch: 6.47 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046557817968625695		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.046557817968625695 | validation: 0.053457839929074796]
	TIME [epoch: 6.47 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04524982472198747		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.04524982472198747 | validation: 0.0405017928296803]
	TIME [epoch: 6.47 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04549865184806371		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.04549865184806371 | validation: 0.05210146889018109]
	TIME [epoch: 6.49 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04395622755159737		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.04395622755159737 | validation: 0.05306362196609276]
	TIME [epoch: 6.49 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04594700961678624		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.04594700961678624 | validation: 0.05232227241047032]
	TIME [epoch: 6.48 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04586118737262905		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.04586118737262905 | validation: 0.05092813436817477]
	TIME [epoch: 6.48 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04548055881495092		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.04548055881495092 | validation: 0.04627781977620616]
	TIME [epoch: 6.47 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04608132355053219		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.04608132355053219 | validation: 0.053236255858193096]
	TIME [epoch: 6.48 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04728095962614758		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.04728095962614758 | validation: 0.049240292793749266]
	TIME [epoch: 6.47 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04312876298863889		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.04312876298863889 | validation: 0.058117017462707]
	TIME [epoch: 6.48 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043305573402896466		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.043305573402896466 | validation: 0.048099643157098665]
	TIME [epoch: 6.51 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044267155004620494		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.044267155004620494 | validation: 0.05302241455316218]
	TIME [epoch: 6.48 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04316136027775261		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.04316136027775261 | validation: 0.05609710861203279]
	TIME [epoch: 6.47 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04248375031073044		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.04248375031073044 | validation: 0.05277191119828688]
	TIME [epoch: 6.48 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043858872087854495		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.043858872087854495 | validation: 0.05607203016280164]
	TIME [epoch: 6.47 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04361066623767731		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.04361066623767731 | validation: 0.05363726667004388]
	TIME [epoch: 6.48 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043731029945740366		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.043731029945740366 | validation: 0.05304909015917552]
	TIME [epoch: 6.48 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04354519836395858		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.04354519836395858 | validation: 0.04726979621321755]
	TIME [epoch: 6.51 sec]
Finished training in 13179.236 seconds.
