Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r2', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3890734075

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 10/20] avg loss: 11.383867905702218		[learning rate: 0.01]
		[batch 20/20] avg loss: 9.861355019986256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.622611462844237 | validation: 9.835316052680362]
	TIME [epoch: 49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 10/20] avg loss: 7.6460332816016745		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.50187867064754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.073955976124607 | validation: 7.132718368878063]
	TIME [epoch: 8.97 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 10/20] avg loss: 6.300995519435679		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.10637010903871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.203682814237194 | validation: 6.874012782012265]
	TIME [epoch: 8.95 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.9819107714596305		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.241106211836641		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.111508491648134 | validation: 6.7141848064154095]
	TIME [epoch: 8.94 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.853159217881371		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.063977720777352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.958568469329362 | validation: 6.661284284775951]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.9138064335893965		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.939500819744361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.926653626666879 | validation: 6.638025922480315]
	TIME [epoch: 8.98 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.67930478426163		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.093273889544973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.886289336903302 | validation: 6.626639817535206]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.791418821385025		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.907405038402603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.849411929893814 | validation: 6.664500470157705]
	TIME [epoch: 8.98 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.754295177600498		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.97505434459725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.864674761098874 | validation: 6.575063677270197]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.806653887897564		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.8913244393878035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.848989163642683 | validation: 6.649197801456031]
	TIME [epoch: 9 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.915745527821921		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.8376232122954255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.876684370058673 | validation: 6.709784904436161]
	TIME [epoch: 8.98 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 10/20] avg loss: 6.0119448331250505		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.623791749434211		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.8178682912796305 | validation: 6.5334914297187]
	TIME [epoch: 8.98 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.919174657652739		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.669412494737086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.794293576194912 | validation: 6.532933347761354]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.9106721593934015		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.639718050713496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.77519510505345 | validation: 6.705734665540982]
	TIME [epoch: 9 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.776791143324877		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.792365040973346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.784578092149112 | validation: 6.5377787501916895]
	TIME [epoch: 8.98 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.758692705427202		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.735645007901242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.747168856664222 | validation: 6.615651314040236]
	TIME [epoch: 8.99 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.607730864972008		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.806743905554617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.707237385263313 | validation: 6.526622431508802]
	TIME [epoch: 9.12 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.652420016909384		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.368552257091357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.51048613700037 | validation: 6.522616441370437]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.16722829941492		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.790584049867879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.978906174641399 | validation: 4.82487959762492]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.72363698938019		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.405972861872493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.0648049256263405 | validation: 4.791166658255865]
	TIME [epoch: 8.98 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.807491460867753		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.4724238131988003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6399576370332767 | validation: 5.035277334683279]
	TIME [epoch: 8.99 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.335492726601256		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.567149513761526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.451321120181391 | validation: 4.882504133083928]
	TIME [epoch: 9 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.7240319509491435		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.7176305738814044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.720831262415275 | validation: 4.6756826079918605]
	TIME [epoch: 8.98 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.750218112585204		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.31174410736593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.530981109975567 | validation: 4.641431349993831]
	TIME [epoch: 8.97 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2462613557034876		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.5665176294603027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.406389492581895 | validation: 4.978058682994259]
	TIME [epoch: 9 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2793494636200355		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.404463809554418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3419066365872268 | validation: 4.604964231570598]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.1408234351259248		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.3757950318326606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.258309233479293 | validation: 4.676454638718977]
	TIME [epoch: 8.99 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.3099548044629485		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.080985390087642		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.195470097275296 | validation: 4.558355909842715]
	TIME [epoch: 9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.3441223603217205		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0403484814822823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1922354209020023 | validation: 4.862988474905789]
	TIME [epoch: 9 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2904188006151927		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.2521209021903523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.271269851402773 | validation: 4.522111241113111]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2076330324491655		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.2093003175118033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2084666749804844 | validation: 4.673626111970806]
	TIME [epoch: 9.03 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2859737361402246		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.164713520607034		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.22534362837363 | validation: 4.472379696678188]
	TIME [epoch: 9.02 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.217591996203802		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0644443346945445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.141018165449173 | validation: 4.647477634506224]
	TIME [epoch: 9 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.0646868285626705		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.272087614403541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.168387221483106 | validation: 4.577786884188551]
	TIME [epoch: 9 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2845113078774824		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0922522964123837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1883818021449333 | validation: 4.582746785518494]
	TIME [epoch: 9.01 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.2590234966391156		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.1236150619354532		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.191319279287284 | validation: 4.508316575226134]
	TIME [epoch: 9 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.1062981670612713		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8818752089358823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.994086687998577 | validation: 4.360880840109267]
	TIME [epoch: 8.98 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.1692332223318114		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8435262876643645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0063797549980875 | validation: 4.483682205328094]
	TIME [epoch: 8.98 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.029755094926542		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.2996547041393045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1647048995329228 | validation: 5.022070430195629]
	TIME [epoch: 9 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.238374213101219		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8289956314629237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.033684922282071 | validation: 4.65889944681324]
	TIME [epoch: 9.01 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.8182103456507996		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.1096572986295756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.963933822140188 | validation: 4.415790843967072]
	TIME [epoch: 9 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.0059926636380676		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0961678077639676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0510802357010176 | validation: 4.515295815466343]
	TIME [epoch: 8.99 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.106670648485191		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.937673378379049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0221720134321206 | validation: 4.813848407719506]
	TIME [epoch: 8.99 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.1078779920491586		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0155096407275597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.061693816388359 | validation: 4.778924627763526]
	TIME [epoch: 8.99 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.9906967995485285		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.9482474670507837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9694721332996563 | validation: 4.456285224203011]
	TIME [epoch: 9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.114296873464922		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.883698606022966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9989977397439436 | validation: 4.486966741469985]
	TIME [epoch: 8.99 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.057294466515593		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.971751845705354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.014523156110473 | validation: 4.387820146838954]
	TIME [epoch: 8.99 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.0028363149185555		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.7953763579247313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.899106336421643 | validation: 4.361228605640851]
	TIME [epoch: 8.98 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.818291695923043		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0705235293158903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9444076126194663 | validation: 4.409086141531927]
	TIME [epoch: 8.99 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.1566573633274864		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.681149040259597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9189032017935417 | validation: 4.394065961634035]
	TIME [epoch: 8.97 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.013931265317289		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.878793817420332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9463625413688104 | validation: 4.292632699547406]
	TIME [epoch: 8.98 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.662896543954724		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.1557811752280047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.909338859591365 | validation: 4.464470429311268]
	TIME [epoch: 8.99 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.0317193215891676		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.93026339482882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9809913582089935 | validation: 4.45782997482464]
	TIME [epoch: 9 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 10/20] avg loss: 3.175510587555447		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8602638646508094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.017887226103128 | validation: 4.333867967920475]
	TIME [epoch: 9.02 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.889035259885567		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.9970683560614035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.943051807973485 | validation: 4.549959000178241]
	TIME [epoch: 9.02 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.8598433223373196		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.960638066757188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.910240694547254 | validation: 4.767398235475431]
	TIME [epoch: 8.99 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.885773415983463		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0269648138229366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9563691149031994 | validation: 4.520294870402049]
	TIME [epoch: 8.99 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.963981354566959		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.889210489341558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9265959219542586 | validation: 4.456582260763651]
	TIME [epoch: 9 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.879225201199991		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.912662498373357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.895943849786674 | validation: 4.422271137539808]
	TIME [epoch: 9 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.85834096390366		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0189896360163524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.938665299960006 | validation: 4.447411443554007]
	TIME [epoch: 9 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.9907327530260956		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.6936969430419433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8422148480340197 | validation: 4.252883657944473]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.7454475690176		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.0267371479465335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.886092358482066 | validation: 4.503343369333963]
	TIME [epoch: 9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.7092833726618455		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8542105359301844		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7817469542960147 | validation: 4.374031691304215]
	TIME [epoch: 9.02 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.6996888760132185		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.8198533705474453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7597711232803315 | validation: 4.453965607871765]
	TIME [epoch: 9.01 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.8928606461086743		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.655041536904924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7739510915067993 | validation: 4.148114580058539]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.7376854807421447		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.990836184344772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.864260832543459 | validation: 4.369078806523423]
	TIME [epoch: 9 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.747630695508139		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.6178061176219556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.682718406565047 | validation: 4.176813961792473]
	TIME [epoch: 8.98 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.640621791312737		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.6012201683289637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6209209798208497 | validation: 3.971748075944232]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.5342447640102117		[learning rate: 0.01]
		[batch 20/20] avg loss: 2.7199137256312778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6270792448207443 | validation: 4.078226535378635]
	TIME [epoch: 8.99 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.6231134459032646		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.980476968527757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3017952072155103 | validation: 1.2584082032623762]
	TIME [epoch: 8.99 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.1401428027186689		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9455216182816055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0428322105001373 | validation: 0.9097615864269175]
	TIME [epoch: 8.97 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.986970478500613		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9895438827200833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9882571806103482 | validation: 1.0253498983353755]
	TIME [epoch: 9.01 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.950279084337472		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9325664180800184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9414227512087452 | validation: 0.9643064201515932]
	TIME [epoch: 9 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8070819405410183		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7928734587009398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.799977699620979 | validation: 1.1700327817112146]
	TIME [epoch: 9 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.9690942111271317		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7605851072459652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8648396591865485 | validation: 1.1551447551283716]
	TIME [epoch: 8.99 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8070567940386205		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9057536861840119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.856405240111316 | validation: 0.7974043342113015]
	TIME [epoch: 8.97 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7294409181908991		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7915248601710977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7604828891809984 | validation: 0.9749534872879544]
	TIME [epoch: 9.01 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6842315306090687		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7952278000612005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7397296653351345 | validation: 0.7975865177034638]
	TIME [epoch: 8.99 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6742384735871387		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7294971437970903		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7018678086921144 | validation: 0.6942102744264209]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6689906011173311		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9535539537857755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8112722774515531 | validation: 0.7020503659993427]
	TIME [epoch: 9.01 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6811829061000789		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6997678347428592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6904753704214691 | validation: 0.852326066854885]
	TIME [epoch: 9.01 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6832022579142654		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.839041125540527		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7611216917273963 | validation: 0.7570017842354023]
	TIME [epoch: 9.03 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5458979948837805		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6809044186147596		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6134012067492699 | validation: 1.2915820172197467]
	TIME [epoch: 9.02 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8523731871832899		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.537637215338656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6950052012609731 | validation: 0.7841025986281548]
	TIME [epoch: 9.01 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8657021397146085		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6042722239528179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7349871818337134 | validation: 0.6934632191070731]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_85.pth
	Model improved!!!
EPOCH 86/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6372499857049129		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6768648499326719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6570574178187923 | validation: 0.7749610908988179]
	TIME [epoch: 9.02 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6738962209686434		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7156854302771766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6947908256229101 | validation: 0.5538070287707293]
	TIME [epoch: 9.01 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5519035271205717		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.9090932488783829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7304983879994772 | validation: 0.5871539485304537]
	TIME [epoch: 9.02 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5705007126555752		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6513629419024338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6109318272790045 | validation: 0.9931132903850908]
	TIME [epoch: 9.46 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6939682456025762		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6977483458943207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6958582957484485 | validation: 0.4954821318706532]
	TIME [epoch: 9.03 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6014685943554572		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6950268570006173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6482477256780373 | validation: 0.43441762378261706]
	TIME [epoch: 8.97 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5558793573526368		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.520145189464633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5380122734086348 | validation: 0.4512391703764945]
	TIME [epoch: 8.97 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5653560368995922		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5214385152163261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5433972760579593 | validation: 0.5910227317217227]
	TIME [epoch: 8.95 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.690675149124182		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6044115773548808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6475433632395314 | validation: 0.46719375715960115]
	TIME [epoch: 8.96 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6002165495192534		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5527078478936962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5764621987064749 | validation: 0.898668895544371]
	TIME [epoch: 8.98 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6048444690250115		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6827054695883238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6437749693066677 | validation: 1.0399116933292216]
	TIME [epoch: 8.96 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6680760983404764		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6950816151899353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6815788567652058 | validation: 0.3757907165988468]
	TIME [epoch: 8.95 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6476253032987378		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6144419186874337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6310336109930857 | validation: 0.6939260299399954]
	TIME [epoch: 8.96 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5320024066160649		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6529374978085581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5924699522123115 | validation: 0.411466068537406]
	TIME [epoch: 8.95 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5418817088044185		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5009391785465004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5214104436754595 | validation: 0.7434244593005456]
	TIME [epoch: 8.97 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5545007543384434		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4306068428957136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49255379861707854 | validation: 0.38150524542280567]
	TIME [epoch: 8.95 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.695073982673077		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5001540936997081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5976140381863926 | validation: 0.22720770181839434]
	TIME [epoch: 9.14 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r2_20240216_185744/states/model_tr_study1_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5365217229681919		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4337014272288945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4851115750985434 | validation: 0.6435858160803443]
	TIME [epoch: 8.95 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7204158864119238		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6402755789260636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6803457326689937 | validation: 0.45459302782923816]
	TIME [epoch: 8.96 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8166035243865564		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.724869186541685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7707363554641206 | validation: 0.7939834136536693]
	TIME [epoch: 8.99 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.564327607761148		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.634964294073934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5996459509175411 | validation: 0.6526521201357712]
	TIME [epoch: 8.95 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5635089885283515		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7485109812215185		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6560099848749351 | validation: 0.7891260203810383]
	TIME [epoch: 8.97 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5365389111539947		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6287151217128004		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5826270164333975 | validation: 1.045500588015218]
	TIME [epoch: 8.96 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6562771755213906		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.47844240426032003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5673597898908552 | validation: 0.3766503166851335]
	TIME [epoch: 9.08 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.591603971252765		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.539218667070489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.565411319161627 | validation: 0.4410756040571783]
	TIME [epoch: 8.98 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6246785090271717		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5822872898555425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6034828994413572 | validation: 0.6224880316435801]
	TIME [epoch: 8.96 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5366948483093658		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5082544164525842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.522474632380975 | validation: 1.01052385555197]
	TIME [epoch: 8.96 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.646772833423109		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6155469880383897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6311599107307495 | validation: 0.9448297524076607]
	TIME [epoch: 8.96 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5709724491673419		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7264935943615315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6487330217644367 | validation: 0.617687856220364]
	TIME [epoch: 8.98 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5795404344157103		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6529622323074588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6162513333615846 | validation: 0.7094274150784654]
	TIME [epoch: 8.96 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.678366135586608		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6354751044285624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6569206200075852 | validation: 0.5837079165419611]
	TIME [epoch: 8.95 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5607450819848581		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6626192171324058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6116821495586319 | validation: 0.4887916115289914]
	TIME [epoch: 8.94 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5278147380578534		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7078330254032457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6178238817305495 | validation: 0.43144856645692836]
	TIME [epoch: 8.96 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7012013500618273		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6326368661259643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6669191080938959 | validation: 0.43877669059850266]
	TIME [epoch: 8.98 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5777006942357953		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5502484712602759		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5639745827480356 | validation: 0.5428320124899352]
	TIME [epoch: 8.96 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5472557312599933		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6413761439385526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.594315937599273 | validation: 0.5038631547968357]
	TIME [epoch: 8.95 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4768274380030403		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5916174738989991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5342224559510197 | validation: 1.2017398584114483]
	TIME [epoch: 8.95 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.621064138558901		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7887790369722091		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7049215877655552 | validation: 1.091155412412009]
	TIME [epoch: 8.97 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6275693732757384		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.46859042715454136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5480799002151399 | validation: 0.34247780026271646]
	TIME [epoch: 8.96 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5650966886566643		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5618393286213311		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5634680086389978 | validation: 0.8360029706974624]
	TIME [epoch: 8.96 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5160508393927612		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7015906687039088		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6088207540483351 | validation: 0.9719299245457993]
	TIME [epoch: 8.95 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5944336826178778		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6732508207993416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6338422517086097 | validation: 1.1589726330234258]
	TIME [epoch: 8.95 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7255675679558836		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6740556193854434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6998115936706636 | validation: 0.6293457217238149]
	TIME [epoch: 8.97 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4947260121932624		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.44393849730400586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4693322547486341 | validation: 0.6023985695271932]
	TIME [epoch: 8.96 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5805932325785303		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7049154478184624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6427543401984963 | validation: 1.127033028669942]
	TIME [epoch: 8.96 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7400115424766824		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5573602864300415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6486859144533621 | validation: 0.5292525526635722]
	TIME [epoch: 8.95 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5255892576401573		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5483594867679076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5369743722040323 | validation: 0.50218418584142]
	TIME [epoch: 8.95 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5636425612947603		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.46480662427056474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5142245927826624 | validation: 0.8719519332874693]
	TIME [epoch: 8.98 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5689733548066136		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4795872911229283		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5242803229647709 | validation: 0.5885367505360982]
	TIME [epoch: 8.96 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.601894881841946		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7494784878361572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6756866848390516 | validation: 0.3504835076095455]
	TIME [epoch: 8.97 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6085943312673472		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5724095657763656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5905019485218563 | validation: 0.787350202163265]
	TIME [epoch: 8.94 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6643753486985071		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.46005527953282305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5622153141156652 | validation: 0.4882999459288775]
	TIME [epoch: 8.97 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5062407943218343		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4967741468311413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5015074705764878 | validation: 0.48214475253579603]
	TIME [epoch: 8.96 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5418015403786436		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5618224572052367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5518119987919403 | validation: 0.685277947362497]
	TIME [epoch: 8.95 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5557522852694354		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5192103985036834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5374813418865595 | validation: 0.8347784161200019]
	TIME [epoch: 8.96 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4689119308755654		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4977091475249066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4833105392002359 | validation: 0.6841464044087479]
	TIME [epoch: 8.96 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.47836883023374427		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5424030363384883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5103859332861164 | validation: 0.634697195784201]
	TIME [epoch: 8.95 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4993596177052376		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.707250614814566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6033051162599018 | validation: 0.4267385546780695]
	TIME [epoch: 8.94 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5250179973918724		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6001299479201713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5625739726560218 | validation: 0.3497934183282031]
	TIME [epoch: 8.95 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.450490006701763		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5829799444053259		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5167349755535444 | validation: 0.34232707170201265]
	TIME [epoch: 8.94 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.552980157295645		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.45851822322098945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5057491902583171 | validation: 0.8758844553592013]
	TIME [epoch: 8.95 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6107835545747621		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.44023689832084206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5255102264478021 | validation: 1.2639830009538353]
	TIME [epoch: 8.97 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.8583553434556197		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.7573580598884793		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8078567016720495 | validation: 0.5342338273275739]
	TIME [epoch: 8.94 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.45509496552766693		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5331977065771362		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49414633605240155 | validation: 0.5337691510742799]
	TIME [epoch: 8.95 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6335337148173884		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4346475491327766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5340906319750826 | validation: 0.8917385389371792]
	TIME [epoch: 8.95 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6564521083491052		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.49682187907079484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5766369937099499 | validation: 0.8758266486072419]
	TIME [epoch: 8.98 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5755089698188439		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8492074526187949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7123582112188193 | validation: 0.586315935992058]
	TIME [epoch: 8.97 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.599868816173877		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6225131126271236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6111909644005002 | validation: 0.7441973232612876]
	TIME [epoch: 8.99 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.48548895032013784		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4366783009507234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4610836256354306 | validation: 0.7336396398179736]
	TIME [epoch: 8.95 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.4562943209626219		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4264395246650937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44136692281385786 | validation: 0.6062676776496766]
	TIME [epoch: 8.95 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.45606601971436705		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5139601596257188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48501308967004303 | validation: 0.5319835990712989]
	TIME [epoch: 8.97 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5401252675747134		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5110733916046446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5255993295896789 | validation: 0.44423862514100226]
	TIME [epoch: 8.96 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.43777563903604405		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6221076135652788		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5299416263006614 | validation: 0.40769834347125444]
	TIME [epoch: 8.95 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5194186666335302		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5295721039876848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5244953853106076 | validation: 1.0092932875202754]
	TIME [epoch: 8.96 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5104402558691361		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6105165277234639		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5604783917962999 | validation: 0.322207771251967]
	TIME [epoch: 8.96 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 10/20] avg loss: 1.2633889408111272		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.122820233812474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.193104587311801 | validation: 1.5944664927672454]
	TIME [epoch: 8.97 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7307687390848061		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5072274887392181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.618998113912012 | validation: 0.39222672415962456]
	TIME [epoch: 8.96 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.46012411623559435		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5492300813482116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.504677098791903 | validation: 0.31252181386835315]
	TIME [epoch: 8.96 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5129570748104227		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4506837884962242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48182043165332356 | validation: 0.6196336031659602]
	TIME [epoch: 8.97 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6254240413742191		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.6188027346387397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6221133880064794 | validation: 1.0329790868558053]
	TIME [epoch: 8.98 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6365933400359244		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.5065933393995047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5715933397177144 | validation: 0.5462229822837855]
	TIME [epoch: 8.97 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5765293650188903		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.4434502590029379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.009989812010914 | validation: 2.8229236977560226]
	TIME [epoch: 8.96 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 10/20] avg loss: 2.2302149112642105		[learning rate: 0.01]
		[batch 20/20] avg loss: 1.306468578152218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7683417447082141 | validation: 0.7878090337776793]
	TIME [epoch: 8.94 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.7588111662696669		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.8298398219291444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7943254940994056 | validation: 0.5345498022353583]
	TIME [epoch: 8.97 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.5127783326521824		[learning rate: 0.01]
		[batch 20/20] avg loss: 0.4776045448095256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4951914387308539 | validation: 0.40854566359701294]
	TIME [epoch: 8.98 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 10/20] avg loss: 0.6652060849868928		[learning rate: 0.01]
		[batch 20/20] avg loss: 3.6273496618177803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1462778734023367 | validation: 2.407496288897181]
	TIME [epoch: 8.97 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.982475581948978		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.9445396133748325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.963507597661906 | validation: 7.651089200045863]
	TIME [epoch: 8.99 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 10/20] avg loss: 5.894428988152468		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.259367494468579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.5768982413105235 | validation: 5.88653434859598]
	TIME [epoch: 8.98 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.844054298290512		[learning rate: 0.01]
		[batch 20/20] avg loss: 5.1420131671431495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.993033732716831 | validation: 5.544980446217166]
	TIME [epoch: 8.99 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 10/20] avg loss: 4.718537928035326		[learning rate: 0.01]
		[batch 20/20] avg loss: 4.227287528348605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.472912728191965 | validation: 6.438728296824225]
	TIME [epoch: 8.99 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 10/20] avg loss: 6.665520476575073		[learning rate: 0.01]
		[batch 20/20] avg loss: 12.638772473672466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.65214647512377 | validation: 13.520798841109427]
	TIME [epoch: 8.99 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 10/20] avg loss: nan		[learning rate: 0.01]
		[batch 20/20] avg loss: nan		[learning rate: 0.01]
ERROR:
nan encountered in epoch 176 (training loss).
