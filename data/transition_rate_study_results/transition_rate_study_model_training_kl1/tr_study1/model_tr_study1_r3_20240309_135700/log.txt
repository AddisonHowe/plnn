Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r3', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2262309087

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 10.226460691147151		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.226460691147151 | validation: 8.101126982178407]
	TIME [epoch: 84.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.830745168551353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.830745168551353 | validation: 7.510746823103656]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.945748177103846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.945748177103846 | validation: 6.705569329988833]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.43749067344569		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.43749067344569 | validation: 6.8374509194173365]
	TIME [epoch: 6.39 sec]
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.030713750677691		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.030713750677691 | validation: 5.85344211631779]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.418982318681377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.418982318681377 | validation: 5.49273401253417]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.011549930468184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.011549930468184 | validation: 4.96321491002001]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.724482921135816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.724482921135816 | validation: 5.579997565050096]
	TIME [epoch: 6.41 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.664218949289529		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.664218949289529 | validation: 5.398107710381182]
	TIME [epoch: 6.42 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.53044430523248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.53044430523248 | validation: 5.149541169379675]
	TIME [epoch: 6.39 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.472021493136767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.472021493136767 | validation: 5.475695965406717]
	TIME [epoch: 6.38 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.529436985259444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.529436985259444 | validation: 5.082186570426776]
	TIME [epoch: 6.38 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.503663014556817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.503663014556817 | validation: 5.411858177199362]
	TIME [epoch: 6.4 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.447716780059323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.447716780059323 | validation: 5.891730236458966]
	TIME [epoch: 6.39 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.496964418872178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.496964418872178 | validation: 5.286845569926994]
	TIME [epoch: 6.41 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.4949512718321785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.4949512718321785 | validation: 5.20917337944076]
	TIME [epoch: 6.44 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.330594932109663		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.330594932109663 | validation: 4.899734435733726]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.164903862706139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.164903862706139 | validation: 5.668178507948889]
	TIME [epoch: 6.39 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.486893132903969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.486893132903969 | validation: 4.925582390474303]
	TIME [epoch: 6.38 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.044334548689233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.044334548689233 | validation: 4.794124445171746]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.179057775735171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.179057775735171 | validation: 4.875176131052406]
	TIME [epoch: 6.38 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.856243504033778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.856243504033778 | validation: 4.718954141578292]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.930197390606796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.930197390606796 | validation: 4.613256123836424]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.894249286591889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.894249286591889 | validation: 5.022212541112305]
	TIME [epoch: 6.38 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.025153761164557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.025153761164557 | validation: 4.660463059858456]
	TIME [epoch: 6.39 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.607971042900681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.607971042900681 | validation: 4.341290417543591]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.42363490434699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.42363490434699 | validation: 4.395146159719601]
	TIME [epoch: 6.39 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.514095730658878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.514095730658878 | validation: 4.505543584757188]
	TIME [epoch: 6.39 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.379031628131678		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.379031628131678 | validation: 4.396511960843721]
	TIME [epoch: 6.4 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.272764813865987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.272764813865987 | validation: 4.33078772750298]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.097179104683796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.097179104683796 | validation: 4.548367269438845]
	TIME [epoch: 6.39 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.380132832032179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.380132832032179 | validation: 3.736785704474183]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7402358615548787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7402358615548787 | validation: 4.443638476314022]
	TIME [epoch: 6.39 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8277251843826217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8277251843826217 | validation: 3.5493824069288635]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.057556255704498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.057556255704498 | validation: 5.031781101867436]
	TIME [epoch: 6.39 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.283950064430041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.283950064430041 | validation: 3.4104234789803924]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2447743120320314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2447743120320314 | validation: 3.147452291697178]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.150400710179772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.150400710179772 | validation: 3.016722657416505]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_38.pth
	Model improved!!!
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.278086137487821		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.278086137487821 | validation: 3.439515913743418]
	TIME [epoch: 6.38 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0544519984729446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0544519984729446 | validation: 3.2592466785114844]
	TIME [epoch: 6.39 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.177985954847758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.177985954847758 | validation: 3.970902434589536]
	TIME [epoch: 6.38 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1831924359625097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1831924359625097 | validation: 2.4507571063411353]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_42.pth
	Model improved!!!
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.542625514176242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.542625514176242 | validation: 2.2610211919471443]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2137925323517935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2137925323517935 | validation: 2.6223704213127266]
	TIME [epoch: 6.41 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5991928913450586		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5991928913450586 | validation: 2.7433638195965875]
	TIME [epoch: 6.38 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.751205797451645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.751205797451645 | validation: 2.039864539226737]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6257151993091767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6257151993091767 | validation: 2.3014105088442998]
	TIME [epoch: 6.38 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.43518286609459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.43518286609459 | validation: 1.9363144543716513]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3362547374554277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3362547374554277 | validation: 3.4545627635032155]
	TIME [epoch: 6.38 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7382152619507294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7382152619507294 | validation: 2.080177953066498]
	TIME [epoch: 6.38 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2403366029194043		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.2403366029194043 | validation: 2.955981428370833]
	TIME [epoch: 6.41 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.369581240148174		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 2.369581240148174 | validation: 2.6535222375026155]
	TIME [epoch: 6.38 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.385374702678749		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.385374702678749 | validation: 1.5116884834395814]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9913538705212632		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 1.9913538705212632 | validation: 4.086019175920254]
	TIME [epoch: 6.38 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.432043443944489		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 2.432043443944489 | validation: 3.4605133284722536]
	TIME [epoch: 6.38 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3269489038615543		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.3269489038615543 | validation: 1.8459687154939741]
	TIME [epoch: 6.38 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1649079848258714		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.1649079848258714 | validation: 1.386548112849004]
	TIME [epoch: 6.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9622403545916598		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 1.9622403545916598 | validation: 1.2136111939911234]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.150738455355541		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 2.150738455355541 | validation: 1.290317539142934]
	TIME [epoch: 6.38 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8337909668070242		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 1.8337909668070242 | validation: 2.2082955440500784]
	TIME [epoch: 6.38 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.85427399700962		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 1.85427399700962 | validation: 2.5403384991884432]
	TIME [epoch: 6.38 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1875239942519675		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.1875239942519675 | validation: 1.5127433215507182]
	TIME [epoch: 6.38 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8857670491319953		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 1.8857670491319953 | validation: 1.156201259892962]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_63.pth
	Model improved!!!
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7901536822943975		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 1.7901536822943975 | validation: 1.544193935997182]
	TIME [epoch: 6.38 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5504260651916133		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 1.5504260651916133 | validation: 1.2560897414922638]
	TIME [epoch: 6.42 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.3365844303862406		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.3365844303862406 | validation: 1.0851161958945783]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8186116993260768		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 1.8186116993260768 | validation: 1.6725031492768279]
	TIME [epoch: 6.38 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7777607143992733		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 1.7777607143992733 | validation: 1.334186810822656]
	TIME [epoch: 6.38 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.607676942008781		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 1.607676942008781 | validation: 2.4609207935436745]
	TIME [epoch: 6.38 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7070316382441673		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 1.7070316382441673 | validation: 2.029966387544878]
	TIME [epoch: 6.39 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.511480343307141		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 1.511480343307141 | validation: 1.4366349475811189]
	TIME [epoch: 6.38 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8955567177172126		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 1.8955567177172126 | validation: 1.1590718678399423]
	TIME [epoch: 6.42 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5901090458558629		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 1.5901090458558629 | validation: 0.9324442019479066]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8528939114102543		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.8528939114102543 | validation: 1.7841612889687748]
	TIME [epoch: 6.39 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9680638000163808		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 1.9680638000163808 | validation: 1.5471421044945992]
	TIME [epoch: 6.38 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.562048546057539		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 1.562048546057539 | validation: 1.827022596382192]
	TIME [epoch: 6.38 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7826156585219382		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 1.7826156585219382 | validation: 1.340928713151949]
	TIME [epoch: 6.38 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.552743501879534		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 1.552743501879534 | validation: 2.2480076346337325]
	TIME [epoch: 6.38 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6331147882842172		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 1.6331147882842172 | validation: 1.0015134520244025]
	TIME [epoch: 6.42 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7780608328747283		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 1.7780608328747283 | validation: 1.1008213097519453]
	TIME [epoch: 6.4 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4742523016158504		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 1.4742523016158504 | validation: 0.8327230705183457]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4209407219717642		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 1.4209407219717642 | validation: 1.2993456613716752]
	TIME [epoch: 6.39 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.495215532611371		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 1.495215532611371 | validation: 1.0007629064917896]
	TIME [epoch: 6.66 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6350867887606002		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 1.6350867887606002 | validation: 1.1205706411499758]
	TIME [epoch: 6.38 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4321548723031134		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 1.4321548723031134 | validation: 1.1940036112010395]
	TIME [epoch: 6.38 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4574770765262597		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.4574770765262597 | validation: 0.879283224572493]
	TIME [epoch: 6.41 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.115397853423792		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 1.115397853423792 | validation: 2.0863550187741997]
	TIME [epoch: 6.4 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9599978760541248		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 1.9599978760541248 | validation: 1.324213023577767]
	TIME [epoch: 6.39 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3711434668551536		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 1.3711434668551536 | validation: 1.4324185099940383]
	TIME [epoch: 6.39 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4131507063570643		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 1.4131507063570643 | validation: 1.458671109290825]
	TIME [epoch: 6.38 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2237558072832768		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 1.2237558072832768 | validation: 2.3140289000176266]
	TIME [epoch: 6.39 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4773162640345576		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 1.4773162640345576 | validation: 1.5692022013891684]
	TIME [epoch: 6.38 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4466038133734584		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 1.4466038133734584 | validation: 1.8038823112327524]
	TIME [epoch: 6.4 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3287997502284778		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 1.3287997502284778 | validation: 0.7923214805516243]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_94.pth
	Model improved!!!
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2930693546435348		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 1.2930693546435348 | validation: 1.247889188107987]
	TIME [epoch: 6.38 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.356837909056512		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 1.356837909056512 | validation: 1.4146683755341913]
	TIME [epoch: 6.38 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.26251241322074		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 1.26251241322074 | validation: 0.705649705254552]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3410878507044384		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 1.3410878507044384 | validation: 1.1176135186986798]
	TIME [epoch: 6.39 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3554295574585422		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 1.3554295574585422 | validation: 0.8070711486233861]
	TIME [epoch: 6.39 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.148147445021773		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 1.148147445021773 | validation: 1.6253418690362815]
	TIME [epoch: 6.41 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4811979274059663		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.4811979274059663 | validation: 1.1389500235040264]
	TIME [epoch: 6.41 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.104346006298113		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 1.104346006298113 | validation: 1.9198847996364332]
	TIME [epoch: 6.4 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.497948300699938		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 1.497948300699938 | validation: 1.704449841476137]
	TIME [epoch: 6.38 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.509026067610422		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.509026067610422 | validation: 0.7540981675975975]
	TIME [epoch: 6.39 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.084097082024307		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.084097082024307 | validation: 0.9707172823839938]
	TIME [epoch: 6.39 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0321341344229675		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.0321341344229675 | validation: 0.6363908275994016]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2579261496449097		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.2579261496449097 | validation: 0.8384781333652203]
	TIME [epoch: 6.39 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7740965724822972		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.7740965724822972 | validation: 0.8555382859164]
	TIME [epoch: 6.42 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6461218861910951		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.6461218861910951 | validation: 0.672160565317881]
	TIME [epoch: 6.39 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2014265150692147		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.2014265150692147 | validation: 0.8111230487495241]
	TIME [epoch: 6.39 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5204470281688582		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.5204470281688582 | validation: 1.481365942913921]
	TIME [epoch: 6.39 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1205774813979155		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.1205774813979155 | validation: 0.8619384927160094]
	TIME [epoch: 6.39 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1101951929221678		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.1101951929221678 | validation: 1.2584419830890037]
	TIME [epoch: 6.39 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2187553707082508		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.2187553707082508 | validation: 1.243734388563112]
	TIME [epoch: 6.39 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2960456429620357		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.2960456429620357 | validation: 0.7742668336362417]
	TIME [epoch: 6.43 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9690009575162855		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 0.9690009575162855 | validation: 0.8465336507463879]
	TIME [epoch: 6.4 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3342991753928444		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.3342991753928444 | validation: 0.5121337844944909]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5737941588709576		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.5737941588709576 | validation: 2.942010895387049]
	TIME [epoch: 6.38 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4698284825280927		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 1.4698284825280927 | validation: 0.5719956260677206]
	TIME [epoch: 6.38 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.431751596277242		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.431751596277242 | validation: 1.0663297373532918]
	TIME [epoch: 6.38 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2213449080187775		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.2213449080187775 | validation: 0.8061495346923113]
	TIME [epoch: 6.38 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.057696592092333		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 1.057696592092333 | validation: 1.4701088823237376]
	TIME [epoch: 6.41 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0685877176915322		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 1.0685877176915322 | validation: 1.176731683183684]
	TIME [epoch: 6.39 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2859483742650384		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 1.2859483742650384 | validation: 1.2241315947948996]
	TIME [epoch: 6.38 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0289138472654693		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 1.0289138472654693 | validation: 0.908140538034967]
	TIME [epoch: 6.38 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9348962736943833		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.9348962736943833 | validation: 1.1403887179653125]
	TIME [epoch: 6.38 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1894916347182984		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 1.1894916347182984 | validation: 1.5708237746933873]
	TIME [epoch: 6.38 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0842201983569455		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.0842201983569455 | validation: 1.3549105170315163]
	TIME [epoch: 6.38 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0547373955484862		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.0547373955484862 | validation: 0.9816032822027805]
	TIME [epoch: 6.39 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1684137208908079		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.1684137208908079 | validation: 0.746562876520443]
	TIME [epoch: 6.4 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8241640700462239		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 0.8241640700462239 | validation: 0.7742579435869814]
	TIME [epoch: 6.39 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1406273792107413		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 1.1406273792107413 | validation: 0.630961221104364]
	TIME [epoch: 6.38 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9953785462184779		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 0.9953785462184779 | validation: 0.8034424431252885]
	TIME [epoch: 6.39 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9463357690551653		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.9463357690551653 | validation: 0.799913212260827]
	TIME [epoch: 6.38 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7966212933934483		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.7966212933934483 | validation: 3.6537466084741625]
	TIME [epoch: 6.4 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5789499694812605		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.5789499694812605 | validation: 0.4759954404254228]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0060972347228376		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.0060972347228376 | validation: 1.4313000177073745]
	TIME [epoch: 6.43 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1944330599468092		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.1944330599468092 | validation: 0.571771515067226]
	TIME [epoch: 6.39 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.044291869438546		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.044291869438546 | validation: 0.8401767210268204]
	TIME [epoch: 6.39 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7712215721479275		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.7712215721479275 | validation: 0.9129055028273291]
	TIME [epoch: 6.39 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1190436130027968		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 1.1190436130027968 | validation: 0.5259519946133554]
	TIME [epoch: 6.39 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.080483804044605		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.080483804044605 | validation: 0.5142412014460307]
	TIME [epoch: 6.4 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1944456241380368		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.1944456241380368 | validation: 1.2430164600387814]
	TIME [epoch: 6.4 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0400215571402307		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 1.0400215571402307 | validation: 2.5861722768154114]
	TIME [epoch: 6.43 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7523293416166794		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.7523293416166794 | validation: 0.7504487497905241]
	TIME [epoch: 6.39 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8978089966510925		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.8978089966510925 | validation: 0.6119441223403738]
	TIME [epoch: 6.4 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8148424609571943		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.8148424609571943 | validation: 0.5304614326530931]
	TIME [epoch: 6.4 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7723397903805657		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 0.7723397903805657 | validation: 1.8390634944443118]
	TIME [epoch: 6.4 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1172250008333955		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.1172250008333955 | validation: 0.792635516619942]
	TIME [epoch: 6.39 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1673509510473647		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 1.1673509510473647 | validation: 0.8423704295760532]
	TIME [epoch: 6.39 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8869096512798826		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.8869096512798826 | validation: 0.5976718729431537]
	TIME [epoch: 6.43 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8368329300174588		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 0.8368329300174588 | validation: 0.5593728405757097]
	TIME [epoch: 6.4 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9550357691791193		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.9550357691791193 | validation: 0.589854041650864]
	TIME [epoch: 6.4 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0722635544796568		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 1.0722635544796568 | validation: 0.8161300752217057]
	TIME [epoch: 6.4 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8174043530398887		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 0.8174043530398887 | validation: 0.7301009515230995]
	TIME [epoch: 6.41 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.055962835424407		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 1.055962835424407 | validation: 0.9234097155345097]
	TIME [epoch: 6.4 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9552321530042619		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 0.9552321530042619 | validation: 0.8038637172257989]
	TIME [epoch: 6.4 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9258877030246984		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.9258877030246984 | validation: 0.7019735761587819]
	TIME [epoch: 6.43 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0047847533942484		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 1.0047847533942484 | validation: 0.5666720071859391]
	TIME [epoch: 6.41 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9127227566845395		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.9127227566845395 | validation: 0.5831980641200881]
	TIME [epoch: 6.4 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8779702494152468		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.8779702494152468 | validation: 1.1512263697392195]
	TIME [epoch: 6.4 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.007926631843179		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.007926631843179 | validation: 1.3895342533550017]
	TIME [epoch: 6.4 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9322852614034536		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.9322852614034536 | validation: 0.6224900615065245]
	TIME [epoch: 6.4 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9350901251837876		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.9350901251837876 | validation: 0.6753806898258091]
	TIME [epoch: 6.4 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9083954205194922		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.9083954205194922 | validation: 0.6292865458727372]
	TIME [epoch: 6.42 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7727614463512339		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.7727614463512339 | validation: 0.9648137218712124]
	TIME [epoch: 6.42 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0045383822489955		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.0045383822489955 | validation: 0.7463090218182447]
	TIME [epoch: 6.4 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9306836020636686		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.9306836020636686 | validation: 0.8103842128782819]
	TIME [epoch: 6.4 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.957408238370016		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.957408238370016 | validation: 0.6864875967783339]
	TIME [epoch: 6.39 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0043592971228574		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.0043592971228574 | validation: 0.8379551746396203]
	TIME [epoch: 6.4 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2561845509481608		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 1.2561845509481608 | validation: 0.5737089199002959]
	TIME [epoch: 6.39 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7061931597349587		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.7061931597349587 | validation: 0.9026522066627473]
	TIME [epoch: 6.41 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0826377436065622		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.0826377436065622 | validation: 0.6655678197305684]
	TIME [epoch: 6.42 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9060675701997747		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.9060675701997747 | validation: 1.6436020476398168]
	TIME [epoch: 6.4 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2357645051063628		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.2357645051063628 | validation: 1.1875371313323837]
	TIME [epoch: 6.39 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8863256978053988		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.8863256978053988 | validation: 0.8532704343430387]
	TIME [epoch: 6.4 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0025078732702393		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.0025078732702393 | validation: 0.6347187822992073]
	TIME [epoch: 6.39 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7286386851142526		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 0.7286386851142526 | validation: 1.1342217786810325]
	TIME [epoch: 6.4 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0077805640407473		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.0077805640407473 | validation: 0.46819086970451373]
	TIME [epoch: 6.39 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7229475433464557		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.7229475433464557 | validation: 0.9454406087880998]
	TIME [epoch: 6.44 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8892562611085635		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.8892562611085635 | validation: 1.2643232354114131]
	TIME [epoch: 6.4 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8759035806034899		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.8759035806034899 | validation: 1.0938361204930767]
	TIME [epoch: 6.39 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8929611028337194		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.8929611028337194 | validation: 0.8890864602248693]
	TIME [epoch: 6.4 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.832667626055484		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.832667626055484 | validation: 0.540251946014082]
	TIME [epoch: 6.4 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9814365214348965		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.9814365214348965 | validation: 0.4765639604138883]
	TIME [epoch: 6.39 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228449662322804		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.6228449662322804 | validation: 0.44277457350904187]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_186.pth
	Model improved!!!
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0208206744623132		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 1.0208206744623132 | validation: 0.8938562571097941]
	TIME [epoch: 6.43 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0423304427112488		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 1.0423304427112488 | validation: 0.5408592678833253]
	TIME [epoch: 6.39 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699499554004265		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 0.699499554004265 | validation: 0.9323537643705854]
	TIME [epoch: 6.39 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0242302369866862		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.0242302369866862 | validation: 0.4792816399746445]
	TIME [epoch: 6.38 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7657001578254565		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.7657001578254565 | validation: 0.7933188278972355]
	TIME [epoch: 6.38 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8562526165893378		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.8562526165893378 | validation: 1.0319967071173755]
	TIME [epoch: 6.38 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8059098181865406		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.8059098181865406 | validation: 0.4407367430078568]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7796981012277412		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.7796981012277412 | validation: 0.7794917714736425]
	TIME [epoch: 6.4 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3785922840025724		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.3785922840025724 | validation: 0.36879695991622685]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7320356585178651		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.7320356585178651 | validation: 0.32027794489022127]
	TIME [epoch: 6.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_196.pth
	Model improved!!!
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6451229397405172		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.6451229397405172 | validation: 0.34802928311178494]
	TIME [epoch: 6.65 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5808913950046719		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.5808913950046719 | validation: 0.8299355171552227]
	TIME [epoch: 6.37 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8251365753099975		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.8251365753099975 | validation: 1.2199127762323707]
	TIME [epoch: 6.38 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0034484242516868		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.0034484242516868 | validation: 0.6816827473545574]
	TIME [epoch: 6.38 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7128739678969856		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.7128739678969856 | validation: 0.543420830914627]
	TIME [epoch: 6.41 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7587341859590833		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.7587341859590833 | validation: 1.1638101891273491]
	TIME [epoch: 6.39 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8866008668410774		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.8866008668410774 | validation: 0.5296827207859338]
	TIME [epoch: 6.38 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7347057797079681		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.7347057797079681 | validation: 0.5697884999864701]
	TIME [epoch: 6.38 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7620136290265829		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.7620136290265829 | validation: 1.0170382475221469]
	TIME [epoch: 6.39 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6661569671932427		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.6661569671932427 | validation: 1.052019746494736]
	TIME [epoch: 6.39 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8280999034884986		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.8280999034884986 | validation: 0.5009436707067273]
	TIME [epoch: 6.39 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6456971139973298		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.6456971139973298 | validation: 0.5007703548652438]
	TIME [epoch: 6.42 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0998182754846082		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 1.0998182754846082 | validation: 0.38065344920972694]
	TIME [epoch: 6.41 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7857691162788233		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.7857691162788233 | validation: 0.34087453168823323]
	TIME [epoch: 6.4 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5978748259883506		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.5978748259883506 | validation: 0.961284883716167]
	TIME [epoch: 6.4 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7580501721253984		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.7580501721253984 | validation: 0.4946534816840098]
	TIME [epoch: 6.4 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5958537934568392		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.5958537934568392 | validation: 0.7721209078777692]
	TIME [epoch: 6.4 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8757575795512091		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.8757575795512091 | validation: 1.0545538163392467]
	TIME [epoch: 6.39 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9508769274326856		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.9508769274326856 | validation: 1.1205844866108536]
	TIME [epoch: 6.41 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7331100194115145		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.7331100194115145 | validation: 0.6500018618087547]
	TIME [epoch: 6.42 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.929983539590991		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.929983539590991 | validation: 0.5822395772649825]
	TIME [epoch: 6.4 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6526290285071814		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.6526290285071814 | validation: 1.6374249932716356]
	TIME [epoch: 6.4 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9610053903581914		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.9610053903581914 | validation: 0.7528052845949057]
	TIME [epoch: 6.4 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6777183368048074		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.6777183368048074 | validation: 0.7632101019395918]
	TIME [epoch: 6.4 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9800181626447539		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.9800181626447539 | validation: 2.615308657368337]
	TIME [epoch: 6.4 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2345001008216108		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.2345001008216108 | validation: 0.8166558602717932]
	TIME [epoch: 6.4 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.701890854589672		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.701890854589672 | validation: 0.5339577097218534]
	TIME [epoch: 6.43 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7731607667557063		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.7731607667557063 | validation: 0.3602354419362898]
	TIME [epoch: 6.4 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8653354667872812		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.8653354667872812 | validation: 0.33398009687809593]
	TIME [epoch: 6.4 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6420491743315697		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.6420491743315697 | validation: 1.2039206564619407]
	TIME [epoch: 6.4 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7712214929652293		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.7712214929652293 | validation: 0.7874338889877942]
	TIME [epoch: 6.4 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7531417558047206		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.7531417558047206 | validation: 0.3576135504859471]
	TIME [epoch: 6.4 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6306755908160324		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.6306755908160324 | validation: 0.46110013498243163]
	TIME [epoch: 6.4 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9766188959011067		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.9766188959011067 | validation: 1.0706222467236]
	TIME [epoch: 6.43 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7325460425172216		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.7325460425172216 | validation: 0.8110244622408207]
	TIME [epoch: 6.41 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6366327182236869		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.6366327182236869 | validation: 0.5764462865565557]
	TIME [epoch: 6.4 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.075433503579448		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 1.075433503579448 | validation: 0.6337881451615781]
	TIME [epoch: 6.4 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6878215880744538		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.6878215880744538 | validation: 1.2094338559118334]
	TIME [epoch: 6.4 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014922901945362		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.7014922901945362 | validation: 0.360784906604123]
	TIME [epoch: 6.4 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7806670974269977		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.7806670974269977 | validation: 0.41302864088187163]
	TIME [epoch: 6.4 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5587214324304843		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.5587214324304843 | validation: 0.7177819833890781]
	TIME [epoch: 6.43 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7679257242572857		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.7679257242572857 | validation: 0.7113026725404169]
	TIME [epoch: 6.41 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6046181881115548		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.6046181881115548 | validation: 1.2903181319783794]
	TIME [epoch: 6.41 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7141184448165572		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.7141184448165572 | validation: 0.5533769748471606]
	TIME [epoch: 6.4 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.792585173883326		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.792585173883326 | validation: 1.1640263729720892]
	TIME [epoch: 6.4 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5934850652175848		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.5934850652175848 | validation: 0.3781562344859091]
	TIME [epoch: 6.4 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5643797880986061		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.5643797880986061 | validation: 0.6778660674367194]
	TIME [epoch: 6.4 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9459594654805691		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.9459594654805691 | validation: 0.3078977991041305]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_244.pth
	Model improved!!!
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8126732384695223		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.8126732384695223 | validation: 0.34709828475252896]
	TIME [epoch: 6.41 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4786064901660846		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.4786064901660846 | validation: 0.6616362244229166]
	TIME [epoch: 6.4 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7882294552551945		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.7882294552551945 | validation: 0.5517417363117576]
	TIME [epoch: 6.4 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7226312546007325		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.7226312546007325 | validation: 0.8962186601773462]
	TIME [epoch: 6.39 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8215189092565148		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.8215189092565148 | validation: 0.2596020274359947]
	TIME [epoch: 6.38 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_249.pth
	Model improved!!!
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4718128751337856		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.4718128751337856 | validation: 1.0299149828084422]
	TIME [epoch: 6.39 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6017219257886448		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.6017219257886448 | validation: 0.6855793662797587]
	TIME [epoch: 6.4 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6554985270542577		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6554985270542577 | validation: 0.3773877529868961]
	TIME [epoch: 6.41 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6485097776150401		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.6485097776150401 | validation: 0.5520973558148928]
	TIME [epoch: 6.4 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6950274794010128		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.6950274794010128 | validation: 1.3210774087143677]
	TIME [epoch: 6.39 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2978451307253738		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 1.2978451307253738 | validation: 0.7979842146291841]
	TIME [epoch: 6.39 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6319481251240088		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.6319481251240088 | validation: 0.36355460948966967]
	TIME [epoch: 6.4 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6228536114267963		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.6228536114267963 | validation: 0.4232325585417672]
	TIME [epoch: 6.4 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5302554923025027		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.5302554923025027 | validation: 0.5815652485336853]
	TIME [epoch: 6.4 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6972073501984204		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.6972073501984204 | validation: 0.2905081749789538]
	TIME [epoch: 6.43 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5073831923229357		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.5073831923229357 | validation: 0.724557187575708]
	TIME [epoch: 6.41 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9961481448605409		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.9961481448605409 | validation: 0.49406384354896205]
	TIME [epoch: 6.39 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5359258945852712		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.5359258945852712 | validation: 0.6015664942457536]
	TIME [epoch: 6.4 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6259970785139695		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.6259970785139695 | validation: 0.4454411355934343]
	TIME [epoch: 6.4 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5945908361219867		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.5945908361219867 | validation: 0.3616193380036603]
	TIME [epoch: 6.4 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5913849597437055		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.5913849597437055 | validation: 0.554680730979064]
	TIME [epoch: 6.4 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0649812803916194		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 1.0649812803916194 | validation: 0.747781303617534]
	TIME [epoch: 6.43 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5946164658814426		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.5946164658814426 | validation: 0.27217462686512833]
	TIME [epoch: 6.41 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48204033976983357		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.48204033976983357 | validation: 0.7207668636930918]
	TIME [epoch: 6.4 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8390200899272613		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.8390200899272613 | validation: 0.42002407834672184]
	TIME [epoch: 6.39 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5586820494087172		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.5586820494087172 | validation: 0.3951107863571228]
	TIME [epoch: 6.4 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5215244470609064		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.5215244470609064 | validation: 0.6807726101121772]
	TIME [epoch: 6.4 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7078035841935791		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7078035841935791 | validation: 0.9803351409445571]
	TIME [epoch: 6.4 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.732569558448924		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.732569558448924 | validation: 1.0208094591962589]
	TIME [epoch: 6.43 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8419795164800266		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.8419795164800266 | validation: 1.4509799845511335]
	TIME [epoch: 6.41 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7208049255803303		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.7208049255803303 | validation: 0.41781849669207743]
	TIME [epoch: 6.4 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5403071432052641		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5403071432052641 | validation: 0.5277314751238061]
	TIME [epoch: 6.4 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48943562764457615		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.48943562764457615 | validation: 0.7216400254308002]
	TIME [epoch: 6.4 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6041079064547044		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.6041079064547044 | validation: 0.943787527628395]
	TIME [epoch: 6.4 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5721587039788019		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.5721587039788019 | validation: 0.2849296992642688]
	TIME [epoch: 6.4 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6466081582307509		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.6466081582307509 | validation: 0.30001962035453406]
	TIME [epoch: 6.42 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43969154292316176		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.43969154292316176 | validation: 0.8182250373436304]
	TIME [epoch: 6.42 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5793836417988297		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.5793836417988297 | validation: 0.4539672013690782]
	TIME [epoch: 6.4 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5016371159884527		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.5016371159884527 | validation: 0.26341027146987456]
	TIME [epoch: 6.4 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5579792421744016		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.5579792421744016 | validation: 0.5328119549790494]
	TIME [epoch: 6.41 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.614379987499159		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.614379987499159 | validation: 0.30276672455428744]
	TIME [epoch: 6.4 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4577562331880782		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.4577562331880782 | validation: 0.6445712043807345]
	TIME [epoch: 6.41 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49205590049014714		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.49205590049014714 | validation: 0.47858341014712724]
	TIME [epoch: 6.42 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5842916423155253		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.5842916423155253 | validation: 0.8934672765030189]
	TIME [epoch: 6.42 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47154392656773425		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.47154392656773425 | validation: 0.18144162686922363]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6231551790356386		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.6231551790356386 | validation: 1.532142263301231]
	TIME [epoch: 6.4 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7867521143009772		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.7867521143009772 | validation: 0.3645029382947106]
	TIME [epoch: 6.4 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5757420793063868		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.5757420793063868 | validation: 0.26763727053011954]
	TIME [epoch: 6.4 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7951781963025584		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.7951781963025584 | validation: 0.3981046591938133]
	TIME [epoch: 6.4 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5936945737485676		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.5936945737485676 | validation: 0.6534208141663614]
	TIME [epoch: 6.4 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4970322948721626		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.4970322948721626 | validation: 0.2900187503803417]
	TIME [epoch: 6.44 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48341207204107534		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.48341207204107534 | validation: 0.35855002803062463]
	TIME [epoch: 6.41 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4717197193323814		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.4717197193323814 | validation: 1.3949290023824574]
	TIME [epoch: 6.4 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7890868254090787		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.7890868254090787 | validation: 0.8514091904913843]
	TIME [epoch: 6.4 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.539692238861808		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.539692238861808 | validation: 0.3738189906159838]
	TIME [epoch: 6.4 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44001702842247437		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.44001702842247437 | validation: 0.39111471159259226]
	TIME [epoch: 6.4 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4616791493478589		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.4616791493478589 | validation: 0.44240950493726594]
	TIME [epoch: 6.4 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4722902225912181		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.4722902225912181 | validation: 0.2694707034228999]
	TIME [epoch: 6.43 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6925226714641901		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.6925226714641901 | validation: 0.40495839106475406]
	TIME [epoch: 6.4 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4226117106899925		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.4226117106899925 | validation: 0.5028325717868273]
	TIME [epoch: 6.4 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.57636559884022		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.57636559884022 | validation: 0.2568493754408755]
	TIME [epoch: 6.4 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4590063213769504		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.4590063213769504 | validation: 0.26841991444348146]
	TIME [epoch: 6.4 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6996235608455411		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6996235608455411 | validation: 0.5210757890178915]
	TIME [epoch: 6.4 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4656461905245247		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.4656461905245247 | validation: 0.6487138496943838]
	TIME [epoch: 6.41 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5519619026666357		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.5519619026666357 | validation: 0.9036242304650529]
	TIME [epoch: 6.43 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05239854899372		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.05239854899372 | validation: 0.39634581646888833]
	TIME [epoch: 6.4 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6050126633033821		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.6050126633033821 | validation: 0.44254015790321505]
	TIME [epoch: 6.4 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5872781743684427		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5872781743684427 | validation: 0.2955315517954809]
	TIME [epoch: 6.4 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6034363349761215		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.6034363349761215 | validation: 0.2924605872908091]
	TIME [epoch: 6.4 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7990783107498646		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7990783107498646 | validation: 0.4989760878976833]
	TIME [epoch: 6.4 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5639715617245074		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.5639715617245074 | validation: 0.4248982704206957]
	TIME [epoch: 6.4 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4569158893474441		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.4569158893474441 | validation: 0.25881352452778467]
	TIME [epoch: 6.42 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39437337574366116		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.39437337574366116 | validation: 0.7586372148641841]
	TIME [epoch: 6.42 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6034929692682685		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.6034929692682685 | validation: 0.2843082182874439]
	TIME [epoch: 6.4 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5941160556598958		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.5941160556598958 | validation: 0.23767606820794845]
	TIME [epoch: 6.4 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6547748012054727		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.6547748012054727 | validation: 0.8046012191509244]
	TIME [epoch: 6.4 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5914615746486339		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.5914615746486339 | validation: 0.4885040218354162]
	TIME [epoch: 6.4 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5964318350378794		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5964318350378794 | validation: 0.7338860977140576]
	TIME [epoch: 6.4 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6108621176186656		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6108621176186656 | validation: 0.25387682595851657]
	TIME [epoch: 6.42 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5395795703220003		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5395795703220003 | validation: 1.3549470678504425]
	TIME [epoch: 6.42 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.717967193813928		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.717967193813928 | validation: 0.4637535162839322]
	TIME [epoch: 6.4 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301504484516065		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.5301504484516065 | validation: 0.2761969349120691]
	TIME [epoch: 6.4 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4883373447376063		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.4883373447376063 | validation: 0.4110787774257845]
	TIME [epoch: 6.4 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.484884879738782		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.484884879738782 | validation: 0.3256385871737595]
	TIME [epoch: 6.4 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42712457320533737		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.42712457320533737 | validation: 0.456455215389159]
	TIME [epoch: 6.4 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8152826913571873		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.8152826913571873 | validation: 0.7125813029162662]
	TIME [epoch: 6.4 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.537565457850348		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.537565457850348 | validation: 0.9050811340493904]
	TIME [epoch: 6.44 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5549436930278129		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.5549436930278129 | validation: 0.5713873887176466]
	TIME [epoch: 6.41 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5049256500942761		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.5049256500942761 | validation: 0.23698990782502413]
	TIME [epoch: 6.4 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33282053509977116		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.33282053509977116 | validation: 0.44032192286215677]
	TIME [epoch: 6.4 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5525047852697423		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5525047852697423 | validation: 0.6380181174445503]
	TIME [epoch: 6.4 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5361597007544229		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.5361597007544229 | validation: 0.5717838031880784]
	TIME [epoch: 6.4 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6014239664846366		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.6014239664846366 | validation: 0.3008690470475783]
	TIME [epoch: 6.4 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44662109120127913		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.44662109120127913 | validation: 0.5682657042741983]
	TIME [epoch: 6.43 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49570522804033207		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.49570522804033207 | validation: 0.7265080255489259]
	TIME [epoch: 6.41 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4705348377661639		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.4705348377661639 | validation: 0.1710022564921769]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7415609506158627		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.7415609506158627 | validation: 0.23657131409711457]
	TIME [epoch: 6.39 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32422386037779694		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.32422386037779694 | validation: 0.357984711849025]
	TIME [epoch: 6.4 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5119256370791928		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.5119256370791928 | validation: 0.36511733980226113]
	TIME [epoch: 6.4 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6382269729849218		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.6382269729849218 | validation: 1.1457617171524177]
	TIME [epoch: 6.4 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7234978817181845		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.7234978817181845 | validation: 0.2632834890178703]
	TIME [epoch: 6.42 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38937250465645623		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.38937250465645623 | validation: 0.22383946707095756]
	TIME [epoch: 6.4 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4346622091658563		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.4346622091658563 | validation: 0.30197395111472264]
	TIME [epoch: 6.39 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4629806239030625		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.4629806239030625 | validation: 0.6136941201904549]
	TIME [epoch: 6.4 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5017698589359557		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.5017698589359557 | validation: 0.41994025306090826]
	TIME [epoch: 6.39 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492835082538541		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.4492835082538541 | validation: 0.21559335475452351]
	TIME [epoch: 6.4 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49348398399785603		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.49348398399785603 | validation: 0.37476627248108835]
	TIME [epoch: 6.4 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38055955007174763		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.38055955007174763 | validation: 0.7699824112519471]
	TIME [epoch: 6.42 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7668894067441878		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.7668894067441878 | validation: 0.30967348566939285]
	TIME [epoch: 6.41 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3832881839621035		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.3832881839621035 | validation: 0.25214207893169766]
	TIME [epoch: 6.4 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4379654499661492		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.4379654499661492 | validation: 0.5223438978911445]
	TIME [epoch: 6.4 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41741074474729206		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.41741074474729206 | validation: 0.23916520250718268]
	TIME [epoch: 6.4 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5968733957370983		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.5968733957370983 | validation: 0.42425737103799804]
	TIME [epoch: 6.4 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3786567286822595		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.3786567286822595 | validation: 0.3418094424134868]
	TIME [epoch: 6.41 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36584868563491424		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.36584868563491424 | validation: 0.5477238372371559]
	TIME [epoch: 6.42 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33832136990494144		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.33832136990494144 | validation: 0.1853740899219387]
	TIME [epoch: 6.42 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4842121091527631		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.4842121091527631 | validation: 0.7700910049344998]
	TIME [epoch: 6.41 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46162814690602105		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.46162814690602105 | validation: 0.3725339350375474]
	TIME [epoch: 6.4 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3434465621276794		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.3434465621276794 | validation: 2.041130882950442]
	TIME [epoch: 6.41 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1984532387412026		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 1.1984532387412026 | validation: 1.32819592686913]
	TIME [epoch: 6.39 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0100186324791065		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 1.0100186324791065 | validation: 0.5730418844511573]
	TIME [epoch: 6.4 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.681423789264677		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.681423789264677 | validation: 0.898887062591711]
	TIME [epoch: 6.41 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6442692875996483		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.6442692875996483 | validation: 0.45439536794030866]
	TIME [epoch: 6.44 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4295500421127278		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.4295500421127278 | validation: 0.24997159750930892]
	TIME [epoch: 6.41 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47745146438189995		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.47745146438189995 | validation: 0.2877692646634583]
	TIME [epoch: 6.4 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48392810540532816		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.48392810540532816 | validation: 0.26332242432045017]
	TIME [epoch: 6.4 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32359088540219993		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.32359088540219993 | validation: 0.3218784775309721]
	TIME [epoch: 6.4 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46169081816537494		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.46169081816537494 | validation: 0.25697702914452075]
	TIME [epoch: 6.38 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4186067073593972		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.4186067073593972 | validation: 0.1492470431957544]
	TIME [epoch: 6.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4350215168537854		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.4350215168537854 | validation: 0.9217140468018752]
	TIME [epoch: 6.41 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.529587464608213		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.529587464608213 | validation: 0.5660273349497966]
	TIME [epoch: 6.38 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5615882433478094		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.5615882433478094 | validation: 0.3244912064664927]
	TIME [epoch: 6.38 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38114169925995345		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.38114169925995345 | validation: 0.22266013158457945]
	TIME [epoch: 6.38 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34402213581305263		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.34402213581305263 | validation: 0.22067596606190085]
	TIME [epoch: 6.38 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35116628195861227		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.35116628195861227 | validation: 0.14866116590231315]
	TIME [epoch: 6.37 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_379.pth
	Model improved!!!
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32261132786981184		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.32261132786981184 | validation: 0.4311356242328062]
	TIME [epoch: 6.37 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3808162831114037		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.3808162831114037 | validation: 0.13059425882008813]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.350651191102988		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.350651191102988 | validation: 0.3346952501361908]
	TIME [epoch: 6.38 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36931224963067877		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.36931224963067877 | validation: 0.5650221678016104]
	TIME [epoch: 6.38 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.370407626232073		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.370407626232073 | validation: 0.21705330220903774]
	TIME [epoch: 6.38 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29461941122797963		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.29461941122797963 | validation: 0.1655403088685243]
	TIME [epoch: 6.37 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25278744075672865		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.25278744075672865 | validation: 0.16090992200192883]
	TIME [epoch: 6.38 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6898679709927715		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.6898679709927715 | validation: 0.2507525351246524]
	TIME [epoch: 6.37 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3109459554426384		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.3109459554426384 | validation: 0.5843212885018596]
	TIME [epoch: 6.41 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3622614503090872		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.3622614503090872 | validation: 0.30045717917282605]
	TIME [epoch: 6.39 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36492257954152696		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.36492257954152696 | validation: 0.5586131137482577]
	TIME [epoch: 6.38 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33743200585036187		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.33743200585036187 | validation: 0.26214622091315554]
	TIME [epoch: 6.39 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3061905637229384		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.3061905637229384 | validation: 0.3566425838550225]
	TIME [epoch: 6.4 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3796906957754666		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.3796906957754666 | validation: 0.17081479291625043]
	TIME [epoch: 6.4 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2550154289206931		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.2550154289206931 | validation: 0.4968535385112459]
	TIME [epoch: 6.4 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32865751234457025		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.32865751234457025 | validation: 1.9995399584613134]
	TIME [epoch: 6.42 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8499117254310503		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.8499117254310503 | validation: 0.2404132823703581]
	TIME [epoch: 6.41 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2773307278648186		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.2773307278648186 | validation: 0.3978733849190026]
	TIME [epoch: 6.4 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39736959961717533		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.39736959961717533 | validation: 0.3479614438533447]
	TIME [epoch: 6.4 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3752482992368071		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.3752482992368071 | validation: 0.32344300806441617]
	TIME [epoch: 6.41 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3352250387507591		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.3352250387507591 | validation: 0.9279173525406985]
	TIME [epoch: 6.41 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644944329344707		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.5644944329344707 | validation: 0.3206868963855196]
	TIME [epoch: 6.41 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4130501912666057		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.4130501912666057 | validation: 0.13115788932585962]
	TIME [epoch: 6.4 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25315525404272143		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.25315525404272143 | validation: 0.14991145987553067]
	TIME [epoch: 6.44 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6284243089567529		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.6284243089567529 | validation: 0.28192768259110396]
	TIME [epoch: 6.41 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3336549585664622		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.3336549585664622 | validation: 0.11463697722670134]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_405.pth
	Model improved!!!
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5423946176753411		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.5423946176753411 | validation: 0.17686735319044672]
	TIME [epoch: 6.41 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5240433746349351		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5240433746349351 | validation: 0.14355928823041794]
	TIME [epoch: 6.41 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36108302917896107		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.36108302917896107 | validation: 0.585912850194835]
	TIME [epoch: 6.41 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419355964480963		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.4419355964480963 | validation: 0.30058309049532544]
	TIME [epoch: 6.41 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3540064099464598		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.3540064099464598 | validation: 0.46452610956542717]
	TIME [epoch: 6.44 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3388558443365846		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.3388558443365846 | validation: 0.43012612431948505]
	TIME [epoch: 6.41 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40555414329652134		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.40555414329652134 | validation: 0.15706003577644428]
	TIME [epoch: 6.4 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2550700607674548		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.2550700607674548 | validation: 0.6939117102210858]
	TIME [epoch: 6.41 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7167840013549448		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.7167840013549448 | validation: 0.6671534615313476]
	TIME [epoch: 6.4 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42396347814442403		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.42396347814442403 | validation: 0.26412104690155164]
	TIME [epoch: 6.4 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2605909807649166		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.2605909807649166 | validation: 0.14330284335504584]
	TIME [epoch: 6.41 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4602652004443709		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.4602652004443709 | validation: 0.288475941675376]
	TIME [epoch: 6.44 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41559636857860965		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.41559636857860965 | validation: 0.38783161536168087]
	TIME [epoch: 6.41 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.308043692045388		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.308043692045388 | validation: 0.2013434956709351]
	TIME [epoch: 6.41 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26744162219261397		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.26744162219261397 | validation: 0.6963044561190429]
	TIME [epoch: 6.41 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44633283824203784		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.44633283824203784 | validation: 0.12568587499853082]
	TIME [epoch: 6.41 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36646046036868773		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.36646046036868773 | validation: 0.20200562506020717]
	TIME [epoch: 6.41 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44810841963833686		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.44810841963833686 | validation: 0.15838197840917265]
	TIME [epoch: 6.4 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30576708860012886		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.30576708860012886 | validation: 0.23182773904322018]
	TIME [epoch: 6.43 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.487912821544048		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.487912821544048 | validation: 0.22656725022006705]
	TIME [epoch: 6.42 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32602500545577107		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.32602500545577107 | validation: 0.5020747970412663]
	TIME [epoch: 6.41 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4892553435702417		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.4892553435702417 | validation: 0.2360314498355249]
	TIME [epoch: 6.41 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37167012817074535		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.37167012817074535 | validation: 0.1819584043833279]
	TIME [epoch: 6.4 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27808889127122066		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.27808889127122066 | validation: 0.13089463891687697]
	TIME [epoch: 6.41 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3692584138855548		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.3692584138855548 | validation: 0.5818972798370746]
	TIME [epoch: 6.4 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8749592538677565		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.8749592538677565 | validation: 0.8002453324029031]
	TIME [epoch: 6.42 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6281209015212604		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.6281209015212604 | validation: 0.5263191618411603]
	TIME [epoch: 6.42 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5366653312902786		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.5366653312902786 | validation: 0.2706141011494059]
	TIME [epoch: 6.41 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3459079495952255		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.3459079495952255 | validation: 0.31192041546519883]
	TIME [epoch: 6.4 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29935283131681634		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.29935283131681634 | validation: 1.095998048645174]
	TIME [epoch: 6.4 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.688438555515919		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.688438555515919 | validation: 0.2755201975402328]
	TIME [epoch: 6.4 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3564330449872669		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.3564330449872669 | validation: 0.8027659472607426]
	TIME [epoch: 6.4 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42050657955208937		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.42050657955208937 | validation: 0.7929484231353245]
	TIME [epoch: 6.42 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409689113366485		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.409689113366485 | validation: 0.16522184250160904]
	TIME [epoch: 6.42 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47497981039306464		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.47497981039306464 | validation: 0.6252686667009156]
	TIME [epoch: 6.41 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4411514033385745		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.4411514033385745 | validation: 0.18039422675939382]
	TIME [epoch: 6.4 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29124275479280476		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.29124275479280476 | validation: 0.17986763403615072]
	TIME [epoch: 6.41 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24308020310376904		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.24308020310376904 | validation: 0.3187701211882117]
	TIME [epoch: 6.41 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39220436043564627		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.39220436043564627 | validation: 0.4054728474733281]
	TIME [epoch: 6.4 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33474175474484574		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.33474175474484574 | validation: 0.2978085374766963]
	TIME [epoch: 6.41 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5552761354675007		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.5552761354675007 | validation: 0.21915399438200703]
	TIME [epoch: 6.43 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2980047775514409		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 0.2980047775514409 | validation: 0.5235773012025823]
	TIME [epoch: 6.41 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3853586702613341		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.3853586702613341 | validation: 0.1782002219553541]
	TIME [epoch: 6.4 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24013058330850617		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.24013058330850617 | validation: 0.34827329095104104]
	TIME [epoch: 6.4 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3641462788141351		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.3641462788141351 | validation: 0.8142679393185518]
	TIME [epoch: 6.41 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528444488011625		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.4528444488011625 | validation: 0.35807685253942156]
	TIME [epoch: 6.41 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3940136953348692		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.3940136953348692 | validation: 0.13683937662619883]
	TIME [epoch: 6.4 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39056029578051393		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.39056029578051393 | validation: 0.25817514048099144]
	TIME [epoch: 6.44 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40968375552747205		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.40968375552747205 | validation: 0.5575345523757228]
	TIME [epoch: 6.41 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4415148276470832		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.4415148276470832 | validation: 0.26831556867350975]
	TIME [epoch: 6.41 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2827040853451661		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.2827040853451661 | validation: 0.2269224226479232]
	TIME [epoch: 6.4 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3240933781848533		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.3240933781848533 | validation: 0.22939485604877355]
	TIME [epoch: 6.4 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26740163190992444		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.26740163190992444 | validation: 0.11487659220058433]
	TIME [epoch: 6.4 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28470789988655915		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.28470789988655915 | validation: 0.5545337206509807]
	TIME [epoch: 6.4 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46447396353468207		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.46447396353468207 | validation: 0.20606635455639213]
	TIME [epoch: 6.43 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44988185515413026		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.44988185515413026 | validation: 0.8553266583005288]
	TIME [epoch: 6.41 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4395800923572215		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.4395800923572215 | validation: 0.18808689672451354]
	TIME [epoch: 6.4 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4188883970093194		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.4188883970093194 | validation: 0.18393964538688018]
	TIME [epoch: 6.4 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2771422180752799		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.2771422180752799 | validation: 0.12665332930111603]
	TIME [epoch: 6.4 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34324264165616136		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.34324264165616136 | validation: 0.49907249425976374]
	TIME [epoch: 6.39 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3566289372310208		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.3566289372310208 | validation: 0.24019756566546954]
	TIME [epoch: 6.4 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23318699058240047		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.23318699058240047 | validation: 0.3341044169164104]
	TIME [epoch: 6.42 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3011481838897202		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.3011481838897202 | validation: 0.2323142411133111]
	TIME [epoch: 6.42 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34631219993331475		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.34631219993331475 | validation: 0.1514424313008223]
	TIME [epoch: 6.4 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2489620126852251		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.2489620126852251 | validation: 0.32742150971500267]
	TIME [epoch: 6.4 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25419701855859295		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.25419701855859295 | validation: 0.3864537262357155]
	TIME [epoch: 6.4 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28500124550694866		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.28500124550694866 | validation: 0.8921932690908453]
	TIME [epoch: 6.39 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5497618943773388		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.5497618943773388 | validation: 0.14305193839082722]
	TIME [epoch: 6.4 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43625555472693456		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.43625555472693456 | validation: 0.38855181157781443]
	TIME [epoch: 6.4 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.327491159471029		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.327491159471029 | validation: 0.20289203923673108]
	TIME [epoch: 6.43 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2442249460071219		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.2442249460071219 | validation: 0.16366992348109777]
	TIME [epoch: 6.41 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35930849280671473		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.35930849280671473 | validation: 0.1511827023272131]
	TIME [epoch: 6.4 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23977028041344256		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.23977028041344256 | validation: 0.5368521915534197]
	TIME [epoch: 6.4 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3808860792251929		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.3808860792251929 | validation: 0.20015991400375363]
	TIME [epoch: 6.4 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4088267091339862		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.4088267091339862 | validation: 0.3424581460542618]
	TIME [epoch: 6.4 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373764357528797		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.373764357528797 | validation: 0.1418809438218625]
	TIME [epoch: 6.4 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25277916465615635		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.25277916465615635 | validation: 0.6258996253398758]
	TIME [epoch: 6.44 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3879174582619525		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.3879174582619525 | validation: 0.1153608528643813]
	TIME [epoch: 6.4 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20630431386444567		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.20630431386444567 | validation: 0.28585421314234155]
	TIME [epoch: 6.4 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.514380717617176		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.514380717617176 | validation: 0.6298686396853381]
	TIME [epoch: 6.4 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5648396334165854		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.5648396334165854 | validation: 0.27944610618118837]
	TIME [epoch: 6.4 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37821468984662876		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.37821468984662876 | validation: 0.33590274325300334]
	TIME [epoch: 6.4 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3576325106848936		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.3576325106848936 | validation: 0.18827758383576693]
	TIME [epoch: 6.4 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704482490506004		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.2704482490506004 | validation: 0.46072058483983386]
	TIME [epoch: 6.44 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3610055132784455		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.3610055132784455 | validation: 0.30154112815969214]
	TIME [epoch: 6.4 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25279209481541065		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.25279209481541065 | validation: 0.23623787415837302]
	TIME [epoch: 6.4 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3942143650342199		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.3942143650342199 | validation: 0.12190324680344099]
	TIME [epoch: 6.4 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3112519260480119		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.3112519260480119 | validation: 0.24532348309647822]
	TIME [epoch: 6.4 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30803600970125244		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.30803600970125244 | validation: 0.24304145781003267]
	TIME [epoch: 6.4 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2556986398859354		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.2556986398859354 | validation: 0.18826041418977937]
	TIME [epoch: 6.4 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26945841789016906		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.26945841789016906 | validation: 0.5966920401351646]
	TIME [epoch: 6.43 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38425144034634384		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.38425144034634384 | validation: 0.2422248499822565]
	TIME [epoch: 6.41 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21696513837425174		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.21696513837425174 | validation: 0.2759153853114909]
	TIME [epoch: 6.4 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24348161606553562		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.24348161606553562 | validation: 0.8806187607828498]
	TIME [epoch: 6.4 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46604540115913495		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.46604540115913495 | validation: 0.20646965730048217]
	TIME [epoch: 6.4 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23492083803119015		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.23492083803119015 | validation: 0.18664112726923665]
	TIME [epoch: 6.4 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2861024921011907		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.2861024921011907 | validation: 0.13586318379144444]
	TIME [epoch: 6.4 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3040873327369263		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.3040873327369263 | validation: 0.16964342298877305]
	TIME [epoch: 6.42 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.327249762649469		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.327249762649469 | validation: 0.2520512503596728]
	TIME [epoch: 6.42 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3344210239999732		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.3344210239999732 | validation: 0.13243161976747264]
	TIME [epoch: 6.4 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2627786631568389		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.2627786631568389 | validation: 0.1868500520740338]
	TIME [epoch: 6.4 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943187929289118		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.2943187929289118 | validation: 0.220099375904194]
	TIME [epoch: 6.4 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1935791190137057		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.1935791190137057 | validation: 0.2818856003865357]
	TIME [epoch: 6.4 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3564732883577755		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.3564732883577755 | validation: 0.148493353984109]
	TIME [epoch: 6.4 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38165011593494286		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.38165011593494286 | validation: 0.15459724077058165]
	TIME [epoch: 6.4 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2259390130801934		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.2259390130801934 | validation: 0.12193671720206674]
	TIME [epoch: 6.43 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1910284349924274		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.1910284349924274 | validation: 0.14597681321758957]
	TIME [epoch: 6.4 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23977867813626477		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.23977867813626477 | validation: 0.4777158029700636]
	TIME [epoch: 6.4 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30260409982797926		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.30260409982797926 | validation: 0.25883035328483467]
	TIME [epoch: 6.4 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3361548791090234		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.3361548791090234 | validation: 0.36541269343755195]
	TIME [epoch: 6.4 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25081364557208546		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.25081364557208546 | validation: 0.26889649568402685]
	TIME [epoch: 6.4 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2825510166764487		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.2825510166764487 | validation: 0.12220150811822628]
	TIME [epoch: 6.4 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22697829829374808		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.22697829829374808 | validation: 0.345257279885513]
	TIME [epoch: 6.44 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38970270354991227		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.38970270354991227 | validation: 0.21990786767955395]
	TIME [epoch: 6.4 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27061252732464675		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.27061252732464675 | validation: 0.21340499149002656]
	TIME [epoch: 6.4 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3770982260935255		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.3770982260935255 | validation: 0.23256208468755313]
	TIME [epoch: 6.4 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34290458876585084		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.34290458876585084 | validation: 0.43283474888650597]
	TIME [epoch: 6.4 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3675552725719473		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.3675552725719473 | validation: 0.16831888928183708]
	TIME [epoch: 6.4 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25712794837070285		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.25712794837070285 | validation: 0.3265341048426933]
	TIME [epoch: 6.4 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31081489714610827		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.31081489714610827 | validation: 0.42662546742505647]
	TIME [epoch: 6.44 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45501442043791557		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.45501442043791557 | validation: 0.2689713206630705]
	TIME [epoch: 6.4 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23018001632509888		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.23018001632509888 | validation: 0.3357509852246182]
	TIME [epoch: 6.4 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2831895741944029		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.2831895741944029 | validation: 0.1767920327157858]
	TIME [epoch: 6.4 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19959078458359497		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.19959078458359497 | validation: 0.4156225483288584]
	TIME [epoch: 6.4 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3516154201732172		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.3516154201732172 | validation: 0.16939012195823708]
	TIME [epoch: 6.4 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2793501398021803		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.2793501398021803 | validation: 0.13216460783027958]
	TIME [epoch: 6.41 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21583628848071454		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.21583628848071454 | validation: 0.11331782279368195]
	TIME [epoch: 6.43 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_532.pth
	Model improved!!!
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1842148211565911		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.1842148211565911 | validation: 0.20325949031274135]
	TIME [epoch: 6.41 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.353334901123865		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.353334901123865 | validation: 0.28910528111520334]
	TIME [epoch: 6.4 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22683932059365194		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.22683932059365194 | validation: 0.18845379614962052]
	TIME [epoch: 6.41 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18307407229648803		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.18307407229648803 | validation: 0.20047475480178528]
	TIME [epoch: 6.41 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22749682761035744		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.22749682761035744 | validation: 0.34107088990034873]
	TIME [epoch: 6.41 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23714575075502511		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.23714575075502511 | validation: 0.09551859239639242]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_538.pth
	Model improved!!!
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17374819808183933		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.17374819808183933 | validation: 0.17332947465731452]
	TIME [epoch: 6.43 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26141220902398166		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.26141220902398166 | validation: 0.5952504939227059]
	TIME [epoch: 6.4 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36173999669583135		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.36173999669583135 | validation: 0.2283339800959535]
	TIME [epoch: 6.4 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32904405097956957		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.32904405097956957 | validation: 0.3509177940175057]
	TIME [epoch: 6.4 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3555474212955603		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.3555474212955603 | validation: 0.5031752881274346]
	TIME [epoch: 6.4 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2708275763578463		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.2708275763578463 | validation: 0.1327404580308133]
	TIME [epoch: 6.4 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2822545846450804		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.2822545846450804 | validation: 0.16840120179343976]
	TIME [epoch: 6.4 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22043506156494913		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.22043506156494913 | validation: 0.3730455023361792]
	TIME [epoch: 6.42 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957559833981925		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.3957559833981925 | validation: 0.2916008377185341]
	TIME [epoch: 6.42 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32233298108527153		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.32233298108527153 | validation: 0.11505190959139934]
	TIME [epoch: 6.41 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.197513470333477		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.197513470333477 | validation: 0.24012644145789505]
	TIME [epoch: 6.4 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2392583661834748		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.2392583661834748 | validation: 0.11724897243122982]
	TIME [epoch: 6.41 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17458556755892973		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.17458556755892973 | validation: 0.2667561503820892]
	TIME [epoch: 6.4 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2050193195874107		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.2050193195874107 | validation: 0.11440399976724555]
	TIME [epoch: 6.41 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20398631475411227		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.20398631475411227 | validation: 0.165357193040842]
	TIME [epoch: 6.41 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1931491119250084		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.1931491119250084 | validation: 0.30448066384470934]
	TIME [epoch: 6.44 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25174974368325237		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.25174974368325237 | validation: 0.18596627799202042]
	TIME [epoch: 6.4 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1621914147549786		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.1621914147549786 | validation: 0.11056407543718443]
	TIME [epoch: 6.41 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16415666474818863		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.16415666474818863 | validation: 0.1830739826822186]
	TIME [epoch: 6.4 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2896343122235554		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.2896343122235554 | validation: 0.33019048908233695]
	TIME [epoch: 6.4 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26575549812271904		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.26575549812271904 | validation: 0.4715349000670157]
	TIME [epoch: 6.4 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33006698962836273		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.33006698962836273 | validation: 0.11029878738079156]
	TIME [epoch: 6.4 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33732741710022734		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.33732741710022734 | validation: 0.12358562431984223]
	TIME [epoch: 6.44 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2393932084712319		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.2393932084712319 | validation: 0.16994217312989748]
	TIME [epoch: 6.4 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18062281645728373		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.18062281645728373 | validation: 0.20209963110461956]
	TIME [epoch: 6.41 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16471366909169846		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.16471366909169846 | validation: 0.41834976919188477]
	TIME [epoch: 6.4 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32237771589906833		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.32237771589906833 | validation: 0.17958911991086893]
	TIME [epoch: 6.4 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17757693400567698		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.17757693400567698 | validation: 0.11139604175167091]
	TIME [epoch: 6.4 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21862107937343284		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.21862107937343284 | validation: 0.20866965982567603]
	TIME [epoch: 6.4 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2715708276895765		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.2715708276895765 | validation: 0.8348978717733546]
	TIME [epoch: 6.44 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3791505807158148		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.3791505807158148 | validation: 0.11214003209145591]
	TIME [epoch: 6.41 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19552549902321076		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.19552549902321076 | validation: 0.4030412389197923]
	TIME [epoch: 6.41 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2641799152477325		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.2641799152477325 | validation: 0.29060151821782587]
	TIME [epoch: 6.4 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2648747870900956		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.2648747870900956 | validation: 0.171063038558414]
	TIME [epoch: 6.4 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17589817415279463		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.17589817415279463 | validation: 0.14946751128855224]
	TIME [epoch: 6.4 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20424953756055203		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.20424953756055203 | validation: 0.14498200989451654]
	TIME [epoch: 6.41 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2393012022863669		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.2393012022863669 | validation: 0.17724514669538166]
	TIME [epoch: 6.44 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26385084311499396		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.26385084311499396 | validation: 0.1416099154719475]
	TIME [epoch: 6.41 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1964761263952523		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.1964761263952523 | validation: 0.18835374694259863]
	TIME [epoch: 6.4 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23318319369736973		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.23318319369736973 | validation: 0.1538406153883707]
	TIME [epoch: 6.4 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1613230428247419		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.1613230428247419 | validation: 0.12982911259115043]
	TIME [epoch: 6.41 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16242301729149672		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.16242301729149672 | validation: 0.09672455990819774]
	TIME [epoch: 6.4 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22885591566353863		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.22885591566353863 | validation: 0.06465611634804516]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_581.pth
	Model improved!!!
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13999553299376213		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.13999553299376213 | validation: 0.20400646112588605]
	TIME [epoch: 6.42 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31598739935339215		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.31598739935339215 | validation: 0.1692597632179569]
	TIME [epoch: 6.42 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16613920375657823		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.16613920375657823 | validation: 0.21398667290931842]
	TIME [epoch: 6.41 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21761902370999786		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.21761902370999786 | validation: 0.19031079983356042]
	TIME [epoch: 6.4 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16294524575720531		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.16294524575720531 | validation: 0.35711048113883587]
	TIME [epoch: 6.4 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31387208650866194		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.31387208650866194 | validation: 0.22587148714795505]
	TIME [epoch: 6.4 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15590473209965586		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.15590473209965586 | validation: 0.41722146160897544]
	TIME [epoch: 6.4 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18225232296346755		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.18225232296346755 | validation: 0.24273167637486665]
	TIME [epoch: 6.42 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21571778583482493		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.21571778583482493 | validation: 0.10192739053382523]
	TIME [epoch: 6.42 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652972984802831		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.3652972984802831 | validation: 0.2438921595584059]
	TIME [epoch: 6.4 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1845453964861802		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.1845453964861802 | validation: 0.23129659731694346]
	TIME [epoch: 6.4 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17060329462995538		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.17060329462995538 | validation: 0.3073611365726476]
	TIME [epoch: 6.4 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2428788579433375		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.2428788579433375 | validation: 0.09211024332142032]
	TIME [epoch: 6.4 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.354077767353127		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.354077767353127 | validation: 0.15786622211226914]
	TIME [epoch: 6.4 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24567854841794418		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.24567854841794418 | validation: 0.15027294749420583]
	TIME [epoch: 6.4 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1844417905318378		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.1844417905318378 | validation: 0.2532142752638424]
	TIME [epoch: 6.43 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.191422943234777		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.191422943234777 | validation: 0.16042270407637937]
	TIME [epoch: 6.4 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14263191260799274		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.14263191260799274 | validation: 0.18063158905149115]
	TIME [epoch: 6.4 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14206419912699297		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.14206419912699297 | validation: 0.40465145908542616]
	TIME [epoch: 6.5 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.204543603035405		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.204543603035405 | validation: 0.10577297275732056]
	TIME [epoch: 6.4 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12749943451823378		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.12749943451823378 | validation: 0.0947970527226666]
	TIME [epoch: 6.4 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12354890099134433		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.12354890099134433 | validation: 0.18937302712379478]
	TIME [epoch: 6.4 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21951425100894018		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.21951425100894018 | validation: 0.3033888797565193]
	TIME [epoch: 6.43 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3661249745185806		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.3661249745185806 | validation: 0.24904225673818992]
	TIME [epoch: 6.4 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45007631301554807		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.45007631301554807 | validation: 0.19894695609694765]
	TIME [epoch: 6.4 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18888384788444657		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.18888384788444657 | validation: 0.24608901736603486]
	TIME [epoch: 6.4 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24535753986021663		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.24535753986021663 | validation: 0.12605548111127132]
	TIME [epoch: 6.4 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593518521815724		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.1593518521815724 | validation: 0.12549281732350967]
	TIME [epoch: 6.4 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17589891070001296		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.17589891070001296 | validation: 0.21388644803172413]
	TIME [epoch: 6.4 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1593393486924703		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.1593393486924703 | validation: 0.10664781797895957]
	TIME [epoch: 6.43 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14371295875881449		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.14371295875881449 | validation: 0.14206746285228808]
	TIME [epoch: 6.41 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18712003451239514		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.18712003451239514 | validation: 0.23413122227714886]
	TIME [epoch: 6.4 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2943044921034915		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.2943044921034915 | validation: 0.24490297209911482]
	TIME [epoch: 6.4 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1820854737498136		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.1820854737498136 | validation: 0.13713642011748153]
	TIME [epoch: 6.4 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25743123164322085		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.25743123164322085 | validation: 0.3384744867178738]
	TIME [epoch: 6.4 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2564893653305543		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.2564893653305543 | validation: 0.18955122964447463]
	TIME [epoch: 6.4 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18992429626095497		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.18992429626095497 | validation: 0.1524518315670832]
	TIME [epoch: 6.42 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1641054380141704		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.1641054380141704 | validation: 0.1888354322404141]
	TIME [epoch: 6.42 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23140797193008913		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.23140797193008913 | validation: 0.1312379079821848]
	TIME [epoch: 6.41 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26638246386601483		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.26638246386601483 | validation: 0.10779171006255231]
	TIME [epoch: 6.4 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21446268987184985		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.21446268987184985 | validation: 0.08727703261045917]
	TIME [epoch: 6.4 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13879732936648947		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.13879732936648947 | validation: 0.05682742176347641]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_623.pth
	Model improved!!!
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1081067319572808		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.1081067319572808 | validation: 0.23813764693709452]
	TIME [epoch: 6.41 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20550267449612145		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.20550267449612145 | validation: 0.1924240500163994]
	TIME [epoch: 6.42 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19915295521255996		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.19915295521255996 | validation: 0.21886527858341204]
	TIME [epoch: 6.43 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17852156935018818		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.17852156935018818 | validation: 0.09835830696139562]
	TIME [epoch: 6.41 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19938883461061496		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.19938883461061496 | validation: 0.20185690354562957]
	TIME [epoch: 6.4 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20923141722565258		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.20923141722565258 | validation: 0.1506977941448789]
	TIME [epoch: 6.4 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.173129069102752		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.173129069102752 | validation: 0.13310739401920776]
	TIME [epoch: 6.41 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11951811297984578		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.11951811297984578 | validation: 0.155769714374833]
	TIME [epoch: 6.4 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23826720987929345		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.23826720987929345 | validation: 0.36520343827428986]
	TIME [epoch: 6.4 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19541841300169083		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.19541841300169083 | validation: 0.06938301552336083]
	TIME [epoch: 6.43 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12487194818160605		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.12487194818160605 | validation: 0.20908092651792667]
	TIME [epoch: 6.41 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21604359991477093		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.21604359991477093 | validation: 0.4042233211276681]
	TIME [epoch: 6.4 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22676193427814847		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.22676193427814847 | validation: 0.1721982774960715]
	TIME [epoch: 6.4 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20480799370830363		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.20480799370830363 | validation: 0.18142107861515477]
	TIME [epoch: 6.41 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24308604510109957		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.24308604510109957 | validation: 0.3698846250168851]
	TIME [epoch: 6.4 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1680733585308805		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.1680733585308805 | validation: 0.19473347215439837]
	TIME [epoch: 6.4 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20141470180892498		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.20141470180892498 | validation: 0.3434395033525356]
	TIME [epoch: 6.44 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18082794329646457		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.18082794329646457 | validation: 0.21666554559560441]
	TIME [epoch: 6.41 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25367890858751235		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.25367890858751235 | validation: 0.5026753015274096]
	TIME [epoch: 6.4 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2622876671699454		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.2622876671699454 | validation: 0.23557260311807995]
	TIME [epoch: 6.4 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24923414235140467		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.24923414235140467 | validation: 0.1721387497701299]
	TIME [epoch: 6.4 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17973021751273938		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.17973021751273938 | validation: 0.0995205878223844]
	TIME [epoch: 6.4 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14876062969139545		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.14876062969139545 | validation: 0.07704409989667002]
	TIME [epoch: 6.41 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1829239215177405		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.1829239215177405 | validation: 0.18784618387737123]
	TIME [epoch: 6.44 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12962102584619817		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.12962102584619817 | validation: 0.16582781441638716]
	TIME [epoch: 6.41 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15732760652753916		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.15732760652753916 | validation: 0.1401440182955709]
	TIME [epoch: 6.4 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14147997116993402		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.14147997116993402 | validation: 0.3239557064678071]
	TIME [epoch: 6.41 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1796424012506519		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.1796424012506519 | validation: 0.2516147973225792]
	TIME [epoch: 6.41 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19149024859449532		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.19149024859449532 | validation: 0.061624366096424195]
	TIME [epoch: 6.4 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11289161932350969		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.11289161932350969 | validation: 0.31107195543394656]
	TIME [epoch: 6.41 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29006767567660247		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.29006767567660247 | validation: 0.21890975933417836]
	TIME [epoch: 6.44 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18609460615981785		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.18609460615981785 | validation: 0.10567994916518235]
	TIME [epoch: 6.41 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16403947365657878		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.16403947365657878 | validation: 0.09840360954214926]
	TIME [epoch: 6.41 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12386395774044469		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.12386395774044469 | validation: 0.1576422260346013]
	TIME [epoch: 6.41 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15334101775799747		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.15334101775799747 | validation: 0.11567966113332918]
	TIME [epoch: 6.41 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13518640321826858		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.13518640321826858 | validation: 0.04255256289731943]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_659.pth
	Model improved!!!
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17877821103769365		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.17877821103769365 | validation: 0.5159515870264169]
	TIME [epoch: 6.41 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.253139886956762		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.253139886956762 | validation: 0.1482952876483428]
	TIME [epoch: 6.42 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14475959340082337		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.14475959340082337 | validation: 0.050181309941341866]
	TIME [epoch: 6.42 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.098106573995537		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.098106573995537 | validation: 0.20301761865569365]
	TIME [epoch: 6.42 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19596562680760485		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.19596562680760485 | validation: 0.0849388889766501]
	TIME [epoch: 6.41 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11198386320895473		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.11198386320895473 | validation: 0.11347837550376451]
	TIME [epoch: 6.41 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1431459652380776		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.1431459652380776 | validation: 0.06599383109000997]
	TIME [epoch: 6.41 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17431542983521814		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.17431542983521814 | validation: 0.40524408381634885]
	TIME [epoch: 6.41 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651640674248427		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.2651640674248427 | validation: 0.08199730374496884]
	TIME [epoch: 6.42 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12658723750778278		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.12658723750778278 | validation: 0.17988034615441018]
	TIME [epoch: 6.43 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15328996234741443		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.15328996234741443 | validation: 0.08422208770171455]
	TIME [epoch: 6.41 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20026216530105356		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.20026216530105356 | validation: 0.08056225883594738]
	TIME [epoch: 6.41 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13757896730012945		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.13757896730012945 | validation: 0.1012303742689153]
	TIME [epoch: 6.41 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1122173458581239		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.1122173458581239 | validation: 0.3594584763740187]
	TIME [epoch: 6.41 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19488840323354092		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.19488840323354092 | validation: 0.15047095607208022]
	TIME [epoch: 6.41 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18706106786809368		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.18706106786809368 | validation: 0.08264259954406274]
	TIME [epoch: 6.41 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13200221550585134		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.13200221550585134 | validation: 0.049326295151175314]
	TIME [epoch: 6.45 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10854591632787858		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.10854591632787858 | validation: 0.13772562556649592]
	TIME [epoch: 6.42 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12740710129016433		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.12740710129016433 | validation: 0.06810383840315658]
	TIME [epoch: 6.41 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22174916115360982		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.22174916115360982 | validation: 0.3959421546665632]
	TIME [epoch: 6.41 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16108531483136024		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.16108531483136024 | validation: 0.09718602475523304]
	TIME [epoch: 6.41 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14970982971440785		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.14970982971440785 | validation: 0.05600119747656014]
	TIME [epoch: 6.41 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26441797563917613		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.26441797563917613 | validation: 0.20852232728602513]
	TIME [epoch: 6.41 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21073560375919065		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.21073560375919065 | validation: 0.150739984706043]
	TIME [epoch: 6.44 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14087121675695058		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.14087121675695058 | validation: 0.09584355838594284]
	TIME [epoch: 6.41 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19575085834884337		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.19575085834884337 | validation: 0.20032740898414939]
	TIME [epoch: 6.41 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11630887582054217		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.11630887582054217 | validation: 0.24714252302907952]
	TIME [epoch: 6.41 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1500720872119092		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.1500720872119092 | validation: 0.09662703676655213]
	TIME [epoch: 6.41 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20678340756243357		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.20678340756243357 | validation: 0.19122138649501721]
	TIME [epoch: 6.4 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16083570414016815		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.16083570414016815 | validation: 0.16258963044161898]
	TIME [epoch: 6.4 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20168001672048114		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.20168001672048114 | validation: 0.044149447978508664]
	TIME [epoch: 6.43 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13939081037005202		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.13939081037005202 | validation: 0.40320409165531035]
	TIME [epoch: 6.42 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20079715407956436		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.20079715407956436 | validation: 0.10064144769113063]
	TIME [epoch: 6.41 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13074566166427987		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.13074566166427987 | validation: 0.20305015953880737]
	TIME [epoch: 6.41 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19126283470158323		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.19126283470158323 | validation: 0.3347189361502598]
	TIME [epoch: 6.41 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22271829822895842		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.22271829822895842 | validation: 0.20873264989578702]
	TIME [epoch: 6.41 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14227052157138695		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.14227052157138695 | validation: 0.06246626005567351]
	TIME [epoch: 6.41 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09264633013034328		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.09264633013034328 | validation: 0.12025197523658943]
	TIME [epoch: 6.43 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24207354171480558		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.24207354171480558 | validation: 0.05298124064440026]
	TIME [epoch: 6.42 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16651912764198956		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.16651912764198956 | validation: 0.28964101880496573]
	TIME [epoch: 6.41 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35737343825549905		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.35737343825549905 | validation: 0.1449832821301029]
	TIME [epoch: 6.41 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21928028815552872		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.21928028815552872 | validation: 0.1877919483592052]
	TIME [epoch: 6.41 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16306813836739653		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.16306813836739653 | validation: 0.11270115241911556]
	TIME [epoch: 6.41 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09589411301351823		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.09589411301351823 | validation: 0.11150364040134689]
	TIME [epoch: 6.41 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1542443570055839		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.1542443570055839 | validation: 0.13390838436893923]
	TIME [epoch: 6.43 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17156033271363963		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.17156033271363963 | validation: 0.05381450041208467]
	TIME [epoch: 6.43 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10188412573469507		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.10188412573469507 | validation: 0.16663748569566886]
	TIME [epoch: 6.41 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35382115863908326		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.35382115863908326 | validation: 0.0720119436036304]
	TIME [epoch: 6.4 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09069286601155328		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.09069286601155328 | validation: 0.07634800589731888]
	TIME [epoch: 6.41 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14156753124762073		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.14156753124762073 | validation: 0.44765101039653477]
	TIME [epoch: 6.41 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25905684914552063		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.25905684914552063 | validation: 0.16786650410844847]
	TIME [epoch: 6.4 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14665633835776498		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.14665633835776498 | validation: 0.09444363028662778]
	TIME [epoch: 6.41 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11024753555851687		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.11024753555851687 | validation: 0.2844905356906874]
	TIME [epoch: 6.44 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17162990668907657		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.17162990668907657 | validation: 0.09456630793302907]
	TIME [epoch: 6.41 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09789278136597612		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.09789278136597612 | validation: 0.20010317540522618]
	TIME [epoch: 6.41 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11846060371988322		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.11846060371988322 | validation: 0.22428135485912343]
	TIME [epoch: 6.41 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18932166029895825		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.18932166029895825 | validation: 0.23298871439615076]
	TIME [epoch: 6.41 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1390189438654646		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.1390189438654646 | validation: 0.10201967404943714]
	TIME [epoch: 6.41 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11152491699017447		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.11152491699017447 | validation: 0.14522856858123373]
	TIME [epoch: 6.41 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1279512312030596		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.1279512312030596 | validation: 0.5945308074630414]
	TIME [epoch: 6.44 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31222405006669673		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.31222405006669673 | validation: 0.15654031114133976]
	TIME [epoch: 6.41 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18444008715371835		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.18444008715371835 | validation: 0.19476411663495907]
	TIME [epoch: 6.41 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1662634597892717		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.1662634597892717 | validation: 0.20641811717476305]
	TIME [epoch: 6.41 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18307016275017227		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.18307016275017227 | validation: 0.07967319495375627]
	TIME [epoch: 6.41 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12062801613495105		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.12062801613495105 | validation: 0.053297059870454876]
	TIME [epoch: 6.41 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1373971005344777		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.1373971005344777 | validation: 0.054699970912125445]
	TIME [epoch: 6.41 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10928468372039851		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.10928468372039851 | validation: 0.1454096871897017]
	TIME [epoch: 6.45 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1607524474867557		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.1607524474867557 | validation: 0.12342602369956004]
	TIME [epoch: 6.42 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15678623532164968		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.15678623532164968 | validation: 0.17171580298319797]
	TIME [epoch: 6.41 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13965997876162647		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.13965997876162647 | validation: 0.1626369876785636]
	TIME [epoch: 6.41 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22520223587668317		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.22520223587668317 | validation: 0.17497808245899954]
	TIME [epoch: 6.41 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665689576449088		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.1665689576449088 | validation: 0.22502572082598576]
	TIME [epoch: 6.41 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1591076770906738		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.1591076770906738 | validation: 0.04214839575169435]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_732.pth
	Model improved!!!
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10095667841089802		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.10095667841089802 | validation: 0.10744477247463159]
	TIME [epoch: 6.44 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10295756192421546		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.10295756192421546 | validation: 0.10376788369743302]
	TIME [epoch: 6.42 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11562464181292781		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.11562464181292781 | validation: 0.19144817320164437]
	TIME [epoch: 6.41 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19687450765749137		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.19687450765749137 | validation: 0.13801307499958693]
	TIME [epoch: 6.4 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14587886524920662		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.14587886524920662 | validation: 0.0723164106233247]
	TIME [epoch: 6.41 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10173513023754331		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.10173513023754331 | validation: 0.050233406601417896]
	TIME [epoch: 6.41 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11517456030774795		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.11517456030774795 | validation: 0.09658904354859144]
	TIME [epoch: 6.41 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10185584174728374		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.10185584174728374 | validation: 0.07735781904527692]
	TIME [epoch: 6.43 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09995733705085957		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.09995733705085957 | validation: 0.05751741574466206]
	TIME [epoch: 6.43 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08468915167181104		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.08468915167181104 | validation: 0.034363244387454105]
	TIME [epoch: 6.41 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15183956209235727		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.15183956209235727 | validation: 0.15045109560090023]
	TIME [epoch: 6.4 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15366840507822516		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.15366840507822516 | validation: 0.07685400163049019]
	TIME [epoch: 6.4 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15218624094326055		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.15218624094326055 | validation: 0.21556913009112813]
	TIME [epoch: 6.41 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15004127596909508		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.15004127596909508 | validation: 0.10260510907604488]
	TIME [epoch: 6.4 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14129195699699126		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.14129195699699126 | validation: 0.0823974226047983]
	TIME [epoch: 6.42 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15152638895782056		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.15152638895782056 | validation: 0.1392034931562413]
	TIME [epoch: 6.42 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10941408161897147		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.10941408161897147 | validation: 0.12899063153003676]
	TIME [epoch: 6.39 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15584728920950613		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.15584728920950613 | validation: 0.06050851761800631]
	TIME [epoch: 6.38 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11394101234221243		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.11394101234221243 | validation: 0.09691200305430167]
	TIME [epoch: 6.37 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12333064801989961		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.12333064801989961 | validation: 0.16133962706284244]
	TIME [epoch: 6.37 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1933962897648847		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.1933962897648847 | validation: 0.09095871491955429]
	TIME [epoch: 6.38 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09631196748659829		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.09631196748659829 | validation: 0.16805356472616964]
	TIME [epoch: 6.38 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17050771445515		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.17050771445515 | validation: 0.054780771834673614]
	TIME [epoch: 6.41 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21661431437351214		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.21661431437351214 | validation: 0.046408354027233846]
	TIME [epoch: 6.38 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12158555478661032		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.12158555478661032 | validation: 0.08549925430856087]
	TIME [epoch: 6.38 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09605133505400214		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.09605133505400214 | validation: 0.05566373677667826]
	TIME [epoch: 6.38 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.096592687353972		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.096592687353972 | validation: 0.0687191482580166]
	TIME [epoch: 6.38 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09167010411383		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.09167010411383 | validation: 0.07605973788598448]
	TIME [epoch: 6.38 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11206488779592204		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.11206488779592204 | validation: 0.09881016879665175]
	TIME [epoch: 6.38 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08815122560922103		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.08815122560922103 | validation: 0.04267149263125575]
	TIME [epoch: 6.42 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1032457081494779		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.1032457081494779 | validation: 0.18431206414500267]
	TIME [epoch: 6.39 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1887224825428753		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.1887224825428753 | validation: 0.24920189322427924]
	TIME [epoch: 6.39 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13688000450292515		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.13688000450292515 | validation: 0.269703303965112]
	TIME [epoch: 6.39 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13590556459489905		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.13590556459489905 | validation: 0.0554440576444518]
	TIME [epoch: 6.4 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08839892528346631		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.08839892528346631 | validation: 0.06490659836181681]
	TIME [epoch: 6.4 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10666312409013903		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.10666312409013903 | validation: 0.09341616627674774]
	TIME [epoch: 6.4 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1385771093482405		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.1385771093482405 | validation: 0.1351704533631123]
	TIME [epoch: 6.43 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.147563820122467		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.147563820122467 | validation: 0.13639105384057967]
	TIME [epoch: 6.41 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.114557774317699		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.114557774317699 | validation: 0.13234203286844357]
	TIME [epoch: 6.4 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09081596361102595		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.09081596361102595 | validation: 0.05269523699636453]
	TIME [epoch: 6.4 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1357650863114023		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.1357650863114023 | validation: 0.08593014138193945]
	TIME [epoch: 6.41 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12625786755341376		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.12625786755341376 | validation: 0.17248969849223036]
	TIME [epoch: 6.41 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1439295165603644		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.1439295165603644 | validation: 0.04210234270346097]
	TIME [epoch: 6.41 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12082059505853693		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.12082059505853693 | validation: 0.07156362493591072]
	TIME [epoch: 6.43 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0937281903029066		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.0937281903029066 | validation: 0.04175808411405393]
	TIME [epoch: 6.43 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10831888481140542		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.10831888481140542 | validation: 0.05815478529293074]
	TIME [epoch: 6.42 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17713690587316064		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.17713690587316064 | validation: 0.10935070454490202]
	TIME [epoch: 6.41 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1651274271738712		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.1651274271738712 | validation: 0.24502681840382617]
	TIME [epoch: 6.41 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14250551515135967		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.14250551515135967 | validation: 0.07227151526930171]
	TIME [epoch: 6.42 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1464387111965423		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.1464387111965423 | validation: 0.07138164218189219]
	TIME [epoch: 6.41 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1278818146922386		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.1278818146922386 | validation: 0.06835674275311139]
	TIME [epoch: 6.43 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10573742959486537		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.10573742959486537 | validation: 0.08351282381443381]
	TIME [epoch: 6.43 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08791277808090366		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.08791277808090366 | validation: 0.10038696323368478]
	TIME [epoch: 6.42 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10858944055174632		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.10858944055174632 | validation: 0.12027899393056427]
	TIME [epoch: 6.41 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12330074516665296		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.12330074516665296 | validation: 0.08704743796112005]
	TIME [epoch: 6.42 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1589228000106561		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.1589228000106561 | validation: 0.14960884445184236]
	TIME [epoch: 6.41 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15684010687881667		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.15684010687881667 | validation: 0.07955859611344483]
	TIME [epoch: 6.4 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1760690471560315		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.1760690471560315 | validation: 0.18680967880163984]
	TIME [epoch: 6.4 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1526320289942681		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.1526320289942681 | validation: 0.08586922124027535]
	TIME [epoch: 6.42 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1090945059244035		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.1090945059244035 | validation: 0.09839739720598407]
	TIME [epoch: 6.39 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08815374766673814		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.08815374766673814 | validation: 0.14723480557438323]
	TIME [epoch: 6.37 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09375570043704158		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.09375570043704158 | validation: 0.057055842374482094]
	TIME [epoch: 6.37 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13114403281475465		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.13114403281475465 | validation: 0.1934555030570473]
	TIME [epoch: 6.38 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12786537915629442		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.12786537915629442 | validation: 0.17416294396118587]
	TIME [epoch: 6.37 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20131768601221586		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.20131768601221586 | validation: 0.33280893871684697]
	TIME [epoch: 6.38 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13871712340917572		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.13871712340917572 | validation: 0.09104731354412372]
	TIME [epoch: 6.41 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07749852021860039		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.07749852021860039 | validation: 0.14099789777229593]
	TIME [epoch: 6.38 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1276878899246485		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.1276878899246485 | validation: 0.12409802091615711]
	TIME [epoch: 6.37 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09596779827569255		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.09596779827569255 | validation: 0.10232398068802487]
	TIME [epoch: 6.37 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11474756291277717		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.11474756291277717 | validation: 0.09911116264176845]
	TIME [epoch: 6.37 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11553473832364743		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.11553473832364743 | validation: 0.1702696382989886]
	TIME [epoch: 6.37 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1568810274976764		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.1568810274976764 | validation: 0.06678186541663823]
	TIME [epoch: 6.38 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11329580261024813		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.11329580261024813 | validation: 0.046852074312973]
	TIME [epoch: 6.4 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08183695683648619		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.08183695683648619 | validation: 0.45144147535951124]
	TIME [epoch: 6.38 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1971070037426897		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.1971070037426897 | validation: 0.15837111517938415]
	TIME [epoch: 6.37 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1516939352314553		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.1516939352314553 | validation: 0.051830957385673636]
	TIME [epoch: 6.38 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11268798345434483		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.11268798345434483 | validation: 0.06110217254671556]
	TIME [epoch: 6.39 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11033060326100852		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.11033060326100852 | validation: 0.043625481224641764]
	TIME [epoch: 6.4 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11285591228818491		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.11285591228818491 | validation: 0.09416564993925004]
	TIME [epoch: 6.4 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11934612126288081		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.11934612126288081 | validation: 0.05560174218801776]
	TIME [epoch: 6.41 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08787765501803096		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.08787765501803096 | validation: 0.07496070765686608]
	TIME [epoch: 6.42 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09439962367430638		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.09439962367430638 | validation: 0.0413487600124706]
	TIME [epoch: 6.4 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12417498965946394		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.12417498965946394 | validation: 0.05307852367534863]
	TIME [epoch: 6.4 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11256020007799192		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.11256020007799192 | validation: 0.062064411763310706]
	TIME [epoch: 6.4 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09753422422909479		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.09753422422909479 | validation: 0.041942484028669076]
	TIME [epoch: 6.41 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08615433452775623		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.08615433452775623 | validation: 0.09297548240965689]
	TIME [epoch: 6.41 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10733165531810784		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.10733165531810784 | validation: 0.11509779345597103]
	TIME [epoch: 6.43 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1281263660075868		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.1281263660075868 | validation: 0.06123000190018832]
	TIME [epoch: 6.43 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13120975617877184		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.13120975617877184 | validation: 0.0694713213502582]
	TIME [epoch: 6.42 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08997705580213114		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.08997705580213114 | validation: 0.17032585891069388]
	TIME [epoch: 6.42 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14323112417781303		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.14323112417781303 | validation: 0.07957947568271449]
	TIME [epoch: 6.41 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11308337666880106		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.11308337666880106 | validation: 0.11386250313839118]
	TIME [epoch: 6.41 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1414948169697506		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.1414948169697506 | validation: 0.08505244017108478]
	TIME [epoch: 6.41 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14657772279107312		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.14657772279107312 | validation: 0.04815901105766125]
	TIME [epoch: 6.41 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0952315317699104		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.0952315317699104 | validation: 0.21148310712616536]
	TIME [epoch: 6.45 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13820205391952683		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.13820205391952683 | validation: 0.20081473936409963]
	TIME [epoch: 6.41 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14232993397433305		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.14232993397433305 | validation: 0.09489927069993069]
	TIME [epoch: 6.41 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09712501036277307		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.09712501036277307 | validation: 0.07919411026878934]
	TIME [epoch: 6.42 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08828738937135802		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.08828738937135802 | validation: 0.1059341755195575]
	TIME [epoch: 6.41 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10034692636090589		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.10034692636090589 | validation: 0.06758858644074406]
	TIME [epoch: 6.41 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11654468634415857		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.11654468634415857 | validation: 0.08431791681964491]
	TIME [epoch: 6.41 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09564014985436405		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.09564014985436405 | validation: 0.11195072191694255]
	TIME [epoch: 6.45 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14746704386271964		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.14746704386271964 | validation: 0.10931797856587049]
	TIME [epoch: 6.41 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10898526933268306		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.10898526933268306 | validation: 0.11581515746569859]
	TIME [epoch: 6.4 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08865483591373874		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.08865483591373874 | validation: 0.06800009269888983]
	TIME [epoch: 6.4 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11425832550705346		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.11425832550705346 | validation: 0.08577756120834272]
	TIME [epoch: 6.4 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07802019376648914		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.07802019376648914 | validation: 0.06255081578387724]
	TIME [epoch: 6.4 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0972839776307759		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.0972839776307759 | validation: 0.04331845427231909]
	TIME [epoch: 6.4 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08176720243704612		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.08176720243704612 | validation: 0.26087341793512014]
	TIME [epoch: 6.43 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1330390055141848		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.1330390055141848 | validation: 0.09850722863947678]
	TIME [epoch: 6.41 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09298035610827797		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.09298035610827797 | validation: 0.0524141321141936]
	TIME [epoch: 6.4 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12052092873558225		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.12052092873558225 | validation: 0.13468507240950406]
	TIME [epoch: 6.4 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08896460738981658		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.08896460738981658 | validation: 0.07381403765890991]
	TIME [epoch: 6.4 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05894050014754965		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.05894050014754965 | validation: 0.09308132382072197]
	TIME [epoch: 6.4 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07073967484975509		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.07073967484975509 | validation: 0.049522625797449024]
	TIME [epoch: 6.4 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05679312640864156		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.05679312640864156 | validation: 0.31208860995903626]
	TIME [epoch: 6.42 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18855938142876957		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.18855938142876957 | validation: 0.12461179222012912]
	TIME [epoch: 6.42 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10220056970004106		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.10220056970004106 | validation: 0.08973070271893895]
	TIME [epoch: 6.4 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12864072695927584		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.12864072695927584 | validation: 0.10059867190230323]
	TIME [epoch: 6.4 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10192809827001915		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.10192809827001915 | validation: 0.11801220920310773]
	TIME [epoch: 6.4 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09291870720416964		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.09291870720416964 | validation: 0.05808787802357994]
	TIME [epoch: 6.4 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08677294929614557		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.08677294929614557 | validation: 0.06029390459697521]
	TIME [epoch: 6.4 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09181173514263034		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.09181173514263034 | validation: 0.09531693790939719]
	TIME [epoch: 6.42 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09813616404738204		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.09813616404738204 | validation: 0.06413835923504708]
	TIME [epoch: 6.42 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08249136411546411		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.08249136411546411 | validation: 0.06625069620888269]
	TIME [epoch: 6.4 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08492769056269106		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.08492769056269106 | validation: 0.09491548436012444]
	TIME [epoch: 6.4 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16790930774140192		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.16790930774140192 | validation: 0.41862747915290555]
	TIME [epoch: 6.4 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21922954116968077		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.21922954116968077 | validation: 0.04380002763999991]
	TIME [epoch: 6.4 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08189946602595932		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.08189946602595932 | validation: 0.05352916138923892]
	TIME [epoch: 6.4 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08046912267220757		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.08046912267220757 | validation: 0.10395068272734659]
	TIME [epoch: 6.4 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08934691236830798		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.08934691236830798 | validation: 0.04170047643925599]
	TIME [epoch: 6.43 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07796514697595174		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.07796514697595174 | validation: 0.11516629730626168]
	TIME [epoch: 6.4 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07624489433742382		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.07624489433742382 | validation: 0.03906423080947786]
	TIME [epoch: 6.4 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07246167182774166		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.07246167182774166 | validation: 0.2073796947173571]
	TIME [epoch: 6.4 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17674795700629142		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.17674795700629142 | validation: 0.11906273560599137]
	TIME [epoch: 6.4 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1230911144474308		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.1230911144474308 | validation: 0.1237555365307766]
	TIME [epoch: 6.4 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0798010053517147		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.0798010053517147 | validation: 0.08946216647867776]
	TIME [epoch: 6.4 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08657604846744071		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.08657604846744071 | validation: 0.16775029753401896]
	TIME [epoch: 6.43 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13054973493826422		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.13054973493826422 | validation: 0.07376911341922783]
	TIME [epoch: 6.4 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11109162713151369		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.11109162713151369 | validation: 0.046401009211490554]
	TIME [epoch: 6.4 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07756979812572383		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.07756979812572383 | validation: 0.1349098806376608]
	TIME [epoch: 6.4 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10466721426281801		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.10466721426281801 | validation: 0.08805565439244421]
	TIME [epoch: 6.4 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10269828583215594		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.10269828583215594 | validation: 0.06278457573447938]
	TIME [epoch: 6.39 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07747789804761819		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.07747789804761819 | validation: 0.05021944984555685]
	TIME [epoch: 6.4 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06321779980233402		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.06321779980233402 | validation: 0.03500337586126707]
	TIME [epoch: 6.43 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15621706994656784		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.15621706994656784 | validation: 0.06272900512489592]
	TIME [epoch: 6.4 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10357964402624283		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.10357964402624283 | validation: 0.31702462825776423]
	TIME [epoch: 6.4 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.17734196403005625		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.17734196403005625 | validation: 0.08156323810678462]
	TIME [epoch: 6.4 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11360951179645593		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.11360951179645593 | validation: 0.16814572110956988]
	TIME [epoch: 6.4 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.13116530524639688		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.13116530524639688 | validation: 0.02654716914289046]
	TIME [epoch: 6.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_882.pth
	Model improved!!!
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07300997516818884		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.07300997516818884 | validation: 0.050194963571107074]
	TIME [epoch: 6.4 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09360814181669425		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.09360814181669425 | validation: 0.0358296593731416]
	TIME [epoch: 6.43 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07512408961500414		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.07512408961500414 | validation: 0.050294965051210894]
	TIME [epoch: 6.41 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08675193463525989		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.08675193463525989 | validation: 0.0488605314985504]
	TIME [epoch: 6.41 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07975706751767925		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.07975706751767925 | validation: 0.05816707282052264]
	TIME [epoch: 6.41 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06588610275703638		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.06588610275703638 | validation: 0.035510487098416074]
	TIME [epoch: 6.41 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06566533566506749		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.06566533566506749 | validation: 0.04241534747927915]
	TIME [epoch: 6.41 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0667249624215667		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.0667249624215667 | validation: 0.050146703158076615]
	TIME [epoch: 6.41 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07268101954304974		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.07268101954304974 | validation: 0.11111174469728796]
	TIME [epoch: 6.42 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14644398645405823		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.14644398645405823 | validation: 0.13360467899731976]
	TIME [epoch: 6.43 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0838535836003015		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.0838535836003015 | validation: 0.18583625075137938]
	TIME [epoch: 6.41 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1482525329296825		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.1482525329296825 | validation: 0.06820129632913298]
	TIME [epoch: 6.41 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.16175853403372503		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.16175853403372503 | validation: 0.0615259775622023]
	TIME [epoch: 6.4 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0941202193152086		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.0941202193152086 | validation: 0.06505159927869861]
	TIME [epoch: 6.41 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10334312908750465		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.10334312908750465 | validation: 0.21042834873675006]
	TIME [epoch: 6.41 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1665768407866926		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.1665768407866926 | validation: 0.04659724048619942]
	TIME [epoch: 6.42 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09118618886369799		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.09118618886369799 | validation: 0.0509200677556794]
	TIME [epoch: 6.43 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14126058991131232		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.14126058991131232 | validation: 0.11124479747137773]
	TIME [epoch: 6.41 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12136928964931809		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.12136928964931809 | validation: 0.03726444651499823]
	TIME [epoch: 6.41 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07619941214033502		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.07619941214033502 | validation: 0.06659813986790723]
	TIME [epoch: 6.41 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12575872504766106		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.12575872504766106 | validation: 0.12813691896736526]
	TIME [epoch: 6.41 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09285242317749864		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.09285242317749864 | validation: 0.10305494939908283]
	TIME [epoch: 6.41 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08247351538216469		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.08247351538216469 | validation: 0.04275514791572122]
	TIME [epoch: 6.41 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08765016947575735		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.08765016947575735 | validation: 0.0797547925992017]
	TIME [epoch: 6.44 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06134127982862357		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.06134127982862357 | validation: 0.0626050563934215]
	TIME [epoch: 6.41 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11184957521637856		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.11184957521637856 | validation: 0.15173268746932891]
	TIME [epoch: 6.41 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11615113281788562		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.11615113281788562 | validation: 0.0643975667799888]
	TIME [epoch: 6.41 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09312981466473103		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.09312981466473103 | validation: 0.12195340940874473]
	TIME [epoch: 6.41 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1809910193567698		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.1809910193567698 | validation: 0.07555830834282656]
	TIME [epoch: 6.4 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08222547137163111		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.08222547137163111 | validation: 0.07138019325225793]
	TIME [epoch: 6.41 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11469874598343108		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.11469874598343108 | validation: 0.09487134594312532]
	TIME [epoch: 6.45 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07988202661013939		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.07988202661013939 | validation: 0.05836782879309355]
	TIME [epoch: 6.41 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06637581431272233		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.06637581431272233 | validation: 0.19207543917002148]
	TIME [epoch: 6.41 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11612354756570524		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.11612354756570524 | validation: 0.09300985944322494]
	TIME [epoch: 6.41 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11523454494877307		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.11523454494877307 | validation: 0.05369019317764546]
	TIME [epoch: 6.41 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08322061766345132		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.08322061766345132 | validation: 0.065814248124954]
	TIME [epoch: 6.41 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08150998041992108		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.08150998041992108 | validation: 0.20059763727629418]
	TIME [epoch: 6.41 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09104162018976253		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.09104162018976253 | validation: 0.1413648285769207]
	TIME [epoch: 6.44 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07147641315029432		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.07147641315029432 | validation: 0.09526389738352162]
	TIME [epoch: 6.42 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08709311081942235		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.08709311081942235 | validation: 0.09258756591572516]
	TIME [epoch: 6.4 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08519226910520879		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.08519226910520879 | validation: 0.09472951680276818]
	TIME [epoch: 6.4 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0778173564452494		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.0778173564452494 | validation: 0.08876751011817824]
	TIME [epoch: 6.4 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.15654886572767002		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.15654886572767002 | validation: 0.23438421641260473]
	TIME [epoch: 6.4 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.099569585940223		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.099569585940223 | validation: 0.12180327048829614]
	TIME [epoch: 6.41 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11257804821305693		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.11257804821305693 | validation: 0.11131844939324785]
	TIME [epoch: 6.43 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11964959030156067		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.11964959030156067 | validation: 0.0832767797857305]
	TIME [epoch: 6.43 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10731503517045674		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.10731503517045674 | validation: 0.07365626281982277]
	TIME [epoch: 6.41 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07209909062374838		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.07209909062374838 | validation: 0.08387829765227962]
	TIME [epoch: 6.41 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08875823065078987		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.08875823065078987 | validation: 0.41835760030511365]
	TIME [epoch: 6.4 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19235711863476576		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.19235711863476576 | validation: 0.1166772620981411]
	TIME [epoch: 6.4 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12710927144036244		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.12710927144036244 | validation: 0.11762638846286365]
	TIME [epoch: 6.4 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07247913777583959		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.07247913777583959 | validation: 0.09814732104404929]
	TIME [epoch: 6.42 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09804447923932857		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.09804447923932857 | validation: 0.04513534105896049]
	TIME [epoch: 6.43 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07747102042609415		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.07747102042609415 | validation: 0.17307196814926942]
	TIME [epoch: 6.41 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2648846791943593		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.2648846791943593 | validation: 0.21985489402288214]
	TIME [epoch: 6.41 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10199779312424886		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.10199779312424886 | validation: 0.06181522696075029]
	TIME [epoch: 6.41 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07593753787099407		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.07593753787099407 | validation: 0.17721871019251034]
	TIME [epoch: 6.4 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1400825298459628		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.1400825298459628 | validation: 0.09097710013486157]
	TIME [epoch: 6.41 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07833392083996507		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.07833392083996507 | validation: 0.05686942146585453]
	TIME [epoch: 6.41 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06558347464072978		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.06558347464072978 | validation: 0.05108912972409924]
	TIME [epoch: 6.45 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07962241708311071		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.07962241708311071 | validation: 0.08271052052796775]
	TIME [epoch: 6.42 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07975449305127869		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.07975449305127869 | validation: 0.17165124115951236]
	TIME [epoch: 6.41 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0947355790323353		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.0947355790323353 | validation: 0.060089212990892024]
	TIME [epoch: 6.42 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06515170367148991		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.06515170367148991 | validation: 0.06989966304529929]
	TIME [epoch: 6.42 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0944981693402635		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.0944981693402635 | validation: 0.14767153464461769]
	TIME [epoch: 6.42 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08730054837798853		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.08730054837798853 | validation: 0.04767579528202228]
	TIME [epoch: 6.42 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06476031798209075		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.06476031798209075 | validation: 0.07787689254446957]
	TIME [epoch: 6.45 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06092379409832535		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.06092379409832535 | validation: 0.11657449147498461]
	TIME [epoch: 6.42 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07061368465865064		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.07061368465865064 | validation: 0.0477455977650537]
	TIME [epoch: 6.42 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07517399721484049		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.07517399721484049 | validation: 0.07639441374407402]
	TIME [epoch: 6.42 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07914100442994511		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.07914100442994511 | validation: 0.05727882747802525]
	TIME [epoch: 6.42 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06215496520544571		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.06215496520544571 | validation: 0.1027366441285626]
	TIME [epoch: 6.42 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09019655395619242		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.09019655395619242 | validation: 0.0526917072920224]
	TIME [epoch: 6.42 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1303614687306817		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.1303614687306817 | validation: 0.10421084258796282]
	TIME [epoch: 6.46 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09140703043576236		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.09140703043576236 | validation: 0.05715725885223019]
	TIME [epoch: 6.43 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08157271071946781		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.08157271071946781 | validation: 0.05241794667653908]
	TIME [epoch: 6.42 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09436842478256771		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.09436842478256771 | validation: 0.0304785373419409]
	TIME [epoch: 6.42 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05858048601394365		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.05858048601394365 | validation: 0.05309480371460696]
	TIME [epoch: 6.43 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07719659312145759		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.07719659312145759 | validation: 0.08689535798400388]
	TIME [epoch: 6.42 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07220804596211665		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.07220804596211665 | validation: 0.05868133588158517]
	TIME [epoch: 6.42 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051144783386788566		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.051144783386788566 | validation: 0.07015632146363482]
	TIME [epoch: 6.46 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08893863245919403		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.08893863245919403 | validation: 0.10691193696366552]
	TIME [epoch: 6.43 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08970683445412203		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.08970683445412203 | validation: 0.029933410831350624]
	TIME [epoch: 6.43 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.056795745092011324		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.056795745092011324 | validation: 0.08975631709146473]
	TIME [epoch: 6.42 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07707939341507515		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.07707939341507515 | validation: 0.0406709482848138]
	TIME [epoch: 6.41 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08400364444594471		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.08400364444594471 | validation: 0.03452100634114144]
	TIME [epoch: 6.4 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05359248919405307		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.05359248919405307 | validation: 0.06104785831312438]
	TIME [epoch: 6.39 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06294483616097377		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.06294483616097377 | validation: 0.06690784384530629]
	TIME [epoch: 6.39 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06686650443159918		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.06686650443159918 | validation: 0.05595443589692467]
	TIME [epoch: 6.4 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05617837025061608		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.05617837025061608 | validation: 0.04619711814237676]
	TIME [epoch: 6.38 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06483994186676009		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.06483994186676009 | validation: 0.03192665444403112]
	TIME [epoch: 6.38 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09737709161269989		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.09737709161269989 | validation: 0.05625945939100599]
	TIME [epoch: 6.37 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06797288350342684		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.06797288350342684 | validation: 0.06524501300005922]
	TIME [epoch: 6.37 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.062303211846831005		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.062303211846831005 | validation: 0.041684634640310005]
	TIME [epoch: 6.37 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08831705913062304		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.08831705913062304 | validation: 0.06485513238007086]
	TIME [epoch: 6.38 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11248476737014745		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.11248476737014745 | validation: 0.09102255796168153]
	TIME [epoch: 6.41 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07450587593094721		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.07450587593094721 | validation: 0.059139442650369765]
	TIME [epoch: 6.38 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06682682987086701		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.06682682987086701 | validation: 0.05519001011992659]
	TIME [epoch: 6.37 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0703588843598228		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.0703588843598228 | validation: 0.039117928802868955]
	TIME [epoch: 6.38 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07411877747267798		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.07411877747267798 | validation: 0.08391515042258427]
	TIME [epoch: 6.38 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07565529595824018		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.07565529595824018 | validation: 0.09208600772756312]
	TIME [epoch: 6.38 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06794092792000506		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.06794092792000506 | validation: 0.04956055780405313]
	TIME [epoch: 6.39 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0542700624294175		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.0542700624294175 | validation: 0.04154900572871295]
	TIME [epoch: 6.44 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07079424769351271		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.07079424769351271 | validation: 0.08972636762582932]
	TIME [epoch: 6.41 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07423459264387976		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.07423459264387976 | validation: 0.06554338014191856]
	TIME [epoch: 6.41 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06773885076521383		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.06773885076521383 | validation: 0.10002472856540391]
	TIME [epoch: 6.4 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05622370577956827		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.05622370577956827 | validation: 0.03430521164917632]
	TIME [epoch: 6.4 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06909387408152329		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.06909387408152329 | validation: 0.08516456861582729]
	TIME [epoch: 6.4 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06966700209786938		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.06966700209786938 | validation: 0.09023965554402012]
	TIME [epoch: 6.4 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11842492670782272		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.11842492670782272 | validation: 0.08513825717837664]
	TIME [epoch: 6.44 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06932293405329087		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.06932293405329087 | validation: 0.09400725983388217]
	TIME [epoch: 6.4 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0776757691107768		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.0776757691107768 | validation: 0.07334545611772951]
	TIME [epoch: 6.4 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09739998709596429		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.09739998709596429 | validation: 0.05239513326174457]
	TIME [epoch: 6.4 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054684723296427665		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.054684723296427665 | validation: 0.04116850047160263]
	TIME [epoch: 6.4 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07011792446734809		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.07011792446734809 | validation: 0.040539713366358275]
	TIME [epoch: 6.4 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0546743620943023		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.0546743620943023 | validation: 0.08181698909271531]
	TIME [epoch: 6.4 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08131197278211762		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.08131197278211762 | validation: 0.05769666952923602]
	TIME [epoch: 6.43 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08366382694753483		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.08366382694753483 | validation: 0.0765894831531477]
	TIME [epoch: 6.41 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06484317162795426		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.06484317162795426 | validation: 0.04676630835704561]
	TIME [epoch: 6.41 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054906669997098576		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.054906669997098576 | validation: 0.05576847110227909]
	TIME [epoch: 6.42 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05201161148075062		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.05201161148075062 | validation: 0.05822273851270426]
	TIME [epoch: 6.43 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0985293944285111		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.0985293944285111 | validation: 0.3018958073169722]
	TIME [epoch: 6.43 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11353137985330634		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.11353137985330634 | validation: 0.07678903945807615]
	TIME [epoch: 6.43 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10079206074699085		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.10079206074699085 | validation: 0.06652810044106479]
	TIME [epoch: 6.44 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07905279430840895		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.07905279430840895 | validation: 0.07066403912023039]
	TIME [epoch: 6.44 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.12739513361359106		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.12739513361359106 | validation: 0.03658259781338923]
	TIME [epoch: 6.42 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055050920119943156		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.055050920119943156 | validation: 0.07946630186591136]
	TIME [epoch: 6.42 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059946594805750195		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.059946594805750195 | validation: 0.07787796541387662]
	TIME [epoch: 6.42 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06468344884205632		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.06468344884205632 | validation: 0.0393545731373532]
	TIME [epoch: 6.42 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05715363285676034		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.05715363285676034 | validation: 0.052144913345214206]
	TIME [epoch: 6.43 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06536477817142344		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.06536477817142344 | validation: 0.03449415422099783]
	TIME [epoch: 6.44 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06785468504870161		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.06785468504870161 | validation: 0.09625013434770384]
	TIME [epoch: 6.45 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06400229430810944		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.06400229430810944 | validation: 0.0407465492578398]
	TIME [epoch: 6.42 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059724970683969314		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.059724970683969314 | validation: 0.07737710910836303]
	TIME [epoch: 6.43 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0983494907491698		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.0983494907491698 | validation: 0.052291979489508755]
	TIME [epoch: 6.43 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05505318618945203		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.05505318618945203 | validation: 0.039260044122333464]
	TIME [epoch: 6.43 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053980146112655183		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.053980146112655183 | validation: 0.03269658765091157]
	TIME [epoch: 6.43 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0592934753388384		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.0592934753388384 | validation: 0.03982729838263904]
	TIME [epoch: 6.43 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06223704659783622		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.06223704659783622 | validation: 0.15540151226341867]
	TIME [epoch: 6.46 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07200658151723564		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.07200658151723564 | validation: 0.0684705732331092]
	TIME [epoch: 6.43 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07235656529478		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.07235656529478 | validation: 0.08193396685668537]
	TIME [epoch: 6.42 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06500857541080735		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.06500857541080735 | validation: 0.06426694990692271]
	TIME [epoch: 6.42 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07011020920159025		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.07011020920159025 | validation: 0.0508492987672521]
	TIME [epoch: 6.42 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06784328568544129		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.06784328568544129 | validation: 0.044167507615779956]
	TIME [epoch: 6.43 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07597615388420698		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.07597615388420698 | validation: 0.1445338806440173]
	TIME [epoch: 6.42 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08354416075811817		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.08354416075811817 | validation: 0.059927719358168034]
	TIME [epoch: 6.46 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07525344230357349		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.07525344230357349 | validation: 0.10602257642138609]
	TIME [epoch: 6.43 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07321819759395094		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.07321819759395094 | validation: 0.08693652192623545]
	TIME [epoch: 6.43 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0786037335827639		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.0786037335827639 | validation: 0.08164044121676371]
	TIME [epoch: 6.42 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0584495053173632		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.0584495053173632 | validation: 0.08725218224004301]
	TIME [epoch: 6.42 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05211486945277981		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.05211486945277981 | validation: 0.07247261552108925]
	TIME [epoch: 6.42 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06384611064076151		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.06384611064076151 | validation: 0.07346182096049093]
	TIME [epoch: 6.42 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06551987931591631		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.06551987931591631 | validation: 0.11124308240621616]
	TIME [epoch: 6.45 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06741823046584287		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.06741823046584287 | validation: 0.08823862325704976]
	TIME [epoch: 6.43 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06345735079249916		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.06345735079249916 | validation: 0.1009755371365026]
	TIME [epoch: 6.43 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07249729544250282		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.07249729544250282 | validation: 0.0731386603635769]
	TIME [epoch: 6.43 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052402739326282886		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.052402739326282886 | validation: 0.071390901948157]
	TIME [epoch: 6.42 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06552006129725317		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.06552006129725317 | validation: 0.1331893173153924]
	TIME [epoch: 6.42 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06488960040554032		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.06488960040554032 | validation: 0.14159875745630518]
	TIME [epoch: 6.42 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07144818643822684		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.07144818643822684 | validation: 0.0861160296163573]
	TIME [epoch: 6.45 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06747837522935483		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.06747837522935483 | validation: 0.08049159681240857]
	TIME [epoch: 6.43 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06027710139836055		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.06027710139836055 | validation: 0.19344834974139097]
	TIME [epoch: 6.42 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09009660978559941		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.09009660978559941 | validation: 0.06737979006155558]
	TIME [epoch: 6.42 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052397977096045385		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.052397977096045385 | validation: 0.04963511271171728]
	TIME [epoch: 6.43 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278709775162085		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.06278709775162085 | validation: 0.07630286608606011]
	TIME [epoch: 6.42 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07167757661516111		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.07167757661516111 | validation: 0.044562971524398136]
	TIME [epoch: 6.43 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06416315144606555		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.06416315144606555 | validation: 0.02385227197563469]
	TIME [epoch: 6.44 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_1049.pth
	Model improved!!!
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05561379592814597		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.05561379592814597 | validation: 0.0360900739687208]
	TIME [epoch: 6.44 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05505342795885161		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.05505342795885161 | validation: 0.05405990066131519]
	TIME [epoch: 6.42 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0628067054734644		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.0628067054734644 | validation: 0.053739511352711065]
	TIME [epoch: 6.42 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07811954729190473		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.07811954729190473 | validation: 0.11123464488181234]
	TIME [epoch: 6.42 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07672026049141051		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.07672026049141051 | validation: 0.12121260588800409]
	TIME [epoch: 6.42 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09283924676335477		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.09283924676335477 | validation: 0.039077906595853994]
	TIME [epoch: 6.42 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05568062307270472		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.05568062307270472 | validation: 0.0744416855453552]
	TIME [epoch: 6.44 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08318648897766896		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.08318648897766896 | validation: 0.045753785832103794]
	TIME [epoch: 6.44 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0604927606991343		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.0604927606991343 | validation: 0.08402164068860288]
	TIME [epoch: 6.42 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.10316613178454694		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.10316613178454694 | validation: 0.07041804249107456]
	TIME [epoch: 6.4 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08752877833477843		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.08752877833477843 | validation: 0.06683764105120109]
	TIME [epoch: 6.4 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04968450199960065		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.04968450199960065 | validation: 0.05625322784069001]
	TIME [epoch: 6.39 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06727380280594844		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.06727380280594844 | validation: 0.1367083754744466]
	TIME [epoch: 6.39 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08246759528992482		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.08246759528992482 | validation: 0.15001953316831407]
	TIME [epoch: 6.39 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07795315710957604		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.07795315710957604 | validation: 0.13449718295155252]
	TIME [epoch: 6.42 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07209654954449049		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.07209654954449049 | validation: 0.09272201177025098]
	TIME [epoch: 6.39 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07350139424823207		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.07350139424823207 | validation: 0.11619464804478286]
	TIME [epoch: 6.39 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1077746562568143		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.1077746562568143 | validation: 0.14484593126546869]
	TIME [epoch: 6.39 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07167650035000392		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.07167650035000392 | validation: 0.09412072580397954]
	TIME [epoch: 6.4 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06209956977873064		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.06209956977873064 | validation: 0.06988366110299969]
	TIME [epoch: 6.39 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06280584061245746		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.06280584061245746 | validation: 0.05254341272559215]
	TIME [epoch: 6.4 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04756986878017323		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.04756986878017323 | validation: 0.10815803284342089]
	TIME [epoch: 6.44 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11145296165166055		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.11145296165166055 | validation: 0.03411176853100448]
	TIME [epoch: 6.41 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055642933280482726		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.055642933280482726 | validation: 0.039358590427310276]
	TIME [epoch: 6.4 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06842600706059558		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.06842600706059558 | validation: 0.07253389289425334]
	TIME [epoch: 6.41 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08276976742869827		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.08276976742869827 | validation: 0.08800998805598365]
	TIME [epoch: 6.4 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07361820351144374		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.07361820351144374 | validation: 0.04442003657049536]
	TIME [epoch: 6.4 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06827170917207573		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.06827170917207573 | validation: 0.12350224219507483]
	TIME [epoch: 6.4 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08955638621082694		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.08955638621082694 | validation: 0.05374865561274323]
	TIME [epoch: 6.43 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047819096904680475		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.047819096904680475 | validation: 0.03280125255756988]
	TIME [epoch: 6.42 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04720532380441828		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.04720532380441828 | validation: 0.044715237454989]
	TIME [epoch: 6.41 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06536964975171104		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.06536964975171104 | validation: 0.03349252254830331]
	TIME [epoch: 6.41 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07073417538169022		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.07073417538169022 | validation: 0.052155818780690755]
	TIME [epoch: 6.41 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06189736614077253		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.06189736614077253 | validation: 0.04701939195416622]
	TIME [epoch: 6.41 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05495070845181768		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.05495070845181768 | validation: 0.04506653843880559]
	TIME [epoch: 6.42 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0636627343244121		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.0636627343244121 | validation: 0.061581909277855146]
	TIME [epoch: 6.45 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054520744056709834		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.054520744056709834 | validation: 0.04187461984852369]
	TIME [epoch: 6.43 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06936913274177917		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.06936913274177917 | validation: 0.03160866921578458]
	TIME [epoch: 6.42 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054422649994807906		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.054422649994807906 | validation: 0.04477345286538796]
	TIME [epoch: 6.42 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05925394403332246		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.05925394403332246 | validation: 0.06905603061147587]
	TIME [epoch: 6.42 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07262643089318163		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.07262643089318163 | validation: 0.1341922901111744]
	TIME [epoch: 6.42 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07678479770552771		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.07678479770552771 | validation: 0.06714639123524486]
	TIME [epoch: 6.41 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06318076905999265		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.06318076905999265 | validation: 0.10142809902417177]
	TIME [epoch: 6.44 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07392295694258792		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.07392295694258792 | validation: 0.06538104200369971]
	TIME [epoch: 6.44 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07293289215739297		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.07293289215739297 | validation: 0.07091993180928764]
	TIME [epoch: 6.42 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06969129840820054		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.06969129840820054 | validation: 0.05713089874251887]
	TIME [epoch: 6.42 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05254618617014252		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.05254618617014252 | validation: 0.04596364234885357]
	TIME [epoch: 6.42 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05946488900879964		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.05946488900879964 | validation: 0.07542347192534092]
	TIME [epoch: 6.42 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05570874946418016		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.05570874946418016 | validation: 0.059279655605554434]
	TIME [epoch: 6.42 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05948548440791998		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.05948548440791998 | validation: 0.059126841415486756]
	TIME [epoch: 6.44 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05329976680324292		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.05329976680324292 | validation: 0.06256882679167688]
	TIME [epoch: 6.44 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06259744720099485		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.06259744720099485 | validation: 0.0590855960315879]
	TIME [epoch: 6.42 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05672260829227586		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.05672260829227586 | validation: 0.07323859125325505]
	TIME [epoch: 6.42 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0712950283892981		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.0712950283892981 | validation: 0.15167452503637643]
	TIME [epoch: 6.42 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09241020007226916		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.09241020007226916 | validation: 0.12264577085978402]
	TIME [epoch: 6.42 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0665192140103103		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.0665192140103103 | validation: 0.06925458317199937]
	TIME [epoch: 6.43 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06641098647009994		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.06641098647009994 | validation: 0.11901130383993298]
	TIME [epoch: 6.42 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07789283575722428		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.07789283575722428 | validation: 0.09584715634950211]
	TIME [epoch: 6.46 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0609966060813241		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.0609966060813241 | validation: 0.07997794905606455]
	TIME [epoch: 6.42 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05691095330228408		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.05691095330228408 | validation: 0.07205743306738606]
	TIME [epoch: 6.42 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06012843478388204		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.06012843478388204 | validation: 0.03816873855210218]
	TIME [epoch: 6.41 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07832647934193314		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.07832647934193314 | validation: 0.06336838311849902]
	TIME [epoch: 6.42 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08991247913056606		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.08991247913056606 | validation: 0.04072291491009695]
	TIME [epoch: 6.41 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06652335028215114		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.06652335028215114 | validation: 0.04851852792540869]
	TIME [epoch: 6.41 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06994200524181665		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.06994200524181665 | validation: 0.06266315593640492]
	TIME [epoch: 6.45 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05492025009743054		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.05492025009743054 | validation: 0.061752563819659836]
	TIME [epoch: 6.42 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05578494223647193		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.05578494223647193 | validation: 0.058976148392819505]
	TIME [epoch: 6.41 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04794044838171174		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.04794044838171174 | validation: 0.049540498801827]
	TIME [epoch: 6.41 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05318616140062182		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.05318616140062182 | validation: 0.05973788691654022]
	TIME [epoch: 6.41 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053084894174712266		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.053084894174712266 | validation: 0.1314462782086737]
	TIME [epoch: 6.41 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07351454388700746		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.07351454388700746 | validation: 0.07788233980818016]
	TIME [epoch: 6.41 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.061936483143780446		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.061936483143780446 | validation: 0.10279817220962563]
	TIME [epoch: 6.44 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057890979334664736		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.057890979334664736 | validation: 0.07272389419471934]
	TIME [epoch: 6.41 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06350814445568606		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.06350814445568606 | validation: 0.10114334117262025]
	TIME [epoch: 6.41 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057526791504719677		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.057526791504719677 | validation: 0.06570253281604592]
	TIME [epoch: 6.41 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09765818517285473		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.09765818517285473 | validation: 0.07915946598819312]
	TIME [epoch: 6.41 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05695147598192937		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.05695147598192937 | validation: 0.07704395582769726]
	TIME [epoch: 6.41 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06619613303625815		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.06619613303625815 | validation: 0.05137838722020721]
	TIME [epoch: 6.41 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0616145156759247		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.0616145156759247 | validation: 0.09499869775859572]
	TIME [epoch: 6.44 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06408352578503468		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.06408352578503468 | validation: 0.048439505882702]
	TIME [epoch: 6.41 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053129125814637995		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.053129125814637995 | validation: 0.06558774182004891]
	TIME [epoch: 6.41 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06236269603233083		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.06236269603233083 | validation: 0.12313218134283326]
	TIME [epoch: 6.41 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06745956989774074		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.06745956989774074 | validation: 0.060953478472623605]
	TIME [epoch: 6.41 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044296157847423155		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.044296157847423155 | validation: 0.1017173404842421]
	TIME [epoch: 6.41 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05856101521181378		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.05856101521181378 | validation: 0.026900889499648244]
	TIME [epoch: 6.41 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057450077068699965		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.057450077068699965 | validation: 0.041375238931797544]
	TIME [epoch: 6.43 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053254093204880615		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.053254093204880615 | validation: 0.04916390894214029]
	TIME [epoch: 6.43 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055355021384964856		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.055355021384964856 | validation: 0.04139861216189286]
	TIME [epoch: 6.41 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052541421194181905		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.052541421194181905 | validation: 0.04933083914316207]
	TIME [epoch: 6.41 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05893596385845495		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.05893596385845495 | validation: 0.02967824852130366]
	TIME [epoch: 6.41 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05017874154349834		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.05017874154349834 | validation: 0.03869638157191434]
	TIME [epoch: 6.41 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06321006928045006		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.06321006928045006 | validation: 0.041628822061773346]
	TIME [epoch: 6.41 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05509180280707229		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.05509180280707229 | validation: 0.044123957813381035]
	TIME [epoch: 6.42 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04853538106545071		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.04853538106545071 | validation: 0.049962680999886065]
	TIME [epoch: 6.44 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0468968978211619		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.0468968978211619 | validation: 0.03401256614831358]
	TIME [epoch: 6.41 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04657410714335268		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.04657410714335268 | validation: 0.03756223631021233]
	TIME [epoch: 6.41 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05336765841334844		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.05336765841334844 | validation: 0.032843666064933066]
	TIME [epoch: 6.41 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049310471310080074		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.049310471310080074 | validation: 0.026787840387633956]
	TIME [epoch: 6.41 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04914417036104725		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.04914417036104725 | validation: 0.030841444229551353]
	TIME [epoch: 6.41 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04893251595825171		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.04893251595825171 | validation: 0.04094836207880512]
	TIME [epoch: 6.42 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0662987150888793		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.0662987150888793 | validation: 0.051757058263696525]
	TIME [epoch: 6.44 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.058700632198127586		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.058700632198127586 | validation: 0.05745118041349726]
	TIME [epoch: 6.42 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05341031590943128		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.05341031590943128 | validation: 0.03479163655723981]
	TIME [epoch: 6.41 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06544324253118813		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.06544324253118813 | validation: 0.06185842254206233]
	TIME [epoch: 6.41 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05365777697579545		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.05365777697579545 | validation: 0.034452493251142774]
	TIME [epoch: 6.41 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05938944565625604		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.05938944565625604 | validation: 0.07329075461039339]
	TIME [epoch: 6.41 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0724155885454985		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.0724155885454985 | validation: 0.03089976308148864]
	TIME [epoch: 6.41 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07326707368503965		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.07326707368503965 | validation: 0.056539292026700425]
	TIME [epoch: 6.44 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05211758692072936		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.05211758692072936 | validation: 0.03525199229184228]
	TIME [epoch: 6.42 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05079167452223411		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.05079167452223411 | validation: 0.08820584280760725]
	TIME [epoch: 6.41 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06322249734989957		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.06322249734989957 | validation: 0.06443097893994403]
	TIME [epoch: 6.41 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05544719691122556		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.05544719691122556 | validation: 0.04249171114469134]
	TIME [epoch: 6.41 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04739463693171955		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.04739463693171955 | validation: 0.07876897863311738]
	TIME [epoch: 6.41 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0538964966246773		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.0538964966246773 | validation: 0.10293172557397334]
	TIME [epoch: 6.42 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07083396907733945		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.07083396907733945 | validation: 0.05939708264065539]
	TIME [epoch: 6.44 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06128288971708485		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.06128288971708485 | validation: 0.036096890043959114]
	TIME [epoch: 6.42 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05062445069822118		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.05062445069822118 | validation: 0.05917921144295809]
	TIME [epoch: 6.41 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07714877462165022		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.07714877462165022 | validation: 0.07813909488818697]
	TIME [epoch: 6.41 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050150971862948604		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.050150971862948604 | validation: 0.04450075743263824]
	TIME [epoch: 6.42 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057818420444098406		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.057818420444098406 | validation: 0.08020878897194894]
	TIME [epoch: 6.42 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06266967207274744		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.06266967207274744 | validation: 0.053337470055613914]
	TIME [epoch: 6.42 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06365551897797742		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.06365551897797742 | validation: 0.0479474348497383]
	TIME [epoch: 6.43 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05526397268510781		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.05526397268510781 | validation: 0.05227838928380226]
	TIME [epoch: 6.43 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0577691898372118		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.0577691898372118 | validation: 0.052356401849021204]
	TIME [epoch: 6.42 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.057765282170517		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.057765282170517 | validation: 0.0710660141779579]
	TIME [epoch: 6.41 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05038155772517591		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.05038155772517591 | validation: 0.0667695121616951]
	TIME [epoch: 6.42 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05596726122417601		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.05596726122417601 | validation: 0.050607088363407424]
	TIME [epoch: 6.42 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05784121645685376		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.05784121645685376 | validation: 0.05962236320965836]
	TIME [epoch: 6.42 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053805848120168656		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.053805848120168656 | validation: 0.0644811141053087]
	TIME [epoch: 6.43 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06518377577345111		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.06518377577345111 | validation: 0.07044720355564633]
	TIME [epoch: 6.44 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05488790183395926		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.05488790183395926 | validation: 0.08261345740884542]
	TIME [epoch: 6.42 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06818920595963776		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.06818920595963776 | validation: 0.053701391826973754]
	TIME [epoch: 6.42 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07409425167549878		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.07409425167549878 | validation: 0.06195771320568337]
	TIME [epoch: 6.42 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.054528977316188706		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.054528977316188706 | validation: 0.048699981118629936]
	TIME [epoch: 6.42 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07394524211177209		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.07394524211177209 | validation: 0.13130409719711963]
	TIME [epoch: 6.42 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08200696604943557		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.08200696604943557 | validation: 0.05846686241009796]
	TIME [epoch: 6.42 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05371238686050498		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.05371238686050498 | validation: 0.03441234709353942]
	TIME [epoch: 6.45 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04426740551215576		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.04426740551215576 | validation: 0.07640877146422587]
	TIME [epoch: 6.42 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049338450447604834		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.049338450447604834 | validation: 0.054248450564189296]
	TIME [epoch: 6.42 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04750709899280882		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.04750709899280882 | validation: 0.044472351650825095]
	TIME [epoch: 6.41 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08026736347975305		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.08026736347975305 | validation: 0.04035803113140745]
	TIME [epoch: 6.42 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05709652857613955		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.05709652857613955 | validation: 0.030309290890811445]
	TIME [epoch: 6.42 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05253222206795992		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.05253222206795992 | validation: 0.021051630922519726]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_1192.pth
	Model improved!!!
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06996890903896363		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.06996890903896363 | validation: 0.03647047916701917]
	TIME [epoch: 6.44 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049890729783428005		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.049890729783428005 | validation: 0.045000662158200026]
	TIME [epoch: 6.42 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04977000078222122		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.04977000078222122 | validation: 0.06091849345861083]
	TIME [epoch: 6.41 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05074549362836717		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.05074549362836717 | validation: 0.06646038881992271]
	TIME [epoch: 6.42 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05323092930090733		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.05323092930090733 | validation: 0.08149660047361185]
	TIME [epoch: 6.42 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0561318926633108		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.0561318926633108 | validation: 0.11750726908527444]
	TIME [epoch: 6.41 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0779469238223244		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.0779469238223244 | validation: 0.09366126685054954]
	TIME [epoch: 6.41 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06488071298089998		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.06488071298089998 | validation: 0.06571452263922231]
	TIME [epoch: 6.45 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0500304403519264		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.0500304403519264 | validation: 0.07423848983472464]
	TIME [epoch: 6.41 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05699426772486721		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.05699426772486721 | validation: 0.06957393606326154]
	TIME [epoch: 6.41 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07950160640476882		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.07950160640476882 | validation: 0.22386649262438518]
	TIME [epoch: 6.41 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.14675483476205978		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.14675483476205978 | validation: 0.10682343312149986]
	TIME [epoch: 6.41 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06190084370535179		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.06190084370535179 | validation: 0.06807112203552505]
	TIME [epoch: 6.41 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0549567792756263		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.0549567792756263 | validation: 0.09287841041622903]
	TIME [epoch: 6.41 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08041325016473452		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.08041325016473452 | validation: 0.1024110984118526]
	TIME [epoch: 6.45 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06215851692281943		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.06215851692281943 | validation: 0.08285607427313846]
	TIME [epoch: 6.42 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06023708916299785		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.06023708916299785 | validation: 0.06478847766842422]
	TIME [epoch: 6.42 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05092296367201249		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.05092296367201249 | validation: 0.07378098247533647]
	TIME [epoch: 6.42 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06540928670130965		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.06540928670130965 | validation: 0.1023745086321734]
	TIME [epoch: 6.41 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05887652906685732		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.05887652906685732 | validation: 0.07034598819753668]
	TIME [epoch: 6.42 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05399441567229304		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.05399441567229304 | validation: 0.06898690346817211]
	TIME [epoch: 6.41 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06635931394008346		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.06635931394008346 | validation: 0.093266656538239]
	TIME [epoch: 6.45 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.11534065816389408		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.11534065816389408 | validation: 0.03719743524642601]
	TIME [epoch: 6.41 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06608002577077954		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.06608002577077954 | validation: 0.08397683956920464]
	TIME [epoch: 6.42 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06981892094817296		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.06981892094817296 | validation: 0.05275885144090856]
	TIME [epoch: 6.42 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053691634187007876		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.053691634187007876 | validation: 0.032066714494523606]
	TIME [epoch: 6.42 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04693766695828411		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.04693766695828411 | validation: 0.07060630977778705]
	TIME [epoch: 6.42 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05469575101644166		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.05469575101644166 | validation: 0.05770929801053864]
	TIME [epoch: 6.41 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04620234352989414		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.04620234352989414 | validation: 0.04188375543536565]
	TIME [epoch: 6.43 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05783571789227129		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.05783571789227129 | validation: 0.0560382875355093]
	TIME [epoch: 6.44 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05009481433999579		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.05009481433999579 | validation: 0.03801118629073093]
	TIME [epoch: 6.41 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05018340465496672		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.05018340465496672 | validation: 0.0570734863496552]
	TIME [epoch: 6.42 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0613057524084464		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.0613057524084464 | validation: 0.06659126406147155]
	TIME [epoch: 6.41 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05645606037904109		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.05645606037904109 | validation: 0.0658027412766235]
	TIME [epoch: 6.41 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05746274311630242		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.05746274311630242 | validation: 0.0868354836388085]
	TIME [epoch: 6.41 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059341071248669275		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.059341071248669275 | validation: 0.09664461761339592]
	TIME [epoch: 6.42 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06972754055656086		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.06972754055656086 | validation: 0.0970647674863368]
	TIME [epoch: 6.44 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07316172279607061		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.07316172279607061 | validation: 0.11509507214973752]
	TIME [epoch: 6.42 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09544703172781965		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.09544703172781965 | validation: 0.16340917101250027]
	TIME [epoch: 6.41 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09223404660019793		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.09223404660019793 | validation: 0.13335676980180147]
	TIME [epoch: 6.42 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09933137946106775		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.09933137946106775 | validation: 0.10110910733728457]
	TIME [epoch: 6.41 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08243364602490526		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.08243364602490526 | validation: 0.12600441096817708]
	TIME [epoch: 6.42 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09049919762054394		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.09049919762054394 | validation: 0.08856161556671176]
	TIME [epoch: 6.42 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06941112722734266		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.06941112722734266 | validation: 0.06348582957770556]
	TIME [epoch: 6.45 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06061429365604902		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.06061429365604902 | validation: 0.044990165724373005]
	TIME [epoch: 6.42 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05208542155500247		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.05208542155500247 | validation: 0.07876546233257266]
	TIME [epoch: 6.42 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06072524393365051		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.06072524393365051 | validation: 0.038301423271837345]
	TIME [epoch: 6.41 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04994243436152896		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.04994243436152896 | validation: 0.05476690456826528]
	TIME [epoch: 6.42 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05472129309623357		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.05472129309623357 | validation: 0.059347619733967]
	TIME [epoch: 6.42 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05834428233793165		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.05834428233793165 | validation: 0.04704563637061249]
	TIME [epoch: 6.42 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05175618812523984		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.05175618812523984 | validation: 0.04795080694542939]
	TIME [epoch: 6.45 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04654649824405218		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.04654649824405218 | validation: 0.0486025639783235]
	TIME [epoch: 6.42 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04731820477393384		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.04731820477393384 | validation: 0.03888465780944043]
	TIME [epoch: 6.42 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052748262250024394		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.052748262250024394 | validation: 0.07956050446990841]
	TIME [epoch: 6.42 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05579977022942064		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.05579977022942064 | validation: 0.05959542719902238]
	TIME [epoch: 6.41 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045752328317020974		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.045752328317020974 | validation: 0.038984339300578943]
	TIME [epoch: 6.41 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044031517547806355		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.044031517547806355 | validation: 0.05696817947715938]
	TIME [epoch: 6.42 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04785633851342665		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.04785633851342665 | validation: 0.0442027840337121]
	TIME [epoch: 6.45 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040214334442443996		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.040214334442443996 | validation: 0.03813513713067482]
	TIME [epoch: 6.42 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04155459056661829		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.04155459056661829 | validation: 0.06203561029958852]
	TIME [epoch: 6.42 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04121931042830738		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.04121931042830738 | validation: 0.0465994430094677]
	TIME [epoch: 6.42 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05269583236256753		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.05269583236256753 | validation: 0.0422284757908543]
	TIME [epoch: 6.42 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04068122821059177		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.04068122821059177 | validation: 0.03871220104481293]
	TIME [epoch: 6.42 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04473858609767721		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.04473858609767721 | validation: 0.028944985282454018]
	TIME [epoch: 6.42 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04367621520866744		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.04367621520866744 | validation: 0.03999918815895194]
	TIME [epoch: 6.45 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050205784187909136		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.050205784187909136 | validation: 0.05967279036615491]
	TIME [epoch: 6.43 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0508986396880779		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.0508986396880779 | validation: 0.04677559046039226]
	TIME [epoch: 6.42 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05116439065730237		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.05116439065730237 | validation: 0.04272912958478036]
	TIME [epoch: 6.42 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05926129733183286		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.05926129733183286 | validation: 0.04457592309062072]
	TIME [epoch: 6.42 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049401570621413794		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.049401570621413794 | validation: 0.06176329967686379]
	TIME [epoch: 6.42 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05551080221252596		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.05551080221252596 | validation: 0.08306659028990747]
	TIME [epoch: 6.42 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05268424808113656		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.05268424808113656 | validation: 0.07143626474084751]
	TIME [epoch: 6.44 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053146732787624607		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.053146732787624607 | validation: 0.0682708866444111]
	TIME [epoch: 6.44 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05340398272978781		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.05340398272978781 | validation: 0.06813892620336401]
	TIME [epoch: 6.42 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05718044724861959		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.05718044724861959 | validation: 0.03801981909190343]
	TIME [epoch: 6.42 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05678434158073842		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.05678434158073842 | validation: 0.050361825463542884]
	TIME [epoch: 6.42 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08599875847705887		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.08599875847705887 | validation: 0.06475809362994892]
	TIME [epoch: 6.42 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07532287890728787		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.07532287890728787 | validation: 0.038936796345733535]
	TIME [epoch: 6.42 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06297002954250887		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.06297002954250887 | validation: 0.044168363216978604]
	TIME [epoch: 6.42 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05777202591510989		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.05777202591510989 | validation: 0.04823587597252052]
	TIME [epoch: 6.45 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0803593028456735		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.0803593028456735 | validation: 0.03133933995722619]
	TIME [epoch: 6.42 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053401769914942804		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.053401769914942804 | validation: 0.034799705376606635]
	TIME [epoch: 6.42 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060014783329130614		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.060014783329130614 | validation: 0.056255590278867736]
	TIME [epoch: 6.42 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05529341091643476		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.05529341091643476 | validation: 0.03313199836566299]
	TIME [epoch: 6.42 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04659751374822577		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.04659751374822577 | validation: 0.03443558718592878]
	TIME [epoch: 6.42 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04491802661263351		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.04491802661263351 | validation: 0.03965179902955055]
	TIME [epoch: 6.42 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04465049104799471		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.04465049104799471 | validation: 0.060206519513221174]
	TIME [epoch: 6.45 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04696963947506325		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.04696963947506325 | validation: 0.04023130008579211]
	TIME [epoch: 6.42 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345940479415306		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.04345940479415306 | validation: 0.035887144770378895]
	TIME [epoch: 6.42 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04876293822376565		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.04876293822376565 | validation: 0.03293126079756445]
	TIME [epoch: 6.42 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04511064777992016		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.04511064777992016 | validation: 0.03741314203752247]
	TIME [epoch: 6.42 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04364017521469449		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.04364017521469449 | validation: 0.03502041969472236]
	TIME [epoch: 6.42 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039458924371250884		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.039458924371250884 | validation: 0.04052721453823766]
	TIME [epoch: 6.42 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04847904182718972		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.04847904182718972 | validation: 0.07446406380929506]
	TIME [epoch: 6.46 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05013097682431167		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.05013097682431167 | validation: 0.03756266604119917]
	TIME [epoch: 6.42 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043530973901235705		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.043530973901235705 | validation: 0.04588018776087093]
	TIME [epoch: 6.42 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047002335651675		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.047002335651675 | validation: 0.04677925197326631]
	TIME [epoch: 6.42 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04180418169464484		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.04180418169464484 | validation: 0.05094899410987996]
	TIME [epoch: 6.42 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04132025490965014		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.04132025490965014 | validation: 0.03626511271588224]
	TIME [epoch: 6.42 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04508284368195312		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.04508284368195312 | validation: 0.03438021781889022]
	TIME [epoch: 6.42 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0469272952279868		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.0469272952279868 | validation: 0.03440784425820466]
	TIME [epoch: 6.45 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037990102634723966		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.037990102634723966 | validation: 0.03533642740360406]
	TIME [epoch: 6.43 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04070045564806137		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.04070045564806137 | validation: 0.05813710903533606]
	TIME [epoch: 6.42 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053846077126132014		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.053846077126132014 | validation: 0.044623400770471736]
	TIME [epoch: 6.42 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04058151745490639		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.04058151745490639 | validation: 0.03673475795376191]
	TIME [epoch: 6.42 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0417131178081086		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.0417131178081086 | validation: 0.03587217334498914]
	TIME [epoch: 6.42 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045467654020694595		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.045467654020694595 | validation: 0.05378059753536932]
	TIME [epoch: 6.42 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04768893774074533		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.04768893774074533 | validation: 0.06433184487717955]
	TIME [epoch: 6.45 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05702976205519937		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.05702976205519937 | validation: 0.0953959598334988]
	TIME [epoch: 6.43 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06892356119046578		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.06892356119046578 | validation: 0.12194780370122106]
	TIME [epoch: 6.42 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.08032489959747474		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.08032489959747474 | validation: 0.12393038064501825]
	TIME [epoch: 6.42 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09991333609897218		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.09991333609897218 | validation: 0.09584735156013363]
	TIME [epoch: 6.42 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06258668946428919		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.06258668946428919 | validation: 0.10187384952172739]
	TIME [epoch: 6.42 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05566032143207661		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.05566032143207661 | validation: 0.04609568490373668]
	TIME [epoch: 6.42 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04870355375854737		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.04870355375854737 | validation: 0.05404071870956791]
	TIME [epoch: 6.44 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04691059384378431		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.04691059384378431 | validation: 0.03303390422635982]
	TIME [epoch: 6.44 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04445925464591538		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.04445925464591538 | validation: 0.027208234671007265]
	TIME [epoch: 6.42 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04856018442124764		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.04856018442124764 | validation: 0.0332320643077389]
	TIME [epoch: 6.42 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05867618262700265		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.05867618262700265 | validation: 0.05974226068791294]
	TIME [epoch: 6.42 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05740441438550635		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.05740441438550635 | validation: 0.045654365977555504]
	TIME [epoch: 6.42 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043149754006514246		[learning rate: 0.00011411]
	Learning Rate: 0.000114106
	LOSS [training: 0.043149754006514246 | validation: 0.039386920340831834]
	TIME [epoch: 6.42 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043185342843402086		[learning rate: 0.0001137]
	Learning Rate: 0.000113702
	LOSS [training: 0.043185342843402086 | validation: 0.03323360866386975]
	TIME [epoch: 6.44 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0425081233774884		[learning rate: 0.0001133]
	Learning Rate: 0.0001133
	LOSS [training: 0.0425081233774884 | validation: 0.024882839844934813]
	TIME [epoch: 6.44 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04160885153350288		[learning rate: 0.0001129]
	Learning Rate: 0.0001129
	LOSS [training: 0.04160885153350288 | validation: 0.031135696329371524]
	TIME [epoch: 6.42 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043978602535061695		[learning rate: 0.0001125]
	Learning Rate: 0.0001125
	LOSS [training: 0.043978602535061695 | validation: 0.03795720084067443]
	TIME [epoch: 6.42 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047747402512192984		[learning rate: 0.0001121]
	Learning Rate: 0.000112103
	LOSS [training: 0.047747402512192984 | validation: 0.029246335423118417]
	TIME [epoch: 6.42 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051690691720475135		[learning rate: 0.00011171]
	Learning Rate: 0.000111706
	LOSS [training: 0.051690691720475135 | validation: 0.043723088853980276]
	TIME [epoch: 6.42 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06190522207910651		[learning rate: 0.00011131]
	Learning Rate: 0.000111311
	LOSS [training: 0.06190522207910651 | validation: 0.039461205710688535]
	TIME [epoch: 6.42 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052375101986219766		[learning rate: 0.00011092]
	Learning Rate: 0.000110918
	LOSS [training: 0.052375101986219766 | validation: 0.04101109442330471]
	TIME [epoch: 6.42 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06609520790570667		[learning rate: 0.00011053]
	Learning Rate: 0.000110525
	LOSS [training: 0.06609520790570667 | validation: 0.06639773803528144]
	TIME [epoch: 6.45 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07091905747194531		[learning rate: 0.00011013]
	Learning Rate: 0.000110134
	LOSS [training: 0.07091905747194531 | validation: 0.03578396089305867]
	TIME [epoch: 6.42 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0446243530585874		[learning rate: 0.00010975]
	Learning Rate: 0.000109745
	LOSS [training: 0.0446243530585874 | validation: 0.028136092371214342]
	TIME [epoch: 6.42 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04387093180636178		[learning rate: 0.00010936]
	Learning Rate: 0.000109357
	LOSS [training: 0.04387093180636178 | validation: 0.0335415689980116]
	TIME [epoch: 6.42 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04701328626612928		[learning rate: 0.00010897]
	Learning Rate: 0.00010897
	LOSS [training: 0.04701328626612928 | validation: 0.03005370515913414]
	TIME [epoch: 6.42 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04260690152987251		[learning rate: 0.00010858]
	Learning Rate: 0.000108585
	LOSS [training: 0.04260690152987251 | validation: 0.033210692276955084]
	TIME [epoch: 6.42 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047361074229179075		[learning rate: 0.0001082]
	Learning Rate: 0.000108201
	LOSS [training: 0.047361074229179075 | validation: 0.043240858360194014]
	TIME [epoch: 6.42 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05318649304712048		[learning rate: 0.00010782]
	Learning Rate: 0.000107818
	LOSS [training: 0.05318649304712048 | validation: 0.036244613752697746]
	TIME [epoch: 6.46 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04231300545526025		[learning rate: 0.00010744]
	Learning Rate: 0.000107437
	LOSS [training: 0.04231300545526025 | validation: 0.04574041110159075]
	TIME [epoch: 6.43 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05561588286158654		[learning rate: 0.00010706]
	Learning Rate: 0.000107057
	LOSS [training: 0.05561588286158654 | validation: 0.07062604903880564]
	TIME [epoch: 6.42 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049229568034944146		[learning rate: 0.00010668]
	Learning Rate: 0.000106679
	LOSS [training: 0.049229568034944146 | validation: 0.02714646892405792]
	TIME [epoch: 6.42 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04229574847089495		[learning rate: 0.0001063]
	Learning Rate: 0.000106301
	LOSS [training: 0.04229574847089495 | validation: 0.031150447495508608]
	TIME [epoch: 6.42 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048918028305919826		[learning rate: 0.00010593]
	Learning Rate: 0.000105925
	LOSS [training: 0.048918028305919826 | validation: 0.0540761246145288]
	TIME [epoch: 6.42 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05865866548230057		[learning rate: 0.00010555]
	Learning Rate: 0.000105551
	LOSS [training: 0.05865866548230057 | validation: 0.028262897404470137]
	TIME [epoch: 6.42 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03824792709641161		[learning rate: 0.00010518]
	Learning Rate: 0.000105178
	LOSS [training: 0.03824792709641161 | validation: 0.03172411449876521]
	TIME [epoch: 6.45 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05098469607198795		[learning rate: 0.00010481]
	Learning Rate: 0.000104806
	LOSS [training: 0.05098469607198795 | validation: 0.04504432710454651]
	TIME [epoch: 6.43 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053151842875315845		[learning rate: 0.00010444]
	Learning Rate: 0.000104435
	LOSS [training: 0.053151842875315845 | validation: 0.03648468494490804]
	TIME [epoch: 6.42 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0454533210268016		[learning rate: 0.00010407]
	Learning Rate: 0.000104066
	LOSS [training: 0.0454533210268016 | validation: 0.031988060106319084]
	TIME [epoch: 6.42 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04746281214527459		[learning rate: 0.0001037]
	Learning Rate: 0.000103698
	LOSS [training: 0.04746281214527459 | validation: 0.041339926854483296]
	TIME [epoch: 6.42 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03897725936795955		[learning rate: 0.00010333]
	Learning Rate: 0.000103331
	LOSS [training: 0.03897725936795955 | validation: 0.050589875161084576]
	TIME [epoch: 6.42 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04406694592339392		[learning rate: 0.00010297]
	Learning Rate: 0.000102966
	LOSS [training: 0.04406694592339392 | validation: 0.032517582305708136]
	TIME [epoch: 6.42 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04535140691488129		[learning rate: 0.0001026]
	Learning Rate: 0.000102602
	LOSS [training: 0.04535140691488129 | validation: 0.07236911674335986]
	TIME [epoch: 6.45 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04480891789477999		[learning rate: 0.00010224]
	Learning Rate: 0.000102239
	LOSS [training: 0.04480891789477999 | validation: 0.06026367222084634]
	TIME [epoch: 6.43 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05513401679755889		[learning rate: 0.00010188]
	Learning Rate: 0.000101877
	LOSS [training: 0.05513401679755889 | validation: 0.0439358712936504]
	TIME [epoch: 6.42 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048091990616459676		[learning rate: 0.00010152]
	Learning Rate: 0.000101517
	LOSS [training: 0.048091990616459676 | validation: 0.03573584479560966]
	TIME [epoch: 6.42 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048184170155677185		[learning rate: 0.00010116]
	Learning Rate: 0.000101158
	LOSS [training: 0.048184170155677185 | validation: 0.0598767773301741]
	TIME [epoch: 6.42 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047835975095457645		[learning rate: 0.0001008]
	Learning Rate: 0.0001008
	LOSS [training: 0.047835975095457645 | validation: 0.0428710986996875]
	TIME [epoch: 6.42 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04469828239885863		[learning rate: 0.00010044]
	Learning Rate: 0.000100444
	LOSS [training: 0.04469828239885863 | validation: 0.05207416505919785]
	TIME [epoch: 6.42 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04655065566227002		[learning rate: 0.00010009]
	Learning Rate: 0.000100089
	LOSS [training: 0.04655065566227002 | validation: 0.03960633076430017]
	TIME [epoch: 6.44 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04162938017908782		[learning rate: 9.9735e-05]
	Learning Rate: 9.97347e-05
	LOSS [training: 0.04162938017908782 | validation: 0.0356696777178208]
	TIME [epoch: 6.44 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041992046044137823		[learning rate: 9.9382e-05]
	Learning Rate: 9.9382e-05
	LOSS [training: 0.041992046044137823 | validation: 0.032252778911317094]
	TIME [epoch: 6.42 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047981328287743166		[learning rate: 9.9031e-05]
	Learning Rate: 9.90306e-05
	LOSS [training: 0.047981328287743166 | validation: 0.03913153722527073]
	TIME [epoch: 6.42 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04298106618995758		[learning rate: 9.868e-05]
	Learning Rate: 9.86804e-05
	LOSS [training: 0.04298106618995758 | validation: 0.033672838273060786]
	TIME [epoch: 6.42 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04245230484497825		[learning rate: 9.8331e-05]
	Learning Rate: 9.83314e-05
	LOSS [training: 0.04245230484497825 | validation: 0.02508060745785459]
	TIME [epoch: 6.43 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04916448475619682		[learning rate: 9.7984e-05]
	Learning Rate: 9.79837e-05
	LOSS [training: 0.04916448475619682 | validation: 0.049488058862099144]
	TIME [epoch: 6.42 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05543816181430056		[learning rate: 9.7637e-05]
	Learning Rate: 9.76372e-05
	LOSS [training: 0.05543816181430056 | validation: 0.027040873616853853]
	TIME [epoch: 6.44 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049890582976211906		[learning rate: 9.7292e-05]
	Learning Rate: 9.7292e-05
	LOSS [training: 0.049890582976211906 | validation: 0.0737965626678372]
	TIME [epoch: 6.44 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06869742575065454		[learning rate: 9.6948e-05]
	Learning Rate: 9.69479e-05
	LOSS [training: 0.06869742575065454 | validation: 0.05137964600633139]
	TIME [epoch: 6.43 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06479557765519062		[learning rate: 9.6605e-05]
	Learning Rate: 9.66051e-05
	LOSS [training: 0.06479557765519062 | validation: 0.05691802713718036]
	TIME [epoch: 6.42 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04294840391745865		[learning rate: 9.6263e-05]
	Learning Rate: 9.62635e-05
	LOSS [training: 0.04294840391745865 | validation: 0.0297357303808203]
	TIME [epoch: 6.42 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046406036818028996		[learning rate: 9.5923e-05]
	Learning Rate: 9.59231e-05
	LOSS [training: 0.046406036818028996 | validation: 0.031352821246186345]
	TIME [epoch: 6.42 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04027666232632037		[learning rate: 9.5584e-05]
	Learning Rate: 9.55839e-05
	LOSS [training: 0.04027666232632037 | validation: 0.02949778796139032]
	TIME [epoch: 6.43 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04644242049300066		[learning rate: 9.5246e-05]
	Learning Rate: 9.52459e-05
	LOSS [training: 0.04644242049300066 | validation: 0.031389023315441474]
	TIME [epoch: 6.43 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0486046526870262		[learning rate: 9.4909e-05]
	Learning Rate: 9.49091e-05
	LOSS [training: 0.0486046526870262 | validation: 0.028262134014600822]
	TIME [epoch: 6.45 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05110842637709731		[learning rate: 9.4573e-05]
	Learning Rate: 9.45735e-05
	LOSS [training: 0.05110842637709731 | validation: 0.02938513086145422]
	TIME [epoch: 6.41 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04275183349097815		[learning rate: 9.4239e-05]
	Learning Rate: 9.4239e-05
	LOSS [training: 0.04275183349097815 | validation: 0.021273627500927757]
	TIME [epoch: 6.41 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0464460328231647		[learning rate: 9.3906e-05]
	Learning Rate: 9.39058e-05
	LOSS [training: 0.0464460328231647 | validation: 0.041459311694035945]
	TIME [epoch: 6.4 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04612864647283083		[learning rate: 9.3574e-05]
	Learning Rate: 9.35737e-05
	LOSS [training: 0.04612864647283083 | validation: 0.03220265994069019]
	TIME [epoch: 6.4 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046441377200480465		[learning rate: 9.3243e-05]
	Learning Rate: 9.32428e-05
	LOSS [training: 0.046441377200480465 | validation: 0.055557021248751885]
	TIME [epoch: 6.4 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050900339650772654		[learning rate: 9.2913e-05]
	Learning Rate: 9.29131e-05
	LOSS [training: 0.050900339650772654 | validation: 0.05393637777845725]
	TIME [epoch: 6.39 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05095805356192009		[learning rate: 9.2585e-05]
	Learning Rate: 9.25845e-05
	LOSS [training: 0.05095805356192009 | validation: 0.056938543713873926]
	TIME [epoch: 6.43 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04930118086543725		[learning rate: 9.2257e-05]
	Learning Rate: 9.22572e-05
	LOSS [training: 0.04930118086543725 | validation: 0.045055910053022834]
	TIME [epoch: 6.39 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042172962903631		[learning rate: 9.1931e-05]
	Learning Rate: 9.19309e-05
	LOSS [training: 0.042172962903631 | validation: 0.03463897177544396]
	TIME [epoch: 6.39 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04591231598155467		[learning rate: 9.1606e-05]
	Learning Rate: 9.16058e-05
	LOSS [training: 0.04591231598155467 | validation: 0.04655940333424018]
	TIME [epoch: 6.39 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0418012274576385		[learning rate: 9.1282e-05]
	Learning Rate: 9.12819e-05
	LOSS [training: 0.0418012274576385 | validation: 0.042914063105326826]
	TIME [epoch: 6.39 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04308151967492364		[learning rate: 9.0959e-05]
	Learning Rate: 9.09591e-05
	LOSS [training: 0.04308151967492364 | validation: 0.05442208681458277]
	TIME [epoch: 6.4 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047036363404387424		[learning rate: 9.0637e-05]
	Learning Rate: 9.06375e-05
	LOSS [training: 0.047036363404387424 | validation: 0.06313462515477133]
	TIME [epoch: 6.4 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0488604889196764		[learning rate: 9.0317e-05]
	Learning Rate: 9.03169e-05
	LOSS [training: 0.0488604889196764 | validation: 0.09168514160986573]
	TIME [epoch: 6.44 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05983857209937171		[learning rate: 8.9998e-05]
	Learning Rate: 8.99976e-05
	LOSS [training: 0.05983857209937171 | validation: 0.047586521375999204]
	TIME [epoch: 6.41 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04858740825044031		[learning rate: 8.9679e-05]
	Learning Rate: 8.96793e-05
	LOSS [training: 0.04858740825044031 | validation: 0.057151283339569446]
	TIME [epoch: 6.41 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07108590390382757		[learning rate: 8.9362e-05]
	Learning Rate: 8.93622e-05
	LOSS [training: 0.07108590390382757 | validation: 0.04446817716647658]
	TIME [epoch: 6.41 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04801891999909656		[learning rate: 8.9046e-05]
	Learning Rate: 8.90462e-05
	LOSS [training: 0.04801891999909656 | validation: 0.04158917936066703]
	TIME [epoch: 6.41 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0402629678502022		[learning rate: 8.8731e-05]
	Learning Rate: 8.87313e-05
	LOSS [training: 0.0402629678502022 | validation: 0.0326762652043053]
	TIME [epoch: 6.41 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041071838541552295		[learning rate: 8.8418e-05]
	Learning Rate: 8.84175e-05
	LOSS [training: 0.041071838541552295 | validation: 0.033543787752408676]
	TIME [epoch: 6.41 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039175455898919506		[learning rate: 8.8105e-05]
	Learning Rate: 8.81049e-05
	LOSS [training: 0.039175455898919506 | validation: 0.05753921201927616]
	TIME [epoch: 6.44 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05203786005634276		[learning rate: 8.7793e-05]
	Learning Rate: 8.77934e-05
	LOSS [training: 0.05203786005634276 | validation: 0.07642540238799952]
	TIME [epoch: 6.41 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07718724568469358		[learning rate: 8.7483e-05]
	Learning Rate: 8.74829e-05
	LOSS [training: 0.07718724568469358 | validation: 0.11467486991453947]
	TIME [epoch: 6.41 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.07994257172265952		[learning rate: 8.7174e-05]
	Learning Rate: 8.71735e-05
	LOSS [training: 0.07994257172265952 | validation: 0.08520833280400651]
	TIME [epoch: 6.41 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052334842298717946		[learning rate: 8.6865e-05]
	Learning Rate: 8.68653e-05
	LOSS [training: 0.052334842298717946 | validation: 0.06264979208264755]
	TIME [epoch: 6.41 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05203688531533451		[learning rate: 8.6558e-05]
	Learning Rate: 8.65581e-05
	LOSS [training: 0.05203688531533451 | validation: 0.062131663730592965]
	TIME [epoch: 6.41 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04840432360989562		[learning rate: 8.6252e-05]
	Learning Rate: 8.6252e-05
	LOSS [training: 0.04840432360989562 | validation: 0.05754673262212988]
	TIME [epoch: 6.42 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04542064933684744		[learning rate: 8.5947e-05]
	Learning Rate: 8.5947e-05
	LOSS [training: 0.04542064933684744 | validation: 0.052905676585523385]
	TIME [epoch: 6.42 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048013539059437595		[learning rate: 8.5643e-05]
	Learning Rate: 8.56431e-05
	LOSS [training: 0.048013539059437595 | validation: 0.061989793626560374]
	TIME [epoch: 6.42 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0551887546375054		[learning rate: 8.534e-05]
	Learning Rate: 8.53402e-05
	LOSS [training: 0.0551887546375054 | validation: 0.05236752175313056]
	TIME [epoch: 6.41 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04768503220951288		[learning rate: 8.5038e-05]
	Learning Rate: 8.50385e-05
	LOSS [training: 0.04768503220951288 | validation: 0.037302791582444705]
	TIME [epoch: 6.4 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045041519433133004		[learning rate: 8.4738e-05]
	Learning Rate: 8.47378e-05
	LOSS [training: 0.045041519433133004 | validation: 0.04437645750223343]
	TIME [epoch: 6.41 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045716284441575904		[learning rate: 8.4438e-05]
	Learning Rate: 8.44381e-05
	LOSS [training: 0.045716284441575904 | validation: 0.045460626459215385]
	TIME [epoch: 6.41 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04726710770830887		[learning rate: 8.414e-05]
	Learning Rate: 8.41395e-05
	LOSS [training: 0.04726710770830887 | validation: 0.05570498831549963]
	TIME [epoch: 6.41 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03924659496314491		[learning rate: 8.3842e-05]
	Learning Rate: 8.3842e-05
	LOSS [training: 0.03924659496314491 | validation: 0.04329683464458119]
	TIME [epoch: 6.41 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04147633985792488		[learning rate: 8.3546e-05]
	Learning Rate: 8.35455e-05
	LOSS [training: 0.04147633985792488 | validation: 0.06779901831408193]
	TIME [epoch: 6.44 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04080595392341457		[learning rate: 8.325e-05]
	Learning Rate: 8.32501e-05
	LOSS [training: 0.04080595392341457 | validation: 0.03465451084101683]
	TIME [epoch: 6.41 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04397151031684088		[learning rate: 8.2956e-05]
	Learning Rate: 8.29557e-05
	LOSS [training: 0.04397151031684088 | validation: 0.03292766582927406]
	TIME [epoch: 6.41 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04608065978565248		[learning rate: 8.2662e-05]
	Learning Rate: 8.26624e-05
	LOSS [training: 0.04608065978565248 | validation: 0.0371821276534783]
	TIME [epoch: 6.41 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03979992836433052		[learning rate: 8.237e-05]
	Learning Rate: 8.237e-05
	LOSS [training: 0.03979992836433052 | validation: 0.03507623421751107]
	TIME [epoch: 6.41 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05261070482183152		[learning rate: 8.2079e-05]
	Learning Rate: 8.20788e-05
	LOSS [training: 0.05261070482183152 | validation: 0.0391785757195107]
	TIME [epoch: 6.41 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04579432664433673		[learning rate: 8.1789e-05]
	Learning Rate: 8.17885e-05
	LOSS [training: 0.04579432664433673 | validation: 0.02158186677330837]
	TIME [epoch: 6.42 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05489189858729555		[learning rate: 8.1499e-05]
	Learning Rate: 8.14993e-05
	LOSS [training: 0.05489189858729555 | validation: 0.03127949122401717]
	TIME [epoch: 6.45 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043491466014081985		[learning rate: 8.1211e-05]
	Learning Rate: 8.12111e-05
	LOSS [training: 0.043491466014081985 | validation: 0.02934771922019086]
	TIME [epoch: 6.43 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04320727528501442		[learning rate: 8.0924e-05]
	Learning Rate: 8.0924e-05
	LOSS [training: 0.04320727528501442 | validation: 0.027487443332646234]
	TIME [epoch: 6.42 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04341690130943349		[learning rate: 8.0638e-05]
	Learning Rate: 8.06378e-05
	LOSS [training: 0.04341690130943349 | validation: 0.018254335131803526]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_1411.pth
	Model improved!!!
EPOCH 1412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04439073772195734		[learning rate: 8.0353e-05]
	Learning Rate: 8.03526e-05
	LOSS [training: 0.04439073772195734 | validation: 0.025687108882606696]
	TIME [epoch: 6.42 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04376066647397746		[learning rate: 8.0069e-05]
	Learning Rate: 8.00685e-05
	LOSS [training: 0.04376066647397746 | validation: 0.03045135056135007]
	TIME [epoch: 6.43 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05736327583944979		[learning rate: 7.9785e-05]
	Learning Rate: 7.97854e-05
	LOSS [training: 0.05736327583944979 | validation: 0.029795447322792407]
	TIME [epoch: 6.43 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04863454094268396		[learning rate: 7.9503e-05]
	Learning Rate: 7.95032e-05
	LOSS [training: 0.04863454094268396 | validation: 0.025319189885522838]
	TIME [epoch: 6.46 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04219586592890688		[learning rate: 7.9222e-05]
	Learning Rate: 7.92221e-05
	LOSS [training: 0.04219586592890688 | validation: 0.03491884044142462]
	TIME [epoch: 6.43 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05486935899107018		[learning rate: 7.8942e-05]
	Learning Rate: 7.8942e-05
	LOSS [training: 0.05486935899107018 | validation: 0.04583495565866507]
	TIME [epoch: 6.42 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055666724547746974		[learning rate: 7.8663e-05]
	Learning Rate: 7.86628e-05
	LOSS [training: 0.055666724547746974 | validation: 0.028929387998576316]
	TIME [epoch: 6.42 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04394754033337323		[learning rate: 7.8385e-05]
	Learning Rate: 7.83846e-05
	LOSS [training: 0.04394754033337323 | validation: 0.026692080166374754]
	TIME [epoch: 6.43 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04171483799313462		[learning rate: 7.8107e-05]
	Learning Rate: 7.81074e-05
	LOSS [training: 0.04171483799313462 | validation: 0.039396620726379276]
	TIME [epoch: 6.43 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042837387196570695		[learning rate: 7.7831e-05]
	Learning Rate: 7.78312e-05
	LOSS [training: 0.042837387196570695 | validation: 0.025573591718136075]
	TIME [epoch: 6.43 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041347240667294984		[learning rate: 7.7556e-05]
	Learning Rate: 7.7556e-05
	LOSS [training: 0.041347240667294984 | validation: 0.0335985736293584]
	TIME [epoch: 6.46 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0406379001263185		[learning rate: 7.7282e-05]
	Learning Rate: 7.72818e-05
	LOSS [training: 0.0406379001263185 | validation: 0.039367725245737034]
	TIME [epoch: 6.44 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.048884182916185626		[learning rate: 7.7008e-05]
	Learning Rate: 7.70085e-05
	LOSS [training: 0.048884182916185626 | validation: 0.047539929839564156]
	TIME [epoch: 6.42 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05996907272918939		[learning rate: 7.6736e-05]
	Learning Rate: 7.67362e-05
	LOSS [training: 0.05996907272918939 | validation: 0.03549300277048129]
	TIME [epoch: 6.43 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046862338186164934		[learning rate: 7.6465e-05]
	Learning Rate: 7.64648e-05
	LOSS [training: 0.046862338186164934 | validation: 0.0378805406582083]
	TIME [epoch: 6.42 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04223923510209599		[learning rate: 7.6194e-05]
	Learning Rate: 7.61944e-05
	LOSS [training: 0.04223923510209599 | validation: 0.04775291505541091]
	TIME [epoch: 6.43 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04446448194661426		[learning rate: 7.5925e-05]
	Learning Rate: 7.5925e-05
	LOSS [training: 0.04446448194661426 | validation: 0.04272187146001448]
	TIME [epoch: 6.43 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04637435912788793		[learning rate: 7.5656e-05]
	Learning Rate: 7.56565e-05
	LOSS [training: 0.04637435912788793 | validation: 0.04643573825548506]
	TIME [epoch: 6.46 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045987511442332464		[learning rate: 7.5389e-05]
	Learning Rate: 7.5389e-05
	LOSS [training: 0.045987511442332464 | validation: 0.06729054992284172]
	TIME [epoch: 6.43 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06602269614880965		[learning rate: 7.5122e-05]
	Learning Rate: 7.51224e-05
	LOSS [training: 0.06602269614880965 | validation: 0.07357931803345419]
	TIME [epoch: 6.42 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045079247696618176		[learning rate: 7.4857e-05]
	Learning Rate: 7.48567e-05
	LOSS [training: 0.045079247696618176 | validation: 0.029755533559086427]
	TIME [epoch: 6.42 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03739094038482577		[learning rate: 7.4592e-05]
	Learning Rate: 7.4592e-05
	LOSS [training: 0.03739094038482577 | validation: 0.04416617850679959]
	TIME [epoch: 6.42 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03933298812836541		[learning rate: 7.4328e-05]
	Learning Rate: 7.43283e-05
	LOSS [training: 0.03933298812836541 | validation: 0.03766528676435442]
	TIME [epoch: 6.43 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04373729849986832		[learning rate: 7.4065e-05]
	Learning Rate: 7.40654e-05
	LOSS [training: 0.04373729849986832 | validation: 0.04489816074003519]
	TIME [epoch: 6.43 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03876494164532132		[learning rate: 7.3803e-05]
	Learning Rate: 7.38035e-05
	LOSS [training: 0.03876494164532132 | validation: 0.04376040942330806]
	TIME [epoch: 6.46 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03951352604208477		[learning rate: 7.3543e-05]
	Learning Rate: 7.35425e-05
	LOSS [training: 0.03951352604208477 | validation: 0.02799225561137221]
	TIME [epoch: 6.43 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039447086995937714		[learning rate: 7.3282e-05]
	Learning Rate: 7.32825e-05
	LOSS [training: 0.039447086995937714 | validation: 0.022122079418676017]
	TIME [epoch: 6.42 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044365701243283547		[learning rate: 7.3023e-05]
	Learning Rate: 7.30233e-05
	LOSS [training: 0.044365701243283547 | validation: 0.03358096861810963]
	TIME [epoch: 6.43 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04342003716521008		[learning rate: 7.2765e-05]
	Learning Rate: 7.27651e-05
	LOSS [training: 0.04342003716521008 | validation: 0.03165103913599663]
	TIME [epoch: 6.43 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03910130321969956		[learning rate: 7.2508e-05]
	Learning Rate: 7.25078e-05
	LOSS [training: 0.03910130321969956 | validation: 0.02665287163793712]
	TIME [epoch: 6.43 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04370517526303067		[learning rate: 7.2251e-05]
	Learning Rate: 7.22514e-05
	LOSS [training: 0.04370517526303067 | validation: 0.03942202711258851]
	TIME [epoch: 6.43 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049122801441624016		[learning rate: 7.1996e-05]
	Learning Rate: 7.19959e-05
	LOSS [training: 0.049122801441624016 | validation: 0.03776851812865721]
	TIME [epoch: 6.44 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055569435046787186		[learning rate: 7.1741e-05]
	Learning Rate: 7.17413e-05
	LOSS [training: 0.055569435046787186 | validation: 0.027923039119291563]
	TIME [epoch: 6.45 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.050063566443376326		[learning rate: 7.1488e-05]
	Learning Rate: 7.14876e-05
	LOSS [training: 0.050063566443376326 | validation: 0.042601665280793094]
	TIME [epoch: 6.43 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059101362039146586		[learning rate: 7.1235e-05]
	Learning Rate: 7.12348e-05
	LOSS [training: 0.059101362039146586 | validation: 0.031666959536514536]
	TIME [epoch: 6.43 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04717518852453706		[learning rate: 7.0983e-05]
	Learning Rate: 7.09829e-05
	LOSS [training: 0.04717518852453706 | validation: 0.028934170908024106]
	TIME [epoch: 6.43 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06197437490300931		[learning rate: 7.0732e-05]
	Learning Rate: 7.07319e-05
	LOSS [training: 0.06197437490300931 | validation: 0.03089799334195822]
	TIME [epoch: 6.43 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03917551997486106		[learning rate: 7.0482e-05]
	Learning Rate: 7.04818e-05
	LOSS [training: 0.03917551997486106 | validation: 0.05798160737209963]
	TIME [epoch: 6.43 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.059595047675807825		[learning rate: 7.0233e-05]
	Learning Rate: 7.02326e-05
	LOSS [training: 0.059595047675807825 | validation: 0.06970699365556407]
	TIME [epoch: 6.45 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046689746256473146		[learning rate: 6.9984e-05]
	Learning Rate: 6.99842e-05
	LOSS [training: 0.046689746256473146 | validation: 0.03189435891681075]
	TIME [epoch: 6.45 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04734020722591523		[learning rate: 6.9737e-05]
	Learning Rate: 6.97367e-05
	LOSS [training: 0.04734020722591523 | validation: 0.02971320347730961]
	TIME [epoch: 6.43 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04413884599572728		[learning rate: 6.949e-05]
	Learning Rate: 6.94901e-05
	LOSS [training: 0.04413884599572728 | validation: 0.024701694308579533]
	TIME [epoch: 6.43 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03841938496632834		[learning rate: 6.9244e-05]
	Learning Rate: 6.92444e-05
	LOSS [training: 0.03841938496632834 | validation: 0.034477078093705614]
	TIME [epoch: 6.43 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04762948570675974		[learning rate: 6.9e-05]
	Learning Rate: 6.89995e-05
	LOSS [training: 0.04762948570675974 | validation: 0.06286089644417053]
	TIME [epoch: 6.43 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043979856151260585		[learning rate: 6.8756e-05]
	Learning Rate: 6.87555e-05
	LOSS [training: 0.043979856151260585 | validation: 0.03145005129015653]
	TIME [epoch: 6.43 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04252572467219154		[learning rate: 6.8512e-05]
	Learning Rate: 6.85124e-05
	LOSS [training: 0.04252572467219154 | validation: 0.027744715541659647]
	TIME [epoch: 6.43 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04161670262355513		[learning rate: 6.827e-05]
	Learning Rate: 6.82702e-05
	LOSS [training: 0.04161670262355513 | validation: 0.03491782684743205]
	TIME [epoch: 6.46 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04648546124061946		[learning rate: 6.8029e-05]
	Learning Rate: 6.80287e-05
	LOSS [training: 0.04648546124061946 | validation: 0.03641551168282826]
	TIME [epoch: 6.43 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03973713416316142		[learning rate: 6.7788e-05]
	Learning Rate: 6.77882e-05
	LOSS [training: 0.03973713416316142 | validation: 0.033218201019578494]
	TIME [epoch: 6.43 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04277517235702804		[learning rate: 6.7548e-05]
	Learning Rate: 6.75485e-05
	LOSS [training: 0.04277517235702804 | validation: 0.037136215294062955]
	TIME [epoch: 6.42 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04136754986137795		[learning rate: 6.731e-05]
	Learning Rate: 6.73096e-05
	LOSS [training: 0.04136754986137795 | validation: 0.04512156443810384]
	TIME [epoch: 6.41 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04912227370195921		[learning rate: 6.7072e-05]
	Learning Rate: 6.70716e-05
	LOSS [training: 0.04912227370195921 | validation: 0.055138170282112826]
	TIME [epoch: 6.41 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043634756047382414		[learning rate: 6.6834e-05]
	Learning Rate: 6.68344e-05
	LOSS [training: 0.043634756047382414 | validation: 0.04402067626619484]
	TIME [epoch: 6.41 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04178058642429407		[learning rate: 6.6598e-05]
	Learning Rate: 6.65981e-05
	LOSS [training: 0.04178058642429407 | validation: 0.030027223743026833]
	TIME [epoch: 6.44 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04939832002486905		[learning rate: 6.6363e-05]
	Learning Rate: 6.63626e-05
	LOSS [training: 0.04939832002486905 | validation: 0.027731948389894453]
	TIME [epoch: 6.4 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05511198333596471		[learning rate: 6.6128e-05]
	Learning Rate: 6.61279e-05
	LOSS [training: 0.05511198333596471 | validation: 0.03427580392097778]
	TIME [epoch: 6.39 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053287750968162184		[learning rate: 6.5894e-05]
	Learning Rate: 6.58941e-05
	LOSS [training: 0.053287750968162184 | validation: 0.033372974400952785]
	TIME [epoch: 6.38 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05258592489572643		[learning rate: 6.5661e-05]
	Learning Rate: 6.5661e-05
	LOSS [training: 0.05258592489572643 | validation: 0.02952214452900123]
	TIME [epoch: 6.38 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05090334404803978		[learning rate: 6.5429e-05]
	Learning Rate: 6.54289e-05
	LOSS [training: 0.05090334404803978 | validation: 0.02845944698050359]
	TIME [epoch: 6.39 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05558154911199002		[learning rate: 6.5197e-05]
	Learning Rate: 6.51975e-05
	LOSS [training: 0.05558154911199002 | validation: 0.034616698781604685]
	TIME [epoch: 6.39 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04221762908084082		[learning rate: 6.4967e-05]
	Learning Rate: 6.49669e-05
	LOSS [training: 0.04221762908084082 | validation: 0.029258899448175446]
	TIME [epoch: 6.42 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040262633477949755		[learning rate: 6.4737e-05]
	Learning Rate: 6.47372e-05
	LOSS [training: 0.040262633477949755 | validation: 0.040888602347439]
	TIME [epoch: 6.4 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05100716140267626		[learning rate: 6.4508e-05]
	Learning Rate: 6.45083e-05
	LOSS [training: 0.05100716140267626 | validation: 0.03966441105748745]
	TIME [epoch: 6.39 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045250526441586454		[learning rate: 6.428e-05]
	Learning Rate: 6.42802e-05
	LOSS [training: 0.045250526441586454 | validation: 0.0438218400615249]
	TIME [epoch: 6.4 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04611847785673312		[learning rate: 6.4053e-05]
	Learning Rate: 6.40529e-05
	LOSS [training: 0.04611847785673312 | validation: 0.026461778435218814]
	TIME [epoch: 6.4 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03870631750891087		[learning rate: 6.3826e-05]
	Learning Rate: 6.38264e-05
	LOSS [training: 0.03870631750891087 | validation: 0.023637147613086974]
	TIME [epoch: 6.4 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04965476195633247		[learning rate: 6.3601e-05]
	Learning Rate: 6.36007e-05
	LOSS [training: 0.04965476195633247 | validation: 0.033366377838297163]
	TIME [epoch: 6.41 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04323262994581575		[learning rate: 6.3376e-05]
	Learning Rate: 6.33758e-05
	LOSS [training: 0.04323262994581575 | validation: 0.029085699691192582]
	TIME [epoch: 6.44 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04155224861676599		[learning rate: 6.3152e-05]
	Learning Rate: 6.31517e-05
	LOSS [training: 0.04155224861676599 | validation: 0.05035052251336676]
	TIME [epoch: 6.42 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04652092085285262		[learning rate: 6.2928e-05]
	Learning Rate: 6.29283e-05
	LOSS [training: 0.04652092085285262 | validation: 0.05091068769200268]
	TIME [epoch: 6.41 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04684151569999412		[learning rate: 6.2706e-05]
	Learning Rate: 6.27058e-05
	LOSS [training: 0.04684151569999412 | validation: 0.06950421098559537]
	TIME [epoch: 6.41 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0571238332106577		[learning rate: 6.2484e-05]
	Learning Rate: 6.24841e-05
	LOSS [training: 0.0571238332106577 | validation: 0.06884157057813377]
	TIME [epoch: 6.41 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04580559736024113		[learning rate: 6.2263e-05]
	Learning Rate: 6.22631e-05
	LOSS [training: 0.04580559736024113 | validation: 0.05202564653635251]
	TIME [epoch: 6.41 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05362640030032793		[learning rate: 6.2043e-05]
	Learning Rate: 6.20429e-05
	LOSS [training: 0.05362640030032793 | validation: 0.0801540078434253]
	TIME [epoch: 6.41 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0545033173414932		[learning rate: 6.1824e-05]
	Learning Rate: 6.18235e-05
	LOSS [training: 0.0545033173414932 | validation: 0.07083762378157213]
	TIME [epoch: 6.42 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05751108366872608		[learning rate: 6.1605e-05]
	Learning Rate: 6.16049e-05
	LOSS [training: 0.05751108366872608 | validation: 0.08086424497726415]
	TIME [epoch: 6.43 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.051723169556534616		[learning rate: 6.1387e-05]
	Learning Rate: 6.13871e-05
	LOSS [training: 0.051723169556534616 | validation: 0.05657832481138338]
	TIME [epoch: 6.41 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052838709698025746		[learning rate: 6.117e-05]
	Learning Rate: 6.117e-05
	LOSS [training: 0.052838709698025746 | validation: 0.06419678295019673]
	TIME [epoch: 6.41 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04716376098314764		[learning rate: 6.0954e-05]
	Learning Rate: 6.09537e-05
	LOSS [training: 0.04716376098314764 | validation: 0.04933882287387196]
	TIME [epoch: 6.42 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044223751359666226		[learning rate: 6.0738e-05]
	Learning Rate: 6.07382e-05
	LOSS [training: 0.044223751359666226 | validation: 0.05257688221178265]
	TIME [epoch: 6.42 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047448399599741405		[learning rate: 6.0523e-05]
	Learning Rate: 6.05234e-05
	LOSS [training: 0.047448399599741405 | validation: 0.054188667431470744]
	TIME [epoch: 6.42 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04360945428197749		[learning rate: 6.0309e-05]
	Learning Rate: 6.03094e-05
	LOSS [training: 0.04360945428197749 | validation: 0.05428621710278959]
	TIME [epoch: 6.43 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04460156947256062		[learning rate: 6.0096e-05]
	Learning Rate: 6.00961e-05
	LOSS [training: 0.04460156947256062 | validation: 0.040229369506466245]
	TIME [epoch: 6.46 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0464156301278475		[learning rate: 5.9884e-05]
	Learning Rate: 5.98836e-05
	LOSS [training: 0.0464156301278475 | validation: 0.052860385623577456]
	TIME [epoch: 6.43 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04829554721783327		[learning rate: 5.9672e-05]
	Learning Rate: 5.96718e-05
	LOSS [training: 0.04829554721783327 | validation: 0.05511392457170221]
	TIME [epoch: 6.43 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04574242781118995		[learning rate: 5.9461e-05]
	Learning Rate: 5.94608e-05
	LOSS [training: 0.04574242781118995 | validation: 0.049460555167094945]
	TIME [epoch: 6.43 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05194415411675721		[learning rate: 5.9251e-05]
	Learning Rate: 5.92505e-05
	LOSS [training: 0.05194415411675721 | validation: 0.045104597316024585]
	TIME [epoch: 6.42 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04315614377064858		[learning rate: 5.9041e-05]
	Learning Rate: 5.9041e-05
	LOSS [training: 0.04315614377064858 | validation: 0.035692080282007745]
	TIME [epoch: 6.43 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045215486932571436		[learning rate: 5.8832e-05]
	Learning Rate: 5.88323e-05
	LOSS [training: 0.045215486932571436 | validation: 0.05347553144618583]
	TIME [epoch: 6.43 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05265864052481077		[learning rate: 5.8624e-05]
	Learning Rate: 5.86242e-05
	LOSS [training: 0.05265864052481077 | validation: 0.07129329733578624]
	TIME [epoch: 6.46 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06069258146958059		[learning rate: 5.8417e-05]
	Learning Rate: 5.84169e-05
	LOSS [training: 0.06069258146958059 | validation: 0.07279002803462435]
	TIME [epoch: 6.43 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.06278489216415858		[learning rate: 5.821e-05]
	Learning Rate: 5.82103e-05
	LOSS [training: 0.06278489216415858 | validation: 0.10576748908310613]
	TIME [epoch: 6.42 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.09584034580244355		[learning rate: 5.8004e-05]
	Learning Rate: 5.80045e-05
	LOSS [training: 0.09584034580244355 | validation: 0.10995934306951805]
	TIME [epoch: 6.43 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0588724314695889		[learning rate: 5.7799e-05]
	Learning Rate: 5.77994e-05
	LOSS [training: 0.0588724314695889 | validation: 0.04881520258839626]
	TIME [epoch: 6.42 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04183886256308411		[learning rate: 5.7595e-05]
	Learning Rate: 5.7595e-05
	LOSS [training: 0.04183886256308411 | validation: 0.04116918636523355]
	TIME [epoch: 6.43 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042471171614472746		[learning rate: 5.7391e-05]
	Learning Rate: 5.73913e-05
	LOSS [training: 0.042471171614472746 | validation: 0.03888080743095979]
	TIME [epoch: 6.43 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04061935224571166		[learning rate: 5.7188e-05]
	Learning Rate: 5.71884e-05
	LOSS [training: 0.04061935224571166 | validation: 0.04355725823325186]
	TIME [epoch: 6.46 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04811249463697441		[learning rate: 5.6986e-05]
	Learning Rate: 5.69861e-05
	LOSS [training: 0.04811249463697441 | validation: 0.05839710656486275]
	TIME [epoch: 6.43 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04521915538523655		[learning rate: 5.6785e-05]
	Learning Rate: 5.67846e-05
	LOSS [training: 0.04521915538523655 | validation: 0.04252601573212264]
	TIME [epoch: 6.43 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045520997617228665		[learning rate: 5.6584e-05]
	Learning Rate: 5.65838e-05
	LOSS [training: 0.045520997617228665 | validation: 0.02991465471059933]
	TIME [epoch: 6.43 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.053553823773515766		[learning rate: 5.6384e-05]
	Learning Rate: 5.63837e-05
	LOSS [training: 0.053553823773515766 | validation: 0.0431093915077635]
	TIME [epoch: 6.43 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05213716276992807		[learning rate: 5.6184e-05]
	Learning Rate: 5.61844e-05
	LOSS [training: 0.05213716276992807 | validation: 0.03846198371885823]
	TIME [epoch: 6.43 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04083115956079354		[learning rate: 5.5986e-05]
	Learning Rate: 5.59857e-05
	LOSS [training: 0.04083115956079354 | validation: 0.038354543737676834]
	TIME [epoch: 6.43 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0414339074155278		[learning rate: 5.5788e-05]
	Learning Rate: 5.57877e-05
	LOSS [training: 0.0414339074155278 | validation: 0.040475315505559044]
	TIME [epoch: 6.46 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042873484382084014		[learning rate: 5.559e-05]
	Learning Rate: 5.55904e-05
	LOSS [training: 0.042873484382084014 | validation: 0.04163576571895554]
	TIME [epoch: 6.43 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042150119710143236		[learning rate: 5.5394e-05]
	Learning Rate: 5.53939e-05
	LOSS [training: 0.042150119710143236 | validation: 0.039178699280274155]
	TIME [epoch: 6.43 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04062982791280638		[learning rate: 5.5198e-05]
	Learning Rate: 5.5198e-05
	LOSS [training: 0.04062982791280638 | validation: 0.03668803674943508]
	TIME [epoch: 6.42 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04512017593820902		[learning rate: 5.5003e-05]
	Learning Rate: 5.50028e-05
	LOSS [training: 0.04512017593820902 | validation: 0.027275334960347147]
	TIME [epoch: 6.42 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04400381639966854		[learning rate: 5.4808e-05]
	Learning Rate: 5.48083e-05
	LOSS [training: 0.04400381639966854 | validation: 0.0364822236784258]
	TIME [epoch: 6.43 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.055585657815305715		[learning rate: 5.4614e-05]
	Learning Rate: 5.46145e-05
	LOSS [training: 0.055585657815305715 | validation: 0.04134422103767426]
	TIME [epoch: 6.43 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04956748145316452		[learning rate: 5.4421e-05]
	Learning Rate: 5.44213e-05
	LOSS [training: 0.04956748145316452 | validation: 0.03753810788287051]
	TIME [epoch: 6.46 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041521294188763186		[learning rate: 5.4229e-05]
	Learning Rate: 5.42289e-05
	LOSS [training: 0.041521294188763186 | validation: 0.030296902642999283]
	TIME [epoch: 6.43 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043833466665924		[learning rate: 5.4037e-05]
	Learning Rate: 5.40371e-05
	LOSS [training: 0.043833466665924 | validation: 0.03432410508865603]
	TIME [epoch: 6.43 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04385860888542137		[learning rate: 5.3846e-05]
	Learning Rate: 5.38461e-05
	LOSS [training: 0.04385860888542137 | validation: 0.04635310575725562]
	TIME [epoch: 6.42 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038499737667074846		[learning rate: 5.3656e-05]
	Learning Rate: 5.36556e-05
	LOSS [training: 0.038499737667074846 | validation: 0.019856189561342212]
	TIME [epoch: 6.43 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037596656180299656		[learning rate: 5.3466e-05]
	Learning Rate: 5.34659e-05
	LOSS [training: 0.037596656180299656 | validation: 0.031868606236973726]
	TIME [epoch: 6.42 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0411401006617891		[learning rate: 5.3277e-05]
	Learning Rate: 5.32769e-05
	LOSS [training: 0.0411401006617891 | validation: 0.030228461885114168]
	TIME [epoch: 6.42 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04390927797225547		[learning rate: 5.3088e-05]
	Learning Rate: 5.30884e-05
	LOSS [training: 0.04390927797225547 | validation: 0.03550358468990117]
	TIME [epoch: 6.44 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04692613967964097		[learning rate: 5.2901e-05]
	Learning Rate: 5.29007e-05
	LOSS [training: 0.04692613967964097 | validation: 0.033729716811321975]
	TIME [epoch: 6.44 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04638937114156695		[learning rate: 5.2714e-05]
	Learning Rate: 5.27137e-05
	LOSS [training: 0.04638937114156695 | validation: 0.048206737103638896]
	TIME [epoch: 6.42 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04346280865504028		[learning rate: 5.2527e-05]
	Learning Rate: 5.25272e-05
	LOSS [training: 0.04346280865504028 | validation: 0.038482409182620546]
	TIME [epoch: 6.43 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04462305688566409		[learning rate: 5.2342e-05]
	Learning Rate: 5.23415e-05
	LOSS [training: 0.04462305688566409 | validation: 0.05308460587091319]
	TIME [epoch: 6.42 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05191833539886534		[learning rate: 5.2156e-05]
	Learning Rate: 5.21564e-05
	LOSS [training: 0.05191833539886534 | validation: 0.041565314968733294]
	TIME [epoch: 6.42 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04547101474474028		[learning rate: 5.1972e-05]
	Learning Rate: 5.1972e-05
	LOSS [training: 0.04547101474474028 | validation: 0.03077340580974567]
	TIME [epoch: 6.42 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05164308600790425		[learning rate: 5.1788e-05]
	Learning Rate: 5.17882e-05
	LOSS [training: 0.05164308600790425 | validation: 0.031097626151303643]
	TIME [epoch: 6.44 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04345986573651685		[learning rate: 5.1605e-05]
	Learning Rate: 5.16051e-05
	LOSS [training: 0.04345986573651685 | validation: 0.02743872777755507]
	TIME [epoch: 6.44 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046306177060315104		[learning rate: 5.1423e-05]
	Learning Rate: 5.14226e-05
	LOSS [training: 0.046306177060315104 | validation: 0.023995589691515686]
	TIME [epoch: 6.43 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046291308452682686		[learning rate: 5.1241e-05]
	Learning Rate: 5.12407e-05
	LOSS [training: 0.046291308452682686 | validation: 0.016136887814118754]
	TIME [epoch: 6.42 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r3_20240309_135700/states/model_tr_study1_1539.pth
	Model improved!!!
EPOCH 1540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04824146030977913		[learning rate: 5.106e-05]
	Learning Rate: 5.10596e-05
	LOSS [training: 0.04824146030977913 | validation: 0.018226890687887177]
	TIME [epoch: 6.42 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.049263733738860685		[learning rate: 5.0879e-05]
	Learning Rate: 5.0879e-05
	LOSS [training: 0.049263733738860685 | validation: 0.029686854935276293]
	TIME [epoch: 6.42 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047529986507947763		[learning rate: 5.0699e-05]
	Learning Rate: 5.06991e-05
	LOSS [training: 0.047529986507947763 | validation: 0.029504542761740537]
	TIME [epoch: 6.42 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04561395089037758		[learning rate: 5.052e-05]
	Learning Rate: 5.05198e-05
	LOSS [training: 0.04561395089037758 | validation: 0.038726964112112926]
	TIME [epoch: 6.44 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05461323732093669		[learning rate: 5.0341e-05]
	Learning Rate: 5.03412e-05
	LOSS [training: 0.05461323732093669 | validation: 0.03628245019352069]
	TIME [epoch: 6.44 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03815036353185483		[learning rate: 5.0163e-05]
	Learning Rate: 5.01631e-05
	LOSS [training: 0.03815036353185483 | validation: 0.027398283330980055]
	TIME [epoch: 6.42 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04017312988692829		[learning rate: 4.9986e-05]
	Learning Rate: 4.99857e-05
	LOSS [training: 0.04017312988692829 | validation: 0.03357600029022766]
	TIME [epoch: 6.42 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04195074262171237		[learning rate: 4.9809e-05]
	Learning Rate: 4.9809e-05
	LOSS [training: 0.04195074262171237 | validation: 0.030804244810074023]
	TIME [epoch: 6.42 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03938297433677372		[learning rate: 4.9633e-05]
	Learning Rate: 4.96329e-05
	LOSS [training: 0.03938297433677372 | validation: 0.0478341973372458]
	TIME [epoch: 6.42 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04276803762288142		[learning rate: 4.9457e-05]
	Learning Rate: 4.94573e-05
	LOSS [training: 0.04276803762288142 | validation: 0.02642221414304276]
	TIME [epoch: 6.42 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04381388745544098		[learning rate: 4.9282e-05]
	Learning Rate: 4.92825e-05
	LOSS [training: 0.04381388745544098 | validation: 0.036749213733263585]
	TIME [epoch: 6.42 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04512733051731884		[learning rate: 4.9108e-05]
	Learning Rate: 4.91082e-05
	LOSS [training: 0.04512733051731884 | validation: 0.04731404760954293]
	TIME [epoch: 6.45 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044850564655888506		[learning rate: 4.8935e-05]
	Learning Rate: 4.89345e-05
	LOSS [training: 0.044850564655888506 | validation: 0.03530981824054672]
	TIME [epoch: 6.42 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036067792114723704		[learning rate: 4.8762e-05]
	Learning Rate: 4.87615e-05
	LOSS [training: 0.036067792114723704 | validation: 0.03741326495689017]
	TIME [epoch: 6.42 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04132427047954819		[learning rate: 4.8589e-05]
	Learning Rate: 4.85891e-05
	LOSS [training: 0.04132427047954819 | validation: 0.034759327579527925]
	TIME [epoch: 6.42 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042163702342818986		[learning rate: 4.8417e-05]
	Learning Rate: 4.84172e-05
	LOSS [training: 0.042163702342818986 | validation: 0.040644204961862766]
	TIME [epoch: 6.42 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03679297279247264		[learning rate: 4.8246e-05]
	Learning Rate: 4.8246e-05
	LOSS [training: 0.03679297279247264 | validation: 0.025495317580488147]
	TIME [epoch: 6.42 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03734931336543744		[learning rate: 4.8075e-05]
	Learning Rate: 4.80754e-05
	LOSS [training: 0.03734931336543744 | validation: 0.03084291867593896]
	TIME [epoch: 6.42 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04055904507786777		[learning rate: 4.7905e-05]
	Learning Rate: 4.79054e-05
	LOSS [training: 0.04055904507786777 | validation: 0.03055747494893019]
	TIME [epoch: 6.46 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03787156513924059		[learning rate: 4.7736e-05]
	Learning Rate: 4.7736e-05
	LOSS [training: 0.03787156513924059 | validation: 0.034433565247866116]
	TIME [epoch: 6.43 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03485118009384505		[learning rate: 4.7567e-05]
	Learning Rate: 4.75672e-05
	LOSS [training: 0.03485118009384505 | validation: 0.031936029648214695]
	TIME [epoch: 6.42 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03838407700251353		[learning rate: 4.7399e-05]
	Learning Rate: 4.7399e-05
	LOSS [training: 0.03838407700251353 | validation: 0.03009149492673324]
	TIME [epoch: 6.42 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04236094861582015		[learning rate: 4.7231e-05]
	Learning Rate: 4.72314e-05
	LOSS [training: 0.04236094861582015 | validation: 0.03856269424705499]
	TIME [epoch: 6.42 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038865563439472776		[learning rate: 4.7064e-05]
	Learning Rate: 4.70644e-05
	LOSS [training: 0.038865563439472776 | validation: 0.03921950037523764]
	TIME [epoch: 6.42 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0373252212310895		[learning rate: 4.6898e-05]
	Learning Rate: 4.6898e-05
	LOSS [training: 0.0373252212310895 | validation: 0.024725704042926823]
	TIME [epoch: 6.42 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047102173466097554		[learning rate: 4.6732e-05]
	Learning Rate: 4.67321e-05
	LOSS [training: 0.047102173466097554 | validation: 0.036356354897839116]
	TIME [epoch: 6.45 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.060094790674078635		[learning rate: 4.6567e-05]
	Learning Rate: 4.65669e-05
	LOSS [training: 0.060094790674078635 | validation: 0.025244451457428835]
	TIME [epoch: 6.43 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.052979683459468255		[learning rate: 4.6402e-05]
	Learning Rate: 4.64022e-05
	LOSS [training: 0.052979683459468255 | validation: 0.028851180405908394]
	TIME [epoch: 6.42 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04423915339923676		[learning rate: 4.6238e-05]
	Learning Rate: 4.62381e-05
	LOSS [training: 0.04423915339923676 | validation: 0.025844999631535207]
	TIME [epoch: 6.42 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04631766800829931		[learning rate: 4.6075e-05]
	Learning Rate: 4.60746e-05
	LOSS [training: 0.04631766800829931 | validation: 0.0356601061030315]
	TIME [epoch: 6.42 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04673137600657225		[learning rate: 4.5912e-05]
	Learning Rate: 4.59117e-05
	LOSS [training: 0.04673137600657225 | validation: 0.050050851650702395]
	TIME [epoch: 6.42 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04671339206398991		[learning rate: 4.5749e-05]
	Learning Rate: 4.57493e-05
	LOSS [training: 0.04671339206398991 | validation: 0.028215946942854685]
	TIME [epoch: 6.42 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039681735333336604		[learning rate: 4.5588e-05]
	Learning Rate: 4.55875e-05
	LOSS [training: 0.039681735333336604 | validation: 0.025666602503660072]
	TIME [epoch: 6.45 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03891677536740355		[learning rate: 4.5426e-05]
	Learning Rate: 4.54264e-05
	LOSS [training: 0.03891677536740355 | validation: 0.03798083392745212]
	TIME [epoch: 6.43 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04291903394534749		[learning rate: 4.5266e-05]
	Learning Rate: 4.52657e-05
	LOSS [training: 0.04291903394534749 | validation: 0.025355099390731516]
	TIME [epoch: 6.42 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04051508447678283		[learning rate: 4.5106e-05]
	Learning Rate: 4.51056e-05
	LOSS [training: 0.04051508447678283 | validation: 0.03159165293393495]
	TIME [epoch: 6.42 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047114338158449794		[learning rate: 4.4946e-05]
	Learning Rate: 4.49461e-05
	LOSS [training: 0.047114338158449794 | validation: 0.025639388734353768]
	TIME [epoch: 6.42 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03968699609395769		[learning rate: 4.4787e-05]
	Learning Rate: 4.47872e-05
	LOSS [training: 0.03968699609395769 | validation: 0.028797719962403025]
	TIME [epoch: 6.43 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040306855496913555		[learning rate: 4.4629e-05]
	Learning Rate: 4.46288e-05
	LOSS [training: 0.040306855496913555 | validation: 0.03749367874139819]
	TIME [epoch: 6.43 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03780266174064821		[learning rate: 4.4471e-05]
	Learning Rate: 4.4471e-05
	LOSS [training: 0.03780266174064821 | validation: 0.037237687608628944]
	TIME [epoch: 6.44 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04225592742860431		[learning rate: 4.4314e-05]
	Learning Rate: 4.43138e-05
	LOSS [training: 0.04225592742860431 | validation: 0.032188733911803824]
	TIME [epoch: 6.44 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041962868191937674		[learning rate: 4.4157e-05]
	Learning Rate: 4.41571e-05
	LOSS [training: 0.041962868191937674 | validation: 0.0405813979015454]
	TIME [epoch: 6.43 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04387274550591143		[learning rate: 4.4001e-05]
	Learning Rate: 4.40009e-05
	LOSS [training: 0.04387274550591143 | validation: 0.05793008543007393]
	TIME [epoch: 6.42 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05744590499343271		[learning rate: 4.3845e-05]
	Learning Rate: 4.38453e-05
	LOSS [training: 0.05744590499343271 | validation: 0.08198989978764203]
	TIME [epoch: 6.42 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05872832435021161		[learning rate: 4.369e-05]
	Learning Rate: 4.36903e-05
	LOSS [training: 0.05872832435021161 | validation: 0.049185349513937604]
	TIME [epoch: 6.42 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0449353436627187		[learning rate: 4.3536e-05]
	Learning Rate: 4.35358e-05
	LOSS [training: 0.0449353436627187 | validation: 0.044445057669636946]
	TIME [epoch: 6.42 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04347367254938107		[learning rate: 4.3382e-05]
	Learning Rate: 4.33818e-05
	LOSS [training: 0.04347367254938107 | validation: 0.04231784132020943]
	TIME [epoch: 6.44 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040840063020195896		[learning rate: 4.3228e-05]
	Learning Rate: 4.32284e-05
	LOSS [training: 0.040840063020195896 | validation: 0.03349994473168174]
	TIME [epoch: 6.44 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044605617034652705		[learning rate: 4.3076e-05]
	Learning Rate: 4.30756e-05
	LOSS [training: 0.044605617034652705 | validation: 0.04595668611211889]
	TIME [epoch: 6.43 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039677687479535595		[learning rate: 4.2923e-05]
	Learning Rate: 4.29232e-05
	LOSS [training: 0.039677687479535595 | validation: 0.03931181190498474]
	TIME [epoch: 6.42 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036876031030279754		[learning rate: 4.2771e-05]
	Learning Rate: 4.27714e-05
	LOSS [training: 0.036876031030279754 | validation: 0.047518320614668944]
	TIME [epoch: 6.42 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04487822839256379		[learning rate: 4.262e-05]
	Learning Rate: 4.26202e-05
	LOSS [training: 0.04487822839256379 | validation: 0.05403524592374874]
	TIME [epoch: 6.42 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05133696990674725		[learning rate: 4.2469e-05]
	Learning Rate: 4.24695e-05
	LOSS [training: 0.05133696990674725 | validation: 0.06153482138902097]
	TIME [epoch: 6.42 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05072549365214701		[learning rate: 4.2319e-05]
	Learning Rate: 4.23193e-05
	LOSS [training: 0.05072549365214701 | validation: 0.0590771488547911]
	TIME [epoch: 6.43 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04283467846154125		[learning rate: 4.217e-05]
	Learning Rate: 4.21697e-05
	LOSS [training: 0.04283467846154125 | validation: 0.042407449304670226]
	TIME [epoch: 6.46 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043959170800101706		[learning rate: 4.2021e-05]
	Learning Rate: 4.20205e-05
	LOSS [training: 0.043959170800101706 | validation: 0.039367641869807395]
	TIME [epoch: 6.43 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04289314496638398		[learning rate: 4.1872e-05]
	Learning Rate: 4.18719e-05
	LOSS [training: 0.04289314496638398 | validation: 0.03872706962477711]
	TIME [epoch: 6.42 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042573254144117896		[learning rate: 4.1724e-05]
	Learning Rate: 4.17239e-05
	LOSS [training: 0.042573254144117896 | validation: 0.030956495136101107]
	TIME [epoch: 6.42 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038951695599222715		[learning rate: 4.1576e-05]
	Learning Rate: 4.15763e-05
	LOSS [training: 0.038951695599222715 | validation: 0.037469703983062534]
	TIME [epoch: 6.43 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040306856966985605		[learning rate: 4.1429e-05]
	Learning Rate: 4.14293e-05
	LOSS [training: 0.040306856966985605 | validation: 0.04694049756379281]
	TIME [epoch: 6.42 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044867322786249074		[learning rate: 4.1283e-05]
	Learning Rate: 4.12828e-05
	LOSS [training: 0.044867322786249074 | validation: 0.05295920992571681]
	TIME [epoch: 6.43 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04943387878441579		[learning rate: 4.1137e-05]
	Learning Rate: 4.11368e-05
	LOSS [training: 0.04943387878441579 | validation: 0.04917955124958976]
	TIME [epoch: 6.45 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038574106434939096		[learning rate: 4.0991e-05]
	Learning Rate: 4.09914e-05
	LOSS [training: 0.038574106434939096 | validation: 0.04070771065491497]
	TIME [epoch: 6.43 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03995671265615991		[learning rate: 4.0846e-05]
	Learning Rate: 4.08464e-05
	LOSS [training: 0.03995671265615991 | validation: 0.046086821871372016]
	TIME [epoch: 6.42 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04303887661640925		[learning rate: 4.0702e-05]
	Learning Rate: 4.0702e-05
	LOSS [training: 0.04303887661640925 | validation: 0.038563702542583726]
	TIME [epoch: 6.42 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0420989709989286		[learning rate: 4.0558e-05]
	Learning Rate: 4.0558e-05
	LOSS [training: 0.0420989709989286 | validation: 0.03791665948181283]
	TIME [epoch: 6.42 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04122595386720393		[learning rate: 4.0415e-05]
	Learning Rate: 4.04146e-05
	LOSS [training: 0.04122595386720393 | validation: 0.04462690218986505]
	TIME [epoch: 6.42 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037037145538226804		[learning rate: 4.0272e-05]
	Learning Rate: 4.02717e-05
	LOSS [training: 0.037037145538226804 | validation: 0.031989461112643766]
	TIME [epoch: 6.42 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03909315095252902		[learning rate: 4.0129e-05]
	Learning Rate: 4.01293e-05
	LOSS [training: 0.03909315095252902 | validation: 0.029361224030993338]
	TIME [epoch: 6.46 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0389803420097659		[learning rate: 3.9987e-05]
	Learning Rate: 3.99874e-05
	LOSS [training: 0.0389803420097659 | validation: 0.03105765980975664]
	TIME [epoch: 6.43 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03748406457225606		[learning rate: 3.9846e-05]
	Learning Rate: 3.9846e-05
	LOSS [training: 0.03748406457225606 | validation: 0.04983919755488708]
	TIME [epoch: 6.42 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04296346302826998		[learning rate: 3.9705e-05]
	Learning Rate: 3.97051e-05
	LOSS [training: 0.04296346302826998 | validation: 0.03011362848873482]
	TIME [epoch: 6.42 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039534754014216904		[learning rate: 3.9565e-05]
	Learning Rate: 3.95647e-05
	LOSS [training: 0.039534754014216904 | validation: 0.026093173299844567]
	TIME [epoch: 6.42 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03822851622347671		[learning rate: 3.9425e-05]
	Learning Rate: 3.94248e-05
	LOSS [training: 0.03822851622347671 | validation: 0.03413317459885291]
	TIME [epoch: 6.42 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03806755023028601		[learning rate: 3.9285e-05]
	Learning Rate: 3.92854e-05
	LOSS [training: 0.03806755023028601 | validation: 0.038780050624206634]
	TIME [epoch: 6.42 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04582359046861725		[learning rate: 3.9146e-05]
	Learning Rate: 3.91464e-05
	LOSS [training: 0.04582359046861725 | validation: 0.056477620010354584]
	TIME [epoch: 6.46 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05033830444003499		[learning rate: 3.9008e-05]
	Learning Rate: 3.9008e-05
	LOSS [training: 0.05033830444003499 | validation: 0.05053778508155151]
	TIME [epoch: 6.43 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04215916581753091		[learning rate: 3.887e-05]
	Learning Rate: 3.88701e-05
	LOSS [training: 0.04215916581753091 | validation: 0.04559988999614941]
	TIME [epoch: 6.42 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038819933588699916		[learning rate: 3.8733e-05]
	Learning Rate: 3.87326e-05
	LOSS [training: 0.038819933588699916 | validation: 0.035674836919424226]
	TIME [epoch: 6.42 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04124489979624599		[learning rate: 3.8596e-05]
	Learning Rate: 3.85957e-05
	LOSS [training: 0.04124489979624599 | validation: 0.04332868845107774]
	TIME [epoch: 6.42 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04147635533995248		[learning rate: 3.8459e-05]
	Learning Rate: 3.84592e-05
	LOSS [training: 0.04147635533995248 | validation: 0.03497346024911411]
	TIME [epoch: 6.42 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03994083951233302		[learning rate: 3.8323e-05]
	Learning Rate: 3.83232e-05
	LOSS [training: 0.03994083951233302 | validation: 0.03554714051253729]
	TIME [epoch: 6.42 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03859035847289023		[learning rate: 3.8188e-05]
	Learning Rate: 3.81877e-05
	LOSS [training: 0.03859035847289023 | validation: 0.0288939181913272]
	TIME [epoch: 6.45 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047192776397286085		[learning rate: 3.8053e-05]
	Learning Rate: 3.80526e-05
	LOSS [training: 0.047192776397286085 | validation: 0.037353666620422915]
	TIME [epoch: 6.43 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.05096288838097202		[learning rate: 3.7918e-05]
	Learning Rate: 3.79181e-05
	LOSS [training: 0.05096288838097202 | validation: 0.026930729812783723]
	TIME [epoch: 6.43 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03864982906170462		[learning rate: 3.7784e-05]
	Learning Rate: 3.7784e-05
	LOSS [training: 0.03864982906170462 | validation: 0.023700788220350103]
	TIME [epoch: 6.42 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040053609071308734		[learning rate: 3.765e-05]
	Learning Rate: 3.76504e-05
	LOSS [training: 0.040053609071308734 | validation: 0.04118601158410115]
	TIME [epoch: 6.42 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04372484661479523		[learning rate: 3.7517e-05]
	Learning Rate: 3.75172e-05
	LOSS [training: 0.04372484661479523 | validation: 0.04091209909865693]
	TIME [epoch: 6.43 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04505783905913428		[learning rate: 3.7385e-05]
	Learning Rate: 3.73846e-05
	LOSS [training: 0.04505783905913428 | validation: 0.03575365743889972]
	TIME [epoch: 6.42 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04413282576082004		[learning rate: 3.7252e-05]
	Learning Rate: 3.72524e-05
	LOSS [training: 0.04413282576082004 | validation: 0.02050754354508101]
	TIME [epoch: 6.44 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037415984827117804		[learning rate: 3.7121e-05]
	Learning Rate: 3.71206e-05
	LOSS [training: 0.037415984827117804 | validation: 0.03142979186337874]
	TIME [epoch: 6.44 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03676425504395171		[learning rate: 3.6989e-05]
	Learning Rate: 3.69894e-05
	LOSS [training: 0.03676425504395171 | validation: 0.028941077220950018]
	TIME [epoch: 6.43 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04104650411384095		[learning rate: 3.6859e-05]
	Learning Rate: 3.68586e-05
	LOSS [training: 0.04104650411384095 | validation: 0.033412400338788055]
	TIME [epoch: 6.42 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03863533975087399		[learning rate: 3.6728e-05]
	Learning Rate: 3.67282e-05
	LOSS [training: 0.03863533975087399 | validation: 0.024374340637432202]
	TIME [epoch: 6.42 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037506516812412044		[learning rate: 3.6598e-05]
	Learning Rate: 3.65984e-05
	LOSS [training: 0.037506516812412044 | validation: 0.020488187853551477]
	TIME [epoch: 6.42 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036551927874449		[learning rate: 3.6469e-05]
	Learning Rate: 3.64689e-05
	LOSS [training: 0.036551927874449 | validation: 0.028186009810742527]
	TIME [epoch: 6.42 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03958951494743761		[learning rate: 3.634e-05]
	Learning Rate: 3.634e-05
	LOSS [training: 0.03958951494743761 | validation: 0.036795644383330876]
	TIME [epoch: 6.44 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03508506730981522		[learning rate: 3.6211e-05]
	Learning Rate: 3.62115e-05
	LOSS [training: 0.03508506730981522 | validation: 0.017699627210184494]
	TIME [epoch: 6.44 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03682392912743975		[learning rate: 3.6083e-05]
	Learning Rate: 3.60834e-05
	LOSS [training: 0.03682392912743975 | validation: 0.03503177942480363]
	TIME [epoch: 6.43 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04041457509213829		[learning rate: 3.5956e-05]
	Learning Rate: 3.59558e-05
	LOSS [training: 0.04041457509213829 | validation: 0.03523648781242014]
	TIME [epoch: 6.42 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0435576158027894		[learning rate: 3.5829e-05]
	Learning Rate: 3.58287e-05
	LOSS [training: 0.0435576158027894 | validation: 0.03943478625877609]
	TIME [epoch: 6.42 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03798722448213721		[learning rate: 3.5702e-05]
	Learning Rate: 3.5702e-05
	LOSS [training: 0.03798722448213721 | validation: 0.04301321804194634]
	TIME [epoch: 6.42 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04318933285517318		[learning rate: 3.5576e-05]
	Learning Rate: 3.55757e-05
	LOSS [training: 0.04318933285517318 | validation: 0.05682272286566937]
	TIME [epoch: 6.42 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04268347899289929		[learning rate: 3.545e-05]
	Learning Rate: 3.54499e-05
	LOSS [training: 0.04268347899289929 | validation: 0.05196512452529085]
	TIME [epoch: 6.43 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044418887913011115		[learning rate: 3.5325e-05]
	Learning Rate: 3.53246e-05
	LOSS [training: 0.044418887913011115 | validation: 0.037451635681754476]
	TIME [epoch: 6.46 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04387250677777916		[learning rate: 3.52e-05]
	Learning Rate: 3.51997e-05
	LOSS [training: 0.04387250677777916 | validation: 0.04609852852851886]
	TIME [epoch: 6.43 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04378380114155923		[learning rate: 3.5075e-05]
	Learning Rate: 3.50752e-05
	LOSS [training: 0.04378380114155923 | validation: 0.05160331352563803]
	TIME [epoch: 6.42 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04244452062581483		[learning rate: 3.4951e-05]
	Learning Rate: 3.49512e-05
	LOSS [training: 0.04244452062581483 | validation: 0.036987810116660524]
	TIME [epoch: 6.42 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03749553718723882		[learning rate: 3.4828e-05]
	Learning Rate: 3.48276e-05
	LOSS [training: 0.03749553718723882 | validation: 0.0350253270628027]
	TIME [epoch: 6.42 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0393145039677968		[learning rate: 3.4704e-05]
	Learning Rate: 3.47044e-05
	LOSS [training: 0.0393145039677968 | validation: 0.025918102887027325]
	TIME [epoch: 6.42 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039903536788856386		[learning rate: 3.4582e-05]
	Learning Rate: 3.45817e-05
	LOSS [training: 0.039903536788856386 | validation: 0.03785132549818356]
	TIME [epoch: 6.42 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03516378365806275		[learning rate: 3.4459e-05]
	Learning Rate: 3.44594e-05
	LOSS [training: 0.03516378365806275 | validation: 0.03886792503958671]
	TIME [epoch: 6.46 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03918575001842772		[learning rate: 3.4338e-05]
	Learning Rate: 3.43375e-05
	LOSS [training: 0.03918575001842772 | validation: 0.044714560612733205]
	TIME [epoch: 6.43 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0402821744012404		[learning rate: 3.4216e-05]
	Learning Rate: 3.42161e-05
	LOSS [training: 0.0402821744012404 | validation: 0.04190610546310127]
	TIME [epoch: 6.43 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04137116869343305		[learning rate: 3.4095e-05]
	Learning Rate: 3.40951e-05
	LOSS [training: 0.04137116869343305 | validation: 0.054872651966399975]
	TIME [epoch: 6.42 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04338599640844144		[learning rate: 3.3975e-05]
	Learning Rate: 3.39746e-05
	LOSS [training: 0.04338599640844144 | validation: 0.0525782034803294]
	TIME [epoch: 6.42 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04443869535035178		[learning rate: 3.3854e-05]
	Learning Rate: 3.38544e-05
	LOSS [training: 0.04443869535035178 | validation: 0.05870247186162965]
	TIME [epoch: 6.42 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047054908171156734		[learning rate: 3.3735e-05]
	Learning Rate: 3.37347e-05
	LOSS [training: 0.047054908171156734 | validation: 0.06178219375423662]
	TIME [epoch: 6.43 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04961154897980249		[learning rate: 3.3615e-05]
	Learning Rate: 3.36154e-05
	LOSS [training: 0.04961154897980249 | validation: 0.047855655650436466]
	TIME [epoch: 6.46 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03966576249412186		[learning rate: 3.3497e-05]
	Learning Rate: 3.34965e-05
	LOSS [training: 0.03966576249412186 | validation: 0.043803173956358805]
	TIME [epoch: 6.43 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040737957366077576		[learning rate: 3.3378e-05]
	Learning Rate: 3.33781e-05
	LOSS [training: 0.040737957366077576 | validation: 0.03959390947640363]
	TIME [epoch: 6.42 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040893540154005564		[learning rate: 3.326e-05]
	Learning Rate: 3.32601e-05
	LOSS [training: 0.040893540154005564 | validation: 0.04387509506096793]
	TIME [epoch: 6.42 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03970676055751084		[learning rate: 3.3142e-05]
	Learning Rate: 3.31425e-05
	LOSS [training: 0.03970676055751084 | validation: 0.05273152376505426]
	TIME [epoch: 6.42 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043444983261800504		[learning rate: 3.3025e-05]
	Learning Rate: 3.30253e-05
	LOSS [training: 0.043444983261800504 | validation: 0.0562591801320729]
	TIME [epoch: 6.42 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04038514427940084		[learning rate: 3.2908e-05]
	Learning Rate: 3.29085e-05
	LOSS [training: 0.04038514427940084 | validation: 0.046642216010373536]
	TIME [epoch: 6.42 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044306738525703576		[learning rate: 3.2792e-05]
	Learning Rate: 3.27921e-05
	LOSS [training: 0.044306738525703576 | validation: 0.04778740975175987]
	TIME [epoch: 6.46 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036008266301198355		[learning rate: 3.2676e-05]
	Learning Rate: 3.26761e-05
	LOSS [training: 0.036008266301198355 | validation: 0.05099771905517262]
	TIME [epoch: 6.43 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04520372119456983		[learning rate: 3.2561e-05]
	Learning Rate: 3.25606e-05
	LOSS [training: 0.04520372119456983 | validation: 0.04111556747563596]
	TIME [epoch: 6.43 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0348549031858288		[learning rate: 3.2445e-05]
	Learning Rate: 3.24455e-05
	LOSS [training: 0.0348549031858288 | validation: 0.03764144268383604]
	TIME [epoch: 6.43 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04123688048526555		[learning rate: 3.2331e-05]
	Learning Rate: 3.23307e-05
	LOSS [training: 0.04123688048526555 | validation: 0.04000528610451522]
	TIME [epoch: 6.43 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037887318072417416		[learning rate: 3.2216e-05]
	Learning Rate: 3.22164e-05
	LOSS [training: 0.037887318072417416 | validation: 0.0311386479484126]
	TIME [epoch: 6.43 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03671900593151957		[learning rate: 3.2102e-05]
	Learning Rate: 3.21025e-05
	LOSS [training: 0.03671900593151957 | validation: 0.03772226700288406]
	TIME [epoch: 6.43 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037654878398319075		[learning rate: 3.1989e-05]
	Learning Rate: 3.1989e-05
	LOSS [training: 0.037654878398319075 | validation: 0.049340822179791265]
	TIME [epoch: 6.44 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042298065701187826		[learning rate: 3.1876e-05]
	Learning Rate: 3.18758e-05
	LOSS [training: 0.042298065701187826 | validation: 0.03149147613621338]
	TIME [epoch: 6.44 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03884597211300542		[learning rate: 3.1763e-05]
	Learning Rate: 3.17631e-05
	LOSS [training: 0.03884597211300542 | validation: 0.0390993076146731]
	TIME [epoch: 6.43 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036984792377472264		[learning rate: 3.1651e-05]
	Learning Rate: 3.16508e-05
	LOSS [training: 0.036984792377472264 | validation: 0.03307114103412593]
	TIME [epoch: 6.43 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0377952158663383		[learning rate: 3.1539e-05]
	Learning Rate: 3.15389e-05
	LOSS [training: 0.0377952158663383 | validation: 0.034593065859503835]
	TIME [epoch: 6.42 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04300744318195768		[learning rate: 3.1427e-05]
	Learning Rate: 3.14274e-05
	LOSS [training: 0.04300744318195768 | validation: 0.042278395654724105]
	TIME [epoch: 6.43 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04747029205373397		[learning rate: 3.1316e-05]
	Learning Rate: 3.13162e-05
	LOSS [training: 0.04747029205373397 | validation: 0.03657407278790289]
	TIME [epoch: 6.42 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04551315105001983		[learning rate: 3.1205e-05]
	Learning Rate: 3.12055e-05
	LOSS [training: 0.04551315105001983 | validation: 0.04284696750270637]
	TIME [epoch: 6.44 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04735615430859185		[learning rate: 3.1095e-05]
	Learning Rate: 3.10951e-05
	LOSS [training: 0.04735615430859185 | validation: 0.030699274193519754]
	TIME [epoch: 6.44 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040376089661827944		[learning rate: 3.0985e-05]
	Learning Rate: 3.09852e-05
	LOSS [training: 0.040376089661827944 | validation: 0.033092134621155615]
	TIME [epoch: 6.42 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03946900279564994		[learning rate: 3.0876e-05]
	Learning Rate: 3.08756e-05
	LOSS [training: 0.03946900279564994 | validation: 0.028758690901189488]
	TIME [epoch: 6.42 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04078626864408855		[learning rate: 3.0766e-05]
	Learning Rate: 3.07664e-05
	LOSS [training: 0.04078626864408855 | validation: 0.034415913054546096]
	TIME [epoch: 6.43 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03740146063033742		[learning rate: 3.0658e-05]
	Learning Rate: 3.06576e-05
	LOSS [training: 0.03740146063033742 | validation: 0.026597856621080912]
	TIME [epoch: 6.42 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03991377882203375		[learning rate: 3.0549e-05]
	Learning Rate: 3.05492e-05
	LOSS [training: 0.03991377882203375 | validation: 0.01960908089026013]
	TIME [epoch: 6.42 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04740534540174993		[learning rate: 3.0441e-05]
	Learning Rate: 3.04412e-05
	LOSS [training: 0.04740534540174993 | validation: 0.034559803806235044]
	TIME [epoch: 6.43 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.047641836419984415		[learning rate: 3.0334e-05]
	Learning Rate: 3.03336e-05
	LOSS [training: 0.047641836419984415 | validation: 0.024425991597087332]
	TIME [epoch: 6.46 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04323788866137056		[learning rate: 3.0226e-05]
	Learning Rate: 3.02263e-05
	LOSS [training: 0.04323788866137056 | validation: 0.03910116537715525]
	TIME [epoch: 6.42 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042346778699635435		[learning rate: 3.0119e-05]
	Learning Rate: 3.01194e-05
	LOSS [training: 0.042346778699635435 | validation: 0.029866600116968706]
	TIME [epoch: 6.42 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040150264777092756		[learning rate: 3.0013e-05]
	Learning Rate: 3.00129e-05
	LOSS [training: 0.040150264777092756 | validation: 0.030667174446152502]
	TIME [epoch: 6.42 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04419916158200127		[learning rate: 2.9907e-05]
	Learning Rate: 2.99068e-05
	LOSS [training: 0.04419916158200127 | validation: 0.02696216785610759]
	TIME [epoch: 6.43 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040033088350172656		[learning rate: 2.9801e-05]
	Learning Rate: 2.9801e-05
	LOSS [training: 0.040033088350172656 | validation: 0.0320035282708202]
	TIME [epoch: 6.43 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04002994809999784		[learning rate: 2.9696e-05]
	Learning Rate: 2.96956e-05
	LOSS [training: 0.04002994809999784 | validation: 0.03556535319434427]
	TIME [epoch: 6.43 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04013357812764919		[learning rate: 2.9591e-05]
	Learning Rate: 2.95906e-05
	LOSS [training: 0.04013357812764919 | validation: 0.03518534935997012]
	TIME [epoch: 6.46 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039727770221165686		[learning rate: 2.9486e-05]
	Learning Rate: 2.9486e-05
	LOSS [training: 0.039727770221165686 | validation: 0.021344777923363454]
	TIME [epoch: 6.43 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04340163909767445		[learning rate: 2.9382e-05]
	Learning Rate: 2.93817e-05
	LOSS [training: 0.04340163909767445 | validation: 0.03291513294370076]
	TIME [epoch: 6.43 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04012994954437968		[learning rate: 2.9278e-05]
	Learning Rate: 2.92778e-05
	LOSS [training: 0.04012994954437968 | validation: 0.03570035010821076]
	TIME [epoch: 6.43 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04049072745952831		[learning rate: 2.9174e-05]
	Learning Rate: 2.91743e-05
	LOSS [training: 0.04049072745952831 | validation: 0.0240147618809931]
	TIME [epoch: 6.43 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03813353833204365		[learning rate: 2.9071e-05]
	Learning Rate: 2.90711e-05
	LOSS [training: 0.03813353833204365 | validation: 0.03233695423432507]
	TIME [epoch: 6.42 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04058049982091207		[learning rate: 2.8968e-05]
	Learning Rate: 2.89683e-05
	LOSS [training: 0.04058049982091207 | validation: 0.025604110163671968]
	TIME [epoch: 6.42 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04474539942598459		[learning rate: 2.8866e-05]
	Learning Rate: 2.88659e-05
	LOSS [training: 0.04474539942598459 | validation: 0.026689619007195065]
	TIME [epoch: 6.46 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04294052769284775		[learning rate: 2.8764e-05]
	Learning Rate: 2.87638e-05
	LOSS [training: 0.04294052769284775 | validation: 0.03279790091476635]
	TIME [epoch: 6.43 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04260125225788835		[learning rate: 2.8662e-05]
	Learning Rate: 2.86621e-05
	LOSS [training: 0.04260125225788835 | validation: 0.02535525108225605]
	TIME [epoch: 6.43 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044393421085324715		[learning rate: 2.8561e-05]
	Learning Rate: 2.85607e-05
	LOSS [training: 0.044393421085324715 | validation: 0.023219759081558572]
	TIME [epoch: 6.42 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03911188100572429		[learning rate: 2.846e-05]
	Learning Rate: 2.84597e-05
	LOSS [training: 0.03911188100572429 | validation: 0.031947694551436846]
	TIME [epoch: 6.43 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03985538087643473		[learning rate: 2.8359e-05]
	Learning Rate: 2.83591e-05
	LOSS [training: 0.03985538087643473 | validation: 0.03560795143745322]
	TIME [epoch: 6.42 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03512899661042005		[learning rate: 2.8259e-05]
	Learning Rate: 2.82588e-05
	LOSS [training: 0.03512899661042005 | validation: 0.029226121093575985]
	TIME [epoch: 6.42 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03820946215099148		[learning rate: 2.8159e-05]
	Learning Rate: 2.81589e-05
	LOSS [training: 0.03820946215099148 | validation: 0.0375624686335724]
	TIME [epoch: 6.46 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035892634117884806		[learning rate: 2.8059e-05]
	Learning Rate: 2.80593e-05
	LOSS [training: 0.035892634117884806 | validation: 0.02338685510294155]
	TIME [epoch: 6.43 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04201550802057717		[learning rate: 2.796e-05]
	Learning Rate: 2.79601e-05
	LOSS [training: 0.04201550802057717 | validation: 0.021930453037172417]
	TIME [epoch: 6.43 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038373206017280316		[learning rate: 2.7861e-05]
	Learning Rate: 2.78612e-05
	LOSS [training: 0.038373206017280316 | validation: 0.0345715357501414]
	TIME [epoch: 6.43 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043779725575164595		[learning rate: 2.7763e-05]
	Learning Rate: 2.77627e-05
	LOSS [training: 0.043779725575164595 | validation: 0.04086029147286789]
	TIME [epoch: 6.43 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043563861767586726		[learning rate: 2.7665e-05]
	Learning Rate: 2.76645e-05
	LOSS [training: 0.043563861767586726 | validation: 0.05950505969972299]
	TIME [epoch: 6.42 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04647922995086167		[learning rate: 2.7567e-05]
	Learning Rate: 2.75667e-05
	LOSS [training: 0.04647922995086167 | validation: 0.04458353933502512]
	TIME [epoch: 6.43 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04120918634350059		[learning rate: 2.7469e-05]
	Learning Rate: 2.74692e-05
	LOSS [training: 0.04120918634350059 | validation: 0.03822804251396731]
	TIME [epoch: 6.45 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04176756383003472		[learning rate: 2.7372e-05]
	Learning Rate: 2.73721e-05
	LOSS [training: 0.04176756383003472 | validation: 0.02958108001228177]
	TIME [epoch: 6.43 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04078132174230466		[learning rate: 2.7275e-05]
	Learning Rate: 2.72753e-05
	LOSS [training: 0.04078132174230466 | validation: 0.04150381029007088]
	TIME [epoch: 6.43 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04132063844256442		[learning rate: 2.7179e-05]
	Learning Rate: 2.71788e-05
	LOSS [training: 0.04132063844256442 | validation: 0.03686358093660758]
	TIME [epoch: 6.42 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04352115374507037		[learning rate: 2.7083e-05]
	Learning Rate: 2.70827e-05
	LOSS [training: 0.04352115374507037 | validation: 0.029889858045412946]
	TIME [epoch: 6.43 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04039787565294839		[learning rate: 2.6987e-05]
	Learning Rate: 2.6987e-05
	LOSS [training: 0.04039787565294839 | validation: 0.04119273173623077]
	TIME [epoch: 6.43 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039095920345248864		[learning rate: 2.6892e-05]
	Learning Rate: 2.68915e-05
	LOSS [training: 0.039095920345248864 | validation: 0.034753530649992474]
	TIME [epoch: 6.43 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04320891208107991		[learning rate: 2.6796e-05]
	Learning Rate: 2.67964e-05
	LOSS [training: 0.04320891208107991 | validation: 0.031711353934894534]
	TIME [epoch: 6.44 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03900943787815434		[learning rate: 2.6702e-05]
	Learning Rate: 2.67017e-05
	LOSS [training: 0.03900943787815434 | validation: 0.038024591869889546]
	TIME [epoch: 6.45 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03327852782921319		[learning rate: 2.6607e-05]
	Learning Rate: 2.66073e-05
	LOSS [training: 0.03327852782921319 | validation: 0.030670216370559427]
	TIME [epoch: 6.43 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037294732043587894		[learning rate: 2.6513e-05]
	Learning Rate: 2.65132e-05
	LOSS [training: 0.037294732043587894 | validation: 0.04060473746089389]
	TIME [epoch: 6.42 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042620111302006644		[learning rate: 2.6419e-05]
	Learning Rate: 2.64194e-05
	LOSS [training: 0.042620111302006644 | validation: 0.0428930616837527]
	TIME [epoch: 6.43 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03956191461076836		[learning rate: 2.6326e-05]
	Learning Rate: 2.6326e-05
	LOSS [training: 0.03956191461076836 | validation: 0.033393582747987254]
	TIME [epoch: 6.42 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04030046990194876		[learning rate: 2.6233e-05]
	Learning Rate: 2.62329e-05
	LOSS [training: 0.04030046990194876 | validation: 0.05299749132040253]
	TIME [epoch: 6.42 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04196496320822782		[learning rate: 2.614e-05]
	Learning Rate: 2.61401e-05
	LOSS [training: 0.04196496320822782 | validation: 0.04601933430369349]
	TIME [epoch: 6.44 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04659238038576703		[learning rate: 2.6048e-05]
	Learning Rate: 2.60477e-05
	LOSS [training: 0.04659238038576703 | validation: 0.05376181857651392]
	TIME [epoch: 6.45 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042779629631964806		[learning rate: 2.5956e-05]
	Learning Rate: 2.59556e-05
	LOSS [training: 0.042779629631964806 | validation: 0.05198224573088528]
	TIME [epoch: 6.43 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043005851123154186		[learning rate: 2.5864e-05]
	Learning Rate: 2.58638e-05
	LOSS [training: 0.043005851123154186 | validation: 0.03220572572723719]
	TIME [epoch: 6.42 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03649042447594021		[learning rate: 2.5772e-05]
	Learning Rate: 2.57723e-05
	LOSS [training: 0.03649042447594021 | validation: 0.035117252584534187]
	TIME [epoch: 6.43 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03820102322369737		[learning rate: 2.5681e-05]
	Learning Rate: 2.56812e-05
	LOSS [training: 0.03820102322369737 | validation: 0.026242449135811842]
	TIME [epoch: 6.42 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043848876028661665		[learning rate: 2.559e-05]
	Learning Rate: 2.55904e-05
	LOSS [training: 0.043848876028661665 | validation: 0.031319076887078766]
	TIME [epoch: 6.42 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03623887241971313		[learning rate: 2.55e-05]
	Learning Rate: 2.54999e-05
	LOSS [training: 0.03623887241971313 | validation: 0.03423818103267639]
	TIME [epoch: 6.43 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04117294674699494		[learning rate: 2.541e-05]
	Learning Rate: 2.54097e-05
	LOSS [training: 0.04117294674699494 | validation: 0.03918697616185344]
	TIME [epoch: 6.46 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03934124886684559		[learning rate: 2.532e-05]
	Learning Rate: 2.53199e-05
	LOSS [training: 0.03934124886684559 | validation: 0.026668309096290838]
	TIME [epoch: 6.43 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04008032419616343		[learning rate: 2.523e-05]
	Learning Rate: 2.52303e-05
	LOSS [training: 0.04008032419616343 | validation: 0.04443927404904823]
	TIME [epoch: 6.43 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04315562582883133		[learning rate: 2.5141e-05]
	Learning Rate: 2.51411e-05
	LOSS [training: 0.04315562582883133 | validation: 0.037268731101481614]
	TIME [epoch: 6.43 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03603485725695922		[learning rate: 2.5052e-05]
	Learning Rate: 2.50522e-05
	LOSS [training: 0.03603485725695922 | validation: 0.05077321090957703]
	TIME [epoch: 6.43 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04629931197251072		[learning rate: 2.4964e-05]
	Learning Rate: 2.49636e-05
	LOSS [training: 0.04629931197251072 | validation: 0.044789807003666235]
	TIME [epoch: 6.42 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04767744031503775		[learning rate: 2.4875e-05]
	Learning Rate: 2.48754e-05
	LOSS [training: 0.04767744031503775 | validation: 0.04741345970843396]
	TIME [epoch: 6.43 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04315111883476643		[learning rate: 2.4787e-05]
	Learning Rate: 2.47874e-05
	LOSS [training: 0.04315111883476643 | validation: 0.04025028249871051]
	TIME [epoch: 6.46 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035622723980363855		[learning rate: 2.47e-05]
	Learning Rate: 2.46997e-05
	LOSS [training: 0.035622723980363855 | validation: 0.03615696361732166]
	TIME [epoch: 6.43 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03480854703080557		[learning rate: 2.4612e-05]
	Learning Rate: 2.46124e-05
	LOSS [training: 0.03480854703080557 | validation: 0.023181625521682615]
	TIME [epoch: 6.43 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040189493631052786		[learning rate: 2.4525e-05]
	Learning Rate: 2.45254e-05
	LOSS [training: 0.040189493631052786 | validation: 0.024402276861271104]
	TIME [epoch: 6.43 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03908121706148805		[learning rate: 2.4439e-05]
	Learning Rate: 2.44386e-05
	LOSS [training: 0.03908121706148805 | validation: 0.029531611125712978]
	TIME [epoch: 6.42 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04161254398879649		[learning rate: 2.4352e-05]
	Learning Rate: 2.43522e-05
	LOSS [training: 0.04161254398879649 | validation: 0.027545526980414344]
	TIME [epoch: 6.43 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04084118620536424		[learning rate: 2.4266e-05]
	Learning Rate: 2.42661e-05
	LOSS [training: 0.04084118620536424 | validation: 0.02625692401951758]
	TIME [epoch: 6.43 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042839490033551926		[learning rate: 2.418e-05]
	Learning Rate: 2.41803e-05
	LOSS [training: 0.042839490033551926 | validation: 0.02466885363803024]
	TIME [epoch: 6.46 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036444946053470456		[learning rate: 2.4095e-05]
	Learning Rate: 2.40948e-05
	LOSS [training: 0.036444946053470456 | validation: 0.03361454482976673]
	TIME [epoch: 6.42 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037574943630394264		[learning rate: 2.401e-05]
	Learning Rate: 2.40096e-05
	LOSS [training: 0.037574943630394264 | validation: 0.04123402584557465]
	TIME [epoch: 6.41 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03744107447949339		[learning rate: 2.3925e-05]
	Learning Rate: 2.39247e-05
	LOSS [training: 0.03744107447949339 | validation: 0.02872810538592547]
	TIME [epoch: 6.41 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03925223021712573		[learning rate: 2.384e-05]
	Learning Rate: 2.38401e-05
	LOSS [training: 0.03925223021712573 | validation: 0.033289000054299675]
	TIME [epoch: 6.4 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043652273271388514		[learning rate: 2.3756e-05]
	Learning Rate: 2.37558e-05
	LOSS [training: 0.043652273271388514 | validation: 0.05073331686525585]
	TIME [epoch: 6.39 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04257248296426918		[learning rate: 2.3672e-05]
	Learning Rate: 2.36718e-05
	LOSS [training: 0.04257248296426918 | validation: 0.05425956608522674]
	TIME [epoch: 6.39 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043365754464000796		[learning rate: 2.3588e-05]
	Learning Rate: 2.35881e-05
	LOSS [training: 0.043365754464000796 | validation: 0.0400357020868417]
	TIME [epoch: 6.41 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03928447313706846		[learning rate: 2.3505e-05]
	Learning Rate: 2.35047e-05
	LOSS [training: 0.03928447313706846 | validation: 0.04434181409864824]
	TIME [epoch: 6.39 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03763847200220305		[learning rate: 2.3422e-05]
	Learning Rate: 2.34215e-05
	LOSS [training: 0.03763847200220305 | validation: 0.036093940189488485]
	TIME [epoch: 6.38 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04024405474384509		[learning rate: 2.3339e-05]
	Learning Rate: 2.33387e-05
	LOSS [training: 0.04024405474384509 | validation: 0.04167363577020142]
	TIME [epoch: 6.38 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03853077316756555		[learning rate: 2.3256e-05]
	Learning Rate: 2.32562e-05
	LOSS [training: 0.03853077316756555 | validation: 0.036078084470392534]
	TIME [epoch: 6.39 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03626829081861357		[learning rate: 2.3174e-05]
	Learning Rate: 2.31739e-05
	LOSS [training: 0.03626829081861357 | validation: 0.04448902580014497]
	TIME [epoch: 6.39 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03994929379507432		[learning rate: 2.3092e-05]
	Learning Rate: 2.3092e-05
	LOSS [training: 0.03994929379507432 | validation: 0.0316733593658284]
	TIME [epoch: 6.39 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036714261824433325		[learning rate: 2.301e-05]
	Learning Rate: 2.30103e-05
	LOSS [training: 0.036714261824433325 | validation: 0.030470417072213013]
	TIME [epoch: 6.41 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03799179666275604		[learning rate: 2.2929e-05]
	Learning Rate: 2.2929e-05
	LOSS [training: 0.03799179666275604 | validation: 0.03385467363445704]
	TIME [epoch: 6.4 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03517752106896811		[learning rate: 2.2848e-05]
	Learning Rate: 2.28479e-05
	LOSS [training: 0.03517752106896811 | validation: 0.04087277904878357]
	TIME [epoch: 6.39 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04262065080822623		[learning rate: 2.2767e-05]
	Learning Rate: 2.27671e-05
	LOSS [training: 0.04262065080822623 | validation: 0.04722674215595348]
	TIME [epoch: 6.4 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040327446845745976		[learning rate: 2.2687e-05]
	Learning Rate: 2.26866e-05
	LOSS [training: 0.040327446845745976 | validation: 0.033190597692598224]
	TIME [epoch: 6.39 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04046977350300153		[learning rate: 2.2606e-05]
	Learning Rate: 2.26064e-05
	LOSS [training: 0.04046977350300153 | validation: 0.04149194720774872]
	TIME [epoch: 6.4 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04081181370319857		[learning rate: 2.2526e-05]
	Learning Rate: 2.25264e-05
	LOSS [training: 0.04081181370319857 | validation: 0.03857207354868516]
	TIME [epoch: 6.4 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04340759239807946		[learning rate: 2.2447e-05]
	Learning Rate: 2.24468e-05
	LOSS [training: 0.04340759239807946 | validation: 0.033537272354327435]
	TIME [epoch: 6.43 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04177996839689407		[learning rate: 2.2367e-05]
	Learning Rate: 2.23674e-05
	LOSS [training: 0.04177996839689407 | validation: 0.04065932844692443]
	TIME [epoch: 6.43 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03773424115377338		[learning rate: 2.2288e-05]
	Learning Rate: 2.22883e-05
	LOSS [training: 0.03773424115377338 | validation: 0.032310985858171604]
	TIME [epoch: 6.42 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039209891371388986		[learning rate: 2.2209e-05]
	Learning Rate: 2.22095e-05
	LOSS [training: 0.039209891371388986 | validation: 0.0333433017023203]
	TIME [epoch: 6.41 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03731381840729102		[learning rate: 2.2131e-05]
	Learning Rate: 2.21309e-05
	LOSS [training: 0.03731381840729102 | validation: 0.03145916690235908]
	TIME [epoch: 6.41 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037585374798838396		[learning rate: 2.2053e-05]
	Learning Rate: 2.20527e-05
	LOSS [training: 0.037585374798838396 | validation: 0.032316998783784336]
	TIME [epoch: 6.41 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039550390113996865		[learning rate: 2.1975e-05]
	Learning Rate: 2.19747e-05
	LOSS [training: 0.039550390113996865 | validation: 0.03170143094941723]
	TIME [epoch: 6.41 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03752344742950107		[learning rate: 2.1897e-05]
	Learning Rate: 2.1897e-05
	LOSS [training: 0.03752344742950107 | validation: 0.027611355612316164]
	TIME [epoch: 6.42 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03721526972186927		[learning rate: 2.182e-05]
	Learning Rate: 2.18196e-05
	LOSS [training: 0.03721526972186927 | validation: 0.02608202359683742]
	TIME [epoch: 6.45 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0384894296782613		[learning rate: 2.1742e-05]
	Learning Rate: 2.17424e-05
	LOSS [training: 0.0384894296782613 | validation: 0.03485362515343045]
	TIME [epoch: 6.42 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04024714559889148		[learning rate: 2.1666e-05]
	Learning Rate: 2.16655e-05
	LOSS [training: 0.04024714559889148 | validation: 0.023067490574421458]
	TIME [epoch: 6.42 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03797561017360151		[learning rate: 2.1589e-05]
	Learning Rate: 2.15889e-05
	LOSS [training: 0.03797561017360151 | validation: 0.02585066115467957]
	TIME [epoch: 6.42 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036085620454525125		[learning rate: 2.1513e-05]
	Learning Rate: 2.15126e-05
	LOSS [training: 0.036085620454525125 | validation: 0.024001314641622095]
	TIME [epoch: 6.43 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036126944507136986		[learning rate: 2.1437e-05]
	Learning Rate: 2.14365e-05
	LOSS [training: 0.036126944507136986 | validation: 0.033806757613207165]
	TIME [epoch: 6.43 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03700826597271273		[learning rate: 2.1361e-05]
	Learning Rate: 2.13607e-05
	LOSS [training: 0.03700826597271273 | validation: 0.021507042598328842]
	TIME [epoch: 6.43 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0381420377685259		[learning rate: 2.1285e-05]
	Learning Rate: 2.12852e-05
	LOSS [training: 0.0381420377685259 | validation: 0.026275511139985563]
	TIME [epoch: 6.46 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0367394712104723		[learning rate: 2.121e-05]
	Learning Rate: 2.12099e-05
	LOSS [training: 0.0367394712104723 | validation: 0.025297177855129922]
	TIME [epoch: 6.43 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03759242084415619		[learning rate: 2.1135e-05]
	Learning Rate: 2.11349e-05
	LOSS [training: 0.03759242084415619 | validation: 0.031067189684311085]
	TIME [epoch: 6.43 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044140030165755864		[learning rate: 2.106e-05]
	Learning Rate: 2.10602e-05
	LOSS [training: 0.044140030165755864 | validation: 0.027531011114165324]
	TIME [epoch: 6.43 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04203805225477724		[learning rate: 2.0986e-05]
	Learning Rate: 2.09857e-05
	LOSS [training: 0.04203805225477724 | validation: 0.024506330332310186]
	TIME [epoch: 6.43 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04117931099825672		[learning rate: 2.0911e-05]
	Learning Rate: 2.09115e-05
	LOSS [training: 0.04117931099825672 | validation: 0.0299736481354632]
	TIME [epoch: 6.43 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04045829184345301		[learning rate: 2.0838e-05]
	Learning Rate: 2.08375e-05
	LOSS [training: 0.04045829184345301 | validation: 0.034235417063493444]
	TIME [epoch: 6.43 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044803941351472205		[learning rate: 2.0764e-05]
	Learning Rate: 2.07638e-05
	LOSS [training: 0.044803941351472205 | validation: 0.035834109698841626]
	TIME [epoch: 6.47 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04412829347472538		[learning rate: 2.069e-05]
	Learning Rate: 2.06904e-05
	LOSS [training: 0.04412829347472538 | validation: 0.03766574787441824]
	TIME [epoch: 6.43 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03747659112815252		[learning rate: 2.0617e-05]
	Learning Rate: 2.06173e-05
	LOSS [training: 0.03747659112815252 | validation: 0.04348259651469518]
	TIME [epoch: 6.43 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04107440794341884		[learning rate: 2.0544e-05]
	Learning Rate: 2.05444e-05
	LOSS [training: 0.04107440794341884 | validation: 0.03028504855846616]
	TIME [epoch: 6.43 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04279159444262508		[learning rate: 2.0472e-05]
	Learning Rate: 2.04717e-05
	LOSS [training: 0.04279159444262508 | validation: 0.036129741884519756]
	TIME [epoch: 6.43 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041977710669499534		[learning rate: 2.0399e-05]
	Learning Rate: 2.03993e-05
	LOSS [training: 0.041977710669499534 | validation: 0.04916587586185323]
	TIME [epoch: 6.43 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04576355186694895		[learning rate: 2.0327e-05]
	Learning Rate: 2.03272e-05
	LOSS [training: 0.04576355186694895 | validation: 0.042323525146976834]
	TIME [epoch: 6.43 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04176586795068779		[learning rate: 2.0255e-05]
	Learning Rate: 2.02553e-05
	LOSS [training: 0.04176586795068779 | validation: 0.03914937898561427]
	TIME [epoch: 6.46 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040840806620366495		[learning rate: 2.0184e-05]
	Learning Rate: 2.01837e-05
	LOSS [training: 0.040840806620366495 | validation: 0.0456174537566727]
	TIME [epoch: 6.43 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043589623672396764		[learning rate: 2.0112e-05]
	Learning Rate: 2.01123e-05
	LOSS [training: 0.043589623672396764 | validation: 0.038889800630512006]
	TIME [epoch: 6.43 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040383139892334025		[learning rate: 2.0041e-05]
	Learning Rate: 2.00412e-05
	LOSS [training: 0.040383139892334025 | validation: 0.045120173235450485]
	TIME [epoch: 6.43 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04110066594055794		[learning rate: 1.997e-05]
	Learning Rate: 1.99703e-05
	LOSS [training: 0.04110066594055794 | validation: 0.038088410155923895]
	TIME [epoch: 6.43 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04385398792214541		[learning rate: 1.99e-05]
	Learning Rate: 1.98997e-05
	LOSS [training: 0.04385398792214541 | validation: 0.04528838177814354]
	TIME [epoch: 6.43 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043287090425333845		[learning rate: 1.9829e-05]
	Learning Rate: 1.98293e-05
	LOSS [training: 0.043287090425333845 | validation: 0.03881382851485178]
	TIME [epoch: 6.43 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04286646540878944		[learning rate: 1.9759e-05]
	Learning Rate: 1.97592e-05
	LOSS [training: 0.04286646540878944 | validation: 0.05303301302251177]
	TIME [epoch: 6.46 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04262237552849163		[learning rate: 1.9689e-05]
	Learning Rate: 1.96893e-05
	LOSS [training: 0.04262237552849163 | validation: 0.04649884784041244]
	TIME [epoch: 6.43 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0369840889890513		[learning rate: 1.962e-05]
	Learning Rate: 1.96197e-05
	LOSS [training: 0.0369840889890513 | validation: 0.0403714285175246]
	TIME [epoch: 6.43 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0383163187786166		[learning rate: 1.955e-05]
	Learning Rate: 1.95503e-05
	LOSS [training: 0.0383163187786166 | validation: 0.03519137022886841]
	TIME [epoch: 6.43 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04109114578219779		[learning rate: 1.9481e-05]
	Learning Rate: 1.94812e-05
	LOSS [training: 0.04109114578219779 | validation: 0.039172557917355105]
	TIME [epoch: 6.43 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040219797849967286		[learning rate: 1.9412e-05]
	Learning Rate: 1.94123e-05
	LOSS [training: 0.040219797849967286 | validation: 0.040280771867974484]
	TIME [epoch: 6.43 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04042526215442421		[learning rate: 1.9344e-05]
	Learning Rate: 1.93437e-05
	LOSS [training: 0.04042526215442421 | validation: 0.049451608712541284]
	TIME [epoch: 6.43 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039421340490262295		[learning rate: 1.9275e-05]
	Learning Rate: 1.92753e-05
	LOSS [training: 0.039421340490262295 | validation: 0.044372012622320406]
	TIME [epoch: 6.44 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04165488731780742		[learning rate: 1.9207e-05]
	Learning Rate: 1.92071e-05
	LOSS [training: 0.04165488731780742 | validation: 0.04288569937777549]
	TIME [epoch: 6.45 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04026211716110087		[learning rate: 1.9139e-05]
	Learning Rate: 1.91392e-05
	LOSS [training: 0.04026211716110087 | validation: 0.048916116048100027]
	TIME [epoch: 6.43 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045937371237352316		[learning rate: 1.9071e-05]
	Learning Rate: 1.90715e-05
	LOSS [training: 0.045937371237352316 | validation: 0.049080310554103335]
	TIME [epoch: 6.43 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04943318486822175		[learning rate: 1.9004e-05]
	Learning Rate: 1.90041e-05
	LOSS [training: 0.04943318486822175 | validation: 0.049524803846316856]
	TIME [epoch: 6.43 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03992531085190201		[learning rate: 1.8937e-05]
	Learning Rate: 1.89369e-05
	LOSS [training: 0.03992531085190201 | validation: 0.04576446026819019]
	TIME [epoch: 6.42 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04361427641401251		[learning rate: 1.887e-05]
	Learning Rate: 1.88699e-05
	LOSS [training: 0.04361427641401251 | validation: 0.046176391950448606]
	TIME [epoch: 6.43 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04531007469139561		[learning rate: 1.8803e-05]
	Learning Rate: 1.88032e-05
	LOSS [training: 0.04531007469139561 | validation: 0.03976575304222083]
	TIME [epoch: 6.44 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04096089039478771		[learning rate: 1.8737e-05]
	Learning Rate: 1.87367e-05
	LOSS [training: 0.04096089039478771 | validation: 0.04336954345214471]
	TIME [epoch: 6.44 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039054338492712046		[learning rate: 1.867e-05]
	Learning Rate: 1.86704e-05
	LOSS [training: 0.039054338492712046 | validation: 0.04432545274462919]
	TIME [epoch: 6.43 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037792956871935394		[learning rate: 1.8604e-05]
	Learning Rate: 1.86044e-05
	LOSS [training: 0.037792956871935394 | validation: 0.04239628292139374]
	TIME [epoch: 6.42 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.044116751621245384		[learning rate: 1.8539e-05]
	Learning Rate: 1.85386e-05
	LOSS [training: 0.044116751621245384 | validation: 0.04812309849067533]
	TIME [epoch: 6.42 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.046106172684531765		[learning rate: 1.8473e-05]
	Learning Rate: 1.84731e-05
	LOSS [training: 0.046106172684531765 | validation: 0.0493343485258343]
	TIME [epoch: 6.43 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045254221129166834		[learning rate: 1.8408e-05]
	Learning Rate: 1.84077e-05
	LOSS [training: 0.045254221129166834 | validation: 0.050077306770752686]
	TIME [epoch: 6.42 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.045845767055836734		[learning rate: 1.8343e-05]
	Learning Rate: 1.83426e-05
	LOSS [training: 0.045845767055836734 | validation: 0.044907329423888795]
	TIME [epoch: 6.43 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03736115284920362		[learning rate: 1.8278e-05]
	Learning Rate: 1.82778e-05
	LOSS [training: 0.03736115284920362 | validation: 0.03516687827005515]
	TIME [epoch: 6.45 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04011451011320502		[learning rate: 1.8213e-05]
	Learning Rate: 1.82131e-05
	LOSS [training: 0.04011451011320502 | validation: 0.04665357759497302]
	TIME [epoch: 6.43 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03879183900367603		[learning rate: 1.8149e-05]
	Learning Rate: 1.81487e-05
	LOSS [training: 0.03879183900367603 | validation: 0.035973178467313634]
	TIME [epoch: 6.43 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037710332248579684		[learning rate: 1.8085e-05]
	Learning Rate: 1.80846e-05
	LOSS [training: 0.037710332248579684 | validation: 0.03989249389100636]
	TIME [epoch: 6.42 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03912629932892625		[learning rate: 1.8021e-05]
	Learning Rate: 1.80206e-05
	LOSS [training: 0.03912629932892625 | validation: 0.03942524442860806]
	TIME [epoch: 6.43 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038334241311013914		[learning rate: 1.7957e-05]
	Learning Rate: 1.79569e-05
	LOSS [training: 0.038334241311013914 | validation: 0.02705706145178528]
	TIME [epoch: 6.43 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04276309471198852		[learning rate: 1.7893e-05]
	Learning Rate: 1.78934e-05
	LOSS [training: 0.04276309471198852 | validation: 0.03574570253563885]
	TIME [epoch: 6.43 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03844956189440151		[learning rate: 1.783e-05]
	Learning Rate: 1.78301e-05
	LOSS [training: 0.03844956189440151 | validation: 0.03178334018417607]
	TIME [epoch: 6.46 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04028086888572		[learning rate: 1.7767e-05]
	Learning Rate: 1.77671e-05
	LOSS [training: 0.04028086888572 | validation: 0.03933291358303693]
	TIME [epoch: 6.43 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04004497007543598		[learning rate: 1.7704e-05]
	Learning Rate: 1.77042e-05
	LOSS [training: 0.04004497007543598 | validation: 0.03192437777748608]
	TIME [epoch: 6.43 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037603034234279145		[learning rate: 1.7642e-05]
	Learning Rate: 1.76416e-05
	LOSS [training: 0.037603034234279145 | validation: 0.026319030228703754]
	TIME [epoch: 6.43 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040282387854634526		[learning rate: 1.7579e-05]
	Learning Rate: 1.75792e-05
	LOSS [training: 0.040282387854634526 | validation: 0.029634693927287716]
	TIME [epoch: 6.43 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036968652643603675		[learning rate: 1.7517e-05]
	Learning Rate: 1.75171e-05
	LOSS [training: 0.036968652643603675 | validation: 0.03198700438776797]
	TIME [epoch: 6.42 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04039289706136846		[learning rate: 1.7455e-05]
	Learning Rate: 1.74551e-05
	LOSS [training: 0.04039289706136846 | validation: 0.023733868972894465]
	TIME [epoch: 6.42 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040325989545065034		[learning rate: 1.7393e-05]
	Learning Rate: 1.73934e-05
	LOSS [training: 0.040325989545065034 | validation: 0.03877805442417586]
	TIME [epoch: 6.46 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04034162974433781		[learning rate: 1.7332e-05]
	Learning Rate: 1.73319e-05
	LOSS [training: 0.04034162974433781 | validation: 0.031631524350942984]
	TIME [epoch: 6.43 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035666334832853926		[learning rate: 1.7271e-05]
	Learning Rate: 1.72706e-05
	LOSS [training: 0.035666334832853926 | validation: 0.03259755679339962]
	TIME [epoch: 6.43 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03949190484410629		[learning rate: 1.721e-05]
	Learning Rate: 1.72095e-05
	LOSS [training: 0.03949190484410629 | validation: 0.040362194094248446]
	TIME [epoch: 6.43 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0382213020942061		[learning rate: 1.7149e-05]
	Learning Rate: 1.71487e-05
	LOSS [training: 0.0382213020942061 | validation: 0.02830196116773456]
	TIME [epoch: 6.42 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03769666321237966		[learning rate: 1.7088e-05]
	Learning Rate: 1.7088e-05
	LOSS [training: 0.03769666321237966 | validation: 0.024195455038477486]
	TIME [epoch: 6.43 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03882401936964044		[learning rate: 1.7028e-05]
	Learning Rate: 1.70276e-05
	LOSS [training: 0.03882401936964044 | validation: 0.03861159728576109]
	TIME [epoch: 6.43 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040400502573515594		[learning rate: 1.6967e-05]
	Learning Rate: 1.69674e-05
	LOSS [training: 0.040400502573515594 | validation: 0.03238056772977239]
	TIME [epoch: 6.46 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04121348308247982		[learning rate: 1.6907e-05]
	Learning Rate: 1.69074e-05
	LOSS [training: 0.04121348308247982 | validation: 0.03242104573725912]
	TIME [epoch: 6.43 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039732617942676504		[learning rate: 1.6848e-05]
	Learning Rate: 1.68476e-05
	LOSS [training: 0.039732617942676504 | validation: 0.029157639519314296]
	TIME [epoch: 6.43 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038025961738675104		[learning rate: 1.6788e-05]
	Learning Rate: 1.6788e-05
	LOSS [training: 0.038025961738675104 | validation: 0.027466650222464823]
	TIME [epoch: 6.42 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03670794666735891		[learning rate: 1.6729e-05]
	Learning Rate: 1.67287e-05
	LOSS [training: 0.03670794666735891 | validation: 0.03302053940075772]
	TIME [epoch: 6.43 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041106900519908424		[learning rate: 1.667e-05]
	Learning Rate: 1.66695e-05
	LOSS [training: 0.041106900519908424 | validation: 0.03433704919359518]
	TIME [epoch: 6.42 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03971482260699844		[learning rate: 1.6611e-05]
	Learning Rate: 1.66106e-05
	LOSS [training: 0.03971482260699844 | validation: 0.029310584380196385]
	TIME [epoch: 6.43 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03566967855526138		[learning rate: 1.6552e-05]
	Learning Rate: 1.65518e-05
	LOSS [training: 0.03566967855526138 | validation: 0.02218992459373417]
	TIME [epoch: 6.45 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03884316913824179		[learning rate: 1.6493e-05]
	Learning Rate: 1.64933e-05
	LOSS [training: 0.03884316913824179 | validation: 0.027062341483287965]
	TIME [epoch: 6.43 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03676485160187775		[learning rate: 1.6435e-05]
	Learning Rate: 1.6435e-05
	LOSS [training: 0.03676485160187775 | validation: 0.02871640026188807]
	TIME [epoch: 6.42 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04104134089085306		[learning rate: 1.6377e-05]
	Learning Rate: 1.63769e-05
	LOSS [training: 0.04104134089085306 | validation: 0.03424554169508657]
	TIME [epoch: 6.43 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035523893040981254		[learning rate: 1.6319e-05]
	Learning Rate: 1.6319e-05
	LOSS [training: 0.035523893040981254 | validation: 0.032413876219613606]
	TIME [epoch: 6.43 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03561364300642328		[learning rate: 1.6261e-05]
	Learning Rate: 1.62612e-05
	LOSS [training: 0.03561364300642328 | validation: 0.025882842107283432]
	TIME [epoch: 6.43 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04038907345701126		[learning rate: 1.6204e-05]
	Learning Rate: 1.62038e-05
	LOSS [training: 0.04038907345701126 | validation: 0.022979995431516423]
	TIME [epoch: 6.42 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03614212981943393		[learning rate: 1.6146e-05]
	Learning Rate: 1.61464e-05
	LOSS [training: 0.03614212981943393 | validation: 0.03305735147521345]
	TIME [epoch: 6.44 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038249992109539874		[learning rate: 1.6089e-05]
	Learning Rate: 1.60894e-05
	LOSS [training: 0.038249992109539874 | validation: 0.03198299776960497]
	TIME [epoch: 6.45 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03960644805454724		[learning rate: 1.6032e-05]
	Learning Rate: 1.60325e-05
	LOSS [training: 0.03960644805454724 | validation: 0.030678703474636804]
	TIME [epoch: 6.43 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035290121588961366		[learning rate: 1.5976e-05]
	Learning Rate: 1.59758e-05
	LOSS [training: 0.035290121588961366 | validation: 0.031163436104728603]
	TIME [epoch: 6.42 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03510947455148797		[learning rate: 1.5919e-05]
	Learning Rate: 1.59193e-05
	LOSS [training: 0.03510947455148797 | validation: 0.02879061370079932]
	TIME [epoch: 6.42 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036071322331426466		[learning rate: 1.5863e-05]
	Learning Rate: 1.5863e-05
	LOSS [training: 0.036071322331426466 | validation: 0.03491946033012436]
	TIME [epoch: 6.42 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0392248082184356		[learning rate: 1.5807e-05]
	Learning Rate: 1.58069e-05
	LOSS [training: 0.0392248082184356 | validation: 0.039675617589167336]
	TIME [epoch: 6.42 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03585327135576343		[learning rate: 1.5751e-05]
	Learning Rate: 1.5751e-05
	LOSS [training: 0.03585327135576343 | validation: 0.031750276449973865]
	TIME [epoch: 6.44 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03994282745614867		[learning rate: 1.5695e-05]
	Learning Rate: 1.56953e-05
	LOSS [training: 0.03994282745614867 | validation: 0.03043504517116086]
	TIME [epoch: 6.45 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03769924079749649		[learning rate: 1.564e-05]
	Learning Rate: 1.56398e-05
	LOSS [training: 0.03769924079749649 | validation: 0.03094823232510128]
	TIME [epoch: 6.43 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04157157444450995		[learning rate: 1.5584e-05]
	Learning Rate: 1.55845e-05
	LOSS [training: 0.04157157444450995 | validation: 0.03937255629224841]
	TIME [epoch: 6.42 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04158347733441485		[learning rate: 1.5529e-05]
	Learning Rate: 1.55294e-05
	LOSS [training: 0.04158347733441485 | validation: 0.03157073439742536]
	TIME [epoch: 6.42 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039570313683487915		[learning rate: 1.5474e-05]
	Learning Rate: 1.54745e-05
	LOSS [training: 0.039570313683487915 | validation: 0.030111788852409244]
	TIME [epoch: 6.42 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04467795461490453		[learning rate: 1.542e-05]
	Learning Rate: 1.54197e-05
	LOSS [training: 0.04467795461490453 | validation: 0.02686809703586465]
	TIME [epoch: 6.42 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04612681536575053		[learning rate: 1.5365e-05]
	Learning Rate: 1.53652e-05
	LOSS [training: 0.04612681536575053 | validation: 0.0356596663497211]
	TIME [epoch: 6.43 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03948239472504856		[learning rate: 1.5311e-05]
	Learning Rate: 1.53109e-05
	LOSS [training: 0.03948239472504856 | validation: 0.040168056891217996]
	TIME [epoch: 6.46 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039629926654819805		[learning rate: 1.5257e-05]
	Learning Rate: 1.52567e-05
	LOSS [training: 0.039629926654819805 | validation: 0.026549606309118484]
	TIME [epoch: 6.43 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041121013350406695		[learning rate: 1.5203e-05]
	Learning Rate: 1.52028e-05
	LOSS [training: 0.041121013350406695 | validation: 0.03702902923103878]
	TIME [epoch: 6.42 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03946405118409231		[learning rate: 1.5149e-05]
	Learning Rate: 1.5149e-05
	LOSS [training: 0.03946405118409231 | validation: 0.03516914197905529]
	TIME [epoch: 6.43 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037423480552961755		[learning rate: 1.5095e-05]
	Learning Rate: 1.50955e-05
	LOSS [training: 0.037423480552961755 | validation: 0.02470240310360537]
	TIME [epoch: 6.42 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04059268286154987		[learning rate: 1.5042e-05]
	Learning Rate: 1.50421e-05
	LOSS [training: 0.04059268286154987 | validation: 0.03372780721130181]
	TIME [epoch: 6.43 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03797557406064987		[learning rate: 1.4989e-05]
	Learning Rate: 1.49889e-05
	LOSS [training: 0.03797557406064987 | validation: 0.029236660826732208]
	TIME [epoch: 6.43 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035471535156979386		[learning rate: 1.4936e-05]
	Learning Rate: 1.49359e-05
	LOSS [training: 0.035471535156979386 | validation: 0.02798860016680844]
	TIME [epoch: 6.46 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03951731032909647		[learning rate: 1.4883e-05]
	Learning Rate: 1.48831e-05
	LOSS [training: 0.03951731032909647 | validation: 0.027155942933551513]
	TIME [epoch: 6.42 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035229041255728746		[learning rate: 1.483e-05]
	Learning Rate: 1.48304e-05
	LOSS [training: 0.035229041255728746 | validation: 0.02819319990925679]
	TIME [epoch: 6.42 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03885144752874964		[learning rate: 1.4778e-05]
	Learning Rate: 1.4778e-05
	LOSS [training: 0.03885144752874964 | validation: 0.040131572993204405]
	TIME [epoch: 6.43 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03724561810521948		[learning rate: 1.4726e-05]
	Learning Rate: 1.47257e-05
	LOSS [training: 0.03724561810521948 | validation: 0.03272137086545196]
	TIME [epoch: 6.42 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03587747194382768		[learning rate: 1.4674e-05]
	Learning Rate: 1.46737e-05
	LOSS [training: 0.03587747194382768 | validation: 0.020858593941136698]
	TIME [epoch: 6.43 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.043850900123366614		[learning rate: 1.4622e-05]
	Learning Rate: 1.46218e-05
	LOSS [training: 0.043850900123366614 | validation: 0.02872951404395206]
	TIME [epoch: 6.43 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039422026194936705		[learning rate: 1.457e-05]
	Learning Rate: 1.45701e-05
	LOSS [training: 0.039422026194936705 | validation: 0.027200302377469586]
	TIME [epoch: 6.46 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03976637951961084		[learning rate: 1.4519e-05]
	Learning Rate: 1.45185e-05
	LOSS [training: 0.03976637951961084 | validation: 0.027771102112456196]
	TIME [epoch: 6.42 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04122374129155264		[learning rate: 1.4467e-05]
	Learning Rate: 1.44672e-05
	LOSS [training: 0.04122374129155264 | validation: 0.03688595155738493]
	TIME [epoch: 6.42 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04067062655787282		[learning rate: 1.4416e-05]
	Learning Rate: 1.44161e-05
	LOSS [training: 0.04067062655787282 | validation: 0.029979650983673497]
	TIME [epoch: 6.42 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03915758482588534		[learning rate: 1.4365e-05]
	Learning Rate: 1.43651e-05
	LOSS [training: 0.03915758482588534 | validation: 0.03100199960717288]
	TIME [epoch: 6.42 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040567152471361986		[learning rate: 1.4314e-05]
	Learning Rate: 1.43143e-05
	LOSS [training: 0.040567152471361986 | validation: 0.025873634194494483]
	TIME [epoch: 6.42 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039576826632877427		[learning rate: 1.4264e-05]
	Learning Rate: 1.42637e-05
	LOSS [training: 0.039576826632877427 | validation: 0.031921842591336354]
	TIME [epoch: 6.42 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03679837599316707		[learning rate: 1.4213e-05]
	Learning Rate: 1.42132e-05
	LOSS [training: 0.03679837599316707 | validation: 0.035408257250270365]
	TIME [epoch: 6.45 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04193321838069438		[learning rate: 1.4163e-05]
	Learning Rate: 1.4163e-05
	LOSS [training: 0.04193321838069438 | validation: 0.031349713244459364]
	TIME [epoch: 6.43 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04307782438115894		[learning rate: 1.4113e-05]
	Learning Rate: 1.41129e-05
	LOSS [training: 0.04307782438115894 | validation: 0.041247468470720854]
	TIME [epoch: 6.43 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04223739316934494		[learning rate: 1.4063e-05]
	Learning Rate: 1.4063e-05
	LOSS [training: 0.04223739316934494 | validation: 0.04324534766781701]
	TIME [epoch: 6.43 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042200288648679814		[learning rate: 1.4013e-05]
	Learning Rate: 1.40132e-05
	LOSS [training: 0.042200288648679814 | validation: 0.033378735631978844]
	TIME [epoch: 6.42 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039438086534700476		[learning rate: 1.3964e-05]
	Learning Rate: 1.39637e-05
	LOSS [training: 0.039438086534700476 | validation: 0.03738709107451157]
	TIME [epoch: 6.43 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041022874690198836		[learning rate: 1.3914e-05]
	Learning Rate: 1.39143e-05
	LOSS [training: 0.041022874690198836 | validation: 0.040405408979556405]
	TIME [epoch: 6.42 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04132240477951371		[learning rate: 1.3865e-05]
	Learning Rate: 1.38651e-05
	LOSS [training: 0.04132240477951371 | validation: 0.0391164164863556]
	TIME [epoch: 6.46 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04283858174654429		[learning rate: 1.3816e-05]
	Learning Rate: 1.38161e-05
	LOSS [training: 0.04283858174654429 | validation: 0.03807218262427066]
	TIME [epoch: 6.43 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04233467202077874		[learning rate: 1.3767e-05]
	Learning Rate: 1.37672e-05
	LOSS [training: 0.04233467202077874 | validation: 0.028240458478298005]
	TIME [epoch: 6.43 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04242552114800386		[learning rate: 1.3719e-05]
	Learning Rate: 1.37185e-05
	LOSS [training: 0.04242552114800386 | validation: 0.02422543233361558]
	TIME [epoch: 6.42 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040289778096886386		[learning rate: 1.367e-05]
	Learning Rate: 1.367e-05
	LOSS [training: 0.040289778096886386 | validation: 0.02674905211403895]
	TIME [epoch: 6.42 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04014751377623885		[learning rate: 1.3622e-05]
	Learning Rate: 1.36217e-05
	LOSS [training: 0.04014751377623885 | validation: 0.036433221585953114]
	TIME [epoch: 6.43 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04190089959355557		[learning rate: 1.3574e-05]
	Learning Rate: 1.35735e-05
	LOSS [training: 0.04190089959355557 | validation: 0.037554786626288264]
	TIME [epoch: 6.42 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041167080003940454		[learning rate: 1.3526e-05]
	Learning Rate: 1.35255e-05
	LOSS [training: 0.041167080003940454 | validation: 0.0457952394427528]
	TIME [epoch: 6.44 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03709391628622066		[learning rate: 1.3478e-05]
	Learning Rate: 1.34777e-05
	LOSS [training: 0.03709391628622066 | validation: 0.0422202837244654]
	TIME [epoch: 6.45 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03865047981660005		[learning rate: 1.343e-05]
	Learning Rate: 1.343e-05
	LOSS [training: 0.03865047981660005 | validation: 0.03274888846302309]
	TIME [epoch: 6.42 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04221335677444888		[learning rate: 1.3383e-05]
	Learning Rate: 1.33825e-05
	LOSS [training: 0.04221335677444888 | validation: 0.03454924660287936]
	TIME [epoch: 6.41 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0395645520762214		[learning rate: 1.3335e-05]
	Learning Rate: 1.33352e-05
	LOSS [training: 0.0395645520762214 | validation: 0.03395007745777736]
	TIME [epoch: 6.4 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03730729784367974		[learning rate: 1.3288e-05]
	Learning Rate: 1.32881e-05
	LOSS [training: 0.03730729784367974 | validation: 0.030604136091857487]
	TIME [epoch: 6.39 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04226820308373638		[learning rate: 1.3241e-05]
	Learning Rate: 1.32411e-05
	LOSS [training: 0.04226820308373638 | validation: 0.0352283097196064]
	TIME [epoch: 6.38 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03773248232174911		[learning rate: 1.3194e-05]
	Learning Rate: 1.31942e-05
	LOSS [training: 0.03773248232174911 | validation: 0.04091027276078588]
	TIME [epoch: 6.4 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039056762466993016		[learning rate: 1.3148e-05]
	Learning Rate: 1.31476e-05
	LOSS [training: 0.039056762466993016 | validation: 0.03823230442169027]
	TIME [epoch: 6.41 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03795769848655887		[learning rate: 1.3101e-05]
	Learning Rate: 1.31011e-05
	LOSS [training: 0.03795769848655887 | validation: 0.029790712770560602]
	TIME [epoch: 6.39 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039012338317510206		[learning rate: 1.3055e-05]
	Learning Rate: 1.30548e-05
	LOSS [training: 0.039012338317510206 | validation: 0.029949430424192975]
	TIME [epoch: 6.39 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.035714931647377685		[learning rate: 1.3009e-05]
	Learning Rate: 1.30086e-05
	LOSS [training: 0.035714931647377685 | validation: 0.029307732990983493]
	TIME [epoch: 6.38 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.033468883013572134		[learning rate: 1.2963e-05]
	Learning Rate: 1.29626e-05
	LOSS [training: 0.033468883013572134 | validation: 0.03021632955732416]
	TIME [epoch: 6.39 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042114415839104836		[learning rate: 1.2917e-05]
	Learning Rate: 1.29168e-05
	LOSS [training: 0.042114415839104836 | validation: 0.031362392320107714]
	TIME [epoch: 6.39 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03842300295420347		[learning rate: 1.2871e-05]
	Learning Rate: 1.28711e-05
	LOSS [training: 0.03842300295420347 | validation: 0.026274275849069568]
	TIME [epoch: 6.4 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03881909708114234		[learning rate: 1.2826e-05]
	Learning Rate: 1.28256e-05
	LOSS [training: 0.03881909708114234 | validation: 0.037890029724066895]
	TIME [epoch: 6.43 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04076332202311553		[learning rate: 1.278e-05]
	Learning Rate: 1.27802e-05
	LOSS [training: 0.04076332202311553 | validation: 0.02990781583826382]
	TIME [epoch: 6.4 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036719439656206505		[learning rate: 1.2735e-05]
	Learning Rate: 1.2735e-05
	LOSS [training: 0.036719439656206505 | validation: 0.030077271008057967]
	TIME [epoch: 6.41 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03800760710070383		[learning rate: 1.269e-05]
	Learning Rate: 1.269e-05
	LOSS [training: 0.03800760710070383 | validation: 0.026954564983137624]
	TIME [epoch: 6.41 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834300890697718		[learning rate: 1.2645e-05]
	Learning Rate: 1.26451e-05
	LOSS [training: 0.03834300890697718 | validation: 0.031385389615505084]
	TIME [epoch: 6.41 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03595658222039233		[learning rate: 1.26e-05]
	Learning Rate: 1.26004e-05
	LOSS [training: 0.03595658222039233 | validation: 0.03211097309029619]
	TIME [epoch: 6.41 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03648447315033724		[learning rate: 1.2556e-05]
	Learning Rate: 1.25559e-05
	LOSS [training: 0.03648447315033724 | validation: 0.03888446684163862]
	TIME [epoch: 6.42 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03734651284500088		[learning rate: 1.2511e-05]
	Learning Rate: 1.25115e-05
	LOSS [training: 0.03734651284500088 | validation: 0.023721373433119756]
	TIME [epoch: 6.45 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03831058388255565		[learning rate: 1.2467e-05]
	Learning Rate: 1.24672e-05
	LOSS [training: 0.03831058388255565 | validation: 0.03408237580542074]
	TIME [epoch: 6.41 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040662885905284815		[learning rate: 1.2423e-05]
	Learning Rate: 1.24231e-05
	LOSS [training: 0.040662885905284815 | validation: 0.029503227017183]
	TIME [epoch: 6.41 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038024168743673106		[learning rate: 1.2379e-05]
	Learning Rate: 1.23792e-05
	LOSS [training: 0.038024168743673106 | validation: 0.03676418788943194]
	TIME [epoch: 6.42 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04256652883835139		[learning rate: 1.2335e-05]
	Learning Rate: 1.23354e-05
	LOSS [training: 0.04256652883835139 | validation: 0.039585005004389016]
	TIME [epoch: 6.41 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04274218576203136		[learning rate: 1.2292e-05]
	Learning Rate: 1.22918e-05
	LOSS [training: 0.04274218576203136 | validation: 0.03356913859920944]
	TIME [epoch: 6.41 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04244324238647964		[learning rate: 1.2248e-05]
	Learning Rate: 1.22483e-05
	LOSS [training: 0.04244324238647964 | validation: 0.037535358080732106]
	TIME [epoch: 6.42 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04312157090868049		[learning rate: 1.2205e-05]
	Learning Rate: 1.2205e-05
	LOSS [training: 0.04312157090868049 | validation: 0.03083585690463937]
	TIME [epoch: 6.46 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042837107865839365		[learning rate: 1.2162e-05]
	Learning Rate: 1.21619e-05
	LOSS [training: 0.042837107865839365 | validation: 0.039138207583744256]
	TIME [epoch: 6.43 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03834105276951822		[learning rate: 1.2119e-05]
	Learning Rate: 1.21189e-05
	LOSS [training: 0.03834105276951822 | validation: 0.03579885934724224]
	TIME [epoch: 6.42 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042879003193259296		[learning rate: 1.2076e-05]
	Learning Rate: 1.2076e-05
	LOSS [training: 0.042879003193259296 | validation: 0.04735958753398358]
	TIME [epoch: 6.43 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04054116636441181		[learning rate: 1.2033e-05]
	Learning Rate: 1.20333e-05
	LOSS [training: 0.04054116636441181 | validation: 0.04813701842259495]
	TIME [epoch: 6.43 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.042264389352250284		[learning rate: 1.1991e-05]
	Learning Rate: 1.19907e-05
	LOSS [training: 0.042264389352250284 | validation: 0.03935061246434391]
	TIME [epoch: 6.42 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03939682942432153		[learning rate: 1.1948e-05]
	Learning Rate: 1.19483e-05
	LOSS [training: 0.03939682942432153 | validation: 0.028288332599024715]
	TIME [epoch: 6.42 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03787989091748648		[learning rate: 1.1906e-05]
	Learning Rate: 1.19061e-05
	LOSS [training: 0.03787989091748648 | validation: 0.030917942591786325]
	TIME [epoch: 6.46 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041421511661104055		[learning rate: 1.1864e-05]
	Learning Rate: 1.1864e-05
	LOSS [training: 0.041421511661104055 | validation: 0.04960746166108782]
	TIME [epoch: 6.43 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04256668865352138		[learning rate: 1.1822e-05]
	Learning Rate: 1.1822e-05
	LOSS [training: 0.04256668865352138 | validation: 0.028872023829190106]
	TIME [epoch: 6.42 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03880176213096731		[learning rate: 1.178e-05]
	Learning Rate: 1.17802e-05
	LOSS [training: 0.03880176213096731 | validation: 0.03227747608251671]
	TIME [epoch: 6.43 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04163534097657273		[learning rate: 1.1739e-05]
	Learning Rate: 1.17386e-05
	LOSS [training: 0.04163534097657273 | validation: 0.0440430965277643]
	TIME [epoch: 6.43 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03964377999066066		[learning rate: 1.1697e-05]
	Learning Rate: 1.16971e-05
	LOSS [training: 0.03964377999066066 | validation: 0.03316446498125169]
	TIME [epoch: 6.42 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0409536731170177		[learning rate: 1.1656e-05]
	Learning Rate: 1.16557e-05
	LOSS [training: 0.0409536731170177 | validation: 0.047102294023107616]
	TIME [epoch: 6.42 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040882103736897796		[learning rate: 1.1614e-05]
	Learning Rate: 1.16145e-05
	LOSS [training: 0.040882103736897796 | validation: 0.04084784142361394]
	TIME [epoch: 6.44 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039067662672756534		[learning rate: 1.1573e-05]
	Learning Rate: 1.15734e-05
	LOSS [training: 0.039067662672756534 | validation: 0.045212294977008474]
	TIME [epoch: 6.44 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038865599907167495		[learning rate: 1.1532e-05]
	Learning Rate: 1.15325e-05
	LOSS [training: 0.038865599907167495 | validation: 0.0431783346348635]
	TIME [epoch: 6.43 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04077185601502797		[learning rate: 1.1492e-05]
	Learning Rate: 1.14917e-05
	LOSS [training: 0.04077185601502797 | validation: 0.03737792496287181]
	TIME [epoch: 6.42 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04058797667357095		[learning rate: 1.1451e-05]
	Learning Rate: 1.14511e-05
	LOSS [training: 0.04058797667357095 | validation: 0.027082515193314442]
	TIME [epoch: 6.42 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037785595615799916		[learning rate: 1.1411e-05]
	Learning Rate: 1.14106e-05
	LOSS [training: 0.037785595615799916 | validation: 0.03585918417423175]
	TIME [epoch: 6.42 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03551827979251119		[learning rate: 1.137e-05]
	Learning Rate: 1.13702e-05
	LOSS [training: 0.03551827979251119 | validation: 0.029562791532703796]
	TIME [epoch: 6.42 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041574824085536775		[learning rate: 1.133e-05]
	Learning Rate: 1.133e-05
	LOSS [training: 0.041574824085536775 | validation: 0.031856806296195916]
	TIME [epoch: 6.44 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038348109510578494		[learning rate: 1.129e-05]
	Learning Rate: 1.129e-05
	LOSS [training: 0.038348109510578494 | validation: 0.03187724435943427]
	TIME [epoch: 6.44 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037903792088507623		[learning rate: 1.125e-05]
	Learning Rate: 1.125e-05
	LOSS [training: 0.037903792088507623 | validation: 0.02766280256565793]
	TIME [epoch: 6.42 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04140991497942418		[learning rate: 1.121e-05]
	Learning Rate: 1.12103e-05
	LOSS [training: 0.04140991497942418 | validation: 0.02797868752753586]
	TIME [epoch: 6.42 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04066758218629401		[learning rate: 1.1171e-05]
	Learning Rate: 1.11706e-05
	LOSS [training: 0.04066758218629401 | validation: 0.03470202737094946]
	TIME [epoch: 6.42 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037983537872630174		[learning rate: 1.1131e-05]
	Learning Rate: 1.11311e-05
	LOSS [training: 0.037983537872630174 | validation: 0.031126194254748434]
	TIME [epoch: 6.41 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03611253244989081		[learning rate: 1.1092e-05]
	Learning Rate: 1.10918e-05
	LOSS [training: 0.03611253244989081 | validation: 0.032542370709198645]
	TIME [epoch: 6.42 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036676956721094334		[learning rate: 1.1053e-05]
	Learning Rate: 1.10525e-05
	LOSS [training: 0.036676956721094334 | validation: 0.028121294756747146]
	TIME [epoch: 6.42 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037219852781677235		[learning rate: 1.1013e-05]
	Learning Rate: 1.10134e-05
	LOSS [training: 0.037219852781677235 | validation: 0.031759410658909054]
	TIME [epoch: 6.45 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03855850474692028		[learning rate: 1.0975e-05]
	Learning Rate: 1.09745e-05
	LOSS [training: 0.03855850474692028 | validation: 0.0255812404842451]
	TIME [epoch: 6.41 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04046391293827623		[learning rate: 1.0936e-05]
	Learning Rate: 1.09357e-05
	LOSS [training: 0.04046391293827623 | validation: 0.031027263424909038]
	TIME [epoch: 6.41 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03604642086157336		[learning rate: 1.0897e-05]
	Learning Rate: 1.0897e-05
	LOSS [training: 0.03604642086157336 | validation: 0.02841396960553555]
	TIME [epoch: 6.38 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.038307571688803485		[learning rate: 1.0858e-05]
	Learning Rate: 1.08585e-05
	LOSS [training: 0.038307571688803485 | validation: 0.029589507788087804]
	TIME [epoch: 6.38 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036816880392415326		[learning rate: 1.082e-05]
	Learning Rate: 1.08201e-05
	LOSS [training: 0.036816880392415326 | validation: 0.024158508620388527]
	TIME [epoch: 6.39 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03626349536841202		[learning rate: 1.0782e-05]
	Learning Rate: 1.07818e-05
	LOSS [training: 0.03626349536841202 | validation: 0.029617201495092966]
	TIME [epoch: 6.39 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0354882970071799		[learning rate: 1.0744e-05]
	Learning Rate: 1.07437e-05
	LOSS [training: 0.0354882970071799 | validation: 0.028657053913394986]
	TIME [epoch: 6.42 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040274896797791386		[learning rate: 1.0706e-05]
	Learning Rate: 1.07057e-05
	LOSS [training: 0.040274896797791386 | validation: 0.02517619835094039]
	TIME [epoch: 6.39 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037227833831854185		[learning rate: 1.0668e-05]
	Learning Rate: 1.06679e-05
	LOSS [training: 0.037227833831854185 | validation: 0.019487359776246153]
	TIME [epoch: 6.38 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.040140124206720196		[learning rate: 1.063e-05]
	Learning Rate: 1.06301e-05
	LOSS [training: 0.040140124206720196 | validation: 0.025347866881122547]
	TIME [epoch: 6.39 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03231948761286439		[learning rate: 1.0593e-05]
	Learning Rate: 1.05925e-05
	LOSS [training: 0.03231948761286439 | validation: 0.02530760925830676]
	TIME [epoch: 6.39 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039037901690091845		[learning rate: 1.0555e-05]
	Learning Rate: 1.05551e-05
	LOSS [training: 0.039037901690091845 | validation: 0.03045550991656157]
	TIME [epoch: 6.38 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0368821607432365		[learning rate: 1.0518e-05]
	Learning Rate: 1.05178e-05
	LOSS [training: 0.0368821607432365 | validation: 0.030145376363615632]
	TIME [epoch: 6.38 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0365648291512979		[learning rate: 1.0481e-05]
	Learning Rate: 1.04806e-05
	LOSS [training: 0.0365648291512979 | validation: 0.03574629260542122]
	TIME [epoch: 6.41 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03655472897109934		[learning rate: 1.0444e-05]
	Learning Rate: 1.04435e-05
	LOSS [training: 0.03655472897109934 | validation: 0.026936729762626947]
	TIME [epoch: 6.38 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03908897699475789		[learning rate: 1.0407e-05]
	Learning Rate: 1.04066e-05
	LOSS [training: 0.03908897699475789 | validation: 0.04118613751538473]
	TIME [epoch: 6.39 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03709680051786672		[learning rate: 1.037e-05]
	Learning Rate: 1.03698e-05
	LOSS [training: 0.03709680051786672 | validation: 0.035396643945367894]
	TIME [epoch: 6.39 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.041735643543921584		[learning rate: 1.0333e-05]
	Learning Rate: 1.03331e-05
	LOSS [training: 0.041735643543921584 | validation: 0.030313785120558594]
	TIME [epoch: 6.4 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04027355866892062		[learning rate: 1.0297e-05]
	Learning Rate: 1.02966e-05
	LOSS [training: 0.04027355866892062 | validation: 0.021796675934819983]
	TIME [epoch: 6.41 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.039932612510365326		[learning rate: 1.026e-05]
	Learning Rate: 1.02602e-05
	LOSS [training: 0.039932612510365326 | validation: 0.03877952559781563]
	TIME [epoch: 6.41 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.04134541379447821		[learning rate: 1.0224e-05]
	Learning Rate: 1.02239e-05
	LOSS [training: 0.04134541379447821 | validation: 0.02892596815132547]
	TIME [epoch: 6.44 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.0358577504767634		[learning rate: 1.0188e-05]
	Learning Rate: 1.01877e-05
	LOSS [training: 0.0358577504767634 | validation: 0.030267845851129637]
	TIME [epoch: 6.42 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036794745323110375		[learning rate: 1.0152e-05]
	Learning Rate: 1.01517e-05
	LOSS [training: 0.036794745323110375 | validation: 0.03386580006121592]
	TIME [epoch: 6.41 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.037611831852973364		[learning rate: 1.0116e-05]
	Learning Rate: 1.01158e-05
	LOSS [training: 0.037611831852973364 | validation: 0.02812187458495839]
	TIME [epoch: 6.41 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03816790580727793		[learning rate: 1.008e-05]
	Learning Rate: 1.008e-05
	LOSS [training: 0.03816790580727793 | validation: 0.02838264133921098]
	TIME [epoch: 6.41 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.036371641563269816		[learning rate: 1.0044e-05]
	Learning Rate: 1.00444e-05
	LOSS [training: 0.036371641563269816 | validation: 0.026068711173712393]
	TIME [epoch: 6.41 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.03640518890159686		[learning rate: 1.0009e-05]
	Learning Rate: 1.00089e-05
	LOSS [training: 0.03640518890159686 | validation: 0.03271951677426653]
	TIME [epoch: 6.42 sec]
Finished training in 13015.108 seconds.
