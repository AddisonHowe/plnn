Args:
Namespace(name='model_tr_study1', outdir='out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5', training_data='data/transition_rate_studies/tr_study1/tr_study1_training/r5', validation_data='data/transition_rate_studies/tr_study1/tr_study1_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3938353145

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 10/20] avg loss: 10.821443330021694		[learning rate: 0.01]
		[batch 20/20] avg loss: 9.730678895255037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 10.276061112638365 | validation: 8.54483055825978]
	TIME [epoch: 48.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 10/20] avg loss: 8.002237048001286		[learning rate: 0.01]
		[batch 20/20] avg loss: 7.030419881449222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.516328464725255 | validation: 6.46993325677287]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 10/20] avg loss: 6.9156549751152525		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.750129816757199		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.832892395936225 | validation: 6.380574519297787]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 10/20] avg loss: 6.777350212180012		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.764566172527881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.770958192353947 | validation: 6.326237428720374]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 10/20] avg loss: 6.5561418018865565		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.884859395397635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7205005986420945 | validation: 6.208203807153005]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 10/20] avg loss: 6.487243063286854		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.821831374122401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.654537218704627 | validation: 6.186397026604993]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 10/20] avg loss: 6.85566539268802		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.395574250683099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.625619821685559 | validation: 6.143854163501649]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 10/20] avg loss: 6.697636376725096		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.443568402899982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.570602389812538 | validation: 6.524498259489533]
	TIME [epoch: 8.85 sec]
EPOCH 9/500:
	Training over batches...
		[batch 10/20] avg loss: 6.768518356301465		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.472690781257572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.620604568779518 | validation: 6.190965445227584]
	TIME [epoch: 8.83 sec]
EPOCH 10/500:
	Training over batches...
		[batch 10/20] avg loss: 6.62520145829791		[learning rate: 0.01]
		[batch 20/20] avg loss: 6.720904264308811		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6730528613033595 | validation: 6.086767250340134]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 10/20] avg loss: 6.664860808434762		[learning rate: 0.0099789]
		[batch 20/20] avg loss: 6.513692875737024		[learning rate: 0.0099555]
	Learning Rate: 0.00995546
	LOSS [training: 6.589276842085894 | validation: 6.111402754496133]
	TIME [epoch: 8.87 sec]
EPOCH 12/500:
	Training over batches...
		[batch 10/20] avg loss: 6.4033099285620825		[learning rate: 0.0099321]
		[batch 20/20] avg loss: 6.752085133864744		[learning rate: 0.0099088]
	Learning Rate: 0.00990879
	LOSS [training: 6.5776975312134125 | validation: 6.1410602277578645]
	TIME [epoch: 8.86 sec]
EPOCH 13/500:
	Training over batches...
		[batch 10/20] avg loss: 6.540762275611526		[learning rate: 0.0098855]
		[batch 20/20] avg loss: 6.535496653458185		[learning rate: 0.0098623]
	Learning Rate: 0.00986233
	LOSS [training: 6.538129464534856 | validation: 6.138695545896401]
	TIME [epoch: 8.85 sec]
EPOCH 14/500:
	Training over batches...
		[batch 10/20] avg loss: 6.526203872064758		[learning rate: 0.0098392]
		[batch 20/20] avg loss: 6.609046714502784		[learning rate: 0.0098161]
	Learning Rate: 0.0098161
	LOSS [training: 6.567625293283771 | validation: 6.066426430583498]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 10/20] avg loss: 6.658449631969413		[learning rate: 0.0097931]
		[batch 20/20] avg loss: 6.452207938132088		[learning rate: 0.0097701]
	Learning Rate: 0.00977008
	LOSS [training: 6.55532878505075 | validation: 6.040321735496535]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 10/20] avg loss: 6.462053129200005		[learning rate: 0.0097471]
		[batch 20/20] avg loss: 6.172046676942648		[learning rate: 0.0097243]
	Learning Rate: 0.00972427
	LOSS [training: 6.317049903071326 | validation: 5.601747081841408]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 10/20] avg loss: 6.061942830376383		[learning rate: 0.0097015]
		[batch 20/20] avg loss: 5.119690550937273		[learning rate: 0.0096787]
	Learning Rate: 0.00967868
	LOSS [training: 5.590816690656827 | validation: 3.5761949445220638]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 10/20] avg loss: 4.524914774837015		[learning rate: 0.009656]
		[batch 20/20] avg loss: 4.327626237208103		[learning rate: 0.0096333]
	Learning Rate: 0.00963331
	LOSS [training: 4.42627050602256 | validation: 4.441993298153015]
	TIME [epoch: 8.85 sec]
EPOCH 19/500:
	Training over batches...
		[batch 10/20] avg loss: 4.397392499470594		[learning rate: 0.0096107]
		[batch 20/20] avg loss: 4.285766082337689		[learning rate: 0.0095881]
	Learning Rate: 0.00958815
	LOSS [training: 4.341579290904142 | validation: 3.975312062128744]
	TIME [epoch: 8.86 sec]
EPOCH 20/500:
	Training over batches...
		[batch 10/20] avg loss: 4.28503355141158		[learning rate: 0.0095656]
		[batch 20/20] avg loss: 4.3725215182429205		[learning rate: 0.0095432]
	Learning Rate: 0.0095432
	LOSS [training: 4.32877753482725 | validation: 3.718342284971348]
	TIME [epoch: 8.85 sec]
EPOCH 21/500:
	Training over batches...
		[batch 10/20] avg loss: 4.352705963748212		[learning rate: 0.0095208]
		[batch 20/20] avg loss: 4.056749352573159		[learning rate: 0.0094985]
	Learning Rate: 0.00949846
	LOSS [training: 4.204727658160686 | validation: 3.719874808549818]
	TIME [epoch: 8.85 sec]
EPOCH 22/500:
	Training over batches...
		[batch 10/20] avg loss: 4.038165607445237		[learning rate: 0.0094762]
		[batch 20/20] avg loss: 4.058141734797345		[learning rate: 0.0094539]
	Learning Rate: 0.00945393
	LOSS [training: 4.048153671121291 | validation: 3.2151563563247336]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_22.pth
	Model improved!!!
EPOCH 23/500:
	Training over batches...
		[batch 10/20] avg loss: 3.9432938440992276		[learning rate: 0.0094317]
		[batch 20/20] avg loss: 3.9746583548401966		[learning rate: 0.0094096]
	Learning Rate: 0.00940961
	LOSS [training: 3.9589760994697123 | validation: 3.637060623233171]
	TIME [epoch: 8.85 sec]
EPOCH 24/500:
	Training over batches...
		[batch 10/20] avg loss: 4.27782691103885		[learning rate: 0.0093875]
		[batch 20/20] avg loss: 4.011129521869305		[learning rate: 0.0093655]
	Learning Rate: 0.00936549
	LOSS [training: 4.144478216454077 | validation: 3.196635222494919]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 10/20] avg loss: 4.151237565790666		[learning rate: 0.0093435]
		[batch 20/20] avg loss: 3.77955274475863		[learning rate: 0.0093216]
	Learning Rate: 0.00932159
	LOSS [training: 3.9653951552746483 | validation: 3.3510656441397804]
	TIME [epoch: 8.82 sec]
EPOCH 26/500:
	Training over batches...
		[batch 10/20] avg loss: 3.9730968333689782		[learning rate: 0.0092997]
		[batch 20/20] avg loss: 3.7433026813681076		[learning rate: 0.0092779]
	Learning Rate: 0.00927788
	LOSS [training: 3.858199757368543 | validation: 3.1036110512863946]
	TIME [epoch: 8.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 10/20] avg loss: 3.9174468373351417		[learning rate: 0.0092561]
		[batch 20/20] avg loss: 3.6728346585093967		[learning rate: 0.0092344]
	Learning Rate: 0.00923439
	LOSS [training: 3.795140747922269 | validation: 3.1255411620842253]
	TIME [epoch: 8.83 sec]
EPOCH 28/500:
	Training over batches...
		[batch 10/20] avg loss: 3.6873899115054227		[learning rate: 0.0092127]
		[batch 20/20] avg loss: 3.9895537923263467		[learning rate: 0.0091911]
	Learning Rate: 0.0091911
	LOSS [training: 3.838471851915885 | validation: 2.8926101929152543]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 10/20] avg loss: 3.778509074808736		[learning rate: 0.0091695]
		[batch 20/20] avg loss: 3.8975845238702194		[learning rate: 0.009148]
	Learning Rate: 0.00914801
	LOSS [training: 3.8380467993394776 | validation: 3.2551628103144923]
	TIME [epoch: 8.85 sec]
EPOCH 30/500:
	Training over batches...
		[batch 10/20] avg loss: 3.909034657126244		[learning rate: 0.0091265]
		[batch 20/20] avg loss: 3.3405558446633647		[learning rate: 0.0091051]
	Learning Rate: 0.00910512
	LOSS [training: 3.624795250894805 | validation: 3.402392052223889]
	TIME [epoch: 8.84 sec]
EPOCH 31/500:
	Training over batches...
		[batch 10/20] avg loss: 3.518156131462294		[learning rate: 0.0090838]
		[batch 20/20] avg loss: 3.3578567581422085		[learning rate: 0.0090624]
	Learning Rate: 0.00906243
	LOSS [training: 3.4380064448022516 | validation: 2.9868956264312247]
	TIME [epoch: 8.84 sec]
EPOCH 32/500:
	Training over batches...
		[batch 10/20] avg loss: 3.327289158328255		[learning rate: 0.0090412]
		[batch 20/20] avg loss: 2.571799018867905		[learning rate: 0.0090199]
	Learning Rate: 0.00901995
	LOSS [training: 2.94954408859808 | validation: 2.305849347613425]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 10/20] avg loss: 2.09700097295494		[learning rate: 0.0089988]
		[batch 20/20] avg loss: 1.9264396378331845		[learning rate: 0.0089777]
	Learning Rate: 0.00897766
	LOSS [training: 2.011720305394063 | validation: 1.6489485405787576]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 10/20] avg loss: 1.888184321785624		[learning rate: 0.0089566]
		[batch 20/20] avg loss: 1.9502706349701864		[learning rate: 0.0089356]
	Learning Rate: 0.00893557
	LOSS [training: 1.9192274783779049 | validation: 1.7927104691772213]
	TIME [epoch: 8.84 sec]
EPOCH 35/500:
	Training over batches...
		[batch 10/20] avg loss: 2.1686969634252233		[learning rate: 0.0089146]
		[batch 20/20] avg loss: 1.7212110423803153		[learning rate: 0.0088937]
	Learning Rate: 0.00889368
	LOSS [training: 1.9449540029027694 | validation: 1.8059171644908985]
	TIME [epoch: 8.83 sec]
EPOCH 36/500:
	Training over batches...
		[batch 10/20] avg loss: 1.7257582907037026		[learning rate: 0.0088728]
		[batch 20/20] avg loss: 1.6673852097322623		[learning rate: 0.008852]
	Learning Rate: 0.00885199
	LOSS [training: 1.696571750217982 | validation: 1.52984308287661]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_36.pth
	Model improved!!!
EPOCH 37/500:
	Training over batches...
		[batch 10/20] avg loss: 1.7413545672968709		[learning rate: 0.0088312]
		[batch 20/20] avg loss: 1.6436154385481214		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 1.6924850029224963 | validation: 2.147011528805652]
	TIME [epoch: 8.86 sec]
EPOCH 38/500:
	Training over batches...
		[batch 10/20] avg loss: 1.8890593524131614		[learning rate: 0.0087898]
		[batch 20/20] avg loss: 1.6305051452464832		[learning rate: 0.0087692]
	Learning Rate: 0.00876918
	LOSS [training: 1.7597822488298225 | validation: 1.4515083336848682]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 10/20] avg loss: 1.7307440475059077		[learning rate: 0.0087486]
		[batch 20/20] avg loss: 1.8622882308117163		[learning rate: 0.0087281]
	Learning Rate: 0.00872807
	LOSS [training: 1.7965161391588123 | validation: 2.2330305220636104]
	TIME [epoch: 8.84 sec]
EPOCH 40/500:
	Training over batches...
		[batch 10/20] avg loss: 1.7184227170670212		[learning rate: 0.0087076]
		[batch 20/20] avg loss: 1.6043895556793277		[learning rate: 0.0086872]
	Learning Rate: 0.00868715
	LOSS [training: 1.6614061363731742 | validation: 1.4014742602468393]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 10/20] avg loss: 1.6043701898532834		[learning rate: 0.0086668]
		[batch 20/20] avg loss: 1.5213815302080826		[learning rate: 0.0086464]
	Learning Rate: 0.00864643
	LOSS [training: 1.562875860030683 | validation: 1.8659280846339414]
	TIME [epoch: 8.85 sec]
EPOCH 42/500:
	Training over batches...
		[batch 10/20] avg loss: 1.6011472875614488		[learning rate: 0.0086261]
		[batch 20/20] avg loss: 1.5158307021208588		[learning rate: 0.0086059]
	Learning Rate: 0.00860589
	LOSS [training: 1.558488994841154 | validation: 1.607996357008217]
	TIME [epoch: 8.85 sec]
EPOCH 43/500:
	Training over batches...
		[batch 10/20] avg loss: 1.5824972652658915		[learning rate: 0.0085857]
		[batch 20/20] avg loss: 1.636289637995634		[learning rate: 0.0085655]
	Learning Rate: 0.00856555
	LOSS [training: 1.6093934516307624 | validation: 1.437585734844674]
	TIME [epoch: 8.85 sec]
EPOCH 44/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3699130688449515		[learning rate: 0.0085454]
		[batch 20/20] avg loss: 1.8544893111815282		[learning rate: 0.0085254]
	Learning Rate: 0.00852539
	LOSS [training: 1.6122011900132396 | validation: 1.3575959352625142]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_44.pth
	Model improved!!!
EPOCH 45/500:
	Training over batches...
		[batch 10/20] avg loss: 1.5141820614389936		[learning rate: 0.0085054]
		[batch 20/20] avg loss: 1.5595280638580982		[learning rate: 0.0084854]
	Learning Rate: 0.00848542
	LOSS [training: 1.536855062648546 | validation: 1.4077926106222536]
	TIME [epoch: 8.87 sec]
EPOCH 46/500:
	Training over batches...
		[batch 10/20] avg loss: 1.5331268521393586		[learning rate: 0.0084655]
		[batch 20/20] avg loss: 1.444362604964224		[learning rate: 0.0084456]
	Learning Rate: 0.00844564
	LOSS [training: 1.4887447285517912 | validation: 1.186417193744736]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 10/20] avg loss: 1.375266136049008		[learning rate: 0.0084258]
		[batch 20/20] avg loss: 1.5232041784862014		[learning rate: 0.008406]
	Learning Rate: 0.00840605
	LOSS [training: 1.449235157267605 | validation: 1.4797521903363031]
	TIME [epoch: 8.85 sec]
EPOCH 48/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4902191280574464		[learning rate: 0.0083863]
		[batch 20/20] avg loss: 1.6161368679250614		[learning rate: 0.0083666]
	Learning Rate: 0.00836664
	LOSS [training: 1.5531779979912537 | validation: 1.5011043633378591]
	TIME [epoch: 8.85 sec]
EPOCH 49/500:
	Training over batches...
		[batch 10/20] avg loss: 1.484218837685824		[learning rate: 0.008347]
		[batch 20/20] avg loss: 1.5796620647293733		[learning rate: 0.0083274]
	Learning Rate: 0.00832742
	LOSS [training: 1.5319404512075987 | validation: 1.322693733725557]
	TIME [epoch: 8.85 sec]
EPOCH 50/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4455719459465501		[learning rate: 0.0083079]
		[batch 20/20] avg loss: 1.530078525462001		[learning rate: 0.0082884]
	Learning Rate: 0.00828838
	LOSS [training: 1.487825235704276 | validation: 1.623535800644106]
	TIME [epoch: 8.93 sec]
EPOCH 51/500:
	Training over batches...
		[batch 10/20] avg loss: 1.448258966006896		[learning rate: 0.0082689]
		[batch 20/20] avg loss: 1.4334790562034336		[learning rate: 0.0082495]
	Learning Rate: 0.00824952
	LOSS [training: 1.4408690111051652 | validation: 1.3799329257546717]
	TIME [epoch: 8.85 sec]
EPOCH 52/500:
	Training over batches...
		[batch 10/20] avg loss: 1.6937716829536082		[learning rate: 0.0082302]
		[batch 20/20] avg loss: 1.327626986925012		[learning rate: 0.0082108]
	Learning Rate: 0.00821084
	LOSS [training: 1.51069933493931 | validation: 2.8952863790452916]
	TIME [epoch: 8.85 sec]
EPOCH 53/500:
	Training over batches...
		[batch 10/20] avg loss: 2.244247762080199		[learning rate: 0.0081916]
		[batch 20/20] avg loss: 1.391870499965219		[learning rate: 0.0081723]
	Learning Rate: 0.00817235
	LOSS [training: 1.8180591310227094 | validation: 1.338690910482372]
	TIME [epoch: 8.84 sec]
EPOCH 54/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4562534979695443		[learning rate: 0.0081532]
		[batch 20/20] avg loss: 1.30100409144142		[learning rate: 0.008134]
	Learning Rate: 0.00813404
	LOSS [training: 1.3786287947054823 | validation: 2.0232470612809594]
	TIME [epoch: 8.85 sec]
EPOCH 55/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3787244963494385		[learning rate: 0.0081149]
		[batch 20/20] avg loss: 1.7614061783541293		[learning rate: 0.0080959]
	Learning Rate: 0.0080959
	LOSS [training: 1.5700653373517839 | validation: 1.7091065788234778]
	TIME [epoch: 8.85 sec]
EPOCH 56/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4079425430524586		[learning rate: 0.0080769]
		[batch 20/20] avg loss: 1.3471528807845057		[learning rate: 0.0080579]
	Learning Rate: 0.00805795
	LOSS [training: 1.3775477119184822 | validation: 1.190115406855619]
	TIME [epoch: 8.83 sec]
EPOCH 57/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3233394018828748		[learning rate: 0.008039]
		[batch 20/20] avg loss: 1.4419032033259171		[learning rate: 0.0080202]
	Learning Rate: 0.00802017
	LOSS [training: 1.3826213026043959 | validation: 1.2292884586118134]
	TIME [epoch: 8.84 sec]
EPOCH 58/500:
	Training over batches...
		[batch 10/20] avg loss: 1.2505909469430052		[learning rate: 0.0080013]
		[batch 20/20] avg loss: 1.4126781748479011		[learning rate: 0.0079826]
	Learning Rate: 0.00798257
	LOSS [training: 1.3316345608954534 | validation: 1.5066448743873189]
	TIME [epoch: 8.85 sec]
EPOCH 59/500:
	Training over batches...
		[batch 10/20] avg loss: 1.39279432635269		[learning rate: 0.0079638]
		[batch 20/20] avg loss: 1.3814483085094678		[learning rate: 0.0079451]
	Learning Rate: 0.00794515
	LOSS [training: 1.387121317431079 | validation: 1.2980027634775073]
	TIME [epoch: 8.85 sec]
EPOCH 60/500:
	Training over batches...
		[batch 10/20] avg loss: 1.6672305923804178		[learning rate: 0.0079265]
		[batch 20/20] avg loss: 1.3016145735193725		[learning rate: 0.0079079]
	Learning Rate: 0.0079079
	LOSS [training: 1.484422582949895 | validation: 1.1767312595359587]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_60.pth
	Model improved!!!
EPOCH 61/500:
	Training over batches...
		[batch 10/20] avg loss: 1.2251525468873		[learning rate: 0.0078893]
		[batch 20/20] avg loss: 1.401869398718875		[learning rate: 0.0078708]
	Learning Rate: 0.00787083
	LOSS [training: 1.3135109728030876 | validation: 1.2740511905318508]
	TIME [epoch: 8.84 sec]
EPOCH 62/500:
	Training over batches...
		[batch 10/20] avg loss: 1.26637100977528		[learning rate: 0.0078524]
		[batch 20/20] avg loss: 1.2020931869905624		[learning rate: 0.0078339]
	Learning Rate: 0.00783393
	LOSS [training: 1.2342320983829211 | validation: 1.6500715958611094]
	TIME [epoch: 8.84 sec]
EPOCH 63/500:
	Training over batches...
		[batch 10/20] avg loss: 1.2841458824074121		[learning rate: 0.0078155]
		[batch 20/20] avg loss: 1.3366386704461501		[learning rate: 0.0077972]
	Learning Rate: 0.0077972
	LOSS [training: 1.3103922764267812 | validation: 1.3177059506370699]
	TIME [epoch: 8.86 sec]
EPOCH 64/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3543903577868084		[learning rate: 0.0077789]
		[batch 20/20] avg loss: 1.0839267302968736		[learning rate: 0.0077606]
	Learning Rate: 0.00776065
	LOSS [training: 1.219158544041841 | validation: 1.1641801089660884]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_64.pth
	Model improved!!!
EPOCH 65/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1725014172474872		[learning rate: 0.0077424]
		[batch 20/20] avg loss: 1.3278822885106967		[learning rate: 0.0077243]
	Learning Rate: 0.00772426
	LOSS [training: 1.250191852879092 | validation: 1.2204932248037383]
	TIME [epoch: 8.83 sec]
EPOCH 66/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4828181385481118		[learning rate: 0.0077061]
		[batch 20/20] avg loss: 1.18067065066254		[learning rate: 0.0076881]
	Learning Rate: 0.00768805
	LOSS [training: 1.3317443946053258 | validation: 1.1884336435371115]
	TIME [epoch: 8.84 sec]
EPOCH 67/500:
	Training over batches...
		[batch 10/20] avg loss: 1.280964899668143		[learning rate: 0.00767]
		[batch 20/20] avg loss: 1.3486471589737188		[learning rate: 0.007652]
	Learning Rate: 0.00765201
	LOSS [training: 1.3148060293209312 | validation: 1.0208465415301844]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_67.pth
	Model improved!!!
EPOCH 68/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0760897529467859		[learning rate: 0.0076341]
		[batch 20/20] avg loss: 1.419676799113439		[learning rate: 0.0076161]
	Learning Rate: 0.00761614
	LOSS [training: 1.2478832760301122 | validation: 1.1474415927191717]
	TIME [epoch: 8.85 sec]
EPOCH 69/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0112856703438236		[learning rate: 0.0075983]
		[batch 20/20] avg loss: 1.0972215944820705		[learning rate: 0.0075804]
	Learning Rate: 0.00758043
	LOSS [training: 1.0542536324129472 | validation: 0.8498016539190226]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_69.pth
	Model improved!!!
EPOCH 70/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0138708143622464		[learning rate: 0.0075626]
		[batch 20/20] avg loss: 1.3681874938919647		[learning rate: 0.0075449]
	Learning Rate: 0.00754489
	LOSS [training: 1.1910291541271052 | validation: 1.979918894078653]
	TIME [epoch: 8.85 sec]
EPOCH 71/500:
	Training over batches...
		[batch 10/20] avg loss: 1.4727105717638869		[learning rate: 0.0075272]
		[batch 20/20] avg loss: 1.1869882789646486		[learning rate: 0.0075095]
	Learning Rate: 0.00750952
	LOSS [training: 1.3298494253642676 | validation: 1.0566321644403813]
	TIME [epoch: 8.87 sec]
EPOCH 72/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0947396990607543		[learning rate: 0.0074919]
		[batch 20/20] avg loss: 1.2576194157622722		[learning rate: 0.0074743]
	Learning Rate: 0.00747431
	LOSS [training: 1.1761795574115133 | validation: 0.8196800317184908]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_72.pth
	Model improved!!!
EPOCH 73/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1195492335253439		[learning rate: 0.0074568]
		[batch 20/20] avg loss: 1.0698094951656536		[learning rate: 0.0074393]
	Learning Rate: 0.00743927
	LOSS [training: 1.0946793643454984 | validation: 0.9237904627383413]
	TIME [epoch: 8.87 sec]
EPOCH 74/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3040213080581364		[learning rate: 0.0074218]
		[batch 20/20] avg loss: 1.441634865379252		[learning rate: 0.0074044]
	Learning Rate: 0.0074044
	LOSS [training: 1.3728280867186942 | validation: 1.5589540885779924]
	TIME [epoch: 8.85 sec]
EPOCH 75/500:
	Training over batches...
		[batch 10/20] avg loss: 1.142477692732652		[learning rate: 0.007387]
		[batch 20/20] avg loss: 1.258274132747		[learning rate: 0.0073697]
	Learning Rate: 0.00736969
	LOSS [training: 1.2003759127398261 | validation: 1.2458474528432866]
	TIME [epoch: 8.85 sec]
EPOCH 76/500:
	Training over batches...
		[batch 10/20] avg loss: 1.2638340389475147		[learning rate: 0.0073524]
		[batch 20/20] avg loss: 1.2524551386686094		[learning rate: 0.0073351]
	Learning Rate: 0.00733514
	LOSS [training: 1.258144588808062 | validation: 0.9398107977379425]
	TIME [epoch: 8.86 sec]
EPOCH 77/500:
	Training over batches...
		[batch 10/20] avg loss: 1.2180243237680697		[learning rate: 0.0073179]
		[batch 20/20] avg loss: 1.192772601775151		[learning rate: 0.0073007]
	Learning Rate: 0.00730075
	LOSS [training: 1.2053984627716106 | validation: 0.9693868834946916]
	TIME [epoch: 8.85 sec]
EPOCH 78/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1525261504127176		[learning rate: 0.0072836]
		[batch 20/20] avg loss: 1.1866090200791863		[learning rate: 0.0072665]
	Learning Rate: 0.00726652
	LOSS [training: 1.1695675852459522 | validation: 1.373024802421407]
	TIME [epoch: 8.85 sec]
EPOCH 79/500:
	Training over batches...
		[batch 10/20] avg loss: 1.2635859105063534		[learning rate: 0.0072495]
		[batch 20/20] avg loss: 1.117460951101709		[learning rate: 0.0072325]
	Learning Rate: 0.00723246
	LOSS [training: 1.1905234308040313 | validation: 0.9257020615150493]
	TIME [epoch: 8.84 sec]
EPOCH 80/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0611168497223868		[learning rate: 0.0072155]
		[batch 20/20] avg loss: 1.1516848570459894		[learning rate: 0.0071985]
	Learning Rate: 0.00719855
	LOSS [training: 1.106400853384188 | validation: 0.7561379323388839]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_80.pth
	Model improved!!!
EPOCH 81/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0470913026963382		[learning rate: 0.0071817]
		[batch 20/20] avg loss: 1.0135948416214258		[learning rate: 0.0071648]
	Learning Rate: 0.0071648
	LOSS [training: 1.030343072158882 | validation: 1.5838515853813313]
	TIME [epoch: 8.84 sec]
EPOCH 82/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1868693180530199		[learning rate: 0.007148]
		[batch 20/20] avg loss: 1.2377184254997853		[learning rate: 0.0071312]
	Learning Rate: 0.00713121
	LOSS [training: 1.212293871776403 | validation: 1.0208257946205088]
	TIME [epoch: 8.84 sec]
EPOCH 83/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3186365904186395		[learning rate: 0.0071145]
		[batch 20/20] avg loss: 1.0805731390030786		[learning rate: 0.0070978]
	Learning Rate: 0.00709778
	LOSS [training: 1.1996048647108593 | validation: 1.0039859662651884]
	TIME [epoch: 8.85 sec]
EPOCH 84/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1365048573240633		[learning rate: 0.0070811]
		[batch 20/20] avg loss: 1.2124172287506325		[learning rate: 0.0070645]
	Learning Rate: 0.0070645
	LOSS [training: 1.1744610430373474 | validation: 1.8559490597920885]
	TIME [epoch: 8.84 sec]
EPOCH 85/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1708974977753246		[learning rate: 0.0070479]
		[batch 20/20] avg loss: 1.4406944653670248		[learning rate: 0.0070314]
	Learning Rate: 0.00703138
	LOSS [training: 1.3057959815711748 | validation: 2.907635180656533]
	TIME [epoch: 8.87 sec]
EPOCH 86/500:
	Training over batches...
		[batch 10/20] avg loss: 1.3172338216339963		[learning rate: 0.0070149]
		[batch 20/20] avg loss: 1.2288407539069621		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.2730372877704792 | validation: 1.1067680121624233]
	TIME [epoch: 8.84 sec]
EPOCH 87/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0926741570698915		[learning rate: 0.006982]
		[batch 20/20] avg loss: 1.2627674866680803		[learning rate: 0.0069656]
	Learning Rate: 0.00696561
	LOSS [training: 1.1777208218689859 | validation: 1.1876186823458463]
	TIME [epoch: 8.84 sec]
EPOCH 88/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0113346642602505		[learning rate: 0.0069493]
		[batch 20/20] avg loss: 1.0228591487862067		[learning rate: 0.006933]
	Learning Rate: 0.00693295
	LOSS [training: 1.0170969065232287 | validation: 0.9166596949268024]
	TIME [epoch: 8.84 sec]
EPOCH 89/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1878827820324578		[learning rate: 0.0069167]
		[batch 20/20] avg loss: 1.0985701762942726		[learning rate: 0.0069005]
	Learning Rate: 0.00690045
	LOSS [training: 1.1432264791633653 | validation: 1.3037122522960432]
	TIME [epoch: 8.86 sec]
EPOCH 90/500:
	Training over batches...
		[batch 10/20] avg loss: 1.037409437036919		[learning rate: 0.0068843]
		[batch 20/20] avg loss: 0.9582054252729527		[learning rate: 0.0068681]
	Learning Rate: 0.0068681
	LOSS [training: 0.9978074311549359 | validation: 1.0903723545714608]
	TIME [epoch: 8.85 sec]
EPOCH 91/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8893473368015018		[learning rate: 0.006852]
		[batch 20/20] avg loss: 1.3748593640413884		[learning rate: 0.0068359]
	Learning Rate: 0.0068359
	LOSS [training: 1.132103350421445 | validation: 1.0884184812989832]
	TIME [epoch: 8.84 sec]
EPOCH 92/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1425500040847851		[learning rate: 0.0068199]
		[batch 20/20] avg loss: 1.0362130086771502		[learning rate: 0.0068039]
	Learning Rate: 0.00680386
	LOSS [training: 1.0893815063809675 | validation: 0.9730707068934132]
	TIME [epoch: 8.84 sec]
EPOCH 93/500:
	Training over batches...
		[batch 10/20] avg loss: 1.1129812020928636		[learning rate: 0.0067879]
		[batch 20/20] avg loss: 1.0345706873794727		[learning rate: 0.006772]
	Learning Rate: 0.00677196
	LOSS [training: 1.0737759447361683 | validation: 0.6549673672660141]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_93.pth
	Model improved!!!
EPOCH 94/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7831298808692543		[learning rate: 0.0067561]
		[batch 20/20] avg loss: 1.0484774803833787		[learning rate: 0.0067402]
	Learning Rate: 0.00674021
	LOSS [training: 0.9158036806263163 | validation: 0.9542993266118189]
	TIME [epoch: 8.87 sec]
EPOCH 95/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8316169635682364		[learning rate: 0.0067244]
		[batch 20/20] avg loss: 1.2787267023589644		[learning rate: 0.0067086]
	Learning Rate: 0.00670861
	LOSS [training: 1.0551718329636004 | validation: 1.070942686547371]
	TIME [epoch: 8.85 sec]
EPOCH 96/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0630005936186517		[learning rate: 0.0066929]
		[batch 20/20] avg loss: 0.8564918266150283		[learning rate: 0.0066772]
	Learning Rate: 0.00667716
	LOSS [training: 0.95974621011684 | validation: 0.7227951291287515]
	TIME [epoch: 8.85 sec]
EPOCH 97/500:
	Training over batches...
		[batch 10/20] avg loss: 0.835724253880435		[learning rate: 0.0066615]
		[batch 20/20] avg loss: 1.0442535529044736		[learning rate: 0.0066459]
	Learning Rate: 0.00664586
	LOSS [training: 0.9399889033924543 | validation: 0.9850387153669933]
	TIME [epoch: 8.85 sec]
EPOCH 98/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0946273677607872		[learning rate: 0.0066303]
		[batch 20/20] avg loss: 1.0958341406131653		[learning rate: 0.0066147]
	Learning Rate: 0.0066147
	LOSS [training: 1.0952307541869761 | validation: 1.0564155205862553]
	TIME [epoch: 8.88 sec]
EPOCH 99/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9795376070259632		[learning rate: 0.0065992]
		[batch 20/20] avg loss: 1.0249228226449811		[learning rate: 0.0065837]
	Learning Rate: 0.00658369
	LOSS [training: 1.0022302148354723 | validation: 1.0810375847221518]
	TIME [epoch: 8.86 sec]
EPOCH 100/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9030509999689889		[learning rate: 0.0065682]
		[batch 20/20] avg loss: 0.9439824480414363		[learning rate: 0.0065528]
	Learning Rate: 0.00655282
	LOSS [training: 0.9235167240052122 | validation: 0.6835366779465073]
	TIME [epoch: 8.86 sec]
EPOCH 101/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0862114223139447		[learning rate: 0.0065374]
		[batch 20/20] avg loss: 0.9366493332541213		[learning rate: 0.0065221]
	Learning Rate: 0.0065221
	LOSS [training: 1.0114303777840332 | validation: 0.9802868918356555]
	TIME [epoch: 8.86 sec]
EPOCH 102/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9434810930321508		[learning rate: 0.0065068]
		[batch 20/20] avg loss: 0.7373907632261326		[learning rate: 0.0064915]
	Learning Rate: 0.00649153
	LOSS [training: 0.8404359281291416 | validation: 0.9487240319221116]
	TIME [epoch: 8.87 sec]
EPOCH 103/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9877519057541504		[learning rate: 0.0064763]
		[batch 20/20] avg loss: 1.0456065367240872		[learning rate: 0.0064611]
	Learning Rate: 0.0064611
	LOSS [training: 1.016679221239119 | validation: 1.011777185031622]
	TIME [epoch: 8.86 sec]
EPOCH 104/500:
	Training over batches...
		[batch 10/20] avg loss: 1.0697116539084082		[learning rate: 0.0064459]
		[batch 20/20] avg loss: 0.9030073700326948		[learning rate: 0.0064308]
	Learning Rate: 0.0064308
	LOSS [training: 0.9863595119705515 | validation: 0.6921829706157667]
	TIME [epoch: 8.86 sec]
EPOCH 105/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8657863025625352		[learning rate: 0.0064157]
		[batch 20/20] avg loss: 0.8413563400951158		[learning rate: 0.0064007]
	Learning Rate: 0.00640066
	LOSS [training: 0.8535713213288256 | validation: 0.8490194778958751]
	TIME [epoch: 8.86 sec]
EPOCH 106/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9557953701673643		[learning rate: 0.0063856]
		[batch 20/20] avg loss: 0.9016060257507649		[learning rate: 0.0063706]
	Learning Rate: 0.00637065
	LOSS [training: 0.9287006979590645 | validation: 0.7322338781647407]
	TIME [epoch: 8.85 sec]
EPOCH 107/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8275956924315675		[learning rate: 0.0063557]
		[batch 20/20] avg loss: 0.8734423678026534		[learning rate: 0.0063408]
	Learning Rate: 0.00634078
	LOSS [training: 0.8505190301171105 | validation: 0.9606933451847389]
	TIME [epoch: 8.88 sec]
EPOCH 108/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8105954269015709		[learning rate: 0.0063259]
		[batch 20/20] avg loss: 0.6710858700896682		[learning rate: 0.0063111]
	Learning Rate: 0.00631106
	LOSS [training: 0.7408406484956196 | validation: 0.8112412658647534]
	TIME [epoch: 8.85 sec]
EPOCH 109/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7717592256707992		[learning rate: 0.0062962]
		[batch 20/20] avg loss: 0.7893902107130837		[learning rate: 0.0062815]
	Learning Rate: 0.00628147
	LOSS [training: 0.7805747181919415 | validation: 1.236706227200705]
	TIME [epoch: 8.85 sec]
EPOCH 110/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8256285700940517		[learning rate: 0.0062667]
		[batch 20/20] avg loss: 0.7957204725704778		[learning rate: 0.006252]
	Learning Rate: 0.00625202
	LOSS [training: 0.8106745213322648 | validation: 0.6229077130802492]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7219507576158636		[learning rate: 0.0062373]
		[batch 20/20] avg loss: 0.8307044294028725		[learning rate: 0.0062227]
	Learning Rate: 0.00622271
	LOSS [training: 0.776327593509368 | validation: 0.8835008377815978]
	TIME [epoch: 8.9 sec]
EPOCH 112/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9577923133291687		[learning rate: 0.0062081]
		[batch 20/20] avg loss: 0.8674014076401727		[learning rate: 0.0061935]
	Learning Rate: 0.00619354
	LOSS [training: 0.9125968604846708 | validation: 0.6943235749435039]
	TIME [epoch: 8.85 sec]
EPOCH 113/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7609226976467236		[learning rate: 0.006179]
		[batch 20/20] avg loss: 0.885146451106453		[learning rate: 0.0061645]
	Learning Rate: 0.0061645
	LOSS [training: 0.8230345743765884 | validation: 0.5972383367428176]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_113.pth
	Model improved!!!
EPOCH 114/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8089842244772747		[learning rate: 0.00615]
		[batch 20/20] avg loss: 0.9084006238079999		[learning rate: 0.0061356]
	Learning Rate: 0.0061356
	LOSS [training: 0.8586924241426376 | validation: 0.9319664305878649]
	TIME [epoch: 8.85 sec]
EPOCH 115/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8953773692109026		[learning rate: 0.0061212]
		[batch 20/20] avg loss: 0.789785151279126		[learning rate: 0.0061068]
	Learning Rate: 0.00610684
	LOSS [training: 0.8425812602450142 | validation: 0.6734453596941594]
	TIME [epoch: 8.85 sec]
EPOCH 116/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7957650299460179		[learning rate: 0.0060925]
		[batch 20/20] avg loss: 0.8059794871616732		[learning rate: 0.0060782]
	Learning Rate: 0.00607821
	LOSS [training: 0.8008722585538454 | validation: 0.5499928070076538]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_116.pth
	Model improved!!!
EPOCH 117/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8716713538868724		[learning rate: 0.0060639]
		[batch 20/20] avg loss: 0.9618865411844828		[learning rate: 0.0060497]
	Learning Rate: 0.00604971
	LOSS [training: 0.9167789475356773 | validation: 0.6379770120158283]
	TIME [epoch: 8.86 sec]
EPOCH 118/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7282665425350442		[learning rate: 0.0060355]
		[batch 20/20] avg loss: 0.9261423599604004		[learning rate: 0.0060213]
	Learning Rate: 0.00602135
	LOSS [training: 0.8272044512477222 | validation: 0.6273239002784894]
	TIME [epoch: 8.87 sec]
EPOCH 119/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7264870918640998		[learning rate: 0.0060072]
		[batch 20/20] avg loss: 0.707523903720843		[learning rate: 0.0059931]
	Learning Rate: 0.00599312
	LOSS [training: 0.7170054977924714 | validation: 0.42355562178121636]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_119.pth
	Model improved!!!
EPOCH 120/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7456766395530978		[learning rate: 0.0059791]
		[batch 20/20] avg loss: 0.7510700652835934		[learning rate: 0.005965]
	Learning Rate: 0.00596502
	LOSS [training: 0.7483733524183458 | validation: 0.541177805888831]
	TIME [epoch: 8.87 sec]
EPOCH 121/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6548358792370409		[learning rate: 0.005951]
		[batch 20/20] avg loss: 0.8840215929740587		[learning rate: 0.0059371]
	Learning Rate: 0.00593706
	LOSS [training: 0.7694287361055497 | validation: 0.9008952620097974]
	TIME [epoch: 8.85 sec]
EPOCH 122/500:
	Training over batches...
		[batch 10/20] avg loss: 0.9093081026156884		[learning rate: 0.0059231]
		[batch 20/20] avg loss: 0.7621267694407524		[learning rate: 0.0059092]
	Learning Rate: 0.00590923
	LOSS [training: 0.8357174360282202 | validation: 0.695272381608993]
	TIME [epoch: 8.83 sec]
EPOCH 123/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7671388520847142		[learning rate: 0.0058954]
		[batch 20/20] avg loss: 0.7513520061717415		[learning rate: 0.0058815]
	Learning Rate: 0.00588152
	LOSS [training: 0.7592454291282278 | validation: 0.9281690904477324]
	TIME [epoch: 8.84 sec]
EPOCH 124/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8185358987623281		[learning rate: 0.0058677]
		[batch 20/20] avg loss: 0.8544282282101193		[learning rate: 0.0058539]
	Learning Rate: 0.00585395
	LOSS [training: 0.8364820634862238 | validation: 0.5768008483703934]
	TIME [epoch: 8.85 sec]
EPOCH 125/500:
	Training over batches...
		[batch 10/20] avg loss: 0.726497786256061		[learning rate: 0.0058402]
		[batch 20/20] avg loss: 0.5981904405949217		[learning rate: 0.0058265]
	Learning Rate: 0.00582651
	LOSS [training: 0.6623441134254913 | validation: 0.6950741981430938]
	TIME [epoch: 8.86 sec]
EPOCH 126/500:
	Training over batches...
		[batch 10/20] avg loss: 0.700177458257672		[learning rate: 0.0058128]
		[batch 20/20] avg loss: 0.7389688125435772		[learning rate: 0.0057992]
	Learning Rate: 0.00579919
	LOSS [training: 0.7195731354006245 | validation: 0.6529862003797331]
	TIME [epoch: 8.85 sec]
EPOCH 127/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8296482014308639		[learning rate: 0.0057856]
		[batch 20/20] avg loss: 0.7899498200069349		[learning rate: 0.005772]
	Learning Rate: 0.005772
	LOSS [training: 0.8097990107188993 | validation: 0.6353681671090001]
	TIME [epoch: 8.85 sec]
EPOCH 128/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7534936708397716		[learning rate: 0.0057585]
		[batch 20/20] avg loss: 0.7307235126606884		[learning rate: 0.0057449]
	Learning Rate: 0.00574494
	LOSS [training: 0.7421085917502299 | validation: 0.6699186681161986]
	TIME [epoch: 8.84 sec]
EPOCH 129/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6633988549627928		[learning rate: 0.0057315]
		[batch 20/20] avg loss: 0.7046203077528543		[learning rate: 0.005718]
	Learning Rate: 0.00571801
	LOSS [training: 0.6840095813578235 | validation: 0.5980894277328713]
	TIME [epoch: 8.86 sec]
EPOCH 130/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6958517065552395		[learning rate: 0.0057046]
		[batch 20/20] avg loss: 0.7192687700842142		[learning rate: 0.0056912]
	Learning Rate: 0.0056912
	LOSS [training: 0.7075602383197268 | validation: 0.5529055241391545]
	TIME [epoch: 8.86 sec]
EPOCH 131/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5820596237818448		[learning rate: 0.0056778]
		[batch 20/20] avg loss: 0.6400369671696167		[learning rate: 0.0056645]
	Learning Rate: 0.00566452
	LOSS [training: 0.6110482954757307 | validation: 0.5312355874879328]
	TIME [epoch: 8.85 sec]
EPOCH 132/500:
	Training over batches...
		[batch 10/20] avg loss: 0.770615661395903		[learning rate: 0.0056512]
		[batch 20/20] avg loss: 0.869432973299834		[learning rate: 0.005638]
	Learning Rate: 0.00563797
	LOSS [training: 0.8200243173478686 | validation: 0.513310037454619]
	TIME [epoch: 8.85 sec]
EPOCH 133/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5564193616705632		[learning rate: 0.0056247]
		[batch 20/20] avg loss: 0.657188453948323		[learning rate: 0.0056115]
	Learning Rate: 0.00561153
	LOSS [training: 0.606803907809443 | validation: 0.4104113613507123]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_133.pth
	Model improved!!!
EPOCH 134/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7455390142906407		[learning rate: 0.0055984]
		[batch 20/20] avg loss: 0.5993466192047324		[learning rate: 0.0055852]
	Learning Rate: 0.00558523
	LOSS [training: 0.6724428167476865 | validation: 0.6762675975588834]
	TIME [epoch: 8.86 sec]
EPOCH 135/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6572704836185179		[learning rate: 0.0055721]
		[batch 20/20] avg loss: 0.7761982536829536		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.7167343686507357 | validation: 0.85490509990984]
	TIME [epoch: 8.84 sec]
EPOCH 136/500:
	Training over batches...
		[batch 10/20] avg loss: 0.72284524832727		[learning rate: 0.005546]
		[batch 20/20] avg loss: 0.6531947762420292		[learning rate: 0.005533]
	Learning Rate: 0.00553298
	LOSS [training: 0.6880200122846496 | validation: 0.5380738883657987]
	TIME [epoch: 8.84 sec]
EPOCH 137/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6394637524854551		[learning rate: 0.00552]
		[batch 20/20] avg loss: 0.6423729246764163		[learning rate: 0.005507]
	Learning Rate: 0.00550704
	LOSS [training: 0.6409183385809355 | validation: 1.0529630737562365]
	TIME [epoch: 8.84 sec]
EPOCH 138/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6731133535671544		[learning rate: 0.0054941]
		[batch 20/20] avg loss: 0.659260974362072		[learning rate: 0.0054812]
	Learning Rate: 0.00548122
	LOSS [training: 0.6661871639646131 | validation: 0.44954516080707335]
	TIME [epoch: 8.86 sec]
EPOCH 139/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8109531710152875		[learning rate: 0.0054684]
		[batch 20/20] avg loss: 0.6206439424152786		[learning rate: 0.0054555]
	Learning Rate: 0.00545553
	LOSS [training: 0.7157985567152831 | validation: 0.7547961228364128]
	TIME [epoch: 8.86 sec]
EPOCH 140/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7076974302843306		[learning rate: 0.0054427]
		[batch 20/20] avg loss: 0.6088426286792293		[learning rate: 0.00543]
	Learning Rate: 0.00542995
	LOSS [training: 0.6582700294817798 | validation: 0.5370215030025801]
	TIME [epoch: 8.84 sec]
EPOCH 141/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7520963373464551		[learning rate: 0.0054172]
		[batch 20/20] avg loss: 0.7254913772646951		[learning rate: 0.0054045]
	Learning Rate: 0.00540449
	LOSS [training: 0.7387938573055751 | validation: 0.5051386535714038]
	TIME [epoch: 8.84 sec]
EPOCH 142/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7649184968647906		[learning rate: 0.0053918]
		[batch 20/20] avg loss: 0.5658433295034471		[learning rate: 0.0053792]
	Learning Rate: 0.00537916
	LOSS [training: 0.6653809131841188 | validation: 0.49890082092519866]
	TIME [epoch: 8.85 sec]
EPOCH 143/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6745592625394152		[learning rate: 0.0053665]
		[batch 20/20] avg loss: 0.4786305622637165		[learning rate: 0.0053539]
	Learning Rate: 0.00535394
	LOSS [training: 0.5765949124015659 | validation: 0.5296061783786377]
	TIME [epoch: 8.85 sec]
EPOCH 144/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5666363080396155		[learning rate: 0.0053414]
		[batch 20/20] avg loss: 0.5500794385382816		[learning rate: 0.0053288]
	Learning Rate: 0.00532884
	LOSS [training: 0.5583578732889485 | validation: 0.6217760119853716]
	TIME [epoch: 8.84 sec]
EPOCH 145/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4875136729717065		[learning rate: 0.0053163]
		[batch 20/20] avg loss: 0.7672407128853445		[learning rate: 0.0053039]
	Learning Rate: 0.00530386
	LOSS [training: 0.6273771929285255 | validation: 0.4478012890517496]
	TIME [epoch: 8.84 sec]
EPOCH 146/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4526251762600035		[learning rate: 0.0052914]
		[batch 20/20] avg loss: 0.7461846089354418		[learning rate: 0.005279]
	Learning Rate: 0.00527899
	LOSS [training: 0.5994048925977228 | validation: 0.6439891357769667]
	TIME [epoch: 8.84 sec]
EPOCH 147/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5486316232885954		[learning rate: 0.0052666]
		[batch 20/20] avg loss: 0.5398379825466728		[learning rate: 0.0052542]
	Learning Rate: 0.00525424
	LOSS [training: 0.544234802917634 | validation: 0.4829967960680629]
	TIME [epoch: 8.86 sec]
EPOCH 148/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4897627193273584		[learning rate: 0.0052419]
		[batch 20/20] avg loss: 0.4593907699717521		[learning rate: 0.0052296]
	Learning Rate: 0.00522961
	LOSS [training: 0.47457674464955524 | validation: 0.3605910198847363]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_148.pth
	Model improved!!!
EPOCH 149/500:
	Training over batches...
		[batch 10/20] avg loss: 0.8422850956289123		[learning rate: 0.0052173]
		[batch 20/20] avg loss: 0.5595925316700586		[learning rate: 0.0052051]
	Learning Rate: 0.00520509
	LOSS [training: 0.7009388136494856 | validation: 0.6044272820188542]
	TIME [epoch: 8.85 sec]
EPOCH 150/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5444138883619905		[learning rate: 0.0051929]
		[batch 20/20] avg loss: 0.5425494388500413		[learning rate: 0.0051807]
	Learning Rate: 0.00518069
	LOSS [training: 0.5434816636060156 | validation: 0.45505727424054143]
	TIME [epoch: 8.85 sec]
EPOCH 151/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5894946776277981		[learning rate: 0.0051685]
		[batch 20/20] avg loss: 0.627917209823523		[learning rate: 0.0051564]
	Learning Rate: 0.0051564
	LOSS [training: 0.6087059437256606 | validation: 0.5038443810373966]
	TIME [epoch: 8.87 sec]
EPOCH 152/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5784059352052499		[learning rate: 0.0051443]
		[batch 20/20] avg loss: 0.47363207478949143		[learning rate: 0.0051322]
	Learning Rate: 0.00513223
	LOSS [training: 0.5260190049973706 | validation: 0.3675387605196406]
	TIME [epoch: 8.85 sec]
EPOCH 153/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4660338167243411		[learning rate: 0.0051202]
		[batch 20/20] avg loss: 0.3916028924900093		[learning rate: 0.0051082]
	Learning Rate: 0.00510817
	LOSS [training: 0.42881835460717516 | validation: 0.40728053997372393]
	TIME [epoch: 8.84 sec]
EPOCH 154/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5868342904924065		[learning rate: 0.0050962]
		[batch 20/20] avg loss: 0.4415173933275941		[learning rate: 0.0050842]
	Learning Rate: 0.00508422
	LOSS [training: 0.5141758419100004 | validation: 0.17685967426441845]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_154.pth
	Model improved!!!
EPOCH 155/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4168492349396328		[learning rate: 0.0050723]
		[batch 20/20] avg loss: 0.4560834258657274		[learning rate: 0.0050604]
	Learning Rate: 0.00506039
	LOSS [training: 0.4364663304026801 | validation: 0.14364521362695884]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_155.pth
	Model improved!!!
EPOCH 156/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4757841269419279		[learning rate: 0.0050485]
		[batch 20/20] avg loss: 0.7074433631672716		[learning rate: 0.0050367]
	Learning Rate: 0.00503666
	LOSS [training: 0.5916137450545998 | validation: 0.4730314573836685]
	TIME [epoch: 8.87 sec]
EPOCH 157/500:
	Training over batches...
		[batch 10/20] avg loss: 0.49626150908860717		[learning rate: 0.0050248]
		[batch 20/20] avg loss: 0.45431078473404324		[learning rate: 0.005013]
	Learning Rate: 0.00501305
	LOSS [training: 0.47528614691132526 | validation: 0.3394944512331587]
	TIME [epoch: 8.84 sec]
EPOCH 158/500:
	Training over batches...
		[batch 10/20] avg loss: 0.47671745435611595		[learning rate: 0.0050013]
		[batch 20/20] avg loss: 0.46745324209568667		[learning rate: 0.0049895]
	Learning Rate: 0.00498955
	LOSS [training: 0.4720853482259013 | validation: 1.9576934380641047]
	TIME [epoch: 8.85 sec]
EPOCH 159/500:
	Training over batches...
		[batch 10/20] avg loss: 0.701415782545472		[learning rate: 0.0049778]
		[batch 20/20] avg loss: 0.5056739033237632		[learning rate: 0.0049662]
	Learning Rate: 0.00496616
	LOSS [training: 0.6035448429346174 | validation: 0.5286100240613643]
	TIME [epoch: 8.85 sec]
EPOCH 160/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5114919436542227		[learning rate: 0.0049545]
		[batch 20/20] avg loss: 0.4327714087523186		[learning rate: 0.0049429]
	Learning Rate: 0.00494287
	LOSS [training: 0.4721316762032706 | validation: 0.32671045137807436]
	TIME [epoch: 8.86 sec]
EPOCH 161/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4892809283264702		[learning rate: 0.0049313]
		[batch 20/20] avg loss: 0.3967347581495219		[learning rate: 0.0049197]
	Learning Rate: 0.0049197
	LOSS [training: 0.443007843237996 | validation: 0.6175250540077372]
	TIME [epoch: 8.86 sec]
EPOCH 162/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6162836229824206		[learning rate: 0.0049082]
		[batch 20/20] avg loss: 0.44242106908364437		[learning rate: 0.0048966]
	Learning Rate: 0.00489664
	LOSS [training: 0.5293523460330325 | validation: 1.2152987686799723]
	TIME [epoch: 8.85 sec]
EPOCH 163/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6706499530832949		[learning rate: 0.0048851]
		[batch 20/20] avg loss: 0.507314684399654		[learning rate: 0.0048737]
	Learning Rate: 0.00487368
	LOSS [training: 0.5889823187414744 | validation: 0.48210885837645234]
	TIME [epoch: 8.85 sec]
EPOCH 164/500:
	Training over batches...
		[batch 10/20] avg loss: 0.491422150219288		[learning rate: 0.0048622]
		[batch 20/20] avg loss: 0.47084438895984493		[learning rate: 0.0048508]
	Learning Rate: 0.00485083
	LOSS [training: 0.4811332695895665 | validation: 0.3601690759333]
	TIME [epoch: 8.84 sec]
EPOCH 165/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40839716996332964		[learning rate: 0.0048394]
		[batch 20/20] avg loss: 0.5507315900081999		[learning rate: 0.0048281]
	Learning Rate: 0.00482809
	LOSS [training: 0.4795643799857647 | validation: 0.6318450970887716]
	TIME [epoch: 8.88 sec]
EPOCH 166/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5149068921408257		[learning rate: 0.0048168]
		[batch 20/20] avg loss: 0.8118239648062678		[learning rate: 0.0048055]
	Learning Rate: 0.00480546
	LOSS [training: 0.6633654284735468 | validation: 0.5285765649460603]
	TIME [epoch: 8.85 sec]
EPOCH 167/500:
	Training over batches...
		[batch 10/20] avg loss: 0.47798253126374357		[learning rate: 0.0047942]
		[batch 20/20] avg loss: 0.43901461325568364		[learning rate: 0.0047829]
	Learning Rate: 0.00478293
	LOSS [training: 0.4584985722597136 | validation: 0.38587756146657215]
	TIME [epoch: 8.85 sec]
EPOCH 168/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32682824465498095		[learning rate: 0.0047717]
		[batch 20/20] avg loss: 0.5108112142865552		[learning rate: 0.0047605]
	Learning Rate: 0.00476051
	LOSS [training: 0.418819729470768 | validation: 1.0249358387933203]
	TIME [epoch: 8.85 sec]
EPOCH 169/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5190443314275747		[learning rate: 0.0047493]
		[batch 20/20] avg loss: 0.42572292024644176		[learning rate: 0.0047382]
	Learning Rate: 0.00473819
	LOSS [training: 0.4723836258370081 | validation: 0.5372470403692218]
	TIME [epoch: 8.88 sec]
EPOCH 170/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5642837958551636		[learning rate: 0.0047271]
		[batch 20/20] avg loss: 0.8033765495510226		[learning rate: 0.004716]
	Learning Rate: 0.00471597
	LOSS [training: 0.6838301727030931 | validation: 0.4433352709669591]
	TIME [epoch: 8.85 sec]
EPOCH 171/500:
	Training over batches...
		[batch 10/20] avg loss: 0.48242460248008656		[learning rate: 0.0047049]
		[batch 20/20] avg loss: 0.4567029877814116		[learning rate: 0.0046939]
	Learning Rate: 0.00469386
	LOSS [training: 0.4695637951307491 | validation: 0.3483509180185237]
	TIME [epoch: 8.85 sec]
EPOCH 172/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5702673712929707		[learning rate: 0.0046828]
		[batch 20/20] avg loss: 0.4583831068100423		[learning rate: 0.0046719]
	Learning Rate: 0.00467186
	LOSS [training: 0.5143252390515065 | validation: 0.23950602142630956]
	TIME [epoch: 8.86 sec]
EPOCH 173/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6540133030144129		[learning rate: 0.0046609]
		[batch 20/20] avg loss: 0.41549293991871605		[learning rate: 0.00465]
	Learning Rate: 0.00464996
	LOSS [training: 0.5347531214665644 | validation: 0.2585341872668765]
	TIME [epoch: 8.86 sec]
EPOCH 174/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3780823249696442		[learning rate: 0.004639]
		[batch 20/20] avg loss: 0.4792350867889416		[learning rate: 0.0046282]
	Learning Rate: 0.00462816
	LOSS [training: 0.42865870587929294 | validation: 0.4758499178202371]
	TIME [epoch: 8.87 sec]
EPOCH 175/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5542902349785072		[learning rate: 0.0046173]
		[batch 20/20] avg loss: 0.3897528717738392		[learning rate: 0.0046065]
	Learning Rate: 0.00460646
	LOSS [training: 0.47202155337617324 | validation: 0.3559571210965486]
	TIME [epoch: 8.86 sec]
EPOCH 176/500:
	Training over batches...
		[batch 10/20] avg loss: 0.48458722023540285		[learning rate: 0.0045956]
		[batch 20/20] avg loss: 0.5039580092368569		[learning rate: 0.0045849]
	Learning Rate: 0.00458486
	LOSS [training: 0.4942726147361299 | validation: 0.40697388757025854]
	TIME [epoch: 8.85 sec]
EPOCH 177/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44928949396145257		[learning rate: 0.0045741]
		[batch 20/20] avg loss: 0.5929397648902496		[learning rate: 0.0045634]
	Learning Rate: 0.00456337
	LOSS [training: 0.5211146294258511 | validation: 0.5245241491091803]
	TIME [epoch: 8.85 sec]
EPOCH 178/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5132862152837764		[learning rate: 0.0045527]
		[batch 20/20] avg loss: 0.4418446543727386		[learning rate: 0.004542]
	Learning Rate: 0.00454198
	LOSS [training: 0.47756543482825753 | validation: 0.3753657461891743]
	TIME [epoch: 8.87 sec]
EPOCH 179/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5426558741360714		[learning rate: 0.0045313]
		[batch 20/20] avg loss: 0.37306879872100623		[learning rate: 0.0045207]
	Learning Rate: 0.00452068
	LOSS [training: 0.4578623364285388 | validation: 0.557840515453225]
	TIME [epoch: 8.85 sec]
EPOCH 180/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4005496960030624		[learning rate: 0.0045101]
		[batch 20/20] avg loss: 0.4821021885216291		[learning rate: 0.0044995]
	Learning Rate: 0.00449949
	LOSS [training: 0.4413259422623458 | validation: 0.36575256266612316]
	TIME [epoch: 8.84 sec]
EPOCH 181/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34122189409748466		[learning rate: 0.0044889]
		[batch 20/20] avg loss: 0.4413496348719665		[learning rate: 0.0044784]
	Learning Rate: 0.0044784
	LOSS [training: 0.3912857644847256 | validation: 0.8480538431206541]
	TIME [epoch: 8.85 sec]
EPOCH 182/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4297402520615569		[learning rate: 0.0044679]
		[batch 20/20] avg loss: 0.49211758244084053		[learning rate: 0.0044574]
	Learning Rate: 0.0044574
	LOSS [training: 0.46092891725119867 | validation: 0.4591712344063078]
	TIME [epoch: 8.88 sec]
EPOCH 183/500:
	Training over batches...
		[batch 10/20] avg loss: 0.7178229038598498		[learning rate: 0.0044469]
		[batch 20/20] avg loss: 0.4552550860666987		[learning rate: 0.0044365]
	Learning Rate: 0.0044365
	LOSS [training: 0.5865389949632742 | validation: 0.4938297627640501]
	TIME [epoch: 8.85 sec]
EPOCH 184/500:
	Training over batches...
		[batch 10/20] avg loss: 0.527782802322388		[learning rate: 0.0044261]
		[batch 20/20] avg loss: 0.4569290523026794		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.49235592731253375 | validation: 0.6016310393158153]
	TIME [epoch: 8.85 sec]
EPOCH 185/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5185115461266074		[learning rate: 0.0044053]
		[batch 20/20] avg loss: 0.38382597876503355		[learning rate: 0.004395]
	Learning Rate: 0.004395
	LOSS [training: 0.45116876244582044 | validation: 0.4622013395665784]
	TIME [epoch: 8.85 sec]
EPOCH 186/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6728312655665186		[learning rate: 0.0043847]
		[batch 20/20] avg loss: 0.4274797873196695		[learning rate: 0.0043744]
	Learning Rate: 0.0043744
	LOSS [training: 0.550155526443094 | validation: 0.31441652546107224]
	TIME [epoch: 8.86 sec]
EPOCH 187/500:
	Training over batches...
		[batch 10/20] avg loss: 0.38167357538666236		[learning rate: 0.0043641]
		[batch 20/20] avg loss: 0.5556666462975377		[learning rate: 0.0043539]
	Learning Rate: 0.00435389
	LOSS [training: 0.4686701108421 | validation: 0.4055909894261215]
	TIME [epoch: 8.86 sec]
EPOCH 188/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6468583136652006		[learning rate: 0.0043437]
		[batch 20/20] avg loss: 0.5377567411394961		[learning rate: 0.0043335]
	Learning Rate: 0.00433348
	LOSS [training: 0.5923075274023484 | validation: 0.5389392715135306]
	TIME [epoch: 8.85 sec]
EPOCH 189/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6259018266514496		[learning rate: 0.0043233]
		[batch 20/20] avg loss: 0.4571184936402255		[learning rate: 0.0043132]
	Learning Rate: 0.00431316
	LOSS [training: 0.5415101601458375 | validation: 1.0584918023994965]
	TIME [epoch: 8.85 sec]
EPOCH 190/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5563570124774595		[learning rate: 0.004303]
		[batch 20/20] avg loss: 0.4499041423251988		[learning rate: 0.0042929]
	Learning Rate: 0.00429294
	LOSS [training: 0.5031305774013293 | validation: 0.33464444627664514]
	TIME [epoch: 8.86 sec]
EPOCH 191/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6069708656637429		[learning rate: 0.0042829]
		[batch 20/20] avg loss: 0.43302448906405006		[learning rate: 0.0042728]
	Learning Rate: 0.00427282
	LOSS [training: 0.5199976773638965 | validation: 0.3580945151626012]
	TIME [epoch: 8.88 sec]
EPOCH 192/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3594248226411544		[learning rate: 0.0042628]
		[batch 20/20] avg loss: 0.6654007635489706		[learning rate: 0.0042528]
	Learning Rate: 0.00425279
	LOSS [training: 0.5124127930950625 | validation: 0.2898113595583265]
	TIME [epoch: 8.86 sec]
EPOCH 193/500:
	Training over batches...
		[batch 10/20] avg loss: 0.49438734641606885		[learning rate: 0.0042428]
		[batch 20/20] avg loss: 0.43361931309525215		[learning rate: 0.0042328]
	Learning Rate: 0.00423285
	LOSS [training: 0.4640033297556604 | validation: 0.18179643616590588]
	TIME [epoch: 8.86 sec]
EPOCH 194/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40992983493695745		[learning rate: 0.0042229]
		[batch 20/20] avg loss: 0.4125330297534158		[learning rate: 0.004213]
	Learning Rate: 0.004213
	LOSS [training: 0.41123143234518655 | validation: 0.31619851123514436]
	TIME [epoch: 8.86 sec]
EPOCH 195/500:
	Training over batches...
		[batch 10/20] avg loss: 0.43056817296931965		[learning rate: 0.0042031]
		[batch 20/20] avg loss: 0.5164509348619694		[learning rate: 0.0041933]
	Learning Rate: 0.00419325
	LOSS [training: 0.47350955391564453 | validation: 0.2571402638636916]
	TIME [epoch: 8.88 sec]
EPOCH 196/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3348261575828432		[learning rate: 0.0041834]
		[batch 20/20] avg loss: 0.44504302553172215		[learning rate: 0.0041736]
	Learning Rate: 0.00417359
	LOSS [training: 0.3899345915572827 | validation: 0.4210841298297344]
	TIME [epoch: 8.86 sec]
EPOCH 197/500:
	Training over batches...
		[batch 10/20] avg loss: 0.49231512815054523		[learning rate: 0.0041638]
		[batch 20/20] avg loss: 0.6047853134143244		[learning rate: 0.004154]
	Learning Rate: 0.00415403
	LOSS [training: 0.5485502207824349 | validation: 0.4247709030597029]
	TIME [epoch: 8.86 sec]
EPOCH 198/500:
	Training over batches...
		[batch 10/20] avg loss: 0.49697840826818496		[learning rate: 0.0041443]
		[batch 20/20] avg loss: 0.4229426667643595		[learning rate: 0.0041346]
	Learning Rate: 0.00413455
	LOSS [training: 0.4599605375162722 | validation: 0.4946039651927917]
	TIME [epoch: 8.85 sec]
EPOCH 199/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4612226251761535		[learning rate: 0.0041249]
		[batch 20/20] avg loss: 0.4211554673817197		[learning rate: 0.0041152]
	Learning Rate: 0.00411517
	LOSS [training: 0.44118904627893657 | validation: 0.5921726405037635]
	TIME [epoch: 8.88 sec]
EPOCH 200/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4509388292245995		[learning rate: 0.0041055]
		[batch 20/20] avg loss: 0.41733148322988906		[learning rate: 0.0040959]
	Learning Rate: 0.00409588
	LOSS [training: 0.4341351562272443 | validation: 0.4746540508530922]
	TIME [epoch: 8.86 sec]
EPOCH 201/500:
	Training over batches...
		[batch 10/20] avg loss: 0.38552834797873664		[learning rate: 0.0040863]
		[batch 20/20] avg loss: 0.604816127705546		[learning rate: 0.0040767]
	Learning Rate: 0.00407667
	LOSS [training: 0.49517223784214137 | validation: 0.4156308060271027]
	TIME [epoch: 8.85 sec]
EPOCH 202/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5618521000200692		[learning rate: 0.0040671]
		[batch 20/20] avg loss: 0.42131588820798777		[learning rate: 0.0040576]
	Learning Rate: 0.00405756
	LOSS [training: 0.4915839941140285 | validation: 0.5524877816363876]
	TIME [epoch: 8.85 sec]
EPOCH 203/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40162407747528983		[learning rate: 0.004048]
		[batch 20/20] avg loss: 0.3268701480110418		[learning rate: 0.0040385]
	Learning Rate: 0.00403854
	LOSS [training: 0.36424711274316585 | validation: 0.34878311170507026]
	TIME [epoch: 8.86 sec]
EPOCH 204/500:
	Training over batches...
		[batch 10/20] avg loss: 0.47244216040966674		[learning rate: 0.0040291]
		[batch 20/20] avg loss: 0.4210975091317223		[learning rate: 0.0040196]
	Learning Rate: 0.00401961
	LOSS [training: 0.44676983477069454 | validation: 0.41174545086941117]
	TIME [epoch: 8.87 sec]
EPOCH 205/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35403630957448684		[learning rate: 0.0040102]
		[batch 20/20] avg loss: 0.467941922564264		[learning rate: 0.0040008]
	Learning Rate: 0.00400076
	LOSS [training: 0.41098911606937544 | validation: 0.2824390948075259]
	TIME [epoch: 8.85 sec]
EPOCH 206/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2711768363846193		[learning rate: 0.0039914]
		[batch 20/20] avg loss: 0.42560733142971907		[learning rate: 0.003982]
	Learning Rate: 0.00398201
	LOSS [training: 0.3483920839071691 | validation: 0.23611096946274765]
	TIME [epoch: 8.86 sec]
EPOCH 207/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4090635067194922		[learning rate: 0.0039727]
		[batch 20/20] avg loss: 0.3505437462191281		[learning rate: 0.0039633]
	Learning Rate: 0.00396334
	LOSS [training: 0.3798036264693102 | validation: 0.230130954670103]
	TIME [epoch: 8.85 sec]
EPOCH 208/500:
	Training over batches...
		[batch 10/20] avg loss: 0.6085240611301075		[learning rate: 0.003954]
		[batch 20/20] avg loss: 0.29731456050607635		[learning rate: 0.0039448]
	Learning Rate: 0.00394476
	LOSS [training: 0.45291931081809195 | validation: 0.5600347351268998]
	TIME [epoch: 8.88 sec]
EPOCH 209/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5005463779231407		[learning rate: 0.0039355]
		[batch 20/20] avg loss: 0.5056938756978363		[learning rate: 0.0039263]
	Learning Rate: 0.00392627
	LOSS [training: 0.5031201268104885 | validation: 0.9510820227913748]
	TIME [epoch: 8.86 sec]
EPOCH 210/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5741703530608376		[learning rate: 0.0039171]
		[batch 20/20] avg loss: 0.4305483070432102		[learning rate: 0.0039079]
	Learning Rate: 0.00390786
	LOSS [training: 0.5023593300520239 | validation: 0.4238722309362497]
	TIME [epoch: 8.85 sec]
EPOCH 211/500:
	Training over batches...
		[batch 10/20] avg loss: 0.40589379829585076		[learning rate: 0.0038987]
		[batch 20/20] avg loss: 0.3702484663721513		[learning rate: 0.0038895]
	Learning Rate: 0.00388954
	LOSS [training: 0.38807113233400103 | validation: 0.27472817879318917]
	TIME [epoch: 8.87 sec]
EPOCH 212/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44978503329847347		[learning rate: 0.0038804]
		[batch 20/20] avg loss: 0.3353770283337906		[learning rate: 0.0038713]
	Learning Rate: 0.0038713
	LOSS [training: 0.39258103081613205 | validation: 0.36530343672817817]
	TIME [epoch: 8.87 sec]
EPOCH 213/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4546205019019289		[learning rate: 0.0038622]
		[batch 20/20] avg loss: 0.3975599780447802		[learning rate: 0.0038532]
	Learning Rate: 0.00385315
	LOSS [training: 0.42609023997335466 | validation: 0.46326532643237206]
	TIME [epoch: 8.85 sec]
EPOCH 214/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35583233888868493		[learning rate: 0.0038441]
		[batch 20/20] avg loss: 0.43891001157555154		[learning rate: 0.0038351]
	Learning Rate: 0.00383509
	LOSS [training: 0.39737117523211823 | validation: 0.6779275496451431]
	TIME [epoch: 8.85 sec]
EPOCH 215/500:
	Training over batches...
		[batch 10/20] avg loss: 0.43610481525398653		[learning rate: 0.0038261]
		[batch 20/20] avg loss: 0.34448127752101504		[learning rate: 0.0038171]
	Learning Rate: 0.00381711
	LOSS [training: 0.3902930463875008 | validation: 0.41775600638966953]
	TIME [epoch: 8.85 sec]
EPOCH 216/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4044175614412181		[learning rate: 0.0038082]
		[batch 20/20] avg loss: 0.4294808830155903		[learning rate: 0.0037992]
	Learning Rate: 0.00379921
	LOSS [training: 0.41694922222840425 | validation: 0.23474717738477524]
	TIME [epoch: 8.86 sec]
EPOCH 217/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31753844430195755		[learning rate: 0.0037903]
		[batch 20/20] avg loss: 0.31117822952134777		[learning rate: 0.0037814]
	Learning Rate: 0.0037814
	LOSS [training: 0.3143583369116527 | validation: 0.3093500691153787]
	TIME [epoch: 8.87 sec]
EPOCH 218/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36741879694488294		[learning rate: 0.0037725]
		[batch 20/20] avg loss: 0.37422468233394907		[learning rate: 0.0037637]
	Learning Rate: 0.00376368
	LOSS [training: 0.370821739639416 | validation: 0.38773699677146356]
	TIME [epoch: 8.85 sec]
EPOCH 219/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3886125760991409		[learning rate: 0.0037548]
		[batch 20/20] avg loss: 0.3635967339465968		[learning rate: 0.003746]
	Learning Rate: 0.00374603
	LOSS [training: 0.37610465502286894 | validation: 0.23727112712999945]
	TIME [epoch: 8.85 sec]
EPOCH 220/500:
	Training over batches...
		[batch 10/20] avg loss: 0.39860009862875717		[learning rate: 0.0037372]
		[batch 20/20] avg loss: 0.4225174931781406		[learning rate: 0.0037285]
	Learning Rate: 0.00372847
	LOSS [training: 0.4105587959034489 | validation: 0.38769453187708736]
	TIME [epoch: 8.85 sec]
EPOCH 221/500:
	Training over batches...
		[batch 10/20] avg loss: 0.5926890883813587		[learning rate: 0.0037197]
		[batch 20/20] avg loss: 0.42357887121670706		[learning rate: 0.003711]
	Learning Rate: 0.00371099
	LOSS [training: 0.5081339797990329 | validation: 0.2820737163788967]
	TIME [epoch: 8.88 sec]
EPOCH 222/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2986675055439437		[learning rate: 0.0037023]
		[batch 20/20] avg loss: 0.48652456058542165		[learning rate: 0.0036936]
	Learning Rate: 0.00369359
	LOSS [training: 0.3925960330646826 | validation: 0.4591333189237231]
	TIME [epoch: 8.85 sec]
EPOCH 223/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30566788337605366		[learning rate: 0.0036849]
		[batch 20/20] avg loss: 0.47058578208162627		[learning rate: 0.0036763]
	Learning Rate: 0.00367628
	LOSS [training: 0.38812683272883997 | validation: 0.29966926917390424]
	TIME [epoch: 8.85 sec]
EPOCH 224/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44861478404115684		[learning rate: 0.0036676]
		[batch 20/20] avg loss: 0.34727820628893774		[learning rate: 0.003659]
	Learning Rate: 0.00365904
	LOSS [training: 0.39794649516504726 | validation: 0.794317132617399]
	TIME [epoch: 8.86 sec]
EPOCH 225/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33816808357401296		[learning rate: 0.0036505]
		[batch 20/20] avg loss: 0.3874046007511789		[learning rate: 0.0036419]
	Learning Rate: 0.00364189
	LOSS [training: 0.3627863421625959 | validation: 0.1995591205526597]
	TIME [epoch: 8.87 sec]
EPOCH 226/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26858991046594644		[learning rate: 0.0036333]
		[batch 20/20] avg loss: 0.33205026227352424		[learning rate: 0.0036248]
	Learning Rate: 0.00362481
	LOSS [training: 0.3003200863697353 | validation: 0.5449386341371677]
	TIME [epoch: 8.86 sec]
EPOCH 227/500:
	Training over batches...
		[batch 10/20] avg loss: 0.43812670886871014		[learning rate: 0.0036163]
		[batch 20/20] avg loss: 0.4548189115067511		[learning rate: 0.0036078]
	Learning Rate: 0.00360782
	LOSS [training: 0.44647281018773066 | validation: 0.39155626945182576]
	TIME [epoch: 8.85 sec]
EPOCH 228/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29559477139999046		[learning rate: 0.0035994]
		[batch 20/20] avg loss: 0.2817304999148392		[learning rate: 0.0035909]
	Learning Rate: 0.00359091
	LOSS [training: 0.28866263565741485 | validation: 0.4490729659453223]
	TIME [epoch: 8.85 sec]
EPOCH 229/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32255341701422224		[learning rate: 0.0035825]
		[batch 20/20] avg loss: 0.32123162102593344		[learning rate: 0.0035741]
	Learning Rate: 0.00357407
	LOSS [training: 0.3218925190200778 | validation: 0.5926102123889462]
	TIME [epoch: 8.86 sec]
EPOCH 230/500:
	Training over batches...
		[batch 10/20] avg loss: 0.44848737490052953		[learning rate: 0.0035657]
		[batch 20/20] avg loss: 0.295614664472574		[learning rate: 0.0035573]
	Learning Rate: 0.00355732
	LOSS [training: 0.3720510196865518 | validation: 0.1985580632808565]
	TIME [epoch: 8.87 sec]
EPOCH 231/500:
	Training over batches...
		[batch 10/20] avg loss: 0.41460203809802093		[learning rate: 0.003549]
		[batch 20/20] avg loss: 0.36885575172268226		[learning rate: 0.0035406]
	Learning Rate: 0.00354064
	LOSS [training: 0.39172889491035157 | validation: 0.3791782873596752]
	TIME [epoch: 8.84 sec]
EPOCH 232/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33354020808855106		[learning rate: 0.0035323]
		[batch 20/20] avg loss: 0.32292771142504895		[learning rate: 0.003524]
	Learning Rate: 0.00352404
	LOSS [training: 0.3282339597568 | validation: 0.49367405021109]
	TIME [epoch: 8.85 sec]
EPOCH 233/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33803946947697544		[learning rate: 0.0035158]
		[batch 20/20] avg loss: 0.3381445533732049		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.33809201142509016 | validation: 0.3452846109108046]
	TIME [epoch: 8.86 sec]
EPOCH 234/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4902029109645626		[learning rate: 0.0034993]
		[batch 20/20] avg loss: 0.2598383107924357		[learning rate: 0.0034911]
	Learning Rate: 0.00349107
	LOSS [training: 0.3750206108784992 | validation: 0.27765841345522485]
	TIME [epoch: 8.87 sec]
EPOCH 235/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36812809573606997		[learning rate: 0.0034829]
		[batch 20/20] avg loss: 0.3580420154645654		[learning rate: 0.0034747]
	Learning Rate: 0.00347471
	LOSS [training: 0.3630850556003177 | validation: 0.3390066943933293]
	TIME [epoch: 8.85 sec]
EPOCH 236/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3109790716575179		[learning rate: 0.0034666]
		[batch 20/20] avg loss: 0.4057463427069017		[learning rate: 0.0034584]
	Learning Rate: 0.00345842
	LOSS [training: 0.3583627071822098 | validation: 0.2664614414393368]
	TIME [epoch: 8.86 sec]
EPOCH 237/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3635368012952457		[learning rate: 0.0034503]
		[batch 20/20] avg loss: 0.30752391502135096		[learning rate: 0.0034422]
	Learning Rate: 0.00344221
	LOSS [training: 0.3355303581582983 | validation: 0.2906084571574691]
	TIME [epoch: 8.86 sec]
EPOCH 238/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34336663966877407		[learning rate: 0.0034341]
		[batch 20/20] avg loss: 0.3629786460445664		[learning rate: 0.0034261]
	Learning Rate: 0.00342607
	LOSS [training: 0.35317264285667027 | validation: 0.24682853845678382]
	TIME [epoch: 8.87 sec]
EPOCH 239/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3769087249957096		[learning rate: 0.003418]
		[batch 20/20] avg loss: 0.4359955948636636		[learning rate: 0.00341]
	Learning Rate: 0.00341001
	LOSS [training: 0.40645215992968664 | validation: 0.39302023623892407]
	TIME [epoch: 8.86 sec]
EPOCH 240/500:
	Training over batches...
		[batch 10/20] avg loss: 0.4483134052586489		[learning rate: 0.003402]
		[batch 20/20] avg loss: 0.2737316707227788		[learning rate: 0.003394]
	Learning Rate: 0.00339402
	LOSS [training: 0.36102253799071377 | validation: 0.2419907986160279]
	TIME [epoch: 8.85 sec]
EPOCH 241/500:
	Training over batches...
		[batch 10/20] avg loss: 0.38145192169474196		[learning rate: 0.0033861]
		[batch 20/20] avg loss: 0.4015544300115038		[learning rate: 0.0033781]
	Learning Rate: 0.00337811
	LOSS [training: 0.3915031758531229 | validation: 0.4232050938340006]
	TIME [epoch: 8.85 sec]
EPOCH 242/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3787261899346128		[learning rate: 0.0033702]
		[batch 20/20] avg loss: 0.3386469236794351		[learning rate: 0.0033623]
	Learning Rate: 0.00336227
	LOSS [training: 0.358686556807024 | validation: 0.21949497360638387]
	TIME [epoch: 8.88 sec]
EPOCH 243/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30469506104221233		[learning rate: 0.0033544]
		[batch 20/20] avg loss: 0.23692745883244387		[learning rate: 0.0033465]
	Learning Rate: 0.00334651
	LOSS [training: 0.2708112599373282 | validation: 0.5131209086812113]
	TIME [epoch: 8.86 sec]
EPOCH 244/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30802575467544463		[learning rate: 0.0033387]
		[batch 20/20] avg loss: 0.27362226683428525		[learning rate: 0.0033308]
	Learning Rate: 0.00333082
	LOSS [training: 0.29082401075486497 | validation: 0.2881186041911937]
	TIME [epoch: 8.85 sec]
EPOCH 245/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2791000563681289		[learning rate: 0.003323]
		[batch 20/20] avg loss: 0.38930714099657704		[learning rate: 0.0033152]
	Learning Rate: 0.0033152
	LOSS [training: 0.33420359868235294 | validation: 0.15298461622003381]
	TIME [epoch: 8.85 sec]
EPOCH 246/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28107324943171086		[learning rate: 0.0033074]
		[batch 20/20] avg loss: 0.32705623445972665		[learning rate: 0.0032997]
	Learning Rate: 0.00329966
	LOSS [training: 0.30406474194571875 | validation: 0.16020518766468866]
	TIME [epoch: 8.87 sec]
EPOCH 247/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3289330135167216		[learning rate: 0.0032919]
		[batch 20/20] avg loss: 0.3288445569237649		[learning rate: 0.0032842]
	Learning Rate: 0.00328419
	LOSS [training: 0.32888878522024323 | validation: 0.27340197110495734]
	TIME [epoch: 8.87 sec]
EPOCH 248/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33315945881229225		[learning rate: 0.0032765]
		[batch 20/20] avg loss: 0.30986938954248555		[learning rate: 0.0032688]
	Learning Rate: 0.0032688
	LOSS [training: 0.32151442417738896 | validation: 0.27971596199683646]
	TIME [epoch: 8.85 sec]
EPOCH 249/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32156360274308315		[learning rate: 0.0032611]
		[batch 20/20] avg loss: 0.2851610595659712		[learning rate: 0.0032535]
	Learning Rate: 0.00325347
	LOSS [training: 0.3033623311545272 | validation: 0.32377461422038967]
	TIME [epoch: 8.85 sec]
EPOCH 250/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31262013744887546		[learning rate: 0.0032458]
		[batch 20/20] avg loss: 0.23393144623196332		[learning rate: 0.0032382]
	Learning Rate: 0.00323822
	LOSS [training: 0.2732757918404193 | validation: 0.17957299079901773]
	TIME [epoch: 8.85 sec]
EPOCH 251/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30808857816426355		[learning rate: 0.0032306]
		[batch 20/20] avg loss: 0.2938516299406208		[learning rate: 0.003223]
	Learning Rate: 0.00322304
	LOSS [training: 0.3009701040524422 | validation: 0.3999814434147645]
	TIME [epoch: 8.88 sec]
EPOCH 252/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3657233001566359		[learning rate: 0.0032155]
		[batch 20/20] avg loss: 0.3783325004816024		[learning rate: 0.0032079]
	Learning Rate: 0.00320793
	LOSS [training: 0.37202790031911914 | validation: 0.23242251254668597]
	TIME [epoch: 8.85 sec]
EPOCH 253/500:
	Training over batches...
		[batch 10/20] avg loss: 0.376218610309962		[learning rate: 0.0032004]
		[batch 20/20] avg loss: 0.24066399593223844		[learning rate: 0.0031929]
	Learning Rate: 0.00319289
	LOSS [training: 0.30844130312110024 | validation: 0.3344386674385888]
	TIME [epoch: 8.85 sec]
EPOCH 254/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27305793658737265		[learning rate: 0.0031854]
		[batch 20/20] avg loss: 0.31168852734822655		[learning rate: 0.0031779]
	Learning Rate: 0.00317792
	LOSS [training: 0.2923732319677996 | validation: 0.3903345672279931]
	TIME [epoch: 8.86 sec]
EPOCH 255/500:
	Training over batches...
		[batch 10/20] avg loss: 0.35446981676104555		[learning rate: 0.0031705]
		[batch 20/20] avg loss: 0.2649501962549222		[learning rate: 0.003163]
	Learning Rate: 0.00316302
	LOSS [training: 0.30971000650798397 | validation: 0.5338351562718312]
	TIME [epoch: 8.87 sec]
EPOCH 256/500:
	Training over batches...
		[batch 10/20] avg loss: 0.47943489130123174		[learning rate: 0.0031556]
		[batch 20/20] avg loss: 0.3108828013088187		[learning rate: 0.0031482]
	Learning Rate: 0.00314819
	LOSS [training: 0.3951588463050253 | validation: 0.2632319225416263]
	TIME [epoch: 8.85 sec]
EPOCH 257/500:
	Training over batches...
		[batch 10/20] avg loss: 0.31436885860223174		[learning rate: 0.0031408]
		[batch 20/20] avg loss: 0.30596189885164204		[learning rate: 0.0031334]
	Learning Rate: 0.00313343
	LOSS [training: 0.3101653787269369 | validation: 0.4441889643237277]
	TIME [epoch: 8.86 sec]
EPOCH 258/500:
	Training over batches...
		[batch 10/20] avg loss: 0.38295263375526306		[learning rate: 0.0031261]
		[batch 20/20] avg loss: 0.29582913222633855		[learning rate: 0.0031187]
	Learning Rate: 0.00311874
	LOSS [training: 0.3393908829908009 | validation: 0.4163140225237007]
	TIME [epoch: 8.85 sec]
EPOCH 259/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3920501432781941		[learning rate: 0.0031114]
		[batch 20/20] avg loss: 0.2876325477817566		[learning rate: 0.0031041]
	Learning Rate: 0.00310412
	LOSS [training: 0.3398413455299754 | validation: 0.23411453907723517]
	TIME [epoch: 8.87 sec]
EPOCH 260/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3868243093141705		[learning rate: 0.0030968]
		[batch 20/20] avg loss: 0.27036068457964807		[learning rate: 0.0030896]
	Learning Rate: 0.00308957
	LOSS [training: 0.3285924969469093 | validation: 0.2575467182892388]
	TIME [epoch: 8.86 sec]
EPOCH 261/500:
	Training over batches...
		[batch 10/20] avg loss: 0.36350560857141534		[learning rate: 0.0030823]
		[batch 20/20] avg loss: 0.31534334676249787		[learning rate: 0.0030751]
	Learning Rate: 0.00307509
	LOSS [training: 0.3394244776669565 | validation: 0.25321797475020674]
	TIME [epoch: 8.85 sec]
EPOCH 262/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3550138566908401		[learning rate: 0.0030679]
		[batch 20/20] avg loss: 0.22704874739672984		[learning rate: 0.0030607]
	Learning Rate: 0.00306067
	LOSS [training: 0.291031302043785 | validation: 0.2723892387228842]
	TIME [epoch: 8.85 sec]
EPOCH 263/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3530373551183072		[learning rate: 0.0030535]
		[batch 20/20] avg loss: 0.355246052851127		[learning rate: 0.0030463]
	Learning Rate: 0.00304632
	LOSS [training: 0.35414170398471706 | validation: 0.4177595779801774]
	TIME [epoch: 8.85 sec]
EPOCH 264/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27047986442777383		[learning rate: 0.0030392]
		[batch 20/20] avg loss: 0.3685042211695791		[learning rate: 0.003032]
	Learning Rate: 0.00303204
	LOSS [training: 0.3194920427986765 | validation: 0.19487490116618392]
	TIME [epoch: 8.88 sec]
EPOCH 265/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2969932049739187		[learning rate: 0.0030249]
		[batch 20/20] avg loss: 0.25840229764568495		[learning rate: 0.0030178]
	Learning Rate: 0.00301782
	LOSS [training: 0.27769775130980184 | validation: 0.27429370886817067]
	TIME [epoch: 8.85 sec]
EPOCH 266/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3994976072444297		[learning rate: 0.0030107]
		[batch 20/20] avg loss: 0.31021694642472536		[learning rate: 0.0030037]
	Learning Rate: 0.00300368
	LOSS [training: 0.3548572768345776 | validation: 0.16297585865923597]
	TIME [epoch: 8.85 sec]
EPOCH 267/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22877945614234937		[learning rate: 0.0029966]
		[batch 20/20] avg loss: 0.23398513373111215		[learning rate: 0.0029896]
	Learning Rate: 0.00298959
	LOSS [training: 0.2313822949367308 | validation: 0.26451395896059177]
	TIME [epoch: 8.86 sec]
EPOCH 268/500:
	Training over batches...
		[batch 10/20] avg loss: 0.390171412758092		[learning rate: 0.0029826]
		[batch 20/20] avg loss: 0.29238033440147004		[learning rate: 0.0029756]
	Learning Rate: 0.00297558
	LOSS [training: 0.34127587357978106 | validation: 0.3078976348488774]
	TIME [epoch: 8.87 sec]
EPOCH 269/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2544083101557751		[learning rate: 0.0029686]
		[batch 20/20] avg loss: 0.2821629971717665		[learning rate: 0.0029616]
	Learning Rate: 0.00296163
	LOSS [training: 0.2682856536637708 | validation: 0.20230023091250388]
	TIME [epoch: 8.86 sec]
EPOCH 270/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2750887248627352		[learning rate: 0.0029547]
		[batch 20/20] avg loss: 0.32610969501463716		[learning rate: 0.0029477]
	Learning Rate: 0.00294774
	LOSS [training: 0.30059920993868616 | validation: 0.15429691507912022]
	TIME [epoch: 8.85 sec]
EPOCH 271/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28297460962548915		[learning rate: 0.0029408]
		[batch 20/20] avg loss: 0.38920108941170195		[learning rate: 0.0029339]
	Learning Rate: 0.00293393
	LOSS [training: 0.3360878495185955 | validation: 0.4432975004040937]
	TIME [epoch: 8.85 sec]
EPOCH 272/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3544978641791082		[learning rate: 0.002927]
		[batch 20/20] avg loss: 0.31502190477551145		[learning rate: 0.0029202]
	Learning Rate: 0.00292017
	LOSS [training: 0.33475988447730975 | validation: 0.3560674158260898]
	TIME [epoch: 8.88 sec]
EPOCH 273/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2955531025676158		[learning rate: 0.0029133]
		[batch 20/20] avg loss: 0.24500261000266818		[learning rate: 0.0029065]
	Learning Rate: 0.00290648
	LOSS [training: 0.27027785628514195 | validation: 0.39981683913943133]
	TIME [epoch: 8.86 sec]
EPOCH 274/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30717500228542005		[learning rate: 0.0028997]
		[batch 20/20] avg loss: 0.23640293603358392		[learning rate: 0.0028929]
	Learning Rate: 0.00289285
	LOSS [training: 0.271788969159502 | validation: 0.22440607054125897]
	TIME [epoch: 8.85 sec]
EPOCH 275/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25429855457336653		[learning rate: 0.0028861]
		[batch 20/20] avg loss: 0.3570099868383317		[learning rate: 0.0028793]
	Learning Rate: 0.00287929
	LOSS [training: 0.30565427070584905 | validation: 0.3050514259009168]
	TIME [epoch: 8.86 sec]
EPOCH 276/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2463619114521017		[learning rate: 0.0028725]
		[batch 20/20] avg loss: 0.33089563718440723		[learning rate: 0.0028658]
	Learning Rate: 0.00286579
	LOSS [training: 0.2886287743182545 | validation: 0.3859744546233339]
	TIME [epoch: 8.86 sec]
EPOCH 277/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28098658642120655		[learning rate: 0.0028591]
		[batch 20/20] avg loss: 0.2134890622726852		[learning rate: 0.0028524]
	Learning Rate: 0.00285236
	LOSS [training: 0.24723782434694588 | validation: 0.19682614344794602]
	TIME [epoch: 8.87 sec]
EPOCH 278/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28022463033090017		[learning rate: 0.0028457]
		[batch 20/20] avg loss: 0.35967591166841206		[learning rate: 0.002839]
	Learning Rate: 0.00283899
	LOSS [training: 0.3199502709996561 | validation: 0.33529301738691]
	TIME [epoch: 8.85 sec]
EPOCH 279/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3639537668516949		[learning rate: 0.0028323]
		[batch 20/20] avg loss: 0.2770385255654186		[learning rate: 0.0028257]
	Learning Rate: 0.00282568
	LOSS [training: 0.32049614620855665 | validation: 0.225622115274427]
	TIME [epoch: 8.85 sec]
EPOCH 280/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24878300140539372		[learning rate: 0.002819]
		[batch 20/20] avg loss: 0.319048888132745		[learning rate: 0.0028124]
	Learning Rate: 0.00281243
	LOSS [training: 0.2839159447690694 | validation: 0.3395351682286995]
	TIME [epoch: 8.85 sec]
EPOCH 281/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3304815070856001		[learning rate: 0.0028058]
		[batch 20/20] avg loss: 0.23291410865300738		[learning rate: 0.0027992]
	Learning Rate: 0.00279924
	LOSS [training: 0.28169780786930365 | validation: 0.39773539586667034]
	TIME [epoch: 8.88 sec]
EPOCH 282/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28842915482901293		[learning rate: 0.0027927]
		[batch 20/20] avg loss: 0.2635372533240183		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.2759832040765156 | validation: 0.1773740599809799]
	TIME [epoch: 8.85 sec]
EPOCH 283/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30699588599726296		[learning rate: 0.0027796]
		[batch 20/20] avg loss: 0.26532870571780376		[learning rate: 0.0027731]
	Learning Rate: 0.00277306
	LOSS [training: 0.28616229585753344 | validation: 0.2818418667666611]
	TIME [epoch: 8.85 sec]
EPOCH 284/500:
	Training over batches...
		[batch 10/20] avg loss: 0.30255829605432455		[learning rate: 0.0027666]
		[batch 20/20] avg loss: 0.25142992006393033		[learning rate: 0.0027601]
	Learning Rate: 0.00276006
	LOSS [training: 0.2769941080591275 | validation: 0.21429935879698386]
	TIME [epoch: 8.85 sec]
EPOCH 285/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29460803113723505		[learning rate: 0.0027536]
		[batch 20/20] avg loss: 0.2648720297013029		[learning rate: 0.0027471]
	Learning Rate: 0.00274712
	LOSS [training: 0.279740030419269 | validation: 0.3124634157279294]
	TIME [epoch: 8.87 sec]
EPOCH 286/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2992812992814425		[learning rate: 0.0027407]
		[batch 20/20] avg loss: 0.3294216782422815		[learning rate: 0.0027342]
	Learning Rate: 0.00273424
	LOSS [training: 0.31435148876186186 | validation: 0.26753473659089116]
	TIME [epoch: 8.85 sec]
EPOCH 287/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3043107362773424		[learning rate: 0.0027278]
		[batch 20/20] avg loss: 0.31795786047914887		[learning rate: 0.0027214]
	Learning Rate: 0.00272142
	LOSS [training: 0.31113429837824563 | validation: 0.36525318563913295]
	TIME [epoch: 8.85 sec]
EPOCH 288/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3525648274012788		[learning rate: 0.002715]
		[batch 20/20] avg loss: 0.39190841948427396		[learning rate: 0.0027087]
	Learning Rate: 0.00270866
	LOSS [training: 0.3722366234427764 | validation: 0.23259791415625797]
	TIME [epoch: 8.84 sec]
EPOCH 289/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23652048629508324		[learning rate: 0.0027023]
		[batch 20/20] avg loss: 0.31748420990373566		[learning rate: 0.002696]
	Learning Rate: 0.00269597
	LOSS [training: 0.27700234809940943 | validation: 0.3026772038134074]
	TIME [epoch: 8.86 sec]
EPOCH 290/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3271196024377064		[learning rate: 0.0026896]
		[batch 20/20] avg loss: 0.2910761948308397		[learning rate: 0.0026833]
	Learning Rate: 0.00268333
	LOSS [training: 0.30909789863427306 | validation: 0.248494277126953]
	TIME [epoch: 8.87 sec]
EPOCH 291/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3348244357389669		[learning rate: 0.002677]
		[batch 20/20] avg loss: 0.34673052303517576		[learning rate: 0.0026707]
	Learning Rate: 0.00267075
	LOSS [training: 0.3407774793870713 | validation: 0.3957768403609532]
	TIME [epoch: 8.85 sec]
EPOCH 292/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3470822664535157		[learning rate: 0.0026645]
		[batch 20/20] avg loss: 0.2269922093002009		[learning rate: 0.0026582]
	Learning Rate: 0.00265823
	LOSS [training: 0.2870372378768583 | validation: 0.3313075004321958]
	TIME [epoch: 8.86 sec]
EPOCH 293/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2996131190565984		[learning rate: 0.002652]
		[batch 20/20] avg loss: 0.240956393826757		[learning rate: 0.0026458]
	Learning Rate: 0.00264576
	LOSS [training: 0.27028475644167765 | validation: 0.19183883922398362]
	TIME [epoch: 8.85 sec]
EPOCH 294/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2762883522482661		[learning rate: 0.0026396]
		[batch 20/20] avg loss: 0.30513375956271716		[learning rate: 0.0026334]
	Learning Rate: 0.00263336
	LOSS [training: 0.29071105590549157 | validation: 0.22576429926380592]
	TIME [epoch: 8.88 sec]
EPOCH 295/500:
	Training over batches...
		[batch 10/20] avg loss: 0.327911350536189		[learning rate: 0.0026272]
		[batch 20/20] avg loss: 0.3219691856938376		[learning rate: 0.002621]
	Learning Rate: 0.00262101
	LOSS [training: 0.3249402681150133 | validation: 0.24542388305604584]
	TIME [epoch: 8.86 sec]
EPOCH 296/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2695195808756562		[learning rate: 0.0026149]
		[batch 20/20] avg loss: 0.3174951769419		[learning rate: 0.0026087]
	Learning Rate: 0.00260873
	LOSS [training: 0.2935073789087781 | validation: 0.1997135668984229]
	TIME [epoch: 8.86 sec]
EPOCH 297/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2830842084016708		[learning rate: 0.0026026]
		[batch 20/20] avg loss: 0.25321074111279257		[learning rate: 0.0025965]
	Learning Rate: 0.0025965
	LOSS [training: 0.2681474747572317 | validation: 0.3116223254306827]
	TIME [epoch: 8.85 sec]
EPOCH 298/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26655471486532434		[learning rate: 0.0025904]
		[batch 20/20] avg loss: 0.26966989981526274		[learning rate: 0.0025843]
	Learning Rate: 0.00258432
	LOSS [training: 0.26811230734029357 | validation: 0.16620891834421544]
	TIME [epoch: 8.88 sec]
EPOCH 299/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20616677602642092		[learning rate: 0.0025783]
		[batch 20/20] avg loss: 0.26899875918076355		[learning rate: 0.0025722]
	Learning Rate: 0.00257221
	LOSS [training: 0.2375827676035922 | validation: 0.23468074976573855]
	TIME [epoch: 8.86 sec]
EPOCH 300/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2654172509674283		[learning rate: 0.0025662]
		[batch 20/20] avg loss: 0.24630547656244067		[learning rate: 0.0025601]
	Learning Rate: 0.00256015
	LOSS [training: 0.2558613637649345 | validation: 0.5011958298346189]
	TIME [epoch: 8.85 sec]
EPOCH 301/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33693379238239685		[learning rate: 0.0025541]
		[batch 20/20] avg loss: 0.25081621457320635		[learning rate: 0.0025481]
	Learning Rate: 0.00254815
	LOSS [training: 0.2938750034778016 | validation: 0.3345063003483479]
	TIME [epoch: 8.86 sec]
EPOCH 302/500:
	Training over batches...
		[batch 10/20] avg loss: 0.34740238755774966		[learning rate: 0.0025422]
		[batch 20/20] avg loss: 0.27009619691487335		[learning rate: 0.0025362]
	Learning Rate: 0.0025362
	LOSS [training: 0.3087492922363116 | validation: 0.20696215132515716]
	TIME [epoch: 8.86 sec]
EPOCH 303/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2968044015581524		[learning rate: 0.0025302]
		[batch 20/20] avg loss: 0.2956585539093427		[learning rate: 0.0025243]
	Learning Rate: 0.00252431
	LOSS [training: 0.29623147773374753 | validation: 0.3484903643689998]
	TIME [epoch: 8.87 sec]
EPOCH 304/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2391452198802874		[learning rate: 0.0025184]
		[batch 20/20] avg loss: 0.42965308408087344		[learning rate: 0.0025125]
	Learning Rate: 0.00251248
	LOSS [training: 0.3343991519805804 | validation: 0.22827382366681842]
	TIME [epoch: 8.85 sec]
EPOCH 305/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2661227235508514		[learning rate: 0.0025066]
		[batch 20/20] avg loss: 0.2835522710709386		[learning rate: 0.0025007]
	Learning Rate: 0.0025007
	LOSS [training: 0.274837497310895 | validation: 0.3261407827143473]
	TIME [epoch: 8.85 sec]
EPOCH 306/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24996073941102143		[learning rate: 0.0024948]
		[batch 20/20] avg loss: 0.2974222539095011		[learning rate: 0.002489]
	Learning Rate: 0.00248897
	LOSS [training: 0.2736914966602613 | validation: 0.2254963236105723]
	TIME [epoch: 8.87 sec]
EPOCH 307/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3614280926920247		[learning rate: 0.0024831]
		[batch 20/20] avg loss: 0.24215165635437322		[learning rate: 0.0024773]
	Learning Rate: 0.00247731
	LOSS [training: 0.301789874523199 | validation: 0.16690212449169398]
	TIME [epoch: 8.87 sec]
EPOCH 308/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3594468421117337		[learning rate: 0.0024715]
		[batch 20/20] avg loss: 0.20314791184720526		[learning rate: 0.0024657]
	Learning Rate: 0.00246569
	LOSS [training: 0.2812973769794695 | validation: 0.14333425524850196]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_308.pth
	Model improved!!!
EPOCH 309/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24974572128247688		[learning rate: 0.0024599]
		[batch 20/20] avg loss: 0.2279960321837636		[learning rate: 0.0024541]
	Learning Rate: 0.00245413
	LOSS [training: 0.23887087673312024 | validation: 0.1900949372067862]
	TIME [epoch: 8.86 sec]
EPOCH 310/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1481201801681376		[learning rate: 0.0024484]
		[batch 20/20] avg loss: 0.28773579691982454		[learning rate: 0.0024426]
	Learning Rate: 0.00244263
	LOSS [training: 0.2179279885439811 | validation: 0.2589967439593472]
	TIME [epoch: 8.85 sec]
EPOCH 311/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2661441209671413		[learning rate: 0.0024369]
		[batch 20/20] avg loss: 0.25541880045217863		[learning rate: 0.0024312]
	Learning Rate: 0.00243118
	LOSS [training: 0.26078146070965996 | validation: 0.22708191295976865]
	TIME [epoch: 8.88 sec]
EPOCH 312/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28873240929972066		[learning rate: 0.0024255]
		[batch 20/20] avg loss: 0.2987288474132931		[learning rate: 0.0024198]
	Learning Rate: 0.00241978
	LOSS [training: 0.29373062835650693 | validation: 0.3980558409593334]
	TIME [epoch: 8.85 sec]
EPOCH 313/500:
	Training over batches...
		[batch 10/20] avg loss: 0.28470380725816596		[learning rate: 0.0024141]
		[batch 20/20] avg loss: 0.2533620662308179		[learning rate: 0.0024084]
	Learning Rate: 0.00240843
	LOSS [training: 0.269032936744492 | validation: 0.18164890618136148]
	TIME [epoch: 8.84 sec]
EPOCH 314/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22460975237424713		[learning rate: 0.0024028]
		[batch 20/20] avg loss: 0.26833954393539455		[learning rate: 0.0023971]
	Learning Rate: 0.00239714
	LOSS [training: 0.24647464815482087 | validation: 0.13710835788485393]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_314.pth
	Model improved!!!
EPOCH 315/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22874691108592266		[learning rate: 0.0023915]
		[batch 20/20] avg loss: 0.19401656103378725		[learning rate: 0.0023859]
	Learning Rate: 0.0023859
	LOSS [training: 0.21138173605985497 | validation: 0.18362756575131775]
	TIME [epoch: 8.86 sec]
EPOCH 316/500:
	Training over batches...
		[batch 10/20] avg loss: 0.350506174711604		[learning rate: 0.0023803]
		[batch 20/20] avg loss: 0.2569504700201634		[learning rate: 0.0023747]
	Learning Rate: 0.00237472
	LOSS [training: 0.30372832236588365 | validation: 0.1369045735427839]
	TIME [epoch: 8.87 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_316.pth
	Model improved!!!
EPOCH 317/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24458945038056887		[learning rate: 0.0023691]
		[batch 20/20] avg loss: 0.23745383857353528		[learning rate: 0.0023636]
	Learning Rate: 0.00236359
	LOSS [training: 0.24102164447705215 | validation: 0.24058180522306583]
	TIME [epoch: 8.86 sec]
EPOCH 318/500:
	Training over batches...
		[batch 10/20] avg loss: 0.27081998080550446		[learning rate: 0.002358]
		[batch 20/20] avg loss: 0.23856983052070907		[learning rate: 0.0023525]
	Learning Rate: 0.00235251
	LOSS [training: 0.2546949056631068 | validation: 0.2528899677265073]
	TIME [epoch: 8.85 sec]
EPOCH 319/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23169381771152123		[learning rate: 0.002347]
		[batch 20/20] avg loss: 0.2368953584197885		[learning rate: 0.0023415]
	Learning Rate: 0.00234148
	LOSS [training: 0.2342945880656549 | validation: 0.3601974367242489]
	TIME [epoch: 8.85 sec]
EPOCH 320/500:
	Training over batches...
		[batch 10/20] avg loss: 0.49037224653199357		[learning rate: 0.002336]
		[batch 20/20] avg loss: 0.28301293937912264		[learning rate: 0.0023305]
	Learning Rate: 0.0023305
	LOSS [training: 0.386692592955558 | validation: 0.20613253167672652]
	TIME [epoch: 8.88 sec]
EPOCH 321/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2277464949385541		[learning rate: 0.002325]
		[batch 20/20] avg loss: 0.38155425902773416		[learning rate: 0.0023196]
	Learning Rate: 0.00231957
	LOSS [training: 0.3046503769831441 | validation: 0.3478872756930229]
	TIME [epoch: 8.86 sec]
EPOCH 322/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2871191738805902		[learning rate: 0.0023141]
		[batch 20/20] avg loss: 0.32083852413795955		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.3039788490092749 | validation: 0.25999728053611915]
	TIME [epoch: 8.85 sec]
EPOCH 323/500:
	Training over batches...
		[batch 10/20] avg loss: 0.38070591754926586		[learning rate: 0.0023033]
		[batch 20/20] avg loss: 0.24719079309338046		[learning rate: 0.0022979]
	Learning Rate: 0.00229788
	LOSS [training: 0.3139483553213232 | validation: 0.23118125349670055]
	TIME [epoch: 8.85 sec]
EPOCH 324/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22712064612429553		[learning rate: 0.0022925]
		[batch 20/20] avg loss: 0.27796982040068424		[learning rate: 0.0022871]
	Learning Rate: 0.0022871
	LOSS [training: 0.2525452332624899 | validation: 0.11246501383743834]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_324.pth
	Model improved!!!
EPOCH 325/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1815630420498509		[learning rate: 0.0022817]
		[batch 20/20] avg loss: 0.30033620400072664		[learning rate: 0.0022764]
	Learning Rate: 0.00227638
	LOSS [training: 0.24094962302528883 | validation: 0.20847668827022794]
	TIME [epoch: 8.88 sec]
EPOCH 326/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2838571557282531		[learning rate: 0.002271]
		[batch 20/20] avg loss: 0.2310198786307076		[learning rate: 0.0022657]
	Learning Rate: 0.00226571
	LOSS [training: 0.25743851717948035 | validation: 0.18968296553095923]
	TIME [epoch: 8.86 sec]
EPOCH 327/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22238303068464166		[learning rate: 0.0022604]
		[batch 20/20] avg loss: 0.25250729439122566		[learning rate: 0.0022551]
	Learning Rate: 0.00225509
	LOSS [training: 0.23744516253793363 | validation: 0.28618948827140483]
	TIME [epoch: 8.86 sec]
EPOCH 328/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26022810787670003		[learning rate: 0.0022498]
		[batch 20/20] avg loss: 0.2887570736326451		[learning rate: 0.0022445]
	Learning Rate: 0.00224451
	LOSS [training: 0.2744925907546726 | validation: 0.12507658196476654]
	TIME [epoch: 8.86 sec]
EPOCH 329/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1886939575023437		[learning rate: 0.0022392]
		[batch 20/20] avg loss: 0.276111475922676		[learning rate: 0.002234]
	Learning Rate: 0.00223399
	LOSS [training: 0.23240271671250984 | validation: 0.23552275890229102]
	TIME [epoch: 8.86 sec]
EPOCH 330/500:
	Training over batches...
		[batch 10/20] avg loss: 0.32355904854724515		[learning rate: 0.0022287]
		[batch 20/20] avg loss: 0.2031964958193062		[learning rate: 0.0022235]
	Learning Rate: 0.00222352
	LOSS [training: 0.2633777721832756 | validation: 0.31710586593037077]
	TIME [epoch: 8.88 sec]
EPOCH 331/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19637027059079923		[learning rate: 0.0022183]
		[batch 20/20] avg loss: 0.27325566995614325		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.23481297027347123 | validation: 0.15442106031714312]
	TIME [epoch: 8.86 sec]
EPOCH 332/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2191468143667367		[learning rate: 0.0022079]
		[batch 20/20] avg loss: 0.1980051757524839		[learning rate: 0.0022027]
	Learning Rate: 0.00220272
	LOSS [training: 0.2085759950596103 | validation: 0.14205740627968064]
	TIME [epoch: 8.85 sec]
EPOCH 333/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2541060002882696		[learning rate: 0.0021976]
		[batch 20/20] avg loss: 0.2532298377807094		[learning rate: 0.0021924]
	Learning Rate: 0.00219239
	LOSS [training: 0.25366791903448954 | validation: 0.10675229186407773]
	TIME [epoch: 8.85 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_333.pth
	Model improved!!!
EPOCH 334/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24588667367374079		[learning rate: 0.0021872]
		[batch 20/20] avg loss: 0.4764766870923814		[learning rate: 0.0021821]
	Learning Rate: 0.00218211
	LOSS [training: 0.36118168038306103 | validation: 0.4360734817039662]
	TIME [epoch: 8.87 sec]
EPOCH 335/500:
	Training over batches...
		[batch 10/20] avg loss: 0.33466211759538667		[learning rate: 0.002177]
		[batch 20/20] avg loss: 0.25488143952836717		[learning rate: 0.0021719]
	Learning Rate: 0.00217188
	LOSS [training: 0.2947717785618769 | validation: 0.20801813431895186]
	TIME [epoch: 8.85 sec]
EPOCH 336/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20930610281590326		[learning rate: 0.0021668]
		[batch 20/20] avg loss: 0.3536800749096387		[learning rate: 0.0021617]
	Learning Rate: 0.0021617
	LOSS [training: 0.281493088862771 | validation: 0.31676496827347855]
	TIME [epoch: 8.85 sec]
EPOCH 337/500:
	Training over batches...
		[batch 10/20] avg loss: 0.29145508260267594		[learning rate: 0.0021566]
		[batch 20/20] avg loss: 0.2539257100319788		[learning rate: 0.0021516]
	Learning Rate: 0.00215157
	LOSS [training: 0.2726903963173274 | validation: 0.5220992888021783]
	TIME [epoch: 8.85 sec]
EPOCH 338/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3629214701824964		[learning rate: 0.0021465]
		[batch 20/20] avg loss: 0.28335710471989206		[learning rate: 0.0021415]
	Learning Rate: 0.00214148
	LOSS [training: 0.3231392874511942 | validation: 0.2015546915214215]
	TIME [epoch: 8.86 sec]
EPOCH 339/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21730008145616866		[learning rate: 0.0021365]
		[batch 20/20] avg loss: 0.29494135000256316		[learning rate: 0.0021314]
	Learning Rate: 0.00213144
	LOSS [training: 0.25612071572936596 | validation: 0.2536075411425906]
	TIME [epoch: 8.87 sec]
EPOCH 340/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17777516917358296		[learning rate: 0.0021264]
		[batch 20/20] avg loss: 0.2542685700430764		[learning rate: 0.0021214]
	Learning Rate: 0.00212145
	LOSS [training: 0.21602186960832967 | validation: 0.22720676929322584]
	TIME [epoch: 8.85 sec]
EPOCH 341/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24154929319033597		[learning rate: 0.0021165]
		[batch 20/20] avg loss: 0.23678329138272916		[learning rate: 0.0021115]
	Learning Rate: 0.0021115
	LOSS [training: 0.2391662922865326 | validation: 0.1663180171513401]
	TIME [epoch: 8.85 sec]
EPOCH 342/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18380596133881547		[learning rate: 0.0021065]
		[batch 20/20] avg loss: 0.24685871890459374		[learning rate: 0.0021016]
	Learning Rate: 0.0021016
	LOSS [training: 0.2153323401217046 | validation: 0.15073838713886722]
	TIME [epoch: 8.85 sec]
EPOCH 343/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20837322232131045		[learning rate: 0.0020967]
		[batch 20/20] avg loss: 0.2438529879694827		[learning rate: 0.0020918]
	Learning Rate: 0.00209175
	LOSS [training: 0.22611310514539656 | validation: 0.1428131420700839]
	TIME [epoch: 8.88 sec]
EPOCH 344/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2285376291396577		[learning rate: 0.0020868]
		[batch 20/20] avg loss: 0.1940860803016084		[learning rate: 0.0020819]
	Learning Rate: 0.00208195
	LOSS [training: 0.21131185472063302 | validation: 0.204734246220145]
	TIME [epoch: 8.86 sec]
EPOCH 345/500:
	Training over batches...
		[batch 10/20] avg loss: 0.25386220477807137		[learning rate: 0.0020771]
		[batch 20/20] avg loss: 0.19919998980507028		[learning rate: 0.0020722]
	Learning Rate: 0.00207219
	LOSS [training: 0.22653109729157084 | validation: 0.17240728075861556]
	TIME [epoch: 8.85 sec]
EPOCH 346/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19871015792721852		[learning rate: 0.0020673]
		[batch 20/20] avg loss: 0.31105824540845994		[learning rate: 0.0020625]
	Learning Rate: 0.00206247
	LOSS [training: 0.25488420166783926 | validation: 0.2950560928796502]
	TIME [epoch: 8.86 sec]
EPOCH 347/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2320382132405666		[learning rate: 0.0020576]
		[batch 20/20] avg loss: 0.28945070652361304		[learning rate: 0.0020528]
	Learning Rate: 0.0020528
	LOSS [training: 0.2607444598820897 | validation: 0.2419340500018431]
	TIME [epoch: 8.88 sec]
EPOCH 348/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26015098807020787		[learning rate: 0.002048]
		[batch 20/20] avg loss: 0.2690329912654396		[learning rate: 0.0020432]
	Learning Rate: 0.00204318
	LOSS [training: 0.26459198966782377 | validation: 0.14399352292354123]
	TIME [epoch: 8.86 sec]
EPOCH 349/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2260070945765925		[learning rate: 0.0020384]
		[batch 20/20] avg loss: 0.24888451104031034		[learning rate: 0.0020336]
	Learning Rate: 0.0020336
	LOSS [training: 0.2374458028084514 | validation: 0.17482901718724964]
	TIME [epoch: 8.85 sec]
EPOCH 350/500:
	Training over batches...
		[batch 10/20] avg loss: 0.263123295886026		[learning rate: 0.0020288]
		[batch 20/20] avg loss: 0.23617427745653008		[learning rate: 0.0020241]
	Learning Rate: 0.00202407
	LOSS [training: 0.24964878667127804 | validation: 0.17920536160131872]
	TIME [epoch: 8.86 sec]
EPOCH 351/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20442139674542018		[learning rate: 0.0020193]
		[batch 20/20] avg loss: 0.3036482149296341		[learning rate: 0.0020146]
	Learning Rate: 0.00201458
	LOSS [training: 0.25403480583752713 | validation: 0.24310124766876806]
	TIME [epoch: 8.86 sec]
EPOCH 352/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3044322124128289		[learning rate: 0.0020098]
		[batch 20/20] avg loss: 0.20574072442255215		[learning rate: 0.0020051]
	Learning Rate: 0.00200513
	LOSS [training: 0.25508646841769056 | validation: 0.22969698786528187]
	TIME [epoch: 8.87 sec]
EPOCH 353/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20148407559899018		[learning rate: 0.0020004]
		[batch 20/20] avg loss: 0.19711294722164222		[learning rate: 0.0019957]
	Learning Rate: 0.00199573
	LOSS [training: 0.19929851141031613 | validation: 0.28503177151581455]
	TIME [epoch: 8.85 sec]
EPOCH 354/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3147140603225301		[learning rate: 0.001991]
		[batch 20/20] avg loss: 0.23221227617684584		[learning rate: 0.0019864]
	Learning Rate: 0.00198637
	LOSS [training: 0.2734631682496879 | validation: 0.17250145605749703]
	TIME [epoch: 8.85 sec]
EPOCH 355/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23194886682473376		[learning rate: 0.0019817]
		[batch 20/20] avg loss: 0.21795824678016298		[learning rate: 0.0019771]
	Learning Rate: 0.00197706
	LOSS [training: 0.22495355680244838 | validation: 0.19332641161263378]
	TIME [epoch: 8.85 sec]
EPOCH 356/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18273107584756915		[learning rate: 0.0019724]
		[batch 20/20] avg loss: 0.1937255534336248		[learning rate: 0.0019678]
	Learning Rate: 0.00196779
	LOSS [training: 0.18822831464059706 | validation: 0.21687528266138897]
	TIME [epoch: 8.88 sec]
EPOCH 357/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19939452802878932		[learning rate: 0.0019632]
		[batch 20/20] avg loss: 0.17601365725145884		[learning rate: 0.0019586]
	Learning Rate: 0.00195857
	LOSS [training: 0.18770409264012405 | validation: 0.18253455975553948]
	TIME [epoch: 8.85 sec]
EPOCH 358/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21670205704500578		[learning rate: 0.001954]
		[batch 20/20] avg loss: 0.2025717278456424		[learning rate: 0.0019494]
	Learning Rate: 0.00194939
	LOSS [training: 0.20963689244532416 | validation: 0.11742466738528824]
	TIME [epoch: 8.85 sec]
EPOCH 359/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18699778449562174		[learning rate: 0.0019448]
		[batch 20/20] avg loss: 0.1698300689031877		[learning rate: 0.0019402]
	Learning Rate: 0.00194025
	LOSS [training: 0.1784139266994047 | validation: 0.21744725350171445]
	TIME [epoch: 8.85 sec]
EPOCH 360/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21525079001229686		[learning rate: 0.0019357]
		[batch 20/20] avg loss: 0.18840026769332546		[learning rate: 0.0019312]
	Learning Rate: 0.00193115
	LOSS [training: 0.20182552885281116 | validation: 0.1265610749357436]
	TIME [epoch: 8.88 sec]
EPOCH 361/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17862168793130412		[learning rate: 0.0019266]
		[batch 20/20] avg loss: 0.17201651947872473		[learning rate: 0.0019221]
	Learning Rate: 0.0019221
	LOSS [training: 0.1753191037050144 | validation: 0.2733342444479891]
	TIME [epoch: 8.85 sec]
EPOCH 362/500:
	Training over batches...
		[batch 10/20] avg loss: 0.3315006927028711		[learning rate: 0.0019176]
		[batch 20/20] avg loss: 0.21619138603681826		[learning rate: 0.0019131]
	Learning Rate: 0.00191309
	LOSS [training: 0.27384603936984464 | validation: 0.14929137630335604]
	TIME [epoch: 8.85 sec]
EPOCH 363/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22033664170480072		[learning rate: 0.0019086]
		[batch 20/20] avg loss: 0.2321154633117811		[learning rate: 0.0019041]
	Learning Rate: 0.00190412
	LOSS [training: 0.22622605250829092 | validation: 0.19356060916987744]
	TIME [epoch: 8.86 sec]
EPOCH 364/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2588042112391973		[learning rate: 0.0018996]
		[batch 20/20] avg loss: 0.1909287141579625		[learning rate: 0.0018952]
	Learning Rate: 0.00189519
	LOSS [training: 0.22486646269857996 | validation: 0.1447157317132433]
	TIME [epoch: 8.87 sec]
EPOCH 365/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17701681654395263		[learning rate: 0.0018907]
		[batch 20/20] avg loss: 0.22367461977928804		[learning rate: 0.0018863]
	Learning Rate: 0.00188631
	LOSS [training: 0.20034571816162033 | validation: 0.2143430013290044]
	TIME [epoch: 8.88 sec]
EPOCH 366/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21218668340869778		[learning rate: 0.0018819]
		[batch 20/20] avg loss: 0.19688555269000327		[learning rate: 0.0018775]
	Learning Rate: 0.00187746
	LOSS [training: 0.20453611804935057 | validation: 0.2718269728785107]
	TIME [epoch: 8.85 sec]
EPOCH 367/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2582628807549748		[learning rate: 0.0018731]
		[batch 20/20] avg loss: 0.19938978199119514		[learning rate: 0.0018687]
	Learning Rate: 0.00186866
	LOSS [training: 0.2288263313730849 | validation: 0.15487696667812223]
	TIME [epoch: 8.85 sec]
EPOCH 368/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2635396184725618		[learning rate: 0.0018643]
		[batch 20/20] avg loss: 0.1337682090524519		[learning rate: 0.0018599]
	Learning Rate: 0.0018599
	LOSS [training: 0.19865391376250685 | validation: 0.2406804371670906]
	TIME [epoch: 8.86 sec]
EPOCH 369/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23617092833467046		[learning rate: 0.0018555]
		[batch 20/20] avg loss: 0.21381230290241304		[learning rate: 0.0018512]
	Learning Rate: 0.00185118
	LOSS [training: 0.22499161561854178 | validation: 0.2822886110878091]
	TIME [epoch: 8.88 sec]
EPOCH 370/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18452353436586086		[learning rate: 0.0018468]
		[batch 20/20] avg loss: 0.15181844195931923		[learning rate: 0.0018425]
	Learning Rate: 0.0018425
	LOSS [training: 0.16817098816259002 | validation: 0.18311560430162277]
	TIME [epoch: 8.86 sec]
EPOCH 371/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18098749139431636		[learning rate: 0.0018382]
		[batch 20/20] avg loss: 0.17874143397305026		[learning rate: 0.0018339]
	Learning Rate: 0.00183386
	LOSS [training: 0.17986446268368333 | validation: 0.11973950390813723]
	TIME [epoch: 8.86 sec]
EPOCH 372/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14002321975111215		[learning rate: 0.0018296]
		[batch 20/20] avg loss: 0.2711317252603814		[learning rate: 0.0018253]
	Learning Rate: 0.00182527
	LOSS [training: 0.2055774725057468 | validation: 0.15731010287311986]
	TIME [epoch: 8.85 sec]
EPOCH 373/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18472424294290174		[learning rate: 0.001821]
		[batch 20/20] avg loss: 0.13649369442901402		[learning rate: 0.0018167]
	Learning Rate: 0.00181671
	LOSS [training: 0.16060896868595792 | validation: 0.25711969660870987]
	TIME [epoch: 8.88 sec]
EPOCH 374/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1783966631033547		[learning rate: 0.0018124]
		[batch 20/20] avg loss: 0.17332061959351378		[learning rate: 0.0018082]
	Learning Rate: 0.00180819
	LOSS [training: 0.1758586413484342 | validation: 0.14291060639806036]
	TIME [epoch: 8.86 sec]
EPOCH 375/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21799639811012636		[learning rate: 0.001804]
		[batch 20/20] avg loss: 0.17829987399049363		[learning rate: 0.0017997]
	Learning Rate: 0.00179972
	LOSS [training: 0.19814813605031 | validation: 0.1473230431591409]
	TIME [epoch: 8.86 sec]
EPOCH 376/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1593730330773237		[learning rate: 0.0017955]
		[batch 20/20] avg loss: 0.19372617737562803		[learning rate: 0.0017913]
	Learning Rate: 0.00179128
	LOSS [training: 0.17654960522647586 | validation: 0.19526751395437603]
	TIME [epoch: 8.86 sec]
EPOCH 377/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17221951294771434		[learning rate: 0.0017871]
		[batch 20/20] avg loss: 0.21401859005251747		[learning rate: 0.0017829]
	Learning Rate: 0.00178288
	LOSS [training: 0.1931190515001159 | validation: 0.17092345926482708]
	TIME [epoch: 8.88 sec]
EPOCH 378/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22980603497497726		[learning rate: 0.0017787]
		[batch 20/20] avg loss: 0.30801888913081166		[learning rate: 0.0017745]
	Learning Rate: 0.00177452
	LOSS [training: 0.2689124620528944 | validation: 0.1400199609388121]
	TIME [epoch: 8.87 sec]
EPOCH 379/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1984730560983281		[learning rate: 0.0017704]
		[batch 20/20] avg loss: 0.2269429561458794		[learning rate: 0.0017662]
	Learning Rate: 0.0017662
	LOSS [training: 0.2127080061221037 | validation: 0.18300650553671405]
	TIME [epoch: 8.86 sec]
EPOCH 380/500:
	Training over batches...
		[batch 10/20] avg loss: 0.2369696869558168		[learning rate: 0.0017621]
		[batch 20/20] avg loss: 0.22623408806649348		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.2316018875111551 | validation: 0.14012841470061127]
	TIME [epoch: 8.86 sec]
EPOCH 381/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14696279089080283		[learning rate: 0.0017538]
		[batch 20/20] avg loss: 0.23402399951768166		[learning rate: 0.0017497]
	Learning Rate: 0.00174968
	LOSS [training: 0.19049339520424222 | validation: 0.1905671294422855]
	TIME [epoch: 8.86 sec]
EPOCH 382/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16532371533402887		[learning rate: 0.0017456]
		[batch 20/20] avg loss: 0.18999126313022438		[learning rate: 0.0017415]
	Learning Rate: 0.00174148
	LOSS [training: 0.1776574892321266 | validation: 0.16910692782517145]
	TIME [epoch: 8.88 sec]
EPOCH 383/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1810700041637166		[learning rate: 0.0017374]
		[batch 20/20] avg loss: 0.23822679514554457		[learning rate: 0.0017333]
	Learning Rate: 0.00173331
	LOSS [training: 0.20964839965463056 | validation: 0.14547265349603822]
	TIME [epoch: 8.86 sec]
EPOCH 384/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21832296362724063		[learning rate: 0.0017292]
		[batch 20/20] avg loss: 0.20367207588362118		[learning rate: 0.0017252]
	Learning Rate: 0.00172519
	LOSS [training: 0.21099751975543093 | validation: 0.1886473743596318]
	TIME [epoch: 8.85 sec]
EPOCH 385/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15367772815710748		[learning rate: 0.0017211]
		[batch 20/20] avg loss: 0.13412005033656701		[learning rate: 0.0017171]
	Learning Rate: 0.0017171
	LOSS [training: 0.14389888924683727 | validation: 0.17703117031731042]
	TIME [epoch: 8.86 sec]
EPOCH 386/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19711846205299316		[learning rate: 0.0017131]
		[batch 20/20] avg loss: 0.1705373290412911		[learning rate: 0.0017091]
	Learning Rate: 0.00170905
	LOSS [training: 0.1838278955471421 | validation: 0.08310394286793374]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_386.pth
	Model improved!!!
EPOCH 387/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18014550917312375		[learning rate: 0.001705]
		[batch 20/20] avg loss: 0.2072697806141554		[learning rate: 0.001701]
	Learning Rate: 0.00170104
	LOSS [training: 0.19370764489363962 | validation: 0.16735336806273984]
	TIME [epoch: 8.86 sec]
EPOCH 388/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1854938523359649		[learning rate: 0.001697]
		[batch 20/20] avg loss: 0.15392370890981139		[learning rate: 0.0016931]
	Learning Rate: 0.00169306
	LOSS [training: 0.1697087806228882 | validation: 0.13967349637076687]
	TIME [epoch: 8.87 sec]
EPOCH 389/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14395480296279098		[learning rate: 0.0016891]
		[batch 20/20] avg loss: 0.17014460820683797		[learning rate: 0.0016851]
	Learning Rate: 0.00168513
	LOSS [training: 0.15704970558481446 | validation: 0.1335576280560783]
	TIME [epoch: 8.88 sec]
EPOCH 390/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1581832569213196		[learning rate: 0.0016812]
		[batch 20/20] avg loss: 0.20380009365078222		[learning rate: 0.0016772]
	Learning Rate: 0.00167723
	LOSS [training: 0.18099167528605092 | validation: 0.2067491064318502]
	TIME [epoch: 8.9 sec]
EPOCH 391/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16274001805282176		[learning rate: 0.0016733]
		[batch 20/20] avg loss: 0.17772569779896033		[learning rate: 0.0016694]
	Learning Rate: 0.00166936
	LOSS [training: 0.170232857925891 | validation: 0.13019118059253126]
	TIME [epoch: 8.89 sec]
EPOCH 392/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18283362705378273		[learning rate: 0.0016654]
		[batch 20/20] avg loss: 0.18589851449248443		[learning rate: 0.0016615]
	Learning Rate: 0.00166154
	LOSS [training: 0.18436607077313355 | validation: 0.22562478084301213]
	TIME [epoch: 8.88 sec]
EPOCH 393/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22239008910380828		[learning rate: 0.0016576]
		[batch 20/20] avg loss: 0.13285271360427098		[learning rate: 0.0016537]
	Learning Rate: 0.00165375
	LOSS [training: 0.17762140135403964 | validation: 0.10952477350033277]
	TIME [epoch: 8.88 sec]
EPOCH 394/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17283271066067618		[learning rate: 0.0016499]
		[batch 20/20] avg loss: 0.17759105097089198		[learning rate: 0.001646]
	Learning Rate: 0.001646
	LOSS [training: 0.17521188081578407 | validation: 0.20742577460370462]
	TIME [epoch: 8.88 sec]
EPOCH 395/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1731053133640732		[learning rate: 0.0016421]
		[batch 20/20] avg loss: 0.16682451368358034		[learning rate: 0.0016383]
	Learning Rate: 0.00163828
	LOSS [training: 0.16996491352382675 | validation: 0.2085633897303888]
	TIME [epoch: 8.9 sec]
EPOCH 396/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18635492452051367		[learning rate: 0.0016344]
		[batch 20/20] avg loss: 0.16841856300190042		[learning rate: 0.0016306]
	Learning Rate: 0.0016306
	LOSS [training: 0.17738674376120706 | validation: 0.1299210931803128]
	TIME [epoch: 8.85 sec]
EPOCH 397/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16616983408945035		[learning rate: 0.0016268]
		[batch 20/20] avg loss: 0.19142970755211855		[learning rate: 0.001623]
	Learning Rate: 0.00162295
	LOSS [training: 0.17879977082078444 | validation: 0.1479072216223269]
	TIME [epoch: 8.87 sec]
EPOCH 398/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17552722038055382		[learning rate: 0.0016191]
		[batch 20/20] avg loss: 0.18945338606551226		[learning rate: 0.0016153]
	Learning Rate: 0.00161535
	LOSS [training: 0.182490303223033 | validation: 0.14066219855752132]
	TIME [epoch: 8.87 sec]
EPOCH 399/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20376238392960272		[learning rate: 0.0016116]
		[batch 20/20] avg loss: 0.1865798676845667		[learning rate: 0.0016078]
	Learning Rate: 0.00160777
	LOSS [training: 0.19517112580708473 | validation: 0.11164981949994733]
	TIME [epoch: 8.87 sec]
EPOCH 400/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16484084276625305		[learning rate: 0.001604]
		[batch 20/20] avg loss: 0.1729429801703008		[learning rate: 0.0016002]
	Learning Rate: 0.00160023
	LOSS [training: 0.16889191146827692 | validation: 0.191037663809909]
	TIME [epoch: 8.85 sec]
EPOCH 401/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14985179623910017		[learning rate: 0.0015965]
		[batch 20/20] avg loss: 0.16731923434813722		[learning rate: 0.0015927]
	Learning Rate: 0.00159273
	LOSS [training: 0.1585855152936187 | validation: 0.1775889695236073]
	TIME [epoch: 8.84 sec]
EPOCH 402/500:
	Training over batches...
		[batch 10/20] avg loss: 0.21702483825797275		[learning rate: 0.001589]
		[batch 20/20] avg loss: 0.16249077391462144		[learning rate: 0.0015853]
	Learning Rate: 0.00158527
	LOSS [training: 0.18975780608629708 | validation: 0.16387764346310948]
	TIME [epoch: 8.86 sec]
EPOCH 403/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1258175706562594		[learning rate: 0.0015815]
		[batch 20/20] avg loss: 0.18723095303517817		[learning rate: 0.0015778]
	Learning Rate: 0.00157783
	LOSS [training: 0.1565242618457188 | validation: 0.3076721808806986]
	TIME [epoch: 8.85 sec]
EPOCH 404/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1819103281711399		[learning rate: 0.0015741]
		[batch 20/20] avg loss: 0.14886722223496926		[learning rate: 0.0015704]
	Learning Rate: 0.00157044
	LOSS [training: 0.16538877520305456 | validation: 0.18742922350350938]
	TIME [epoch: 8.87 sec]
EPOCH 405/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18164685993523072		[learning rate: 0.0015668]
		[batch 20/20] avg loss: 0.15958714632605747		[learning rate: 0.0015631]
	Learning Rate: 0.00156307
	LOSS [training: 0.1706170031306441 | validation: 0.17254636632224268]
	TIME [epoch: 8.85 sec]
EPOCH 406/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15110596339564866		[learning rate: 0.0015594]
		[batch 20/20] avg loss: 0.17869261690023275		[learning rate: 0.0015557]
	Learning Rate: 0.00155575
	LOSS [training: 0.1648992901479407 | validation: 0.1291360365461844]
	TIME [epoch: 8.85 sec]
EPOCH 407/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15718719669006395		[learning rate: 0.0015521]
		[batch 20/20] avg loss: 0.161514441381356		[learning rate: 0.0015485]
	Learning Rate: 0.00154845
	LOSS [training: 0.15935081903570997 | validation: 0.11550636475733071]
	TIME [epoch: 8.85 sec]
EPOCH 408/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18766210056811805		[learning rate: 0.0015448]
		[batch 20/20] avg loss: 0.15898694329654323		[learning rate: 0.0015412]
	Learning Rate: 0.00154119
	LOSS [training: 0.17332452193233058 | validation: 0.12143744074182813]
	TIME [epoch: 8.87 sec]
EPOCH 409/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17421033366439068		[learning rate: 0.0015376]
		[batch 20/20] avg loss: 0.17143149139212768		[learning rate: 0.001534]
	Learning Rate: 0.00153397
	LOSS [training: 0.17282091252825918 | validation: 0.0837399738841317]
	TIME [epoch: 8.85 sec]
EPOCH 410/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18231629399011667		[learning rate: 0.0015304]
		[batch 20/20] avg loss: 0.1596257653007675		[learning rate: 0.0015268]
	Learning Rate: 0.00152678
	LOSS [training: 0.17097102964544214 | validation: 0.12756266155806756]
	TIME [epoch: 8.85 sec]
EPOCH 411/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13173078882270384		[learning rate: 0.0015232]
		[batch 20/20] avg loss: 0.22154636509839176		[learning rate: 0.0015196]
	Learning Rate: 0.00151962
	LOSS [training: 0.1766385769605478 | validation: 0.16457687404724164]
	TIME [epoch: 8.84 sec]
EPOCH 412/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1961830581797313		[learning rate: 0.0015161]
		[batch 20/20] avg loss: 0.15523634270337708		[learning rate: 0.0015125]
	Learning Rate: 0.00151249
	LOSS [training: 0.1757097004415542 | validation: 0.13432379277188933]
	TIME [epoch: 8.88 sec]
EPOCH 413/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1846031966885875		[learning rate: 0.0015089]
		[batch 20/20] avg loss: 0.13304792294972217		[learning rate: 0.0015054]
	Learning Rate: 0.0015054
	LOSS [training: 0.1588255598191548 | validation: 0.09920740820890012]
	TIME [epoch: 8.86 sec]
EPOCH 414/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17902065385130367		[learning rate: 0.0015019]
		[batch 20/20] avg loss: 0.14717444652863393		[learning rate: 0.0014983]
	Learning Rate: 0.00149835
	LOSS [training: 0.1630975501899688 | validation: 0.10601282389945588]
	TIME [epoch: 8.87 sec]
EPOCH 415/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1546032270461557		[learning rate: 0.0014948]
		[batch 20/20] avg loss: 0.1675165469046095		[learning rate: 0.0014913]
	Learning Rate: 0.00149132
	LOSS [training: 0.1610598869753826 | validation: 0.2013919254279623]
	TIME [epoch: 8.86 sec]
EPOCH 416/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20030780426177025		[learning rate: 0.0014878]
		[batch 20/20] avg loss: 0.2243789526953721		[learning rate: 0.0014843]
	Learning Rate: 0.00148433
	LOSS [training: 0.21234337847857115 | validation: 0.13691811733578915]
	TIME [epoch: 8.9 sec]
EPOCH 417/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15156035325588801		[learning rate: 0.0014808]
		[batch 20/20] avg loss: 0.13892631937449246		[learning rate: 0.0014774]
	Learning Rate: 0.00147737
	LOSS [training: 0.1452433363151902 | validation: 0.17435403436755445]
	TIME [epoch: 8.88 sec]
EPOCH 418/500:
	Training over batches...
		[batch 10/20] avg loss: 0.22207655356089867		[learning rate: 0.0014739]
		[batch 20/20] avg loss: 0.1865261958557458		[learning rate: 0.0014704]
	Learning Rate: 0.00147045
	LOSS [training: 0.20430137470832221 | validation: 0.16281173502016646]
	TIME [epoch: 8.87 sec]
EPOCH 419/500:
	Training over batches...
		[batch 10/20] avg loss: 0.20279111797303093		[learning rate: 0.001467]
		[batch 20/20] avg loss: 0.1874974522769		[learning rate: 0.0014636]
	Learning Rate: 0.00146355
	LOSS [training: 0.19514428512496548 | validation: 0.20680121786976202]
	TIME [epoch: 8.85 sec]
EPOCH 420/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15580449679477676		[learning rate: 0.0014601]
		[batch 20/20] avg loss: 0.15231890966888237		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.15406170323182958 | validation: 0.12888066704354875]
	TIME [epoch: 8.88 sec]
EPOCH 421/500:
	Training over batches...
		[batch 10/20] avg loss: 0.197581460139224		[learning rate: 0.0014533]
		[batch 20/20] avg loss: 0.15084500054759098		[learning rate: 0.0014499]
	Learning Rate: 0.00144986
	LOSS [training: 0.1742132303434075 | validation: 0.07978986281122714]
	TIME [epoch: 8.88 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_421.pth
	Model improved!!!
EPOCH 422/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1586365617140847		[learning rate: 0.0014465]
		[batch 20/20] avg loss: 0.1527195259775264		[learning rate: 0.0014431]
	Learning Rate: 0.00144306
	LOSS [training: 0.15567804384580558 | validation: 0.1465355323593603]
	TIME [epoch: 8.84 sec]
EPOCH 423/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18316031127235963		[learning rate: 0.0014397]
		[batch 20/20] avg loss: 0.16368228014419967		[learning rate: 0.0014363]
	Learning Rate: 0.0014363
	LOSS [training: 0.17342129570827966 | validation: 0.174657498492382]
	TIME [epoch: 8.82 sec]
EPOCH 424/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15657651396224545		[learning rate: 0.0014329]
		[batch 20/20] avg loss: 0.21377830300744766		[learning rate: 0.0014296]
	Learning Rate: 0.00142957
	LOSS [training: 0.18517740848484654 | validation: 0.1430432958282133]
	TIME [epoch: 8.84 sec]
EPOCH 425/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1378016670449611		[learning rate: 0.0014262]
		[batch 20/20] avg loss: 0.1728145930484974		[learning rate: 0.0014229]
	Learning Rate: 0.00142286
	LOSS [training: 0.15530813004672922 | validation: 0.1335491339517674]
	TIME [epoch: 8.86 sec]
EPOCH 426/500:
	Training over batches...
		[batch 10/20] avg loss: 0.24868770075528598		[learning rate: 0.0014195]
		[batch 20/20] avg loss: 0.1910421793960476		[learning rate: 0.0014162]
	Learning Rate: 0.00141619
	LOSS [training: 0.2198649400756668 | validation: 0.13446627029023728]
	TIME [epoch: 8.84 sec]
EPOCH 427/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16519418070778563		[learning rate: 0.0014129]
		[batch 20/20] avg loss: 0.1489731913454316		[learning rate: 0.0014096]
	Learning Rate: 0.00140955
	LOSS [training: 0.15708368602660863 | validation: 0.06972842597049013]
	TIME [epoch: 8.84 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_427.pth
	Model improved!!!
EPOCH 428/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13914123049693408		[learning rate: 0.0014062]
		[batch 20/20] avg loss: 0.18090654992208427		[learning rate: 0.0014029]
	Learning Rate: 0.00140295
	LOSS [training: 0.1600238902095092 | validation: 0.15557553403359298]
	TIME [epoch: 8.83 sec]
EPOCH 429/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15345105988021562		[learning rate: 0.0013997]
		[batch 20/20] avg loss: 0.1662126831737764		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.15983187152699604 | validation: 0.12956695664827705]
	TIME [epoch: 8.84 sec]
EPOCH 430/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17698627234782568		[learning rate: 0.0013931]
		[batch 20/20] avg loss: 0.15882938322564535		[learning rate: 0.0013898]
	Learning Rate: 0.00138982
	LOSS [training: 0.1679078277867355 | validation: 0.08687869533463229]
	TIME [epoch: 8.86 sec]
EPOCH 431/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15902778650640625		[learning rate: 0.0013866]
		[batch 20/20] avg loss: 0.1436001721947649		[learning rate: 0.0013833]
	Learning Rate: 0.00138331
	LOSS [training: 0.15131397935058558 | validation: 0.19036944691605356]
	TIME [epoch: 8.84 sec]
EPOCH 432/500:
	Training over batches...
		[batch 10/20] avg loss: 0.26500690832367435		[learning rate: 0.0013801]
		[batch 20/20] avg loss: 0.17776113801745952		[learning rate: 0.0013768]
	Learning Rate: 0.00137682
	LOSS [training: 0.22138402317056696 | validation: 0.21363853636497632]
	TIME [epoch: 8.83 sec]
EPOCH 433/500:
	Training over batches...
		[batch 10/20] avg loss: 0.23880818826391206		[learning rate: 0.0013736]
		[batch 20/20] avg loss: 0.15921893928149666		[learning rate: 0.0013704]
	Learning Rate: 0.00137037
	LOSS [training: 0.19901356377270435 | validation: 0.3003942116479844]
	TIME [epoch: 8.83 sec]
EPOCH 434/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17419475419006772		[learning rate: 0.0013672]
		[batch 20/20] avg loss: 0.16708982280515172		[learning rate: 0.0013639]
	Learning Rate: 0.00136394
	LOSS [training: 0.1706422884976097 | validation: 0.1908713980698778]
	TIME [epoch: 8.86 sec]
EPOCH 435/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16484611923947876		[learning rate: 0.0013607]
		[batch 20/20] avg loss: 0.1328968990030843		[learning rate: 0.0013575]
	Learning Rate: 0.00135755
	LOSS [training: 0.14887150912128153 | validation: 0.09829988639667131]
	TIME [epoch: 8.84 sec]
EPOCH 436/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13684694498811625		[learning rate: 0.0013544]
		[batch 20/20] avg loss: 0.1254440544650785		[learning rate: 0.0013512]
	Learning Rate: 0.00135118
	LOSS [training: 0.13114549972659734 | validation: 0.08768404560203685]
	TIME [epoch: 8.85 sec]
EPOCH 437/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13204950147245315		[learning rate: 0.001348]
		[batch 20/20] avg loss: 0.14088365997746605		[learning rate: 0.0013448]
	Learning Rate: 0.00134485
	LOSS [training: 0.1364665807249596 | validation: 0.13456534092678346]
	TIME [epoch: 8.84 sec]
EPOCH 438/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18047994595898095		[learning rate: 0.0013417]
		[batch 20/20] avg loss: 0.15304870988660138		[learning rate: 0.0013385]
	Learning Rate: 0.00133854
	LOSS [training: 0.16676432792279114 | validation: 0.09234226160527405]
	TIME [epoch: 8.85 sec]
EPOCH 439/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15885704733887668		[learning rate: 0.0013354]
		[batch 20/20] avg loss: 0.11650621414753852		[learning rate: 0.0013323]
	Learning Rate: 0.00133227
	LOSS [training: 0.13768163074320763 | validation: 0.11452149627091154]
	TIME [epoch: 8.85 sec]
EPOCH 440/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13552421840491122		[learning rate: 0.0013291]
		[batch 20/20] avg loss: 0.1959251877790875		[learning rate: 0.001326]
	Learning Rate: 0.00132602
	LOSS [training: 0.16572470309199935 | validation: 0.11781743282518674]
	TIME [epoch: 8.84 sec]
EPOCH 441/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1197398623730822		[learning rate: 0.0013229]
		[batch 20/20] avg loss: 0.12167227451028176		[learning rate: 0.0013198]
	Learning Rate: 0.00131981
	LOSS [training: 0.120706068441682 | validation: 0.11525227513344194]
	TIME [epoch: 8.83 sec]
EPOCH 442/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16436189256545536		[learning rate: 0.0013167]
		[batch 20/20] avg loss: 0.14836476339866422		[learning rate: 0.0013136]
	Learning Rate: 0.00131362
	LOSS [training: 0.1563633279820598 | validation: 0.08377738217586049]
	TIME [epoch: 8.83 sec]
EPOCH 443/500:
	Training over batches...
		[batch 10/20] avg loss: 0.10583844944430469		[learning rate: 0.0013105]
		[batch 20/20] avg loss: 0.1645723189845673		[learning rate: 0.0013075]
	Learning Rate: 0.00130746
	LOSS [training: 0.135205384214436 | validation: 0.1717000089853639]
	TIME [epoch: 8.85 sec]
EPOCH 444/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13755431285691583		[learning rate: 0.0013044]
		[batch 20/20] avg loss: 0.16480486633222943		[learning rate: 0.0013013]
	Learning Rate: 0.00130133
	LOSS [training: 0.15117958959457262 | validation: 0.23123406502341914]
	TIME [epoch: 8.86 sec]
EPOCH 445/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1472376698709296		[learning rate: 0.0012983]
		[batch 20/20] avg loss: 0.14037250893957015		[learning rate: 0.0012952]
	Learning Rate: 0.00129523
	LOSS [training: 0.14380508940524986 | validation: 0.10045955894340289]
	TIME [epoch: 8.83 sec]
EPOCH 446/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1650892986860812		[learning rate: 0.0012922]
		[batch 20/20] avg loss: 0.1722744890575914		[learning rate: 0.0012892]
	Learning Rate: 0.00128916
	LOSS [training: 0.1686818938718363 | validation: 0.09426386766983147]
	TIME [epoch: 8.83 sec]
EPOCH 447/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13956098219297855		[learning rate: 0.0012861]
		[batch 20/20] avg loss: 0.1518076329220886		[learning rate: 0.0012831]
	Learning Rate: 0.00128311
	LOSS [training: 0.14568430755753353 | validation: 0.166062500426265]
	TIME [epoch: 8.85 sec]
EPOCH 448/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14054472605361745		[learning rate: 0.0012801]
		[batch 20/20] avg loss: 0.1654997228624979		[learning rate: 0.0012771]
	Learning Rate: 0.0012771
	LOSS [training: 0.15302222445805766 | validation: 0.13480327712860407]
	TIME [epoch: 8.84 sec]
EPOCH 449/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12316078117752158		[learning rate: 0.0012741]
		[batch 20/20] avg loss: 0.12940929054431968		[learning rate: 0.0012711]
	Learning Rate: 0.00127111
	LOSS [training: 0.12628503586092063 | validation: 0.11435522326470544]
	TIME [epoch: 8.84 sec]
EPOCH 450/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12735060384040026		[learning rate: 0.0012681]
		[batch 20/20] avg loss: 0.12176361642723128		[learning rate: 0.0012652]
	Learning Rate: 0.00126515
	LOSS [training: 0.1245571101338158 | validation: 0.09991192913870395]
	TIME [epoch: 8.82 sec]
EPOCH 451/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12667410817452301		[learning rate: 0.0012622]
		[batch 20/20] avg loss: 0.18558716041551165		[learning rate: 0.0012592]
	Learning Rate: 0.00125922
	LOSS [training: 0.15613063429501733 | validation: 0.11709487139142424]
	TIME [epoch: 8.85 sec]
EPOCH 452/500:
	Training over batches...
		[batch 10/20] avg loss: 0.18239582098585522		[learning rate: 0.0012563]
		[batch 20/20] avg loss: 0.19571232668281913		[learning rate: 0.0012533]
	Learning Rate: 0.00125332
	LOSS [training: 0.1890540738343372 | validation: 0.11417600149304369]
	TIME [epoch: 8.85 sec]
EPOCH 453/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13194219989018646		[learning rate: 0.0012504]
		[batch 20/20] avg loss: 0.15811652683733052		[learning rate: 0.0012474]
	Learning Rate: 0.00124744
	LOSS [training: 0.1450293633637585 | validation: 0.13598704158252792]
	TIME [epoch: 8.83 sec]
EPOCH 454/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16954858181611004		[learning rate: 0.0012445]
		[batch 20/20] avg loss: 0.14675601895494278		[learning rate: 0.0012416]
	Learning Rate: 0.00124159
	LOSS [training: 0.15815230038552638 | validation: 0.16392651873480898]
	TIME [epoch: 8.82 sec]
EPOCH 455/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12671192540915677		[learning rate: 0.0012387]
		[batch 20/20] avg loss: 0.11263644617170791		[learning rate: 0.0012358]
	Learning Rate: 0.00123577
	LOSS [training: 0.11967418579043232 | validation: 0.09765751365816058]
	TIME [epoch: 8.83 sec]
EPOCH 456/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14649982497492645		[learning rate: 0.0012329]
		[batch 20/20] avg loss: 0.1656966715450979		[learning rate: 0.00123]
	Learning Rate: 0.00122998
	LOSS [training: 0.15609824826001215 | validation: 0.09664436357180263]
	TIME [epoch: 8.86 sec]
EPOCH 457/500:
	Training over batches...
		[batch 10/20] avg loss: 0.16594799213522848		[learning rate: 0.0012271]
		[batch 20/20] avg loss: 0.13062481054943503		[learning rate: 0.0012242]
	Learning Rate: 0.00122421
	LOSS [training: 0.14828640134233176 | validation: 0.06862710580848844]
	TIME [epoch: 8.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_457.pth
	Model improved!!!
EPOCH 458/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13505427760898397		[learning rate: 0.0012213]
		[batch 20/20] avg loss: 0.1414107802957824		[learning rate: 0.0012185]
	Learning Rate: 0.00121847
	LOSS [training: 0.1382325289523832 | validation: 0.10943000619410528]
	TIME [epoch: 8.84 sec]
EPOCH 459/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12178415215366867		[learning rate: 0.0012156]
		[batch 20/20] avg loss: 0.1299523747135946		[learning rate: 0.0012128]
	Learning Rate: 0.00121276
	LOSS [training: 0.1258682634336316 | validation: 0.08662051337502409]
	TIME [epoch: 8.84 sec]
EPOCH 460/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12929987127748382		[learning rate: 0.0012099]
		[batch 20/20] avg loss: 0.10072946547680642		[learning rate: 0.0012071]
	Learning Rate: 0.00120708
	LOSS [training: 0.11501466837714511 | validation: 0.1151395177175452]
	TIME [epoch: 8.86 sec]
EPOCH 461/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15729208087687319		[learning rate: 0.0012042]
		[batch 20/20] avg loss: 0.15231258447581814		[learning rate: 0.0012014]
	Learning Rate: 0.00120142
	LOSS [training: 0.15480233267634563 | validation: 0.18790950601520792]
	TIME [epoch: 8.83 sec]
EPOCH 462/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1820494045426501		[learning rate: 0.0011986]
		[batch 20/20] avg loss: 0.15916662932536682		[learning rate: 0.0011958]
	Learning Rate: 0.00119578
	LOSS [training: 0.17060801693400846 | validation: 0.13721084375703063]
	TIME [epoch: 8.84 sec]
EPOCH 463/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13686071772438685		[learning rate: 0.001193]
		[batch 20/20] avg loss: 0.1317148457962571		[learning rate: 0.0011902]
	Learning Rate: 0.00119018
	LOSS [training: 0.13428778176032202 | validation: 0.14902080338657428]
	TIME [epoch: 8.84 sec]
EPOCH 464/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13398660905222964		[learning rate: 0.0011874]
		[batch 20/20] avg loss: 0.1337292535300429		[learning rate: 0.0011846]
	Learning Rate: 0.0011846
	LOSS [training: 0.13385793129113624 | validation: 0.19633360473524167]
	TIME [epoch: 8.84 sec]
EPOCH 465/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15481766667692204		[learning rate: 0.0011818]
		[batch 20/20] avg loss: 0.14454268062541756		[learning rate: 0.001179]
	Learning Rate: 0.00117905
	LOSS [training: 0.14968017365116987 | validation: 0.15957786694002918]
	TIME [epoch: 8.88 sec]
EPOCH 466/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1368244095952455		[learning rate: 0.0011763]
		[batch 20/20] avg loss: 0.12810260204597515		[learning rate: 0.0011735]
	Learning Rate: 0.00117352
	LOSS [training: 0.13246350582061034 | validation: 0.08933443633086112]
	TIME [epoch: 8.84 sec]
EPOCH 467/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12175133179386233		[learning rate: 0.0011708]
		[batch 20/20] avg loss: 0.11383671962266495		[learning rate: 0.001168]
	Learning Rate: 0.00116802
	LOSS [training: 0.11779402570826362 | validation: 0.12049759345407664]
	TIME [epoch: 8.84 sec]
EPOCH 468/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15146980227002022		[learning rate: 0.0011653]
		[batch 20/20] avg loss: 0.12379648405950797		[learning rate: 0.0011625]
	Learning Rate: 0.00116254
	LOSS [training: 0.13763314316476408 | validation: 0.10008647266958896]
	TIME [epoch: 8.84 sec]
EPOCH 469/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1304949083872445		[learning rate: 0.0011598]
		[batch 20/20] avg loss: 0.13130048334700004		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.13089769586712224 | validation: 0.20697295904131724]
	TIME [epoch: 8.87 sec]
EPOCH 470/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15343686831362058		[learning rate: 0.0011544]
		[batch 20/20] avg loss: 0.1468661800562447		[learning rate: 0.0011517]
	Learning Rate: 0.00115167
	LOSS [training: 0.15015152418493263 | validation: 0.12950319758274165]
	TIME [epoch: 8.84 sec]
EPOCH 471/500:
	Training over batches...
		[batch 10/20] avg loss: 0.17208696624279518		[learning rate: 0.001149]
		[batch 20/20] avg loss: 0.14742256875639947		[learning rate: 0.0011463]
	Learning Rate: 0.00114627
	LOSS [training: 0.15975476749959733 | validation: 0.1970501072273678]
	TIME [epoch: 8.84 sec]
EPOCH 472/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1291830230778269		[learning rate: 0.0011436]
		[batch 20/20] avg loss: 0.1527561130477235		[learning rate: 0.0011409]
	Learning Rate: 0.00114089
	LOSS [training: 0.1409695680627752 | validation: 0.16637907323313827]
	TIME [epoch: 8.85 sec]
EPOCH 473/500:
	Training over batches...
		[batch 10/20] avg loss: 0.15816956884307456		[learning rate: 0.0011382]
		[batch 20/20] avg loss: 0.16680897653585244		[learning rate: 0.0011355]
	Learning Rate: 0.00113554
	LOSS [training: 0.1624892726894635 | validation: 0.10617197494582299]
	TIME [epoch: 8.85 sec]
EPOCH 474/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1523620807710863		[learning rate: 0.0011329]
		[batch 20/20] avg loss: 0.26240138822120657		[learning rate: 0.0011302]
	Learning Rate: 0.00113022
	LOSS [training: 0.20738173449614647 | validation: 0.28331394722585507]
	TIME [epoch: 8.85 sec]
EPOCH 475/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13148720658728202		[learning rate: 0.0011276]
		[batch 20/20] avg loss: 0.15428523313220682		[learning rate: 0.0011249]
	Learning Rate: 0.00112492
	LOSS [training: 0.14288621985974442 | validation: 0.30888124841128006]
	TIME [epoch: 8.84 sec]
EPOCH 476/500:
	Training over batches...
		[batch 10/20] avg loss: 0.19285315885284987		[learning rate: 0.0011223]
		[batch 20/20] avg loss: 0.13798181906247792		[learning rate: 0.0011196]
	Learning Rate: 0.00111965
	LOSS [training: 0.1654174889576639 | validation: 0.09386301064486594]
	TIME [epoch: 8.85 sec]
EPOCH 477/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13609625456265595		[learning rate: 0.001117]
		[batch 20/20] avg loss: 0.1515254581658318		[learning rate: 0.0011144]
	Learning Rate: 0.0011144
	LOSS [training: 0.14381085636424387 | validation: 0.17456513732431758]
	TIME [epoch: 8.84 sec]
EPOCH 478/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13254898279773586		[learning rate: 0.0011118]
		[batch 20/20] avg loss: 0.14407172168924046		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.13831035224348814 | validation: 0.08145308651733092]
	TIME [epoch: 8.87 sec]
EPOCH 479/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12915701556720277		[learning rate: 0.0011066]
		[batch 20/20] avg loss: 0.13316068512701953		[learning rate: 0.001104]
	Learning Rate: 0.00110397
	LOSS [training: 0.1311588503471112 | validation: 0.19986733905472504]
	TIME [epoch: 8.84 sec]
EPOCH 480/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13973154775223418		[learning rate: 0.0011014]
		[batch 20/20] avg loss: 0.14011578287379595		[learning rate: 0.0010988]
	Learning Rate: 0.0010988
	LOSS [training: 0.1399236653130151 | validation: 0.12114836724789714]
	TIME [epoch: 8.84 sec]
EPOCH 481/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1192354754250173		[learning rate: 0.0010962]
		[batch 20/20] avg loss: 0.13344934692790572		[learning rate: 0.0010936]
	Learning Rate: 0.00109365
	LOSS [training: 0.12634241117646153 | validation: 0.07279690586025167]
	TIME [epoch: 8.84 sec]
EPOCH 482/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12068998752069351		[learning rate: 0.0010911]
		[batch 20/20] avg loss: 0.15536621088062041		[learning rate: 0.0010885]
	Learning Rate: 0.00108852
	LOSS [training: 0.13802809920065698 | validation: 0.12116384194162845]
	TIME [epoch: 8.87 sec]
EPOCH 483/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1433675607342982		[learning rate: 0.001086]
		[batch 20/20] avg loss: 0.14809142997139055		[learning rate: 0.0010834]
	Learning Rate: 0.00108342
	LOSS [training: 0.14572949535284438 | validation: 0.114007327565772]
	TIME [epoch: 8.85 sec]
EPOCH 484/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1905339096358724		[learning rate: 0.0010809]
		[batch 20/20] avg loss: 0.13012135828542107		[learning rate: 0.0010783]
	Learning Rate: 0.00107834
	LOSS [training: 0.16032763396064678 | validation: 0.12198096137909518]
	TIME [epoch: 8.85 sec]
EPOCH 485/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1576683936657764		[learning rate: 0.0010758]
		[batch 20/20] avg loss: 0.15486911705653258		[learning rate: 0.0010733]
	Learning Rate: 0.00107328
	LOSS [training: 0.1562687553611545 | validation: 0.08567387575066551]
	TIME [epoch: 8.84 sec]
EPOCH 486/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12464845153521623		[learning rate: 0.0010708]
		[batch 20/20] avg loss: 0.14733068206393618		[learning rate: 0.0010683]
	Learning Rate: 0.00106825
	LOSS [training: 0.13598956679957616 | validation: 0.07377838952914353]
	TIME [epoch: 8.86 sec]
EPOCH 487/500:
	Training over batches...
		[batch 10/20] avg loss: 0.13447400437237086		[learning rate: 0.0010657]
		[batch 20/20] avg loss: 0.1356990127679853		[learning rate: 0.0010632]
	Learning Rate: 0.00106324
	LOSS [training: 0.13508650857017807 | validation: 0.19472768176714603]
	TIME [epoch: 8.85 sec]
EPOCH 488/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1638528681761179		[learning rate: 0.0010607]
		[batch 20/20] avg loss: 0.12399440665944073		[learning rate: 0.0010583]
	Learning Rate: 0.00105826
	LOSS [training: 0.1439236374177793 | validation: 0.098969949893214]
	TIME [epoch: 8.85 sec]
EPOCH 489/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12494597320144174		[learning rate: 0.0010558]
		[batch 20/20] avg loss: 0.1200573347820146		[learning rate: 0.0010533]
	Learning Rate: 0.0010533
	LOSS [training: 0.12250165399172816 | validation: 0.10807627792669272]
	TIME [epoch: 8.84 sec]
EPOCH 490/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14619987385160269		[learning rate: 0.0010508]
		[batch 20/20] avg loss: 0.10791142870727714		[learning rate: 0.0010484]
	Learning Rate: 0.00104836
	LOSS [training: 0.12705565127943994 | validation: 0.05996078236799893]
	TIME [epoch: 8.86 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study1/model_tr_study1_r5_20240214_213319/states/model_tr_study1_490.pth
	Model improved!!!
EPOCH 491/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11624033692881622		[learning rate: 0.0010459]
		[batch 20/20] avg loss: 0.16238630548545097		[learning rate: 0.0010434]
	Learning Rate: 0.00104344
	LOSS [training: 0.13931332120713358 | validation: 0.27932804487827745]
	TIME [epoch: 8.86 sec]
EPOCH 492/500:
	Training over batches...
		[batch 10/20] avg loss: 0.1775343226341904		[learning rate: 0.001041]
		[batch 20/20] avg loss: 0.1100230626843216		[learning rate: 0.0010386]
	Learning Rate: 0.00103855
	LOSS [training: 0.14377869265925597 | validation: 0.09162734025506361]
	TIME [epoch: 8.85 sec]
EPOCH 493/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11160501474463232		[learning rate: 0.0010361]
		[batch 20/20] avg loss: 0.08789565900973632		[learning rate: 0.0010337]
	Learning Rate: 0.00103368
	LOSS [training: 0.09975033687718433 | validation: 0.08911359967668771]
	TIME [epoch: 8.85 sec]
EPOCH 494/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11504452505382778		[learning rate: 0.0010313]
		[batch 20/20] avg loss: 0.15014327980903716		[learning rate: 0.0010288]
	Learning Rate: 0.00102884
	LOSS [training: 0.1325939024314325 | validation: 0.18446934098798531]
	TIME [epoch: 8.84 sec]
EPOCH 495/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12331364734691586		[learning rate: 0.0010264]
		[batch 20/20] avg loss: 0.15179739328394098		[learning rate: 0.001024]
	Learning Rate: 0.00102401
	LOSS [training: 0.1375555203154284 | validation: 0.10927453040663687]
	TIME [epoch: 8.86 sec]
EPOCH 496/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12334228127436997		[learning rate: 0.0010216]
		[batch 20/20] avg loss: 0.13697658119418027		[learning rate: 0.0010192]
	Learning Rate: 0.00101921
	LOSS [training: 0.13015943123427515 | validation: 0.08281495859296635]
	TIME [epoch: 8.85 sec]
EPOCH 497/500:
	Training over batches...
		[batch 10/20] avg loss: 0.12568019164103514		[learning rate: 0.0010168]
		[batch 20/20] avg loss: 0.12336743995066604		[learning rate: 0.0010144]
	Learning Rate: 0.00101444
	LOSS [training: 0.12452381579585056 | validation: 0.11468440453913142]
	TIME [epoch: 8.84 sec]
EPOCH 498/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14007924092201973		[learning rate: 0.0010121]
		[batch 20/20] avg loss: 0.13260655249559158		[learning rate: 0.0010097]
	Learning Rate: 0.00100968
	LOSS [training: 0.13634289670880567 | validation: 0.10402803847520828]
	TIME [epoch: 8.84 sec]
EPOCH 499/500:
	Training over batches...
		[batch 10/20] avg loss: 0.11738040288925315		[learning rate: 0.0010073]
		[batch 20/20] avg loss: 0.13131017884382837		[learning rate: 0.0010049]
	Learning Rate: 0.00100495
	LOSS [training: 0.12434529086654071 | validation: 0.12519049437839222]
	TIME [epoch: 8.85 sec]
EPOCH 500/500:
	Training over batches...
		[batch 10/20] avg loss: 0.14202646536412994		[learning rate: 0.0010026]
		[batch 20/20] avg loss: 0.17206245271240087		[learning rate: 0.0010002]
	Learning Rate: 0.00100023
	LOSS [training: 0.1570444590382654 | validation: 0.08784579700288157]
	TIME [epoch: 8.86 sec]
Finished training in 4489.761 seconds.
