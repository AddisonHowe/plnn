Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r1', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3104824033

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.929962867507756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.929962867507756 | validation: 9.029545422790571]
	TIME [epoch: 54.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.976307180993457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.976307180993457 | validation: 9.032345872359917]
	TIME [epoch: 9.62 sec]
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.745105961704711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.745105961704711 | validation: 8.380363334422954]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.277669914086118		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.277669914086118 | validation: 7.98131985393223]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.784586078266214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.784586078266214 | validation: 7.923784548417353]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.641069976120626		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.641069976120626 | validation: 7.481278783780085]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.447564714249644		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.447564714249644 | validation: 7.2340549963950025]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.352620003204136		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.352620003204136 | validation: 7.219743353600669]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.15117342392209		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.15117342392209 | validation: 7.04190801678506]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.173970295292716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.173970295292716 | validation: 7.046537796627139]
	TIME [epoch: 9.61 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.135479631346993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.135479631346993 | validation: 7.148983551317392]
	TIME [epoch: 9.6 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.130078226205535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.130078226205535 | validation: 7.103945609307612]
	TIME [epoch: 9.6 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.094561157518987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.094561157518987 | validation: 6.984102294170416]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.932279863318085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.932279863318085 | validation: 6.7736928547116575]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.420552840183764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.420552840183764 | validation: 6.120619522520922]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.027336906660832		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.027336906660832 | validation: 5.970969929222024]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.951282763122924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.951282763122924 | validation: 5.884899095437338]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.833565933751054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.833565933751054 | validation: 5.768759808219568]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.852416294287822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.852416294287822 | validation: 5.497410072928438]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.450342128809787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.450342128809787 | validation: 5.05252143553856]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.094227454706278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.094227454706278 | validation: 4.290780312730909]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.846542463472544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.846542463472544 | validation: 4.009635212918156]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.675306242363166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.675306242363166 | validation: 3.4756415926114133]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4150945873573555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4150945873573555 | validation: 3.1722589279041995]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.838232708805549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.838232708805549 | validation: 3.435226316718689]
	TIME [epoch: 9.59 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4646293053922137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4646293053922137 | validation: 3.4866031629623837]
	TIME [epoch: 9.58 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.54648931018252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.54648931018252 | validation: 3.3984845338261858]
	TIME [epoch: 9.61 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.395259601438		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.395259601438 | validation: 3.8425862612105095]
	TIME [epoch: 9.59 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.347543097098041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.347543097098041 | validation: 3.098745453326243]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.083588630185919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.083588630185919 | validation: 2.914837278116561]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1948944812148747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1948944812148747 | validation: 2.927404952609267]
	TIME [epoch: 9.59 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.054734091926496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.054734091926496 | validation: 4.107786244714884]
	TIME [epoch: 9.59 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.661638683274488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.661638683274488 | validation: 2.8838778063276926]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.92458525269449		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.92458525269449 | validation: 2.5592474562595973]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_34.pth
	Model improved!!!
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.631010605962836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.631010605962836 | validation: 2.517569647319492]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1585775615957137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1585775615957137 | validation: 3.48245097128594]
	TIME [epoch: 9.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9531474332350904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9531474332350904 | validation: 2.5922547178712336]
	TIME [epoch: 9.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3741192876535715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3741192876535715 | validation: 4.449874127822063]
	TIME [epoch: 9.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3247878220240117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3247878220240117 | validation: 3.891972269919958]
	TIME [epoch: 9.6 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.255527772019834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.255527772019834 | validation: 2.594609727686539]
	TIME [epoch: 9.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.822547545037164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.822547545037164 | validation: 2.360721209168812]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5600346784464385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5600346784464385 | validation: 5.747812661782689]
	TIME [epoch: 9.6 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.01810684554072		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.01810684554072 | validation: 6.684277273604303]
	TIME [epoch: 9.61 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.0533777837540175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0533777837540175 | validation: 4.004840009407759]
	TIME [epoch: 9.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3633780710321006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3633780710321006 | validation: 2.859198802333633]
	TIME [epoch: 9.64 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.872830030596549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.872830030596549 | validation: 2.5924928297356153]
	TIME [epoch: 9.59 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7072683181930834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7072683181930834 | validation: 2.3623397390060363]
	TIME [epoch: 9.6 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.515150200715924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.515150200715924 | validation: 2.683293514447862]
	TIME [epoch: 9.61 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.01095405172684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.01095405172684 | validation: 2.635307952345776]
	TIME [epoch: 9.61 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2320911048650465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2320911048650465 | validation: 3.69514027017784]
	TIME [epoch: 9.58 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.986769854326252		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.986769854326252 | validation: 2.3411536172024623]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2737267480372103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2737267480372103 | validation: 3.0413484168702904]
	TIME [epoch: 9.61 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8789222318052787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8789222318052787 | validation: 2.7663660924755415]
	TIME [epoch: 9.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1140144613437215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1140144613437215 | validation: 2.605922627579924]
	TIME [epoch: 9.59 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8610345282272434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8610345282272434 | validation: 4.287651626688473]
	TIME [epoch: 9.61 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.677639655018101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.677639655018101 | validation: 3.2541438095415742]
	TIME [epoch: 9.63 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.600661845682363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.600661845682363 | validation: 2.097134658248786]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_57.pth
	Model improved!!!
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1692337781354936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1692337781354936 | validation: 1.785753195572124]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.150021797959611		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.150021797959611 | validation: 2.0530976710683935]
	TIME [epoch: 9.63 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3342532347901086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3342532347901086 | validation: 2.6438099412579765]
	TIME [epoch: 9.61 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1558423554429202		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1558423554429202 | validation: 1.7204327591837643]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_61.pth
	Model improved!!!
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.130382593145393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.130382593145393 | validation: 1.7897684637081899]
	TIME [epoch: 9.62 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6892965014911883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6892965014911883 | validation: 2.237327346903403]
	TIME [epoch: 9.61 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7710010083478536		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7710010083478536 | validation: 1.82672995107759]
	TIME [epoch: 9.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9981490968401787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9981490968401787 | validation: 1.696374949440593]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_65.pth
	Model improved!!!
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.902292565177173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.902292565177173 | validation: 1.3500987042547157]
	TIME [epoch: 9.63 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_66.pth
	Model improved!!!
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.426598883684361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.426598883684361 | validation: 1.343174824870751]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8499938839903767		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8499938839903767 | validation: 1.117513685404548]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_68.pth
	Model improved!!!
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.210502786585826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.210502786585826 | validation: 1.0585681151094872]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1710568953777307		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1710568953777307 | validation: 2.16418468147404]
	TIME [epoch: 9.61 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.021052138782232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.021052138782232 | validation: 1.1029851337048338]
	TIME [epoch: 9.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.095514149909203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.095514149909203 | validation: 2.8159436529618582]
	TIME [epoch: 9.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4919572762569486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4919572762569486 | validation: 1.0577434977335893]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2593623027234249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2593623027234249 | validation: 0.965120735552068]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3251205509735517		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3251205509735517 | validation: 1.1818963986118178]
	TIME [epoch: 9.59 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0857659655784282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0857659655784282 | validation: 0.9456892577422467]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.020649821607592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.020649821607592 | validation: 0.8788242357755914]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_77.pth
	Model improved!!!
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2313930841701466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2313930841701466 | validation: 1.0727621365585913]
	TIME [epoch: 9.61 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0231710793626505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0231710793626505 | validation: 0.848976893065912]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.162414433081902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.162414433081902 | validation: 1.048009315572479]
	TIME [epoch: 9.63 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3404447046810892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3404447046810892 | validation: 1.8098339592485229]
	TIME [epoch: 9.61 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.393542594802666		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.393542594802666 | validation: 0.9930503820713144]
	TIME [epoch: 9.61 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1228159489806189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1228159489806189 | validation: 0.9368039976467831]
	TIME [epoch: 9.62 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.250148396418594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.250148396418594 | validation: 1.9552441498875892]
	TIME [epoch: 9.61 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.428809857333231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.428809857333231 | validation: 1.0907605624266836]
	TIME [epoch: 9.61 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0903966791670519		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0903966791670519 | validation: 1.1735909062655432]
	TIME [epoch: 9.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1451994181222556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1451994181222556 | validation: 0.9645176565638082]
	TIME [epoch: 9.62 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5934495110380693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5934495110380693 | validation: 1.1691612501078772]
	TIME [epoch: 9.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2270304834206054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2270304834206054 | validation: 1.0589733209583656]
	TIME [epoch: 9.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.057011283956466		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.057011283956466 | validation: 1.343679599391063]
	TIME [epoch: 9.62 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1433140686330578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1433140686330578 | validation: 0.8101313817755249]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8402519706735594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8402519706735594 | validation: 0.7242555972429545]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4537375449564407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4537375449564407 | validation: 2.910394057801253]
	TIME [epoch: 9.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7482185199744036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7482185199744036 | validation: 2.408237707534512]
	TIME [epoch: 9.62 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.629055874574198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.629055874574198 | validation: 1.6460381441792253]
	TIME [epoch: 9.61 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.376093137636469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.376093137636469 | validation: 0.9450613049544834]
	TIME [epoch: 9.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9502109935235857		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9502109935235857 | validation: 0.9607110278466761]
	TIME [epoch: 9.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2387639177868568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2387639177868568 | validation: 1.0548676111485131]
	TIME [epoch: 9.63 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9909764581372281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9909764581372281 | validation: 1.1259382889147804]
	TIME [epoch: 9.61 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4942918179917597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4942918179917597 | validation: 1.3244020481550112]
	TIME [epoch: 9.61 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.235563495697329		[learning rate: 0.0099806]
	Learning Rate: 0.00998063
	LOSS [training: 1.235563495697329 | validation: 0.9087842379118177]
	TIME [epoch: 9.62 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0615956741696329		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 1.0615956741696329 | validation: 0.9307186840630807]
	TIME [epoch: 9.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3375566413613895		[learning rate: 0.0099324]
	Learning Rate: 0.00993236
	LOSS [training: 1.3375566413613895 | validation: 0.7428406984572362]
	TIME [epoch: 9.6 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8530165552426947		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 0.8530165552426947 | validation: 0.9444349983483662]
	TIME [epoch: 9.6 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9153298878670633		[learning rate: 0.0098843]
	Learning Rate: 0.00988433
	LOSS [training: 0.9153298878670633 | validation: 0.9606806997779858]
	TIME [epoch: 9.62 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8504490754287508		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 0.8504490754287508 | validation: 1.3886576621650522]
	TIME [epoch: 9.61 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3054394935337617		[learning rate: 0.0098365]
	Learning Rate: 0.00983653
	LOSS [training: 1.3054394935337617 | validation: 1.173664214022619]
	TIME [epoch: 9.61 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0039508154939016		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 1.0039508154939016 | validation: 0.7760724832460109]
	TIME [epoch: 9.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0581117870674948		[learning rate: 0.009789]
	Learning Rate: 0.00978897
	LOSS [training: 1.0581117870674948 | validation: 1.4344835860096072]
	TIME [epoch: 9.61 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9329229326354023		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 0.9329229326354023 | validation: 0.9835972013305164]
	TIME [epoch: 9.6 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9030173851403133		[learning rate: 0.0097416]
	Learning Rate: 0.00974163
	LOSS [training: 0.9030173851403133 | validation: 0.7862441879802111]
	TIME [epoch: 9.59 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9083356012275065		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 0.9083356012275065 | validation: 0.9179988420388054]
	TIME [epoch: 9.62 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7926205723817279		[learning rate: 0.0096945]
	Learning Rate: 0.00969452
	LOSS [training: 0.7926205723817279 | validation: 0.7212082087615527]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5174191298975166		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 2.5174191298975166 | validation: 4.425489098198088]
	TIME [epoch: 9.61 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0916743831221196		[learning rate: 0.0096476]
	Learning Rate: 0.00964764
	LOSS [training: 3.0916743831221196 | validation: 0.9150364284308896]
	TIME [epoch: 9.62 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4177593411416018		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 1.4177593411416018 | validation: 0.862666665242637]
	TIME [epoch: 9.62 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.972977224341801		[learning rate: 0.009601]
	Learning Rate: 0.00960098
	LOSS [training: 0.972977224341801 | validation: 0.8348630537744341]
	TIME [epoch: 9.6 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.788935606758028		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 0.788935606758028 | validation: 2.1825365627769755]
	TIME [epoch: 9.6 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0955705603880261		[learning rate: 0.0095546]
	Learning Rate: 0.00955456
	LOSS [training: 1.0955705603880261 | validation: 0.7698298376582108]
	TIME [epoch: 9.61 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.528848784516455		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 1.528848784516455 | validation: 1.2184657854871799]
	TIME [epoch: 9.62 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9816049568701675		[learning rate: 0.0095084]
	Learning Rate: 0.00950835
	LOSS [training: 1.9816049568701675 | validation: 2.3063764119845223]
	TIME [epoch: 9.61 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6358911060180406		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 2.6358911060180406 | validation: 2.12012359350337]
	TIME [epoch: 9.6 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.574770289253054		[learning rate: 0.0094624]
	Learning Rate: 0.00946237
	LOSS [training: 2.574770289253054 | validation: 2.0664261489205513]
	TIME [epoch: 9.63 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4906286601918763		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 2.4906286601918763 | validation: 0.9758948355120498]
	TIME [epoch: 9.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9624727083137126		[learning rate: 0.0094166]
	Learning Rate: 0.00941661
	LOSS [training: 0.9624727083137126 | validation: 1.2607079576202231]
	TIME [epoch: 9.6 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0809293083515765		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 2.0809293083515765 | validation: 1.50708653652561]
	TIME [epoch: 9.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8779214556421162		[learning rate: 0.0093711]
	Learning Rate: 0.00937108
	LOSS [training: 1.8779214556421162 | validation: 1.993422458304392]
	TIME [epoch: 9.63 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.800906045629446		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.800906045629446 | validation: 1.8976124238607082]
	TIME [epoch: 9.6 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6620403735808018		[learning rate: 0.0093258]
	Learning Rate: 0.00932576
	LOSS [training: 1.6620403735808018 | validation: 0.9694228823760268]
	TIME [epoch: 9.61 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5387172270637985		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 1.5387172270637985 | validation: 1.6904737030785402]
	TIME [epoch: 9.63 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3004537440678197		[learning rate: 0.0092807]
	Learning Rate: 0.00928066
	LOSS [training: 1.3004537440678197 | validation: 0.7958960856329769]
	TIME [epoch: 9.61 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0666155934491477		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 1.0666155934491477 | validation: 0.8343459453561016]
	TIME [epoch: 9.61 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9664932797613399		[learning rate: 0.0092358]
	Learning Rate: 0.00923578
	LOSS [training: 0.9664932797613399 | validation: 1.4661080575509624]
	TIME [epoch: 9.6 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3953702868184579		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 1.3953702868184579 | validation: 1.0026796038634769]
	TIME [epoch: 9.62 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2094717819610978		[learning rate: 0.0091911]
	Learning Rate: 0.00919112
	LOSS [training: 1.2094717819610978 | validation: 0.8578022447229878]
	TIME [epoch: 9.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3778755523063002		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.3778755523063002 | validation: 0.7679208079970067]
	TIME [epoch: 9.6 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9708782177002304		[learning rate: 0.0091467]
	Learning Rate: 0.00914667
	LOSS [training: 0.9708782177002304 | validation: 0.64688419414882]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7079052881439976		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 0.7079052881439976 | validation: 0.634875673062305]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9527167083690461		[learning rate: 0.0091024]
	Learning Rate: 0.00910244
	LOSS [training: 0.9527167083690461 | validation: 0.5885694663315547]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8321296829181779		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 0.8321296829181779 | validation: 1.1169713389534]
	TIME [epoch: 9.59 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.442811730717382		[learning rate: 0.0090584]
	Learning Rate: 0.00905842
	LOSS [training: 1.442811730717382 | validation: 2.51062986364649]
	TIME [epoch: 9.62 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.720595665731338		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.720595665731338 | validation: 1.916399682572795]
	TIME [epoch: 9.59 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.153730442427359		[learning rate: 0.0090146]
	Learning Rate: 0.00901462
	LOSS [training: 1.153730442427359 | validation: 0.7367250742934717]
	TIME [epoch: 9.6 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8642312124375323		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 0.8642312124375323 | validation: 1.0540404592290467]
	TIME [epoch: 9.61 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8653781091270586		[learning rate: 0.008971]
	Learning Rate: 0.00897103
	LOSS [training: 0.8653781091270586 | validation: 0.6297909881693188]
	TIME [epoch: 9.63 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7230330858545486		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 0.7230330858545486 | validation: 0.590570778900042]
	TIME [epoch: 9.6 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8011601551014694		[learning rate: 0.0089276]
	Learning Rate: 0.00892764
	LOSS [training: 0.8011601551014694 | validation: 0.7311561003675504]
	TIME [epoch: 9.59 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9573503820104341		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 0.9573503820104341 | validation: 0.7710900464804904]
	TIME [epoch: 9.61 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0663708843171176		[learning rate: 0.0088845]
	Learning Rate: 0.00888447
	LOSS [training: 1.0663708843171176 | validation: 0.6217307328159749]
	TIME [epoch: 9.58 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.711328021325839		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 0.711328021325839 | validation: 0.6983200187138803]
	TIME [epoch: 9.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.800165114914242		[learning rate: 0.0088415]
	Learning Rate: 0.00884151
	LOSS [training: 1.800165114914242 | validation: 0.7540532392263398]
	TIME [epoch: 9.59 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8007062053550282		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 0.8007062053550282 | validation: 0.8588357739180157]
	TIME [epoch: 9.62 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8701791804306815		[learning rate: 0.0087988]
	Learning Rate: 0.00879875
	LOSS [training: 0.8701791804306815 | validation: 1.4120228197807239]
	TIME [epoch: 9.59 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9555835479593844		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 0.9555835479593844 | validation: 1.0332981247662996]
	TIME [epoch: 9.59 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0135615504349014		[learning rate: 0.0087562]
	Learning Rate: 0.0087562
	LOSS [training: 2.0135615504349014 | validation: 4.750535033277673]
	TIME [epoch: 9.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6732351829976837		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 3.6732351829976837 | validation: 4.5816863582284535]
	TIME [epoch: 9.61 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.346546449543245		[learning rate: 0.0087139]
	Learning Rate: 0.00871386
	LOSS [training: 3.346546449543245 | validation: 0.8504517865696832]
	TIME [epoch: 9.59 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4461490484828934		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 1.4461490484828934 | validation: 0.9809627108275493]
	TIME [epoch: 9.61 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2398676591030025		[learning rate: 0.0086717]
	Learning Rate: 0.00867172
	LOSS [training: 1.2398676591030025 | validation: 0.8956489145579981]
	TIME [epoch: 9.62 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8782734002253241		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 0.8782734002253241 | validation: 0.939278508001247]
	TIME [epoch: 9.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9007987107019101		[learning rate: 0.0086298]
	Learning Rate: 0.00862979
	LOSS [training: 0.9007987107019101 | validation: 0.923415402818207]
	TIME [epoch: 9.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7686636761844051		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 0.7686636761844051 | validation: 0.8625603044521757]
	TIME [epoch: 9.59 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7616265351588538		[learning rate: 0.0085881]
	Learning Rate: 0.00858805
	LOSS [training: 0.7616265351588538 | validation: 0.7842822215597471]
	TIME [epoch: 9.61 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8310936083526632		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 0.8310936083526632 | validation: 0.890486724851882]
	TIME [epoch: 9.59 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7796001143728493		[learning rate: 0.0085465]
	Learning Rate: 0.00854652
	LOSS [training: 0.7796001143728493 | validation: 0.8040820573020035]
	TIME [epoch: 9.59 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.46102169209991		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.46102169209991 | validation: 0.8517781277414963]
	TIME [epoch: 9.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8158646299949487		[learning rate: 0.0085052]
	Learning Rate: 0.00850519
	LOSS [training: 0.8158646299949487 | validation: 0.8202115856319233]
	TIME [epoch: 9.59 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.050320203569549		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 1.050320203569549 | validation: 0.7421096286703807]
	TIME [epoch: 9.59 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8646651874428078		[learning rate: 0.0084641]
	Learning Rate: 0.00846406
	LOSS [training: 0.8646651874428078 | validation: 0.945849974071512]
	TIME [epoch: 9.59 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9677250391551275		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.9677250391551275 | validation: 1.031077302522435]
	TIME [epoch: 9.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.79142796436123		[learning rate: 0.0084231]
	Learning Rate: 0.00842313
	LOSS [training: 0.79142796436123 | validation: 0.6304409467596159]
	TIME [epoch: 9.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7942158101880081		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.7942158101880081 | validation: 0.7827464500779389]
	TIME [epoch: 9.58 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8455324913500046		[learning rate: 0.0083824]
	Learning Rate: 0.0083824
	LOSS [training: 0.8455324913500046 | validation: 1.0834475419672789]
	TIME [epoch: 9.59 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2475494093235733		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.2475494093235733 | validation: 0.7343909667791587]
	TIME [epoch: 9.61 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7727078748220317		[learning rate: 0.0083419]
	Learning Rate: 0.00834186
	LOSS [training: 0.7727078748220317 | validation: 0.8166991636727869]
	TIME [epoch: 9.58 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8090261733654328		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 0.8090261733654328 | validation: 1.682396074023059]
	TIME [epoch: 9.58 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4059947394406591		[learning rate: 0.0083015]
	Learning Rate: 0.00830153
	LOSS [training: 1.4059947394406591 | validation: 0.9753951147048113]
	TIME [epoch: 9.62 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7134869514795763		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 0.7134869514795763 | validation: 0.6489547486916843]
	TIME [epoch: 9.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8719144121243583		[learning rate: 0.0082614]
	Learning Rate: 0.00826138
	LOSS [training: 0.8719144121243583 | validation: 0.9324897874903314]
	TIME [epoch: 9.59 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8945367235190916		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.8945367235190916 | validation: 0.6168696563513661]
	TIME [epoch: 9.59 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5899359559089694		[learning rate: 0.0082214]
	Learning Rate: 0.00822143
	LOSS [training: 0.5899359559089694 | validation: 0.7339209169930782]
	TIME [epoch: 9.61 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7058628752272365		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 0.7058628752272365 | validation: 0.5949494883850421]
	TIME [epoch: 9.59 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.754840312864909		[learning rate: 0.0081817]
	Learning Rate: 0.00818167
	LOSS [training: 0.754840312864909 | validation: 0.7013395185746992]
	TIME [epoch: 9.59 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8201285733128755		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.8201285733128755 | validation: 0.653424739950674]
	TIME [epoch: 9.59 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9449702296003684		[learning rate: 0.0081421]
	Learning Rate: 0.00814211
	LOSS [training: 0.9449702296003684 | validation: 1.1107035044278302]
	TIME [epoch: 9.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3727863422739928		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 1.3727863422739928 | validation: 0.8500075326420882]
	TIME [epoch: 9.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1039190291602423		[learning rate: 0.0081027]
	Learning Rate: 0.00810273
	LOSS [training: 1.1039190291602423 | validation: 1.349417729528374]
	TIME [epoch: 9.58 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4956079071637545		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 1.4956079071637545 | validation: 1.3989259232599733]
	TIME [epoch: 9.61 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0653217594789148		[learning rate: 0.0080636]
	Learning Rate: 0.00806355
	LOSS [training: 1.0653217594789148 | validation: 0.9824582294790989]
	TIME [epoch: 9.6 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2192766854324428		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 1.2192766854324428 | validation: 1.9137968337136502]
	TIME [epoch: 9.6 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.343039024546449		[learning rate: 0.0080246]
	Learning Rate: 0.00802456
	LOSS [training: 1.343039024546449 | validation: 0.7385387259369435]
	TIME [epoch: 9.59 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7556405255169066		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 0.7556405255169066 | validation: 0.75893933436343]
	TIME [epoch: 9.62 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7452947732011532		[learning rate: 0.0079858]
	Learning Rate: 0.00798575
	LOSS [training: 0.7452947732011532 | validation: 0.6215728316214546]
	TIME [epoch: 9.59 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6807389480028533		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.6807389480028533 | validation: 0.7373550364925799]
	TIME [epoch: 9.61 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6471963544779076		[learning rate: 0.0079471]
	Learning Rate: 0.00794713
	LOSS [training: 0.6471963544779076 | validation: 0.8131534078890428]
	TIME [epoch: 9.61 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7181977596311117		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 0.7181977596311117 | validation: 0.7602570820419138]
	TIME [epoch: 9.61 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7154924092859809		[learning rate: 0.0079087]
	Learning Rate: 0.0079087
	LOSS [training: 0.7154924092859809 | validation: 1.1106747937405776]
	TIME [epoch: 9.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8065204703952737		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 0.8065204703952737 | validation: 2.1229469222777535]
	TIME [epoch: 9.58 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.82433541062477		[learning rate: 0.0078705]
	Learning Rate: 0.00787046
	LOSS [training: 0.82433541062477 | validation: 0.5942802041433928]
	TIME [epoch: 9.61 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7871099971035734		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 0.7871099971035734 | validation: 0.6099643560026429]
	TIME [epoch: 9.84 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.770742222569941		[learning rate: 0.0078324]
	Learning Rate: 0.0078324
	LOSS [training: 0.770742222569941 | validation: 0.7101146110935875]
	TIME [epoch: 9.59 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6008617577050133		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 0.6008617577050133 | validation: 0.7994901139322511]
	TIME [epoch: 9.59 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7041228702928144		[learning rate: 0.0077945]
	Learning Rate: 0.00779452
	LOSS [training: 0.7041228702928144 | validation: 0.5642511701541489]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8729896113015059		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 0.8729896113015059 | validation: 1.078764346619332]
	TIME [epoch: 9.59 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9373664926057106		[learning rate: 0.0077568]
	Learning Rate: 0.00775683
	LOSS [training: 0.9373664926057106 | validation: 1.4151318322241506]
	TIME [epoch: 9.59 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5340455400919106		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 3.5340455400919106 | validation: 3.184287350569198]
	TIME [epoch: 9.61 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2082227326313126		[learning rate: 0.0077193]
	Learning Rate: 0.00771932
	LOSS [training: 2.2082227326313126 | validation: 0.6468710092728347]
	TIME [epoch: 9.59 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6887803254564303		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.6887803254564303 | validation: 0.6092948882016778]
	TIME [epoch: 9.59 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6785949202408389		[learning rate: 0.007682]
	Learning Rate: 0.00768199
	LOSS [training: 0.6785949202408389 | validation: 0.5386161969058912]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_209.pth
	Model improved!!!
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5658666332665463		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 0.5658666332665463 | validation: 0.6839446080866699]
	TIME [epoch: 9.61 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6915636762132459		[learning rate: 0.0076448]
	Learning Rate: 0.00764484
	LOSS [training: 0.6915636762132459 | validation: 0.7098239895161197]
	TIME [epoch: 9.59 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6214559010653072		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.6214559010653072 | validation: 0.8235527038073841]
	TIME [epoch: 9.59 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7905245896335242		[learning rate: 0.0076079]
	Learning Rate: 0.00760787
	LOSS [training: 1.7905245896335242 | validation: 2.0408670840692413]
	TIME [epoch: 9.61 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4666586129081107		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 2.4666586129081107 | validation: 2.0127754706216514]
	TIME [epoch: 9.59 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1094494785578597		[learning rate: 0.0075711]
	Learning Rate: 0.00757108
	LOSS [training: 2.1094494785578597 | validation: 1.6777337953989866]
	TIME [epoch: 9.59 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.458385575666046		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 2.458385575666046 | validation: 1.9592738922214836]
	TIME [epoch: 9.59 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4466223556996978		[learning rate: 0.0075345]
	Learning Rate: 0.00753447
	LOSS [training: 2.4466223556996978 | validation: 1.9055452697668875]
	TIME [epoch: 9.61 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3713164972439325		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 2.3713164972439325 | validation: 1.93475784919094]
	TIME [epoch: 9.59 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3660172568217264		[learning rate: 0.007498]
	Learning Rate: 0.00749803
	LOSS [training: 2.3660172568217264 | validation: 1.918766806112931]
	TIME [epoch: 9.59 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4964346041356904		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 1.4964346041356904 | validation: 0.7329837444853027]
	TIME [epoch: 9.6 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9595422999153275		[learning rate: 0.0074618]
	Learning Rate: 0.00746177
	LOSS [training: 0.9595422999153275 | validation: 0.9646376576371134]
	TIME [epoch: 9.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8780644884849232		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.8780644884849232 | validation: 0.653183750394635]
	TIME [epoch: 9.59 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.686382516090169		[learning rate: 0.0074257]
	Learning Rate: 0.00742569
	LOSS [training: 0.686382516090169 | validation: 0.699132494064256]
	TIME [epoch: 9.58 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6258206751739837		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.6258206751739837 | validation: 0.4720697816123451]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5829974283861883		[learning rate: 0.0073898]
	Learning Rate: 0.00738978
	LOSS [training: 0.5829974283861883 | validation: 0.5738419021261412]
	TIME [epoch: 9.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.635570162771864		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.635570162771864 | validation: 0.7904564683298929]
	TIME [epoch: 9.59 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9707737465684056		[learning rate: 0.007354]
	Learning Rate: 0.00735405
	LOSS [training: 0.9707737465684056 | validation: 0.6474215221583802]
	TIME [epoch: 9.59 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.694276141108347		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.694276141108347 | validation: 0.4461682821327409]
	TIME [epoch: 9.62 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_228.pth
	Model improved!!!
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6341581769656777		[learning rate: 0.0073185]
	Learning Rate: 0.00731848
	LOSS [training: 0.6341581769656777 | validation: 0.6127488633197642]
	TIME [epoch: 9.59 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6446474115173731		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.6446474115173731 | validation: 0.6807590605946452]
	TIME [epoch: 9.59 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.198754845441129		[learning rate: 0.0072831]
	Learning Rate: 0.00728309
	LOSS [training: 2.198754845441129 | validation: 1.9895156526722269]
	TIME [epoch: 9.61 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.476329360644895		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 2.476329360644895 | validation: 1.963590995161333]
	TIME [epoch: 9.6 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.481794540797647		[learning rate: 0.0072479]
	Learning Rate: 0.00724787
	LOSS [training: 2.481794540797647 | validation: 2.164486248622555]
	TIME [epoch: 9.58 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4677793406355315		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 2.4677793406355315 | validation: 1.9098507888218046]
	TIME [epoch: 9.59 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.351383800635324		[learning rate: 0.0072128]
	Learning Rate: 0.00721282
	LOSS [training: 2.351383800635324 | validation: 1.9333043778072048]
	TIME [epoch: 9.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3582222722554484		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 2.3582222722554484 | validation: 2.0814335426700565]
	TIME [epoch: 9.59 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.383827479599205		[learning rate: 0.0071779]
	Learning Rate: 0.00717794
	LOSS [training: 2.383827479599205 | validation: 1.8652795986488344]
	TIME [epoch: 9.59 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3657095927083533		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 2.3657095927083533 | validation: 1.9511146278499802]
	TIME [epoch: 9.61 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3574216018525584		[learning rate: 0.0071432]
	Learning Rate: 0.00714323
	LOSS [training: 2.3574216018525584 | validation: 1.9466120293142228]
	TIME [epoch: 9.6 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3496607913931173		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 2.3496607913931173 | validation: 1.9334879947018624]
	TIME [epoch: 9.59 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.391442015277404		[learning rate: 0.0071087]
	Learning Rate: 0.00710869
	LOSS [training: 2.391442015277404 | validation: 1.850081327744112]
	TIME [epoch: 9.59 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.098358971421687		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 2.098358971421687 | validation: 1.0351135335250334]
	TIME [epoch: 9.62 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1374093449920593		[learning rate: 0.0070743]
	Learning Rate: 0.00707431
	LOSS [training: 1.1374093449920593 | validation: 0.891832267137546]
	TIME [epoch: 9.59 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.941004685675091		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.941004685675091 | validation: 0.7718135383312251]
	TIME [epoch: 9.59 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.681996000351151		[learning rate: 0.0070401]
	Learning Rate: 0.0070401
	LOSS [training: 0.681996000351151 | validation: 0.5941830967058361]
	TIME [epoch: 9.59 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7540597442641879		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.7540597442641879 | validation: 1.0220896295022868]
	TIME [epoch: 9.62 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9818510976704605		[learning rate: 0.0070061]
	Learning Rate: 0.00700606
	LOSS [training: 0.9818510976704605 | validation: 1.52818216358159]
	TIME [epoch: 9.6 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9850599141055756		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.9850599141055756 | validation: 0.554691158183493]
	TIME [epoch: 9.59 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7329933014419131		[learning rate: 0.0069722]
	Learning Rate: 0.00697218
	LOSS [training: 0.7329933014419131 | validation: 0.6985305436541023]
	TIME [epoch: 9.59 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6334004276904304		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.6334004276904304 | validation: 0.3910128655573007]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_250.pth
	Model improved!!!
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6140373614677771		[learning rate: 0.0069385]
	Learning Rate: 0.00693846
	LOSS [training: 0.6140373614677771 | validation: 0.4771160349648882]
	TIME [epoch: 9.59 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6589150202907943		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.6589150202907943 | validation: 0.630143823601077]
	TIME [epoch: 9.59 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6183104424108299		[learning rate: 0.0069049]
	Learning Rate: 0.00690491
	LOSS [training: 0.6183104424108299 | validation: 0.46244620518822616]
	TIME [epoch: 9.61 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8549214328072365		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.8549214328072365 | validation: 0.8949538509517007]
	TIME [epoch: 9.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.700686167483586		[learning rate: 0.0068715]
	Learning Rate: 0.00687152
	LOSS [training: 0.700686167483586 | validation: 0.5175188836968664]
	TIME [epoch: 9.59 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5453714338801863		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.5453714338801863 | validation: 0.7979943317854291]
	TIME [epoch: 9.6 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7543820644640269		[learning rate: 0.0068383]
	Learning Rate: 0.00683829
	LOSS [training: 0.7543820644640269 | validation: 0.880600073590786]
	TIME [epoch: 9.62 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7409543094616575		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.7409543094616575 | validation: 0.42971240063710014]
	TIME [epoch: 9.59 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7578436888217336		[learning rate: 0.0068052]
	Learning Rate: 0.00680522
	LOSS [training: 0.7578436888217336 | validation: 1.7664170068519238]
	TIME [epoch: 9.58 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4577916268310447		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.4577916268310447 | validation: 0.5436711226010543]
	TIME [epoch: 9.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6622779867836133		[learning rate: 0.0067723]
	Learning Rate: 0.00677231
	LOSS [training: 0.6622779867836133 | validation: 0.5005535878955412]
	TIME [epoch: 9.59 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8856246940345451		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.8856246940345451 | validation: 0.665703122177176]
	TIME [epoch: 9.59 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7204348194612419		[learning rate: 0.0067396]
	Learning Rate: 0.00673956
	LOSS [training: 0.7204348194612419 | validation: 0.7562573884584015]
	TIME [epoch: 9.59 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7169437067217082		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.7169437067217082 | validation: 0.7071378347454723]
	TIME [epoch: 9.61 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8474043367842128		[learning rate: 0.006707]
	Learning Rate: 0.00670697
	LOSS [training: 0.8474043367842128 | validation: 0.7374796702056889]
	TIME [epoch: 9.59 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7390854762468448		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.7390854762468448 | validation: 0.46204438063422554]
	TIME [epoch: 9.59 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5180213998930397		[learning rate: 0.0066745]
	Learning Rate: 0.00667454
	LOSS [training: 0.5180213998930397 | validation: 0.4294835249353071]
	TIME [epoch: 9.6 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5326306292909487		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.5326306292909487 | validation: 0.5341841154509561]
	TIME [epoch: 9.59 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5923297381309847		[learning rate: 0.0066423]
	Learning Rate: 0.00664226
	LOSS [training: 0.5923297381309847 | validation: 0.6350620360963276]
	TIME [epoch: 9.6 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8597605575364959		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.8597605575364959 | validation: 0.7540625259206319]
	TIME [epoch: 9.59 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9212377650357506		[learning rate: 0.0066101]
	Learning Rate: 0.00661014
	LOSS [training: 0.9212377650357506 | validation: 0.6395723274713151]
	TIME [epoch: 9.62 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6490787804711353		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.6490787804711353 | validation: 1.0452991866772143]
	TIME [epoch: 9.6 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9703536008397966		[learning rate: 0.0065782]
	Learning Rate: 0.00657817
	LOSS [training: 0.9703536008397966 | validation: 0.845793674411873]
	TIME [epoch: 9.59 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7507035876011422		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.7507035876011422 | validation: 0.5468102646952576]
	TIME [epoch: 9.59 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0826299247705684		[learning rate: 0.0065464]
	Learning Rate: 0.00654636
	LOSS [training: 1.0826299247705684 | validation: 0.8945453605863773]
	TIME [epoch: 9.62 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0196339558855283		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.0196339558855283 | validation: 0.7505989410639363]
	TIME [epoch: 9.59 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6645293760113513		[learning rate: 0.0065147]
	Learning Rate: 0.0065147
	LOSS [training: 0.6645293760113513 | validation: 0.5936792812157694]
	TIME [epoch: 9.59 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5432564954679753		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.5432564954679753 | validation: 0.4487199504545397]
	TIME [epoch: 9.6 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6205302040994448		[learning rate: 0.0064832]
	Learning Rate: 0.0064832
	LOSS [training: 0.6205302040994448 | validation: 0.6827588516258045]
	TIME [epoch: 9.6 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7703337788883771		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.7703337788883771 | validation: 0.8052805090851399]
	TIME [epoch: 9.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9450616641089222		[learning rate: 0.0064518]
	Learning Rate: 0.00645185
	LOSS [training: 0.9450616641089222 | validation: 0.583335915629528]
	TIME [epoch: 9.59 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5771717792682073		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.5771717792682073 | validation: 0.6196594851228723]
	TIME [epoch: 9.62 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3346108775576078		[learning rate: 0.0064206]
	Learning Rate: 0.00642065
	LOSS [training: 1.3346108775576078 | validation: 1.483029426550346]
	TIME [epoch: 9.59 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0467511142602899		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 1.0467511142602899 | validation: 0.6794663809257184]
	TIME [epoch: 9.59 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6993662771099161		[learning rate: 0.0063896]
	Learning Rate: 0.0063896
	LOSS [training: 0.6993662771099161 | validation: 0.675251096784632]
	TIME [epoch: 9.58 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3778614688036561		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 1.3778614688036561 | validation: 0.8782289249479002]
	TIME [epoch: 9.62 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9432857888291182		[learning rate: 0.0063587]
	Learning Rate: 0.0063587
	LOSS [training: 0.9432857888291182 | validation: 0.6675542512481937]
	TIME [epoch: 9.6 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6526152520810999		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.6526152520810999 | validation: 0.6807485494484835]
	TIME [epoch: 9.59 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.793842277499954		[learning rate: 0.006328]
	Learning Rate: 0.00632795
	LOSS [training: 0.793842277499954 | validation: 0.47088349101825644]
	TIME [epoch: 9.62 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5278442159544625		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.5278442159544625 | validation: 0.49358114193782454]
	TIME [epoch: 9.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48265706516590406		[learning rate: 0.0062974]
	Learning Rate: 0.00629735
	LOSS [training: 0.48265706516590406 | validation: 0.5534737834074628]
	TIME [epoch: 9.59 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.513470203990362		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.513470203990362 | validation: 0.6906928653335175]
	TIME [epoch: 9.59 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6298715028906855		[learning rate: 0.0062669]
	Learning Rate: 0.0062669
	LOSS [training: 0.6298715028906855 | validation: 0.3974489493367559]
	TIME [epoch: 9.62 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5014409439538723		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.5014409439538723 | validation: 0.500734459986974]
	TIME [epoch: 9.59 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5947386949504876		[learning rate: 0.0062366]
	Learning Rate: 0.00623659
	LOSS [training: 0.5947386949504876 | validation: 1.0905180093689855]
	TIME [epoch: 9.59 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0832960919361079		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 1.0832960919361079 | validation: 1.3856014222716397]
	TIME [epoch: 9.59 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7191028707441636		[learning rate: 0.0062064]
	Learning Rate: 0.00620643
	LOSS [training: 0.7191028707441636 | validation: 0.4814123085768956]
	TIME [epoch: 9.6 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7563143146065379		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.7563143146065379 | validation: 1.1459096499550572]
	TIME [epoch: 9.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3224953731644618		[learning rate: 0.0061764]
	Learning Rate: 0.00617642
	LOSS [training: 1.3224953731644618 | validation: 0.7970733745078005]
	TIME [epoch: 9.59 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7213523585011077		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.7213523585011077 | validation: 0.5183145223238335]
	TIME [epoch: 9.61 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5165069780628263		[learning rate: 0.0061466]
	Learning Rate: 0.00614655
	LOSS [training: 0.5165069780628263 | validation: 0.53989657281339]
	TIME [epoch: 9.59 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6140776217276462		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.6140776217276462 | validation: 0.6122156149532761]
	TIME [epoch: 9.58 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5452625973383329		[learning rate: 0.0061168]
	Learning Rate: 0.00611683
	LOSS [training: 0.5452625973383329 | validation: 0.4342508130439196]
	TIME [epoch: 9.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5626510962437923		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.5626510962437923 | validation: 0.5025155849802374]
	TIME [epoch: 9.61 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6157407757514992		[learning rate: 0.0060872]
	Learning Rate: 0.00608725
	LOSS [training: 0.6157407757514992 | validation: 1.50217754715291]
	TIME [epoch: 9.6 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2436672499841215		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 1.2436672499841215 | validation: 0.7987607403240743]
	TIME [epoch: 9.59 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6969236544218841		[learning rate: 0.0060578]
	Learning Rate: 0.00605781
	LOSS [training: 0.6969236544218841 | validation: 0.6622170923180809]
	TIME [epoch: 9.61 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6957137907637548		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.6957137907637548 | validation: 0.6740184742637273]
	TIME [epoch: 9.6 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6185171808356732		[learning rate: 0.0060285]
	Learning Rate: 0.00602852
	LOSS [training: 0.6185171808356732 | validation: 0.5314664057713727]
	TIME [epoch: 9.59 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.918913620659664		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.918913620659664 | validation: 0.7569507922257228]
	TIME [epoch: 9.59 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5702737436852255		[learning rate: 0.0059994]
	Learning Rate: 0.00599936
	LOSS [training: 0.5702737436852255 | validation: 0.4870411263666789]
	TIME [epoch: 9.61 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5799879650175908		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.5799879650175908 | validation: 0.5391552367476892]
	TIME [epoch: 9.59 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5492476437192723		[learning rate: 0.0059704]
	Learning Rate: 0.00597035
	LOSS [training: 0.5492476437192723 | validation: 0.47246626371766043]
	TIME [epoch: 9.59 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5552778254714841		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.5552778254714841 | validation: 0.4923901721389794]
	TIME [epoch: 9.59 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5114891655497877		[learning rate: 0.0059415]
	Learning Rate: 0.00594148
	LOSS [training: 0.5114891655497877 | validation: 0.4390548131028356]
	TIME [epoch: 9.61 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5164454943921536		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.5164454943921536 | validation: 0.5529224774505437]
	TIME [epoch: 9.59 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0039711810771323		[learning rate: 0.0059127]
	Learning Rate: 0.00591275
	LOSS [training: 1.0039711810771323 | validation: 1.373131499766019]
	TIME [epoch: 9.58 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9471970157383687		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.9471970157383687 | validation: 0.5308800640949252]
	TIME [epoch: 9.6 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8248848095857377		[learning rate: 0.0058842]
	Learning Rate: 0.00588416
	LOSS [training: 0.8248848095857377 | validation: 0.7341030375562022]
	TIME [epoch: 9.58 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6800710467578011		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.6800710467578011 | validation: 0.4871280302781608]
	TIME [epoch: 9.59 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6999762935452518		[learning rate: 0.0058557]
	Learning Rate: 0.0058557
	LOSS [training: 0.6999762935452518 | validation: 0.3876402055907688]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_321.pth
	Model improved!!!
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6502438880350698		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.6502438880350698 | validation: 0.690779104103051]
	TIME [epoch: 9.6 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6226486341327668		[learning rate: 0.0058274]
	Learning Rate: 0.00582738
	LOSS [training: 0.6226486341327668 | validation: 0.39718857669901464]
	TIME [epoch: 9.59 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6502012275967652		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.6502012275967652 | validation: 0.8179313706961954]
	TIME [epoch: 9.58 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7000459012272486		[learning rate: 0.0057992]
	Learning Rate: 0.0057992
	LOSS [training: 0.7000459012272486 | validation: 0.9708179575758737]
	TIME [epoch: 9.6 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9410234860631241		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 1.9410234860631241 | validation: 1.0736285265296175]
	TIME [epoch: 9.6 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7737758059838342		[learning rate: 0.0057712]
	Learning Rate: 0.00577116
	LOSS [training: 0.7737758059838342 | validation: 0.5629414618606746]
	TIME [epoch: 9.59 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6716455531185828		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.6716455531185828 | validation: 0.4591087472404886]
	TIME [epoch: 9.58 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.50078397015958		[learning rate: 0.0057433]
	Learning Rate: 0.00574325
	LOSS [training: 0.50078397015958 | validation: 0.6244998507427624]
	TIME [epoch: 9.6 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5108570303029446		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.5108570303029446 | validation: 0.6656101690030107]
	TIME [epoch: 9.59 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0127042622035254		[learning rate: 0.0057155]
	Learning Rate: 0.00571548
	LOSS [training: 1.0127042622035254 | validation: 0.5649104268561106]
	TIME [epoch: 9.59 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5745460888643689		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.5745460888643689 | validation: 0.3569458593799185]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_332.pth
	Model improved!!!
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4147699097499714		[learning rate: 0.0056878]
	Learning Rate: 0.00568784
	LOSS [training: 0.4147699097499714 | validation: 0.35837583636348264]
	TIME [epoch: 9.62 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.54570526387209		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.54570526387209 | validation: 0.7871984347526813]
	TIME [epoch: 9.59 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.645099705827423		[learning rate: 0.0056603]
	Learning Rate: 0.00566033
	LOSS [training: 0.645099705827423 | validation: 0.641050269040091]
	TIME [epoch: 9.59 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6401174576944635		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.6401174576944635 | validation: 0.607034733495995]
	TIME [epoch: 9.61 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5661035237526906		[learning rate: 0.005633]
	Learning Rate: 0.00563296
	LOSS [training: 0.5661035237526906 | validation: 0.6475769972219239]
	TIME [epoch: 9.6 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5284605855422255		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.5284605855422255 | validation: 0.6445180451022866]
	TIME [epoch: 9.58 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7359937951464047		[learning rate: 0.0056057]
	Learning Rate: 0.00560572
	LOSS [training: 0.7359937951464047 | validation: 0.5014782918356763]
	TIME [epoch: 9.58 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6505148710178583		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.6505148710178583 | validation: 1.635916250999751]
	TIME [epoch: 9.6 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9998154797058969		[learning rate: 0.0055786]
	Learning Rate: 0.00557861
	LOSS [training: 0.9998154797058969 | validation: 0.5097804425883032]
	TIME [epoch: 9.6 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48277065698036575		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.48277065698036575 | validation: 0.5937932001789002]
	TIME [epoch: 9.59 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4782616729827878		[learning rate: 0.0055516]
	Learning Rate: 0.00555164
	LOSS [training: 0.4782616729827878 | validation: 0.44123896112400074]
	TIME [epoch: 9.58 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4402675968329469		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.4402675968329469 | validation: 0.5015367838264301]
	TIME [epoch: 9.61 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4241638161747673		[learning rate: 0.0055248]
	Learning Rate: 0.00552479
	LOSS [training: 0.4241638161747673 | validation: 0.4222369733766409]
	TIME [epoch: 9.59 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4696471247659357		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.4696471247659357 | validation: 0.5358630096972572]
	TIME [epoch: 9.57 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7606638539486801		[learning rate: 0.0054981]
	Learning Rate: 0.00549807
	LOSS [training: 0.7606638539486801 | validation: 0.5360282704163747]
	TIME [epoch: 9.61 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7094020595076896		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.7094020595076896 | validation: 0.48853856210807933]
	TIME [epoch: 9.59 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5316588774530933		[learning rate: 0.0054715]
	Learning Rate: 0.00547149
	LOSS [training: 0.5316588774530933 | validation: 0.584722292050342]
	TIME [epoch: 9.58 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5602669298151275		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.5602669298151275 | validation: 0.4976395781356432]
	TIME [epoch: 9.6 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6492552604980849		[learning rate: 0.005445]
	Learning Rate: 0.00544503
	LOSS [training: 0.6492552604980849 | validation: 0.5105124727512775]
	TIME [epoch: 9.6 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6230462436733265		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.6230462436733265 | validation: 0.548369508024349]
	TIME [epoch: 9.6 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.505971429707873		[learning rate: 0.0054187]
	Learning Rate: 0.0054187
	LOSS [training: 0.505971429707873 | validation: 0.48462815291529965]
	TIME [epoch: 9.58 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3874433255590732		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.3874433255590732 | validation: 0.4479302916817832]
	TIME [epoch: 9.59 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5125185724693775		[learning rate: 0.0053925]
	Learning Rate: 0.00539249
	LOSS [training: 0.5125185724693775 | validation: 0.5812901339005041]
	TIME [epoch: 9.58 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6774028484043901		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.6774028484043901 | validation: 0.9924872163958333]
	TIME [epoch: 9.58 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6120782332646008		[learning rate: 0.0053664]
	Learning Rate: 0.00536641
	LOSS [training: 0.6120782332646008 | validation: 0.49274396274105897]
	TIME [epoch: 9.59 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.588425283244814		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.588425283244814 | validation: 0.625891544425089]
	TIME [epoch: 9.61 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5451915080643529		[learning rate: 0.0053405]
	Learning Rate: 0.00534046
	LOSS [training: 0.5451915080643529 | validation: 0.4006423860958028]
	TIME [epoch: 9.59 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7682938004774145		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.7682938004774145 | validation: 1.5542844326609497]
	TIME [epoch: 9.58 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2102209822357743		[learning rate: 0.0053146]
	Learning Rate: 0.00531464
	LOSS [training: 1.2102209822357743 | validation: 0.42305074001134985]
	TIME [epoch: 9.6 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8678602126498627		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.8678602126498627 | validation: 0.5470036254829392]
	TIME [epoch: 9.61 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5492018050765446		[learning rate: 0.0052889]
	Learning Rate: 0.00528894
	LOSS [training: 0.5492018050765446 | validation: 0.4831950540854758]
	TIME [epoch: 9.59 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5727638185147432		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.5727638185147432 | validation: 0.6658543058320815]
	TIME [epoch: 9.58 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6475164927821097		[learning rate: 0.0052634]
	Learning Rate: 0.00526336
	LOSS [training: 0.6475164927821097 | validation: 0.6081246824343151]
	TIME [epoch: 9.6 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8993526703351347		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.8993526703351347 | validation: 1.1004887353559984]
	TIME [epoch: 9.6 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9146951800102334		[learning rate: 0.0052379]
	Learning Rate: 0.00523791
	LOSS [training: 0.9146951800102334 | validation: 0.46393690919740593]
	TIME [epoch: 9.6 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5347242605057521		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.5347242605057521 | validation: 0.6516778595946358]
	TIME [epoch: 9.59 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1061431683798988		[learning rate: 0.0052126]
	Learning Rate: 0.00521258
	LOSS [training: 1.1061431683798988 | validation: 0.8396314778317567]
	TIME [epoch: 9.61 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7915477794034673		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.7915477794034673 | validation: 0.7320014690108393]
	TIME [epoch: 9.58 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6114091777958093		[learning rate: 0.0051874]
	Learning Rate: 0.00518737
	LOSS [training: 0.6114091777958093 | validation: 0.6157216886763281]
	TIME [epoch: 9.6 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5627872187359965		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.5627872187359965 | validation: 0.5666211204068654]
	TIME [epoch: 9.59 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5272082184795781		[learning rate: 0.0051623]
	Learning Rate: 0.00516229
	LOSS [training: 0.5272082184795781 | validation: 0.5521166840720931]
	TIME [epoch: 9.6 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6033534848324811		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.6033534848324811 | validation: 0.8188076322966572]
	TIME [epoch: 9.6 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6425974142586116		[learning rate: 0.0051373]
	Learning Rate: 0.00513732
	LOSS [training: 0.6425974142586116 | validation: 0.4450428305510751]
	TIME [epoch: 9.59 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5247507471663827		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.5247507471663827 | validation: 0.6733358358951853]
	TIME [epoch: 9.6 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5131818029903272		[learning rate: 0.0051125]
	Learning Rate: 0.00511248
	LOSS [training: 0.5131818029903272 | validation: 0.6268031444338201]
	TIME [epoch: 9.59 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4669107008375334		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.4669107008375334 | validation: 0.4521845312240194]
	TIME [epoch: 9.58 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5045454153035184		[learning rate: 0.0050878]
	Learning Rate: 0.00508776
	LOSS [training: 0.5045454153035184 | validation: 0.5354423484186318]
	TIME [epoch: 9.58 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4513935666498369		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.4513935666498369 | validation: 0.3591993448782463]
	TIME [epoch: 9.61 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4306765146642627		[learning rate: 0.0050632]
	Learning Rate: 0.00506315
	LOSS [training: 0.4306765146642627 | validation: 0.46720663514645994]
	TIME [epoch: 9.59 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5014189185387243		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.5014189185387243 | validation: 0.5857255426726425]
	TIME [epoch: 9.58 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.492412918750799		[learning rate: 0.0050387]
	Learning Rate: 0.00503867
	LOSS [training: 0.492412918750799 | validation: 0.4370820558011865]
	TIME [epoch: 9.59 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5350313056215479		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.5350313056215479 | validation: 0.6836137543481832]
	TIME [epoch: 9.62 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5328620973706055		[learning rate: 0.0050143]
	Learning Rate: 0.0050143
	LOSS [training: 0.5328620973706055 | validation: 0.40310499073278233]
	TIME [epoch: 9.58 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43890891210674166		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.43890891210674166 | validation: 0.4540583481742527]
	TIME [epoch: 9.58 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.485314820988911		[learning rate: 0.0049901]
	Learning Rate: 0.00499005
	LOSS [training: 0.485314820988911 | validation: 0.4709313156266128]
	TIME [epoch: 9.61 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4545151864779043		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.4545151864779043 | validation: 0.41772323838302217]
	TIME [epoch: 9.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4429483258928807		[learning rate: 0.0049659]
	Learning Rate: 0.00496592
	LOSS [training: 0.4429483258928807 | validation: 0.5613392952659008]
	TIME [epoch: 9.59 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44132488761759364		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.44132488761759364 | validation: 0.3974224954306492]
	TIME [epoch: 9.59 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5167576332429069		[learning rate: 0.0049419]
	Learning Rate: 0.00494191
	LOSS [training: 0.5167576332429069 | validation: 0.619448808842615]
	TIME [epoch: 9.6 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4909801254493071		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.4909801254493071 | validation: 0.3265775731072146]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_392.pth
	Model improved!!!
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40726764151853095		[learning rate: 0.004918]
	Learning Rate: 0.00491801
	LOSS [training: 0.40726764151853095 | validation: 0.4579201050916199]
	TIME [epoch: 9.59 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47619325131317075		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.47619325131317075 | validation: 0.5990005663846152]
	TIME [epoch: 9.6 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43398334558372353		[learning rate: 0.0048942]
	Learning Rate: 0.00489423
	LOSS [training: 0.43398334558372353 | validation: 0.39624962021655064]
	TIME [epoch: 9.6 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7058486818099986		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.7058486818099986 | validation: 0.41003622554584956]
	TIME [epoch: 9.59 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42066620555874784		[learning rate: 0.0048706]
	Learning Rate: 0.00487056
	LOSS [training: 0.42066620555874784 | validation: 0.32104788375598037]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_397.pth
	Model improved!!!
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33124829331956557		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.33124829331956557 | validation: 0.30612318925142723]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_398.pth
	Model improved!!!
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5098580465852357		[learning rate: 0.004847]
	Learning Rate: 0.00484701
	LOSS [training: 0.5098580465852357 | validation: 0.53027072055686]
	TIME [epoch: 9.59 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.766292211036425		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.766292211036425 | validation: 0.8071540891133261]
	TIME [epoch: 9.59 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5965885175681604		[learning rate: 0.0048236]
	Learning Rate: 0.00482357
	LOSS [training: 0.5965885175681604 | validation: 0.43987132991509337]
	TIME [epoch: 9.61 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293972944363523		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.5293972944363523 | validation: 0.4063545233504982]
	TIME [epoch: 9.59 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36113493249509865		[learning rate: 0.0048002]
	Learning Rate: 0.00480024
	LOSS [training: 0.36113493249509865 | validation: 0.5388192279510183]
	TIME [epoch: 9.58 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5676102040255704		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.5676102040255704 | validation: 0.36692432085026]
	TIME [epoch: 9.58 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6260210951562167		[learning rate: 0.004777]
	Learning Rate: 0.00477703
	LOSS [training: 0.6260210951562167 | validation: 0.6020866746394]
	TIME [epoch: 9.61 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8785807299695094		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.8785807299695094 | validation: 0.44089998854244905]
	TIME [epoch: 9.58 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39382592998423394		[learning rate: 0.0047539]
	Learning Rate: 0.00475393
	LOSS [training: 0.39382592998423394 | validation: 0.526848008827002]
	TIME [epoch: 9.59 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5273895391909303		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.5273895391909303 | validation: 0.4440512519668309]
	TIME [epoch: 9.59 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37939759558937897		[learning rate: 0.0047309]
	Learning Rate: 0.00473094
	LOSS [training: 0.37939759558937897 | validation: 0.4845088364326552]
	TIME [epoch: 9.59 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3991320831865915		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.3991320831865915 | validation: 0.45203062939751115]
	TIME [epoch: 9.59 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38257701533185406		[learning rate: 0.0047081]
	Learning Rate: 0.00470806
	LOSS [training: 0.38257701533185406 | validation: 0.5804095473739213]
	TIME [epoch: 9.58 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3447091505955996		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.3447091505955996 | validation: 0.3462544095820803]
	TIME [epoch: 9.61 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5950599496575661		[learning rate: 0.0046853]
	Learning Rate: 0.00468529
	LOSS [training: 0.5950599496575661 | validation: 0.6764195880240073]
	TIME [epoch: 9.59 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4377166378248168		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.4377166378248168 | validation: 0.37577841249501914]
	TIME [epoch: 9.58 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.503449550031433		[learning rate: 0.0046626]
	Learning Rate: 0.00466264
	LOSS [training: 0.503449550031433 | validation: 0.3733934600364192]
	TIME [epoch: 9.58 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4119717071956586		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.4119717071956586 | validation: 0.5552702760982294]
	TIME [epoch: 9.6 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39962989161057877		[learning rate: 0.0046401]
	Learning Rate: 0.00464009
	LOSS [training: 0.39962989161057877 | validation: 0.769700855424717]
	TIME [epoch: 9.58 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5028882766465401		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.5028882766465401 | validation: 0.4792294085826277]
	TIME [epoch: 9.58 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4588809399373398		[learning rate: 0.0046177]
	Learning Rate: 0.00461765
	LOSS [training: 0.4588809399373398 | validation: 0.47657257925129287]
	TIME [epoch: 9.6 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3986682667092249		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.3986682667092249 | validation: 0.41637782044547633]
	TIME [epoch: 9.59 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36940858470223537		[learning rate: 0.0045953]
	Learning Rate: 0.00459532
	LOSS [training: 0.36940858470223537 | validation: 0.35728646938448677]
	TIME [epoch: 9.58 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3441132007475938		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.3441132007475938 | validation: 0.3504628753836221]
	TIME [epoch: 9.58 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5442202966786623		[learning rate: 0.0045731]
	Learning Rate: 0.0045731
	LOSS [training: 0.5442202966786623 | validation: 0.5246634956666876]
	TIME [epoch: 9.6 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40940220693475204		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.40940220693475204 | validation: 0.29383519393830204]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_424.pth
	Model improved!!!
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30549010766876816		[learning rate: 0.004551]
	Learning Rate: 0.00455098
	LOSS [training: 0.30549010766876816 | validation: 0.39480785903743065]
	TIME [epoch: 9.58 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34770581390108246		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.34770581390108246 | validation: 0.4310912191673934]
	TIME [epoch: 9.58 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28420583868864474		[learning rate: 0.004529]
	Learning Rate: 0.00452898
	LOSS [training: 0.28420583868864474 | validation: 0.28697016972405137]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_427.pth
	Model improved!!!
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3115846673910047		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.3115846673910047 | validation: 0.37847642344416704]
	TIME [epoch: 9.58 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38821759158845504		[learning rate: 0.0045071]
	Learning Rate: 0.00450707
	LOSS [training: 0.38821759158845504 | validation: 0.32723411542341746]
	TIME [epoch: 9.58 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4006491818967116		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.4006491818967116 | validation: 0.38286989593485743]
	TIME [epoch: 9.6 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3901495702338237		[learning rate: 0.0044853]
	Learning Rate: 0.00448528
	LOSS [training: 0.3901495702338237 | validation: 0.42215439547119377]
	TIME [epoch: 9.58 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3169933340789969		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.3169933340789969 | validation: 0.3999950657757801]
	TIME [epoch: 9.58 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3362802423197926		[learning rate: 0.0044636]
	Learning Rate: 0.00446359
	LOSS [training: 0.3362802423197926 | validation: 0.28305299541508766]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_433.pth
	Model improved!!!
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2968847899718307		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.2968847899718307 | validation: 0.31116814616817934]
	TIME [epoch: 9.61 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2837973390733664		[learning rate: 0.004442]
	Learning Rate: 0.004442
	LOSS [training: 0.2837973390733664 | validation: 0.5022570733086889]
	TIME [epoch: 9.59 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3504312473153617		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.3504312473153617 | validation: 0.24836236389949393]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_436.pth
	Model improved!!!
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29730895655704026		[learning rate: 0.0044205]
	Learning Rate: 0.00442052
	LOSS [training: 0.29730895655704026 | validation: 0.256095455815483]
	TIME [epoch: 9.6 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2679087059043245		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.2679087059043245 | validation: 0.2554687363646099]
	TIME [epoch: 9.59 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26520601950307443		[learning rate: 0.0043991]
	Learning Rate: 0.00439915
	LOSS [training: 0.26520601950307443 | validation: 0.2862594811933203]
	TIME [epoch: 9.6 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2847663615130959		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.2847663615130959 | validation: 0.34247644685131484]
	TIME [epoch: 9.59 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44426199025837654		[learning rate: 0.0043779]
	Learning Rate: 0.00437787
	LOSS [training: 0.44426199025837654 | validation: 0.4244397987251764]
	TIME [epoch: 9.61 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46392476568134533		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.46392476568134533 | validation: 0.3312510031878963]
	TIME [epoch: 9.59 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30089276290933487		[learning rate: 0.0043567]
	Learning Rate: 0.0043567
	LOSS [training: 0.30089276290933487 | validation: 0.22738347580104573]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_443.pth
	Model improved!!!
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4986033449668418		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.4986033449668418 | validation: 0.48494592672735876]
	TIME [epoch: 9.59 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6982462348243426		[learning rate: 0.0043356]
	Learning Rate: 0.00433563
	LOSS [training: 0.6982462348243426 | validation: 0.753322760609789]
	TIME [epoch: 9.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5783299429731408		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.5783299429731408 | validation: 0.2163180125744193]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_446.pth
	Model improved!!!
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21562016646087562		[learning rate: 0.0043147]
	Learning Rate: 0.00431467
	LOSS [training: 0.21562016646087562 | validation: 0.2290561443112542]
	TIME [epoch: 9.59 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25399475055299325		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.25399475055299325 | validation: 0.3863527419044452]
	TIME [epoch: 9.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29443535203297755		[learning rate: 0.0042938]
	Learning Rate: 0.0042938
	LOSS [training: 0.29443535203297755 | validation: 0.20859214711556803]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_449.pth
	Model improved!!!
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24658512176152927		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.24658512176152927 | validation: 0.26156949209402536]
	TIME [epoch: 9.58 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6066713246159651		[learning rate: 0.004273]
	Learning Rate: 0.00427304
	LOSS [training: 0.6066713246159651 | validation: 1.8544451293497244]
	TIME [epoch: 9.59 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2704547446618024		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 2.2704547446618024 | validation: 1.5615560618932256]
	TIME [epoch: 9.61 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5551384278820073		[learning rate: 0.0042524]
	Learning Rate: 0.00425238
	LOSS [training: 1.5551384278820073 | validation: 0.5283860401652153]
	TIME [epoch: 9.59 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3323751461972653		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.3323751461972653 | validation: 0.19896950733700763]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36494826251584545		[learning rate: 0.0042318]
	Learning Rate: 0.00423181
	LOSS [training: 0.36494826251584545 | validation: 0.27953852909526633]
	TIME [epoch: 9.6 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26286930922580964		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.26286930922580964 | validation: 0.2210589999899829]
	TIME [epoch: 9.58 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2792178562501327		[learning rate: 0.0042113]
	Learning Rate: 0.00421135
	LOSS [training: 0.2792178562501327 | validation: 0.26767574953619294]
	TIME [epoch: 9.59 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43368707219806685		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.43368707219806685 | validation: 0.20658662949182927]
	TIME [epoch: 9.59 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22569925069061963		[learning rate: 0.004191]
	Learning Rate: 0.00419098
	LOSS [training: 0.22569925069061963 | validation: 0.33667945698100793]
	TIME [epoch: 9.61 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7108235209626991		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.7108235209626991 | validation: 0.43192763363821857]
	TIME [epoch: 9.58 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42682095382627006		[learning rate: 0.0041707]
	Learning Rate: 0.00417071
	LOSS [training: 0.42682095382627006 | validation: 0.3238788386903962]
	TIME [epoch: 9.58 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3667714818185589		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.3667714818185589 | validation: 0.4614748121797785]
	TIME [epoch: 9.58 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8949933475796223		[learning rate: 0.0041505]
	Learning Rate: 0.00415055
	LOSS [training: 0.8949933475796223 | validation: 0.7505608555301622]
	TIME [epoch: 9.6 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0108553570276482		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 1.0108553570276482 | validation: 0.7424691951850619]
	TIME [epoch: 9.58 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9361133207527264		[learning rate: 0.0041305]
	Learning Rate: 0.00413047
	LOSS [training: 0.9361133207527264 | validation: 0.7519445906662564]
	TIME [epoch: 9.59 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5712642184899744		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.5712642184899744 | validation: 0.34848719082808094]
	TIME [epoch: 9.6 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27463141476225666		[learning rate: 0.0041105]
	Learning Rate: 0.0041105
	LOSS [training: 0.27463141476225666 | validation: 0.22584948454977125]
	TIME [epoch: 9.59 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24273729517570955		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.24273729517570955 | validation: 0.26642586038587834]
	TIME [epoch: 9.59 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32415546250683935		[learning rate: 0.0040906]
	Learning Rate: 0.00409062
	LOSS [training: 0.32415546250683935 | validation: 0.3480077102645652]
	TIME [epoch: 9.59 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22786507150188165		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.22786507150188165 | validation: 0.23415524151144396]
	TIME [epoch: 9.61 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2649744211738535		[learning rate: 0.0040708]
	Learning Rate: 0.00407084
	LOSS [training: 0.2649744211738535 | validation: 0.23063917091630465]
	TIME [epoch: 9.59 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23193936807174403		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.23193936807174403 | validation: 0.31938302290644666]
	TIME [epoch: 9.59 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25767768145119757		[learning rate: 0.0040512]
	Learning Rate: 0.00405116
	LOSS [training: 0.25767768145119757 | validation: 0.3208806629218232]
	TIME [epoch: 9.6 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2575345585963057		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.2575345585963057 | validation: 0.2840468649232395]
	TIME [epoch: 9.6 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21711024573800666		[learning rate: 0.0040316]
	Learning Rate: 0.00403157
	LOSS [training: 0.21711024573800666 | validation: 0.20353835255498362]
	TIME [epoch: 9.59 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22300444718525086		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.22300444718525086 | validation: 0.3464486703677882]
	TIME [epoch: 9.58 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38335443159882515		[learning rate: 0.0040121]
	Learning Rate: 0.00401207
	LOSS [training: 0.38335443159882515 | validation: 0.6295237528462521]
	TIME [epoch: 9.6 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4625539494872922		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.4625539494872922 | validation: 0.3118165725847856]
	TIME [epoch: 9.6 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28707662571229114		[learning rate: 0.0039927]
	Learning Rate: 0.00399267
	LOSS [training: 0.28707662571229114 | validation: 0.30575755308997493]
	TIME [epoch: 9.59 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30809181533623137		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.30809181533623137 | validation: 0.3513311410064528]
	TIME [epoch: 9.59 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2502386508706146		[learning rate: 0.0039734]
	Learning Rate: 0.00397336
	LOSS [training: 0.2502386508706146 | validation: 0.2768525534187464]
	TIME [epoch: 9.61 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2453929312254007		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.2453929312254007 | validation: 0.2769291237200883]
	TIME [epoch: 9.59 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6164291957285263		[learning rate: 0.0039541]
	Learning Rate: 0.00395415
	LOSS [training: 0.6164291957285263 | validation: 0.48573337582525694]
	TIME [epoch: 9.59 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5607258886282172		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.5607258886282172 | validation: 0.23772358018627912]
	TIME [epoch: 9.59 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28173564986526534		[learning rate: 0.003935]
	Learning Rate: 0.00393502
	LOSS [training: 0.28173564986526534 | validation: 0.40087909797538757]
	TIME [epoch: 9.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3528231070610456		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.3528231070610456 | validation: 0.3777873536629629]
	TIME [epoch: 9.59 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3522329309196214		[learning rate: 0.003916]
	Learning Rate: 0.00391599
	LOSS [training: 0.3522329309196214 | validation: 0.4126326538479036]
	TIME [epoch: 9.59 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3387342283715193		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.3387342283715193 | validation: 0.22658348912205828]
	TIME [epoch: 9.6 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1873546137915003		[learning rate: 0.0038971]
	Learning Rate: 0.00389706
	LOSS [training: 0.1873546137915003 | validation: 0.19992196177528787]
	TIME [epoch: 9.59 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.260493888751529		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.260493888751529 | validation: 0.30815500091319725]
	TIME [epoch: 9.58 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2416138039151981		[learning rate: 0.0038782]
	Learning Rate: 0.00387821
	LOSS [training: 0.2416138039151981 | validation: 0.2983563223237699]
	TIME [epoch: 9.59 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22409662619049092		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.22409662619049092 | validation: 0.44571236691306765]
	TIME [epoch: 9.61 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3361128520608645		[learning rate: 0.0038595]
	Learning Rate: 0.00385946
	LOSS [training: 0.3361128520608645 | validation: 0.20145344392736264]
	TIME [epoch: 9.59 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40978830520664616		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.40978830520664616 | validation: 0.611836662093455]
	TIME [epoch: 9.59 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.78977903565715		[learning rate: 0.0038408]
	Learning Rate: 0.00384079
	LOSS [training: 0.78977903565715 | validation: 0.25691754390058763]
	TIME [epoch: 9.6 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2967216864801861		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.2967216864801861 | validation: 0.4459200256901795]
	TIME [epoch: 9.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.960934433658047		[learning rate: 0.0038222]
	Learning Rate: 0.00382222
	LOSS [training: 0.960934433658047 | validation: 0.49557111875232795]
	TIME [epoch: 9.59 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5958445395750236		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.5958445395750236 | validation: 0.2916367966968748]
	TIME [epoch: 9.58 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37892802712127927		[learning rate: 0.0038037]
	Learning Rate: 0.00380374
	LOSS [training: 0.37892802712127927 | validation: 0.6017645008730179]
	TIME [epoch: 9.61 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9009745281185122		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.9009745281185122 | validation: 0.5341614157072248]
	TIME [epoch: 9.58 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45890102607784333		[learning rate: 0.0037853]
	Learning Rate: 0.00378534
	LOSS [training: 0.45890102607784333 | validation: 0.30209898824746406]
	TIME [epoch: 9.59 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.290029912320208		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.290029912320208 | validation: 0.20195745590084987]
	TIME [epoch: 9.6 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17496587696035323		[learning rate: 0.003767]
	Learning Rate: 0.00376704
	LOSS [training: 0.17496587696035323 | validation: 0.20047720846746975]
	TIME [epoch: 9.59 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2921098173894364		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.2921098173894364 | validation: 0.502039990717906]
	TIME [epoch: 9.58 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.609878094507782		[learning rate: 0.0037488]
	Learning Rate: 0.00374882
	LOSS [training: 0.609878094507782 | validation: 0.7151917829637228]
	TIME [epoch: 9.58 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4236323707062426		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 1.4236323707062426 | validation: 1.0638192192047657]
	TIME [epoch: 9.6 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5713713267334333		[learning rate: 0.0037307]
	Learning Rate: 0.00373069
	LOSS [training: 0.5713713267334333 | validation: 0.43189904061851714]
	TIME [epoch: 9.6 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5965173459196718		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.5965173459196718 | validation: 1.162051418507701]
	TIME [epoch: 9.58 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0407524763778828		[learning rate: 0.0037127]
	Learning Rate: 0.00371265
	LOSS [training: 1.0407524763778828 | validation: 0.5467047853355047]
	TIME [epoch: 9.59 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7035725474745796		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.7035725474745796 | validation: 0.6220337167897169]
	TIME [epoch: 9.61 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6532391707044182		[learning rate: 0.0036947]
	Learning Rate: 0.0036947
	LOSS [training: 0.6532391707044182 | validation: 0.31359288828903675]
	TIME [epoch: 9.59 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5242642983052141		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.5242642983052141 | validation: 0.7320319684806702]
	TIME [epoch: 9.59 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5832622340989064		[learning rate: 0.0036768]
	Learning Rate: 0.00367683
	LOSS [training: 0.5832622340989064 | validation: 0.34452335981093585]
	TIME [epoch: 9.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3342385406846014		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.3342385406846014 | validation: 0.35914290124331244]
	TIME [epoch: 9.6 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31525253134841014		[learning rate: 0.0036591]
	Learning Rate: 0.00365905
	LOSS [training: 0.31525253134841014 | validation: 0.23314845372065462]
	TIME [epoch: 9.59 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27745389566038786		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.27745389566038786 | validation: 0.25249937013314094]
	TIME [epoch: 9.59 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2589416148806893		[learning rate: 0.0036414]
	Learning Rate: 0.00364136
	LOSS [training: 0.2589416148806893 | validation: 0.28643592400159734]
	TIME [epoch: 9.61 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22210739292429876		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.22210739292429876 | validation: 0.4051769366655411]
	TIME [epoch: 9.59 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9588714408247754		[learning rate: 0.0036237]
	Learning Rate: 0.00362375
	LOSS [training: 0.9588714408247754 | validation: 0.5004748399895853]
	TIME [epoch: 9.59 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5365044019581341		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.5365044019581341 | validation: 0.28565279526025544]
	TIME [epoch: 9.59 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29552411683688895		[learning rate: 0.0036062]
	Learning Rate: 0.00360622
	LOSS [training: 0.29552411683688895 | validation: 0.42333527559544176]
	TIME [epoch: 9.61 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5059948841582249		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.5059948841582249 | validation: 0.5089993529433172]
	TIME [epoch: 9.59 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4116974472235279		[learning rate: 0.0035888]
	Learning Rate: 0.00358878
	LOSS [training: 0.4116974472235279 | validation: 0.33834887282857923]
	TIME [epoch: 9.59 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31238920833265665		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.31238920833265665 | validation: 0.27462571781898737]
	TIME [epoch: 9.59 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36343368538148646		[learning rate: 0.0035714]
	Learning Rate: 0.00357143
	LOSS [training: 0.36343368538148646 | validation: 0.24472549732283205]
	TIME [epoch: 9.59 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21611678828138442		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.21611678828138442 | validation: 0.26141288520768435]
	TIME [epoch: 9.58 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33000920468822226		[learning rate: 0.0035542]
	Learning Rate: 0.00355416
	LOSS [training: 0.33000920468822226 | validation: 0.27215096244788195]
	TIME [epoch: 9.58 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1931755703870129		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.1931755703870129 | validation: 0.2987382068135547]
	TIME [epoch: 9.61 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27785208574878295		[learning rate: 0.003537]
	Learning Rate: 0.00353697
	LOSS [training: 0.27785208574878295 | validation: 0.319116018641896]
	TIME [epoch: 9.59 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3180833676555382		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.3180833676555382 | validation: 0.27300887509106764]
	TIME [epoch: 9.58 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21339176065584872		[learning rate: 0.0035199]
	Learning Rate: 0.00351987
	LOSS [training: 0.21339176065584872 | validation: 0.3118915841703251]
	TIME [epoch: 9.58 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28329768193168553		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.28329768193168553 | validation: 0.255822506183055]
	TIME [epoch: 9.6 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23027452248144606		[learning rate: 0.0035028]
	Learning Rate: 0.00350285
	LOSS [training: 0.23027452248144606 | validation: 0.19662307307261295]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_533.pth
	Model improved!!!
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21054298317202963		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.21054298317202963 | validation: 0.23659002118983316]
	TIME [epoch: 9.58 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19968730545700503		[learning rate: 0.0034859]
	Learning Rate: 0.00348591
	LOSS [training: 0.19968730545700503 | validation: 0.19520779364830154]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_535.pth
	Model improved!!!
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24714502920059003		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.24714502920059003 | validation: 0.19678694302985442]
	TIME [epoch: 9.58 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.456895225634117		[learning rate: 0.003469]
	Learning Rate: 0.00346905
	LOSS [training: 0.456895225634117 | validation: 0.7997888551244751]
	TIME [epoch: 9.58 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5044507328805542		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.5044507328805542 | validation: 0.286162773725329]
	TIME [epoch: 9.59 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27041671704342357		[learning rate: 0.0034523]
	Learning Rate: 0.00345227
	LOSS [training: 0.27041671704342357 | validation: 0.2370194467699958]
	TIME [epoch: 9.59 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19331202301960915		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.19331202301960915 | validation: 0.1601190526422516]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_540.pth
	Model improved!!!
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1866035164331649		[learning rate: 0.0034356]
	Learning Rate: 0.00343558
	LOSS [training: 0.1866035164331649 | validation: 0.18229312088614588]
	TIME [epoch: 9.58 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18114928361770694		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.18114928361770694 | validation: 0.25649955531255175]
	TIME [epoch: 9.61 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20067604014789292		[learning rate: 0.003419]
	Learning Rate: 0.00341897
	LOSS [training: 0.20067604014789292 | validation: 0.19398096317786767]
	TIME [epoch: 9.59 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17511005441452954		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.17511005441452954 | validation: 0.25639726114522854]
	TIME [epoch: 9.58 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20712293460872355		[learning rate: 0.0034024]
	Learning Rate: 0.00340243
	LOSS [training: 0.20712293460872355 | validation: 0.17408765474795931]
	TIME [epoch: 9.58 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22078827744534496		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.22078827744534496 | validation: 0.25588928819212803]
	TIME [epoch: 9.6 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20969786749141045		[learning rate: 0.003386]
	Learning Rate: 0.00338598
	LOSS [training: 0.20969786749141045 | validation: 0.19579259763156992]
	TIME [epoch: 9.57 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16023979968916613		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.16023979968916613 | validation: 0.16502848075232257]
	TIME [epoch: 9.58 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19482570655126746		[learning rate: 0.0033696]
	Learning Rate: 0.0033696
	LOSS [training: 0.19482570655126746 | validation: 0.1793148223569744]
	TIME [epoch: 9.6 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2414603934547392		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.2414603934547392 | validation: 0.532400467369126]
	TIME [epoch: 9.59 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6039383919000778		[learning rate: 0.0033533]
	Learning Rate: 0.00335331
	LOSS [training: 0.6039383919000778 | validation: 0.3371441807823108]
	TIME [epoch: 9.58 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3913508794103625		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.3913508794103625 | validation: 0.26936765231555315]
	TIME [epoch: 9.58 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44867222597937184		[learning rate: 0.0033371]
	Learning Rate: 0.00333709
	LOSS [training: 0.44867222597937184 | validation: 0.44960942528406056]
	TIME [epoch: 9.6 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38445867252702315		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.38445867252702315 | validation: 0.2752124602654361]
	TIME [epoch: 9.59 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2997347992868512		[learning rate: 0.003321]
	Learning Rate: 0.00332096
	LOSS [training: 0.2997347992868512 | validation: 0.2347989594066415]
	TIME [epoch: 9.58 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27697814014920963		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.27697814014920963 | validation: 0.27175761833490675]
	TIME [epoch: 9.6 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.412034650230765		[learning rate: 0.0033049]
	Learning Rate: 0.0033049
	LOSS [training: 0.412034650230765 | validation: 0.21924530036369994]
	TIME [epoch: 9.59 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3052243125627003		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.3052243125627003 | validation: 0.21301921819127942]
	TIME [epoch: 9.59 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18932116519739087		[learning rate: 0.0032889]
	Learning Rate: 0.00328891
	LOSS [training: 0.18932116519739087 | validation: 0.2501684428467643]
	TIME [epoch: 9.58 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31153005582343796		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.31153005582343796 | validation: 0.2728456242963307]
	TIME [epoch: 9.6 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18045381921905082		[learning rate: 0.003273]
	Learning Rate: 0.00327301
	LOSS [training: 0.18045381921905082 | validation: 0.21803913448633222]
	TIME [epoch: 9.58 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3102256747959954		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.3102256747959954 | validation: 0.25035981771737464]
	TIME [epoch: 9.58 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3007201327693664		[learning rate: 0.0032572]
	Learning Rate: 0.00325718
	LOSS [training: 0.3007201327693664 | validation: 0.26892923148332804]
	TIME [epoch: 9.59 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21245512289617613		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.21245512289617613 | validation: 0.25032898444848856]
	TIME [epoch: 9.6 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35132750476491015		[learning rate: 0.0032414]
	Learning Rate: 0.00324143
	LOSS [training: 0.35132750476491015 | validation: 0.2862129449216907]
	TIME [epoch: 9.58 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20195507868715662		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.20195507868715662 | validation: 0.18527851910884557]
	TIME [epoch: 9.58 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1831879961674728		[learning rate: 0.0032258]
	Learning Rate: 0.00322576
	LOSS [training: 0.1831879961674728 | validation: 0.1689790349525849]
	TIME [epoch: 9.59 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20718633950943607		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.20718633950943607 | validation: 0.20881596278657596]
	TIME [epoch: 9.59 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3385099407190769		[learning rate: 0.0032102]
	Learning Rate: 0.00321016
	LOSS [training: 0.3385099407190769 | validation: 0.2634562753073876]
	TIME [epoch: 9.58 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28671042703339744		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.28671042703339744 | validation: 0.27177454404481305]
	TIME [epoch: 9.58 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22825025732870557		[learning rate: 0.0031946]
	Learning Rate: 0.00319463
	LOSS [training: 0.22825025732870557 | validation: 0.24572123254871983]
	TIME [epoch: 9.6 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21756185156335733		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.21756185156335733 | validation: 0.2510271792682871]
	TIME [epoch: 9.59 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3013746015468511		[learning rate: 0.0031792]
	Learning Rate: 0.00317918
	LOSS [training: 0.3013746015468511 | validation: 0.2878335892769751]
	TIME [epoch: 9.58 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.237942487924956		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.237942487924956 | validation: 0.1735048891106435]
	TIME [epoch: 9.58 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3467608791019427		[learning rate: 0.0031638]
	Learning Rate: 0.00316381
	LOSS [training: 0.3467608791019427 | validation: 0.3133227790363857]
	TIME [epoch: 9.6 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3131753115236669		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.3131753115236669 | validation: 0.33372091081299254]
	TIME [epoch: 9.59 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2917102777023447		[learning rate: 0.0031485]
	Learning Rate: 0.00314851
	LOSS [training: 0.2917102777023447 | validation: 0.2434405592777675]
	TIME [epoch: 9.58 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22119571343703592		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.22119571343703592 | validation: 0.2688137811186993]
	TIME [epoch: 9.6 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23310550091581206		[learning rate: 0.0031333]
	Learning Rate: 0.00313329
	LOSS [training: 0.23310550091581206 | validation: 0.2874698656159068]
	TIME [epoch: 9.59 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25787719943323695		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.25787719943323695 | validation: 0.2595000285986847]
	TIME [epoch: 9.58 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2930561503584698		[learning rate: 0.0031181]
	Learning Rate: 0.00311813
	LOSS [training: 0.2930561503584698 | validation: 0.6891714631079012]
	TIME [epoch: 9.59 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5130534132467002		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.5130534132467002 | validation: 0.28061044636712595]
	TIME [epoch: 9.6 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25934052111353123		[learning rate: 0.0031031]
	Learning Rate: 0.00310305
	LOSS [training: 0.25934052111353123 | validation: 0.31293305092736207]
	TIME [epoch: 9.58 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23882006975001735		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.23882006975001735 | validation: 0.2542465157936021]
	TIME [epoch: 9.58 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22414190354615066		[learning rate: 0.003088]
	Learning Rate: 0.00308805
	LOSS [training: 0.22414190354615066 | validation: 0.1983388412771647]
	TIME [epoch: 9.58 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24749852974796216		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.24749852974796216 | validation: 0.20665927820322785]
	TIME [epoch: 9.59 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18056347538081513		[learning rate: 0.0030731]
	Learning Rate: 0.00307312
	LOSS [training: 0.18056347538081513 | validation: 0.18190048390021687]
	TIME [epoch: 9.58 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28373430565468294		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.28373430565468294 | validation: 0.3499413671182528]
	TIME [epoch: 9.58 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2712553562845004		[learning rate: 0.0030583]
	Learning Rate: 0.00305825
	LOSS [training: 0.2712553562845004 | validation: 0.21383106162163804]
	TIME [epoch: 9.6 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2240143859279767		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.2240143859279767 | validation: 0.25236588514365915]
	TIME [epoch: 9.58 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23358185174161758		[learning rate: 0.0030435]
	Learning Rate: 0.00304347
	LOSS [training: 0.23358185174161758 | validation: 0.1757008436780275]
	TIME [epoch: 9.58 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15989229623041773		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.15989229623041773 | validation: 0.24073200025995925]
	TIME [epoch: 9.58 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.209059981423583		[learning rate: 0.0030287]
	Learning Rate: 0.00302875
	LOSS [training: 0.209059981423583 | validation: 0.18793268872329663]
	TIME [epoch: 9.6 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15748378018339376		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.15748378018339376 | validation: 0.12061482653277648]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_594.pth
	Model improved!!!
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15505817285712525		[learning rate: 0.0030141]
	Learning Rate: 0.0030141
	LOSS [training: 0.15505817285712525 | validation: 0.42392907761316123]
	TIME [epoch: 9.6 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3147058285105902		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.3147058285105902 | validation: 0.23918394837608464]
	TIME [epoch: 9.6 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23142358674944283		[learning rate: 0.0029995]
	Learning Rate: 0.00299953
	LOSS [training: 0.23142358674944283 | validation: 0.18921055875888443]
	TIME [epoch: 9.6 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15754333286188404		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.15754333286188404 | validation: 0.1469557274639962]
	TIME [epoch: 9.59 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15124065654704802		[learning rate: 0.002985]
	Learning Rate: 0.00298502
	LOSS [training: 0.15124065654704802 | validation: 0.17501434296763088]
	TIME [epoch: 9.59 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14270919806311966		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.14270919806311966 | validation: 0.16919246411197153]
	TIME [epoch: 9.6 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24050421093172783		[learning rate: 0.0029706]
	Learning Rate: 0.00297059
	LOSS [training: 0.24050421093172783 | validation: 0.26499719894484475]
	TIME [epoch: 9.59 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18611376274085356		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.18611376274085356 | validation: 0.11145663036742917]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_602.pth
	Model improved!!!
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14022484493766724		[learning rate: 0.0029562]
	Learning Rate: 0.00295622
	LOSS [training: 0.14022484493766724 | validation: 0.2332295703339272]
	TIME [epoch: 9.58 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15930543292738525		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.15930543292738525 | validation: 0.2307064125155764]
	TIME [epoch: 9.61 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21326901327769554		[learning rate: 0.0029419]
	Learning Rate: 0.00294192
	LOSS [training: 0.21326901327769554 | validation: 0.32870606543973824]
	TIME [epoch: 9.59 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2501182379456902		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.2501182379456902 | validation: 0.15698266785085932]
	TIME [epoch: 9.6 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14002099606971385		[learning rate: 0.0029277]
	Learning Rate: 0.0029277
	LOSS [training: 0.14002099606971385 | validation: 0.26906906770390543]
	TIME [epoch: 9.6 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19061173094493747		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.19061173094493747 | validation: 0.1909101609078655]
	TIME [epoch: 9.59 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23841710356050944		[learning rate: 0.0029135]
	Learning Rate: 0.00291354
	LOSS [training: 0.23841710356050944 | validation: 0.20435248541829978]
	TIME [epoch: 9.58 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18844918495327503		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.18844918495327503 | validation: 0.24273912895831623]
	TIME [epoch: 9.59 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24351577779383163		[learning rate: 0.0028995]
	Learning Rate: 0.00289945
	LOSS [training: 0.24351577779383163 | validation: 0.20998962040172386]
	TIME [epoch: 9.61 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2613710664628536		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.2613710664628536 | validation: 0.2562829249243564]
	TIME [epoch: 9.59 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18556516306362758		[learning rate: 0.0028854]
	Learning Rate: 0.00288543
	LOSS [training: 0.18556516306362758 | validation: 0.2503661798043831]
	TIME [epoch: 9.58 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3615939299443963		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.3615939299443963 | validation: 0.33173559665051117]
	TIME [epoch: 9.6 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23569197770559355		[learning rate: 0.0028715]
	Learning Rate: 0.00287148
	LOSS [training: 0.23569197770559355 | validation: 0.238655681701193]
	TIME [epoch: 9.6 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26768646347071445		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.26768646347071445 | validation: 0.19103869414398314]
	TIME [epoch: 9.59 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1438970994696645		[learning rate: 0.0028576]
	Learning Rate: 0.00285759
	LOSS [training: 0.1438970994696645 | validation: 0.13780419745517153]
	TIME [epoch: 9.59 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1806392213258279		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.1806392213258279 | validation: 0.15184157511867202]
	TIME [epoch: 9.61 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1558998604550397		[learning rate: 0.0028438]
	Learning Rate: 0.00284377
	LOSS [training: 0.1558998604550397 | validation: 0.12806913580933943]
	TIME [epoch: 9.59 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16311995731765694		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.16311995731765694 | validation: 0.13058423384783904]
	TIME [epoch: 9.59 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19807273423617108		[learning rate: 0.00283]
	Learning Rate: 0.00283002
	LOSS [training: 0.19807273423617108 | validation: 0.20476256287468822]
	TIME [epoch: 9.59 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24748084323090097		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.24748084323090097 | validation: 0.15869270621735512]
	TIME [epoch: 9.6 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20322123164465428		[learning rate: 0.0028163]
	Learning Rate: 0.00281633
	LOSS [training: 0.20322123164465428 | validation: 0.23110424957553963]
	TIME [epoch: 9.58 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1905789030952691		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.1905789030952691 | validation: 0.11761618275932388]
	TIME [epoch: 9.59 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14385747752353953		[learning rate: 0.0028027]
	Learning Rate: 0.00280272
	LOSS [training: 0.14385747752353953 | validation: 0.17339462290098973]
	TIME [epoch: 9.6 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14380696096540144		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.14380696096540144 | validation: 0.15380912458089527]
	TIME [epoch: 9.6 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25914607367149717		[learning rate: 0.0027892]
	Learning Rate: 0.00278916
	LOSS [training: 0.25914607367149717 | validation: 0.3889158984320757]
	TIME [epoch: 9.59 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42723291504360644		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.42723291504360644 | validation: 0.2787305675673282]
	TIME [epoch: 9.59 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3229556837008741		[learning rate: 0.0027757]
	Learning Rate: 0.00277567
	LOSS [training: 0.3229556837008741 | validation: 0.23176784775937642]
	TIME [epoch: 9.6 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21638619230785064		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.21638619230785064 | validation: 0.13811879275268288]
	TIME [epoch: 9.58 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15092342070036907		[learning rate: 0.0027623]
	Learning Rate: 0.00276225
	LOSS [training: 0.15092342070036907 | validation: 0.14039707032846135]
	TIME [epoch: 9.58 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14474335022957802		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.14474335022957802 | validation: 0.11690095420273089]
	TIME [epoch: 9.59 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15807430430788044		[learning rate: 0.0027489]
	Learning Rate: 0.00274889
	LOSS [training: 0.15807430430788044 | validation: 0.16446217642657432]
	TIME [epoch: 9.6 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1270321619465172		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.1270321619465172 | validation: 0.09815003199119303]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_634.pth
	Model improved!!!
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17158504025815957		[learning rate: 0.0027356]
	Learning Rate: 0.0027356
	LOSS [training: 0.17158504025815957 | validation: 0.1683553222145628]
	TIME [epoch: 9.58 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1417245062306556		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.1417245062306556 | validation: 0.1610203835854351]
	TIME [epoch: 9.61 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15682748994121143		[learning rate: 0.0027224]
	Learning Rate: 0.00272237
	LOSS [training: 0.15682748994121143 | validation: 0.14308291614342628]
	TIME [epoch: 9.59 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14858658104417904		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.14858658104417904 | validation: 0.09341774047668651]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_638.pth
	Model improved!!!
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14912388022956374		[learning rate: 0.0027092]
	Learning Rate: 0.00270921
	LOSS [training: 0.14912388022956374 | validation: 0.2194841094741539]
	TIME [epoch: 9.58 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16578507835858755		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.16578507835858755 | validation: 0.22525003570456129]
	TIME [epoch: 9.6 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30584196301723904		[learning rate: 0.0026961]
	Learning Rate: 0.00269611
	LOSS [training: 0.30584196301723904 | validation: 0.21828128615883735]
	TIME [epoch: 9.58 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22012877938405168		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.22012877938405168 | validation: 0.18973839108298776]
	TIME [epoch: 9.58 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23748020958041455		[learning rate: 0.0026831]
	Learning Rate: 0.00268307
	LOSS [training: 0.23748020958041455 | validation: 0.25513447463223693]
	TIME [epoch: 9.59 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1584550499268771		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.1584550499268771 | validation: 0.16040630265869535]
	TIME [epoch: 9.59 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15858237601766195		[learning rate: 0.0026701]
	Learning Rate: 0.00267009
	LOSS [training: 0.15858237601766195 | validation: 0.22114201238699344]
	TIME [epoch: 9.58 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1867588053222107		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.1867588053222107 | validation: 0.21283186011824845]
	TIME [epoch: 9.58 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1963930917572418		[learning rate: 0.0026572]
	Learning Rate: 0.00265718
	LOSS [training: 0.1963930917572418 | validation: 0.15005470952625533]
	TIME [epoch: 9.59 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19376653220639634		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.19376653220639634 | validation: 0.21875808593711682]
	TIME [epoch: 9.59 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29623308532228027		[learning rate: 0.0026443]
	Learning Rate: 0.00264433
	LOSS [training: 0.29623308532228027 | validation: 0.16472330700012588]
	TIME [epoch: 9.57 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.153013538436031		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.153013538436031 | validation: 0.1877361654105778]
	TIME [epoch: 9.58 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18750283389103556		[learning rate: 0.0026315]
	Learning Rate: 0.00263154
	LOSS [training: 0.18750283389103556 | validation: 0.16970313353059766]
	TIME [epoch: 9.6 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17204150742636887		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.17204150742636887 | validation: 0.20470361619886446]
	TIME [epoch: 9.59 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23599638951566426		[learning rate: 0.0026188]
	Learning Rate: 0.00261882
	LOSS [training: 0.23599638951566426 | validation: 0.2880466627801407]
	TIME [epoch: 9.57 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3541963121717476		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.3541963121717476 | validation: 0.19184457683530107]
	TIME [epoch: 9.6 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1911872535719216		[learning rate: 0.0026062]
	Learning Rate: 0.00260615
	LOSS [training: 0.1911872535719216 | validation: 0.1653598447972191]
	TIME [epoch: 9.58 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1808119182247821		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.1808119182247821 | validation: 0.13426835722276437]
	TIME [epoch: 9.58 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22502429740256638		[learning rate: 0.0025936]
	Learning Rate: 0.00259355
	LOSS [training: 0.22502429740256638 | validation: 0.29378658621682335]
	TIME [epoch: 9.58 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2999669836351558		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.2999669836351558 | validation: 0.45645389942764775]
	TIME [epoch: 9.6 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26301709351395186		[learning rate: 0.002581]
	Learning Rate: 0.00258101
	LOSS [training: 0.26301709351395186 | validation: 0.18693529285324276]
	TIME [epoch: 9.59 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21480925364120043		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.21480925364120043 | validation: 0.18195270306631586]
	TIME [epoch: 9.59 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22152100582759537		[learning rate: 0.0025685]
	Learning Rate: 0.00256853
	LOSS [training: 0.22152100582759537 | validation: 0.18418059003096818]
	TIME [epoch: 9.58 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24021689773539606		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.24021689773539606 | validation: 0.21400530854425853]
	TIME [epoch: 9.61 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23836423176516033		[learning rate: 0.0025561]
	Learning Rate: 0.00255611
	LOSS [training: 0.23836423176516033 | validation: 0.16559683737246125]
	TIME [epoch: 9.58 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1628649912173798		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.1628649912173798 | validation: 0.15918712961602347]
	TIME [epoch: 9.59 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1900898976484283		[learning rate: 0.0025437]
	Learning Rate: 0.00254375
	LOSS [training: 0.1900898976484283 | validation: 0.20204524866979853]
	TIME [epoch: 9.6 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1521493770205929		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.1521493770205929 | validation: 0.1432539711925642]
	TIME [epoch: 9.59 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2577336569875088		[learning rate: 0.0025314]
	Learning Rate: 0.00253144
	LOSS [training: 0.2577336569875088 | validation: 0.23278088168178376]
	TIME [epoch: 9.59 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24928092727666695		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.24928092727666695 | validation: 0.23609119701187134]
	TIME [epoch: 9.59 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23279305053230748		[learning rate: 0.0025192]
	Learning Rate: 0.0025192
	LOSS [training: 0.23279305053230748 | validation: 0.19856489524599888]
	TIME [epoch: 9.61 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26818158699744005		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.26818158699744005 | validation: 0.35880646568571833]
	TIME [epoch: 9.59 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3470330893562536		[learning rate: 0.002507]
	Learning Rate: 0.00250702
	LOSS [training: 0.3470330893562536 | validation: 0.22224328192595608]
	TIME [epoch: 9.58 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26978996729867105		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.26978996729867105 | validation: 0.24720998684255352]
	TIME [epoch: 9.59 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2202240403873727		[learning rate: 0.0024949]
	Learning Rate: 0.0024949
	LOSS [training: 0.2202240403873727 | validation: 0.17409936828060854]
	TIME [epoch: 9.59 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21035908276189003		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.21035908276189003 | validation: 0.22808660650511872]
	TIME [epoch: 9.58 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3259064347046131		[learning rate: 0.0024828]
	Learning Rate: 0.00248283
	LOSS [training: 0.3259064347046131 | validation: 0.30489493675317775]
	TIME [epoch: 9.58 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28554646887926155		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.28554646887926155 | validation: 0.1826878666017388]
	TIME [epoch: 9.6 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20467499649593957		[learning rate: 0.0024708]
	Learning Rate: 0.00247083
	LOSS [training: 0.20467499649593957 | validation: 0.17564678982075307]
	TIME [epoch: 9.59 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17732767870258737		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.17732767870258737 | validation: 0.21524269995557546]
	TIME [epoch: 9.58 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19947800400228383		[learning rate: 0.0024589]
	Learning Rate: 0.00245888
	LOSS [training: 0.19947800400228383 | validation: 0.12548876048071286]
	TIME [epoch: 9.58 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11237008182999834		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.11237008182999834 | validation: 0.1720885081413371]
	TIME [epoch: 9.6 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21446789717288284		[learning rate: 0.002447]
	Learning Rate: 0.00244699
	LOSS [training: 0.21446789717288284 | validation: 0.18003916942057047]
	TIME [epoch: 9.58 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2452107963418173		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.2452107963418173 | validation: 0.15715828609424173]
	TIME [epoch: 9.59 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19159468222694978		[learning rate: 0.0024352]
	Learning Rate: 0.00243515
	LOSS [training: 0.19159468222694978 | validation: 0.2571687035346127]
	TIME [epoch: 9.6 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23918267374308141		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.23918267374308141 | validation: 0.28213064669640875]
	TIME [epoch: 9.6 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21764889845751992		[learning rate: 0.0024234]
	Learning Rate: 0.00242338
	LOSS [training: 0.21764889845751992 | validation: 0.11970840590377653]
	TIME [epoch: 9.59 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1325490063399643		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.1325490063399643 | validation: 0.1707373502186733]
	TIME [epoch: 9.59 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23915685210490256		[learning rate: 0.0024117]
	Learning Rate: 0.00241166
	LOSS [training: 0.23915685210490256 | validation: 0.15999409389402702]
	TIME [epoch: 9.6 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21550859594008961		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.21550859594008961 | validation: 0.18626579501064366]
	TIME [epoch: 9.59 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23482432454175745		[learning rate: 0.0024]
	Learning Rate: 0.0024
	LOSS [training: 0.23482432454175745 | validation: 0.25766926394137923]
	TIME [epoch: 9.58 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23797728408244004		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.23797728408244004 | validation: 0.1941286854218307]
	TIME [epoch: 9.59 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1974371391892926		[learning rate: 0.0023884]
	Learning Rate: 0.00238839
	LOSS [training: 0.1974371391892926 | validation: 0.234224354996444]
	TIME [epoch: 9.6 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2534325809737439		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.2534325809737439 | validation: 0.20274205733152798]
	TIME [epoch: 9.59 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15084048608204917		[learning rate: 0.0023768]
	Learning Rate: 0.00237684
	LOSS [training: 0.15084048608204917 | validation: 0.12890784917802584]
	TIME [epoch: 9.6 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1578083854263628		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.1578083854263628 | validation: 0.19178890963211018]
	TIME [epoch: 9.61 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15051291831358132		[learning rate: 0.0023653]
	Learning Rate: 0.00236535
	LOSS [training: 0.15051291831358132 | validation: 0.1051238613290845]
	TIME [epoch: 9.59 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13756913256999823		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.13756913256999823 | validation: 0.1376015273158486]
	TIME [epoch: 9.59 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13025842958400569		[learning rate: 0.0023539]
	Learning Rate: 0.00235391
	LOSS [training: 0.13025842958400569 | validation: 0.11300564709156694]
	TIME [epoch: 9.59 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12199044767095302		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.12199044767095302 | validation: 0.079941360442345]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_698.pth
	Model improved!!!
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10524508496567613		[learning rate: 0.0023425]
	Learning Rate: 0.00234252
	LOSS [training: 0.10524508496567613 | validation: 0.1275112590329677]
	TIME [epoch: 9.59 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13369164850934767		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.13369164850934767 | validation: 0.14031776592951903]
	TIME [epoch: 9.59 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13746678054894312		[learning rate: 0.0023312]
	Learning Rate: 0.0023312
	LOSS [training: 0.13746678054894312 | validation: 0.17353941702441134]
	TIME [epoch: 9.6 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16349227980000092		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.16349227980000092 | validation: 0.1350282924677493]
	TIME [epoch: 9.59 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19788862182217523		[learning rate: 0.0023199]
	Learning Rate: 0.00231992
	LOSS [training: 0.19788862182217523 | validation: 0.2459573033080689]
	TIME [epoch: 9.58 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3528376688854241		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.3528376688854241 | validation: 0.29142258769559193]
	TIME [epoch: 9.59 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3068077212768125		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.3068077212768125 | validation: 0.1921955175316201]
	TIME [epoch: 9.61 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22998235439000664		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.22998235439000664 | validation: 0.14126163608755363]
	TIME [epoch: 9.59 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2924812657018389		[learning rate: 0.0022975]
	Learning Rate: 0.00229754
	LOSS [training: 0.2924812657018389 | validation: 0.32129398417739324]
	TIME [epoch: 9.58 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2714915345555822		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.2714915345555822 | validation: 0.173406124735547]
	TIME [epoch: 9.59 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24429176346329387		[learning rate: 0.0022864]
	Learning Rate: 0.00228643
	LOSS [training: 0.24429176346329387 | validation: 0.18472685835495956]
	TIME [epoch: 9.61 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2529553733511662		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.2529553733511662 | validation: 0.16503645461530478]
	TIME [epoch: 9.59 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2263892757224577		[learning rate: 0.0022754]
	Learning Rate: 0.00227537
	LOSS [training: 0.2263892757224577 | validation: 0.15969822839792555]
	TIME [epoch: 9.58 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20438972266617209		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.20438972266617209 | validation: 0.1333932434191071]
	TIME [epoch: 9.59 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1847532702841133		[learning rate: 0.0022644]
	Learning Rate: 0.00226437
	LOSS [training: 0.1847532702841133 | validation: 0.19227119881942756]
	TIME [epoch: 9.6 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16549781102051564		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.16549781102051564 | validation: 0.10556068954654645]
	TIME [epoch: 9.58 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17270997088358028		[learning rate: 0.0022534]
	Learning Rate: 0.00225342
	LOSS [training: 0.17270997088358028 | validation: 0.21237825901724516]
	TIME [epoch: 9.58 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23392527844911704		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.23392527844911704 | validation: 0.16601243170830157]
	TIME [epoch: 9.6 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18582409315087936		[learning rate: 0.0022425]
	Learning Rate: 0.00224252
	LOSS [training: 0.18582409315087936 | validation: 0.16958674484161962]
	TIME [epoch: 9.59 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1916323186114132		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.1916323186114132 | validation: 0.1505371148363563]
	TIME [epoch: 9.58 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15062483062715995		[learning rate: 0.0022317]
	Learning Rate: 0.00223168
	LOSS [training: 0.15062483062715995 | validation: 0.10418346047442578]
	TIME [epoch: 9.59 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13034070876218012		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.13034070876218012 | validation: 0.1433558783860839]
	TIME [epoch: 9.6 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13543327269345778		[learning rate: 0.0022209]
	Learning Rate: 0.00222089
	LOSS [training: 0.13543327269345778 | validation: 0.1465536456789146]
	TIME [epoch: 9.58 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21250508020838116		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.21250508020838116 | validation: 0.12825694773530688]
	TIME [epoch: 9.59 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16639938166465496		[learning rate: 0.0022101]
	Learning Rate: 0.00221015
	LOSS [training: 0.16639938166465496 | validation: 0.09200000373433515]
	TIME [epoch: 9.6 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16443744226770818		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.16443744226770818 | validation: 0.29640350630377416]
	TIME [epoch: 9.59 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2326087488885415		[learning rate: 0.0021995]
	Learning Rate: 0.00219946
	LOSS [training: 0.2326087488885415 | validation: 0.16565391136349575]
	TIME [epoch: 9.59 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14125386139302917		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.14125386139302917 | validation: 0.20314426505178837]
	TIME [epoch: 9.59 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2660795742388907		[learning rate: 0.0021888]
	Learning Rate: 0.00218882
	LOSS [training: 0.2660795742388907 | validation: 0.2023194429042078]
	TIME [epoch: 9.6 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13358631189786488		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.13358631189786488 | validation: 0.09169173023166231]
	TIME [epoch: 9.59 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12047680233516192		[learning rate: 0.0021782]
	Learning Rate: 0.00217824
	LOSS [training: 0.12047680233516192 | validation: 0.0941381189712077]
	TIME [epoch: 9.59 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16035187867696102		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.16035187867696102 | validation: 0.2834020479344949]
	TIME [epoch: 9.6 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3537891276477858		[learning rate: 0.0021677]
	Learning Rate: 0.0021677
	LOSS [training: 0.3537891276477858 | validation: 0.16218417722095724]
	TIME [epoch: 9.6 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21944958610269644		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.21944958610269644 | validation: 0.21172112103069296]
	TIME [epoch: 9.59 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24058137956985112		[learning rate: 0.0021572]
	Learning Rate: 0.00215722
	LOSS [training: 0.24058137956985112 | validation: 0.17441275974402268]
	TIME [epoch: 9.58 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21910409527929203		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.21910409527929203 | validation: 0.19247595856113645]
	TIME [epoch: 9.6 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35182171049932365		[learning rate: 0.0021468]
	Learning Rate: 0.00214679
	LOSS [training: 0.35182171049932365 | validation: 0.3461599492255097]
	TIME [epoch: 9.6 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3586616484906221		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.3586616484906221 | validation: 0.46024166868946637]
	TIME [epoch: 9.58 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6639709811187027		[learning rate: 0.0021364]
	Learning Rate: 0.00213641
	LOSS [training: 0.6639709811187027 | validation: 0.3221823754403748]
	TIME [epoch: 9.59 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5466075589326902		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.5466075589326902 | validation: 0.6371965007665265]
	TIME [epoch: 9.61 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4955162682384019		[learning rate: 0.0021261]
	Learning Rate: 0.00212608
	LOSS [training: 0.4955162682384019 | validation: 0.28596524612634944]
	TIME [epoch: 9.59 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3824248818563044		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.3824248818563044 | validation: 0.28298890412953576]
	TIME [epoch: 9.59 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28962048429424275		[learning rate: 0.0021158]
	Learning Rate: 0.0021158
	LOSS [training: 0.28962048429424275 | validation: 0.15018153314736057]
	TIME [epoch: 9.6 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13270013672814546		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.13270013672814546 | validation: 0.11252888358289916]
	TIME [epoch: 9.59 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24350386872988197		[learning rate: 0.0021056]
	Learning Rate: 0.00210556
	LOSS [training: 0.24350386872988197 | validation: 0.147347115539375]
	TIME [epoch: 9.58 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19511563061377069		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.19511563061377069 | validation: 0.11855193259612698]
	TIME [epoch: 9.59 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1261192903773793		[learning rate: 0.0020954]
	Learning Rate: 0.00209538
	LOSS [training: 0.1261192903773793 | validation: 0.09002457059886605]
	TIME [epoch: 9.6 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08389981149216483		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.08389981149216483 | validation: 0.07589965252049738]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_746.pth
	Model improved!!!
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0988030158253993		[learning rate: 0.0020852]
	Learning Rate: 0.00208525
	LOSS [training: 0.0988030158253993 | validation: 0.07666003132417774]
	TIME [epoch: 9.59 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11146988042714315		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.11146988042714315 | validation: 0.12985255240657848]
	TIME [epoch: 9.6 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12354856653188387		[learning rate: 0.0020752]
	Learning Rate: 0.00207517
	LOSS [training: 0.12354856653188387 | validation: 0.13881705608316489]
	TIME [epoch: 9.6 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12567223490571747		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.12567223490571747 | validation: 0.10955682517858063]
	TIME [epoch: 9.59 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2199577665180123		[learning rate: 0.0020651]
	Learning Rate: 0.00206513
	LOSS [training: 0.2199577665180123 | validation: 0.1492702713907459]
	TIME [epoch: 9.59 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1385411800343544		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.1385411800343544 | validation: 0.09482373169458212]
	TIME [epoch: 9.6 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13104279935319296		[learning rate: 0.0020551]
	Learning Rate: 0.00205514
	LOSS [training: 0.13104279935319296 | validation: 0.07707795891488091]
	TIME [epoch: 9.59 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08728146477420072		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.08728146477420072 | validation: 0.06641846518150293]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_754.pth
	Model improved!!!
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11759350561088089		[learning rate: 0.0020452]
	Learning Rate: 0.0020452
	LOSS [training: 0.11759350561088089 | validation: 0.15129900192524923]
	TIME [epoch: 9.59 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13026974463602353		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.13026974463602353 | validation: 0.09782315790232449]
	TIME [epoch: 9.6 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1185416640132552		[learning rate: 0.0020353]
	Learning Rate: 0.00203531
	LOSS [training: 0.1185416640132552 | validation: 0.08174643363485498]
	TIME [epoch: 9.58 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13921182278869643		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.13921182278869643 | validation: 0.18460388871894665]
	TIME [epoch: 9.59 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1454588877650264		[learning rate: 0.0020255]
	Learning Rate: 0.00202547
	LOSS [training: 0.1454588877650264 | validation: 0.12433793066395073]
	TIME [epoch: 9.6 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1447079713341831		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.1447079713341831 | validation: 0.1908868678880926]
	TIME [epoch: 9.59 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1304691407845603		[learning rate: 0.0020157]
	Learning Rate: 0.00201568
	LOSS [training: 0.1304691407845603 | validation: 0.1212847396275012]
	TIME [epoch: 9.59 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17076714339356944		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.17076714339356944 | validation: 0.2535475019237654]
	TIME [epoch: 9.58 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2083123431564154		[learning rate: 0.0020059]
	Learning Rate: 0.00200593
	LOSS [training: 0.2083123431564154 | validation: 0.14313883094423588]
	TIME [epoch: 9.6 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1974263032343291		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.1974263032343291 | validation: 0.2775369391338107]
	TIME [epoch: 9.59 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2672547917879212		[learning rate: 0.0019962]
	Learning Rate: 0.00199623
	LOSS [training: 0.2672547917879212 | validation: 0.17198597604992988]
	TIME [epoch: 9.58 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15098309297024762		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.15098309297024762 | validation: 0.08212451689118272]
	TIME [epoch: 9.6 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10817319466932125		[learning rate: 0.0019866]
	Learning Rate: 0.00198658
	LOSS [training: 0.10817319466932125 | validation: 0.09493093456649065]
	TIME [epoch: 9.59 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10919682141167406		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.10919682141167406 | validation: 0.07160074017507945]
	TIME [epoch: 9.59 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10071106296698591		[learning rate: 0.001977]
	Learning Rate: 0.00197697
	LOSS [training: 0.10071106296698591 | validation: 0.11817808381237488]
	TIME [epoch: 9.58 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15151949401081283		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.15151949401081283 | validation: 0.1058479084332826]
	TIME [epoch: 9.6 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15315410599334903		[learning rate: 0.0019674]
	Learning Rate: 0.00196741
	LOSS [training: 0.15315410599334903 | validation: 0.17948323057609636]
	TIME [epoch: 9.58 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21804470816199806		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.21804470816199806 | validation: 0.10947555916381856]
	TIME [epoch: 9.59 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13852834499783867		[learning rate: 0.0019579]
	Learning Rate: 0.0019579
	LOSS [training: 0.13852834499783867 | validation: 0.11546972201545636]
	TIME [epoch: 9.58 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13672597664418978		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.13672597664418978 | validation: 0.11778862984725788]
	TIME [epoch: 9.61 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15709649566047118		[learning rate: 0.0019484]
	Learning Rate: 0.00194843
	LOSS [training: 0.15709649566047118 | validation: 0.09935302377942577]
	TIME [epoch: 9.58 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1621138500950504		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.1621138500950504 | validation: 0.15832078601807661]
	TIME [epoch: 9.59 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18947582879293284		[learning rate: 0.001939]
	Learning Rate: 0.00193901
	LOSS [training: 0.18947582879293284 | validation: 0.11251848670779278]
	TIME [epoch: 9.6 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1285643046705531		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.1285643046705531 | validation: 0.10678693205554794]
	TIME [epoch: 9.59 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16558164432804096		[learning rate: 0.0019296]
	Learning Rate: 0.00192963
	LOSS [training: 0.16558164432804096 | validation: 0.13007463588033016]
	TIME [epoch: 9.58 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1907283535060766		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.1907283535060766 | validation: 0.1296340473884488]
	TIME [epoch: 9.59 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21119382259667457		[learning rate: 0.0019203]
	Learning Rate: 0.0019203
	LOSS [training: 0.21119382259667457 | validation: 0.23434822473466846]
	TIME [epoch: 9.6 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2858880512939158		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.2858880512939158 | validation: 0.2290170386762622]
	TIME [epoch: 9.59 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2855748915037011		[learning rate: 0.001911]
	Learning Rate: 0.00191101
	LOSS [training: 0.2855748915037011 | validation: 0.2157187471473283]
	TIME [epoch: 9.59 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2701069916887292		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.2701069916887292 | validation: 0.2205419361151779]
	TIME [epoch: 9.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26327148817107043		[learning rate: 0.0019018]
	Learning Rate: 0.00190177
	LOSS [training: 0.26327148817107043 | validation: 0.20020712050152994]
	TIME [epoch: 9.59 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2702255311238443		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.2702255311238443 | validation: 0.17070323585589833]
	TIME [epoch: 9.59 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2428368043129451		[learning rate: 0.0018926]
	Learning Rate: 0.00189257
	LOSS [training: 0.2428368043129451 | validation: 0.2369391428800705]
	TIME [epoch: 9.58 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27588568704087973		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.27588568704087973 | validation: 0.16311513288277368]
	TIME [epoch: 9.61 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2572828602550112		[learning rate: 0.0018834]
	Learning Rate: 0.00188342
	LOSS [training: 0.2572828602550112 | validation: 0.18729754583372354]
	TIME [epoch: 9.58 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20579817608911358		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.20579817608911358 | validation: 0.14325109054737387]
	TIME [epoch: 9.59 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14759205107294324		[learning rate: 0.0018743]
	Learning Rate: 0.00187431
	LOSS [training: 0.14759205107294324 | validation: 0.10799886793529925]
	TIME [epoch: 9.59 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13211246734289359		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.13211246734289359 | validation: 0.10979296307805006]
	TIME [epoch: 9.6 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10474544067516198		[learning rate: 0.0018652]
	Learning Rate: 0.00186525
	LOSS [training: 0.10474544067516198 | validation: 0.06147843763964364]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_793.pth
	Model improved!!!
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0774376647796884		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.0774376647796884 | validation: 0.07250854091949924]
	TIME [epoch: 9.59 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09923248748794772		[learning rate: 0.0018562]
	Learning Rate: 0.00185623
	LOSS [training: 0.09923248748794772 | validation: 0.07046678714484651]
	TIME [epoch: 9.6 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09578810239797739		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.09578810239797739 | validation: 0.18095460008910852]
	TIME [epoch: 9.58 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1631830550780198		[learning rate: 0.0018473]
	Learning Rate: 0.00184725
	LOSS [training: 0.1631830550780198 | validation: 0.12495959988585024]
	TIME [epoch: 9.58 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14505269558350503		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.14505269558350503 | validation: 0.0900523141873465]
	TIME [epoch: 9.59 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08709865984011336		[learning rate: 0.0018383]
	Learning Rate: 0.00183832
	LOSS [training: 0.08709865984011336 | validation: 0.12625229933423487]
	TIME [epoch: 9.6 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10857276280669796		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.10857276280669796 | validation: 0.04928394585667273]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_800.pth
	Model improved!!!
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07205449110645369		[learning rate: 0.0018294]
	Learning Rate: 0.00182943
	LOSS [training: 0.07205449110645369 | validation: 0.13268123635376086]
	TIME [epoch: 9.58 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10883421088267167		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.10883421088267167 | validation: 0.06446139909158008]
	TIME [epoch: 9.59 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07312614124499586		[learning rate: 0.0018206]
	Learning Rate: 0.00182058
	LOSS [training: 0.07312614124499586 | validation: 0.046262419829452374]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_803.pth
	Model improved!!!
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06281750133756944		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.06281750133756944 | validation: 0.06170393415283778]
	TIME [epoch: 9.58 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07248306795822142		[learning rate: 0.0018118]
	Learning Rate: 0.00181178
	LOSS [training: 0.07248306795822142 | validation: 0.03984574259574361]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_805.pth
	Model improved!!!
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10121200533951047		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.10121200533951047 | validation: 0.033016827401850524]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_806.pth
	Model improved!!!
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05614747715158702		[learning rate: 0.001803]
	Learning Rate: 0.00180302
	LOSS [training: 0.05614747715158702 | validation: 0.06788586626637796]
	TIME [epoch: 9.59 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07422058659573348		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.07422058659573348 | validation: 0.11553542561688175]
	TIME [epoch: 9.58 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0904496455742545		[learning rate: 0.0017943]
	Learning Rate: 0.0017943
	LOSS [training: 0.0904496455742545 | validation: 0.057086253989891596]
	TIME [epoch: 9.59 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05819609566421848		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.05819609566421848 | validation: 0.0927897182481745]
	TIME [epoch: 9.6 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09702896189802633		[learning rate: 0.0017856]
	Learning Rate: 0.00178562
	LOSS [training: 0.09702896189802633 | validation: 0.1166135852504447]
	TIME [epoch: 9.59 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11261390845059589		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.11261390845059589 | validation: 0.0764428236403282]
	TIME [epoch: 9.58 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08861552948993305		[learning rate: 0.001777]
	Learning Rate: 0.00177699
	LOSS [training: 0.08861552948993305 | validation: 0.0722149742388563]
	TIME [epoch: 9.61 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13213178936708794		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.13213178936708794 | validation: 0.17836844486027117]
	TIME [epoch: 9.59 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11455710883873808		[learning rate: 0.0017684]
	Learning Rate: 0.00176839
	LOSS [training: 0.11455710883873808 | validation: 0.05661960188420137]
	TIME [epoch: 9.58 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1033310586455504		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.1033310586455504 | validation: 0.07053360554044655]
	TIME [epoch: 9.58 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0581610406674382		[learning rate: 0.0017598]
	Learning Rate: 0.00175984
	LOSS [training: 0.0581610406674382 | validation: 0.072971111080108]
	TIME [epoch: 9.61 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10056415922956419		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.10056415922956419 | validation: 0.055754146580353076]
	TIME [epoch: 9.59 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060931449732694806		[learning rate: 0.0017513]
	Learning Rate: 0.00175133
	LOSS [training: 0.060931449732694806 | validation: 0.0350063974027149]
	TIME [epoch: 9.59 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05490507192684193		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.05490507192684193 | validation: 0.052745312016106556]
	TIME [epoch: 9.59 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13561732442264987		[learning rate: 0.0017429]
	Learning Rate: 0.00174286
	LOSS [training: 0.13561732442264987 | validation: 0.14446493383416767]
	TIME [epoch: 9.6 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19036675742800763		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.19036675742800763 | validation: 0.10711593946757553]
	TIME [epoch: 9.58 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13815542615737947		[learning rate: 0.0017344]
	Learning Rate: 0.00173443
	LOSS [training: 0.13815542615737947 | validation: 0.09994508154871476]
	TIME [epoch: 9.59 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15642348965976577		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.15642348965976577 | validation: 0.19496499487029628]
	TIME [epoch: 9.6 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22444980753551488		[learning rate: 0.001726]
	Learning Rate: 0.00172605
	LOSS [training: 0.22444980753551488 | validation: 0.180903870210824]
	TIME [epoch: 9.59 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.299791508269882		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.299791508269882 | validation: 0.4732936473607765]
	TIME [epoch: 9.58 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5350857773038433		[learning rate: 0.0017177]
	Learning Rate: 0.0017177
	LOSS [training: 0.5350857773038433 | validation: 0.28293138547580826]
	TIME [epoch: 9.59 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41994988730073884		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.41994988730073884 | validation: 0.4386659403459339]
	TIME [epoch: 9.6 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5872172173600451		[learning rate: 0.0017094]
	Learning Rate: 0.00170939
	LOSS [training: 0.5872172173600451 | validation: 0.4992167367616513]
	TIME [epoch: 9.59 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7212381536451907		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.7212381536451907 | validation: 0.4917549488997058]
	TIME [epoch: 9.58 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5222652073125389		[learning rate: 0.0017011]
	Learning Rate: 0.00170113
	LOSS [training: 0.5222652073125389 | validation: 0.25467892858744995]
	TIME [epoch: 9.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3702438310346076		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.3702438310346076 | validation: 0.2783916932865944]
	TIME [epoch: 9.6 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2904618696541911		[learning rate: 0.0016929]
	Learning Rate: 0.0016929
	LOSS [training: 0.2904618696541911 | validation: 0.2577857482683507]
	TIME [epoch: 9.58 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3843353955498913		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.3843353955498913 | validation: 0.3148683801144954]
	TIME [epoch: 9.58 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6172875154040971		[learning rate: 0.0016847]
	Learning Rate: 0.00168471
	LOSS [training: 0.6172875154040971 | validation: 0.6178557353399194]
	TIME [epoch: 9.59 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8645011939767363		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.8645011939767363 | validation: 0.4834749233129719]
	TIME [epoch: 9.59 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5448300542220115		[learning rate: 0.0016766]
	Learning Rate: 0.00167657
	LOSS [training: 0.5448300542220115 | validation: 0.2321112199356282]
	TIME [epoch: 9.58 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18439077973428367		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.18439077973428367 | validation: 0.11918218022618525]
	TIME [epoch: 9.58 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14617518376555122		[learning rate: 0.0016685]
	Learning Rate: 0.00166846
	LOSS [training: 0.14617518376555122 | validation: 0.12212124636654093]
	TIME [epoch: 9.6 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14300414239560624		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.14300414239560624 | validation: 0.12674944750986553]
	TIME [epoch: 9.6 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11149315836007787		[learning rate: 0.0016604]
	Learning Rate: 0.00166039
	LOSS [training: 0.11149315836007787 | validation: 0.08117837193714923]
	TIME [epoch: 9.58 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10286261703744996		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.10286261703744996 | validation: 0.10832832551346241]
	TIME [epoch: 9.61 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1273611460789265		[learning rate: 0.0016524]
	Learning Rate: 0.00165236
	LOSS [training: 0.1273611460789265 | validation: 0.08277127658821516]
	TIME [epoch: 9.58 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08543695534330963		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.08543695534330963 | validation: 0.10114394651208908]
	TIME [epoch: 9.59 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21166510516061782		[learning rate: 0.0016444]
	Learning Rate: 0.00164437
	LOSS [training: 0.21166510516061782 | validation: 0.23745268825885685]
	TIME [epoch: 9.58 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34828680152701064		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.34828680152701064 | validation: 0.36168076465102444]
	TIME [epoch: 9.61 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3622494678508927		[learning rate: 0.0016364]
	Learning Rate: 0.00163642
	LOSS [training: 0.3622494678508927 | validation: 0.11950117683138693]
	TIME [epoch: 9.59 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23973868397413867		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.23973868397413867 | validation: 0.31222664677889184]
	TIME [epoch: 9.58 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308793995267023		[learning rate: 0.0016285]
	Learning Rate: 0.00162851
	LOSS [training: 0.308793995267023 | validation: 0.3261862611896213]
	TIME [epoch: 9.59 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5473472651983907		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.5473472651983907 | validation: 0.33934825894891246]
	TIME [epoch: 9.6 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30427274295852824		[learning rate: 0.0016206]
	Learning Rate: 0.00162063
	LOSS [training: 0.30427274295852824 | validation: 0.12818899074126536]
	TIME [epoch: 9.59 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17465719669806137		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.17465719669806137 | validation: 0.1590271377773604]
	TIME [epoch: 9.58 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16445975276114147		[learning rate: 0.0016128]
	Learning Rate: 0.00161279
	LOSS [training: 0.16445975276114147 | validation: 0.13610699128035872]
	TIME [epoch: 9.61 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22347691128037916		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.22347691128037916 | validation: 0.19601849435756977]
	TIME [epoch: 9.59 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20449168786260002		[learning rate: 0.001605]
	Learning Rate: 0.001605
	LOSS [training: 0.20449168786260002 | validation: 0.16592457277075226]
	TIME [epoch: 9.58 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1752519269350445		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.1752519269350445 | validation: 0.21708819611756916]
	TIME [epoch: 9.59 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20684974896264446		[learning rate: 0.0015972]
	Learning Rate: 0.00159723
	LOSS [training: 0.20684974896264446 | validation: 0.14345193783173166]
	TIME [epoch: 9.6 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12082303610640473		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.12082303610640473 | validation: 0.1291439942483884]
	TIME [epoch: 9.59 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0929591317394218		[learning rate: 0.0015895]
	Learning Rate: 0.00158951
	LOSS [training: 0.0929591317394218 | validation: 0.0716844775196846]
	TIME [epoch: 9.59 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10904158697702675		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.10904158697702675 | validation: 0.17016422328835373]
	TIME [epoch: 9.59 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20772297398824166		[learning rate: 0.0015818]
	Learning Rate: 0.00158182
	LOSS [training: 0.20772297398824166 | validation: 0.1409821529778425]
	TIME [epoch: 9.59 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10962653198589807		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.10962653198589807 | validation: 0.09481423324882197]
	TIME [epoch: 9.58 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11030103607745054		[learning rate: 0.0015742]
	Learning Rate: 0.00157417
	LOSS [training: 0.11030103607745054 | validation: 0.13100250326236137]
	TIME [epoch: 9.58 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1156097027958087		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.1156097027958087 | validation: 0.0924857914301062]
	TIME [epoch: 9.6 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0926916267057086		[learning rate: 0.0015666]
	Learning Rate: 0.00156656
	LOSS [training: 0.0926916267057086 | validation: 0.10597289891802739]
	TIME [epoch: 9.58 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.131481068069593		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.131481068069593 | validation: 0.07736480251095905]
	TIME [epoch: 9.58 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08049436734601856		[learning rate: 0.001559]
	Learning Rate: 0.00155899
	LOSS [training: 0.08049436734601856 | validation: 0.11474194350773143]
	TIME [epoch: 9.58 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10907515365199352		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.10907515365199352 | validation: 0.17663090116884533]
	TIME [epoch: 9.59 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13419221552228042		[learning rate: 0.0015514]
	Learning Rate: 0.00155145
	LOSS [training: 0.13419221552228042 | validation: 0.10790877227435113]
	TIME [epoch: 9.59 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11028711255381114		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.11028711255381114 | validation: 0.08588994170449837]
	TIME [epoch: 9.59 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13230862187004383		[learning rate: 0.0015439]
	Learning Rate: 0.00154394
	LOSS [training: 0.13230862187004383 | validation: 0.1533326276496369]
	TIME [epoch: 9.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1421459341277464		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.1421459341277464 | validation: 0.0862451390000335]
	TIME [epoch: 9.59 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0975552581686702		[learning rate: 0.0015365]
	Learning Rate: 0.00153648
	LOSS [training: 0.0975552581686702 | validation: 0.09196920766813793]
	TIME [epoch: 9.59 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13200452340762286		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.13200452340762286 | validation: 0.16449317788661513]
	TIME [epoch: 9.58 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1803320278294015		[learning rate: 0.001529]
	Learning Rate: 0.00152905
	LOSS [training: 0.1803320278294015 | validation: 0.1290404988168119]
	TIME [epoch: 9.6 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14439030574643777		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.14439030574643777 | validation: 0.10122103946987278]
	TIME [epoch: 9.59 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13541928256848487		[learning rate: 0.0015217]
	Learning Rate: 0.00152165
	LOSS [training: 0.13541928256848487 | validation: 0.12604964295834253]
	TIME [epoch: 9.57 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15553247431506584		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.15553247431506584 | validation: 0.09759564441293385]
	TIME [epoch: 9.59 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14488116998591943		[learning rate: 0.0015143]
	Learning Rate: 0.00151429
	LOSS [training: 0.14488116998591943 | validation: 0.13340269450338432]
	TIME [epoch: 9.6 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13606900902533428		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.13606900902533428 | validation: 0.12787085648728355]
	TIME [epoch: 9.58 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15938434912642477		[learning rate: 0.001507]
	Learning Rate: 0.00150697
	LOSS [training: 0.15938434912642477 | validation: 0.12855252582502813]
	TIME [epoch: 9.58 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11299813804423509		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.11299813804423509 | validation: 0.08047264411423137]
	TIME [epoch: 9.6 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.084462553935222		[learning rate: 0.0014997]
	Learning Rate: 0.00149968
	LOSS [training: 0.084462553935222 | validation: 0.06941475087823135]
	TIME [epoch: 9.59 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0812063483504537		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.0812063483504537 | validation: 0.08843891366329935]
	TIME [epoch: 9.59 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05877517331849411		[learning rate: 0.0014924]
	Learning Rate: 0.00149243
	LOSS [training: 0.05877517331849411 | validation: 0.04243395849302753]
	TIME [epoch: 9.58 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06264694077601032		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.06264694077601032 | validation: 0.06736572659093419]
	TIME [epoch: 9.6 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08961788645203232		[learning rate: 0.0014852]
	Learning Rate: 0.00148522
	LOSS [training: 0.08961788645203232 | validation: 0.11549664094923634]
	TIME [epoch: 9.58 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11656808602939468		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.11656808602939468 | validation: 0.09761590809741051]
	TIME [epoch: 9.58 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07525955052892337		[learning rate: 0.001478]
	Learning Rate: 0.00147803
	LOSS [training: 0.07525955052892337 | validation: 0.05542269187349083]
	TIME [epoch: 9.6 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06222338548843746		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.06222338548843746 | validation: 0.05672707565579863]
	TIME [epoch: 9.59 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06329945683597274		[learning rate: 0.0014709]
	Learning Rate: 0.00147089
	LOSS [training: 0.06329945683597274 | validation: 0.03986618060940717]
	TIME [epoch: 9.58 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04777514294797773		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.04777514294797773 | validation: 0.09523921784502606]
	TIME [epoch: 9.59 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06444078971848125		[learning rate: 0.0014638]
	Learning Rate: 0.00146377
	LOSS [training: 0.06444078971848125 | validation: 0.06000433623572108]
	TIME [epoch: 9.6 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05431605968612677		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.05431605968612677 | validation: 0.05079946420563866]
	TIME [epoch: 9.58 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09870405150362178		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.09870405150362178 | validation: 0.14028821757636042]
	TIME [epoch: 9.58 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.118429481419615		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.118429481419615 | validation: 0.11108693646631576]
	TIME [epoch: 9.58 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11331995513865249		[learning rate: 0.0014497]
	Learning Rate: 0.00144965
	LOSS [training: 0.11331995513865249 | validation: 0.17055313266939492]
	TIME [epoch: 9.59 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15472660662006027		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.15472660662006027 | validation: 0.09411142876675012]
	TIME [epoch: 9.59 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09159089436499693		[learning rate: 0.0014426]
	Learning Rate: 0.00144264
	LOSS [training: 0.09159089436499693 | validation: 0.10173390660901646]
	TIME [epoch: 9.57 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07221595251999009		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.07221595251999009 | validation: 0.08564493042290273]
	TIME [epoch: 9.59 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10010841340691135		[learning rate: 0.0014357]
	Learning Rate: 0.00143566
	LOSS [training: 0.10010841340691135 | validation: 0.08914193873421684]
	TIME [epoch: 9.6 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11550751228002679		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.11550751228002679 | validation: 0.09429455993905567]
	TIME [epoch: 9.59 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11328943313401199		[learning rate: 0.0014287]
	Learning Rate: 0.00142872
	LOSS [training: 0.11328943313401199 | validation: 0.06945327171404182]
	TIME [epoch: 9.58 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07425684930635643		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.07425684930635643 | validation: 0.06483354878721867]
	TIME [epoch: 9.61 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08278853183335505		[learning rate: 0.0014218]
	Learning Rate: 0.00142181
	LOSS [training: 0.08278853183335505 | validation: 0.044580771965527156]
	TIME [epoch: 9.59 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07552200005752989		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.07552200005752989 | validation: 0.09602320105918276]
	TIME [epoch: 9.59 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09085848210317075		[learning rate: 0.0014149]
	Learning Rate: 0.00141494
	LOSS [training: 0.09085848210317075 | validation: 0.08511751328338078]
	TIME [epoch: 9.58 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06799572062222932		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.06799572062222932 | validation: 0.04523718707747034]
	TIME [epoch: 9.6 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05785251179448767		[learning rate: 0.0014081]
	Learning Rate: 0.00140809
	LOSS [training: 0.05785251179448767 | validation: 0.08245823019827946]
	TIME [epoch: 9.59 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06887608471099073		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.06887608471099073 | validation: 0.06313258255177275]
	TIME [epoch: 9.58 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05810928127346421		[learning rate: 0.0014013]
	Learning Rate: 0.00140128
	LOSS [training: 0.05810928127346421 | validation: 0.062393336311330504]
	TIME [epoch: 9.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06285411062511145		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.06285411062511145 | validation: 0.05496380492204269]
	TIME [epoch: 9.59 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07530330846197766		[learning rate: 0.0013945]
	Learning Rate: 0.00139451
	LOSS [training: 0.07530330846197766 | validation: 0.09313396270508408]
	TIME [epoch: 9.58 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15311088793500122		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.15311088793500122 | validation: 0.13646597427905025]
	TIME [epoch: 9.59 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14892861977007624		[learning rate: 0.0013878]
	Learning Rate: 0.00138776
	LOSS [training: 0.14892861977007624 | validation: 0.15174280856271738]
	TIME [epoch: 9.61 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13306566524376068		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.13306566524376068 | validation: 0.11968441400456861]
	TIME [epoch: 9.58 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09099551852780233		[learning rate: 0.0013811]
	Learning Rate: 0.00138105
	LOSS [training: 0.09099551852780233 | validation: 0.06699457970202967]
	TIME [epoch: 9.59 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07116855461571854		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.07116855461571854 | validation: 0.08191648244629587]
	TIME [epoch: 9.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09334392311567227		[learning rate: 0.0013744]
	Learning Rate: 0.00137437
	LOSS [training: 0.09334392311567227 | validation: 0.07838725320971865]
	TIME [epoch: 9.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06758785046331177		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.06758785046331177 | validation: 0.07243316332059771]
	TIME [epoch: 9.58 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0607490847677674		[learning rate: 0.0013677]
	Learning Rate: 0.00136773
	LOSS [training: 0.0607490847677674 | validation: 0.0719151555217994]
	TIME [epoch: 9.59 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0644051119268768		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.0644051119268768 | validation: 0.05482603944593536]
	TIME [epoch: 9.6 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05787498642931914		[learning rate: 0.0013611]
	Learning Rate: 0.00136111
	LOSS [training: 0.05787498642931914 | validation: 0.08410161805076737]
	TIME [epoch: 9.59 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07405112281012435		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.07405112281012435 | validation: 0.05064042489020558]
	TIME [epoch: 9.59 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05960792119201512		[learning rate: 0.0013545]
	Learning Rate: 0.00135453
	LOSS [training: 0.05960792119201512 | validation: 0.05365018419651987]
	TIME [epoch: 9.58 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0966044748118412		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.0966044748118412 | validation: 0.14417034182514094]
	TIME [epoch: 9.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14644883554745056		[learning rate: 0.001348]
	Learning Rate: 0.00134798
	LOSS [training: 0.14644883554745056 | validation: 0.08757247461257887]
	TIME [epoch: 9.59 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07183501580074299		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.07183501580074299 | validation: 0.0668268935711409]
	TIME [epoch: 9.59 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07438330851142978		[learning rate: 0.0013415]
	Learning Rate: 0.00134146
	LOSS [training: 0.07438330851142978 | validation: 0.09992403122394912]
	TIME [epoch: 9.6 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11144368374986786		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.11144368374986786 | validation: 0.0622026165024599]
	TIME [epoch: 9.6 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08177563927309975		[learning rate: 0.001335]
	Learning Rate: 0.00133498
	LOSS [training: 0.08177563927309975 | validation: 0.07095110726708935]
	TIME [epoch: 9.58 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08748682944897836		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.08748682944897836 | validation: 0.07130434221050803]
	TIME [epoch: 9.58 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07042299464547451		[learning rate: 0.0013285]
	Learning Rate: 0.00132852
	LOSS [training: 0.07042299464547451 | validation: 0.05105081398052687]
	TIME [epoch: 9.6 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05305641485271757		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.05305641485271757 | validation: 0.04589287193412523]
	TIME [epoch: 9.6 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04761031565147432		[learning rate: 0.0013221]
	Learning Rate: 0.0013221
	LOSS [training: 0.04761031565147432 | validation: 0.04202879905705747]
	TIME [epoch: 9.58 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0816347483852395		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.0816347483852395 | validation: 0.08227046616180993]
	TIME [epoch: 9.59 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10470805175767073		[learning rate: 0.0013157]
	Learning Rate: 0.0013157
	LOSS [training: 0.10470805175767073 | validation: 0.08600475461265704]
	TIME [epoch: 9.6 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11758182809839117		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.11758182809839117 | validation: 0.06736410196006]
	TIME [epoch: 9.59 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09904729485577857		[learning rate: 0.0013093]
	Learning Rate: 0.00130934
	LOSS [training: 0.09904729485577857 | validation: 0.05380477504102741]
	TIME [epoch: 9.58 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0962846676612578		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.0962846676612578 | validation: 0.1687223278950396]
	TIME [epoch: 9.61 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1786448606848597		[learning rate: 0.001303]
	Learning Rate: 0.00130301
	LOSS [training: 0.1786448606848597 | validation: 0.29347769916540034]
	TIME [epoch: 9.59 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27930782950725297		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.27930782950725297 | validation: 0.15567592440416783]
	TIME [epoch: 9.59 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11264209621201444		[learning rate: 0.0012967]
	Learning Rate: 0.00129671
	LOSS [training: 0.11264209621201444 | validation: 0.07776448074359485]
	TIME [epoch: 9.58 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0678937371649234		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.0678937371649234 | validation: 0.06738390377608902]
	TIME [epoch: 9.6 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05911821895111909		[learning rate: 0.0012904]
	Learning Rate: 0.00129044
	LOSS [training: 0.05911821895111909 | validation: 0.06575373513600766]
	TIME [epoch: 9.58 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052689226501329664		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.052689226501329664 | validation: 0.09943233486642082]
	TIME [epoch: 9.59 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07043720964366809		[learning rate: 0.0012842]
	Learning Rate: 0.0012842
	LOSS [training: 0.07043720964366809 | validation: 0.07337197343233359]
	TIME [epoch: 9.58 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09110450476611551		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.09110450476611551 | validation: 0.10282207122091194]
	TIME [epoch: 9.6 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09231505970204616		[learning rate: 0.001278]
	Learning Rate: 0.00127799
	LOSS [training: 0.09231505970204616 | validation: 0.0712637130959279]
	TIME [epoch: 9.58 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06737462249106481		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.06737462249106481 | validation: 0.038430297427365846]
	TIME [epoch: 9.59 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05403116426917155		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.05403116426917155 | validation: 0.04867062926548019]
	TIME [epoch: 9.61 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06232916457819386		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.06232916457819386 | validation: 0.039463793762564335]
	TIME [epoch: 9.59 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060211920794057974		[learning rate: 0.0012657]
	Learning Rate: 0.00126566
	LOSS [training: 0.060211920794057974 | validation: 0.06915924573367356]
	TIME [epoch: 9.58 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06520738699579322		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.06520738699579322 | validation: 0.07672146348972059]
	TIME [epoch: 9.59 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07780923954303162		[learning rate: 0.0012595]
	Learning Rate: 0.00125954
	LOSS [training: 0.07780923954303162 | validation: 0.08797571669266673]
	TIME [epoch: 9.6 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11882660181780844		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.11882660181780844 | validation: 0.09450507356767406]
	TIME [epoch: 9.59 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09792647135618109		[learning rate: 0.0012534]
	Learning Rate: 0.00125344
	LOSS [training: 0.09792647135618109 | validation: 0.0814244439948403]
	TIME [epoch: 9.59 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08844830434075533		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.08844830434075533 | validation: 0.11993627272244173]
	TIME [epoch: 9.6 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12115318675898665		[learning rate: 0.0012474]
	Learning Rate: 0.00124738
	LOSS [training: 0.12115318675898665 | validation: 0.08733401556836587]
	TIME [epoch: 9.59 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13376976555640907		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.13376976555640907 | validation: 0.20242990076627762]
	TIME [epoch: 9.58 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29553013015384166		[learning rate: 0.0012414]
	Learning Rate: 0.00124135
	LOSS [training: 0.29553013015384166 | validation: 0.19709164258148118]
	TIME [epoch: 9.58 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20506162990013782		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.20506162990013782 | validation: 0.17224754549894009]
	TIME [epoch: 9.6 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22250861994655433		[learning rate: 0.0012353]
	Learning Rate: 0.00123535
	LOSS [training: 0.22250861994655433 | validation: 0.19996157336028503]
	TIME [epoch: 9.58 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2000245136565093		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.2000245136565093 | validation: 0.19853277550510767]
	TIME [epoch: 9.59 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2062590456214281		[learning rate: 0.0012294]
	Learning Rate: 0.00122937
	LOSS [training: 0.2062590456214281 | validation: 0.15473358078877789]
	TIME [epoch: 9.58 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19371523440276298		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.19371523440276298 | validation: 0.15792509446519662]
	TIME [epoch: 9.61 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16338359750370632		[learning rate: 0.0012234]
	Learning Rate: 0.00122343
	LOSS [training: 0.16338359750370632 | validation: 0.12353351493254186]
	TIME [epoch: 9.58 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21231033354610393		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.21231033354610393 | validation: 0.27124335720328263]
	TIME [epoch: 9.58 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3076162544152969		[learning rate: 0.0012175]
	Learning Rate: 0.00121751
	LOSS [training: 0.3076162544152969 | validation: 0.20795558821870758]
	TIME [epoch: 9.6 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1878448490973208		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.1878448490973208 | validation: 0.12854012228479283]
	TIME [epoch: 9.59 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1156008876215147		[learning rate: 0.0012116]
	Learning Rate: 0.00121163
	LOSS [training: 0.1156008876215147 | validation: 0.08685203991444147]
	TIME [epoch: 9.58 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1153889175870754		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.1153889175870754 | validation: 0.08326791490622379]
	TIME [epoch: 9.58 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08736355664767964		[learning rate: 0.0012058]
	Learning Rate: 0.00120577
	LOSS [training: 0.08736355664767964 | validation: 0.07968436233644444]
	TIME [epoch: 9.6 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08300957841545906		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.08300957841545906 | validation: 0.0655765353227892]
	TIME [epoch: 9.59 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07551378600893724		[learning rate: 0.0011999]
	Learning Rate: 0.00119994
	LOSS [training: 0.07551378600893724 | validation: 0.06353313898842977]
	TIME [epoch: 9.58 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0781880161552704		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.0781880161552704 | validation: 0.07482637048847285]
	TIME [epoch: 9.59 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08574422361754395		[learning rate: 0.0011941]
	Learning Rate: 0.00119413
	LOSS [training: 0.08574422361754395 | validation: 0.07004409020660435]
	TIME [epoch: 9.61 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07303674824460839		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.07303674824460839 | validation: 0.07692918157891984]
	TIME [epoch: 9.59 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1011233142583324		[learning rate: 0.0011884]
	Learning Rate: 0.00118836
	LOSS [training: 0.1011233142583324 | validation: 0.09675623763021478]
	TIME [epoch: 9.58 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12047026988809391		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.12047026988809391 | validation: 0.10963659193217305]
	TIME [epoch: 9.6 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12136299632136702		[learning rate: 0.0011826]
	Learning Rate: 0.00118261
	LOSS [training: 0.12136299632136702 | validation: 0.1509584727792539]
	TIME [epoch: 9.59 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1121625358036148		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.1121625358036148 | validation: 0.08322170230984298]
	TIME [epoch: 9.59 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09382299295544896		[learning rate: 0.0011769]
	Learning Rate: 0.00117689
	LOSS [training: 0.09382299295544896 | validation: 0.1243640656962025]
	TIME [epoch: 9.58 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10862593996780245		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.10862593996780245 | validation: 0.11923789577946854]
	TIME [epoch: 9.6 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11534520120252915		[learning rate: 0.0011712]
	Learning Rate: 0.0011712
	LOSS [training: 0.11534520120252915 | validation: 0.097030017668126]
	TIME [epoch: 9.58 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10977553218440794		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.10977553218440794 | validation: 0.09323116584234314]
	TIME [epoch: 9.58 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11848162103310053		[learning rate: 0.0011655]
	Learning Rate: 0.00116554
	LOSS [training: 0.11848162103310053 | validation: 0.09697724888370399]
	TIME [epoch: 9.59 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0905704081735499		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.0905704081735499 | validation: 0.10411501231781944]
	TIME [epoch: 9.59 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10715979030385356		[learning rate: 0.0011599]
	Learning Rate: 0.0011599
	LOSS [training: 0.10715979030385356 | validation: 0.1406304750102272]
	TIME [epoch: 9.58 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.270570902567115		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.270570902567115 | validation: 0.3054227677766649]
	TIME [epoch: 9.58 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36812394662354414		[learning rate: 0.0011543]
	Learning Rate: 0.00115429
	LOSS [training: 0.36812394662354414 | validation: 0.26008158530335385]
	TIME [epoch: 9.6 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24010072034983243		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.24010072034983243 | validation: 0.2288053785541146]
	TIME [epoch: 9.59 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2915991195479362		[learning rate: 0.0011487]
	Learning Rate: 0.00114871
	LOSS [training: 0.2915991195479362 | validation: 0.16487217259183265]
	TIME [epoch: 9.59 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17535299514742717		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.17535299514742717 | validation: 0.22993644313102932]
	TIME [epoch: 9.59 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23808562451250417		[learning rate: 0.0011432]
	Learning Rate: 0.00114316
	LOSS [training: 0.23808562451250417 | validation: 0.1219992562648613]
	TIME [epoch: 9.6 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1154418873124319		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.1154418873124319 | validation: 0.10578192721456357]
	TIME [epoch: 9.58 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09827842989085366		[learning rate: 0.0011376]
	Learning Rate: 0.00113763
	LOSS [training: 0.09827842989085366 | validation: 0.10030325997890432]
	TIME [epoch: 9.6 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10379324032322827		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.10379324032322827 | validation: 0.10119205789375457]
	TIME [epoch: 9.61 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12253288146290742		[learning rate: 0.0011321]
	Learning Rate: 0.00113213
	LOSS [training: 0.12253288146290742 | validation: 0.08350430283445383]
	TIME [epoch: 9.6 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11859286835846203		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.11859286835846203 | validation: 0.10858576271381061]
	TIME [epoch: 9.59 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11023631084537751		[learning rate: 0.0011267]
	Learning Rate: 0.00112665
	LOSS [training: 0.11023631084537751 | validation: 0.09657495158997292]
	TIME [epoch: 9.58 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1107130332925718		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.1107130332925718 | validation: 0.13120698061773253]
	TIME [epoch: 9.6 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1757759316839985		[learning rate: 0.0011212]
	Learning Rate: 0.0011212
	LOSS [training: 0.1757759316839985 | validation: 0.12393636408576736]
	TIME [epoch: 9.59 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11742111903702443		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.11742111903702443 | validation: 0.08814575470075159]
	TIME [epoch: 9.58 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08050789687662559		[learning rate: 0.0011158]
	Learning Rate: 0.00111578
	LOSS [training: 0.08050789687662559 | validation: 0.12963212118625658]
	TIME [epoch: 9.58 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10809347846647148		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.10809347846647148 | validation: 0.07533766856311928]
	TIME [epoch: 9.6 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0759994782991324		[learning rate: 0.0011104]
	Learning Rate: 0.00111039
	LOSS [training: 0.0759994782991324 | validation: 0.12501675465930942]
	TIME [epoch: 9.58 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09370889621961356		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.09370889621961356 | validation: 0.1385712821299258]
	TIME [epoch: 9.58 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24997458190191058		[learning rate: 0.001105]
	Learning Rate: 0.00110502
	LOSS [training: 0.24997458190191058 | validation: 0.26292183879277503]
	TIME [epoch: 9.6 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3298506400291172		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.3298506400291172 | validation: 0.19168037780193514]
	TIME [epoch: 9.58 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1507145746310023		[learning rate: 0.0010997]
	Learning Rate: 0.00109967
	LOSS [training: 0.1507145746310023 | validation: 0.07411666023894938]
	TIME [epoch: 9.58 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09651112901674215		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.09651112901674215 | validation: 0.07836471455589954]
	TIME [epoch: 9.58 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0631443717113134		[learning rate: 0.0010944]
	Learning Rate: 0.00109435
	LOSS [training: 0.0631443717113134 | validation: 0.06496137217271272]
	TIME [epoch: 9.6 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07868080268558532		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.07868080268558532 | validation: 0.07886435193851034]
	TIME [epoch: 9.58 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08390332282454353		[learning rate: 0.0010891]
	Learning Rate: 0.00108906
	LOSS [training: 0.08390332282454353 | validation: 0.08064165524107404]
	TIME [epoch: 9.58 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07991562204780649		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.07991562204780649 | validation: 0.07231841019675908]
	TIME [epoch: 9.6 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0686392453042107		[learning rate: 0.0010838]
	Learning Rate: 0.0010838
	LOSS [training: 0.0686392453042107 | validation: 0.0928915474270909]
	TIME [epoch: 9.59 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0724577730720419		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.0724577730720419 | validation: 0.07318765148478062]
	TIME [epoch: 9.58 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07862469730738199		[learning rate: 0.0010786]
	Learning Rate: 0.00107855
	LOSS [training: 0.07862469730738199 | validation: 0.07091573881991149]
	TIME [epoch: 9.59 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06239445474397913		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.06239445474397913 | validation: 0.07677086069250298]
	TIME [epoch: 9.6 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057388020370787274		[learning rate: 0.0010733]
	Learning Rate: 0.00107334
	LOSS [training: 0.057388020370787274 | validation: 0.08199162668041901]
	TIME [epoch: 9.58 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07071607653268626		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.07071607653268626 | validation: 0.07032489311639868]
	TIME [epoch: 9.59 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08448217467618264		[learning rate: 0.0010681]
	Learning Rate: 0.00106815
	LOSS [training: 0.08448217467618264 | validation: 0.05181552068256255]
	TIME [epoch: 9.58 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10532590743518795		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.10532590743518795 | validation: 0.09400708820813883]
	TIME [epoch: 9.61 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08748102575650947		[learning rate: 0.001063]
	Learning Rate: 0.00106298
	LOSS [training: 0.08748102575650947 | validation: 0.05230595443131922]
	TIME [epoch: 9.58 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06120493623325054		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.06120493623325054 | validation: 0.0689746431931733]
	TIME [epoch: 9.59 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09612583143523917		[learning rate: 0.0010578]
	Learning Rate: 0.00105784
	LOSS [training: 0.09612583143523917 | validation: 0.09196840376190624]
	TIME [epoch: 9.59 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09044779916045435		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.09044779916045435 | validation: 0.06397035341173035]
	TIME [epoch: 9.59 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0886343866641868		[learning rate: 0.0010527]
	Learning Rate: 0.00105273
	LOSS [training: 0.0886343866641868 | validation: 0.07739741941172247]
	TIME [epoch: 9.58 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08444082410195386		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.08444082410195386 | validation: 0.06659106217574796]
	TIME [epoch: 9.58 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0784644594054977		[learning rate: 0.0010476]
	Learning Rate: 0.00104764
	LOSS [training: 0.0784644594054977 | validation: 0.07956982880935554]
	TIME [epoch: 9.6 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0798501347289779		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.0798501347289779 | validation: 0.07119733608455567]
	TIME [epoch: 9.59 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09450968646166633		[learning rate: 0.0010426]
	Learning Rate: 0.00104257
	LOSS [training: 0.09450968646166633 | validation: 0.07798481720382269]
	TIME [epoch: 9.58 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06328046619707525		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.06328046619707525 | validation: 0.024637642623924025]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_1034.pth
	Model improved!!!
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06099436547057775		[learning rate: 0.0010375]
	Learning Rate: 0.00103753
	LOSS [training: 0.06099436547057775 | validation: 0.05236820215328033]
	TIME [epoch: 9.6 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07088956084826534		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.07088956084826534 | validation: 0.05149320465871053]
	TIME [epoch: 9.59 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07338679819418746		[learning rate: 0.0010325]
	Learning Rate: 0.00103251
	LOSS [training: 0.07338679819418746 | validation: 0.06878023740452126]
	TIME [epoch: 9.59 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08181039093046744		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.08181039093046744 | validation: 0.06566215948937641]
	TIME [epoch: 9.61 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06869920352818086		[learning rate: 0.0010275]
	Learning Rate: 0.00102752
	LOSS [training: 0.06869920352818086 | validation: 0.07617820372211381]
	TIME [epoch: 9.59 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058283210387981024		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.058283210387981024 | validation: 0.0346173243685808]
	TIME [epoch: 9.59 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06901063606505908		[learning rate: 0.0010225]
	Learning Rate: 0.00102255
	LOSS [training: 0.06901063606505908 | validation: 0.08974211597372414]
	TIME [epoch: 9.58 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08947267587239364		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.08947267587239364 | validation: 0.10063523198004319]
	TIME [epoch: 9.6 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09581232990050256		[learning rate: 0.0010176]
	Learning Rate: 0.0010176
	LOSS [training: 0.09581232990050256 | validation: 0.0905807876540283]
	TIME [epoch: 9.59 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07726841045310887		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.07726841045310887 | validation: 0.055142608026696606]
	TIME [epoch: 9.59 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07669073658035942		[learning rate: 0.0010127]
	Learning Rate: 0.00101268
	LOSS [training: 0.07669073658035942 | validation: 0.10182516932498029]
	TIME [epoch: 9.6 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0930261934513327		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.0930261934513327 | validation: 0.07088787949508195]
	TIME [epoch: 9.6 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08043574128271254		[learning rate: 0.0010078]
	Learning Rate: 0.00100779
	LOSS [training: 0.08043574128271254 | validation: 0.06035566702250758]
	TIME [epoch: 9.58 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08767592910305727		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.08767592910305727 | validation: 0.06570734813442573]
	TIME [epoch: 9.59 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11275821560051047		[learning rate: 0.0010029]
	Learning Rate: 0.00100291
	LOSS [training: 0.11275821560051047 | validation: 0.08414459625293744]
	TIME [epoch: 9.6 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11474137216225903		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.11474137216225903 | validation: 0.09842956231748776]
	TIME [epoch: 9.59 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1055165775294435		[learning rate: 0.00099806]
	Learning Rate: 0.000998063
	LOSS [training: 0.1055165775294435 | validation: 0.06382567492076359]
	TIME [epoch: 9.58 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07996072149720931		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.07996072149720931 | validation: 0.0835179305767035]
	TIME [epoch: 9.58 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08391291329330343		[learning rate: 0.00099324]
	Learning Rate: 0.000993237
	LOSS [training: 0.08391291329330343 | validation: 0.09040826732824311]
	TIME [epoch: 9.6 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1025648497942454		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.1025648497942454 | validation: 0.07597282507218325]
	TIME [epoch: 9.58 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11043120176499832		[learning rate: 0.00098843]
	Learning Rate: 0.000988433
	LOSS [training: 0.11043120176499832 | validation: 0.07830781960445031]
	TIME [epoch: 9.58 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.122776469079192		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.122776469079192 | validation: 0.08698216651162785]
	TIME [epoch: 9.59 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10008929033512896		[learning rate: 0.00098365]
	Learning Rate: 0.000983653
	LOSS [training: 0.10008929033512896 | validation: 0.08079079874292003]
	TIME [epoch: 9.59 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10477471095591581		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.10477471095591581 | validation: 0.0891381195692094]
	TIME [epoch: 9.57 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11969347843602565		[learning rate: 0.0009789]
	Learning Rate: 0.000978897
	LOSS [training: 0.11969347843602565 | validation: 0.09300415185591668]
	TIME [epoch: 9.59 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12387398390921027		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.12387398390921027 | validation: 0.08470808685647757]
	TIME [epoch: 9.6 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08344617126304454		[learning rate: 0.00097416]
	Learning Rate: 0.000974163
	LOSS [training: 0.08344617126304454 | validation: 0.05978241633663297]
	TIME [epoch: 9.59 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12020397353567032		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.12020397353567032 | validation: 0.12145082802732919]
	TIME [epoch: 9.59 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10525227297424258		[learning rate: 0.00096945]
	Learning Rate: 0.000969452
	LOSS [training: 0.10525227297424258 | validation: 0.07775018248193837]
	TIME [epoch: 9.59 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08114757907300255		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.08114757907300255 | validation: 0.0826982779407577]
	TIME [epoch: 9.6 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09424655999460711		[learning rate: 0.00096476]
	Learning Rate: 0.000964764
	LOSS [training: 0.09424655999460711 | validation: 0.09584490296953892]
	TIME [epoch: 9.59 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08120442455006846		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.08120442455006846 | validation: 0.05430175568931155]
	TIME [epoch: 9.58 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06109474157759857		[learning rate: 0.0009601]
	Learning Rate: 0.000960098
	LOSS [training: 0.06109474157759857 | validation: 0.052814409446255046]
	TIME [epoch: 9.6 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05681285588770367		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.05681285588770367 | validation: 0.06663947399966469]
	TIME [epoch: 9.58 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1090097406659161		[learning rate: 0.00095546]
	Learning Rate: 0.000955456
	LOSS [training: 0.1090097406659161 | validation: 0.10676486024922614]
	TIME [epoch: 9.58 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07546780584787079		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.07546780584787079 | validation: 0.07017272455121441]
	TIME [epoch: 9.58 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07477778224544086		[learning rate: 0.00095084]
	Learning Rate: 0.000950835
	LOSS [training: 0.07477778224544086 | validation: 0.05986098989539322]
	TIME [epoch: 9.61 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06731334861446923		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.06731334861446923 | validation: 0.039965420722622234]
	TIME [epoch: 9.58 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04774745416372963		[learning rate: 0.00094624]
	Learning Rate: 0.000946237
	LOSS [training: 0.04774745416372963 | validation: 0.05372403870218262]
	TIME [epoch: 9.58 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09598638884553636		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.09598638884553636 | validation: 0.10597968235890186]
	TIME [epoch: 9.6 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12950371642108394		[learning rate: 0.00094166]
	Learning Rate: 0.000941661
	LOSS [training: 0.12950371642108394 | validation: 0.07219110078700748]
	TIME [epoch: 9.59 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08277161205132175		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.08277161205132175 | validation: 0.046805505230037174]
	TIME [epoch: 9.58 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04607012272967152		[learning rate: 0.00093711]
	Learning Rate: 0.000937108
	LOSS [training: 0.04607012272967152 | validation: 0.05044441841221171]
	TIME [epoch: 9.58 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0670654516598919		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.0670654516598919 | validation: 0.07368371254479647]
	TIME [epoch: 9.6 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0793218609098373		[learning rate: 0.00093258]
	Learning Rate: 0.000932576
	LOSS [training: 0.0793218609098373 | validation: 0.061617731304022476]
	TIME [epoch: 9.59 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0589195567118279		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.0589195567118279 | validation: 0.059539101714225925]
	TIME [epoch: 9.58 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06112689045045607		[learning rate: 0.00092807]
	Learning Rate: 0.000928066
	LOSS [training: 0.06112689045045607 | validation: 0.08286711125347601]
	TIME [epoch: 9.58 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07316813354154772		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.07316813354154772 | validation: 0.052048987937046175]
	TIME [epoch: 9.6 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06393948477284835		[learning rate: 0.00092358]
	Learning Rate: 0.000923578
	LOSS [training: 0.06393948477284835 | validation: 0.07271631599919917]
	TIME [epoch: 9.58 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06457761413842286		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.06457761413842286 | validation: 0.05904939606337127]
	TIME [epoch: 9.58 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05740377944158355		[learning rate: 0.00091911]
	Learning Rate: 0.000919112
	LOSS [training: 0.05740377944158355 | validation: 0.08103857478220405]
	TIME [epoch: 9.59 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08187760566422493		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.08187760566422493 | validation: 0.09306194454127803]
	TIME [epoch: 9.59 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08896813261903973		[learning rate: 0.00091467]
	Learning Rate: 0.000914667
	LOSS [training: 0.08896813261903973 | validation: 0.1133397384149486]
	TIME [epoch: 9.58 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08516921930616789		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.08516921930616789 | validation: 0.09452729730614472]
	TIME [epoch: 9.58 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08948103911556134		[learning rate: 0.00091024]
	Learning Rate: 0.000910244
	LOSS [training: 0.08948103911556134 | validation: 0.07133301517076614]
	TIME [epoch: 9.61 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06559453602218364		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.06559453602218364 | validation: 0.06487797174122756]
	TIME [epoch: 9.59 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0625252896348401		[learning rate: 0.00090584]
	Learning Rate: 0.000905843
	LOSS [training: 0.0625252896348401 | validation: 0.06205797034946399]
	TIME [epoch: 9.59 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05880581293167029		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.05880581293167029 | validation: 0.09608911451316203]
	TIME [epoch: 9.58 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08932296967729894		[learning rate: 0.00090146]
	Learning Rate: 0.000901462
	LOSS [training: 0.08932296967729894 | validation: 0.08933735580216012]
	TIME [epoch: 9.6 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07860441518377437		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.07860441518377437 | validation: 0.07267419635013905]
	TIME [epoch: 9.58 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06934176939395875		[learning rate: 0.0008971]
	Learning Rate: 0.000897103
	LOSS [training: 0.06934176939395875 | validation: 0.06373107407521632]
	TIME [epoch: 9.58 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05205568046738103		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.05205568046738103 | validation: 0.06170807681987224]
	TIME [epoch: 9.6 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06213206700718965		[learning rate: 0.00089276]
	Learning Rate: 0.000892764
	LOSS [training: 0.06213206700718965 | validation: 0.059133789961574645]
	TIME [epoch: 9.59 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06025710849229756		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.06025710849229756 | validation: 0.04674519332912059]
	TIME [epoch: 9.59 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07629155920753027		[learning rate: 0.00088845]
	Learning Rate: 0.000888447
	LOSS [training: 0.07629155920753027 | validation: 0.06440498515442095]
	TIME [epoch: 9.59 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08188704219302868		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.08188704219302868 | validation: 0.06750832922820685]
	TIME [epoch: 9.61 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07162920253734209		[learning rate: 0.00088415]
	Learning Rate: 0.000884151
	LOSS [training: 0.07162920253734209 | validation: 0.06954677500875843]
	TIME [epoch: 9.59 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0886293604087927		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.0886293604087927 | validation: 0.11376066608840246]
	TIME [epoch: 9.6 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11069840470569106		[learning rate: 0.00087988]
	Learning Rate: 0.000879875
	LOSS [training: 0.11069840470569106 | validation: 0.0751738876631996]
	TIME [epoch: 9.59 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10539773795873568		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.10539773795873568 | validation: 0.11566595469160681]
	TIME [epoch: 9.59 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17300631072501843		[learning rate: 0.00087562]
	Learning Rate: 0.00087562
	LOSS [training: 0.17300631072501843 | validation: 0.09980156886834747]
	TIME [epoch: 9.58 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13542467105972103		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.13542467105972103 | validation: 0.1250563108258177]
	TIME [epoch: 9.59 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13895623235119525		[learning rate: 0.00087139]
	Learning Rate: 0.000871386
	LOSS [training: 0.13895623235119525 | validation: 0.11773592345003947]
	TIME [epoch: 9.6 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1621676267312094		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.1621676267312094 | validation: 0.11519363375087878]
	TIME [epoch: 9.59 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1471657717480725		[learning rate: 0.00086717]
	Learning Rate: 0.000867172
	LOSS [training: 0.1471657717480725 | validation: 0.10659990726235474]
	TIME [epoch: 9.58 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13860220978088533		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.13860220978088533 | validation: 0.13999566904027894]
	TIME [epoch: 9.59 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16464018854383303		[learning rate: 0.00086298]
	Learning Rate: 0.000862979
	LOSS [training: 0.16464018854383303 | validation: 0.13441139089630988]
	TIME [epoch: 9.6 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12655786778826886		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.12655786778826886 | validation: 0.12196226477626951]
	TIME [epoch: 9.58 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11763517643606396		[learning rate: 0.00085881]
	Learning Rate: 0.000858805
	LOSS [training: 0.11763517643606396 | validation: 0.0883009196269883]
	TIME [epoch: 9.58 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09742034587381884		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.09742034587381884 | validation: 0.1023576419609783]
	TIME [epoch: 9.6 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08340153344123777		[learning rate: 0.00085465]
	Learning Rate: 0.000854652
	LOSS [training: 0.08340153344123777 | validation: 0.08432976543468523]
	TIME [epoch: 9.59 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08129680840987633		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.08129680840987633 | validation: 0.08051130396219758]
	TIME [epoch: 9.59 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08090284467958968		[learning rate: 0.00085052]
	Learning Rate: 0.000850519
	LOSS [training: 0.08090284467958968 | validation: 0.0961077800913411]
	TIME [epoch: 9.58 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08125273810426843		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.08125273810426843 | validation: 0.09881733670906746]
	TIME [epoch: 9.61 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09146057998475805		[learning rate: 0.00084641]
	Learning Rate: 0.000846406
	LOSS [training: 0.09146057998475805 | validation: 0.08584499523435367]
	TIME [epoch: 9.58 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09756187076674626		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.09756187076674626 | validation: 0.09650118862506421]
	TIME [epoch: 9.59 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08574917962937938		[learning rate: 0.00084231]
	Learning Rate: 0.000842313
	LOSS [training: 0.08574917962937938 | validation: 0.0694890415743904]
	TIME [epoch: 9.58 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06473276388267579		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.06473276388267579 | validation: 0.051026707761931814]
	TIME [epoch: 9.61 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0699678747195724		[learning rate: 0.00083824]
	Learning Rate: 0.00083824
	LOSS [training: 0.0699678747195724 | validation: 0.05169383647530114]
	TIME [epoch: 9.59 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06583494452219896		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.06583494452219896 | validation: 0.05758852100449751]
	TIME [epoch: 9.59 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08171156668526727		[learning rate: 0.00083419]
	Learning Rate: 0.000834187
	LOSS [training: 0.08171156668526727 | validation: 0.07068160634769265]
	TIME [epoch: 9.6 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07621612591202154		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.07621612591202154 | validation: 0.07384443125160409]
	TIME [epoch: 9.58 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06244340843518535		[learning rate: 0.00083015]
	Learning Rate: 0.000830152
	LOSS [training: 0.06244340843518535 | validation: 0.05592520244819135]
	TIME [epoch: 9.59 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05472395666187181		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.05472395666187181 | validation: 0.050028886870636065]
	TIME [epoch: 9.58 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05263620136587761		[learning rate: 0.00082614]
	Learning Rate: 0.000826138
	LOSS [training: 0.05263620136587761 | validation: 0.05322487769843321]
	TIME [epoch: 9.6 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06703474838095008		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.06703474838095008 | validation: 0.050961023694665174]
	TIME [epoch: 9.59 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06298191139525153		[learning rate: 0.00082214]
	Learning Rate: 0.000822143
	LOSS [training: 0.06298191139525153 | validation: 0.05725860373897439]
	TIME [epoch: 9.58 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06652397919109078		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.06652397919109078 | validation: 0.07560754503394326]
	TIME [epoch: 9.58 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07301576595332142		[learning rate: 0.00081817]
	Learning Rate: 0.000818167
	LOSS [training: 0.07301576595332142 | validation: 0.07833399928670483]
	TIME [epoch: 9.6 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06639507666790756		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.06639507666790756 | validation: 0.046258737668523536]
	TIME [epoch: 9.59 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06219795822310068		[learning rate: 0.00081421]
	Learning Rate: 0.000814211
	LOSS [training: 0.06219795822310068 | validation: 0.04630201578291554]
	TIME [epoch: 9.58 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052907058571663376		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.052907058571663376 | validation: 0.07397197005204134]
	TIME [epoch: 9.6 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09526502961803113		[learning rate: 0.00081027]
	Learning Rate: 0.000810273
	LOSS [training: 0.09526502961803113 | validation: 0.12949802996168522]
	TIME [epoch: 9.59 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14248055463881187		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.14248055463881187 | validation: 0.1285769958915158]
	TIME [epoch: 9.58 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11887206679295459		[learning rate: 0.00080636]
	Learning Rate: 0.000806355
	LOSS [training: 0.11887206679295459 | validation: 0.06961493875724996]
	TIME [epoch: 9.58 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07076187527960083		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.07076187527960083 | validation: 0.06318289199695025]
	TIME [epoch: 9.6 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06640188038938283		[learning rate: 0.00080246]
	Learning Rate: 0.000802456
	LOSS [training: 0.06640188038938283 | validation: 0.08041918108558914]
	TIME [epoch: 9.59 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05533097107879079		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.05533097107879079 | validation: 0.05210109899848721]
	TIME [epoch: 9.59 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052992343194944225		[learning rate: 0.00079858]
	Learning Rate: 0.000798575
	LOSS [training: 0.052992343194944225 | validation: 0.052170548488737485]
	TIME [epoch: 9.6 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08281522495946805		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.08281522495946805 | validation: 0.08853594213637987]
	TIME [epoch: 9.59 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10600117910712285		[learning rate: 0.00079471]
	Learning Rate: 0.000794713
	LOSS [training: 0.10600117910712285 | validation: 0.07143968641349395]
	TIME [epoch: 9.59 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09313150598776891		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.09313150598776891 | validation: 0.06935878328660815]
	TIME [epoch: 9.58 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0697413450616022		[learning rate: 0.00079087]
	Learning Rate: 0.00079087
	LOSS [training: 0.0697413450616022 | validation: 0.09204259497508575]
	TIME [epoch: 9.6 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09752797157014843		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.09752797157014843 | validation: 0.118633585799297]
	TIME [epoch: 9.6 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11119551389895015		[learning rate: 0.00078705]
	Learning Rate: 0.000787046
	LOSS [training: 0.11119551389895015 | validation: 0.08686947001608492]
	TIME [epoch: 9.58 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10581480958558229		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.10581480958558229 | validation: 0.10514841051414772]
	TIME [epoch: 9.58 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1254662139741015		[learning rate: 0.00078324]
	Learning Rate: 0.00078324
	LOSS [training: 0.1254662139741015 | validation: 0.12221829566943075]
	TIME [epoch: 9.61 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11597265542489135		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.11597265542489135 | validation: 0.09565208029216385]
	TIME [epoch: 9.58 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13701090996354903		[learning rate: 0.00077945]
	Learning Rate: 0.000779452
	LOSS [training: 0.13701090996354903 | validation: 0.1026893110710704]
	TIME [epoch: 9.59 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11786985381773385		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.11786985381773385 | validation: 0.07345241829261705]
	TIME [epoch: 9.6 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07887048604633189		[learning rate: 0.00077568]
	Learning Rate: 0.000775683
	LOSS [training: 0.07887048604633189 | validation: 0.05111752749770722]
	TIME [epoch: 9.59 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06539943603631773		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.06539943603631773 | validation: 0.08264192320876604]
	TIME [epoch: 9.57 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0859483360206575		[learning rate: 0.00077193]
	Learning Rate: 0.000771932
	LOSS [training: 0.0859483360206575 | validation: 0.05783385419821265]
	TIME [epoch: 9.59 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06394845909229543		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.06394845909229543 | validation: 0.06125006109444666]
	TIME [epoch: 9.6 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06573379134620237		[learning rate: 0.0007682]
	Learning Rate: 0.000768199
	LOSS [training: 0.06573379134620237 | validation: 0.06323898188492466]
	TIME [epoch: 9.58 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06879894812327211		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.06879894812327211 | validation: 0.06880565312540741]
	TIME [epoch: 9.58 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06242740170747215		[learning rate: 0.00076448]
	Learning Rate: 0.000764484
	LOSS [training: 0.06242740170747215 | validation: 0.06463680125482213]
	TIME [epoch: 9.59 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07938895608207405		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.07938895608207405 | validation: 0.06068215767988331]
	TIME [epoch: 9.59 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06747654019526436		[learning rate: 0.00076079]
	Learning Rate: 0.000760787
	LOSS [training: 0.06747654019526436 | validation: 0.06730226439346516]
	TIME [epoch: 9.59 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09365377140909235		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.09365377140909235 | validation: 0.13491693512708364]
	TIME [epoch: 9.58 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13889845244452456		[learning rate: 0.00075711]
	Learning Rate: 0.000757108
	LOSS [training: 0.13889845244452456 | validation: 0.1427096481002009]
	TIME [epoch: 9.59 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14446388727899223		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.14446388727899223 | validation: 0.132249578199869]
	TIME [epoch: 9.58 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11497310960582119		[learning rate: 0.00075345]
	Learning Rate: 0.000753447
	LOSS [training: 0.11497310960582119 | validation: 0.1435909344102607]
	TIME [epoch: 9.58 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11396658293376775		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.11396658293376775 | validation: 0.1050864287913689]
	TIME [epoch: 9.58 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07446111648744068		[learning rate: 0.0007498]
	Learning Rate: 0.000749803
	LOSS [training: 0.07446111648744068 | validation: 0.05136143985596577]
	TIME [epoch: 9.6 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05260107181212461		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.05260107181212461 | validation: 0.04510986843227881]
	TIME [epoch: 9.59 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06341421408422525		[learning rate: 0.00074618]
	Learning Rate: 0.000746177
	LOSS [training: 0.06341421408422525 | validation: 0.05659844481239711]
	TIME [epoch: 9.59 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09216692415602666		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.09216692415602666 | validation: 0.07922460491078555]
	TIME [epoch: 9.59 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09942017089538484		[learning rate: 0.00074257]
	Learning Rate: 0.000742569
	LOSS [training: 0.09942017089538484 | validation: 0.07091234084120916]
	TIME [epoch: 9.6 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07760638533305683		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.07760638533305683 | validation: 0.045752367484085905]
	TIME [epoch: 9.59 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049615978151942276		[learning rate: 0.00073898]
	Learning Rate: 0.000738978
	LOSS [training: 0.049615978151942276 | validation: 0.04027828484329623]
	TIME [epoch: 9.59 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05039562239778368		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.05039562239778368 | validation: 0.055052007722031775]
	TIME [epoch: 9.6 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05604479243865575		[learning rate: 0.0007354]
	Learning Rate: 0.000735405
	LOSS [training: 0.05604479243865575 | validation: 0.07361432080025533]
	TIME [epoch: 9.59 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06190124084276756		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.06190124084276756 | validation: 0.03991044970140623]
	TIME [epoch: 9.59 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05183186014345503		[learning rate: 0.00073185]
	Learning Rate: 0.000731848
	LOSS [training: 0.05183186014345503 | validation: 0.06454819656116369]
	TIME [epoch: 9.59 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05811849976770393		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.05811849976770393 | validation: 0.07442231473364114]
	TIME [epoch: 9.6 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07784440306436499		[learning rate: 0.00072831]
	Learning Rate: 0.000728309
	LOSS [training: 0.07784440306436499 | validation: 0.07541198614112714]
	TIME [epoch: 9.58 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05846459038772187		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.05846459038772187 | validation: 0.05107275815441266]
	TIME [epoch: 9.59 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061535900198836146		[learning rate: 0.00072479]
	Learning Rate: 0.000724787
	LOSS [training: 0.061535900198836146 | validation: 0.05294030959622788]
	TIME [epoch: 9.61 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05135318382862902		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.05135318382862902 | validation: 0.046526612222921315]
	TIME [epoch: 9.59 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05830627280327634		[learning rate: 0.00072128]
	Learning Rate: 0.000721282
	LOSS [training: 0.05830627280327634 | validation: 0.06664714755635107]
	TIME [epoch: 9.58 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060972378544827746		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.060972378544827746 | validation: 0.05735357731231966]
	TIME [epoch: 9.58 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05892538127019964		[learning rate: 0.00071779]
	Learning Rate: 0.000717794
	LOSS [training: 0.05892538127019964 | validation: 0.05500290554641993]
	TIME [epoch: 9.61 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08193635422834855		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.08193635422834855 | validation: 0.07658629777746516]
	TIME [epoch: 9.59 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08198375141643902		[learning rate: 0.00071432]
	Learning Rate: 0.000714323
	LOSS [training: 0.08198375141643902 | validation: 0.04091419653370358]
	TIME [epoch: 9.58 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05461972072706123		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.05461972072706123 | validation: 0.03370424143800189]
	TIME [epoch: 9.59 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06581110315306934		[learning rate: 0.00071087]
	Learning Rate: 0.000710869
	LOSS [training: 0.06581110315306934 | validation: 0.0734303463007625]
	TIME [epoch: 9.61 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06546568715654057		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.06546568715654057 | validation: 0.0581515596660986]
	TIME [epoch: 9.59 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056990176604375775		[learning rate: 0.00070743]
	Learning Rate: 0.000707431
	LOSS [training: 0.056990176604375775 | validation: 0.07362795391064256]
	TIME [epoch: 9.6 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08245433792624307		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.08245433792624307 | validation: 0.05946845766947451]
	TIME [epoch: 9.6 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08348974819561003		[learning rate: 0.00070401]
	Learning Rate: 0.00070401
	LOSS [training: 0.08348974819561003 | validation: 0.07116316661765365]
	TIME [epoch: 9.59 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0793958081362196		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.0793958081362196 | validation: 0.05064208246600629]
	TIME [epoch: 9.59 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05099965506639731		[learning rate: 0.00070061]
	Learning Rate: 0.000700606
	LOSS [training: 0.05099965506639731 | validation: 0.043258830789399225]
	TIME [epoch: 9.59 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04847202430067158		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.04847202430067158 | validation: 0.046177265080381835]
	TIME [epoch: 9.61 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05927664968212759		[learning rate: 0.00069722]
	Learning Rate: 0.000697218
	LOSS [training: 0.05927664968212759 | validation: 0.06502402216996409]
	TIME [epoch: 9.59 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05541140059908008		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.05541140059908008 | validation: 0.06138909873132962]
	TIME [epoch: 9.58 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04436375585346443		[learning rate: 0.00069385]
	Learning Rate: 0.000693846
	LOSS [training: 0.04436375585346443 | validation: 0.04819177925542657]
	TIME [epoch: 9.6 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043357791395759085		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.043357791395759085 | validation: 0.03739333793653808]
	TIME [epoch: 9.6 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03872091797307349		[learning rate: 0.00069049]
	Learning Rate: 0.000690491
	LOSS [training: 0.03872091797307349 | validation: 0.038657999872626074]
	TIME [epoch: 9.6 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06301723102008654		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.06301723102008654 | validation: 0.04087194169917966]
	TIME [epoch: 9.59 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04937874142138075		[learning rate: 0.00068715]
	Learning Rate: 0.000687152
	LOSS [training: 0.04937874142138075 | validation: 0.03896295373424651]
	TIME [epoch: 9.61 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05124000331587962		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.05124000331587962 | validation: 0.05153325095144657]
	TIME [epoch: 9.58 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050516863683925314		[learning rate: 0.00068383]
	Learning Rate: 0.000683829
	LOSS [training: 0.050516863683925314 | validation: 0.04134557717427786]
	TIME [epoch: 9.59 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040589356945593694		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.040589356945593694 | validation: 0.03817976283032578]
	TIME [epoch: 9.59 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048122839649006835		[learning rate: 0.00068052]
	Learning Rate: 0.000680522
	LOSS [training: 0.048122839649006835 | validation: 0.04205366535067819]
	TIME [epoch: 9.61 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05378165836085154		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.05378165836085154 | validation: 0.048128766537249276]
	TIME [epoch: 9.59 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05623047784857208		[learning rate: 0.00067723]
	Learning Rate: 0.000677231
	LOSS [training: 0.05623047784857208 | validation: 0.05833788437216563]
	TIME [epoch: 9.59 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06057884915665855		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.06057884915665855 | validation: 0.04814354344681842]
	TIME [epoch: 9.6 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06091191985885754		[learning rate: 0.00067396]
	Learning Rate: 0.000673956
	LOSS [training: 0.06091191985885754 | validation: 0.05236849874767283]
	TIME [epoch: 9.59 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07154435815385358		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.07154435815385358 | validation: 0.054181645262001636]
	TIME [epoch: 9.59 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06258849906507144		[learning rate: 0.0006707]
	Learning Rate: 0.000670697
	LOSS [training: 0.06258849906507144 | validation: 0.042596266963963264]
	TIME [epoch: 9.59 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05187353637192893		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.05187353637192893 | validation: 0.06078197204927612]
	TIME [epoch: 9.61 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04334881149304491		[learning rate: 0.00066745]
	Learning Rate: 0.000667454
	LOSS [training: 0.04334881149304491 | validation: 0.03152784655115375]
	TIME [epoch: 9.59 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040444652687225184		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.040444652687225184 | validation: 0.04370782420517668]
	TIME [epoch: 9.59 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04252223322045058		[learning rate: 0.00066423]
	Learning Rate: 0.000664226
	LOSS [training: 0.04252223322045058 | validation: 0.04742270161248942]
	TIME [epoch: 9.58 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06500707791454576		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.06500707791454576 | validation: 0.06544246406539724]
	TIME [epoch: 9.61 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07436422397948236		[learning rate: 0.00066101]
	Learning Rate: 0.000661014
	LOSS [training: 0.07436422397948236 | validation: 0.06932410944802546]
	TIME [epoch: 9.58 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08227179434498635		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.08227179434498635 | validation: 0.0749913074037814]
	TIME [epoch: 9.58 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0657737327948396		[learning rate: 0.00065782]
	Learning Rate: 0.000657817
	LOSS [training: 0.0657737327948396 | validation: 0.03989721325955576]
	TIME [epoch: 9.59 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04566248655372131		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.04566248655372131 | validation: 0.05316113362313375]
	TIME [epoch: 9.59 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061992522184689224		[learning rate: 0.00065464]
	Learning Rate: 0.000654636
	LOSS [training: 0.061992522184689224 | validation: 0.07606064643166638]
	TIME [epoch: 9.58 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08260744545085782		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.08260744545085782 | validation: 0.06675144396199988]
	TIME [epoch: 9.58 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08196694713010994		[learning rate: 0.00065147]
	Learning Rate: 0.000651471
	LOSS [training: 0.08196694713010994 | validation: 0.0753239971686481]
	TIME [epoch: 9.6 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09142156447792686		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.09142156447792686 | validation: 0.062473774848227234]
	TIME [epoch: 9.59 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06675577219643587		[learning rate: 0.00064832]
	Learning Rate: 0.00064832
	LOSS [training: 0.06675577219643587 | validation: 0.05156540002606626]
	TIME [epoch: 9.59 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05158933357731239		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.05158933357731239 | validation: 0.04675145850549019]
	TIME [epoch: 9.6 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042792249200401034		[learning rate: 0.00064519]
	Learning Rate: 0.000645185
	LOSS [training: 0.042792249200401034 | validation: 0.03566980148125914]
	TIME [epoch: 9.6 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04415482065564241		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.04415482065564241 | validation: 0.05213100155381369]
	TIME [epoch: 9.58 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060245075698665475		[learning rate: 0.00064206]
	Learning Rate: 0.000642065
	LOSS [training: 0.060245075698665475 | validation: 0.05181407757893327]
	TIME [epoch: 9.59 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050313881354040454		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.050313881354040454 | validation: 0.030163553749043774]
	TIME [epoch: 9.59 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04040635300103505		[learning rate: 0.00063896]
	Learning Rate: 0.00063896
	LOSS [training: 0.04040635300103505 | validation: 0.04627309391020143]
	TIME [epoch: 9.59 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05362851037582568		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.05362851037582568 | validation: 0.04725550744961357]
	TIME [epoch: 9.59 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06488615933214857		[learning rate: 0.00063587]
	Learning Rate: 0.00063587
	LOSS [training: 0.06488615933214857 | validation: 0.061838371718847436]
	TIME [epoch: 9.59 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0617205419856498		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.0617205419856498 | validation: 0.07212976545521115]
	TIME [epoch: 9.6 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05108257530621255		[learning rate: 0.0006328]
	Learning Rate: 0.000632795
	LOSS [training: 0.05108257530621255 | validation: 0.053541353391579075]
	TIME [epoch: 9.58 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04979833598087498		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.04979833598087498 | validation: 0.04720072805337127]
	TIME [epoch: 9.58 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0421335340372223		[learning rate: 0.00062974]
	Learning Rate: 0.000629735
	LOSS [training: 0.0421335340372223 | validation: 0.03909760552011599]
	TIME [epoch: 9.6 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04892031807270383		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.04892031807270383 | validation: 0.0470321580420916]
	TIME [epoch: 9.59 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04737938411024292		[learning rate: 0.00062669]
	Learning Rate: 0.00062669
	LOSS [training: 0.04737938411024292 | validation: 0.04435750284020884]
	TIME [epoch: 9.59 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04460136963550788		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.04460136963550788 | validation: 0.05504206246379106]
	TIME [epoch: 9.58 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0567144498579699		[learning rate: 0.00062366]
	Learning Rate: 0.000623659
	LOSS [training: 0.0567144498579699 | validation: 0.0435461826420151]
	TIME [epoch: 9.61 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05241073152356925		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.05241073152356925 | validation: 0.05925172068577388]
	TIME [epoch: 9.59 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08016415254388531		[learning rate: 0.00062064]
	Learning Rate: 0.000620643
	LOSS [training: 0.08016415254388531 | validation: 0.07916789569733224]
	TIME [epoch: 9.58 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08207703374895661		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.08207703374895661 | validation: 0.07728734098067103]
	TIME [epoch: 9.59 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07999851469356777		[learning rate: 0.00061764]
	Learning Rate: 0.000617642
	LOSS [training: 0.07999851469356777 | validation: 0.06909104710430831]
	TIME [epoch: 9.59 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07070451665594027		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.07070451665594027 | validation: 0.05698994669333976]
	TIME [epoch: 9.6 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05574372951850093		[learning rate: 0.00061466]
	Learning Rate: 0.000614655
	LOSS [training: 0.05574372951850093 | validation: 0.032883669401809985]
	TIME [epoch: 9.59 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04892921563746552		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.04892921563746552 | validation: 0.07885701650336906]
	TIME [epoch: 9.6 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06502465504679887		[learning rate: 0.00061168]
	Learning Rate: 0.000611683
	LOSS [training: 0.06502465504679887 | validation: 0.04905337831246255]
	TIME [epoch: 9.58 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05193435300353485		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.05193435300353485 | validation: 0.0729889525790495]
	TIME [epoch: 9.59 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06180179344477964		[learning rate: 0.00060872]
	Learning Rate: 0.000608725
	LOSS [training: 0.06180179344477964 | validation: 0.05272343810528606]
	TIME [epoch: 9.59 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05414985841089953		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.05414985841089953 | validation: 0.044521019044011824]
	TIME [epoch: 9.6 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06024201909085789		[learning rate: 0.00060578]
	Learning Rate: 0.000605781
	LOSS [training: 0.06024201909085789 | validation: 0.05220937327664359]
	TIME [epoch: 9.59 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06491633379379617		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.06491633379379617 | validation: 0.05361747258162877]
	TIME [epoch: 9.59 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06385987001025666		[learning rate: 0.00060285]
	Learning Rate: 0.000602852
	LOSS [training: 0.06385987001025666 | validation: 0.07369043734752577]
	TIME [epoch: 9.6 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08429737463843909		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.08429737463843909 | validation: 0.0570660659612791]
	TIME [epoch: 9.6 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060836304447899246		[learning rate: 0.00059994]
	Learning Rate: 0.000599936
	LOSS [training: 0.060836304447899246 | validation: 0.04926618160862968]
	TIME [epoch: 9.59 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0691016300516935		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.0691016300516935 | validation: 0.06372261435054076]
	TIME [epoch: 9.58 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07891630997164553		[learning rate: 0.00059704]
	Learning Rate: 0.000597035
	LOSS [training: 0.07891630997164553 | validation: 0.06698809659506455]
	TIME [epoch: 9.61 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07529298075688792		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.07529298075688792 | validation: 0.06761081221387141]
	TIME [epoch: 9.58 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06300663727601746		[learning rate: 0.00059415]
	Learning Rate: 0.000594148
	LOSS [training: 0.06300663727601746 | validation: 0.044013409745403645]
	TIME [epoch: 9.59 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06742786364888634		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.06742786364888634 | validation: 0.07025633893116924]
	TIME [epoch: 9.59 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07320263323412932		[learning rate: 0.00059128]
	Learning Rate: 0.000591275
	LOSS [training: 0.07320263323412932 | validation: 0.05947800084007608]
	TIME [epoch: 9.6 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06536175312118928		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.06536175312118928 | validation: 0.06382362353749836]
	TIME [epoch: 9.59 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08804475229895711		[learning rate: 0.00058842]
	Learning Rate: 0.000588416
	LOSS [training: 0.08804475229895711 | validation: 0.09222651726490326]
	TIME [epoch: 9.58 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10378118184353		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.10378118184353 | validation: 0.1188006978387437]
	TIME [epoch: 9.6 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11293754459966969		[learning rate: 0.00058557]
	Learning Rate: 0.00058557
	LOSS [training: 0.11293754459966969 | validation: 0.06225910621841139]
	TIME [epoch: 9.6 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06441586008873196		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.06441586008873196 | validation: 0.05247486149904379]
	TIME [epoch: 9.59 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0574253045587393		[learning rate: 0.00058274]
	Learning Rate: 0.000582738
	LOSS [training: 0.0574253045587393 | validation: 0.05863793728657179]
	TIME [epoch: 9.59 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06849452391363342		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.06849452391363342 | validation: 0.07495712287888195]
	TIME [epoch: 9.61 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08085295879485499		[learning rate: 0.00057992]
	Learning Rate: 0.00057992
	LOSS [training: 0.08085295879485499 | validation: 0.08098269206697419]
	TIME [epoch: 9.59 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0883981272413458		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.0883981272413458 | validation: 0.07259852991983581]
	TIME [epoch: 9.58 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07252071738060366		[learning rate: 0.00057712]
	Learning Rate: 0.000577116
	LOSS [training: 0.07252071738060366 | validation: 0.07532319452903846]
	TIME [epoch: 9.59 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06663917696134536		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.06663917696134536 | validation: 0.06570868147261254]
	TIME [epoch: 9.6 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06738374197003458		[learning rate: 0.00057433]
	Learning Rate: 0.000574325
	LOSS [training: 0.06738374197003458 | validation: 0.059879481862953304]
	TIME [epoch: 9.59 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07145635623094307		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.07145635623094307 | validation: 0.06478650309829238]
	TIME [epoch: 9.59 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06738567432103798		[learning rate: 0.00057155]
	Learning Rate: 0.000571548
	LOSS [training: 0.06738567432103798 | validation: 0.07712255867027824]
	TIME [epoch: 9.61 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0708658010478412		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.0708658010478412 | validation: 0.052134231616491285]
	TIME [epoch: 9.59 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06171343035658581		[learning rate: 0.00056878]
	Learning Rate: 0.000568784
	LOSS [training: 0.06171343035658581 | validation: 0.048857052431440805]
	TIME [epoch: 9.59 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06139543270616086		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.06139543270616086 | validation: 0.060310643199828644]
	TIME [epoch: 9.58 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06028722292893014		[learning rate: 0.00056603]
	Learning Rate: 0.000566033
	LOSS [training: 0.06028722292893014 | validation: 0.05141640320283471]
	TIME [epoch: 9.62 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07901218292864194		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.07901218292864194 | validation: 0.10130530384022414]
	TIME [epoch: 9.59 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08192695905730402		[learning rate: 0.0005633]
	Learning Rate: 0.000563296
	LOSS [training: 0.08192695905730402 | validation: 0.07755794114233934]
	TIME [epoch: 9.59 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06696643255538312		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.06696643255538312 | validation: 0.06939114144619636]
	TIME [epoch: 9.59 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06077207011029286		[learning rate: 0.00056057]
	Learning Rate: 0.000560572
	LOSS [training: 0.06077207011029286 | validation: 0.06489147485618092]
	TIME [epoch: 9.6 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0696472288317861		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.0696472288317861 | validation: 0.06656637339589291]
	TIME [epoch: 9.58 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07134036358942034		[learning rate: 0.00055786]
	Learning Rate: 0.000557861
	LOSS [training: 0.07134036358942034 | validation: 0.06659369433544834]
	TIME [epoch: 9.6 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08057357917075883		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.08057357917075883 | validation: 0.04291706383077932]
	TIME [epoch: 9.6 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05724582823816615		[learning rate: 0.00055516]
	Learning Rate: 0.000555164
	LOSS [training: 0.05724582823816615 | validation: 0.043994595931836175]
	TIME [epoch: 9.59 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04697234331513376		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.04697234331513376 | validation: 0.04412572947047595]
	TIME [epoch: 9.58 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06252310769030196		[learning rate: 0.00055248]
	Learning Rate: 0.000552479
	LOSS [training: 0.06252310769030196 | validation: 0.06170068155227885]
	TIME [epoch: 9.58 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06608938075108799		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.06608938075108799 | validation: 0.07810051935472728]
	TIME [epoch: 9.6 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07452788846995986		[learning rate: 0.00054981]
	Learning Rate: 0.000549807
	LOSS [training: 0.07452788846995986 | validation: 0.08571055525170117]
	TIME [epoch: 9.59 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08784437431348874		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.08784437431348874 | validation: 0.0657003471848675]
	TIME [epoch: 9.57 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07728459474792078		[learning rate: 0.00054715]
	Learning Rate: 0.000547149
	LOSS [training: 0.07728459474792078 | validation: 0.0693921409162013]
	TIME [epoch: 9.6 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07801253037827355		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.07801253037827355 | validation: 0.06278939464913469]
	TIME [epoch: 9.59 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07062502651342015		[learning rate: 0.0005445]
	Learning Rate: 0.000544503
	LOSS [training: 0.07062502651342015 | validation: 0.0728359754007401]
	TIME [epoch: 9.59 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07031131726743464		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.07031131726743464 | validation: 0.07368349000114163]
	TIME [epoch: 9.58 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09716072936359917		[learning rate: 0.00054187]
	Learning Rate: 0.000541869
	LOSS [training: 0.09716072936359917 | validation: 0.0704684354882805]
	TIME [epoch: 9.6 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07707748694963602		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.07707748694963602 | validation: 0.07452008880911208]
	TIME [epoch: 9.58 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07831894866779723		[learning rate: 0.00053925]
	Learning Rate: 0.000539249
	LOSS [training: 0.07831894866779723 | validation: 0.06276521435865111]
	TIME [epoch: 9.58 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06598394472417138		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.06598394472417138 | validation: 0.06930805127810957]
	TIME [epoch: 9.58 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07431451245027625		[learning rate: 0.00053664]
	Learning Rate: 0.000536641
	LOSS [training: 0.07431451245027625 | validation: 0.06630962253271662]
	TIME [epoch: 9.61 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07421243571891546		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.07421243571891546 | validation: 0.08253270327529105]
	TIME [epoch: 9.58 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09977257713254442		[learning rate: 0.00053405]
	Learning Rate: 0.000534046
	LOSS [training: 0.09977257713254442 | validation: 0.08333361816880924]
	TIME [epoch: 9.59 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0854742596865521		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.0854742596865521 | validation: 0.0713642712348954]
	TIME [epoch: 9.61 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08088671835865073		[learning rate: 0.00053146]
	Learning Rate: 0.000531464
	LOSS [training: 0.08088671835865073 | validation: 0.06149026719727635]
	TIME [epoch: 9.59 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057928378610317674		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.057928378610317674 | validation: 0.06069154784677831]
	TIME [epoch: 9.58 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054705286505475945		[learning rate: 0.00052889]
	Learning Rate: 0.000528894
	LOSS [training: 0.054705286505475945 | validation: 0.04355398365594805]
	TIME [epoch: 9.58 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06040580983159703		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.06040580983159703 | validation: 0.044975421749481756]
	TIME [epoch: 9.6 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06281773357205611		[learning rate: 0.00052634]
	Learning Rate: 0.000526336
	LOSS [training: 0.06281773357205611 | validation: 0.04920630856548332]
	TIME [epoch: 9.59 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06608888707242978		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.06608888707242978 | validation: 0.07155422505399761]
	TIME [epoch: 9.59 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07727043807248582		[learning rate: 0.00052379]
	Learning Rate: 0.000523791
	LOSS [training: 0.07727043807248582 | validation: 0.05095538552478672]
	TIME [epoch: 9.59 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05849776230942435		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.05849776230942435 | validation: 0.06006284552604292]
	TIME [epoch: 9.59 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07183679316053208		[learning rate: 0.00052126]
	Learning Rate: 0.000521258
	LOSS [training: 0.07183679316053208 | validation: 0.088239266114486]
	TIME [epoch: 9.58 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10497827570614907		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.10497827570614907 | validation: 0.1003174659185677]
	TIME [epoch: 9.59 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07884709553660567		[learning rate: 0.00051874]
	Learning Rate: 0.000518737
	LOSS [training: 0.07884709553660567 | validation: 0.0537998988772393]
	TIME [epoch: 9.6 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06773497986315827		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.06773497986315827 | validation: 0.048021078477155504]
	TIME [epoch: 9.59 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056812614046883245		[learning rate: 0.00051623]
	Learning Rate: 0.000516229
	LOSS [training: 0.056812614046883245 | validation: 0.055326190409877095]
	TIME [epoch: 9.58 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050753607911779096		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.050753607911779096 | validation: 0.05565986212549734]
	TIME [epoch: 9.6 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05732349108613731		[learning rate: 0.00051373]
	Learning Rate: 0.000513732
	LOSS [training: 0.05732349108613731 | validation: 0.05391790333213197]
	TIME [epoch: 9.61 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06761449682390572		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.06761449682390572 | validation: 0.05979476323494428]
	TIME [epoch: 9.59 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07453086566628683		[learning rate: 0.00051125]
	Learning Rate: 0.000511248
	LOSS [training: 0.07453086566628683 | validation: 0.0831371634524796]
	TIME [epoch: 9.58 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08466966594601537		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.08466966594601537 | validation: 0.06782840902887433]
	TIME [epoch: 9.59 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09116314582395608		[learning rate: 0.00050878]
	Learning Rate: 0.000508776
	LOSS [training: 0.09116314582395608 | validation: 0.06587243363673412]
	TIME [epoch: 9.59 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06228128179197394		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.06228128179197394 | validation: 0.03806467694505126]
	TIME [epoch: 9.58 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048670698508805135		[learning rate: 0.00050632]
	Learning Rate: 0.000506315
	LOSS [training: 0.048670698508805135 | validation: 0.04089634129994531]
	TIME [epoch: 9.58 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046716544648965144		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.046716544648965144 | validation: 0.03694785493237939]
	TIME [epoch: 9.61 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043658508100999846		[learning rate: 0.00050387]
	Learning Rate: 0.000503867
	LOSS [training: 0.043658508100999846 | validation: 0.03394946065241765]
	TIME [epoch: 9.58 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0345108148742874		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.0345108148742874 | validation: 0.026744794030216505]
	TIME [epoch: 9.58 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042424100555034774		[learning rate: 0.00050143]
	Learning Rate: 0.00050143
	LOSS [training: 0.042424100555034774 | validation: 0.03781044784346612]
	TIME [epoch: 9.58 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04114508813662312		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.04114508813662312 | validation: 0.038495763353824576]
	TIME [epoch: 9.6 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04362605867953122		[learning rate: 0.00049901]
	Learning Rate: 0.000499005
	LOSS [training: 0.04362605867953122 | validation: 0.039010930441092134]
	TIME [epoch: 9.58 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039043212350624766		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.039043212350624766 | validation: 0.042482514936551856]
	TIME [epoch: 9.58 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05404856858899548		[learning rate: 0.00049659]
	Learning Rate: 0.000496592
	LOSS [training: 0.05404856858899548 | validation: 0.06097938417417275]
	TIME [epoch: 9.61 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04536360119171623		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.04536360119171623 | validation: 0.06960029033092387]
	TIME [epoch: 9.59 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.067024556263173		[learning rate: 0.00049419]
	Learning Rate: 0.000494191
	LOSS [training: 0.067024556263173 | validation: 0.08040950101157769]
	TIME [epoch: 9.59 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08626428248657181		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.08626428248657181 | validation: 0.06946663038100673]
	TIME [epoch: 9.59 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07327440178054546		[learning rate: 0.0004918]
	Learning Rate: 0.000491801
	LOSS [training: 0.07327440178054546 | validation: 0.033397948577534205]
	TIME [epoch: 9.6 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05214037410360066		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.05214037410360066 | validation: 0.044995112123935796]
	TIME [epoch: 9.58 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05634326186139079		[learning rate: 0.00048942]
	Learning Rate: 0.000489423
	LOSS [training: 0.05634326186139079 | validation: 0.04092219146233868]
	TIME [epoch: 9.58 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05629513661149721		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.05629513661149721 | validation: 0.0481890128718282]
	TIME [epoch: 9.6 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05567229682261682		[learning rate: 0.00048706]
	Learning Rate: 0.000487056
	LOSS [training: 0.05567229682261682 | validation: 0.045851950168982095]
	TIME [epoch: 9.59 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06058062316423538		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.06058062316423538 | validation: 0.047956583025038524]
	TIME [epoch: 9.57 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06221861394643373		[learning rate: 0.0004847]
	Learning Rate: 0.000484701
	LOSS [training: 0.06221861394643373 | validation: 0.04085404848859759]
	TIME [epoch: 9.58 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047230498311819816		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.047230498311819816 | validation: 0.04140440758991055]
	TIME [epoch: 9.6 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043102432876371694		[learning rate: 0.00048236]
	Learning Rate: 0.000482357
	LOSS [training: 0.043102432876371694 | validation: 0.029510155529100142]
	TIME [epoch: 9.59 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045022301800884346		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.045022301800884346 | validation: 0.051302266933375196]
	TIME [epoch: 9.58 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04151496789083078		[learning rate: 0.00048002]
	Learning Rate: 0.000480024
	LOSS [training: 0.04151496789083078 | validation: 0.049831251164404906]
	TIME [epoch: 9.59 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052029834864130306		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.052029834864130306 | validation: 0.03458347757714982]
	TIME [epoch: 9.6 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0442753304801		[learning rate: 0.0004777]
	Learning Rate: 0.000477703
	LOSS [training: 0.0442753304801 | validation: 0.031491000395511025]
	TIME [epoch: 9.6 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04536344135665714		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.04536344135665714 | validation: 0.02577190326453544]
	TIME [epoch: 9.59 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038243052582824684		[learning rate: 0.00047539]
	Learning Rate: 0.000475393
	LOSS [training: 0.038243052582824684 | validation: 0.04803056900152341]
	TIME [epoch: 9.6 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04720753879725958		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.04720753879725958 | validation: 0.03900984655499948]
	TIME [epoch: 9.59 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048926358787763885		[learning rate: 0.00047309]
	Learning Rate: 0.000473094
	LOSS [training: 0.048926358787763885 | validation: 0.05272869969322391]
	TIME [epoch: 9.58 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047610122240585376		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.047610122240585376 | validation: 0.03914349083584253]
	TIME [epoch: 9.59 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041948622280798716		[learning rate: 0.00047081]
	Learning Rate: 0.000470806
	LOSS [training: 0.041948622280798716 | validation: 0.045094204956315526]
	TIME [epoch: 9.6 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044081400621700774		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.044081400621700774 | validation: 0.029411220466895194]
	TIME [epoch: 9.59 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0490051217810535		[learning rate: 0.00046853]
	Learning Rate: 0.000468529
	LOSS [training: 0.0490051217810535 | validation: 0.031940259864895564]
	TIME [epoch: 9.59 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041815026973214806		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.041815026973214806 | validation: 0.043304019315699785]
	TIME [epoch: 9.58 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03929604693156256		[learning rate: 0.00046626]
	Learning Rate: 0.000466264
	LOSS [training: 0.03929604693156256 | validation: 0.02774208190200265]
	TIME [epoch: 9.61 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0484224022865629		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.0484224022865629 | validation: 0.03235698001543305]
	TIME [epoch: 9.59 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059254026744274366		[learning rate: 0.00046401]
	Learning Rate: 0.000464009
	LOSS [training: 0.059254026744274366 | validation: 0.036179298996129886]
	TIME [epoch: 9.58 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05333795074674721		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.05333795074674721 | validation: 0.05746718518132624]
	TIME [epoch: 9.61 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07576255880843062		[learning rate: 0.00046177]
	Learning Rate: 0.000461765
	LOSS [training: 0.07576255880843062 | validation: 0.048266299320898404]
	TIME [epoch: 9.59 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046324449854701064		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.046324449854701064 | validation: 0.02392133797636068]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_1370.pth
	Model improved!!!
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041559331198050484		[learning rate: 0.00045953]
	Learning Rate: 0.000459532
	LOSS [training: 0.041559331198050484 | validation: 0.022933094076477284]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_1371.pth
	Model improved!!!
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054051767889734245		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.054051767889734245 | validation: 0.04113677511094148]
	TIME [epoch: 9.61 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061818685011953145		[learning rate: 0.00045731]
	Learning Rate: 0.00045731
	LOSS [training: 0.061818685011953145 | validation: 0.054354206442326664]
	TIME [epoch: 9.59 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06551167833101587		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.06551167833101587 | validation: 0.03835746767490472]
	TIME [epoch: 9.59 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0667471643848897		[learning rate: 0.0004551]
	Learning Rate: 0.000455098
	LOSS [training: 0.0667471643848897 | validation: 0.05078765144076762]
	TIME [epoch: 9.6 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039924250322300264		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.039924250322300264 | validation: 0.035816330268302915]
	TIME [epoch: 9.59 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04240104241598752		[learning rate: 0.0004529]
	Learning Rate: 0.000452898
	LOSS [training: 0.04240104241598752 | validation: 0.04213330473781587]
	TIME [epoch: 9.59 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04429107989663095		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.04429107989663095 | validation: 0.03931285076680046]
	TIME [epoch: 9.59 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04763615523965488		[learning rate: 0.00045071]
	Learning Rate: 0.000450708
	LOSS [training: 0.04763615523965488 | validation: 0.04158405831488791]
	TIME [epoch: 9.61 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041770135242180303		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.041770135242180303 | validation: 0.031048514355446196]
	TIME [epoch: 9.59 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0465532702352698		[learning rate: 0.00044853]
	Learning Rate: 0.000448528
	LOSS [training: 0.0465532702352698 | validation: 0.04358593809091246]
	TIME [epoch: 9.58 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038156691833494086		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.038156691833494086 | validation: 0.023127887380288686]
	TIME [epoch: 9.6 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0479812691147703		[learning rate: 0.00044636]
	Learning Rate: 0.000446359
	LOSS [training: 0.0479812691147703 | validation: 0.04479203509155597]
	TIME [epoch: 9.59 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04615429043905238		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.04615429043905238 | validation: 0.03796214813466874]
	TIME [epoch: 9.59 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04787805894741567		[learning rate: 0.0004442]
	Learning Rate: 0.0004442
	LOSS [training: 0.04787805894741567 | validation: 0.0439849242440917]
	TIME [epoch: 9.58 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05448888854335234		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.05448888854335234 | validation: 0.037648614980140854]
	TIME [epoch: 9.6 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04310205537087645		[learning rate: 0.00044205]
	Learning Rate: 0.000442052
	LOSS [training: 0.04310205537087645 | validation: 0.028218154681342904]
	TIME [epoch: 9.59 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05254543950943531		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.05254543950943531 | validation: 0.04164894285334558]
	TIME [epoch: 9.59 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04150628201671324		[learning rate: 0.00043991]
	Learning Rate: 0.000439915
	LOSS [training: 0.04150628201671324 | validation: 0.04058513380882415]
	TIME [epoch: 9.59 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03996262467610527		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.03996262467610527 | validation: 0.05201873016707975]
	TIME [epoch: 9.61 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05204103095075607		[learning rate: 0.00043779]
	Learning Rate: 0.000437787
	LOSS [training: 0.05204103095075607 | validation: 0.04761104944110888]
	TIME [epoch: 9.6 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04656133828217512		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.04656133828217512 | validation: 0.04334879380902451]
	TIME [epoch: 9.59 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0389648674909863		[learning rate: 0.00043567]
	Learning Rate: 0.00043567
	LOSS [training: 0.0389648674909863 | validation: 0.04232424275078585]
	TIME [epoch: 9.6 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04679587528787465		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.04679587528787465 | validation: 0.05200513922230632]
	TIME [epoch: 9.6 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06852828188832076		[learning rate: 0.00043356]
	Learning Rate: 0.000433563
	LOSS [training: 0.06852828188832076 | validation: 0.05502348865662663]
	TIME [epoch: 9.59 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05281788923444215		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.05281788923444215 | validation: 0.04342979665878349]
	TIME [epoch: 9.59 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04453793767278513		[learning rate: 0.00043147]
	Learning Rate: 0.000431467
	LOSS [training: 0.04453793767278513 | validation: 0.03488506268383079]
	TIME [epoch: 9.61 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03926091628157487		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.03926091628157487 | validation: 0.034643464901856866]
	TIME [epoch: 9.59 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03647433336902621		[learning rate: 0.00042938]
	Learning Rate: 0.00042938
	LOSS [training: 0.03647433336902621 | validation: 0.04391894069815635]
	TIME [epoch: 9.59 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030906824236052722		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.030906824236052722 | validation: 0.054792604843638806]
	TIME [epoch: 9.59 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034526373344811255		[learning rate: 0.0004273]
	Learning Rate: 0.000427304
	LOSS [training: 0.034526373344811255 | validation: 0.03768115490309516]
	TIME [epoch: 9.59 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04083329433889428		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.04083329433889428 | validation: 0.047987091403530684]
	TIME [epoch: 9.58 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042521118942952164		[learning rate: 0.00042524]
	Learning Rate: 0.000425238
	LOSS [training: 0.042521118942952164 | validation: 0.031091919285907058]
	TIME [epoch: 9.59 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0580416998746584		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.0580416998746584 | validation: 0.060478406628830084]
	TIME [epoch: 9.61 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05999036065816341		[learning rate: 0.00042318]
	Learning Rate: 0.000423181
	LOSS [training: 0.05999036065816341 | validation: 0.038577255976541894]
	TIME [epoch: 9.59 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05314548553417309		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.05314548553417309 | validation: 0.05828654971879829]
	TIME [epoch: 9.59 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06504519674336433		[learning rate: 0.00042113]
	Learning Rate: 0.000421135
	LOSS [training: 0.06504519674336433 | validation: 0.0560010065464317]
	TIME [epoch: 9.59 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05997995106178422		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.05997995106178422 | validation: 0.050676628799623716]
	TIME [epoch: 9.61 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04434842660528265		[learning rate: 0.0004191]
	Learning Rate: 0.000419098
	LOSS [training: 0.04434842660528265 | validation: 0.03424735211249836]
	TIME [epoch: 9.59 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0360820193564237		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.0360820193564237 | validation: 0.038273059885158424]
	TIME [epoch: 9.59 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049987820798510364		[learning rate: 0.00041707]
	Learning Rate: 0.000417072
	LOSS [training: 0.049987820798510364 | validation: 0.03686674939500737]
	TIME [epoch: 9.61 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05086011523671681		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.05086011523671681 | validation: 0.025917511473420567]
	TIME [epoch: 9.59 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048344436992499594		[learning rate: 0.00041505]
	Learning Rate: 0.000415055
	LOSS [training: 0.048344436992499594 | validation: 0.03789985832538478]
	TIME [epoch: 9.58 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0419864491201841		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.0419864491201841 | validation: 0.03542542699690941]
	TIME [epoch: 9.58 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036469985211095346		[learning rate: 0.00041305]
	Learning Rate: 0.000413048
	LOSS [training: 0.036469985211095346 | validation: 0.035245842701382445]
	TIME [epoch: 9.61 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04061264973769248		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.04061264973769248 | validation: 0.03791189990610473]
	TIME [epoch: 9.59 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04750880955864008		[learning rate: 0.00041105]
	Learning Rate: 0.00041105
	LOSS [training: 0.04750880955864008 | validation: 0.03359969752311925]
	TIME [epoch: 9.59 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046642009349893425		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.046642009349893425 | validation: 0.05267020460466913]
	TIME [epoch: 9.59 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04502473758859669		[learning rate: 0.00040906]
	Learning Rate: 0.000409062
	LOSS [training: 0.04502473758859669 | validation: 0.038589148539739306]
	TIME [epoch: 9.6 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047547166747846474		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.047547166747846474 | validation: 0.022874659180560523]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_1420.pth
	Model improved!!!
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029216905861469196		[learning rate: 0.00040708]
	Learning Rate: 0.000407084
	LOSS [training: 0.029216905861469196 | validation: 0.026110650694876655]
	TIME [epoch: 9.59 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0310549801799364		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.0310549801799364 | validation: 0.021561839663652358]
	TIME [epoch: 9.61 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_1422.pth
	Model improved!!!
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028252981373499457		[learning rate: 0.00040512]
	Learning Rate: 0.000405116
	LOSS [training: 0.028252981373499457 | validation: 0.02932535837751826]
	TIME [epoch: 9.59 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0314768065458761		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.0314768065458761 | validation: 0.04255456139489116]
	TIME [epoch: 9.58 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02964121830418399		[learning rate: 0.00040316]
	Learning Rate: 0.000403157
	LOSS [training: 0.02964121830418399 | validation: 0.01596175416351685]
	TIME [epoch: 9.58 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_1425.pth
	Model improved!!!
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023016321339174105		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.023016321339174105 | validation: 0.010194072197427611]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_1426.pth
	Model improved!!!
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03769551676160948		[learning rate: 0.00040121]
	Learning Rate: 0.000401207
	LOSS [training: 0.03769551676160948 | validation: 0.034278946705493134]
	TIME [epoch: 9.59 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0297201089543703		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.0297201089543703 | validation: 0.026680934363205462]
	TIME [epoch: 9.58 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027367940461530828		[learning rate: 0.00039927]
	Learning Rate: 0.000399267
	LOSS [training: 0.027367940461530828 | validation: 0.02436525594457036]
	TIME [epoch: 9.6 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034008058855544		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.034008058855544 | validation: 0.021457002613318163]
	TIME [epoch: 9.58 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02585540912585989		[learning rate: 0.00039734]
	Learning Rate: 0.000397336
	LOSS [training: 0.02585540912585989 | validation: 0.020154773853614954]
	TIME [epoch: 9.59 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026004960666193844		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.026004960666193844 | validation: 0.015577790694306272]
	TIME [epoch: 9.58 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023565683428679887		[learning rate: 0.00039541]
	Learning Rate: 0.000395415
	LOSS [training: 0.023565683428679887 | validation: 0.00432249751807644]
	TIME [epoch: 9.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_1433.pth
	Model improved!!!
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022680650019428986		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.022680650019428986 | validation: 0.014710010481597414]
	TIME [epoch: 9.58 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028148059200542717		[learning rate: 0.0003935]
	Learning Rate: 0.000393502
	LOSS [training: 0.028148059200542717 | validation: 0.019886568896683585]
	TIME [epoch: 9.58 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024006106192270886		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.024006106192270886 | validation: 0.037136107216399476]
	TIME [epoch: 9.58 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030753660563015546		[learning rate: 0.0003916]
	Learning Rate: 0.000391599
	LOSS [training: 0.030753660563015546 | validation: 0.01240495033635098]
	TIME [epoch: 9.6 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038409310926942636		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.038409310926942636 | validation: 0.012323186646619293]
	TIME [epoch: 9.58 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03153713015707512		[learning rate: 0.00038971]
	Learning Rate: 0.000389706
	LOSS [training: 0.03153713015707512 | validation: 0.016478282909604746]
	TIME [epoch: 9.58 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025157164864979514		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.025157164864979514 | validation: 0.022668174918339085]
	TIME [epoch: 9.61 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0362207634842309		[learning rate: 0.00038782]
	Learning Rate: 0.000387821
	LOSS [training: 0.0362207634842309 | validation: 0.030434967593628712]
	TIME [epoch: 9.58 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0450104089177562		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.0450104089177562 | validation: 0.03115101433644446]
	TIME [epoch: 9.59 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04590824351480113		[learning rate: 0.00038595]
	Learning Rate: 0.000385946
	LOSS [training: 0.04590824351480113 | validation: 0.0346758840419919]
	TIME [epoch: 9.59 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06133183954208632		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.06133183954208632 | validation: 0.05022261489936278]
	TIME [epoch: 9.59 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055567127521365986		[learning rate: 0.00038408]
	Learning Rate: 0.000384079
	LOSS [training: 0.055567127521365986 | validation: 0.03379414053269859]
	TIME [epoch: 9.59 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058959712791071726		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.058959712791071726 | validation: 0.041171658291290644]
	TIME [epoch: 9.58 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037771851269732704		[learning rate: 0.00038222]
	Learning Rate: 0.000382222
	LOSS [training: 0.037771851269732704 | validation: 0.03856584729438747]
	TIME [epoch: 9.6 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03923783243342215		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.03923783243342215 | validation: 0.04192371695728526]
	TIME [epoch: 9.58 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03523274243889126		[learning rate: 0.00038037]
	Learning Rate: 0.000380374
	LOSS [training: 0.03523274243889126 | validation: 0.025433895244254285]
	TIME [epoch: 9.58 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037519066362564954		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.037519066362564954 | validation: 0.043611400266245756]
	TIME [epoch: 9.59 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06683018755387349		[learning rate: 0.00037853]
	Learning Rate: 0.000378534
	LOSS [training: 0.06683018755387349 | validation: 0.07577939457450615]
	TIME [epoch: 9.6 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09086352902620405		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.09086352902620405 | validation: 0.0592262210369986]
	TIME [epoch: 9.57 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08449871594105782		[learning rate: 0.0003767]
	Learning Rate: 0.000376704
	LOSS [training: 0.08449871594105782 | validation: 0.050503913645338766]
	TIME [epoch: 9.57 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07768106321726367		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.07768106321726367 | validation: 0.06898104752675645]
	TIME [epoch: 9.59 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07393955766389637		[learning rate: 0.00037488]
	Learning Rate: 0.000374882
	LOSS [training: 0.07393955766389637 | validation: 0.041534978705376986]
	TIME [epoch: 9.59 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053297014226828844		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.053297014226828844 | validation: 0.0289352615519856]
	TIME [epoch: 9.58 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05236798752973759		[learning rate: 0.00037307]
	Learning Rate: 0.000373069
	LOSS [training: 0.05236798752973759 | validation: 0.04098656553562192]
	TIME [epoch: 9.57 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03971509516332013		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.03971509516332013 | validation: 0.020679633924806488]
	TIME [epoch: 9.6 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034675984631043794		[learning rate: 0.00037127]
	Learning Rate: 0.000371265
	LOSS [training: 0.034675984631043794 | validation: 0.015629513813932953]
	TIME [epoch: 9.58 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02923395671019611		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.02923395671019611 | validation: 0.026630364490055174]
	TIME [epoch: 9.59 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03333096338628867		[learning rate: 0.00036947]
	Learning Rate: 0.00036947
	LOSS [training: 0.03333096338628867 | validation: 0.022170747557545903]
	TIME [epoch: 9.58 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033470644360473575		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.033470644360473575 | validation: 0.00548001729413759]
	TIME [epoch: 9.61 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03000455207824715		[learning rate: 0.00036768]
	Learning Rate: 0.000367683
	LOSS [training: 0.03000455207824715 | validation: 0.03760659775829762]
	TIME [epoch: 9.59 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039960407021280085		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.039960407021280085 | validation: 0.045618087293544336]
	TIME [epoch: 9.59 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04415073220474576		[learning rate: 0.00036591]
	Learning Rate: 0.000365905
	LOSS [training: 0.04415073220474576 | validation: 0.023345804730683036]
	TIME [epoch: 9.59 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043846618339499224		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.043846618339499224 | validation: 0.021481365576103223]
	TIME [epoch: 9.6 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038598424905333835		[learning rate: 0.00036414]
	Learning Rate: 0.000364136
	LOSS [training: 0.038598424905333835 | validation: 0.026815779961913346]
	TIME [epoch: 9.58 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041871401171698186		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.041871401171698186 | validation: 0.03562625586157313]
	TIME [epoch: 9.59 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044682291279136754		[learning rate: 0.00036237]
	Learning Rate: 0.000362375
	LOSS [training: 0.044682291279136754 | validation: 0.029403915960869453]
	TIME [epoch: 9.6 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0484056132667708		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.0484056132667708 | validation: 0.04110276409688383]
	TIME [epoch: 9.59 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058530383194518275		[learning rate: 0.00036062]
	Learning Rate: 0.000360622
	LOSS [training: 0.058530383194518275 | validation: 0.0477249475810038]
	TIME [epoch: 9.58 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05101382315294548		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.05101382315294548 | validation: 0.04791129661106882]
	TIME [epoch: 9.59 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05025851457644034		[learning rate: 0.00035888]
	Learning Rate: 0.000358878
	LOSS [training: 0.05025851457644034 | validation: 0.03862852166883922]
	TIME [epoch: 9.6 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044389707564088186		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.044389707564088186 | validation: 0.03083495005401091]
	TIME [epoch: 9.57 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03958093110500129		[learning rate: 0.00035714]
	Learning Rate: 0.000357143
	LOSS [training: 0.03958093110500129 | validation: 0.04492194802419481]
	TIME [epoch: 9.58 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03651004726566097		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.03651004726566097 | validation: 0.04069099569011478]
	TIME [epoch: 9.6 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0435504519538137		[learning rate: 0.00035542]
	Learning Rate: 0.000355416
	LOSS [training: 0.0435504519538137 | validation: 0.02323359196635871]
	TIME [epoch: 9.59 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04527755239626668		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.04527755239626668 | validation: 0.03276918082937307]
	TIME [epoch: 9.58 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05199454377612128		[learning rate: 0.0003537]
	Learning Rate: 0.000353697
	LOSS [training: 0.05199454377612128 | validation: 0.04205211056880045]
	TIME [epoch: 9.58 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035948822332513154		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.035948822332513154 | validation: 0.037111661228724974]
	TIME [epoch: 9.6 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06115229414174459		[learning rate: 0.00035199]
	Learning Rate: 0.000351987
	LOSS [training: 0.06115229414174459 | validation: 0.05562835943255803]
	TIME [epoch: 9.58 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07671721032323606		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.07671721032323606 | validation: 0.05968394125551688]
	TIME [epoch: 9.58 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07861036463912265		[learning rate: 0.00035028]
	Learning Rate: 0.000350285
	LOSS [training: 0.07861036463912265 | validation: 0.06659477000838354]
	TIME [epoch: 9.59 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07618394421028248		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.07618394421028248 | validation: 0.05760634663970298]
	TIME [epoch: 9.59 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08176096908987962		[learning rate: 0.00034859]
	Learning Rate: 0.000348591
	LOSS [training: 0.08176096908987962 | validation: 0.056837035325516164]
	TIME [epoch: 9.59 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0637693968465394		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.0637693968465394 | validation: 0.02950976780828793]
	TIME [epoch: 9.58 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05119863749915997		[learning rate: 0.0003469]
	Learning Rate: 0.000346905
	LOSS [training: 0.05119863749915997 | validation: 0.03371779237682016]
	TIME [epoch: 9.6 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03812823803359765		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.03812823803359765 | validation: 0.02607929900494587]
	TIME [epoch: 9.58 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04639222824116172		[learning rate: 0.00034523]
	Learning Rate: 0.000345227
	LOSS [training: 0.04639222824116172 | validation: 0.05836578997666992]
	TIME [epoch: 9.58 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06727384684139248		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.06727384684139248 | validation: 0.04797672131009346]
	TIME [epoch: 9.58 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057375031642802575		[learning rate: 0.00034356]
	Learning Rate: 0.000343558
	LOSS [training: 0.057375031642802575 | validation: 0.03703517412394404]
	TIME [epoch: 9.61 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03855812303649485		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.03855812303649485 | validation: 0.032302663493285866]
	TIME [epoch: 9.58 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044614011958363106		[learning rate: 0.0003419]
	Learning Rate: 0.000341897
	LOSS [training: 0.044614011958363106 | validation: 0.03292541461753311]
	TIME [epoch: 9.57 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04079458646639837		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.04079458646639837 | validation: 0.028218916006069152]
	TIME [epoch: 9.6 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04099353961322487		[learning rate: 0.00034024]
	Learning Rate: 0.000340243
	LOSS [training: 0.04099353961322487 | validation: 0.019405483530028543]
	TIME [epoch: 9.59 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0435311767323152		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.0435311767323152 | validation: 0.032090677954290873]
	TIME [epoch: 9.59 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04807028361992623		[learning rate: 0.0003386]
	Learning Rate: 0.000338598
	LOSS [training: 0.04807028361992623 | validation: 0.031643372991236214]
	TIME [epoch: 9.59 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0397003280838422		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.0397003280838422 | validation: 0.031129576563185657]
	TIME [epoch: 9.6 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04633046705100127		[learning rate: 0.00033696]
	Learning Rate: 0.00033696
	LOSS [training: 0.04633046705100127 | validation: 0.04532131426889742]
	TIME [epoch: 9.57 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03611962765850605		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.03611962765850605 | validation: 0.0311097241462363]
	TIME [epoch: 9.58 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03844075305879092		[learning rate: 0.00033533]
	Learning Rate: 0.000335331
	LOSS [training: 0.03844075305879092 | validation: 0.03314570328790444]
	TIME [epoch: 9.58 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03246543662100533		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.03246543662100533 | validation: 0.03787649908265235]
	TIME [epoch: 9.6 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035192212780203194		[learning rate: 0.00033371]
	Learning Rate: 0.000333709
	LOSS [training: 0.035192212780203194 | validation: 0.03644946028549723]
	TIME [epoch: 9.58 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03312658906443076		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.03312658906443076 | validation: 0.03401636204458744]
	TIME [epoch: 9.59 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037230441023665004		[learning rate: 0.0003321]
	Learning Rate: 0.000332096
	LOSS [training: 0.037230441023665004 | validation: 0.03498132051231646]
	TIME [epoch: 9.59 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02711127166985026		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.02711127166985026 | validation: 0.017512968997244065]
	TIME [epoch: 9.58 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032812433053481284		[learning rate: 0.00033049]
	Learning Rate: 0.00033049
	LOSS [training: 0.032812433053481284 | validation: 0.02618152021182045]
	TIME [epoch: 9.59 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032534883377111704		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.032534883377111704 | validation: 0.020109937996085465]
	TIME [epoch: 9.59 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029179458002586582		[learning rate: 0.00032889]
	Learning Rate: 0.000328891
	LOSS [training: 0.029179458002586582 | validation: 0.030848509399036887]
	TIME [epoch: 9.61 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033616400408832695		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.033616400408832695 | validation: 0.021873566168657713]
	TIME [epoch: 9.59 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030887956322548725		[learning rate: 0.0003273]
	Learning Rate: 0.000327301
	LOSS [training: 0.030887956322548725 | validation: 0.010520149760851454]
	TIME [epoch: 9.58 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027292714424959497		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.027292714424959497 | validation: 0.015051901126820231]
	TIME [epoch: 9.59 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03033059667291741		[learning rate: 0.00032572]
	Learning Rate: 0.000325718
	LOSS [training: 0.03033059667291741 | validation: -0.0021352464421626506]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240219_183145/states/model_tr_study6_1513.pth
	Model improved!!!
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023743359306191602		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.023743359306191602 | validation: 0.025818817959626063]
	TIME [epoch: 9.59 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021108276242423264		[learning rate: 0.00032414]
	Learning Rate: 0.000324143
	LOSS [training: 0.021108276242423264 | validation: 0.018591608450844593]
	TIME [epoch: 9.58 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029461172559343184		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.029461172559343184 | validation: 0.04545991586279019]
	TIME [epoch: 9.61 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037854093213158836		[learning rate: 0.00032258]
	Learning Rate: 0.000322576
	LOSS [training: 0.037854093213158836 | validation: 0.032894166390562]
	TIME [epoch: 9.59 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04510622524061662		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.04510622524061662 | validation: 0.05723053085894834]
	TIME [epoch: 9.58 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048112904572886396		[learning rate: 0.00032102]
	Learning Rate: 0.000321016
	LOSS [training: 0.048112904572886396 | validation: 0.05694024788818676]
	TIME [epoch: 9.59 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07520485648720501		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.07520485648720501 | validation: 0.06564573099298195]
	TIME [epoch: 9.61 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.081472082690709		[learning rate: 0.00031946]
	Learning Rate: 0.000319463
	LOSS [training: 0.081472082690709 | validation: 0.06552734385987626]
	TIME [epoch: 9.59 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09139629581516266		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.09139629581516266 | validation: 0.09700724693067002]
	TIME [epoch: 9.59 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12345789408052703		[learning rate: 0.00031792]
	Learning Rate: 0.000317918
	LOSS [training: 0.12345789408052703 | validation: 0.11532310878863168]
	TIME [epoch: 9.59 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13482010829321284		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.13482010829321284 | validation: 0.08606716653214175]
	TIME [epoch: 9.6 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10552491929824334		[learning rate: 0.00031638]
	Learning Rate: 0.000316381
	LOSS [training: 0.10552491929824334 | validation: 0.09978949123934705]
	TIME [epoch: 9.59 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08019997360923062		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.08019997360923062 | validation: 0.04709378869011289]
	TIME [epoch: 9.59 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06851100248516565		[learning rate: 0.00031485]
	Learning Rate: 0.000314851
	LOSS [training: 0.06851100248516565 | validation: 0.04308937711321618]
	TIME [epoch: 9.6 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06620985899668794		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.06620985899668794 | validation: 0.050429379981425736]
	TIME [epoch: 9.59 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05886809482948252		[learning rate: 0.00031333]
	Learning Rate: 0.000313329
	LOSS [training: 0.05886809482948252 | validation: 0.04355921913449983]
	TIME [epoch: 9.59 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0474863577902025		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.0474863577902025 | validation: 0.03051253354312877]
	TIME [epoch: 9.59 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05025521137493301		[learning rate: 0.00031181]
	Learning Rate: 0.000311813
	LOSS [training: 0.05025521137493301 | validation: 0.04730399734614131]
	TIME [epoch: 9.61 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0568791576970926		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.0568791576970926 | validation: 0.06441383045551316]
	TIME [epoch: 9.59 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06072040847202605		[learning rate: 0.00031031]
	Learning Rate: 0.000310305
	LOSS [training: 0.06072040847202605 | validation: 0.05011891744445579]
	TIME [epoch: 9.6 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048844612979329474		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.048844612979329474 | validation: 0.028096329364515338]
	TIME [epoch: 9.6 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04323084011818427		[learning rate: 0.0003088]
	Learning Rate: 0.000308805
	LOSS [training: 0.04323084011818427 | validation: 0.039487656872020625]
	TIME [epoch: 9.6 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06384019674814001		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.06384019674814001 | validation: 0.07582957415940797]
	TIME [epoch: 9.58 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07369929874738142		[learning rate: 0.00030731]
	Learning Rate: 0.000307312
	LOSS [training: 0.07369929874738142 | validation: 0.03208422054859038]
	TIME [epoch: 9.59 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04803764392165743		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.04803764392165743 | validation: 0.05194399025819294]
	TIME [epoch: 9.61 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05620997038902433		[learning rate: 0.00030583]
	Learning Rate: 0.000305826
	LOSS [training: 0.05620997038902433 | validation: 0.07058651706222961]
	TIME [epoch: 9.59 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07093230470387361		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.07093230470387361 | validation: 0.04208874876350815]
	TIME [epoch: 9.59 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053673939731841244		[learning rate: 0.00030435]
	Learning Rate: 0.000304347
	LOSS [training: 0.053673939731841244 | validation: 0.0582172211485422]
	TIME [epoch: 9.59 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06221719268624765		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.06221719268624765 | validation: 0.047053738621902035]
	TIME [epoch: 9.6 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04825012180616811		[learning rate: 0.00030287]
	Learning Rate: 0.000302875
	LOSS [training: 0.04825012180616811 | validation: 0.03208380703171182]
	TIME [epoch: 9.59 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05157963592583751		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.05157963592583751 | validation: 0.04607688341501612]
	TIME [epoch: 9.58 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04239115002495748		[learning rate: 0.00030141]
	Learning Rate: 0.00030141
	LOSS [training: 0.04239115002495748 | validation: 0.03555738789210697]
	TIME [epoch: 9.61 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052348849478064376		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.052348849478064376 | validation: 0.05045460038699263]
	TIME [epoch: 9.59 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04669593132228704		[learning rate: 0.00029995]
	Learning Rate: 0.000299953
	LOSS [training: 0.04669593132228704 | validation: 0.01783481537632444]
	TIME [epoch: 9.58 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039518290939130604		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.039518290939130604 | validation: 0.02667158337310278]
	TIME [epoch: 9.59 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0348931322469261		[learning rate: 0.0002985]
	Learning Rate: 0.000298502
	LOSS [training: 0.0348931322469261 | validation: 0.02083922888217065]
	TIME [epoch: 9.61 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03544511747286874		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.03544511747286874 | validation: 0.03667810143967008]
	TIME [epoch: 9.58 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03989724929083334		[learning rate: 0.00029706]
	Learning Rate: 0.000297059
	LOSS [training: 0.03989724929083334 | validation: 0.028992001213271668]
	TIME [epoch: 9.59 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037185266082136265		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.037185266082136265 | validation: 0.0264483809525137]
	TIME [epoch: 9.59 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04553926193390407		[learning rate: 0.00029562]
	Learning Rate: 0.000295622
	LOSS [training: 0.04553926193390407 | validation: 0.05177208092376722]
	TIME [epoch: 9.59 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06010144367772687		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.06010144367772687 | validation: 0.052346704856873524]
	TIME [epoch: 9.58 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058593020591578726		[learning rate: 0.00029419]
	Learning Rate: 0.000294193
	LOSS [training: 0.058593020591578726 | validation: 0.03607066012913001]
	TIME [epoch: 9.59 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05766102478764752		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.05766102478764752 | validation: 0.04416303796789137]
	TIME [epoch: 9.6 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058026279056892796		[learning rate: 0.00029277]
	Learning Rate: 0.00029277
	LOSS [training: 0.058026279056892796 | validation: 0.039789373078714475]
	TIME [epoch: 9.59 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05398296601289856		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.05398296601289856 | validation: 0.03858174198829175]
	TIME [epoch: 9.58 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060453564093564574		[learning rate: 0.00029135]
	Learning Rate: 0.000291354
	LOSS [training: 0.060453564093564574 | validation: 0.047487454565921336]
	TIME [epoch: 9.59 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0490060685548705		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.0490060685548705 | validation: 0.04133966360245979]
	TIME [epoch: 9.6 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051727830903415414		[learning rate: 0.00028995]
	Learning Rate: 0.000289945
	LOSS [training: 0.051727830903415414 | validation: 0.04543270682770059]
	TIME [epoch: 9.58 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04734516138980945		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.04734516138980945 | validation: 0.028478667649124257]
	TIME [epoch: 9.59 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04522151943486542		[learning rate: 0.00028854]
	Learning Rate: 0.000288543
	LOSS [training: 0.04522151943486542 | validation: 0.042619630775434694]
	TIME [epoch: 9.6 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05018754604070831		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.05018754604070831 | validation: 0.042480133082033585]
	TIME [epoch: 9.59 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035387528144865635		[learning rate: 0.00028715]
	Learning Rate: 0.000287148
	LOSS [training: 0.035387528144865635 | validation: 0.027712811758671352]
	TIME [epoch: 9.58 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04085329524691107		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.04085329524691107 | validation: 0.04190946093891462]
	TIME [epoch: 9.59 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044922938463880326		[learning rate: 0.00028576]
	Learning Rate: 0.000285759
	LOSS [training: 0.044922938463880326 | validation: 0.021118650270373438]
	TIME [epoch: 9.6 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035503096294001515		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.035503096294001515 | validation: 0.03941315469884284]
	TIME [epoch: 9.58 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03271378632181746		[learning rate: 0.00028438]
	Learning Rate: 0.000284377
	LOSS [training: 0.03271378632181746 | validation: 0.017968000817124873]
	TIME [epoch: 9.59 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03879466082973549		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.03879466082973549 | validation: 0.035228351528338184]
	TIME [epoch: 9.6 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05088990551809795		[learning rate: 0.000283]
	Learning Rate: 0.000283002
	LOSS [training: 0.05088990551809795 | validation: 0.02162885067180761]
	TIME [epoch: 9.59 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0456341262880432		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.0456341262880432 | validation: 0.04437642646133191]
	TIME [epoch: 9.58 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05133486525663757		[learning rate: 0.00028163]
	Learning Rate: 0.000281633
	LOSS [training: 0.05133486525663757 | validation: 0.03401590075862081]
	TIME [epoch: 9.58 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0456714811295036		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.0456714811295036 | validation: 0.03907489884769064]
	TIME [epoch: 9.6 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04474379390450148		[learning rate: 0.00028027]
	Learning Rate: 0.000280272
	LOSS [training: 0.04474379390450148 | validation: 0.02306182917774617]
	TIME [epoch: 9.6 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034951852911671404		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.034951852911671404 | validation: 0.042865993976394526]
	TIME [epoch: 9.58 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0373712664041261		[learning rate: 0.00027892]
	Learning Rate: 0.000278916
	LOSS [training: 0.0373712664041261 | validation: 0.020199249836744492]
	TIME [epoch: 9.59 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038800580781518185		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.038800580781518185 | validation: 0.026474865614571238]
	TIME [epoch: 9.6 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03289921532492379		[learning rate: 0.00027757]
	Learning Rate: 0.000277567
	LOSS [training: 0.03289921532492379 | validation: 0.0335090802731273]
	TIME [epoch: 9.6 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03871585805760244		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.03871585805760244 | validation: 0.028049616556973744]
	TIME [epoch: 9.59 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04898672996158593		[learning rate: 0.00027623]
	Learning Rate: 0.000276225
	LOSS [training: 0.04898672996158593 | validation: 0.033484833063754035]
	TIME [epoch: 9.61 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04195325655046071		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.04195325655046071 | validation: 0.030376754492912474]
	TIME [epoch: 9.58 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04597109119144125		[learning rate: 0.00027489]
	Learning Rate: 0.000274889
	LOSS [training: 0.04597109119144125 | validation: 0.05481272265133029]
	TIME [epoch: 9.58 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04634544551909411		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.04634544551909411 | validation: 0.023227965839343258]
	TIME [epoch: 9.58 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05110498169100872		[learning rate: 0.00027356]
	Learning Rate: 0.00027356
	LOSS [training: 0.05110498169100872 | validation: 0.050873976967102816]
	TIME [epoch: 9.61 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055569203427734526		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.055569203427734526 | validation: 0.06012935199980225]
	TIME [epoch: 9.57 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.065426474719442		[learning rate: 0.00027224]
	Learning Rate: 0.000272237
	LOSS [training: 0.065426474719442 | validation: 0.05683460267087563]
	TIME [epoch: 9.59 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07103428912563943		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.07103428912563943 | validation: 0.04780155391986572]
	TIME [epoch: 9.58 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07767438283093016		[learning rate: 0.00027092]
	Learning Rate: 0.000270921
	LOSS [training: 0.07767438283093016 | validation: 0.05774181849735133]
	TIME [epoch: 9.61 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06328407071822743		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.06328407071822743 | validation: 0.04735557249326401]
	TIME [epoch: 9.59 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06566973549018854		[learning rate: 0.00026961]
	Learning Rate: 0.000269611
	LOSS [training: 0.06566973549018854 | validation: 0.033135306047062725]
	TIME [epoch: 9.59 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06869890689483611		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.06869890689483611 | validation: 0.05538836579831294]
	TIME [epoch: 9.6 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06153670683706698		[learning rate: 0.00026831]
	Learning Rate: 0.000268307
	LOSS [training: 0.06153670683706698 | validation: 0.04968548779835229]
	TIME [epoch: 9.59 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04731658696965396		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.04731658696965396 | validation: 0.04043348937702689]
	TIME [epoch: 9.57 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05474453305282543		[learning rate: 0.00026701]
	Learning Rate: 0.000267009
	LOSS [training: 0.05474453305282543 | validation: 0.04168361585570193]
	TIME [epoch: 9.59 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056375583717701995		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.056375583717701995 | validation: 0.044544633494829004]
	TIME [epoch: 9.6 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05739864573130551		[learning rate: 0.00026572]
	Learning Rate: 0.000265718
	LOSS [training: 0.05739864573130551 | validation: 0.04194376834615324]
	TIME [epoch: 9.58 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058889763212061255		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.058889763212061255 | validation: 0.042858160566603236]
	TIME [epoch: 9.58 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060169631213509954		[learning rate: 0.00026443]
	Learning Rate: 0.000264433
	LOSS [training: 0.060169631213509954 | validation: 0.04858558694394317]
	TIME [epoch: 9.59 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06831010082293866		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.06831010082293866 | validation: 0.053752692326138794]
	TIME [epoch: 9.59 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07738341562451732		[learning rate: 0.00026315]
	Learning Rate: 0.000263154
	LOSS [training: 0.07738341562451732 | validation: 0.05378568519454361]
	TIME [epoch: 9.58 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05529732200546489		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.05529732200546489 | validation: 0.044759111828040585]
	TIME [epoch: 9.59 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06586728681051374		[learning rate: 0.00026188]
	Learning Rate: 0.000261882
	LOSS [training: 0.06586728681051374 | validation: 0.07253249841707575]
	TIME [epoch: 9.6 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08369510320385432		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.08369510320385432 | validation: 0.05234631890002214]
	TIME [epoch: 9.58 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08312942275212773		[learning rate: 0.00026062]
	Learning Rate: 0.000260615
	LOSS [training: 0.08312942275212773 | validation: 0.0789781280922747]
	TIME [epoch: 9.59 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08734929018263274		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.08734929018263274 | validation: 0.05935893707898664]
	TIME [epoch: 9.59 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07189720861537315		[learning rate: 0.00025936]
	Learning Rate: 0.000259355
	LOSS [training: 0.07189720861537315 | validation: 0.03541021214760938]
	TIME [epoch: 9.6 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05807163768492133		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.05807163768492133 | validation: 0.036076857653425984]
	TIME [epoch: 9.59 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05243142539453296		[learning rate: 0.0002581]
	Learning Rate: 0.000258101
	LOSS [training: 0.05243142539453296 | validation: 0.04322715429656937]
	TIME [epoch: 9.59 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06122142441893946		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.06122142441893946 | validation: 0.0565485507907697]
	TIME [epoch: 9.6 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06662960052410447		[learning rate: 0.00025685]
	Learning Rate: 0.000256853
	LOSS [training: 0.06662960052410447 | validation: 0.06790709744516597]
	TIME [epoch: 9.59 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0686506340273684		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.0686506340273684 | validation: 0.05173793790805204]
	TIME [epoch: 9.59 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06174048394477692		[learning rate: 0.00025561]
	Learning Rate: 0.000255611
	LOSS [training: 0.06174048394477692 | validation: 0.06299863737463918]
	TIME [epoch: 9.58 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056640263722458416		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.056640263722458416 | validation: 0.03681895422442604]
	TIME [epoch: 9.6 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04475485627792104		[learning rate: 0.00025437]
	Learning Rate: 0.000254375
	LOSS [training: 0.04475485627792104 | validation: 0.021638975399958762]
	TIME [epoch: 9.59 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034682665887321946		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.034682665887321946 | validation: 0.026560211989882267]
	TIME [epoch: 9.58 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04104435344869935		[learning rate: 0.00025314]
	Learning Rate: 0.000253144
	LOSS [training: 0.04104435344869935 | validation: 0.03440496706077909]
	TIME [epoch: 9.58 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044015261991952104		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.044015261991952104 | validation: 0.030552636448609408]
	TIME [epoch: 9.61 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035590926677347666		[learning rate: 0.00025192]
	Learning Rate: 0.00025192
	LOSS [training: 0.035590926677347666 | validation: 0.02525220828507397]
	TIME [epoch: 9.58 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03728023949882758		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.03728023949882758 | validation: 0.02794155910451831]
	TIME [epoch: 9.59 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034204625697506943		[learning rate: 0.0002507]
	Learning Rate: 0.000250702
	LOSS [training: 0.034204625697506943 | validation: 0.03190908804388758]
	TIME [epoch: 9.6 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03794980436989294		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.03794980436989294 | validation: 0.026234216613500682]
	TIME [epoch: 9.6 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03636428088749403		[learning rate: 0.00024949]
	Learning Rate: 0.00024949
	LOSS [training: 0.03636428088749403 | validation: 0.02379175733325882]
	TIME [epoch: 9.58 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026492055176708516		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.026492055176708516 | validation: 0.026867152615307203]
	TIME [epoch: 9.58 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027752269526906626		[learning rate: 0.00024828]
	Learning Rate: 0.000248283
	LOSS [training: 0.027752269526906626 | validation: 0.010236412898852352]
	TIME [epoch: 9.6 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030638354001253598		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.030638354001253598 | validation: 0.02448061921780587]
	TIME [epoch: 9.58 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023572854616743296		[learning rate: 0.00024708]
	Learning Rate: 0.000247083
	LOSS [training: 0.023572854616743296 | validation: 0.027329358194849995]
	TIME [epoch: 9.6 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0334647891337135		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.0334647891337135 | validation: 0.02339891675476056]
	TIME [epoch: 9.6 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028309427237397405		[learning rate: 0.00024589]
	Learning Rate: 0.000245888
	LOSS [training: 0.028309427237397405 | validation: 0.021179359620821618]
	TIME [epoch: 9.6 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03000209578044785		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.03000209578044785 | validation: 0.026856964767991577]
	TIME [epoch: 9.59 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028682008888760085		[learning rate: 0.0002447]
	Learning Rate: 0.000244699
	LOSS [training: 0.028682008888760085 | validation: 0.020551358594900142]
	TIME [epoch: 9.59 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027071721206352605		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.027071721206352605 | validation: 0.015604449078158588]
	TIME [epoch: 9.6 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04156160810904412		[learning rate: 0.00024352]
	Learning Rate: 0.000243515
	LOSS [training: 0.04156160810904412 | validation: 0.03268908588221325]
	TIME [epoch: 9.59 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04834822748683374		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.04834822748683374 | validation: 0.04282498121758973]
	TIME [epoch: 9.58 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07322662312805613		[learning rate: 0.00024234]
	Learning Rate: 0.000242338
	LOSS [training: 0.07322662312805613 | validation: 0.0601059142241712]
	TIME [epoch: 9.59 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0823983022168353		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.0823983022168353 | validation: 0.04323990667747284]
	TIME [epoch: 9.6 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06839153597532743		[learning rate: 0.00024117]
	Learning Rate: 0.000241166
	LOSS [training: 0.06839153597532743 | validation: 0.0477827083269449]
	TIME [epoch: 9.58 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044891877520785606		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.044891877520785606 | validation: 0.03163264292872538]
	TIME [epoch: 9.58 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04627877253845577		[learning rate: 0.00024]
	Learning Rate: 0.00024
	LOSS [training: 0.04627877253845577 | validation: 0.026489455505016912]
	TIME [epoch: 9.6 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04152800397682317		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.04152800397682317 | validation: 0.032895116639248705]
	TIME [epoch: 9.58 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03644614074248029		[learning rate: 0.00023884]
	Learning Rate: 0.000238839
	LOSS [training: 0.03644614074248029 | validation: 0.03354611950682843]
	TIME [epoch: 9.59 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04204744202975065		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.04204744202975065 | validation: 0.03736798175964626]
	TIME [epoch: 9.58 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043996898117123345		[learning rate: 0.00023768]
	Learning Rate: 0.000237684
	LOSS [training: 0.043996898117123345 | validation: 0.03518655596514109]
	TIME [epoch: 9.61 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04363116958174461		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.04363116958174461 | validation: 0.02988426812355714]
	TIME [epoch: 9.59 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042755267906076526		[learning rate: 0.00023653]
	Learning Rate: 0.000236535
	LOSS [training: 0.042755267906076526 | validation: 0.023708108134028655]
	TIME [epoch: 9.59 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033759370913959905		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.033759370913959905 | validation: 0.04264142880074764]
	TIME [epoch: 9.59 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03505525335714137		[learning rate: 0.00023539]
	Learning Rate: 0.000235391
	LOSS [training: 0.03505525335714137 | validation: 0.040973413981127756]
	TIME [epoch: 9.6 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03623690436517172		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.03623690436517172 | validation: 0.028944646012798305]
	TIME [epoch: 9.59 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038578757895633024		[learning rate: 0.00023425]
	Learning Rate: 0.000234252
	LOSS [training: 0.038578757895633024 | validation: 0.03063231922741748]
	TIME [epoch: 9.58 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025693522115192696		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.025693522115192696 | validation: 0.020885546292221155]
	TIME [epoch: 9.6 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028000131532639076		[learning rate: 0.00023312]
	Learning Rate: 0.00023312
	LOSS [training: 0.028000131532639076 | validation: 0.029973590326262834]
	TIME [epoch: 9.59 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029658531845769404		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.029658531845769404 | validation: 0.02203852804991917]
	TIME [epoch: 9.59 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028926566278132254		[learning rate: 0.00023199]
	Learning Rate: 0.000231992
	LOSS [training: 0.028926566278132254 | validation: 0.0312539726434825]
	TIME [epoch: 9.59 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023909328206895033		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.023909328206895033 | validation: 0.029727297843171338]
	TIME [epoch: 9.6 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033287553132512006		[learning rate: 0.00023087]
	Learning Rate: 0.00023087
	LOSS [training: 0.033287553132512006 | validation: 0.015648693398510907]
	TIME [epoch: 9.59 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030737847456608604		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.030737847456608604 | validation: 0.016573927299682763]
	TIME [epoch: 9.58 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03519904821077442		[learning rate: 0.00022975]
	Learning Rate: 0.000229754
	LOSS [training: 0.03519904821077442 | validation: 0.04795352167454414]
	TIME [epoch: 9.59 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04681702231019912		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.04681702231019912 | validation: 0.02406701235489495]
	TIME [epoch: 9.59 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03953480624223153		[learning rate: 0.00022864]
	Learning Rate: 0.000228643
	LOSS [training: 0.03953480624223153 | validation: 0.03353533811565461]
	TIME [epoch: 9.58 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031840960818531557		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.031840960818531557 | validation: 0.025138198761248818]
	TIME [epoch: 9.59 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0366695869297391		[learning rate: 0.00022754]
	Learning Rate: 0.000227537
	LOSS [training: 0.0366695869297391 | validation: 0.016806784681454138]
	TIME [epoch: 9.6 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025375228810541883		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.025375228810541883 | validation: 0.017086530807615873]
	TIME [epoch: 9.59 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03281975436304957		[learning rate: 0.00022644]
	Learning Rate: 0.000226437
	LOSS [training: 0.03281975436304957 | validation: 0.025432094450432912]
	TIME [epoch: 9.58 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03800799734891048		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.03800799734891048 | validation: 0.031953015045427975]
	TIME [epoch: 9.58 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04998909362756736		[learning rate: 0.00022534]
	Learning Rate: 0.000225342
	LOSS [training: 0.04998909362756736 | validation: 0.03842967842761566]
	TIME [epoch: 9.6 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046444742847678376		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.046444742847678376 | validation: 0.03208849589100805]
	TIME [epoch: 9.58 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042553138773235466		[learning rate: 0.00022425]
	Learning Rate: 0.000224252
	LOSS [training: 0.042553138773235466 | validation: 0.026823859800772287]
	TIME [epoch: 9.58 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049498385425161724		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.049498385425161724 | validation: 0.04072691524622538]
	TIME [epoch: 9.61 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04786659515409281		[learning rate: 0.00022317]
	Learning Rate: 0.000223168
	LOSS [training: 0.04786659515409281 | validation: 0.05062230922134844]
	TIME [epoch: 9.58 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03834307743174099		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.03834307743174099 | validation: 0.03775159720230905]
	TIME [epoch: 9.58 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03824016737612587		[learning rate: 0.00022209]
	Learning Rate: 0.000222089
	LOSS [training: 0.03824016737612587 | validation: 0.026736811675376712]
	TIME [epoch: 9.57 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03782873043175434		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.03782873043175434 | validation: 0.02339645082046956]
	TIME [epoch: 9.6 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034641158636162135		[learning rate: 0.00022101]
	Learning Rate: 0.000221015
	LOSS [training: 0.034641158636162135 | validation: 0.015002286050894282]
	TIME [epoch: 9.58 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04093509624330441		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.04093509624330441 | validation: 0.021327289719796454]
	TIME [epoch: 9.58 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03821615121829818		[learning rate: 0.00021995]
	Learning Rate: 0.000219946
	LOSS [training: 0.03821615121829818 | validation: 0.0344557171693003]
	TIME [epoch: 9.58 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03557965139758144		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.03557965139758144 | validation: 0.021461409966052784]
	TIME [epoch: 9.6 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0322471152918114		[learning rate: 0.00021888]
	Learning Rate: 0.000218882
	LOSS [training: 0.0322471152918114 | validation: 0.026903292715705792]
	TIME [epoch: 9.59 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036186306199495186		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.036186306199495186 | validation: 0.022763940661765455]
	TIME [epoch: 9.59 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03108592487310949		[learning rate: 0.00021782]
	Learning Rate: 0.000217824
	LOSS [training: 0.03108592487310949 | validation: 0.02565941082599052]
	TIME [epoch: 9.61 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03165946090857943		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.03165946090857943 | validation: 0.03604729873105251]
	TIME [epoch: 9.58 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0374848614233806		[learning rate: 0.00021677]
	Learning Rate: 0.00021677
	LOSS [training: 0.0374848614233806 | validation: 0.024758417243116837]
	TIME [epoch: 9.57 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030827497159599572		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.030827497159599572 | validation: 0.031656753342384096]
	TIME [epoch: 9.58 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03437917149747891		[learning rate: 0.00021572]
	Learning Rate: 0.000215722
	LOSS [training: 0.03437917149747891 | validation: 0.024793498564624615]
	TIME [epoch: 9.6 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03194883910223447		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.03194883910223447 | validation: 0.03655104649689717]
	TIME [epoch: 9.59 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03506034759588349		[learning rate: 0.00021468]
	Learning Rate: 0.000214679
	LOSS [training: 0.03506034759588349 | validation: 0.03019825028856218]
	TIME [epoch: 9.58 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024150060040939104		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.024150060040939104 | validation: 0.028296105909099756]
	TIME [epoch: 9.59 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03291853749503901		[learning rate: 0.00021364]
	Learning Rate: 0.000213641
	LOSS [training: 0.03291853749503901 | validation: 0.02169617789018978]
	TIME [epoch: 9.6 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034551278260065744		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.034551278260065744 | validation: 0.024262596737398178]
	TIME [epoch: 9.57 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038286196834453		[learning rate: 0.00021261]
	Learning Rate: 0.000212608
	LOSS [training: 0.038286196834453 | validation: 0.02720470491004956]
	TIME [epoch: 9.59 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038144103555369964		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.038144103555369964 | validation: 0.019548890463298853]
	TIME [epoch: 9.61 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03889408454570713		[learning rate: 0.00021158]
	Learning Rate: 0.00021158
	LOSS [training: 0.03889408454570713 | validation: 0.016122372150253944]
	TIME [epoch: 9.58 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029801090609389125		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.029801090609389125 | validation: 0.02467371450590913]
	TIME [epoch: 9.58 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02960988875936251		[learning rate: 0.00021056]
	Learning Rate: 0.000210556
	LOSS [training: 0.02960988875936251 | validation: 0.02789744739359215]
	TIME [epoch: 9.58 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028045279468003316		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.028045279468003316 | validation: 0.012322502579869412]
	TIME [epoch: 9.6 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03254066507675836		[learning rate: 0.00020954]
	Learning Rate: 0.000209538
	LOSS [training: 0.03254066507675836 | validation: 0.02185086570965038]
	TIME [epoch: 9.58 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04054873407790753		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.04054873407790753 | validation: 0.0304042002779527]
	TIME [epoch: 9.59 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035711289861918		[learning rate: 0.00020852]
	Learning Rate: 0.000208525
	LOSS [training: 0.035711289861918 | validation: 0.035015471207546146]
	TIME [epoch: 9.59 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04079717223887808		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.04079717223887808 | validation: 0.026666093662625588]
	TIME [epoch: 9.59 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04116598981809967		[learning rate: 0.00020752]
	Learning Rate: 0.000207516
	LOSS [training: 0.04116598981809967 | validation: 0.042489001493528175]
	TIME [epoch: 9.59 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043401363310945525		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.043401363310945525 | validation: 0.0412504966609003]
	TIME [epoch: 9.58 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041243168004049056		[learning rate: 0.00020651]
	Learning Rate: 0.000206513
	LOSS [training: 0.041243168004049056 | validation: 0.03462334759981352]
	TIME [epoch: 9.59 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029578266273786576		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.029578266273786576 | validation: 0.03080580997443]
	TIME [epoch: 9.58 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030519532421122465		[learning rate: 0.00020551]
	Learning Rate: 0.000205514
	LOSS [training: 0.030519532421122465 | validation: 0.024963015011335635]
	TIME [epoch: 9.58 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033050399404403984		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.033050399404403984 | validation: 0.019110637610309112]
	TIME [epoch: 9.57 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025139630510207872		[learning rate: 0.00020452]
	Learning Rate: 0.000204521
	LOSS [training: 0.025139630510207872 | validation: 0.026033364844367246]
	TIME [epoch: 9.6 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025293427378760315		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.025293427378760315 | validation: 0.008084563983421406]
	TIME [epoch: 9.58 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030563360663539284		[learning rate: 0.00020353]
	Learning Rate: 0.000203531
	LOSS [training: 0.030563360663539284 | validation: 0.01114724949775241]
	TIME [epoch: 9.58 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025581835324413733		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.025581835324413733 | validation: 0.01890310481414456]
	TIME [epoch: 9.6 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02882112235330796		[learning rate: 0.00020255]
	Learning Rate: 0.000202547
	LOSS [training: 0.02882112235330796 | validation: 0.021352803084675208]
	TIME [epoch: 9.59 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03168598271366364		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.03168598271366364 | validation: 0.02673236779981994]
	TIME [epoch: 9.57 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025711143734029385		[learning rate: 0.00020157]
	Learning Rate: 0.000201568
	LOSS [training: 0.025711143734029385 | validation: 0.01986057593836654]
	TIME [epoch: 9.58 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021206249973557904		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.021206249973557904 | validation: 0.01921749514428199]
	TIME [epoch: 9.59 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029565197453878513		[learning rate: 0.00020059]
	Learning Rate: 0.000200593
	LOSS [training: 0.029565197453878513 | validation: 0.02424650930106962]
	TIME [epoch: 9.58 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025558123922042004		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.025558123922042004 | validation: 0.01119854407039545]
	TIME [epoch: 9.58 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03132655141202624		[learning rate: 0.00019962]
	Learning Rate: 0.000199623
	LOSS [training: 0.03132655141202624 | validation: 0.028065802426267744]
	TIME [epoch: 9.6 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028705444567106775		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.028705444567106775 | validation: 0.02282766682267437]
	TIME [epoch: 9.59 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028832825603204458		[learning rate: 0.00019866]
	Learning Rate: 0.000198658
	LOSS [training: 0.028832825603204458 | validation: 0.018751813844654578]
	TIME [epoch: 9.58 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028744369260931258		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.028744369260931258 | validation: 0.01865569298401648]
	TIME [epoch: 9.58 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02567743899650086		[learning rate: 0.0001977]
	Learning Rate: 0.000197697
	LOSS [training: 0.02567743899650086 | validation: 0.018054581264868787]
	TIME [epoch: 9.6 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030739647724566027		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.030739647724566027 | validation: 0.021381410907860082]
	TIME [epoch: 9.58 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022563303668808907		[learning rate: 0.00019674]
	Learning Rate: 0.000196741
	LOSS [training: 0.022563303668808907 | validation: 0.02522530815601372]
	TIME [epoch: 9.59 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021089462497952214		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.021089462497952214 | validation: 0.028221461633289053]
	TIME [epoch: 9.58 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02480577713444454		[learning rate: 0.00019579]
	Learning Rate: 0.00019579
	LOSS [training: 0.02480577713444454 | validation: 0.022065961463568557]
	TIME [epoch: 9.6 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02844591624236976		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.02844591624236976 | validation: 0.025418376827016215]
	TIME [epoch: 9.59 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02326239571737542		[learning rate: 0.00019484]
	Learning Rate: 0.000194843
	LOSS [training: 0.02326239571737542 | validation: 0.01848616203884226]
	TIME [epoch: 9.58 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022412004266667666		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.022412004266667666 | validation: 0.024244373239171092]
	TIME [epoch: 9.6 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02429686690663032		[learning rate: 0.0001939]
	Learning Rate: 0.000193901
	LOSS [training: 0.02429686690663032 | validation: 0.006979570264682459]
	TIME [epoch: 9.59 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02182140157690028		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.02182140157690028 | validation: 0.02522237580727663]
	TIME [epoch: 9.58 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0234936388522104		[learning rate: 0.00019296]
	Learning Rate: 0.000192963
	LOSS [training: 0.0234936388522104 | validation: 0.011963798234829275]
	TIME [epoch: 9.58 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02456093167441047		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.02456093167441047 | validation: 0.013006242548012302]
	TIME [epoch: 9.6 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024300268421781256		[learning rate: 0.00019203]
	Learning Rate: 0.00019203
	LOSS [training: 0.024300268421781256 | validation: 0.016630824302409294]
	TIME [epoch: 9.58 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022632356477554887		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.022632356477554887 | validation: 0.00996041603677655]
	TIME [epoch: 9.58 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025312833994542504		[learning rate: 0.0001911]
	Learning Rate: 0.000191101
	LOSS [training: 0.025312833994542504 | validation: 0.0025200329554737767]
	TIME [epoch: 9.59 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024276517133038727		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.024276517133038727 | validation: 0.00941267547371639]
	TIME [epoch: 9.61 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020891304595661502		[learning rate: 0.00019018]
	Learning Rate: 0.000190177
	LOSS [training: 0.020891304595661502 | validation: 0.01792805753238587]
	TIME [epoch: 9.59 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02221141215285806		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.02221141215285806 | validation: 0.030632094862593724]
	TIME [epoch: 9.59 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027289991053451045		[learning rate: 0.00018926]
	Learning Rate: 0.000189257
	LOSS [training: 0.027289991053451045 | validation: 0.010714360628897777]
	TIME [epoch: 9.61 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020571950275480724		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.020571950275480724 | validation: 0.009664132924118512]
	TIME [epoch: 9.59 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025675880015198337		[learning rate: 0.00018834]
	Learning Rate: 0.000188342
	LOSS [training: 0.025675880015198337 | validation: 0.01686964611530222]
	TIME [epoch: 9.59 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021068527029900384		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.021068527029900384 | validation: 0.01541811114537055]
	TIME [epoch: 9.58 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018546195971552763		[learning rate: 0.00018743]
	Learning Rate: 0.000187431
	LOSS [training: 0.018546195971552763 | validation: 0.011413832054606833]
	TIME [epoch: 9.6 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025387729631236772		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.025387729631236772 | validation: 0.013833315698850246]
	TIME [epoch: 9.59 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021499918172574486		[learning rate: 0.00018652]
	Learning Rate: 0.000186525
	LOSS [training: 0.021499918172574486 | validation: 0.014386990195387177]
	TIME [epoch: 9.59 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025135968585053098		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.025135968585053098 | validation: 0.018941337308205256]
	TIME [epoch: 9.6 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023125748451917404		[learning rate: 0.00018562]
	Learning Rate: 0.000185623
	LOSS [training: 0.023125748451917404 | validation: 0.025261463556612917]
	TIME [epoch: 9.6 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0269116353534601		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.0269116353534601 | validation: 0.013027785117998824]
	TIME [epoch: 9.59 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024092970923295143		[learning rate: 0.00018473]
	Learning Rate: 0.000184725
	LOSS [training: 0.024092970923295143 | validation: 0.02422787704699843]
	TIME [epoch: 9.58 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02157689146464543		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.02157689146464543 | validation: 0.01574492520709917]
	TIME [epoch: 9.6 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025703178920266866		[learning rate: 0.00018383]
	Learning Rate: 0.000183832
	LOSS [training: 0.025703178920266866 | validation: 0.01534927309974528]
	TIME [epoch: 9.58 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025509796933063777		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.025509796933063777 | validation: 0.02092745275545086]
	TIME [epoch: 9.59 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028210723301568125		[learning rate: 0.00018294]
	Learning Rate: 0.000182943
	LOSS [training: 0.028210723301568125 | validation: 0.009925628706250527]
	TIME [epoch: 9.59 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021684098411750355		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.021684098411750355 | validation: 0.010328296255380823]
	TIME [epoch: 9.6 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026438008923952056		[learning rate: 0.00018206]
	Learning Rate: 0.000182058
	LOSS [training: 0.026438008923952056 | validation: 0.010062995530783856]
	TIME [epoch: 9.58 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02447619108346304		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.02447619108346304 | validation: 0.012811765802607837]
	TIME [epoch: 9.58 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02165717590387175		[learning rate: 0.00018118]
	Learning Rate: 0.000181178
	LOSS [training: 0.02165717590387175 | validation: 0.004191613067569947]
	TIME [epoch: 9.6 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0259698973299247		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.0259698973299247 | validation: 0.02083560895128578]
	TIME [epoch: 9.59 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030008782222219234		[learning rate: 0.0001803]
	Learning Rate: 0.000180302
	LOSS [training: 0.030008782222219234 | validation: 0.019256481381413528]
	TIME [epoch: 9.59 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025651743051644395		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.025651743051644395 | validation: 0.023821192585807074]
	TIME [epoch: 9.58 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024276959203540952		[learning rate: 0.00017943]
	Learning Rate: 0.00017943
	LOSS [training: 0.024276959203540952 | validation: 0.03398487026461952]
	TIME [epoch: 9.61 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022774909709142033		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.022774909709142033 | validation: 0.030032033785332313]
	TIME [epoch: 9.58 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02377405467389874		[learning rate: 0.00017856]
	Learning Rate: 0.000178562
	LOSS [training: 0.02377405467389874 | validation: 0.021184576746465768]
	TIME [epoch: 9.59 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022057836460708947		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.022057836460708947 | validation: 0.02063405657609357]
	TIME [epoch: 9.59 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024433823760388808		[learning rate: 0.0001777]
	Learning Rate: 0.000177699
	LOSS [training: 0.024433823760388808 | validation: 0.011813491852394852]
	TIME [epoch: 9.6 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0242470030353708		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.0242470030353708 | validation: 0.01289667170722707]
	TIME [epoch: 9.59 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02565798809478122		[learning rate: 0.00017684]
	Learning Rate: 0.000176839
	LOSS [training: 0.02565798809478122 | validation: 0.017865040928215267]
	TIME [epoch: 9.59 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018305095339988732		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.018305095339988732 | validation: 0.025469011503241924]
	TIME [epoch: 9.6 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02566818676440192		[learning rate: 0.00017598]
	Learning Rate: 0.000175984
	LOSS [training: 0.02566818676440192 | validation: 0.023822366119379264]
	TIME [epoch: 9.59 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03066054313857447		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.03066054313857447 | validation: 0.01343743331410416]
	TIME [epoch: 9.58 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028961507275914615		[learning rate: 0.00017513]
	Learning Rate: 0.000175133
	LOSS [training: 0.028961507275914615 | validation: 0.01597740764104157]
	TIME [epoch: 9.58 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02645505064594309		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.02645505064594309 | validation: 0.03003440073200382]
	TIME [epoch: 9.59 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02812518664700951		[learning rate: 0.00017429]
	Learning Rate: 0.000174286
	LOSS [training: 0.02812518664700951 | validation: 0.03149755829890822]
	TIME [epoch: 9.59 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02674282403068013		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.02674282403068013 | validation: 0.023460402143680965]
	TIME [epoch: 9.59 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023617179933772416		[learning rate: 0.00017344]
	Learning Rate: 0.000173443
	LOSS [training: 0.023617179933772416 | validation: 0.012524079729604539]
	TIME [epoch: 9.61 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018123862077260598		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.018123862077260598 | validation: 0.011620215430559907]
	TIME [epoch: 9.59 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0227674367933799		[learning rate: 0.0001726]
	Learning Rate: 0.000172605
	LOSS [training: 0.0227674367933799 | validation: 0.015672373542422575]
	TIME [epoch: 9.59 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02147747058839558		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.02147747058839558 | validation: 0.012195046295634077]
	TIME [epoch: 9.58 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025961323874476794		[learning rate: 0.00017177]
	Learning Rate: 0.00017177
	LOSS [training: 0.025961323874476794 | validation: 0.027741221917604534]
	TIME [epoch: 9.62 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029921355711724395		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.029921355711724395 | validation: 0.00959026992974273]
	TIME [epoch: 9.6 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024926880626459973		[learning rate: 0.00017094]
	Learning Rate: 0.000170939
	LOSS [training: 0.024926880626459973 | validation: 0.033022390668174244]
	TIME [epoch: 9.6 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026184493947530002		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.026184493947530002 | validation: 0.023495252371657064]
	TIME [epoch: 9.59 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02247915722266044		[learning rate: 0.00017011]
	Learning Rate: 0.000170113
	LOSS [training: 0.02247915722266044 | validation: 0.01562320455897063]
	TIME [epoch: 9.6 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025601437252271885		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.025601437252271885 | validation: 0.017676621831860476]
	TIME [epoch: 9.58 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022443373926249184		[learning rate: 0.00016929]
	Learning Rate: 0.00016929
	LOSS [training: 0.022443373926249184 | validation: 0.0001698327143886047]
	TIME [epoch: 9.6 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.013616960240986384		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.013616960240986384 | validation: 0.02401231064092183]
	TIME [epoch: 9.59 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02234887742445561		[learning rate: 0.00016847]
	Learning Rate: 0.000168471
	LOSS [training: 0.02234887742445561 | validation: 0.008634824057579068]
	TIME [epoch: 9.58 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022794506103122503		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.022794506103122503 | validation: 0.010477780543200312]
	TIME [epoch: 9.58 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.018428585128978874		[learning rate: 0.00016766]
	Learning Rate: 0.000167657
	LOSS [training: 0.018428585128978874 | validation: 0.01462980302714893]
	TIME [epoch: 9.58 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02342029680332808		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.02342029680332808 | validation: 0.02016809324082793]
	TIME [epoch: 9.6 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02462542463523957		[learning rate: 0.00016685]
	Learning Rate: 0.000166846
	LOSS [training: 0.02462542463523957 | validation: 0.01695740729645275]
	TIME [epoch: 9.6 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.017941279658594565		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.017941279658594565 | validation: 0.01697470013364823]
	TIME [epoch: 9.58 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025052968829128625		[learning rate: 0.00016604]
	Learning Rate: 0.000166039
	LOSS [training: 0.025052968829128625 | validation: 0.01756792212146926]
	TIME [epoch: 9.6 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021487897497949427		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.021487897497949427 | validation: 0.02655583554129689]
	TIME [epoch: 9.6 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020538235294023464		[learning rate: 0.00016524]
	Learning Rate: 0.000165236
	LOSS [training: 0.020538235294023464 | validation: 0.028474151818393505]
	TIME [epoch: 9.59 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02389555796902417		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.02389555796902417 | validation: 0.00039141230961407206]
	TIME [epoch: 9.59 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020842213456669905		[learning rate: 0.00016444]
	Learning Rate: 0.000164437
	LOSS [training: 0.020842213456669905 | validation: 0.016459895133083168]
	TIME [epoch: 9.6 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020440738569340255		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.020440738569340255 | validation: 0.0160829630970009]
	TIME [epoch: 9.6 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024980942744868503		[learning rate: 0.00016364]
	Learning Rate: 0.000163642
	LOSS [training: 0.024980942744868503 | validation: 0.018467804655017028]
	TIME [epoch: 9.59 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024363072581791562		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.024363072581791562 | validation: 0.026205032652155173]
	TIME [epoch: 9.58 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024415592344705618		[learning rate: 0.00016285]
	Learning Rate: 0.000162851
	LOSS [training: 0.024415592344705618 | validation: 0.016209911583757144]
	TIME [epoch: 9.61 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032434444644926466		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.032434444644926466 | validation: 0.027973186183525765]
	TIME [epoch: 9.59 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03533968120964302		[learning rate: 0.00016206]
	Learning Rate: 0.000162063
	LOSS [training: 0.03533968120964302 | validation: 0.01216025517743319]
	TIME [epoch: 9.59 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046035742368124646		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.046035742368124646 | validation: 0.027933398529153077]
	TIME [epoch: 9.61 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03788316075598267		[learning rate: 0.00016128]
	Learning Rate: 0.000161279
	LOSS [training: 0.03788316075598267 | validation: 0.017201573660032242]
	TIME [epoch: 9.61 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04137469241358185		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.04137469241358185 | validation: 0.04386560670595882]
	TIME [epoch: 9.59 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04790093476984013		[learning rate: 0.0001605]
	Learning Rate: 0.000160499
	LOSS [training: 0.04790093476984013 | validation: 0.03990447893704977]
	TIME [epoch: 9.59 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04141568005835043		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.04141568005835043 | validation: 0.02737637934825862]
	TIME [epoch: 9.61 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039813216988884		[learning rate: 0.00015972]
	Learning Rate: 0.000159723
	LOSS [training: 0.039813216988884 | validation: 0.02108197526261289]
	TIME [epoch: 9.59 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03327843001813594		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.03327843001813594 | validation: 0.032608558091390766]
	TIME [epoch: 9.6 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030060940054998726		[learning rate: 0.00015895]
	Learning Rate: 0.000158951
	LOSS [training: 0.030060940054998726 | validation: 0.04459928562127468]
	TIME [epoch: 9.59 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04150553648622016		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.04150553648622016 | validation: 0.02532965584709717]
	TIME [epoch: 9.61 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03834390483911269		[learning rate: 0.00015818]
	Learning Rate: 0.000158182
	LOSS [training: 0.03834390483911269 | validation: 0.03396291072477909]
	TIME [epoch: 9.59 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04208810522952372		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.04208810522952372 | validation: 0.033903077931974]
	TIME [epoch: 9.59 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03421017292808964		[learning rate: 0.00015742]
	Learning Rate: 0.000157417
	LOSS [training: 0.03421017292808964 | validation: 0.0145000643283044]
	TIME [epoch: 9.6 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03208730228670488		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.03208730228670488 | validation: 0.012944845532263475]
	TIME [epoch: 9.6 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027853599486122		[learning rate: 0.00015666]
	Learning Rate: 0.000156656
	LOSS [training: 0.027853599486122 | validation: 0.02055663338677554]
	TIME [epoch: 9.6 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025067535149478397		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.025067535149478397 | validation: 0.0156567869524926]
	TIME [epoch: 9.6 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029562397628739707		[learning rate: 0.0001559]
	Learning Rate: 0.000155899
	LOSS [training: 0.029562397628739707 | validation: 0.030479763708686478]
	TIME [epoch: 9.61 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02724856917254148		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.02724856917254148 | validation: 0.024549106658464256]
	TIME [epoch: 9.6 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030939788698106603		[learning rate: 0.00015514]
	Learning Rate: 0.000155145
	LOSS [training: 0.030939788698106603 | validation: 0.01651299395496004]
	TIME [epoch: 9.59 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03891897799854502		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.03891897799854502 | validation: 0.03059843264352976]
	TIME [epoch: 9.61 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030043164571017755		[learning rate: 0.00015439]
	Learning Rate: 0.000154394
	LOSS [training: 0.030043164571017755 | validation: 0.04250278024195238]
	TIME [epoch: 9.6 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039945394356959055		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.039945394356959055 | validation: 0.028892267891487432]
	TIME [epoch: 9.59 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023404909352925496		[learning rate: 0.00015365]
	Learning Rate: 0.000153648
	LOSS [training: 0.023404909352925496 | validation: 0.025617623091114004]
	TIME [epoch: 9.6 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03511025078652219		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.03511025078652219 | validation: 0.03155457308065346]
	TIME [epoch: 9.61 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036302886954304406		[learning rate: 0.0001529]
	Learning Rate: 0.000152905
	LOSS [training: 0.036302886954304406 | validation: 0.041232548030628535]
	TIME [epoch: 9.59 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0347058528454159		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.0347058528454159 | validation: 0.03321731741832311]
	TIME [epoch: 9.58 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0372825175221855		[learning rate: 0.00015217]
	Learning Rate: 0.000152165
	LOSS [training: 0.0372825175221855 | validation: 0.03004536215044298]
	TIME [epoch: 9.59 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03541728611930404		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.03541728611930404 | validation: 0.034623014707358686]
	TIME [epoch: 9.61 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028890320327492898		[learning rate: 0.00015143]
	Learning Rate: 0.00015143
	LOSS [training: 0.028890320327492898 | validation: 0.002662382481694956]
	TIME [epoch: 9.58 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03184655217729363		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.03184655217729363 | validation: 0.020196122551876697]
	TIME [epoch: 9.58 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03536832760823026		[learning rate: 0.0001507]
	Learning Rate: 0.000150697
	LOSS [training: 0.03536832760823026 | validation: 0.031602815647536114]
	TIME [epoch: 9.59 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041329189424193155		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.041329189424193155 | validation: 0.037730351844461635]
	TIME [epoch: 9.6 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038877508094305645		[learning rate: 0.00014997]
	Learning Rate: 0.000149968
	LOSS [training: 0.038877508094305645 | validation: 0.04079969767509652]
	TIME [epoch: 9.59 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036912752082048146		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.036912752082048146 | validation: 0.027856471869345204]
	TIME [epoch: 9.6 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03594326776741169		[learning rate: 0.00014924]
	Learning Rate: 0.000149243
	LOSS [training: 0.03594326776741169 | validation: 0.039899172186904266]
	TIME [epoch: 9.59 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033006346581364414		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.033006346581364414 | validation: 0.03359148956706471]
	TIME [epoch: 9.59 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03556094224832629		[learning rate: 0.00014852]
	Learning Rate: 0.000148522
	LOSS [training: 0.03556094224832629 | validation: 0.031892481344534165]
	TIME [epoch: 9.59 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027206102077020268		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.027206102077020268 | validation: 0.00833861894783475]
	TIME [epoch: 9.59 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02953112451826536		[learning rate: 0.0001478]
	Learning Rate: 0.000147803
	LOSS [training: 0.02953112451826536 | validation: 0.01426828277566551]
	TIME [epoch: 9.6 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025995198817871056		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.025995198817871056 | validation: 0.03592576263915402]
	TIME [epoch: 9.59 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024058116639955628		[learning rate: 0.00014709]
	Learning Rate: 0.000147089
	LOSS [training: 0.024058116639955628 | validation: 0.015734398584699622]
	TIME [epoch: 9.59 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030333738247176965		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.030333738247176965 | validation: 0.015282907858367818]
	TIME [epoch: 9.6 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024526772831823786		[learning rate: 0.00014638]
	Learning Rate: 0.000146377
	LOSS [training: 0.024526772831823786 | validation: 0.02782062559026585]
	TIME [epoch: 9.6 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02797089661561857		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.02797089661561857 | validation: 0.028835505738897763]
	TIME [epoch: 9.58 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022372136117060234		[learning rate: 0.00014567]
	Learning Rate: 0.000145669
	LOSS [training: 0.022372136117060234 | validation: 0.017191732493275276]
	TIME [epoch: 9.58 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02557736429240312		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.02557736429240312 | validation: 0.02447115034771738]
	TIME [epoch: 9.62 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028617948043272536		[learning rate: 0.00014497]
	Learning Rate: 0.000144965
	LOSS [training: 0.028617948043272536 | validation: 0.022425415219297227]
	TIME [epoch: 9.6 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02936143792698992		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.02936143792698992 | validation: 0.03033815505575884]
	TIME [epoch: 9.59 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024785811024637554		[learning rate: 0.00014426]
	Learning Rate: 0.000144264
	LOSS [training: 0.024785811024637554 | validation: 0.012812660970168328]
	TIME [epoch: 9.61 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02569957893789878		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.02569957893789878 | validation: 0.017244459097983836]
	TIME [epoch: 9.6 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028115122003663968		[learning rate: 0.00014357]
	Learning Rate: 0.000143566
	LOSS [training: 0.028115122003663968 | validation: 0.023460213046300766]
	TIME [epoch: 9.59 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03244277706871594		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.03244277706871594 | validation: 0.016981287845582862]
	TIME [epoch: 9.59 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025712434800965668		[learning rate: 0.00014287]
	Learning Rate: 0.000142872
	LOSS [training: 0.025712434800965668 | validation: 0.02212355429018424]
	TIME [epoch: 9.62 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028800929038019684		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.028800929038019684 | validation: 0.017841706321580324]
	TIME [epoch: 9.61 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03130067868183404		[learning rate: 0.00014218]
	Learning Rate: 0.000142181
	LOSS [training: 0.03130067868183404 | validation: 0.024102045520838573]
	TIME [epoch: 9.58 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02921930303289279		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.02921930303289279 | validation: 0.029585871536808285]
	TIME [epoch: 9.59 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027220534906998734		[learning rate: 0.00014149]
	Learning Rate: 0.000141494
	LOSS [training: 0.027220534906998734 | validation: 0.008607651875925338]
	TIME [epoch: 9.61 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03488399725543567		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.03488399725543567 | validation: 0.020302627372848013]
	TIME [epoch: 9.59 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03330667333309587		[learning rate: 0.00014081]
	Learning Rate: 0.000140809
	LOSS [training: 0.03330667333309587 | validation: 0.024413641757137484]
	TIME [epoch: 9.58 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03941650887469582		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.03941650887469582 | validation: 0.016853743021663023]
	TIME [epoch: 9.6 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035362374822774545		[learning rate: 0.00014013]
	Learning Rate: 0.000140128
	LOSS [training: 0.035362374822774545 | validation: 0.020673953275935904]
	TIME [epoch: 9.6 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037854719602086015		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.037854719602086015 | validation: 0.02795244977454003]
	TIME [epoch: 9.58 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03326768542391498		[learning rate: 0.00013945]
	Learning Rate: 0.000139451
	LOSS [training: 0.03326768542391498 | validation: 0.014930609783560839]
	TIME [epoch: 9.58 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031235191990937928		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.031235191990937928 | validation: 0.020870368363824242]
	TIME [epoch: 9.6 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028364101076699143		[learning rate: 0.00013878]
	Learning Rate: 0.000138776
	LOSS [training: 0.028364101076699143 | validation: 0.015676932358979837]
	TIME [epoch: 9.59 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029174282636037153		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.029174282636037153 | validation: 0.015590907421206751]
	TIME [epoch: 9.57 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02192474229010227		[learning rate: 0.00013811]
	Learning Rate: 0.000138105
	LOSS [training: 0.02192474229010227 | validation: 0.01297600591992619]
	TIME [epoch: 9.59 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02383127515070101		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.02383127515070101 | validation: 0.030406530936532818]
	TIME [epoch: 9.6 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02467838708553499		[learning rate: 0.00013744]
	Learning Rate: 0.000137437
	LOSS [training: 0.02467838708553499 | validation: 0.01762180894197935]
	TIME [epoch: 9.58 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026526733729721495		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.026526733729721495 | validation: 0.01930841726319786]
	TIME [epoch: 9.59 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02327205367337503		[learning rate: 0.00013677]
	Learning Rate: 0.000136773
	LOSS [training: 0.02327205367337503 | validation: 0.02520336971035419]
	TIME [epoch: 9.61 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024507696316502625		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.024507696316502625 | validation: 0.01633662060433293]
	TIME [epoch: 9.59 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025435313565337396		[learning rate: 0.00013611]
	Learning Rate: 0.000136111
	LOSS [training: 0.025435313565337396 | validation: 0.008689482638792765]
	TIME [epoch: 9.58 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030650722839342937		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.030650722839342937 | validation: 0.022751863348207283]
	TIME [epoch: 9.59 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022110480874881863		[learning rate: 0.00013545]
	Learning Rate: 0.000135453
	LOSS [training: 0.022110480874881863 | validation: 0.027351191590016623]
	TIME [epoch: 9.6 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0237954464124869		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.0237954464124869 | validation: 0.015892810117845706]
	TIME [epoch: 9.6 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02502569578306531		[learning rate: 0.0001348]
	Learning Rate: 0.000134798
	LOSS [training: 0.02502569578306531 | validation: 0.020537163437438968]
	TIME [epoch: 9.6 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023965291928161627		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.023965291928161627 | validation: 0.031677759581604945]
	TIME [epoch: 9.6 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026031537362285983		[learning rate: 0.00013415]
	Learning Rate: 0.000134146
	LOSS [training: 0.026031537362285983 | validation: 0.009331551257026146]
	TIME [epoch: 9.61 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027146509014759502		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.027146509014759502 | validation: 0.01909790659559777]
	TIME [epoch: 9.61 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026183361261255984		[learning rate: 0.0001335]
	Learning Rate: 0.000133498
	LOSS [training: 0.026183361261255984 | validation: 0.028047967805486112]
	TIME [epoch: 9.59 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03236898161629072		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.03236898161629072 | validation: 0.016490159131804107]
	TIME [epoch: 9.61 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02400395455325726		[learning rate: 0.00013285]
	Learning Rate: 0.000132852
	LOSS [training: 0.02400395455325726 | validation: 0.016187553151168602]
	TIME [epoch: 9.58 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026936206207990355		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.026936206207990355 | validation: 0.018635176921044886]
	TIME [epoch: 9.58 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027357502167990037		[learning rate: 0.00013221]
	Learning Rate: 0.00013221
	LOSS [training: 0.027357502167990037 | validation: 0.02956351659293599]
	TIME [epoch: 9.58 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02814437368434239		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.02814437368434239 | validation: 0.018608965926779623]
	TIME [epoch: 9.59 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021284437163357185		[learning rate: 0.00013157]
	Learning Rate: 0.00013157
	LOSS [training: 0.021284437163357185 | validation: 0.015830476078901094]
	TIME [epoch: 9.59 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028392874076401925		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.028392874076401925 | validation: 0.020483448008912983]
	TIME [epoch: 9.59 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030082819213329122		[learning rate: 0.00013093]
	Learning Rate: 0.000130934
	LOSS [training: 0.030082819213329122 | validation: 0.028180196055571382]
	TIME [epoch: 9.6 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027642894174939602		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.027642894174939602 | validation: 0.025740092990624464]
	TIME [epoch: 9.59 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021470133853437445		[learning rate: 0.0001303]
	Learning Rate: 0.000130301
	LOSS [training: 0.021470133853437445 | validation: 0.016508526887195615]
	TIME [epoch: 9.59 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025220031713872486		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.025220031713872486 | validation: 0.018105478370696072]
	TIME [epoch: 9.6 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02608644200177269		[learning rate: 0.00012967]
	Learning Rate: 0.000129671
	LOSS [training: 0.02608644200177269 | validation: 0.011167996494159213]
	TIME [epoch: 9.61 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02479822781555162		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.02479822781555162 | validation: 0.014389158378885393]
	TIME [epoch: 9.59 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023394808908219974		[learning rate: 0.00012904]
	Learning Rate: 0.000129044
	LOSS [training: 0.023394808908219974 | validation: 0.01846397697927288]
	TIME [epoch: 9.58 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026735187631731126		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.026735187631731126 | validation: 0.017911020610488704]
	TIME [epoch: 9.61 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025779334422440958		[learning rate: 0.00012842]
	Learning Rate: 0.00012842
	LOSS [training: 0.025779334422440958 | validation: 0.008615273892367123]
	TIME [epoch: 9.6 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026942096373292312		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.026942096373292312 | validation: 0.01860581218319432]
	TIME [epoch: 9.59 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025556401340603923		[learning rate: 0.0001278]
	Learning Rate: 0.000127799
	LOSS [training: 0.025556401340603923 | validation: 0.021836011171518174]
	TIME [epoch: 9.59 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027485085807111682		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.027485085807111682 | validation: 0.005557516947269448]
	TIME [epoch: 9.58 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02286270344245548		[learning rate: 0.00012718]
	Learning Rate: 0.000127181
	LOSS [training: 0.02286270344245548 | validation: 0.024030730874609812]
	TIME [epoch: 9.57 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021933786523020766		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.021933786523020766 | validation: 0.012263612624280044]
	TIME [epoch: 9.58 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02296196687033912		[learning rate: 0.00012657]
	Learning Rate: 0.000126566
	LOSS [training: 0.02296196687033912 | validation: 0.03043173297805052]
	TIME [epoch: 9.59 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028047621423430136		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.028047621423430136 | validation: 0.019549251256277628]
	TIME [epoch: 9.58 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02788701953098613		[learning rate: 0.00012595]
	Learning Rate: 0.000125954
	LOSS [training: 0.02788701953098613 | validation: 0.016763529390250952]
	TIME [epoch: 9.59 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02054928409990251		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.02054928409990251 | validation: 0.019080455011637458]
	TIME [epoch: 9.59 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023564209059982005		[learning rate: 0.00012534]
	Learning Rate: 0.000125345
	LOSS [training: 0.023564209059982005 | validation: 0.020854418827685774]
	TIME [epoch: 9.59 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027017897804639507		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.027017897804639507 | validation: 0.023874568903522037]
	TIME [epoch: 9.57 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03192715672196346		[learning rate: 0.00012474]
	Learning Rate: 0.000124738
	LOSS [training: 0.03192715672196346 | validation: 0.020583682599327215]
	TIME [epoch: 9.59 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02367837540599178		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.02367837540599178 | validation: 0.02902018415600138]
	TIME [epoch: 9.59 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02774317301425374		[learning rate: 0.00012414]
	Learning Rate: 0.000124135
	LOSS [training: 0.02774317301425374 | validation: 0.016731774308745444]
	TIME [epoch: 9.58 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02737198910323178		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.02737198910323178 | validation: 0.01735898827702198]
	TIME [epoch: 9.59 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025980899241289795		[learning rate: 0.00012353]
	Learning Rate: 0.000123535
	LOSS [training: 0.025980899241289795 | validation: 0.016122002437600418]
	TIME [epoch: 9.59 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02286394525783462		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.02286394525783462 | validation: 0.012277648742939754]
	TIME [epoch: 9.59 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0219547571477973		[learning rate: 0.00012294]
	Learning Rate: 0.000122937
	LOSS [training: 0.0219547571477973 | validation: 0.022225772794275237]
	TIME [epoch: 9.58 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02062878328606458		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.02062878328606458 | validation: -0.0004443000301068245]
	TIME [epoch: 9.59 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022623498576580404		[learning rate: 0.00012234]
	Learning Rate: 0.000122343
	LOSS [training: 0.022623498576580404 | validation: 0.011475448515211342]
	TIME [epoch: 9.6 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026649702769732664		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.026649702769732664 | validation: 0.02240845130752991]
	TIME [epoch: 9.59 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022192968601888907		[learning rate: 0.00012175]
	Learning Rate: 0.000121751
	LOSS [training: 0.022192968601888907 | validation: 0.015869648210086205]
	TIME [epoch: 9.58 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020868924857070564		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.020868924857070564 | validation: 0.017457993462973415]
	TIME [epoch: 9.61 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021226471579776383		[learning rate: 0.00012116]
	Learning Rate: 0.000121163
	LOSS [training: 0.021226471579776383 | validation: 0.01464645861216142]
	TIME [epoch: 9.59 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.022232186448802975		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.022232186448802975 | validation: 0.0006306688032989772]
	TIME [epoch: 9.59 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024389763910312664		[learning rate: 0.00012058]
	Learning Rate: 0.000120577
	LOSS [training: 0.024389763910312664 | validation: 0.009539838642792913]
	TIME [epoch: 9.58 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.014707447988649817		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.014707447988649817 | validation: 0.021952861910856478]
	TIME [epoch: 9.59 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02152269639696621		[learning rate: 0.00011999]
	Learning Rate: 0.000119994
	LOSS [training: 0.02152269639696621 | validation: 0.008991022857194459]
	TIME [epoch: 9.58 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026706807680712034		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.026706807680712034 | validation: 0.0035069599882749615]
	TIME [epoch: 9.57 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021415943308132887		[learning rate: 0.00011941]
	Learning Rate: 0.000119413
	LOSS [training: 0.021415943308132887 | validation: 0.009809300598203393]
	TIME [epoch: 9.59 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021677599173706256		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.021677599173706256 | validation: 0.00995112911431933]
	TIME [epoch: 9.59 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027136001578990064		[learning rate: 0.00011884]
	Learning Rate: 0.000118836
	LOSS [training: 0.027136001578990064 | validation: 0.01769249193751477]
	TIME [epoch: 9.57 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021901886389813958		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.021901886389813958 | validation: 0.0242966946420791]
	TIME [epoch: 9.58 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026466706123931268		[learning rate: 0.00011826]
	Learning Rate: 0.000118261
	LOSS [training: 0.026466706123931268 | validation: 0.018544464883984656]
	TIME [epoch: 9.6 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02548784865744482		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.02548784865744482 | validation: 0.0043015334768186945]
	TIME [epoch: 9.57 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.020004875203311664		[learning rate: 0.00011769]
	Learning Rate: 0.000117689
	LOSS [training: 0.020004875203311664 | validation: 0.025366926044023023]
	TIME [epoch: 9.57 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024384129534814024		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.024384129534814024 | validation: 0.012233577149768138]
	TIME [epoch: 9.59 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023026515837177366		[learning rate: 0.00011712]
	Learning Rate: 0.00011712
	LOSS [training: 0.023026515837177366 | validation: 0.00897609566079601]
	TIME [epoch: 9.58 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02766892778698609		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.02766892778698609 | validation: 0.022486694056556535]
	TIME [epoch: 9.61 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02195547558871133		[learning rate: 0.00011655]
	Learning Rate: 0.000116554
	LOSS [training: 0.02195547558871133 | validation: 0.01662946030271898]
	TIME [epoch: 9.6 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02225611822166782		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.02225611822166782 | validation: 0.025537443720484086]
	TIME [epoch: 9.58 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023564701771429324		[learning rate: 0.00011599]
	Learning Rate: 0.00011599
	LOSS [training: 0.023564701771429324 | validation: 0.030679058605150283]
	TIME [epoch: 9.57 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02872801860403341		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.02872801860403341 | validation: 0.03447542647171642]
	TIME [epoch: 9.58 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03425946742836906		[learning rate: 0.00011543]
	Learning Rate: 0.000115429
	LOSS [training: 0.03425946742836906 | validation: 0.02215972848268493]
	TIME [epoch: 9.61 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03034479234289217		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.03034479234289217 | validation: 0.024023893722636955]
	TIME [epoch: 9.6 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034063113228212774		[learning rate: 0.00011487]
	Learning Rate: 0.000114871
	LOSS [training: 0.034063113228212774 | validation: 0.04149266545499395]
	TIME [epoch: 9.59 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03450066843454482		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.03450066843454482 | validation: 0.03260708423299834]
	TIME [epoch: 9.6 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03469568662792764		[learning rate: 0.00011432]
	Learning Rate: 0.000114316
	LOSS [training: 0.03469568662792764 | validation: 0.025431238910867106]
	TIME [epoch: 9.6 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031274843118348994		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.031274843118348994 | validation: 0.037154667651885236]
	TIME [epoch: 9.58 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03739170677135325		[learning rate: 0.00011376]
	Learning Rate: 0.000113763
	LOSS [training: 0.03739170677135325 | validation: 0.028246277320600026]
	TIME [epoch: 9.59 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04033537252576029		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.04033537252576029 | validation: 0.02424569632731183]
	TIME [epoch: 9.61 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037584802471670564		[learning rate: 0.00011321]
	Learning Rate: 0.000113213
	LOSS [training: 0.037584802471670564 | validation: 0.049000374116436964]
	TIME [epoch: 9.59 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03744528960939055		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.03744528960939055 | validation: 0.010413258358598921]
	TIME [epoch: 9.59 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03736222646490388		[learning rate: 0.00011267]
	Learning Rate: 0.000112665
	LOSS [training: 0.03736222646490388 | validation: 0.01610263115561992]
	TIME [epoch: 9.6 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02951164020004534		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.02951164020004534 | validation: 0.02049109208613766]
	TIME [epoch: 9.6 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033842317278825806		[learning rate: 0.00011212]
	Learning Rate: 0.00011212
	LOSS [training: 0.033842317278825806 | validation: 0.013400749037379365]
	TIME [epoch: 9.58 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0296070043762584		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.0296070043762584 | validation: 0.02497121224351366]
	TIME [epoch: 9.59 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03028208847492786		[learning rate: 0.00011158]
	Learning Rate: 0.000111578
	LOSS [training: 0.03028208847492786 | validation: 0.025274827899204842]
	TIME [epoch: 9.61 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02674600619207119		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.02674600619207119 | validation: 0.014851708342045482]
	TIME [epoch: 9.59 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02720361659144881		[learning rate: 0.00011104]
	Learning Rate: 0.000111039
	LOSS [training: 0.02720361659144881 | validation: 0.016852393186971747]
	TIME [epoch: 9.59 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02602431977490789		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.02602431977490789 | validation: 0.024692715211810604]
	TIME [epoch: 9.6 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024394592867926095		[learning rate: 0.0001105]
	Learning Rate: 0.000110502
	LOSS [training: 0.024394592867926095 | validation: 0.031466603137535396]
	TIME [epoch: 9.59 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02814440187385205		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.02814440187385205 | validation: 0.025237678562881838]
	TIME [epoch: 9.59 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026803088794110936		[learning rate: 0.00010997]
	Learning Rate: 0.000109967
	LOSS [training: 0.026803088794110936 | validation: 0.013904180062480748]
	TIME [epoch: 9.59 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.01949147370290171		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.01949147370290171 | validation: 0.01988965481104972]
	TIME [epoch: 9.6 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025794043501720577		[learning rate: 0.00010944]
	Learning Rate: 0.000109435
	LOSS [training: 0.025794043501720577 | validation: 0.023359756469513153]
	TIME [epoch: 9.59 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026496194241756015		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.026496194241756015 | validation: 0.007212697241471994]
	TIME [epoch: 9.59 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026474859202177025		[learning rate: 0.00010891]
	Learning Rate: 0.000108906
	LOSS [training: 0.026474859202177025 | validation: 0.02070872740262787]
	TIME [epoch: 9.61 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029423066201597226		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.029423066201597226 | validation: 0.02340772920281796]
	TIME [epoch: 9.59 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029348948433224997		[learning rate: 0.00010838]
	Learning Rate: 0.00010838
	LOSS [training: 0.029348948433224997 | validation: 0.017994756007962565]
	TIME [epoch: 9.58 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03868554442582534		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.03868554442582534 | validation: 0.03321903343865162]
	TIME [epoch: 9.58 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02780319570089429		[learning rate: 0.00010786]
	Learning Rate: 0.000107855
	LOSS [training: 0.02780319570089429 | validation: 0.020383301402930223]
	TIME [epoch: 9.6 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028901210341813265		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.028901210341813265 | validation: 0.02620878659290932]
	TIME [epoch: 9.59 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026823794088844898		[learning rate: 0.00010733]
	Learning Rate: 0.000107334
	LOSS [training: 0.026823794088844898 | validation: 0.014048131880435851]
	TIME [epoch: 9.59 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02980405648243385		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.02980405648243385 | validation: 0.015957999063643077]
	TIME [epoch: 9.61 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026692966120264238		[learning rate: 0.00010681]
	Learning Rate: 0.000106815
	LOSS [training: 0.026692966120264238 | validation: 0.02113530961891501]
	TIME [epoch: 9.59 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03161630712431892		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.03161630712431892 | validation: 0.01909757906787395]
	TIME [epoch: 9.6 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02314898736918784		[learning rate: 0.0001063]
	Learning Rate: 0.000106298
	LOSS [training: 0.02314898736918784 | validation: 0.012590216955329062]
	TIME [epoch: 9.61 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023654975805078155		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.023654975805078155 | validation: 0.007741932997422092]
	TIME [epoch: 9.6 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03039517558043231		[learning rate: 0.00010578]
	Learning Rate: 0.000105784
	LOSS [training: 0.03039517558043231 | validation: 0.0171143319517337]
	TIME [epoch: 9.59 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023885760858707267		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.023885760858707267 | validation: 0.008348664058824201]
	TIME [epoch: 9.59 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02061261490007199		[learning rate: 0.00010527]
	Learning Rate: 0.000105273
	LOSS [training: 0.02061261490007199 | validation: 0.024024922760701083]
	TIME [epoch: 9.6 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02522174581993396		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.02522174581993396 | validation: 0.027335263774812296]
	TIME [epoch: 9.58 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02686223652933743		[learning rate: 0.00010476]
	Learning Rate: 0.000104764
	LOSS [training: 0.02686223652933743 | validation: 0.01967179508147436]
	TIME [epoch: 9.59 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024888435691496437		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.024888435691496437 | validation: 0.021323136468538055]
	TIME [epoch: 9.6 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02106672540752997		[learning rate: 0.00010426]
	Learning Rate: 0.000104257
	LOSS [training: 0.02106672540752997 | validation: 0.017299041303961524]
	TIME [epoch: 9.59 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027293856070018364		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.027293856070018364 | validation: 0.014307571215144522]
	TIME [epoch: 9.59 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023894645151691242		[learning rate: 0.00010375]
	Learning Rate: 0.000103753
	LOSS [training: 0.023894645151691242 | validation: 0.006926022649316937]
	TIME [epoch: 9.59 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0291459642204129		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.0291459642204129 | validation: 0.02692641651839073]
	TIME [epoch: 9.61 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026074789076897854		[learning rate: 0.00010325]
	Learning Rate: 0.000103251
	LOSS [training: 0.026074789076897854 | validation: 0.009339688278032386]
	TIME [epoch: 9.61 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023175720260956496		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.023175720260956496 | validation: 0.02338214524051104]
	TIME [epoch: 9.59 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03002409991589653		[learning rate: 0.00010275]
	Learning Rate: 0.000102752
	LOSS [training: 0.03002409991589653 | validation: 0.015088521840003161]
	TIME [epoch: 9.62 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030734411558717378		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.030734411558717378 | validation: 0.030613845419147374]
	TIME [epoch: 9.6 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030955610674050626		[learning rate: 0.00010225]
	Learning Rate: 0.000102255
	LOSS [training: 0.030955610674050626 | validation: 0.019063002852323447]
	TIME [epoch: 9.6 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027062960085856368		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.027062960085856368 | validation: 0.021097712149648302]
	TIME [epoch: 9.61 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027328360581178712		[learning rate: 0.00010176]
	Learning Rate: 0.00010176
	LOSS [training: 0.027328360581178712 | validation: 0.015243930354283066]
	TIME [epoch: 9.62 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030932276449649986		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.030932276449649986 | validation: 0.0124498129272042]
	TIME [epoch: 9.59 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0269287091041042		[learning rate: 0.00010127]
	Learning Rate: 0.000101268
	LOSS [training: 0.0269287091041042 | validation: 0.03781340232130657]
	TIME [epoch: 9.6 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028609357691581943		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.028609357691581943 | validation: 0.03237268552591787]
	TIME [epoch: 9.6 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033083855299909926		[learning rate: 0.00010078]
	Learning Rate: 0.000100779
	LOSS [training: 0.033083855299909926 | validation: 0.020796605911449547]
	TIME [epoch: 9.6 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02925945808822559		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.02925945808822559 | validation: 0.029673625401778047]
	TIME [epoch: 9.59 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02371933979532707		[learning rate: 0.00010029]
	Learning Rate: 0.000100291
	LOSS [training: 0.02371933979532707 | validation: 0.017824860686755543]
	TIME [epoch: 9.6 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.021478564936478466		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.021478564936478466 | validation: 0.02800861417249137]
	TIME [epoch: 9.61 sec]
Finished training in 19328.391 seconds.
