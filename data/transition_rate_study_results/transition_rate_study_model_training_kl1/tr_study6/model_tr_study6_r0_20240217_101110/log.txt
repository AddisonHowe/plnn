Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r0', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3036828465

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.999337888758967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.999337888758967 | validation: 9.403325160227077]
	TIME [epoch: 49.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.397992704758824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.397992704758824 | validation: 9.401595244950904]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.955877099482285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.955877099482285 | validation: 9.006045918133637]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.416489113818448		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.416489113818448 | validation: 8.512787751800326]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.557934470750622		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.557934470750622 | validation: 8.826510051761487]
	TIME [epoch: 10.3 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.099110803788188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.099110803788188 | validation: 8.086619641568106]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.0594331612561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.0594331612561 | validation: 8.336209970084301]
	TIME [epoch: 10.3 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.625829629555764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.625829629555764 | validation: 7.733983658255785]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.277203273126743		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.277203273126743 | validation: 7.631480512359251]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.268716801263999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.268716801263999 | validation: 7.62153123819088]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.098763199977223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.098763199977223 | validation: 7.563071014403601]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.930746249639677		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.930746249639677 | validation: 7.510596504240645]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.931447946556237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.931447946556237 | validation: 7.626472219651474]
	TIME [epoch: 10.3 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.876297536516174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.876297536516174 | validation: 7.614815539947178]
	TIME [epoch: 10.3 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.784765927765707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.784765927765707 | validation: 7.35441854758283]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.723311113216724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.723311113216724 | validation: 7.321111716822279]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.6512497038092615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6512497038092615 | validation: 7.374503805767285]
	TIME [epoch: 10.3 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.64260834075516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.64260834075516 | validation: 7.568191743785934]
	TIME [epoch: 10.3 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.686801166660869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.686801166660869 | validation: 7.29693162621933]
	TIME [epoch: 10.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.6254414958127485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6254414958127485 | validation: 7.199627070197899]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.503197828925279		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.503197828925279 | validation: 5.858150854492428]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.23972979857215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.23972979857215 | validation: 4.489841453078358]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.152807078375608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.152807078375608 | validation: 3.828528216961057]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.278658091801525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.278658091801525 | validation: 5.94668849740099]
	TIME [epoch: 10.3 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.551279612031648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.551279612031648 | validation: 3.7806621085312813]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7221561428059173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7221561428059173 | validation: 3.1394548866610172]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7629525454596924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7629525454596924 | validation: 3.47911293258751]
	TIME [epoch: 10.4 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5562330919763623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5562330919763623 | validation: 4.681235109026453]
	TIME [epoch: 10.3 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.961789130993896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.961789130993896 | validation: 3.090036129838582]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.791412836084161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.791412836084161 | validation: 2.9310819796762484]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0179783017950856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0179783017950856 | validation: 2.5859618518102447]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.103855101960309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.103855101960309 | validation: 3.2608212100711036]
	TIME [epoch: 10.3 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.092744128059403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.092744128059403 | validation: 3.554498836458364]
	TIME [epoch: 10.3 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.350688997300554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.350688997300554 | validation: 4.232240483658808]
	TIME [epoch: 10.3 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.444148943691083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.444148943691083 | validation: 7.014336875701219]
	TIME [epoch: 10.3 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.0496481875029655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0496481875029655 | validation: 3.107098337098617]
	TIME [epoch: 10.3 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.134792724213145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.134792724213145 | validation: 3.3468959024974767]
	TIME [epoch: 10.3 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.291246266495863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.291246266495863 | validation: 3.3531606661633884]
	TIME [epoch: 10.3 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.315582905335667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.315582905335667 | validation: 2.815674766456928]
	TIME [epoch: 10.3 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.177217460261067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.177217460261067 | validation: 2.9562796410059713]
	TIME [epoch: 10.3 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.898207250487789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.898207250487789 | validation: 2.5829365537628415]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.284058124396504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.284058124396504 | validation: 4.079100556152204]
	TIME [epoch: 10.3 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.337342897292174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.337342897292174 | validation: 3.5019799725539484]
	TIME [epoch: 10.3 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5047759382533137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5047759382533137 | validation: 2.6424172771134096]
	TIME [epoch: 10.3 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.500933457425343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.500933457425343 | validation: 4.096116782402444]
	TIME [epoch: 10.3 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4534301635776132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4534301635776132 | validation: 2.270210454152435]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_46.pth
	Model improved!!!
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.335580004366991		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.335580004366991 | validation: 3.082912031409179]
	TIME [epoch: 10.3 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.413233620686669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.413233620686669 | validation: 2.6143860978799154]
	TIME [epoch: 10.3 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.243111187685561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.243111187685561 | validation: 4.145649764492244]
	TIME [epoch: 10.3 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4963668399439682		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4963668399439682 | validation: 2.8474933704592638]
	TIME [epoch: 10.3 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9391542839595823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9391542839595823 | validation: 2.9058586678403824]
	TIME [epoch: 10.3 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6512061490941123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6512061490941123 | validation: 2.8226897260588406]
	TIME [epoch: 10.3 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.527400619924149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.527400619924149 | validation: 2.1471329917588324]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1837566274774787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1837566274774787 | validation: 2.1870892791266323]
	TIME [epoch: 10.3 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1233962799495054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1233962799495054 | validation: 2.5428990046598017]
	TIME [epoch: 10.3 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.442657462527104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.442657462527104 | validation: 4.249950860912501]
	TIME [epoch: 10.3 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2055564292142535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2055564292142535 | validation: 2.8623699125412503]
	TIME [epoch: 10.3 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.057945741494863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.057945741494863 | validation: 1.6484700322263792]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5724645091744982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5724645091744982 | validation: 1.3864780138975932]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_59.pth
	Model improved!!!
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6185543208181667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6185543208181667 | validation: 2.622104684590446]
	TIME [epoch: 10.3 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.894266356342077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.894266356342077 | validation: 1.6042323371685683]
	TIME [epoch: 10.3 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2717700541468653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2717700541468653 | validation: 4.0017509878494675]
	TIME [epoch: 10.3 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.223669507709938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.223669507709938 | validation: 3.176623356393012]
	TIME [epoch: 10.3 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.949131998217638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.949131998217638 | validation: 3.00916203190348]
	TIME [epoch: 10.3 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.764632723413475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.764632723413475 | validation: 3.117380709592402]
	TIME [epoch: 10.3 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8300723528111016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8300723528111016 | validation: 2.5864963686589806]
	TIME [epoch: 10.3 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.199064693998015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.199064693998015 | validation: 2.1343611558609634]
	TIME [epoch: 10.3 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6453576713360825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6453576713360825 | validation: 1.3943360861223608]
	TIME [epoch: 10.3 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.632973579952709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.632973579952709 | validation: 1.2109100180310197]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2075043323898087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2075043323898087 | validation: 0.9930816922799807]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7731833995846067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7731833995846067 | validation: 1.2952171876105554]
	TIME [epoch: 10.3 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.258297476026164		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.258297476026164 | validation: 1.1908784882517245]
	TIME [epoch: 10.3 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1763840251579958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1763840251579958 | validation: 1.3461248936623227]
	TIME [epoch: 10.3 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.117064720401718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.117064720401718 | validation: 0.9092034070921514]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0908262106773872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0908262106773872 | validation: 1.1092531285284275]
	TIME [epoch: 10.3 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1210818040074637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1210818040074637 | validation: 0.9240525515214979]
	TIME [epoch: 10.3 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8508530947574926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8508530947574926 | validation: 1.5176931439300763]
	TIME [epoch: 10.3 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9991285466568695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9991285466568695 | validation: 0.8970933668095213]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_78.pth
	Model improved!!!
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9903648030845495		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9903648030845495 | validation: 0.7085941286721834]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8143029156863264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8143029156863264 | validation: 1.7470472192602495]
	TIME [epoch: 10.3 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1093301886854063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1093301886854063 | validation: 1.0113598606322314]
	TIME [epoch: 10.3 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0927096004203976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0927096004203976 | validation: 0.697307503455005]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8947980366686638		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8947980366686638 | validation: 0.8508238362126269]
	TIME [epoch: 10.3 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.815558226078734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.815558226078734 | validation: 0.6902623364987713]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_84.pth
	Model improved!!!
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7963485369695208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7963485369695208 | validation: 0.7913710825955375]
	TIME [epoch: 10.3 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7489183060918826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7489183060918826 | validation: 0.6969326142906315]
	TIME [epoch: 10.3 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.657646558115531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.657646558115531 | validation: 2.7477619632520898]
	TIME [epoch: 10.3 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4443456959933951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4443456959933951 | validation: 1.223252526281385]
	TIME [epoch: 10.3 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.938669059856845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.938669059856845 | validation: 0.6821506161988877]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8255025360938696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8255025360938696 | validation: 0.6940292471091922]
	TIME [epoch: 10.3 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6926303927819186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6926303927819186 | validation: 1.256041472883515]
	TIME [epoch: 10.3 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8802893968260926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8802893968260926 | validation: 1.088632623523352]
	TIME [epoch: 10.3 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8336191656757954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8336191656757954 | validation: 0.8568585462776434]
	TIME [epoch: 10.3 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.448781241430477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.448781241430477 | validation: 5.190240974556097]
	TIME [epoch: 10.3 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.44491239240705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.44491239240705 | validation: 4.081573196863265]
	TIME [epoch: 10.3 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8155881546473887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8155881546473887 | validation: 4.031638370060132]
	TIME [epoch: 10.3 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7340623208603625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7340623208603625 | validation: 4.038268824643033]
	TIME [epoch: 10.3 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4733834764276894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4733834764276894 | validation: 2.8044614474100933]
	TIME [epoch: 10.3 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5547757332858914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5547757332858914 | validation: 1.0542101959339758]
	TIME [epoch: 10.3 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.208688591572964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.208688591572964 | validation: 1.432767841838676]
	TIME [epoch: 10.3 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9331401882042656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9331401882042656 | validation: 0.8333821353543147]
	TIME [epoch: 10.3 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4605038688102152		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4605038688102152 | validation: 1.0614669889943484]
	TIME [epoch: 10.3 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.612650567132253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.612650567132253 | validation: 0.7656423214181381]
	TIME [epoch: 10.3 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9559106120485067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9559106120485067 | validation: 0.8873208698355859]
	TIME [epoch: 10.3 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7617935657049364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7617935657049364 | validation: 1.7184596337215627]
	TIME [epoch: 10.3 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.01692464821726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.01692464821726 | validation: 0.6100447768198244]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6422040863384739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6422040863384739 | validation: 0.48908284875056834]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6939947400418875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6939947400418875 | validation: 0.6624136465790754]
	TIME [epoch: 10.3 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6317990578462835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6317990578462835 | validation: 0.5578822063085541]
	TIME [epoch: 10.3 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.079752692043598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.079752692043598 | validation: 0.7406253943703223]
	TIME [epoch: 10.3 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8298685887587522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8298685887587522 | validation: 1.2664642420557304]
	TIME [epoch: 10.3 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9577018559200541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9577018559200541 | validation: 0.9831600664575332]
	TIME [epoch: 10.3 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1125850794330296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1125850794330296 | validation: 0.9672454468323888]
	TIME [epoch: 10.3 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6850389888015358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6850389888015358 | validation: 1.7997273084419967]
	TIME [epoch: 10.3 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.061289711356822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.061289711356822 | validation: 0.8388046985674896]
	TIME [epoch: 10.3 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8876498059285612		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8876498059285612 | validation: 0.8696629761920879]
	TIME [epoch: 10.3 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9974322509265041		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9974322509265041 | validation: 0.6818752807880981]
	TIME [epoch: 10.3 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7485606994264182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7485606994264182 | validation: 0.6486431029875485]
	TIME [epoch: 10.3 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8888798454380336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8888798454380336 | validation: 0.752628324527599]
	TIME [epoch: 10.3 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.078845235742255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.078845235742255 | validation: 1.2607763765930418]
	TIME [epoch: 10.3 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0835187851586425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0835187851586425 | validation: 1.0058502712551947]
	TIME [epoch: 10.3 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.393750638852988		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.393750638852988 | validation: 0.7305879002858399]
	TIME [epoch: 10.3 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6692772380584355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6692772380584355 | validation: 0.6757499958701993]
	TIME [epoch: 10.3 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2086056946406538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2086056946406538 | validation: 1.1553443860756893]
	TIME [epoch: 10.3 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8864928888000124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8864928888000124 | validation: 3.2397817850843276]
	TIME [epoch: 10.3 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8170450855677172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8170450855677172 | validation: 0.9115878831803212]
	TIME [epoch: 10.3 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.071725480259803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.071725480259803 | validation: 0.919771882928038]
	TIME [epoch: 10.3 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8793582864773928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8793582864773928 | validation: 1.5533155945285808]
	TIME [epoch: 10.3 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2110644759463716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2110644759463716 | validation: 1.9324692347770378]
	TIME [epoch: 10.3 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5202092207516469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5202092207516469 | validation: 0.8908349120075277]
	TIME [epoch: 10.3 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9452097221375485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9452097221375485 | validation: 0.9699329614047255]
	TIME [epoch: 10.3 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2246231027716177		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2246231027716177 | validation: 0.6167752434552172]
	TIME [epoch: 10.3 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.695527517865975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.695527517865975 | validation: 0.5111492698165866]
	TIME [epoch: 10.3 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6418435686318203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6418435686318203 | validation: 0.6478904243112612]
	TIME [epoch: 10.3 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8781117414784335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8781117414784335 | validation: 1.1947014769494086]
	TIME [epoch: 10.3 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8743945080849898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8743945080849898 | validation: 0.5824181981857768]
	TIME [epoch: 10.3 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6434311975541296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6434311975541296 | validation: 0.7857965703304018]
	TIME [epoch: 10.3 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6781809282858048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6781809282858048 | validation: 0.7427261691343688]
	TIME [epoch: 10.3 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7683500475491482		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7683500475491482 | validation: 1.0349877834516195]
	TIME [epoch: 10.3 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9141656975742777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9141656975742777 | validation: 0.6319173352049002]
	TIME [epoch: 10.3 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6720105195817698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6720105195817698 | validation: 0.6940571192358695]
	TIME [epoch: 10.3 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7295497526542531		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7295497526542531 | validation: 0.5993037855892981]
	TIME [epoch: 10.3 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8499238291093251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8499238291093251 | validation: 0.7218037725332253]
	TIME [epoch: 10.3 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6997283559017443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6997283559017443 | validation: 0.8081786539478154]
	TIME [epoch: 10.3 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7167078529235191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7167078529235191 | validation: 1.3472859881555719]
	TIME [epoch: 10.3 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.951037821369165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.951037821369165 | validation: 0.4974498514824912]
	TIME [epoch: 10.3 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5914966755187087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5914966755187087 | validation: 0.5024013572829114]
	TIME [epoch: 10.3 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5484920091865187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5484920091865187 | validation: 0.6134406976316863]
	TIME [epoch: 10.3 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6997915690514833		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6997915690514833 | validation: 1.747280195239054]
	TIME [epoch: 10.3 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9713208541387075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9713208541387075 | validation: 0.901468172867483]
	TIME [epoch: 10.3 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7942584932119173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7942584932119173 | validation: 0.5833964169216063]
	TIME [epoch: 10.3 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7089597699661703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7089597699661703 | validation: 0.5395409204956103]
	TIME [epoch: 10.3 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6241466834746112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6241466834746112 | validation: 0.9243397602853645]
	TIME [epoch: 10.3 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6711210448051219		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6711210448051219 | validation: 0.48068803942335264]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_154.pth
	Model improved!!!
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6879809528751852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6879809528751852 | validation: 0.6857780725330562]
	TIME [epoch: 10.3 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6506958730313535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6506958730313535 | validation: 0.5553917509083636]
	TIME [epoch: 10.3 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7207548782093095		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7207548782093095 | validation: 0.5731822947464178]
	TIME [epoch: 10.3 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7595975365324064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7595975365324064 | validation: 0.6380100463114917]
	TIME [epoch: 10.3 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9481016928622179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9481016928622179 | validation: 0.661493306556666]
	TIME [epoch: 10.3 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6240155025579316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6240155025579316 | validation: 0.5307326606467199]
	TIME [epoch: 10.3 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7701127548942333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7701127548942333 | validation: 0.6022930442901052]
	TIME [epoch: 10.3 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6544767294183879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6544767294183879 | validation: 0.6009016681208424]
	TIME [epoch: 10.3 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6818790408559812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6818790408559812 | validation: 0.6221355035638166]
	TIME [epoch: 10.3 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7088075454625445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7088075454625445 | validation: 0.8456946692148058]
	TIME [epoch: 10.3 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7983968821083731		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7983968821083731 | validation: 0.6270737655646401]
	TIME [epoch: 10.3 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6193628652163508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6193628652163508 | validation: 0.5302955570131084]
	TIME [epoch: 10.3 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6371022661443712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6371022661443712 | validation: 0.654085605600307]
	TIME [epoch: 10.3 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8784774043090977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8784774043090977 | validation: 1.2516918154494137]
	TIME [epoch: 10.3 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.894206107348676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.894206107348676 | validation: 0.9837480441170652]
	TIME [epoch: 10.3 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7736562513056422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7736562513056422 | validation: 0.6513462244182603]
	TIME [epoch: 10.3 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2514229508366388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2514229508366388 | validation: 2.583655055893138]
	TIME [epoch: 10.3 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3256049041924123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3256049041924123 | validation: 0.49872234839762286]
	TIME [epoch: 10.3 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5141601422188342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5141601422188342 | validation: 0.675033205340016]
	TIME [epoch: 10.3 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7440190561510784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7440190561510784 | validation: 0.7449089355641374]
	TIME [epoch: 10.3 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9024854195326248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9024854195326248 | validation: 1.748413216153145]
	TIME [epoch: 10.3 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9824486728260957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9824486728260957 | validation: 0.6963076934385097]
	TIME [epoch: 10.3 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6455530479089874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6455530479089874 | validation: 0.541503746365027]
	TIME [epoch: 10.3 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6217681787535009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6217681787535009 | validation: 0.7132497274477705]
	TIME [epoch: 10.3 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7156994296106829		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7156994296106829 | validation: 0.7855097982007732]
	TIME [epoch: 10.3 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7410609534644989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7410609534644989 | validation: 1.0299115747094265]
	TIME [epoch: 10.3 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8087720147926287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8087720147926287 | validation: 0.48894284747135025]
	TIME [epoch: 10.3 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9309603363825888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9309603363825888 | validation: 0.8046522647691694]
	TIME [epoch: 10.3 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7259298343920851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7259298343920851 | validation: 0.6782339140768301]
	TIME [epoch: 10.3 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6554852947148542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6554852947148542 | validation: 0.9189376379849955]
	TIME [epoch: 10.3 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6812005748724843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6812005748724843 | validation: 0.5198592330157294]
	TIME [epoch: 10.3 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5546188911063942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5546188911063942 | validation: 0.7049159564997683]
	TIME [epoch: 10.3 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6243230866616705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6243230866616705 | validation: 0.6301360005952045]
	TIME [epoch: 10.3 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7678923878221634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7678923878221634 | validation: 0.44077951357179374]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_188.pth
	Model improved!!!
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7102247667086584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7102247667086584 | validation: 0.9649350995817888]
	TIME [epoch: 10.3 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8273517570127924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8273517570127924 | validation: 0.9410094995831386]
	TIME [epoch: 10.3 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8964867813098261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8964867813098261 | validation: 0.6379489823427837]
	TIME [epoch: 10.3 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3038155949009727		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3038155949009727 | validation: 1.242210043733223]
	TIME [epoch: 10.3 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8667319003633249		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8667319003633249 | validation: 0.5894717548949904]
	TIME [epoch: 10.3 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6166667140582374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6166667140582374 | validation: 0.5209827110863556]
	TIME [epoch: 10.3 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5894221675352511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5894221675352511 | validation: 0.6801148669510945]
	TIME [epoch: 10.3 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5498342802643064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5498342802643064 | validation: 0.7354161215626374]
	TIME [epoch: 10.3 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6805965682526989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6805965682526989 | validation: 0.6844975757861076]
	TIME [epoch: 10.3 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6503431539568192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6503431539568192 | validation: 0.46071514198728436]
	TIME [epoch: 10.3 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6166761996347605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6166761996347605 | validation: 0.6065941639711239]
	TIME [epoch: 10.3 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5967702611121067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5967702611121067 | validation: 0.6099645529887474]
	TIME [epoch: 10.3 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.654126228661229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.654126228661229 | validation: 0.6997310378415541]
	TIME [epoch: 10.3 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6521351947327331		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6521351947327331 | validation: 0.5042243742943856]
	TIME [epoch: 10.3 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.592583144978191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.592583144978191 | validation: 0.5233425239321405]
	TIME [epoch: 10.3 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6934995500845746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6934995500845746 | validation: 0.8741899594128375]
	TIME [epoch: 10.3 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6660450432483762		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6660450432483762 | validation: 0.6308964074957369]
	TIME [epoch: 10.3 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6111880184102053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6111880184102053 | validation: 0.5508170959311771]
	TIME [epoch: 10.3 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5458319877566498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5458319877566498 | validation: 0.7264100422258803]
	TIME [epoch: 10.3 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6165569234878332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6165569234878332 | validation: 0.5024297857938983]
	TIME [epoch: 10.3 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6759457649516841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6759457649516841 | validation: 0.5708663020825955]
	TIME [epoch: 10.3 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.552077516972831		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.552077516972831 | validation: 0.4468789505622334]
	TIME [epoch: 10.3 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7299113747450071		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7299113747450071 | validation: 0.7559980743569125]
	TIME [epoch: 10.3 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0049408996278548		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0049408996278548 | validation: 0.7513734209046169]
	TIME [epoch: 10.3 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7508603823239882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7508603823239882 | validation: 1.3036036964976854]
	TIME [epoch: 10.3 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8514012409590388		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8514012409590388 | validation: 0.9241653891269722]
	TIME [epoch: 10.3 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6781119714256126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6781119714256126 | validation: 0.44862379922604406]
	TIME [epoch: 10.3 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5191723411606392		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5191723411606392 | validation: 0.7147273437491242]
	TIME [epoch: 10.3 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5534310341185924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5534310341185924 | validation: 0.5091808377500692]
	TIME [epoch: 10.3 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6347915960198055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6347915960198055 | validation: 0.6410635981771546]
	TIME [epoch: 10.3 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6016612830364086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6016612830364086 | validation: 0.503467029625979]
	TIME [epoch: 10.3 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47574996337769715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47574996337769715 | validation: 0.7034133520006154]
	TIME [epoch: 10.3 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.688317426557912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.688317426557912 | validation: 0.6490320043865389]
	TIME [epoch: 10.3 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6082142392055138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6082142392055138 | validation: 0.7275358851715796]
	TIME [epoch: 10.3 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7541410448510381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7541410448510381 | validation: 0.6498512874391683]
	TIME [epoch: 10.3 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7264076553941097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7264076553941097 | validation: 0.9610834190807814]
	TIME [epoch: 10.3 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8452988340549463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8452988340549463 | validation: 0.5530062860047517]
	TIME [epoch: 10.3 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5772524338720549		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5772524338720549 | validation: 0.5904606459738585]
	TIME [epoch: 10.3 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5943422461119852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5943422461119852 | validation: 0.751502114322949]
	TIME [epoch: 10.3 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7099664364980026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7099664364980026 | validation: 0.7386176443710898]
	TIME [epoch: 10.3 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.747036872175407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.747036872175407 | validation: 0.6526133781335124]
	TIME [epoch: 10.3 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6304351466824316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6304351466824316 | validation: 0.7037725385122081]
	TIME [epoch: 10.3 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6260045632148501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6260045632148501 | validation: 0.6306048789473061]
	TIME [epoch: 10.3 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6674446115218077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6674446115218077 | validation: 1.2969566256126184]
	TIME [epoch: 10.3 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1329082053765267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1329082053765267 | validation: 0.6970285219540258]
	TIME [epoch: 10.3 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8103691956093837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8103691956093837 | validation: 0.9952843890451862]
	TIME [epoch: 10.3 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8574772560114974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8574772560114974 | validation: 0.7488789082353159]
	TIME [epoch: 10.3 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7959832427956399		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7959832427956399 | validation: 0.5110644293663278]
	TIME [epoch: 10.3 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5480811155366654		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5480811155366654 | validation: 0.5620973624550653]
	TIME [epoch: 10.3 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6685329652933085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6685329652933085 | validation: 0.5640059260708626]
	TIME [epoch: 10.3 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.612290707016332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.612290707016332 | validation: 0.6662259533227396]
	TIME [epoch: 10.3 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6002661780659062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6002661780659062 | validation: 0.569691745333608]
	TIME [epoch: 10.3 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5673317840078134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5673317840078134 | validation: 0.533871967757642]
	TIME [epoch: 10.3 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5650175554415747		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5650175554415747 | validation: 0.5650270660547755]
	TIME [epoch: 10.3 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.505929419493895		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.505929419493895 | validation: 0.5838843424807799]
	TIME [epoch: 10.3 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.773909049143165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.773909049143165 | validation: 1.2544567297222127]
	TIME [epoch: 10.3 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7729894442268923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7729894442268923 | validation: 0.6224598132169716]
	TIME [epoch: 10.3 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7221814501102107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7221814501102107 | validation: 0.7398127274293242]
	TIME [epoch: 10.3 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5359772141360925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5359772141360925 | validation: 0.774833156602858]
	TIME [epoch: 10.3 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6194500217066381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6194500217066381 | validation: 0.4819125774906863]
	TIME [epoch: 10.3 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5037153622353009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5037153622353009 | validation: 0.47766936769028406]
	TIME [epoch: 10.3 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6040854447431949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6040854447431949 | validation: 0.634089696665742]
	TIME [epoch: 10.3 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5666517628911378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5666517628911378 | validation: 0.4756483206180221]
	TIME [epoch: 10.3 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6189698982664542		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6189698982664542 | validation: 0.6186782377634238]
	TIME [epoch: 10.3 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2131740474337014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2131740474337014 | validation: 1.3453593325772506]
	TIME [epoch: 10.3 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9160230777624372		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9160230777624372 | validation: 0.5735026779427258]
	TIME [epoch: 10.3 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6171463892326063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6171463892326063 | validation: 0.5133226851833274]
	TIME [epoch: 10.3 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5624365263215375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5624365263215375 | validation: 0.6318722280200574]
	TIME [epoch: 10.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5906958803105807		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5906958803105807 | validation: 0.5314943019129033]
	TIME [epoch: 10.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.509854507162669		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.509854507162669 | validation: 0.5345956247506712]
	TIME [epoch: 10.3 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3818410669847783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3818410669847783 | validation: 3.1444994916765996]
	TIME [epoch: 10.3 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6807525658109403		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6807525658109403 | validation: 2.60213766169845]
	TIME [epoch: 10.3 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.136428821487581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.136428821487581 | validation: 1.694496951557852]
	TIME [epoch: 10.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1341647645355493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1341647645355493 | validation: 0.6048573293095622]
	TIME [epoch: 10.3 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7456850317842535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7456850317842535 | validation: 0.7632983521524637]
	TIME [epoch: 10.3 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0113730559394154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0113730559394154 | validation: 0.6677368046368656]
	TIME [epoch: 10.3 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0484891479262441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0484891479262441 | validation: 1.1015008081664908]
	TIME [epoch: 10.3 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7879401607681111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7879401607681111 | validation: 0.6833705703351416]
	TIME [epoch: 10.3 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5429773330817236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5429773330817236 | validation: 0.4590305095577174]
	TIME [epoch: 10.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4925753833171381		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4925753833171381 | validation: 0.4001316726290778]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_268.pth
	Model improved!!!
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5267663385941218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5267663385941218 | validation: 0.9136633134140542]
	TIME [epoch: 10.3 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6143500174325365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6143500174325365 | validation: 0.553049105335159]
	TIME [epoch: 10.3 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7314954133561383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7314954133561383 | validation: 1.3943599792127406]
	TIME [epoch: 10.3 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8283829043019395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8283829043019395 | validation: 0.5864340950596943]
	TIME [epoch: 10.3 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.616027421713375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.616027421713375 | validation: 0.5654146538427923]
	TIME [epoch: 10.3 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5440226146311098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5440226146311098 | validation: 0.5783289405848789]
	TIME [epoch: 10.3 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47212647620081116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47212647620081116 | validation: 0.39188170945321504]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_275.pth
	Model improved!!!
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6484889855254512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6484889855254512 | validation: 0.9579891490804531]
	TIME [epoch: 10.3 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6579705450461412		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6579705450461412 | validation: 0.4834754097205311]
	TIME [epoch: 10.3 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5521416726254487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5521416726254487 | validation: 0.6903185852185749]
	TIME [epoch: 10.3 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5417943004782254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5417943004782254 | validation: 0.5210137617154187]
	TIME [epoch: 10.3 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5169668389450965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5169668389450965 | validation: 0.3914767510367847]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_280.pth
	Model improved!!!
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47532507992366446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47532507992366446 | validation: 0.7377585136213192]
	TIME [epoch: 10.3 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6000219497183792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6000219497183792 | validation: 1.4783651293050755]
	TIME [epoch: 10.3 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9449461907872105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9449461907872105 | validation: 0.443320868429648]
	TIME [epoch: 10.3 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8583516774850144		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8583516774850144 | validation: 0.4631943363032876]
	TIME [epoch: 10.3 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49544110044201295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49544110044201295 | validation: 0.42944834487456024]
	TIME [epoch: 10.3 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4761207430638771		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4761207430638771 | validation: 0.6098297112742392]
	TIME [epoch: 10.3 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5696443589821087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5696443589821087 | validation: 0.5786383590062387]
	TIME [epoch: 10.3 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47545785506822913		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47545785506822913 | validation: 0.436716132496325]
	TIME [epoch: 10.3 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43755214386341984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43755214386341984 | validation: 0.46084410369632495]
	TIME [epoch: 10.3 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6654974103626452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6654974103626452 | validation: 0.5266590449732023]
	TIME [epoch: 10.3 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6378372635644352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6378372635644352 | validation: 0.5667635619851774]
	TIME [epoch: 10.3 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7296165912075869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7296165912075869 | validation: 0.3786087352436715]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_292.pth
	Model improved!!!
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4676044567249805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4676044567249805 | validation: 0.3821740781420982]
	TIME [epoch: 10.3 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46681229988357253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46681229988357253 | validation: 0.9788077001574774]
	TIME [epoch: 10.3 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6542571496710975		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6542571496710975 | validation: 0.5853838583661664]
	TIME [epoch: 10.3 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49364909538158186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49364909538158186 | validation: 0.5376061838904925]
	TIME [epoch: 10.3 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5161326845934054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5161326845934054 | validation: 0.6396230632262002]
	TIME [epoch: 10.3 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6276322023226133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6276322023226133 | validation: 0.5084291525313093]
	TIME [epoch: 10.3 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6578618111971396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6578618111971396 | validation: 0.5578422958569549]
	TIME [epoch: 10.3 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355428101628084		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6355428101628084 | validation: 0.3822891241893967]
	TIME [epoch: 10.3 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4031725054172843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4031725054172843 | validation: 0.6508885087072491]
	TIME [epoch: 10.3 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.866579589596404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.866579589596404 | validation: 0.9806475879393198]
	TIME [epoch: 10.3 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7098120215674928		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7098120215674928 | validation: 0.44441748032941464]
	TIME [epoch: 10.3 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45066818936029945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45066818936029945 | validation: 0.6333776538846958]
	TIME [epoch: 10.3 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4418478234147335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4418478234147335 | validation: 0.5642883890965962]
	TIME [epoch: 10.3 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5382104184248911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5382104184248911 | validation: 0.3900406821893947]
	TIME [epoch: 10.3 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37416433838865404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37416433838865404 | validation: 0.3360562497759918]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_307.pth
	Model improved!!!
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5150472866881273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5150472866881273 | validation: 0.782819141926411]
	TIME [epoch: 10.3 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6734226300922962		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6734226300922962 | validation: 0.6185149955088052]
	TIME [epoch: 10.3 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5052872980219563		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5052872980219563 | validation: 0.3996502019496944]
	TIME [epoch: 10.3 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.457053039174645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.457053039174645 | validation: 0.37126510574903293]
	TIME [epoch: 10.3 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5705755027006645		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5705755027006645 | validation: 0.9935707354242884]
	TIME [epoch: 10.3 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6398052675130553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6398052675130553 | validation: 0.4634995441838183]
	TIME [epoch: 10.3 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6654118441428454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6654118441428454 | validation: 0.9562137171269461]
	TIME [epoch: 10.3 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7041892157957237		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7041892157957237 | validation: 0.42447667892841123]
	TIME [epoch: 10.3 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.434689124916143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.434689124916143 | validation: 0.6830618683244325]
	TIME [epoch: 10.3 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5452548350085541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5452548350085541 | validation: 0.4501798408149027]
	TIME [epoch: 10.3 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4360873924421343		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4360873924421343 | validation: 0.76915477080804]
	TIME [epoch: 10.3 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.560899642602726		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.560899642602726 | validation: 0.40917448127079725]
	TIME [epoch: 10.3 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6870834798053704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6870834798053704 | validation: 0.5328443369062629]
	TIME [epoch: 10.3 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0205901681527814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0205901681527814 | validation: 1.2322431681973829]
	TIME [epoch: 10.3 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7314434732158868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7314434732158868 | validation: 0.4984948880695779]
	TIME [epoch: 10.3 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5580718450454734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5580718450454734 | validation: 0.9311945256573931]
	TIME [epoch: 10.3 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8040945253986411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8040945253986411 | validation: 0.6937083077918527]
	TIME [epoch: 10.3 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5809153523687066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5809153523687066 | validation: 0.5994106653269993]
	TIME [epoch: 10.3 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5544328383706336		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5544328383706336 | validation: 0.4578893316495269]
	TIME [epoch: 10.3 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5396971246091111		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5396971246091111 | validation: 0.6186565764740154]
	TIME [epoch: 10.3 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0065828114105355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0065828114105355 | validation: 0.35439383366794885]
	TIME [epoch: 10.3 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4178251976913042		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4178251976913042 | validation: 0.4058213711047688]
	TIME [epoch: 10.3 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46650901311984205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46650901311984205 | validation: 0.49118935773464933]
	TIME [epoch: 10.3 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7934570521736422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7934570521736422 | validation: 1.0484077672304903]
	TIME [epoch: 10.3 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1932295398299633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1932295398299633 | validation: 1.819912623363843]
	TIME [epoch: 10.3 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9195148745312729		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9195148745312729 | validation: 0.4397153220339682]
	TIME [epoch: 10.3 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.482335348725287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.482335348725287 | validation: 0.4470461563366655]
	TIME [epoch: 10.3 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4516323198917614		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4516323198917614 | validation: 0.44749607865471214]
	TIME [epoch: 10.3 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4362618640128445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4362618640128445 | validation: 0.5803536539512304]
	TIME [epoch: 10.3 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5145006967897736		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5145006967897736 | validation: 0.49252251638207684]
	TIME [epoch: 10.3 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4627758131482863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4627758131482863 | validation: 0.38994643431587117]
	TIME [epoch: 10.3 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5216316988265981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5216316988265981 | validation: 0.5930769645937606]
	TIME [epoch: 10.3 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5487616824449005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5487616824449005 | validation: 0.3199142071132462]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.447421221069061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.447421221069061 | validation: 0.5911441920441776]
	TIME [epoch: 10.3 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5509186372026061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5509186372026061 | validation: 0.6723762620894693]
	TIME [epoch: 10.3 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.442211649348713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.442211649348713 | validation: 3.647494935153059]
	TIME [epoch: 10.3 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.251965837895574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.251965837895574 | validation: 3.2160578037592007]
	TIME [epoch: 10.3 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3425689660398006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3425689660398006 | validation: 0.48733776842626897]
	TIME [epoch: 10.3 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7467877369504097		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7467877369504097 | validation: 0.6091933581845862]
	TIME [epoch: 10.3 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5348892787874983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5348892787874983 | validation: 0.6045331957304282]
	TIME [epoch: 10.3 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7352585310274333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7352585310274333 | validation: 0.676410407526916]
	TIME [epoch: 10.3 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46940485161596096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46940485161596096 | validation: 0.42226084772709466]
	TIME [epoch: 10.3 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5042522798455868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5042522798455868 | validation: 2.498401568162829]
	TIME [epoch: 10.3 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.334110074495436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.334110074495436 | validation: 1.4169392188524967]
	TIME [epoch: 10.3 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8958185581831369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8958185581831369 | validation: 0.684564514337325]
	TIME [epoch: 10.3 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6935054690154794		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6935054690154794 | validation: 0.540439444444784]
	TIME [epoch: 10.3 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5898754195678074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5898754195678074 | validation: 0.6194998889696706]
	TIME [epoch: 10.3 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5955465876966686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5955465876966686 | validation: 0.5137089365170854]
	TIME [epoch: 10.3 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43658259468709426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43658259468709426 | validation: 0.5916900687057867]
	TIME [epoch: 10.3 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49589982670526866		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49589982670526866 | validation: 0.8431593393224859]
	TIME [epoch: 10.3 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5351413877739902		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5351413877739902 | validation: 0.5273604248250073]
	TIME [epoch: 10.3 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6041976259557		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6041976259557 | validation: 1.1139728099452664]
	TIME [epoch: 10.3 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6104653176263891		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6104653176263891 | validation: 0.31793543288419984]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_360.pth
	Model improved!!!
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5437397728292288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5437397728292288 | validation: 0.7978415658617448]
	TIME [epoch: 10.3 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6000699979580024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6000699979580024 | validation: 0.536094476206293]
	TIME [epoch: 10.3 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8112853344687292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8112853344687292 | validation: 0.4982970251132154]
	TIME [epoch: 10.3 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5094047961783621		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5094047961783621 | validation: 0.4224027108583421]
	TIME [epoch: 10.3 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.534955927146186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.534955927146186 | validation: 0.7474377479341524]
	TIME [epoch: 10.3 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5789789792734937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5789789792734937 | validation: 0.48336891674803645]
	TIME [epoch: 10.3 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6012931300744848		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6012931300744848 | validation: 0.6101465849595031]
	TIME [epoch: 10.3 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5053682506287889		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5053682506287889 | validation: 0.35961477303977857]
	TIME [epoch: 10.3 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5658409657449329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5658409657449329 | validation: 0.7944518209243977]
	TIME [epoch: 10.3 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9102670825678914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9102670825678914 | validation: 2.511595398436954]
	TIME [epoch: 10.3 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.123291236079879		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.123291236079879 | validation: 1.5624253196828852]
	TIME [epoch: 10.3 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.938174005845838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.938174005845838 | validation: 0.6711151024116652]
	TIME [epoch: 10.3 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6101716437189489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6101716437189489 | validation: 0.6641518806022083]
	TIME [epoch: 10.3 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.760504542862538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.760504542862538 | validation: 0.6993519389560707]
	TIME [epoch: 10.3 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5967204675229346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5967204675229346 | validation: 0.7090066475974633]
	TIME [epoch: 10.3 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5869369195956512		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5869369195956512 | validation: 0.5352308914487217]
	TIME [epoch: 10.3 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5701021267485695		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5701021267485695 | validation: 1.1960474009574442]
	TIME [epoch: 10.3 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7016948074062239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7016948074062239 | validation: 0.8457933503165856]
	TIME [epoch: 10.3 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6155860259109768		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6155860259109768 | validation: 0.767237999523505]
	TIME [epoch: 10.3 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5632847730399498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5632847730399498 | validation: 0.4472466371819843]
	TIME [epoch: 10.3 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6073950095821173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6073950095821173 | validation: 0.3381811135634258]
	TIME [epoch: 10.3 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4006427415976779		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4006427415976779 | validation: 0.4651256131888093]
	TIME [epoch: 10.3 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4163321577969558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4163321577969558 | validation: 0.4270456842890061]
	TIME [epoch: 10.3 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7314743256555987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7314743256555987 | validation: 0.6593880451625098]
	TIME [epoch: 10.3 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5071823391496795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5071823391496795 | validation: 0.44605417530576885]
	TIME [epoch: 10.3 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5904016773406143		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5904016773406143 | validation: 0.41194984680135405]
	TIME [epoch: 10.3 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44135718415052416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44135718415052416 | validation: 0.3556340261782469]
	TIME [epoch: 10.3 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42414622365258603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42414622365258603 | validation: 0.5250603872939253]
	TIME [epoch: 10.3 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6105735880973799		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6105735880973799 | validation: 0.48119448328296416]
	TIME [epoch: 10.3 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43577255791956604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43577255791956604 | validation: 0.34807633560159046]
	TIME [epoch: 10.3 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7889601324221027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7889601324221027 | validation: 1.442280634733053]
	TIME [epoch: 10.3 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8629059159572862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8629059159572862 | validation: 0.38658179790816105]
	TIME [epoch: 10.3 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48049658387473854		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48049658387473854 | validation: 0.4966206887838589]
	TIME [epoch: 10.3 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5519775239671049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5519775239671049 | validation: 0.39909188333761914]
	TIME [epoch: 10.3 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6937876646401584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6937876646401584 | validation: 0.36357879051778386]
	TIME [epoch: 10.3 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5972381923369524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5972381923369524 | validation: 0.6587454263329877]
	TIME [epoch: 10.3 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5686204549963778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5686204549963778 | validation: 0.45687763132014164]
	TIME [epoch: 10.3 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4390549999073018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4390549999073018 | validation: 0.33004081945175173]
	TIME [epoch: 10.3 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44053912822729463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44053912822729463 | validation: 0.9291061927413692]
	TIME [epoch: 10.3 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5764514213630604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5764514213630604 | validation: 0.290011391524981]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_400.pth
	Model improved!!!
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4565333797446514		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4565333797446514 | validation: 0.35507837394293407]
	TIME [epoch: 10.3 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4355257214950721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4355257214950721 | validation: 0.4719870632263148]
	TIME [epoch: 10.3 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3910380415855128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3910380415855128 | validation: 0.5823579043656796]
	TIME [epoch: 10.3 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.445538312652679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.445538312652679 | validation: 0.46664775624023946]
	TIME [epoch: 10.3 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4181329354211073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4181329354211073 | validation: 0.32291512803089717]
	TIME [epoch: 10.3 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3651088754037194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3651088754037194 | validation: 0.37967394646257896]
	TIME [epoch: 10.3 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5519687963889938		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5519687963889938 | validation: 0.47008009519215693]
	TIME [epoch: 10.3 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4193343521606153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4193343521606153 | validation: 0.7108170365427026]
	TIME [epoch: 10.3 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5534179727958948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5534179727958948 | validation: 0.38643518621884554]
	TIME [epoch: 10.3 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4000299389030615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4000299389030615 | validation: 0.8957629373490812]
	TIME [epoch: 10.3 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5323452252851568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5323452252851568 | validation: 0.4417595506253988]
	TIME [epoch: 10.3 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46995400994005354		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46995400994005354 | validation: 0.5698385851202941]
	TIME [epoch: 10.3 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4911822027228939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4911822027228939 | validation: 0.5099322903757981]
	TIME [epoch: 10.3 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4363040335219629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4363040335219629 | validation: 0.6584626664823742]
	TIME [epoch: 10.3 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.595594259946982		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.595594259946982 | validation: 0.6406237272836589]
	TIME [epoch: 10.3 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48803010386711937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48803010386711937 | validation: 0.3046580072889034]
	TIME [epoch: 10.3 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43684809204550723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43684809204550723 | validation: 0.4575176806804231]
	TIME [epoch: 10.3 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4939223169478927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4939223169478927 | validation: 0.2933133146919558]
	TIME [epoch: 10.3 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3475485811637539		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3475485811637539 | validation: 0.6138736779989317]
	TIME [epoch: 10.3 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6444138223904309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6444138223904309 | validation: 0.5317566973236519]
	TIME [epoch: 10.3 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4461594119909346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4461594119909346 | validation: 0.6848529024212805]
	TIME [epoch: 10.3 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8271078050569777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8271078050569777 | validation: 1.753397568950283]
	TIME [epoch: 10.3 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.916556922124559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.916556922124559 | validation: 1.01033915752021]
	TIME [epoch: 10.3 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9457613990397686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9457613990397686 | validation: 0.4712168344065573]
	TIME [epoch: 10.3 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5134827167427067		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5134827167427067 | validation: 0.549384920102719]
	TIME [epoch: 10.3 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6389582193860169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6389582193860169 | validation: 0.7375955536595055]
	TIME [epoch: 10.3 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7852367086345415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7852367086345415 | validation: 0.6018598173279002]
	TIME [epoch: 10.3 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4609882862944124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4609882862944124 | validation: 0.3887049057177629]
	TIME [epoch: 10.3 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5622544945698773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5622544945698773 | validation: 0.48720490561401947]
	TIME [epoch: 10.3 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6234933704821101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6234933704821101 | validation: 0.3293780460318119]
	TIME [epoch: 10.3 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25680512019341706		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.25680512019341706 | validation: 0.2377614411102184]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_431.pth
	Model improved!!!
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.327347025470101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.327347025470101 | validation: 0.9377217481918325]
	TIME [epoch: 10.3 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8069501699415429		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8069501699415429 | validation: 0.566435656293077]
	TIME [epoch: 10.3 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47751170834261086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47751170834261086 | validation: 0.4217076208604229]
	TIME [epoch: 10.3 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42795325234724685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42795325234724685 | validation: 0.4570324210112623]
	TIME [epoch: 10.3 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7682427637574604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7682427637574604 | validation: 1.162231341346913]
	TIME [epoch: 10.3 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7726887471428451		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7726887471428451 | validation: 0.6161332409406057]
	TIME [epoch: 10.3 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1687545718068104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1687545718068104 | validation: 1.2513425003732785]
	TIME [epoch: 10.3 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9213406368751189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9213406368751189 | validation: 0.2931833755214081]
	TIME [epoch: 10.3 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.340309557874208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.340309557874208 | validation: 0.5325013816970758]
	TIME [epoch: 10.3 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41691542913157054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.41691542913157054 | validation: 0.44799288786892505]
	TIME [epoch: 10.3 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44757589391617125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44757589391617125 | validation: 0.8777203098726301]
	TIME [epoch: 10.3 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9145939571847572		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9145939571847572 | validation: 0.7418755921152267]
	TIME [epoch: 10.3 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5622306263423166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5622306263423166 | validation: 0.39401973072137936]
	TIME [epoch: 10.3 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39745503450067715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39745503450067715 | validation: 0.29521598791550635]
	TIME [epoch: 10.3 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3437224867797006		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3437224867797006 | validation: 0.5855355000286923]
	TIME [epoch: 10.3 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5952955547677609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5952955547677609 | validation: 0.3166492079482132]
	TIME [epoch: 10.3 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.323329046892956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.323329046892956 | validation: 0.3238754483081484]
	TIME [epoch: 10.3 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37798451367983865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.37798451367983865 | validation: 0.47261446519703515]
	TIME [epoch: 10.3 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4814257303153419		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4814257303153419 | validation: 0.47275985162440526]
	TIME [epoch: 10.3 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42584104491141384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42584104491141384 | validation: 0.39987342855169217]
	TIME [epoch: 10.3 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4159196874933951		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4159196874933951 | validation: 0.50302206228238]
	TIME [epoch: 10.3 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4936706605021353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4936706605021353 | validation: 0.3471463337288568]
	TIME [epoch: 10.3 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8702149866138007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8702149866138007 | validation: 2.7387312153476784]
	TIME [epoch: 10.3 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.202197504277925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.202197504277925 | validation: 2.6139571515160487]
	TIME [epoch: 10.3 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0777157388932657		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0777157388932657 | validation: 2.5364927194725477]
	TIME [epoch: 10.3 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1627952940688377		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1627952940688377 | validation: 2.6272880174791933]
	TIME [epoch: 10.3 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1230440818221172		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1230440818221172 | validation: 0.9074107228314433]
	TIME [epoch: 10.3 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7011222382199896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7011222382199896 | validation: 0.5349595195853423]
	TIME [epoch: 10.3 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5520184618649993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5520184618649993 | validation: 0.576514356454537]
	TIME [epoch: 10.3 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7923494506998288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7923494506998288 | validation: 0.7233339611434143]
	TIME [epoch: 10.3 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3479739671181714		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3479739671181714 | validation: 1.0477834521411895]
	TIME [epoch: 10.3 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7102357895963892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7102357895963892 | validation: 0.5148576082498283]
	TIME [epoch: 10.3 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.728716533256735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.728716533256735 | validation: 0.6040418836054847]
	TIME [epoch: 10.3 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5746058060991214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5746058060991214 | validation: 0.6438829997549194]
	TIME [epoch: 10.3 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5426293921845382		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5426293921845382 | validation: 0.5691005914563116]
	TIME [epoch: 10.3 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5892465345303357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5892465345303357 | validation: 0.376876284972234]
	TIME [epoch: 10.3 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293303694058576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5293303694058576 | validation: 0.4476430349739355]
	TIME [epoch: 10.3 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7681440129900875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7681440129900875 | validation: 0.9203444506828558]
	TIME [epoch: 10.3 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8412417075331355		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8412417075331355 | validation: 0.7061002128861386]
	TIME [epoch: 10.3 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4912354445083101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4912354445083101 | validation: 0.5365153293517287]
	TIME [epoch: 10.3 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4885478071164061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4885478071164061 | validation: 0.4252113043241101]
	TIME [epoch: 10.3 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4615753397105872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4615753397105872 | validation: 0.4309274223510691]
	TIME [epoch: 10.3 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182967722622174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4182967722622174 | validation: 0.4074610373586121]
	TIME [epoch: 10.3 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43320823252953033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.43320823252953033 | validation: 0.44237343916994176]
	TIME [epoch: 10.3 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8139959670710141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8139959670710141 | validation: 0.8604404272494768]
	TIME [epoch: 10.3 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6763847149865797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6763847149865797 | validation: 0.33875504286277347]
	TIME [epoch: 10.3 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42070442492117427		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.42070442492117427 | validation: 0.48625901606945254]
	TIME [epoch: 10.3 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5395582909349215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5395582909349215 | validation: 0.4627657167719973]
	TIME [epoch: 10.3 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5362101092022541		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5362101092022541 | validation: 0.5021928163041808]
	TIME [epoch: 10.3 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9977445847657282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9977445847657282 | validation: 2.386094435411696]
	TIME [epoch: 10.3 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3267273046506323		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3267273046506323 | validation: 0.7140974342193488]
	TIME [epoch: 10.3 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6094128987367565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6094128987367565 | validation: 1.1587724411174367]
	TIME [epoch: 10.3 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8559687368610197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8559687368610197 | validation: 1.1696887477173992]
	TIME [epoch: 10.3 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.647182764307422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.647182764307422 | validation: 0.7089011960543705]
	TIME [epoch: 10.3 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4949016113986414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4949016113986414 | validation: 0.4015044716755238]
	TIME [epoch: 10.3 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4768549478334668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4768549478334668 | validation: 0.45741392898688504]
	TIME [epoch: 10.3 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4790014984179803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4790014984179803 | validation: 0.7699242102381593]
	TIME [epoch: 10.3 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5125385744525176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5125385744525176 | validation: 0.4695632894602379]
	TIME [epoch: 10.3 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4855934706340713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4855934706340713 | validation: 0.4143279519409364]
	TIME [epoch: 10.3 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45652209857466464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45652209857466464 | validation: 0.37319632606919056]
	TIME [epoch: 10.3 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49336092417151994		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49336092417151994 | validation: 0.5509226550155932]
	TIME [epoch: 10.3 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5162029504973604		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5162029504973604 | validation: 0.7196046530640534]
	TIME [epoch: 10.3 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5413992133128278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5413992133128278 | validation: 0.5079786109197596]
	TIME [epoch: 10.3 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4919850288722965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4919850288722965 | validation: 0.5229123586641969]
	TIME [epoch: 10.3 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5681234981205481		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5681234981205481 | validation: 0.8287724947588239]
	TIME [epoch: 10.3 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6039126023286292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6039126023286292 | validation: 0.5010199587810469]
	TIME [epoch: 10.3 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5203094475983098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5203094475983098 | validation: 0.5595115934349036]
	TIME [epoch: 10.3 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5408491568950291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5408491568950291 | validation: 0.6721856091551325]
	TIME [epoch: 10.3 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5156334322659183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5156334322659183 | validation: 0.48870640606247995]
	TIME [epoch: 10.3 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3876710426652984		[learning rate: 0.0099755]
	Learning Rate: 0.00997547
	LOSS [training: 0.3876710426652984 | validation: 0.4649138023228331]
	TIME [epoch: 10.3 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47705930140670033		[learning rate: 0.0099449]
	Learning Rate: 0.00994489
	LOSS [training: 0.47705930140670033 | validation: 0.37819596933430916]
	TIME [epoch: 10.3 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5445963993717646		[learning rate: 0.0099144]
	Learning Rate: 0.0099144
	LOSS [training: 0.5445963993717646 | validation: 0.5791767087128565]
	TIME [epoch: 10.3 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48969694154118776		[learning rate: 0.009884]
	Learning Rate: 0.00988401
	LOSS [training: 0.48969694154118776 | validation: 0.45123192751466384]
	TIME [epoch: 10.3 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44388492077217884		[learning rate: 0.0098537]
	Learning Rate: 0.00985371
	LOSS [training: 0.44388492077217884 | validation: 0.42930404453519755]
	TIME [epoch: 10.3 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5633879064731413		[learning rate: 0.0098235]
	Learning Rate: 0.00982351
	LOSS [training: 0.5633879064731413 | validation: 0.9026214492592456]
	TIME [epoch: 10.3 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7886736449575306		[learning rate: 0.0097934]
	Learning Rate: 0.0097934
	LOSS [training: 0.7886736449575306 | validation: 0.6646886229656874]
	TIME [epoch: 10.3 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6810081860706843		[learning rate: 0.0097634]
	Learning Rate: 0.00976337
	LOSS [training: 0.6810081860706843 | validation: 0.8492982006192011]
	TIME [epoch: 10.3 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7053722767055393		[learning rate: 0.0097334]
	Learning Rate: 0.00973345
	LOSS [training: 0.7053722767055393 | validation: 0.47545087207813214]
	TIME [epoch: 10.3 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4894291679096224		[learning rate: 0.0097036]
	Learning Rate: 0.00970361
	LOSS [training: 0.4894291679096224 | validation: 0.6763911120982755]
	TIME [epoch: 10.3 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5666916605343431		[learning rate: 0.0096739]
	Learning Rate: 0.00967386
	LOSS [training: 0.5666916605343431 | validation: 0.5280395648103481]
	TIME [epoch: 10.3 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.576420940783492		[learning rate: 0.0096442]
	Learning Rate: 0.00964421
	LOSS [training: 0.576420940783492 | validation: 0.5630731561404485]
	TIME [epoch: 10.3 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5431291935925018		[learning rate: 0.0096146]
	Learning Rate: 0.00961465
	LOSS [training: 0.5431291935925018 | validation: 0.5785893418400404]
	TIME [epoch: 10.3 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5610258546521184		[learning rate: 0.0095852]
	Learning Rate: 0.00958517
	LOSS [training: 0.5610258546521184 | validation: 0.45915811872499895]
	TIME [epoch: 10.3 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4508706413183087		[learning rate: 0.0095558]
	Learning Rate: 0.00955579
	LOSS [training: 0.4508706413183087 | validation: 0.6980298993640836]
	TIME [epoch: 10.3 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.520232875873695		[learning rate: 0.0095265]
	Learning Rate: 0.0095265
	LOSS [training: 1.520232875873695 | validation: 0.7212084848031646]
	TIME [epoch: 10.3 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5735769181366865		[learning rate: 0.0094973]
	Learning Rate: 0.0094973
	LOSS [training: 0.5735769181366865 | validation: 0.4513352573021829]
	TIME [epoch: 10.3 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4143412565578056		[learning rate: 0.0094682]
	Learning Rate: 0.00946818
	LOSS [training: 0.4143412565578056 | validation: 0.5468837360923129]
	TIME [epoch: 10.3 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5347415753226407		[learning rate: 0.0094392]
	Learning Rate: 0.00943916
	LOSS [training: 0.5347415753226407 | validation: 1.0903490024287206]
	TIME [epoch: 10.3 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7684076177643473		[learning rate: 0.0094102]
	Learning Rate: 0.00941022
	LOSS [training: 0.7684076177643473 | validation: 0.5522061221684832]
	TIME [epoch: 10.3 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47625702840802164		[learning rate: 0.0093814]
	Learning Rate: 0.00938138
	LOSS [training: 0.47625702840802164 | validation: 0.5861110854525237]
	TIME [epoch: 10.3 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6221535169486639		[learning rate: 0.0093526]
	Learning Rate: 0.00935262
	LOSS [training: 0.6221535169486639 | validation: 0.45210948743187224]
	TIME [epoch: 10.3 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45397036601874		[learning rate: 0.009324]
	Learning Rate: 0.00932395
	LOSS [training: 0.45397036601874 | validation: 0.9030091669260172]
	TIME [epoch: 10.3 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5690314349690597		[learning rate: 0.0092954]
	Learning Rate: 0.00929537
	LOSS [training: 0.5690314349690597 | validation: 0.5503688257012779]
	TIME [epoch: 10.3 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4826613615075475		[learning rate: 0.0092669]
	Learning Rate: 0.00926687
	LOSS [training: 0.4826613615075475 | validation: 0.5319477927387103]
	TIME [epoch: 10.3 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5101236463407185		[learning rate: 0.0092385]
	Learning Rate: 0.00923847
	LOSS [training: 0.5101236463407185 | validation: 0.5960583331239317]
	TIME [epoch: 10.3 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5277096880117719		[learning rate: 0.0092101]
	Learning Rate: 0.00921015
	LOSS [training: 0.5277096880117719 | validation: 0.5034994559440203]
	TIME [epoch: 10.3 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2654028791152387		[learning rate: 0.0091819]
	Learning Rate: 0.00918192
	LOSS [training: 1.2654028791152387 | validation: 2.941265450757527]
	TIME [epoch: 10.3 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3258624721258983		[learning rate: 0.0091538]
	Learning Rate: 0.00915377
	LOSS [training: 2.3258624721258983 | validation: 0.5297337164098674]
	TIME [epoch: 10.3 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46398049170258915		[learning rate: 0.0091257]
	Learning Rate: 0.00912571
	LOSS [training: 0.46398049170258915 | validation: 0.5467534706758803]
	TIME [epoch: 10.3 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5704427271417783		[learning rate: 0.0090977]
	Learning Rate: 0.00909774
	LOSS [training: 0.5704427271417783 | validation: 0.42457572923842735]
	TIME [epoch: 10.3 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5079282603249885		[learning rate: 0.0090698]
	Learning Rate: 0.00906985
	LOSS [training: 0.5079282603249885 | validation: 0.608773681189892]
	TIME [epoch: 10.3 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6103156467557507		[learning rate: 0.009042]
	Learning Rate: 0.00904205
	LOSS [training: 0.6103156467557507 | validation: 0.5359805557208109]
	TIME [epoch: 10.3 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4801953395331388		[learning rate: 0.0090143]
	Learning Rate: 0.00901433
	LOSS [training: 0.4801953395331388 | validation: 0.5141145367052224]
	TIME [epoch: 10.3 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44259048313100696		[learning rate: 0.0089867]
	Learning Rate: 0.00898669
	LOSS [training: 0.44259048313100696 | validation: 0.42038333016210644]
	TIME [epoch: 10.3 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4006255738397904		[learning rate: 0.0089591]
	Learning Rate: 0.00895915
	LOSS [training: 0.4006255738397904 | validation: 0.41096742641956163]
	TIME [epoch: 10.3 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5837967966556181		[learning rate: 0.0089317]
	Learning Rate: 0.00893168
	LOSS [training: 0.5837967966556181 | validation: 0.5965298616282034]
	TIME [epoch: 10.3 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5878633504307943		[learning rate: 0.0089043]
	Learning Rate: 0.0089043
	LOSS [training: 0.5878633504307943 | validation: 0.6670854758820599]
	TIME [epoch: 10.3 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5473354104770041		[learning rate: 0.008877]
	Learning Rate: 0.00887701
	LOSS [training: 0.5473354104770041 | validation: 0.5539073867494756]
	TIME [epoch: 10.3 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5845990099880358		[learning rate: 0.0088498]
	Learning Rate: 0.0088498
	LOSS [training: 0.5845990099880358 | validation: 0.6428526847725001]
	TIME [epoch: 10.3 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6440379400571952		[learning rate: 0.0088227]
	Learning Rate: 0.00882267
	LOSS [training: 0.6440379400571952 | validation: 0.5790420983254295]
	TIME [epoch: 10.3 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5277133824808832		[learning rate: 0.0087956]
	Learning Rate: 0.00879562
	LOSS [training: 0.5277133824808832 | validation: 0.5007725019093485]
	TIME [epoch: 10.3 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3783589021550192		[learning rate: 0.0087687]
	Learning Rate: 0.00876866
	LOSS [training: 0.3783589021550192 | validation: 0.4428780913046309]
	TIME [epoch: 10.3 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5276568486175984		[learning rate: 0.0087418]
	Learning Rate: 0.00874178
	LOSS [training: 0.5276568486175984 | validation: 0.6491973536088879]
	TIME [epoch: 10.3 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7919991001761905		[learning rate: 0.008715]
	Learning Rate: 0.00871499
	LOSS [training: 0.7919991001761905 | validation: 0.6057870404555663]
	TIME [epoch: 10.3 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5612790288989292		[learning rate: 0.0086883]
	Learning Rate: 0.00868827
	LOSS [training: 0.5612790288989292 | validation: 1.2360411843365295]
	TIME [epoch: 10.3 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.190814405531688		[learning rate: 0.0086616]
	Learning Rate: 0.00866164
	LOSS [training: 1.190814405531688 | validation: 1.037528372223244]
	TIME [epoch: 10.3 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6654459632919015		[learning rate: 0.0086351]
	Learning Rate: 0.00863509
	LOSS [training: 0.6654459632919015 | validation: 0.4226657843075509]
	TIME [epoch: 10.3 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49978916711298754		[learning rate: 0.0086086]
	Learning Rate: 0.00860862
	LOSS [training: 0.49978916711298754 | validation: 0.9049219529974931]
	TIME [epoch: 10.3 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4790535736474929		[learning rate: 0.0085822]
	Learning Rate: 0.00858223
	LOSS [training: 0.4790535736474929 | validation: 0.3658321156641928]
	TIME [epoch: 10.3 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45478673289002486		[learning rate: 0.0085559]
	Learning Rate: 0.00855592
	LOSS [training: 0.45478673289002486 | validation: 0.8105739456656263]
	TIME [epoch: 10.3 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.62152085309091		[learning rate: 0.0085297]
	Learning Rate: 0.00852969
	LOSS [training: 0.62152085309091 | validation: 0.4176606561404169]
	TIME [epoch: 10.3 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.418685209454489		[learning rate: 0.0085035]
	Learning Rate: 0.00850354
	LOSS [training: 0.418685209454489 | validation: 0.7044770326822504]
	TIME [epoch: 10.3 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7793745551747904		[learning rate: 0.0084775]
	Learning Rate: 0.00847748
	LOSS [training: 0.7793745551747904 | validation: 0.7695370035296819]
	TIME [epoch: 10.3 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7458146220891375		[learning rate: 0.0084515]
	Learning Rate: 0.00845149
	LOSS [training: 0.7458146220891375 | validation: 0.6851862388128046]
	TIME [epoch: 10.3 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4852488608117172		[learning rate: 0.0084256]
	Learning Rate: 0.00842558
	LOSS [training: 0.4852488608117172 | validation: 0.36799250014552853]
	TIME [epoch: 10.3 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4265586582655049		[learning rate: 0.0083998]
	Learning Rate: 0.00839976
	LOSS [training: 0.4265586582655049 | validation: 0.6096905297985435]
	TIME [epoch: 10.3 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5773578099542546		[learning rate: 0.008374]
	Learning Rate: 0.00837401
	LOSS [training: 0.5773578099542546 | validation: 0.5298158720154236]
	TIME [epoch: 10.3 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5149077038024679		[learning rate: 0.0083483]
	Learning Rate: 0.00834834
	LOSS [training: 0.5149077038024679 | validation: 0.5604751875358099]
	TIME [epoch: 10.3 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41542898803790324		[learning rate: 0.0083227]
	Learning Rate: 0.00832275
	LOSS [training: 0.41542898803790324 | validation: 0.4581651081857123]
	TIME [epoch: 10.3 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4519297582492798		[learning rate: 0.0082972]
	Learning Rate: 0.00829723
	LOSS [training: 0.4519297582492798 | validation: 0.40564267235221285]
	TIME [epoch: 10.3 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49430296892615083		[learning rate: 0.0082718]
	Learning Rate: 0.0082718
	LOSS [training: 0.49430296892615083 | validation: 0.5481339600377731]
	TIME [epoch: 10.3 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4798766574437504		[learning rate: 0.0082464]
	Learning Rate: 0.00824644
	LOSS [training: 0.4798766574437504 | validation: 0.4182217827394727]
	TIME [epoch: 10.3 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4152697961169979		[learning rate: 0.0082212]
	Learning Rate: 0.00822116
	LOSS [training: 0.4152697961169979 | validation: 0.376677541554113]
	TIME [epoch: 10.3 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43202183900620766		[learning rate: 0.008196]
	Learning Rate: 0.00819596
	LOSS [training: 0.43202183900620766 | validation: 0.48132257764643394]
	TIME [epoch: 10.3 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4883509791264232		[learning rate: 0.0081708]
	Learning Rate: 0.00817084
	LOSS [training: 0.4883509791264232 | validation: 1.1119027606662124]
	TIME [epoch: 10.3 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8330167494290466		[learning rate: 0.0081458]
	Learning Rate: 0.00814579
	LOSS [training: 0.8330167494290466 | validation: 0.732905959958662]
	TIME [epoch: 10.3 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5266039440589342		[learning rate: 0.0081208]
	Learning Rate: 0.00812082
	LOSS [training: 0.5266039440589342 | validation: 0.4406522389038767]
	TIME [epoch: 10.3 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.407951818532965		[learning rate: 0.0080959]
	Learning Rate: 0.00809593
	LOSS [training: 0.407951818532965 | validation: 0.3176683261053411]
	TIME [epoch: 10.3 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39775493579740645		[learning rate: 0.0080711]
	Learning Rate: 0.00807111
	LOSS [training: 0.39775493579740645 | validation: 0.4840265020712682]
	TIME [epoch: 10.3 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9061167885515768		[learning rate: 0.0080464]
	Learning Rate: 0.00804637
	LOSS [training: 0.9061167885515768 | validation: 2.780023433562592]
	TIME [epoch: 10.3 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1553239126541506		[learning rate: 0.0080217]
	Learning Rate: 0.0080217
	LOSS [training: 2.1553239126541506 | validation: 1.6483416847020045]
	TIME [epoch: 10.3 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9756131547373214		[learning rate: 0.0079971]
	Learning Rate: 0.00799711
	LOSS [training: 0.9756131547373214 | validation: 0.638496219933384]
	TIME [epoch: 10.3 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4514958134007904		[learning rate: 0.0079726]
	Learning Rate: 0.0079726
	LOSS [training: 0.4514958134007904 | validation: 0.41208260580840744]
	TIME [epoch: 10.3 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4553491717642378		[learning rate: 0.0079482]
	Learning Rate: 0.00794816
	LOSS [training: 0.4553491717642378 | validation: 0.6620338259476682]
	TIME [epoch: 10.3 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40184029725919024		[learning rate: 0.0079238]
	Learning Rate: 0.0079238
	LOSS [training: 0.40184029725919024 | validation: 0.4046981161406819]
	TIME [epoch: 10.3 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45001557814528653		[learning rate: 0.0078995]
	Learning Rate: 0.00789951
	LOSS [training: 0.45001557814528653 | validation: 0.4169551454373051]
	TIME [epoch: 10.3 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4716796715430308		[learning rate: 0.0078753]
	Learning Rate: 0.00787529
	LOSS [training: 0.4716796715430308 | validation: 0.37088890958814624]
	TIME [epoch: 10.3 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44828568105105066		[learning rate: 0.0078512]
	Learning Rate: 0.00785115
	LOSS [training: 0.44828568105105066 | validation: 0.374752074817989]
	TIME [epoch: 10.3 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41553492288752414		[learning rate: 0.0078271]
	Learning Rate: 0.00782708
	LOSS [training: 0.41553492288752414 | validation: 0.4688147277505823]
	TIME [epoch: 10.3 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43618732843341296		[learning rate: 0.0078031]
	Learning Rate: 0.00780309
	LOSS [training: 0.43618732843341296 | validation: 0.45893857927376913]
	TIME [epoch: 10.3 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3738455610343535		[learning rate: 0.0077792]
	Learning Rate: 0.00777917
	LOSS [training: 0.3738455610343535 | validation: 0.36691255447722265]
	TIME [epoch: 10.3 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43043250125491384		[learning rate: 0.0077553]
	Learning Rate: 0.00775532
	LOSS [training: 0.43043250125491384 | validation: 0.4901943574453681]
	TIME [epoch: 10.3 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5253766101627816		[learning rate: 0.0077316]
	Learning Rate: 0.00773155
	LOSS [training: 0.5253766101627816 | validation: 0.5677261537908679]
	TIME [epoch: 10.3 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4494209197017146		[learning rate: 0.0077079]
	Learning Rate: 0.00770785
	LOSS [training: 0.4494209197017146 | validation: 0.40499078717022713]
	TIME [epoch: 10.3 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6086002202793533		[learning rate: 0.0076842]
	Learning Rate: 0.00768422
	LOSS [training: 0.6086002202793533 | validation: 0.5102423227512324]
	TIME [epoch: 10.3 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6843979216654115		[learning rate: 0.0076607]
	Learning Rate: 0.00766067
	LOSS [training: 0.6843979216654115 | validation: 1.3827027282936883]
	TIME [epoch: 10.3 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8089462744455925		[learning rate: 0.0076372]
	Learning Rate: 0.00763718
	LOSS [training: 0.8089462744455925 | validation: 0.6098720557576167]
	TIME [epoch: 10.3 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4622700849702827		[learning rate: 0.0076138]
	Learning Rate: 0.00761377
	LOSS [training: 0.4622700849702827 | validation: 0.5108050519193347]
	TIME [epoch: 10.3 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40428645313076206		[learning rate: 0.0075904]
	Learning Rate: 0.00759043
	LOSS [training: 0.40428645313076206 | validation: 0.8445105231734762]
	TIME [epoch: 10.3 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7028385298063404		[learning rate: 0.0075672]
	Learning Rate: 0.00756717
	LOSS [training: 0.7028385298063404 | validation: 0.7251991052776035]
	TIME [epoch: 10.3 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6392719770675109		[learning rate: 0.007544]
	Learning Rate: 0.00754397
	LOSS [training: 0.6392719770675109 | validation: 0.47151076335899095]
	TIME [epoch: 10.3 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4874427475764934		[learning rate: 0.0075208]
	Learning Rate: 0.00752085
	LOSS [training: 0.4874427475764934 | validation: 0.5278068893167478]
	TIME [epoch: 10.3 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4830466671459311		[learning rate: 0.0074978]
	Learning Rate: 0.00749779
	LOSS [training: 0.4830466671459311 | validation: 0.4052610726607832]
	TIME [epoch: 10.3 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4122743449854772		[learning rate: 0.0074748]
	Learning Rate: 0.00747481
	LOSS [training: 0.4122743449854772 | validation: 0.459615720242576]
	TIME [epoch: 10.3 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4314870730282679		[learning rate: 0.0074519]
	Learning Rate: 0.00745189
	LOSS [training: 0.4314870730282679 | validation: 0.5230976871838573]
	TIME [epoch: 10.3 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43273362862969006		[learning rate: 0.0074291]
	Learning Rate: 0.00742905
	LOSS [training: 0.43273362862969006 | validation: 0.4213656144576172]
	TIME [epoch: 10.3 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40789324307558267		[learning rate: 0.0074063]
	Learning Rate: 0.00740628
	LOSS [training: 0.40789324307558267 | validation: 0.4134616087628396]
	TIME [epoch: 10.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3795239958840634		[learning rate: 0.0073836]
	Learning Rate: 0.00738357
	LOSS [training: 0.3795239958840634 | validation: 0.4896414925685635]
	TIME [epoch: 10.3 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38219629693327184		[learning rate: 0.0073609]
	Learning Rate: 0.00736094
	LOSS [training: 0.38219629693327184 | validation: 0.4322500864588011]
	TIME [epoch: 10.3 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40498316073531465		[learning rate: 0.0073384]
	Learning Rate: 0.00733838
	LOSS [training: 0.40498316073531465 | validation: 0.4132248383633922]
	TIME [epoch: 10.3 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4304957442107488		[learning rate: 0.0073159]
	Learning Rate: 0.00731588
	LOSS [training: 0.4304957442107488 | validation: 0.48770691248213527]
	TIME [epoch: 10.3 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4962322572540872		[learning rate: 0.0072935]
	Learning Rate: 0.00729345
	LOSS [training: 0.4962322572540872 | validation: 0.4774086223809293]
	TIME [epoch: 10.3 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4375274341397251		[learning rate: 0.0072711]
	Learning Rate: 0.0072711
	LOSS [training: 0.4375274341397251 | validation: 0.38540180103892485]
	TIME [epoch: 10.3 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48823978156096814		[learning rate: 0.0072488]
	Learning Rate: 0.00724881
	LOSS [training: 0.48823978156096814 | validation: 0.5221988210709904]
	TIME [epoch: 10.3 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4767761398312335		[learning rate: 0.0072266]
	Learning Rate: 0.00722659
	LOSS [training: 0.4767761398312335 | validation: 0.6374408855680087]
	TIME [epoch: 10.3 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5407821648512927		[learning rate: 0.0072044]
	Learning Rate: 0.00720444
	LOSS [training: 0.5407821648512927 | validation: 0.5350976624542729]
	TIME [epoch: 10.3 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48917701085578774		[learning rate: 0.0071824]
	Learning Rate: 0.00718235
	LOSS [training: 0.48917701085578774 | validation: 0.43338302350622043]
	TIME [epoch: 10.3 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44271225474269116		[learning rate: 0.0071603]
	Learning Rate: 0.00716033
	LOSS [training: 0.44271225474269116 | validation: 0.48387736190141256]
	TIME [epoch: 10.3 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5379341549795191		[learning rate: 0.0071384]
	Learning Rate: 0.00713838
	LOSS [training: 0.5379341549795191 | validation: 0.6495267576595041]
	TIME [epoch: 10.3 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6089551125693295		[learning rate: 0.0071165]
	Learning Rate: 0.0071165
	LOSS [training: 0.6089551125693295 | validation: 0.6155730689650212]
	TIME [epoch: 10.3 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7041275696499147		[learning rate: 0.0070947]
	Learning Rate: 0.00709469
	LOSS [training: 0.7041275696499147 | validation: 0.5886415170367125]
	TIME [epoch: 10.3 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5187422592989851		[learning rate: 0.0070729]
	Learning Rate: 0.00707294
	LOSS [training: 0.5187422592989851 | validation: 0.4768765537698086]
	TIME [epoch: 10.3 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47279744994843986		[learning rate: 0.0070513]
	Learning Rate: 0.00705126
	LOSS [training: 0.47279744994843986 | validation: 0.4139875954180988]
	TIME [epoch: 10.3 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4573101210970293		[learning rate: 0.0070296]
	Learning Rate: 0.00702964
	LOSS [training: 0.4573101210970293 | validation: 0.479826946087546]
	TIME [epoch: 10.3 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5438123900913971		[learning rate: 0.0070081]
	Learning Rate: 0.00700809
	LOSS [training: 0.5438123900913971 | validation: 0.5360369263581458]
	TIME [epoch: 10.3 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5129878849677845		[learning rate: 0.0069866]
	Learning Rate: 0.00698661
	LOSS [training: 0.5129878849677845 | validation: 0.6611478048793386]
	TIME [epoch: 10.3 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5602966878227644		[learning rate: 0.0069652]
	Learning Rate: 0.0069652
	LOSS [training: 0.5602966878227644 | validation: 0.49863803521225003]
	TIME [epoch: 10.3 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4531793589023142		[learning rate: 0.0069438]
	Learning Rate: 0.00694384
	LOSS [training: 0.4531793589023142 | validation: 0.3853380859669281]
	TIME [epoch: 10.3 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4027746397566167		[learning rate: 0.0069226]
	Learning Rate: 0.00692256
	LOSS [training: 0.4027746397566167 | validation: 0.46488032608403623]
	TIME [epoch: 10.3 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4799502759818419		[learning rate: 0.0069013]
	Learning Rate: 0.00690134
	LOSS [training: 0.4799502759818419 | validation: 0.4973296136787696]
	TIME [epoch: 10.3 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6071845284679828		[learning rate: 0.0068802]
	Learning Rate: 0.00688018
	LOSS [training: 0.6071845284679828 | validation: 1.0069469069983286]
	TIME [epoch: 10.3 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7466642742560765		[learning rate: 0.0068591]
	Learning Rate: 0.00685909
	LOSS [training: 0.7466642742560765 | validation: 0.7449786594494349]
	TIME [epoch: 10.3 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5611262263431737		[learning rate: 0.0068381]
	Learning Rate: 0.00683807
	LOSS [training: 0.5611262263431737 | validation: 0.4731908487864914]
	TIME [epoch: 10.3 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5091566663944394		[learning rate: 0.0068171]
	Learning Rate: 0.0068171
	LOSS [training: 0.5091566663944394 | validation: 0.5307735563838157]
	TIME [epoch: 10.3 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44722415654150083		[learning rate: 0.0067962]
	Learning Rate: 0.00679621
	LOSS [training: 0.44722415654150083 | validation: 1.539011508069585]
	TIME [epoch: 10.3 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8303615499621488		[learning rate: 0.0067754]
	Learning Rate: 0.00677537
	LOSS [training: 0.8303615499621488 | validation: 0.5079674442422516]
	TIME [epoch: 10.3 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4715329200544929		[learning rate: 0.0067546]
	Learning Rate: 0.00675461
	LOSS [training: 0.4715329200544929 | validation: 0.4758497395326582]
	TIME [epoch: 10.3 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4535383398463117		[learning rate: 0.0067339]
	Learning Rate: 0.0067339
	LOSS [training: 0.4535383398463117 | validation: 0.5342141619918371]
	TIME [epoch: 10.3 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5079039032904061		[learning rate: 0.0067133]
	Learning Rate: 0.00671326
	LOSS [training: 0.5079039032904061 | validation: 0.5381131168115968]
	TIME [epoch: 10.3 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.507483359552497		[learning rate: 0.0066927]
	Learning Rate: 0.00669268
	LOSS [training: 0.507483359552497 | validation: 0.548704535923079]
	TIME [epoch: 10.3 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41308373012127814		[learning rate: 0.0066722]
	Learning Rate: 0.00667216
	LOSS [training: 0.41308373012127814 | validation: 0.40718198664115834]
	TIME [epoch: 10.3 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45632558332205625		[learning rate: 0.0066517]
	Learning Rate: 0.00665171
	LOSS [training: 0.45632558332205625 | validation: 0.5423448939413242]
	TIME [epoch: 10.3 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4108480505585034		[learning rate: 0.0066313]
	Learning Rate: 0.00663132
	LOSS [training: 0.4108480505585034 | validation: 0.37185763137081806]
	TIME [epoch: 10.3 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3490160318683023		[learning rate: 0.006611]
	Learning Rate: 0.00661099
	LOSS [training: 0.3490160318683023 | validation: 0.36574698577130094]
	TIME [epoch: 10.3 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36182569068805637		[learning rate: 0.0065907]
	Learning Rate: 0.00659073
	LOSS [training: 0.36182569068805637 | validation: 0.44725323448703747]
	TIME [epoch: 10.3 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42935587538537845		[learning rate: 0.0065705]
	Learning Rate: 0.00657052
	LOSS [training: 0.42935587538537845 | validation: 0.4347063970504427]
	TIME [epoch: 10.3 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4082397566569747		[learning rate: 0.0065504]
	Learning Rate: 0.00655038
	LOSS [training: 0.4082397566569747 | validation: 0.45217477680382173]
	TIME [epoch: 10.3 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3987250672852568		[learning rate: 0.0065303]
	Learning Rate: 0.0065303
	LOSS [training: 0.3987250672852568 | validation: 0.3728991025527475]
	TIME [epoch: 10.3 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34842881042721724		[learning rate: 0.0065103]
	Learning Rate: 0.00651028
	LOSS [training: 0.34842881042721724 | validation: 0.6455236127957968]
	TIME [epoch: 10.3 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6131352260052316		[learning rate: 0.0064903]
	Learning Rate: 0.00649033
	LOSS [training: 0.6131352260052316 | validation: 0.5990425096246275]
	TIME [epoch: 10.3 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4488971158146966		[learning rate: 0.0064704]
	Learning Rate: 0.00647043
	LOSS [training: 0.4488971158146966 | validation: 0.373914420514201]
	TIME [epoch: 10.3 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33460540037027486		[learning rate: 0.0064506]
	Learning Rate: 0.0064506
	LOSS [training: 0.33460540037027486 | validation: 0.4062115672948724]
	TIME [epoch: 10.3 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39475862768138076		[learning rate: 0.0064308]
	Learning Rate: 0.00643082
	LOSS [training: 0.39475862768138076 | validation: 0.34661519448666356]
	TIME [epoch: 10.3 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4604579942562407		[learning rate: 0.0064111]
	Learning Rate: 0.00641111
	LOSS [training: 0.4604579942562407 | validation: 0.4519794828216403]
	TIME [epoch: 10.3 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4291792122380794		[learning rate: 0.0063915]
	Learning Rate: 0.00639146
	LOSS [training: 0.4291792122380794 | validation: 0.4356140222045054]
	TIME [epoch: 10.3 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4650409403267518		[learning rate: 0.0063719]
	Learning Rate: 0.00637187
	LOSS [training: 0.4650409403267518 | validation: 0.506616494275892]
	TIME [epoch: 10.3 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44274114729919417		[learning rate: 0.0063523]
	Learning Rate: 0.00635233
	LOSS [training: 0.44274114729919417 | validation: 0.4777441600346913]
	TIME [epoch: 10.3 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45197525052653315		[learning rate: 0.0063329]
	Learning Rate: 0.00633286
	LOSS [training: 0.45197525052653315 | validation: 0.3787166472779753]
	TIME [epoch: 10.3 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3810931651350699		[learning rate: 0.0063134]
	Learning Rate: 0.00631345
	LOSS [training: 0.3810931651350699 | validation: 0.37803551905753907]
	TIME [epoch: 10.3 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.502817522256318		[learning rate: 0.0062941]
	Learning Rate: 0.0062941
	LOSS [training: 0.502817522256318 | validation: 0.4761130343626191]
	TIME [epoch: 10.3 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.422395709798689		[learning rate: 0.0062748]
	Learning Rate: 0.0062748
	LOSS [training: 0.422395709798689 | validation: 0.38691642912116375]
	TIME [epoch: 10.3 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38881821781383286		[learning rate: 0.0062556]
	Learning Rate: 0.00625557
	LOSS [training: 0.38881821781383286 | validation: 0.40430618591281914]
	TIME [epoch: 10.3 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3893035351397923		[learning rate: 0.0062364]
	Learning Rate: 0.00623639
	LOSS [training: 0.3893035351397923 | validation: 0.41487068146859435]
	TIME [epoch: 10.3 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3795131562634381		[learning rate: 0.0062173]
	Learning Rate: 0.00621727
	LOSS [training: 0.3795131562634381 | validation: 0.5094753744435319]
	TIME [epoch: 10.3 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42547948313242223		[learning rate: 0.0061982]
	Learning Rate: 0.00619822
	LOSS [training: 0.42547948313242223 | validation: 0.39444137516961364]
	TIME [epoch: 10.3 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37658254879649516		[learning rate: 0.0061792]
	Learning Rate: 0.00617922
	LOSS [training: 0.37658254879649516 | validation: 0.4466948100984986]
	TIME [epoch: 10.3 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45877365992128816		[learning rate: 0.0061603]
	Learning Rate: 0.00616027
	LOSS [training: 0.45877365992128816 | validation: 0.42125992426703535]
	TIME [epoch: 10.3 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42543964292239894		[learning rate: 0.0061414]
	Learning Rate: 0.00614139
	LOSS [training: 0.42543964292239894 | validation: 0.37208010427099625]
	TIME [epoch: 10.3 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4221732847551971		[learning rate: 0.0061226]
	Learning Rate: 0.00612256
	LOSS [training: 0.4221732847551971 | validation: 0.9822983282713159]
	TIME [epoch: 10.3 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5792133454528208		[learning rate: 0.0061038]
	Learning Rate: 0.0061038
	LOSS [training: 0.5792133454528208 | validation: 0.47421680135325617]
	TIME [epoch: 10.3 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4438625413273664		[learning rate: 0.0060851]
	Learning Rate: 0.00608508
	LOSS [training: 0.4438625413273664 | validation: 0.47355542763947805]
	TIME [epoch: 10.3 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42155730670435		[learning rate: 0.0060664]
	Learning Rate: 0.00606643
	LOSS [training: 0.42155730670435 | validation: 0.37018431044530387]
	TIME [epoch: 10.3 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3714327314767921		[learning rate: 0.0060478]
	Learning Rate: 0.00604784
	LOSS [training: 0.3714327314767921 | validation: 0.4812241884119473]
	TIME [epoch: 10.3 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.510771614269822		[learning rate: 0.0060293]
	Learning Rate: 0.0060293
	LOSS [training: 0.510771614269822 | validation: 0.43316963169065814]
	TIME [epoch: 10.3 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43936195455106886		[learning rate: 0.0060108]
	Learning Rate: 0.00601081
	LOSS [training: 0.43936195455106886 | validation: 0.4441462994863738]
	TIME [epoch: 10.3 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46088605217517153		[learning rate: 0.0059924]
	Learning Rate: 0.00599239
	LOSS [training: 0.46088605217517153 | validation: 0.5590954287274391]
	TIME [epoch: 10.3 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4264703244220163		[learning rate: 0.005974]
	Learning Rate: 0.00597402
	LOSS [training: 0.4264703244220163 | validation: 0.3651481280689403]
	TIME [epoch: 10.3 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36467998933039836		[learning rate: 0.0059557]
	Learning Rate: 0.00595571
	LOSS [training: 0.36467998933039836 | validation: 0.4085543802789195]
	TIME [epoch: 10.3 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4677344295491279		[learning rate: 0.0059375]
	Learning Rate: 0.00593745
	LOSS [training: 0.4677344295491279 | validation: 0.4836981517330635]
	TIME [epoch: 10.3 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5322164153216355		[learning rate: 0.0059192]
	Learning Rate: 0.00591925
	LOSS [training: 0.5322164153216355 | validation: 0.4821671160463453]
	TIME [epoch: 10.3 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48659503556898304		[learning rate: 0.0059011]
	Learning Rate: 0.0059011
	LOSS [training: 0.48659503556898304 | validation: 0.48613986175916085]
	TIME [epoch: 10.3 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48539046731976276		[learning rate: 0.005883]
	Learning Rate: 0.00588302
	LOSS [training: 0.48539046731976276 | validation: 0.44564087836612926]
	TIME [epoch: 10.3 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42786576875793614		[learning rate: 0.005865]
	Learning Rate: 0.00586498
	LOSS [training: 0.42786576875793614 | validation: 0.3931999621269272]
	TIME [epoch: 10.3 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44102534091407347		[learning rate: 0.005847]
	Learning Rate: 0.005847
	LOSS [training: 0.44102534091407347 | validation: 0.4832159441002136]
	TIME [epoch: 10.3 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.137881083601445		[learning rate: 0.0058291]
	Learning Rate: 0.00582908
	LOSS [training: 2.137881083601445 | validation: 2.7221281764407963]
	TIME [epoch: 10.3 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3369508471288225		[learning rate: 0.0058112]
	Learning Rate: 0.00581121
	LOSS [training: 1.3369508471288225 | validation: 0.4533661417044897]
	TIME [epoch: 10.3 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4415984682068087		[learning rate: 0.0057934]
	Learning Rate: 0.0057934
	LOSS [training: 0.4415984682068087 | validation: 0.48968909611952216]
	TIME [epoch: 10.3 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5259274077525695		[learning rate: 0.0057756]
	Learning Rate: 0.00577564
	LOSS [training: 0.5259274077525695 | validation: 0.4602737832138397]
	TIME [epoch: 10.3 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4531720939124975		[learning rate: 0.0057579]
	Learning Rate: 0.00575793
	LOSS [training: 0.4531720939124975 | validation: 0.4711555225137318]
	TIME [epoch: 10.3 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4623128054327106		[learning rate: 0.0057403]
	Learning Rate: 0.00574028
	LOSS [training: 0.4623128054327106 | validation: 0.48477258465092304]
	TIME [epoch: 10.3 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4942059597884181		[learning rate: 0.0057227]
	Learning Rate: 0.00572269
	LOSS [training: 0.4942059597884181 | validation: 0.4285678919165129]
	TIME [epoch: 10.3 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.436045207479877		[learning rate: 0.0057051]
	Learning Rate: 0.00570514
	LOSS [training: 0.436045207479877 | validation: 0.45746063067516474]
	TIME [epoch: 10.3 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4502761186486769		[learning rate: 0.0056877]
	Learning Rate: 0.00568766
	LOSS [training: 0.4502761186486769 | validation: 0.5235444058567494]
	TIME [epoch: 10.3 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.482865939930946		[learning rate: 0.0056702]
	Learning Rate: 0.00567022
	LOSS [training: 0.482865939930946 | validation: 0.4347247573871762]
	TIME [epoch: 10.3 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.466303060713069		[learning rate: 0.0056528]
	Learning Rate: 0.00565284
	LOSS [training: 0.466303060713069 | validation: 0.38323722310059]
	TIME [epoch: 10.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4592075143563153		[learning rate: 0.0056355]
	Learning Rate: 0.00563551
	LOSS [training: 0.4592075143563153 | validation: 0.45562690177954873]
	TIME [epoch: 10.3 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42670496534677593		[learning rate: 0.0056182]
	Learning Rate: 0.00561824
	LOSS [training: 0.42670496534677593 | validation: 0.383856809798539]
	TIME [epoch: 10.3 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3952486021248942		[learning rate: 0.005601]
	Learning Rate: 0.00560101
	LOSS [training: 0.3952486021248942 | validation: 0.49826519925783275]
	TIME [epoch: 10.3 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5459628840316039		[learning rate: 0.0055838]
	Learning Rate: 0.00558384
	LOSS [training: 0.5459628840316039 | validation: 0.5704094082378949]
	TIME [epoch: 10.3 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4212576303785026		[learning rate: 0.0055667]
	Learning Rate: 0.00556673
	LOSS [training: 0.4212576303785026 | validation: 0.3940394929151722]
	TIME [epoch: 10.3 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4906255395983788		[learning rate: 0.0055497]
	Learning Rate: 0.00554966
	LOSS [training: 0.4906255395983788 | validation: 0.46444833371302763]
	TIME [epoch: 10.3 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4342211241575858		[learning rate: 0.0055327]
	Learning Rate: 0.00553265
	LOSS [training: 0.4342211241575858 | validation: 0.42010271020938744]
	TIME [epoch: 10.3 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3901118027088599		[learning rate: 0.0055157]
	Learning Rate: 0.00551569
	LOSS [training: 0.3901118027088599 | validation: 0.4544657566609106]
	TIME [epoch: 10.3 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3581045049013263		[learning rate: 0.0054988]
	Learning Rate: 0.00549878
	LOSS [training: 0.3581045049013263 | validation: 0.40565647250349657]
	TIME [epoch: 10.3 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3985020592837706		[learning rate: 0.0054819]
	Learning Rate: 0.00548193
	LOSS [training: 0.3985020592837706 | validation: 0.3625874320268323]
	TIME [epoch: 10.3 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4013387167816555		[learning rate: 0.0054651]
	Learning Rate: 0.00546512
	LOSS [training: 0.4013387167816555 | validation: 0.41409587351152544]
	TIME [epoch: 10.3 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3915432897015326		[learning rate: 0.0054484]
	Learning Rate: 0.00544837
	LOSS [training: 0.3915432897015326 | validation: 0.4580811382119609]
	TIME [epoch: 10.3 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4226423200015431		[learning rate: 0.0054317]
	Learning Rate: 0.00543167
	LOSS [training: 0.4226423200015431 | validation: 0.44656275679147445]
	TIME [epoch: 10.3 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4323725661930403		[learning rate: 0.005415]
	Learning Rate: 0.00541502
	LOSS [training: 0.4323725661930403 | validation: 0.6401209832470641]
	TIME [epoch: 10.3 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5555114122269893		[learning rate: 0.0053984]
	Learning Rate: 0.00539842
	LOSS [training: 0.5555114122269893 | validation: 0.4837211486951532]
	TIME [epoch: 10.3 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47002809372475146		[learning rate: 0.0053819]
	Learning Rate: 0.00538187
	LOSS [training: 0.47002809372475146 | validation: 0.4997940102553162]
	TIME [epoch: 10.3 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4728854800365461		[learning rate: 0.0053654]
	Learning Rate: 0.00536537
	LOSS [training: 0.4728854800365461 | validation: 0.4401252343760258]
	TIME [epoch: 10.3 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4335531611363316		[learning rate: 0.0053489]
	Learning Rate: 0.00534893
	LOSS [training: 0.4335531611363316 | validation: 0.465619276742715]
	TIME [epoch: 10.3 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4977492865900658		[learning rate: 0.0053325]
	Learning Rate: 0.00533253
	LOSS [training: 0.4977492865900658 | validation: 0.4676278560739823]
	TIME [epoch: 10.3 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44369012962080623		[learning rate: 0.0053162]
	Learning Rate: 0.00531618
	LOSS [training: 0.44369012962080623 | validation: 0.47006943687966657]
	TIME [epoch: 10.3 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177276459986662		[learning rate: 0.0052999]
	Learning Rate: 0.00529989
	LOSS [training: 0.4177276459986662 | validation: 0.4505741865942616]
	TIME [epoch: 10.3 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4520702840473999		[learning rate: 0.0052836]
	Learning Rate: 0.00528364
	LOSS [training: 0.4520702840473999 | validation: 0.46269348970789886]
	TIME [epoch: 10.3 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4517914998385958		[learning rate: 0.0052674]
	Learning Rate: 0.00526744
	LOSS [training: 0.4517914998385958 | validation: 0.4318710373450143]
	TIME [epoch: 10.3 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45911219928720265		[learning rate: 0.0052513]
	Learning Rate: 0.0052513
	LOSS [training: 0.45911219928720265 | validation: 0.41953817047504777]
	TIME [epoch: 10.3 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4084404593570422		[learning rate: 0.0052352]
	Learning Rate: 0.0052352
	LOSS [training: 0.4084404593570422 | validation: 0.38089109525772474]
	TIME [epoch: 10.3 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3980414477087016		[learning rate: 0.0052192]
	Learning Rate: 0.00521915
	LOSS [training: 0.3980414477087016 | validation: 0.3839271770247509]
	TIME [epoch: 10.3 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35208270264264185		[learning rate: 0.0052032]
	Learning Rate: 0.00520315
	LOSS [training: 0.35208270264264185 | validation: 0.4204927673906797]
	TIME [epoch: 10.3 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3723675905744998		[learning rate: 0.0051872]
	Learning Rate: 0.0051872
	LOSS [training: 0.3723675905744998 | validation: 0.38606758189445983]
	TIME [epoch: 10.3 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4164236679191796		[learning rate: 0.0051713]
	Learning Rate: 0.0051713
	LOSS [training: 0.4164236679191796 | validation: 0.4786175980877874]
	TIME [epoch: 10.3 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41901340657540553		[learning rate: 0.0051555]
	Learning Rate: 0.00515545
	LOSS [training: 0.41901340657540553 | validation: 0.4112962673038231]
	TIME [epoch: 10.3 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4222457791730364		[learning rate: 0.0051396]
	Learning Rate: 0.00513965
	LOSS [training: 0.4222457791730364 | validation: 0.3730907591041388]
	TIME [epoch: 10.3 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36642410640650974		[learning rate: 0.0051239]
	Learning Rate: 0.00512389
	LOSS [training: 0.36642410640650974 | validation: 0.3789629091499364]
	TIME [epoch: 10.3 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38309671759261		[learning rate: 0.0051082]
	Learning Rate: 0.00510819
	LOSS [training: 0.38309671759261 | validation: 0.3976183597301203]
	TIME [epoch: 10.3 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3799386505597872		[learning rate: 0.0050925]
	Learning Rate: 0.00509253
	LOSS [training: 0.3799386505597872 | validation: 0.3679456796033033]
	TIME [epoch: 10.3 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4148632094059165		[learning rate: 0.0050769]
	Learning Rate: 0.00507692
	LOSS [training: 0.4148632094059165 | validation: 0.6039362479360708]
	TIME [epoch: 10.3 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4763094026688169		[learning rate: 0.0050614]
	Learning Rate: 0.00506135
	LOSS [training: 0.4763094026688169 | validation: 0.44170487600435393]
	TIME [epoch: 10.3 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4176249161696858		[learning rate: 0.0050458]
	Learning Rate: 0.00504584
	LOSS [training: 0.4176249161696858 | validation: 0.40823390823361755]
	TIME [epoch: 10.3 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39131051707524384		[learning rate: 0.0050304]
	Learning Rate: 0.00503037
	LOSS [training: 0.39131051707524384 | validation: 0.4830230274704968]
	TIME [epoch: 10.3 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39361292077832016		[learning rate: 0.005015]
	Learning Rate: 0.00501495
	LOSS [training: 0.39361292077832016 | validation: 0.8220604680198279]
	TIME [epoch: 10.3 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5452381618421921		[learning rate: 0.0049996]
	Learning Rate: 0.00499958
	LOSS [training: 0.5452381618421921 | validation: 0.384398651629501]
	TIME [epoch: 10.3 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34773953327450907		[learning rate: 0.0049843]
	Learning Rate: 0.00498425
	LOSS [training: 0.34773953327450907 | validation: 0.3708862299514956]
	TIME [epoch: 10.3 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4123697050906288		[learning rate: 0.004969]
	Learning Rate: 0.00496897
	LOSS [training: 0.4123697050906288 | validation: 0.38491703929451077]
	TIME [epoch: 10.3 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4137425520619614		[learning rate: 0.0049537]
	Learning Rate: 0.00495374
	LOSS [training: 0.4137425520619614 | validation: 0.3586948894377862]
	TIME [epoch: 10.3 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3313940438219747		[learning rate: 0.0049386]
	Learning Rate: 0.00493856
	LOSS [training: 0.3313940438219747 | validation: 0.42069163467203463]
	TIME [epoch: 10.3 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43697929678954683		[learning rate: 0.0049234]
	Learning Rate: 0.00492342
	LOSS [training: 0.43697929678954683 | validation: 0.9267480248267037]
	TIME [epoch: 10.3 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5945260074970043		[learning rate: 0.0049083]
	Learning Rate: 0.00490832
	LOSS [training: 0.5945260074970043 | validation: 0.32347465051775437]
	TIME [epoch: 10.3 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36375956511613217		[learning rate: 0.0048933]
	Learning Rate: 0.00489328
	LOSS [training: 0.36375956511613217 | validation: 0.3313750839452226]
	TIME [epoch: 10.3 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3865523116637303		[learning rate: 0.0048783]
	Learning Rate: 0.00487828
	LOSS [training: 0.3865523116637303 | validation: 0.3783809485208741]
	TIME [epoch: 10.3 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36240257398051506		[learning rate: 0.0048633]
	Learning Rate: 0.00486333
	LOSS [training: 0.36240257398051506 | validation: 0.3157811775986382]
	TIME [epoch: 10.3 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31861644249615073		[learning rate: 0.0048484]
	Learning Rate: 0.00484842
	LOSS [training: 0.31861644249615073 | validation: 0.3644141114256823]
	TIME [epoch: 10.3 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3790572759649423		[learning rate: 0.0048336]
	Learning Rate: 0.00483355
	LOSS [training: 0.3790572759649423 | validation: 0.4171069071041455]
	TIME [epoch: 10.3 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39595252479110454		[learning rate: 0.0048187]
	Learning Rate: 0.00481874
	LOSS [training: 0.39595252479110454 | validation: 0.3793752902987397]
	TIME [epoch: 10.3 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34572374141300805		[learning rate: 0.004804]
	Learning Rate: 0.00480397
	LOSS [training: 0.34572374141300805 | validation: 0.3211302487684589]
	TIME [epoch: 10.3 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3249575551624903		[learning rate: 0.0047892]
	Learning Rate: 0.00478924
	LOSS [training: 0.3249575551624903 | validation: 0.30559965184137045]
	TIME [epoch: 10.3 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3233006779349522		[learning rate: 0.0047746]
	Learning Rate: 0.00477456
	LOSS [training: 0.3233006779349522 | validation: 0.395262929581389]
	TIME [epoch: 10.3 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4015273062674547		[learning rate: 0.0047599]
	Learning Rate: 0.00475992
	LOSS [training: 0.4015273062674547 | validation: 0.4801744584488102]
	TIME [epoch: 10.3 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3532585486405984		[learning rate: 0.0047453]
	Learning Rate: 0.00474533
	LOSS [training: 0.3532585486405984 | validation: 0.45429046630821857]
	TIME [epoch: 10.3 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5148218137876304		[learning rate: 0.0047308]
	Learning Rate: 0.00473079
	LOSS [training: 0.5148218137876304 | validation: 0.6941303831251466]
	TIME [epoch: 10.3 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5738848734152794		[learning rate: 0.0047163]
	Learning Rate: 0.00471628
	LOSS [training: 0.5738848734152794 | validation: 0.3581832005312654]
	TIME [epoch: 10.3 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3238234518163342		[learning rate: 0.0047018]
	Learning Rate: 0.00470183
	LOSS [training: 0.3238234518163342 | validation: 0.3188492032360491]
	TIME [epoch: 10.3 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3531249018890889		[learning rate: 0.0046874]
	Learning Rate: 0.00468741
	LOSS [training: 0.3531249018890889 | validation: 0.3749343428169224]
	TIME [epoch: 10.3 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4290434750874194		[learning rate: 0.004673]
	Learning Rate: 0.00467305
	LOSS [training: 0.4290434750874194 | validation: 0.41109411948352004]
	TIME [epoch: 10.3 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45401575552713336		[learning rate: 0.0046587]
	Learning Rate: 0.00465872
	LOSS [training: 0.45401575552713336 | validation: 0.562973705543725]
	TIME [epoch: 10.3 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355056570502915		[learning rate: 0.0046444]
	Learning Rate: 0.00464444
	LOSS [training: 0.6355056570502915 | validation: 0.3841026882437216]
	TIME [epoch: 10.3 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4251040536323809		[learning rate: 0.0046302]
	Learning Rate: 0.0046302
	LOSS [training: 0.4251040536323809 | validation: 0.4423372600836359]
	TIME [epoch: 10.3 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44010382154166816		[learning rate: 0.004616]
	Learning Rate: 0.00461601
	LOSS [training: 0.44010382154166816 | validation: 0.4183063658437108]
	TIME [epoch: 10.3 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4859262851229734		[learning rate: 0.0046019]
	Learning Rate: 0.00460186
	LOSS [training: 0.4859262851229734 | validation: 0.7016659099746011]
	TIME [epoch: 10.3 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0462638738212895		[learning rate: 0.0045878]
	Learning Rate: 0.00458775
	LOSS [training: 1.0462638738212895 | validation: 0.5266956087270924]
	TIME [epoch: 10.3 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5504672231161377		[learning rate: 0.0045737]
	Learning Rate: 0.00457369
	LOSS [training: 0.5504672231161377 | validation: 0.448972879413279]
	TIME [epoch: 10.3 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39260876711775883		[learning rate: 0.0045597]
	Learning Rate: 0.00455967
	LOSS [training: 0.39260876711775883 | validation: 0.3967012121968286]
	TIME [epoch: 10.3 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3510830867080387		[learning rate: 0.0045457]
	Learning Rate: 0.00454569
	LOSS [training: 0.3510830867080387 | validation: 0.31450001206309824]
	TIME [epoch: 10.3 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35870509017962166		[learning rate: 0.0045318]
	Learning Rate: 0.00453176
	LOSS [training: 0.35870509017962166 | validation: 0.34167366897125173]
	TIME [epoch: 10.3 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.321022473427604		[learning rate: 0.0045179]
	Learning Rate: 0.00451787
	LOSS [training: 0.321022473427604 | validation: 0.6730683805306994]
	TIME [epoch: 10.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5825965633446476		[learning rate: 0.004504]
	Learning Rate: 0.00450402
	LOSS [training: 0.5825965633446476 | validation: 0.6843888307690914]
	TIME [epoch: 10.3 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47741923317471036		[learning rate: 0.0044902]
	Learning Rate: 0.00449021
	LOSS [training: 0.47741923317471036 | validation: 0.39894421017403053]
	TIME [epoch: 10.3 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4150147801334808		[learning rate: 0.0044764]
	Learning Rate: 0.00447645
	LOSS [training: 0.4150147801334808 | validation: 0.3151074216045868]
	TIME [epoch: 10.3 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30969565084091066		[learning rate: 0.0044627]
	Learning Rate: 0.00446272
	LOSS [training: 0.30969565084091066 | validation: 0.3725695986676798]
	TIME [epoch: 10.3 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3114212264577247		[learning rate: 0.004449]
	Learning Rate: 0.00444904
	LOSS [training: 0.3114212264577247 | validation: 0.3198400366459528]
	TIME [epoch: 10.3 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3602415802486886		[learning rate: 0.0044354]
	Learning Rate: 0.0044354
	LOSS [training: 0.3602415802486886 | validation: 0.3474570232733181]
	TIME [epoch: 10.3 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3231906262936956		[learning rate: 0.0044218]
	Learning Rate: 0.00442181
	LOSS [training: 0.3231906262936956 | validation: 0.31618574880050415]
	TIME [epoch: 10.3 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45758118639955214		[learning rate: 0.0044083]
	Learning Rate: 0.00440825
	LOSS [training: 0.45758118639955214 | validation: 0.4244531835369355]
	TIME [epoch: 10.3 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36431882236310204		[learning rate: 0.0043947]
	Learning Rate: 0.00439474
	LOSS [training: 0.36431882236310204 | validation: 0.4186870060265163]
	TIME [epoch: 10.3 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48380528899016684		[learning rate: 0.0043813]
	Learning Rate: 0.00438127
	LOSS [training: 0.48380528899016684 | validation: 0.4311822853189625]
	TIME [epoch: 10.3 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3922026569867867		[learning rate: 0.0043678]
	Learning Rate: 0.00436784
	LOSS [training: 0.3922026569867867 | validation: 0.4241260259866688]
	TIME [epoch: 10.3 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.393379281307577		[learning rate: 0.0043544]
	Learning Rate: 0.00435445
	LOSS [training: 0.393379281307577 | validation: 0.4400123598561865]
	TIME [epoch: 10.3 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38892063514545605		[learning rate: 0.0043411]
	Learning Rate: 0.0043411
	LOSS [training: 0.38892063514545605 | validation: 0.38217376260731756]
	TIME [epoch: 10.3 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30018306791654437		[learning rate: 0.0043278]
	Learning Rate: 0.0043278
	LOSS [training: 0.30018306791654437 | validation: 0.5637727885083844]
	TIME [epoch: 10.3 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7663571401700753		[learning rate: 0.0043145]
	Learning Rate: 0.00431453
	LOSS [training: 0.7663571401700753 | validation: 0.4530819149811272]
	TIME [epoch: 10.3 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41794909777967454		[learning rate: 0.0043013]
	Learning Rate: 0.0043013
	LOSS [training: 0.41794909777967454 | validation: 0.4303887568546928]
	TIME [epoch: 10.3 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3868057715860288		[learning rate: 0.0042881]
	Learning Rate: 0.00428812
	LOSS [training: 0.3868057715860288 | validation: 0.37632213051677615]
	TIME [epoch: 10.3 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3323625067640439		[learning rate: 0.004275]
	Learning Rate: 0.00427497
	LOSS [training: 0.3323625067640439 | validation: 0.3373047251037126]
	TIME [epoch: 10.3 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34992507375959625		[learning rate: 0.0042619]
	Learning Rate: 0.00426187
	LOSS [training: 0.34992507375959625 | validation: 0.8204261495174945]
	TIME [epoch: 10.3 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5631130580631558		[learning rate: 0.0042488]
	Learning Rate: 0.0042488
	LOSS [training: 0.5631130580631558 | validation: 0.33556884917660074]
	TIME [epoch: 10.3 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31878903812276516		[learning rate: 0.0042358]
	Learning Rate: 0.00423578
	LOSS [training: 0.31878903812276516 | validation: 0.38307265166321464]
	TIME [epoch: 10.3 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3541553714753345		[learning rate: 0.0042228]
	Learning Rate: 0.00422279
	LOSS [training: 0.3541553714753345 | validation: 0.3703160945259738]
	TIME [epoch: 10.3 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42124887276943845		[learning rate: 0.0042098]
	Learning Rate: 0.00420985
	LOSS [training: 0.42124887276943845 | validation: 0.4314922172613691]
	TIME [epoch: 10.3 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33502521167887217		[learning rate: 0.0041969]
	Learning Rate: 0.00419695
	LOSS [training: 0.33502521167887217 | validation: 0.3243512949013811]
	TIME [epoch: 10.3 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3184173964029892		[learning rate: 0.0041841]
	Learning Rate: 0.00418408
	LOSS [training: 0.3184173964029892 | validation: 0.4521107712477901]
	TIME [epoch: 10.3 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39233165111417745		[learning rate: 0.0041713]
	Learning Rate: 0.00417125
	LOSS [training: 0.39233165111417745 | validation: 0.35883409863986687]
	TIME [epoch: 10.3 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3710849675645429		[learning rate: 0.0041585]
	Learning Rate: 0.00415847
	LOSS [training: 0.3710849675645429 | validation: 0.3540453860519264]
	TIME [epoch: 10.3 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3982456258448814		[learning rate: 0.0041457]
	Learning Rate: 0.00414572
	LOSS [training: 0.3982456258448814 | validation: 0.432851145243974]
	TIME [epoch: 10.3 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3258948092090499		[learning rate: 0.004133]
	Learning Rate: 0.00413301
	LOSS [training: 0.3258948092090499 | validation: 0.30537575969620256]
	TIME [epoch: 10.3 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42160704043796854		[learning rate: 0.0041203]
	Learning Rate: 0.00412034
	LOSS [training: 0.42160704043796854 | validation: 0.44324325742373183]
	TIME [epoch: 10.3 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3500436319121824		[learning rate: 0.0041077]
	Learning Rate: 0.00410771
	LOSS [training: 0.3500436319121824 | validation: 0.6520509149195187]
	TIME [epoch: 10.3 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4336392986775531		[learning rate: 0.0040951]
	Learning Rate: 0.00409512
	LOSS [training: 0.4336392986775531 | validation: 0.39239184483082534]
	TIME [epoch: 10.3 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44283252477451185		[learning rate: 0.0040826]
	Learning Rate: 0.00408257
	LOSS [training: 0.44283252477451185 | validation: 0.5196052764259097]
	TIME [epoch: 10.3 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39949820570454103		[learning rate: 0.0040701]
	Learning Rate: 0.00407005
	LOSS [training: 0.39949820570454103 | validation: 0.4351301065804849]
	TIME [epoch: 10.3 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.339138353097732		[learning rate: 0.0040576]
	Learning Rate: 0.00405758
	LOSS [training: 0.339138353097732 | validation: 0.3721164558632695]
	TIME [epoch: 10.3 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3310613507367698		[learning rate: 0.0040451]
	Learning Rate: 0.00404514
	LOSS [training: 0.3310613507367698 | validation: 0.5819538657896984]
	TIME [epoch: 10.3 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6698267763985523		[learning rate: 0.0040327]
	Learning Rate: 0.00403274
	LOSS [training: 0.6698267763985523 | validation: 0.5076826296532377]
	TIME [epoch: 10.3 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4428939826063155		[learning rate: 0.0040204]
	Learning Rate: 0.00402038
	LOSS [training: 0.4428939826063155 | validation: 0.5704049705598151]
	TIME [epoch: 10.3 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44575627094352444		[learning rate: 0.0040081]
	Learning Rate: 0.00400805
	LOSS [training: 0.44575627094352444 | validation: 0.3237693467907632]
	TIME [epoch: 10.3 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46158162391716007		[learning rate: 0.0039958]
	Learning Rate: 0.00399577
	LOSS [training: 0.46158162391716007 | validation: 0.45339870021160245]
	TIME [epoch: 10.3 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4732820550203864		[learning rate: 0.0039835]
	Learning Rate: 0.00398352
	LOSS [training: 0.4732820550203864 | validation: 0.49998780926510505]
	TIME [epoch: 10.3 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4303789907510064		[learning rate: 0.0039713]
	Learning Rate: 0.00397131
	LOSS [training: 0.4303789907510064 | validation: 0.4501477528022717]
	TIME [epoch: 10.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42984730878201266		[learning rate: 0.0039591]
	Learning Rate: 0.00395913
	LOSS [training: 0.42984730878201266 | validation: 0.5777745497717609]
	TIME [epoch: 10.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45121013081212596		[learning rate: 0.003947]
	Learning Rate: 0.003947
	LOSS [training: 0.45121013081212596 | validation: 0.4292217530819278]
	TIME [epoch: 10.3 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43230815476345885		[learning rate: 0.0039349]
	Learning Rate: 0.0039349
	LOSS [training: 0.43230815476345885 | validation: 0.43581838376179804]
	TIME [epoch: 10.3 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38858339715170553		[learning rate: 0.0039228]
	Learning Rate: 0.00392283
	LOSS [training: 0.38858339715170553 | validation: 0.3809396134099397]
	TIME [epoch: 10.3 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3549381220480275		[learning rate: 0.0039108]
	Learning Rate: 0.00391081
	LOSS [training: 0.3549381220480275 | validation: 0.45535077544943164]
	TIME [epoch: 10.3 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37437707651599816		[learning rate: 0.0038988]
	Learning Rate: 0.00389882
	LOSS [training: 0.37437707651599816 | validation: 0.3416954781879272]
	TIME [epoch: 10.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31910248436058025		[learning rate: 0.0038869]
	Learning Rate: 0.00388687
	LOSS [training: 0.31910248436058025 | validation: 0.32881901043031947]
	TIME [epoch: 10.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4739093285376129		[learning rate: 0.003875]
	Learning Rate: 0.00387495
	LOSS [training: 0.4739093285376129 | validation: 0.3942395240514657]
	TIME [epoch: 10.3 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3928404202423997		[learning rate: 0.0038631]
	Learning Rate: 0.00386308
	LOSS [training: 0.3928404202423997 | validation: 0.6385920032701151]
	TIME [epoch: 10.3 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5056595024224992		[learning rate: 0.0038512]
	Learning Rate: 0.00385123
	LOSS [training: 0.5056595024224992 | validation: 0.46857035505573325]
	TIME [epoch: 10.3 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4739708646329328		[learning rate: 0.0038394]
	Learning Rate: 0.00383943
	LOSS [training: 0.4739708646329328 | validation: 0.6492159856732264]
	TIME [epoch: 10.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.472003053723126		[learning rate: 0.0038277]
	Learning Rate: 0.00382766
	LOSS [training: 0.472003053723126 | validation: 0.746136154030709]
	TIME [epoch: 10.3 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5677537279650614		[learning rate: 0.0038159]
	Learning Rate: 0.00381593
	LOSS [training: 0.5677537279650614 | validation: 0.4044527136253797]
	TIME [epoch: 10.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37911592916979087		[learning rate: 0.0038042]
	Learning Rate: 0.00380423
	LOSS [training: 0.37911592916979087 | validation: 0.3640017988591581]
	TIME [epoch: 10.3 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37652127860390217		[learning rate: 0.0037926]
	Learning Rate: 0.00379257
	LOSS [training: 0.37652127860390217 | validation: 0.5140621288891086]
	TIME [epoch: 10.3 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4195501387373614		[learning rate: 0.0037809]
	Learning Rate: 0.00378094
	LOSS [training: 0.4195501387373614 | validation: 0.3533173134621637]
	TIME [epoch: 10.3 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36139471828532627		[learning rate: 0.0037694]
	Learning Rate: 0.00376935
	LOSS [training: 0.36139471828532627 | validation: 0.5899861824619734]
	TIME [epoch: 10.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5021324844564219		[learning rate: 0.0037578]
	Learning Rate: 0.0037578
	LOSS [training: 0.5021324844564219 | validation: 0.5410747137794117]
	TIME [epoch: 10.3 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4243313612610905		[learning rate: 0.0037463]
	Learning Rate: 0.00374628
	LOSS [training: 0.4243313612610905 | validation: 0.3002556754689104]
	TIME [epoch: 10.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8525931402468914		[learning rate: 0.0037348]
	Learning Rate: 0.00373479
	LOSS [training: 0.8525931402468914 | validation: 1.2679928115227628]
	TIME [epoch: 10.3 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6034968785711665		[learning rate: 0.0037233]
	Learning Rate: 0.00372335
	LOSS [training: 0.6034968785711665 | validation: 0.4422015360364314]
	TIME [epoch: 10.3 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34275398382053035		[learning rate: 0.0037119]
	Learning Rate: 0.00371193
	LOSS [training: 0.34275398382053035 | validation: 0.3520562957040793]
	TIME [epoch: 10.3 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3219616616578382		[learning rate: 0.0037006]
	Learning Rate: 0.00370055
	LOSS [training: 0.3219616616578382 | validation: 0.3320522031377544]
	TIME [epoch: 10.3 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37381969372688084		[learning rate: 0.0036892]
	Learning Rate: 0.00368921
	LOSS [training: 0.37381969372688084 | validation: 0.456305760866964]
	TIME [epoch: 10.3 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3673614308927964		[learning rate: 0.0036779]
	Learning Rate: 0.0036779
	LOSS [training: 0.3673614308927964 | validation: 0.37535614937046924]
	TIME [epoch: 10.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3719809758699632		[learning rate: 0.0036666]
	Learning Rate: 0.00366663
	LOSS [training: 0.3719809758699632 | validation: 0.41538897907307554]
	TIME [epoch: 10.3 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182411938230534		[learning rate: 0.0036554]
	Learning Rate: 0.00365539
	LOSS [training: 0.4182411938230534 | validation: 0.3980505851755475]
	TIME [epoch: 10.3 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4260681578476432		[learning rate: 0.0036442]
	Learning Rate: 0.00364418
	LOSS [training: 0.4260681578476432 | validation: 0.4418046625370633]
	TIME [epoch: 10.3 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41399164195886157		[learning rate: 0.003633]
	Learning Rate: 0.00363301
	LOSS [training: 0.41399164195886157 | validation: 0.3820952972332827]
	TIME [epoch: 10.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3690706931436204		[learning rate: 0.0036219]
	Learning Rate: 0.00362187
	LOSS [training: 0.3690706931436204 | validation: 0.3440374185344895]
	TIME [epoch: 10.3 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3458987621755686		[learning rate: 0.0036108]
	Learning Rate: 0.00361077
	LOSS [training: 0.3458987621755686 | validation: 0.3580155416632742]
	TIME [epoch: 10.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3302930947998254		[learning rate: 0.0035997]
	Learning Rate: 0.0035997
	LOSS [training: 0.3302930947998254 | validation: 0.2875471849836446]
	TIME [epoch: 10.3 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2865147245793209		[learning rate: 0.0035887]
	Learning Rate: 0.00358867
	LOSS [training: 0.2865147245793209 | validation: 0.3030419841233639]
	TIME [epoch: 10.3 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32966606207880655		[learning rate: 0.0035777]
	Learning Rate: 0.00357767
	LOSS [training: 0.32966606207880655 | validation: 0.3936625205562618]
	TIME [epoch: 10.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4159193699474845		[learning rate: 0.0035667]
	Learning Rate: 0.0035667
	LOSS [training: 0.4159193699474845 | validation: 0.3948690211664797]
	TIME [epoch: 10.3 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37216645600856374		[learning rate: 0.0035558]
	Learning Rate: 0.00355577
	LOSS [training: 0.37216645600856374 | validation: 0.32611338531107037]
	TIME [epoch: 10.3 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35996241863273265		[learning rate: 0.0035449]
	Learning Rate: 0.00354487
	LOSS [training: 0.35996241863273265 | validation: 0.4104589890951282]
	TIME [epoch: 10.3 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37064526128422914		[learning rate: 0.003534]
	Learning Rate: 0.003534
	LOSS [training: 0.37064526128422914 | validation: 0.3667058649438475]
	TIME [epoch: 10.3 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35997140591975263		[learning rate: 0.0035232]
	Learning Rate: 0.00352317
	LOSS [training: 0.35997140591975263 | validation: 0.38567310589911574]
	TIME [epoch: 10.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3261039530224358		[learning rate: 0.0035124]
	Learning Rate: 0.00351237
	LOSS [training: 0.3261039530224358 | validation: 0.37636933695320085]
	TIME [epoch: 10.3 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3260253709162308		[learning rate: 0.0035016]
	Learning Rate: 0.0035016
	LOSS [training: 0.3260253709162308 | validation: 0.39470915965625]
	TIME [epoch: 10.3 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33961185341403255		[learning rate: 0.0034909]
	Learning Rate: 0.00349087
	LOSS [training: 0.33961185341403255 | validation: 0.36280557707251165]
	TIME [epoch: 10.3 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4271561131877344		[learning rate: 0.0034802]
	Learning Rate: 0.00348017
	LOSS [training: 0.4271561131877344 | validation: 0.4528607575347314]
	TIME [epoch: 10.3 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40411074412525105		[learning rate: 0.0034695]
	Learning Rate: 0.0034695
	LOSS [training: 0.40411074412525105 | validation: 0.4449400788767675]
	TIME [epoch: 10.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33178710336477246		[learning rate: 0.0034589]
	Learning Rate: 0.00345886
	LOSS [training: 0.33178710336477246 | validation: 0.3261460679691075]
	TIME [epoch: 10.3 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34870336942944147		[learning rate: 0.0034483]
	Learning Rate: 0.00344826
	LOSS [training: 0.34870336942944147 | validation: 0.37668199150458265]
	TIME [epoch: 10.3 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3696204135504705		[learning rate: 0.0034377]
	Learning Rate: 0.00343769
	LOSS [training: 0.3696204135504705 | validation: 0.3816607846508481]
	TIME [epoch: 10.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3658160963002176		[learning rate: 0.0034272]
	Learning Rate: 0.00342715
	LOSS [training: 0.3658160963002176 | validation: 0.39093461854425016]
	TIME [epoch: 10.3 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.372140956381913		[learning rate: 0.0034166]
	Learning Rate: 0.00341665
	LOSS [training: 0.372140956381913 | validation: 0.3418790064383983]
	TIME [epoch: 10.3 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3472382039192654		[learning rate: 0.0034062]
	Learning Rate: 0.00340617
	LOSS [training: 0.3472382039192654 | validation: 0.3946869816402087]
	TIME [epoch: 10.3 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40651133422396224		[learning rate: 0.0033957]
	Learning Rate: 0.00339573
	LOSS [training: 0.40651133422396224 | validation: 0.32663083685028826]
	TIME [epoch: 10.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2995746188401781		[learning rate: 0.0033853]
	Learning Rate: 0.00338532
	LOSS [training: 0.2995746188401781 | validation: 0.30435732969439805]
	TIME [epoch: 10.3 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.290319725034211		[learning rate: 0.0033749]
	Learning Rate: 0.00337494
	LOSS [training: 0.290319725034211 | validation: 0.273007764159598]
	TIME [epoch: 10.3 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28588875686467163		[learning rate: 0.0033646]
	Learning Rate: 0.0033646
	LOSS [training: 0.28588875686467163 | validation: 0.29436949971850795]
	TIME [epoch: 10.3 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2875375347123715		[learning rate: 0.0033543]
	Learning Rate: 0.00335428
	LOSS [training: 0.2875375347123715 | validation: 0.2955313354395909]
	TIME [epoch: 10.3 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2925349007103827		[learning rate: 0.003344]
	Learning Rate: 0.003344
	LOSS [training: 0.2925349007103827 | validation: 0.8101031522898117]
	TIME [epoch: 10.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8210525780558037		[learning rate: 0.0033338]
	Learning Rate: 0.00333375
	LOSS [training: 0.8210525780558037 | validation: 0.6072587385997086]
	TIME [epoch: 10.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.415710077450127		[learning rate: 0.0033235]
	Learning Rate: 0.00332353
	LOSS [training: 0.415710077450127 | validation: 0.6518441477756426]
	TIME [epoch: 10.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45847688631341477		[learning rate: 0.0033133]
	Learning Rate: 0.00331334
	LOSS [training: 0.45847688631341477 | validation: 0.37775274584859075]
	TIME [epoch: 10.3 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27965415755385437		[learning rate: 0.0033032]
	Learning Rate: 0.00330319
	LOSS [training: 0.27965415755385437 | validation: 0.32374677579943395]
	TIME [epoch: 10.3 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32594907094834896		[learning rate: 0.0032931]
	Learning Rate: 0.00329306
	LOSS [training: 0.32594907094834896 | validation: 0.3004627645914524]
	TIME [epoch: 10.3 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3052266778278849		[learning rate: 0.003283]
	Learning Rate: 0.00328297
	LOSS [training: 0.3052266778278849 | validation: 0.3054496149808816]
	TIME [epoch: 10.3 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33993445593906635		[learning rate: 0.0032729]
	Learning Rate: 0.0032729
	LOSS [training: 0.33993445593906635 | validation: 0.3225455194346739]
	TIME [epoch: 10.3 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3037998787753104		[learning rate: 0.0032629]
	Learning Rate: 0.00326287
	LOSS [training: 0.3037998787753104 | validation: 0.30930262952352244]
	TIME [epoch: 10.3 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30572019639268316		[learning rate: 0.0032529]
	Learning Rate: 0.00325287
	LOSS [training: 0.30572019639268316 | validation: 0.43431143610957107]
	TIME [epoch: 10.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3568901911926347		[learning rate: 0.0032429]
	Learning Rate: 0.0032429
	LOSS [training: 0.3568901911926347 | validation: 0.3079883128517448]
	TIME [epoch: 10.3 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2790516195789895		[learning rate: 0.003233]
	Learning Rate: 0.00323296
	LOSS [training: 0.2790516195789895 | validation: 0.27124574306942445]
	TIME [epoch: 10.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2782838109372691		[learning rate: 0.003223]
	Learning Rate: 0.00322305
	LOSS [training: 0.2782838109372691 | validation: 0.31434356900082927]
	TIME [epoch: 10.3 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2989182293609041		[learning rate: 0.0032132]
	Learning Rate: 0.00321317
	LOSS [training: 0.2989182293609041 | validation: 0.3342897780473332]
	TIME [epoch: 10.3 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3157791734578173		[learning rate: 0.0032033]
	Learning Rate: 0.00320332
	LOSS [training: 0.3157791734578173 | validation: 0.35080123176668365]
	TIME [epoch: 10.3 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3427993946336561		[learning rate: 0.0031935]
	Learning Rate: 0.0031935
	LOSS [training: 0.3427993946336561 | validation: 0.34497662060126644]
	TIME [epoch: 10.3 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3389878742488062		[learning rate: 0.0031837]
	Learning Rate: 0.00318371
	LOSS [training: 0.3389878742488062 | validation: 0.2976682158343517]
	TIME [epoch: 10.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27785520174724765		[learning rate: 0.0031739]
	Learning Rate: 0.00317395
	LOSS [training: 0.27785520174724765 | validation: 0.33305373203536365]
	TIME [epoch: 10.3 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2878108120604356		[learning rate: 0.0031642]
	Learning Rate: 0.00316422
	LOSS [training: 0.2878108120604356 | validation: 0.26928249504283985]
	TIME [epoch: 10.3 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922644387733724		[learning rate: 0.0031545]
	Learning Rate: 0.00315452
	LOSS [training: 0.2922644387733724 | validation: 0.39801809316818093]
	TIME [epoch: 10.3 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2976379060039083		[learning rate: 0.0031449]
	Learning Rate: 0.00314485
	LOSS [training: 0.2976379060039083 | validation: 0.3028160675654462]
	TIME [epoch: 10.3 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2785020292334629		[learning rate: 0.0031352]
	Learning Rate: 0.00313521
	LOSS [training: 0.2785020292334629 | validation: 0.5191486638480929]
	TIME [epoch: 10.3 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3600157319577157		[learning rate: 0.0031256]
	Learning Rate: 0.0031256
	LOSS [training: 0.3600157319577157 | validation: 0.3355995263626578]
	TIME [epoch: 10.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2996504036560098		[learning rate: 0.003116]
	Learning Rate: 0.00311602
	LOSS [training: 0.2996504036560098 | validation: 0.3388871811851415]
	TIME [epoch: 10.3 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2685410737059174		[learning rate: 0.0031065]
	Learning Rate: 0.00310647
	LOSS [training: 0.2685410737059174 | validation: 0.31415348080696176]
	TIME [epoch: 10.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2784062431568917		[learning rate: 0.0030969]
	Learning Rate: 0.00309694
	LOSS [training: 0.2784062431568917 | validation: 0.2888247908296824]
	TIME [epoch: 10.3 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2554986901910935		[learning rate: 0.0030875]
	Learning Rate: 0.00308745
	LOSS [training: 0.2554986901910935 | validation: 0.2594318125649248]
	TIME [epoch: 10.3 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2879045951958371		[learning rate: 0.003078]
	Learning Rate: 0.00307799
	LOSS [training: 0.2879045951958371 | validation: 0.3345090922699966]
	TIME [epoch: 10.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32000434204420153		[learning rate: 0.0030686]
	Learning Rate: 0.00306855
	LOSS [training: 0.32000434204420153 | validation: 0.3654510638321257]
	TIME [epoch: 10.3 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4091502670712261		[learning rate: 0.0030591]
	Learning Rate: 0.00305914
	LOSS [training: 0.4091502670712261 | validation: 0.45650991757859366]
	TIME [epoch: 10.3 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39266825479998557		[learning rate: 0.0030498]
	Learning Rate: 0.00304977
	LOSS [training: 0.39266825479998557 | validation: 0.3614728352965483]
	TIME [epoch: 10.3 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3671863923986727		[learning rate: 0.0030404]
	Learning Rate: 0.00304042
	LOSS [training: 0.3671863923986727 | validation: 0.3524390175999585]
	TIME [epoch: 10.3 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3152395435271953		[learning rate: 0.0030311]
	Learning Rate: 0.0030311
	LOSS [training: 0.3152395435271953 | validation: 0.3340853374146323]
	TIME [epoch: 10.3 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3233566680884755		[learning rate: 0.0030218]
	Learning Rate: 0.00302181
	LOSS [training: 0.3233566680884755 | validation: 0.3505412746516497]
	TIME [epoch: 10.3 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.333478887575538		[learning rate: 0.0030125]
	Learning Rate: 0.00301254
	LOSS [training: 0.333478887575538 | validation: 0.38908116442564555]
	TIME [epoch: 10.3 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3399076504391597		[learning rate: 0.0030033]
	Learning Rate: 0.00300331
	LOSS [training: 0.3399076504391597 | validation: 0.33117636786231003]
	TIME [epoch: 10.3 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2970640310213537		[learning rate: 0.0029941]
	Learning Rate: 0.0029941
	LOSS [training: 0.2970640310213537 | validation: 0.31136921676477414]
	TIME [epoch: 10.3 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28570812513816446		[learning rate: 0.0029849]
	Learning Rate: 0.00298492
	LOSS [training: 0.28570812513816446 | validation: 0.3144439027731295]
	TIME [epoch: 10.3 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30302576426662553		[learning rate: 0.0029758]
	Learning Rate: 0.00297577
	LOSS [training: 0.30302576426662553 | validation: 0.35379253342112804]
	TIME [epoch: 10.3 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3125815024613863		[learning rate: 0.0029667]
	Learning Rate: 0.00296665
	LOSS [training: 0.3125815024613863 | validation: 0.3119407948013664]
	TIME [epoch: 10.3 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3180181585170033		[learning rate: 0.0029576]
	Learning Rate: 0.00295756
	LOSS [training: 0.3180181585170033 | validation: 0.31708521923661115]
	TIME [epoch: 10.3 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2827932119364059		[learning rate: 0.0029485]
	Learning Rate: 0.00294849
	LOSS [training: 0.2827932119364059 | validation: 0.3467133982802323]
	TIME [epoch: 10.3 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3890516893233086		[learning rate: 0.0029395]
	Learning Rate: 0.00293945
	LOSS [training: 0.3890516893233086 | validation: 0.3207491654784772]
	TIME [epoch: 10.3 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26998448995489943		[learning rate: 0.0029304]
	Learning Rate: 0.00293044
	LOSS [training: 0.26998448995489943 | validation: 0.3086242746156135]
	TIME [epoch: 10.3 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2793841870081322		[learning rate: 0.0029215]
	Learning Rate: 0.00292146
	LOSS [training: 0.2793841870081322 | validation: 0.3440599589242791]
	TIME [epoch: 10.3 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30847394614532453		[learning rate: 0.0029125]
	Learning Rate: 0.0029125
	LOSS [training: 0.30847394614532453 | validation: 0.8729450601657915]
	TIME [epoch: 10.3 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.522067015131727		[learning rate: 0.0029036]
	Learning Rate: 0.00290358
	LOSS [training: 0.522067015131727 | validation: 0.4129844100797344]
	TIME [epoch: 10.3 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3218958381639834		[learning rate: 0.0028947]
	Learning Rate: 0.00289468
	LOSS [training: 0.3218958381639834 | validation: 0.3017172998476995]
	TIME [epoch: 10.3 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2827147574847761		[learning rate: 0.0028858]
	Learning Rate: 0.0028858
	LOSS [training: 0.2827147574847761 | validation: 0.3123350649673863]
	TIME [epoch: 10.3 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.281616036369782		[learning rate: 0.002877]
	Learning Rate: 0.00287696
	LOSS [training: 0.281616036369782 | validation: 0.30512691757848787]
	TIME [epoch: 10.3 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2880394875391282		[learning rate: 0.0028681]
	Learning Rate: 0.00286814
	LOSS [training: 0.2880394875391282 | validation: 0.5066657820848315]
	TIME [epoch: 10.3 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7881006367437557		[learning rate: 0.0028593]
	Learning Rate: 0.00285935
	LOSS [training: 0.7881006367437557 | validation: 0.6180517696392817]
	TIME [epoch: 10.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42248152808231315		[learning rate: 0.0028506]
	Learning Rate: 0.00285058
	LOSS [training: 0.42248152808231315 | validation: 0.4448331589415952]
	TIME [epoch: 10.3 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33589061872930803		[learning rate: 0.0028418]
	Learning Rate: 0.00284184
	LOSS [training: 0.33589061872930803 | validation: 0.4781238928361042]
	TIME [epoch: 10.3 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31109087034394795		[learning rate: 0.0028331]
	Learning Rate: 0.00283313
	LOSS [training: 0.31109087034394795 | validation: 0.42590188193601275]
	TIME [epoch: 10.3 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46296547571408186		[learning rate: 0.0028244]
	Learning Rate: 0.00282445
	LOSS [training: 0.46296547571408186 | validation: 0.4068730438723253]
	TIME [epoch: 10.3 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2986440079025935		[learning rate: 0.0028158]
	Learning Rate: 0.00281579
	LOSS [training: 0.2986440079025935 | validation: 0.2938197169011825]
	TIME [epoch: 10.3 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2798259110575942		[learning rate: 0.0028072]
	Learning Rate: 0.00280716
	LOSS [training: 0.2798259110575942 | validation: 0.3170965669853718]
	TIME [epoch: 10.3 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38818651391085635		[learning rate: 0.0027986]
	Learning Rate: 0.00279855
	LOSS [training: 0.38818651391085635 | validation: 0.3641777915481284]
	TIME [epoch: 10.3 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37009078680583246		[learning rate: 0.00279]
	Learning Rate: 0.00278997
	LOSS [training: 0.37009078680583246 | validation: 0.34716742018831226]
	TIME [epoch: 10.3 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4532999930544652		[learning rate: 0.0027814]
	Learning Rate: 0.00278142
	LOSS [training: 0.4532999930544652 | validation: 0.2794501744989781]
	TIME [epoch: 10.3 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34018874239484415		[learning rate: 0.0027729]
	Learning Rate: 0.00277289
	LOSS [training: 0.34018874239484415 | validation: 0.40650908765863153]
	TIME [epoch: 10.3 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4365613572922619		[learning rate: 0.0027644]
	Learning Rate: 0.00276439
	LOSS [training: 0.4365613572922619 | validation: 0.5341603902115807]
	TIME [epoch: 10.3 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7702649214605672		[learning rate: 0.0027559]
	Learning Rate: 0.00275592
	LOSS [training: 0.7702649214605672 | validation: 0.6699883037671813]
	TIME [epoch: 10.3 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5311997775643891		[learning rate: 0.0027475]
	Learning Rate: 0.00274747
	LOSS [training: 0.5311997775643891 | validation: 0.44159275705580203]
	TIME [epoch: 10.3 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49520597398105526		[learning rate: 0.002739]
	Learning Rate: 0.00273905
	LOSS [training: 0.49520597398105526 | validation: 0.5436980580769089]
	TIME [epoch: 10.3 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43161156756839547		[learning rate: 0.0027307]
	Learning Rate: 0.00273065
	LOSS [training: 0.43161156756839547 | validation: 0.32568206009542033]
	TIME [epoch: 10.3 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.348606793141057		[learning rate: 0.0027223]
	Learning Rate: 0.00272228
	LOSS [training: 0.348606793141057 | validation: 0.3895201562510188]
	TIME [epoch: 10.3 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3563406372759587		[learning rate: 0.0027139]
	Learning Rate: 0.00271394
	LOSS [training: 0.3563406372759587 | validation: 0.4158105973421254]
	TIME [epoch: 10.3 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7554924936312343		[learning rate: 0.0027056]
	Learning Rate: 0.00270562
	LOSS [training: 0.7554924936312343 | validation: 1.0031697718492125]
	TIME [epoch: 10.3 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8665955181940177		[learning rate: 0.0026973]
	Learning Rate: 0.00269733
	LOSS [training: 0.8665955181940177 | validation: 0.6287379944943516]
	TIME [epoch: 10.3 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5572911446037153		[learning rate: 0.0026891]
	Learning Rate: 0.00268906
	LOSS [training: 0.5572911446037153 | validation: 0.5332994987624857]
	TIME [epoch: 10.3 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344241578325659		[learning rate: 0.0026808]
	Learning Rate: 0.00268081
	LOSS [training: 0.5344241578325659 | validation: 0.4943400019560093]
	TIME [epoch: 10.3 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5110844486887955		[learning rate: 0.0026726]
	Learning Rate: 0.0026726
	LOSS [training: 0.5110844486887955 | validation: 0.5071107832415065]
	TIME [epoch: 10.3 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5928194172257543		[learning rate: 0.0026644]
	Learning Rate: 0.0026644
	LOSS [training: 0.5928194172257543 | validation: 0.7383864837240895]
	TIME [epoch: 10.3 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8243623564721487		[learning rate: 0.0026562]
	Learning Rate: 0.00265624
	LOSS [training: 0.8243623564721487 | validation: 0.4805990306766119]
	TIME [epoch: 10.3 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.504971664722456		[learning rate: 0.0026481]
	Learning Rate: 0.00264809
	LOSS [training: 0.504971664722456 | validation: 0.5915887651531841]
	TIME [epoch: 10.3 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4726222314932319		[learning rate: 0.00264]
	Learning Rate: 0.00263998
	LOSS [training: 0.4726222314932319 | validation: 0.3774800607430793]
	TIME [epoch: 10.3 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4340324556033031		[learning rate: 0.0026319]
	Learning Rate: 0.00263188
	LOSS [training: 0.4340324556033031 | validation: 0.43249001750759347]
	TIME [epoch: 10.3 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48032269843979253		[learning rate: 0.0026238]
	Learning Rate: 0.00262382
	LOSS [training: 0.48032269843979253 | validation: 0.6591298266468713]
	TIME [epoch: 10.3 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.581499257931834		[learning rate: 0.0026158]
	Learning Rate: 0.00261577
	LOSS [training: 0.581499257931834 | validation: 0.38403410358472956]
	TIME [epoch: 10.3 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3567931156492278		[learning rate: 0.0026078]
	Learning Rate: 0.00260775
	LOSS [training: 0.3567931156492278 | validation: 0.33555339743931983]
	TIME [epoch: 10.3 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3377022290546829		[learning rate: 0.0025998]
	Learning Rate: 0.00259976
	LOSS [training: 0.3377022290546829 | validation: 0.35572167470330485]
	TIME [epoch: 10.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35603732975700136		[learning rate: 0.0025918]
	Learning Rate: 0.00259179
	LOSS [training: 0.35603732975700136 | validation: 0.347918718583491]
	TIME [epoch: 10.3 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.364353963135993		[learning rate: 0.0025838]
	Learning Rate: 0.00258385
	LOSS [training: 0.364353963135993 | validation: 0.35874368588721156]
	TIME [epoch: 10.3 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30854311930307404		[learning rate: 0.0025759]
	Learning Rate: 0.00257593
	LOSS [training: 0.30854311930307404 | validation: 0.29104504418223515]
	TIME [epoch: 10.3 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29281877353773933		[learning rate: 0.002568]
	Learning Rate: 0.00256803
	LOSS [training: 0.29281877353773933 | validation: 0.3005685814852452]
	TIME [epoch: 10.3 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2586916288035263		[learning rate: 0.0025602]
	Learning Rate: 0.00256016
	LOSS [training: 0.2586916288035263 | validation: 0.27108350571813156]
	TIME [epoch: 10.3 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.271939541803294		[learning rate: 0.0025523]
	Learning Rate: 0.00255231
	LOSS [training: 0.271939541803294 | validation: 0.33331964368643496]
	TIME [epoch: 10.3 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32791686614888843		[learning rate: 0.0025445]
	Learning Rate: 0.00254449
	LOSS [training: 0.32791686614888843 | validation: 0.32700936718296236]
	TIME [epoch: 10.3 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26558313713657233		[learning rate: 0.0025367]
	Learning Rate: 0.00253669
	LOSS [training: 0.26558313713657233 | validation: 0.2592536411842497]
	TIME [epoch: 10.3 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23875112638241855		[learning rate: 0.0025289]
	Learning Rate: 0.00252891
	LOSS [training: 0.23875112638241855 | validation: 0.311564963493466]
	TIME [epoch: 10.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2507899696347311		[learning rate: 0.0025212]
	Learning Rate: 0.00252116
	LOSS [training: 0.2507899696347311 | validation: 0.26522049745232784]
	TIME [epoch: 10.3 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2261170983727804		[learning rate: 0.0025134]
	Learning Rate: 0.00251343
	LOSS [training: 0.2261170983727804 | validation: 0.2568864446493343]
	TIME [epoch: 10.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2424755433328305		[learning rate: 0.0025057]
	Learning Rate: 0.00250572
	LOSS [training: 0.2424755433328305 | validation: 0.24257964303394866]
	TIME [epoch: 10.3 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25277169669879285		[learning rate: 0.002498]
	Learning Rate: 0.00249804
	LOSS [training: 0.25277169669879285 | validation: 0.2697454450032223]
	TIME [epoch: 10.3 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25618933821436257		[learning rate: 0.0024904]
	Learning Rate: 0.00249039
	LOSS [training: 0.25618933821436257 | validation: 0.5117201953677583]
	TIME [epoch: 10.3 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35536656264684374		[learning rate: 0.0024828]
	Learning Rate: 0.00248275
	LOSS [training: 0.35536656264684374 | validation: 0.26412775842869324]
	TIME [epoch: 10.3 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2393152266188514		[learning rate: 0.0024751]
	Learning Rate: 0.00247514
	LOSS [training: 0.2393152266188514 | validation: 0.2266678384465935]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_955.pth
	Model improved!!!
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2338966725206693		[learning rate: 0.0024676]
	Learning Rate: 0.00246755
	LOSS [training: 0.2338966725206693 | validation: 0.24882318001954726]
	TIME [epoch: 10.3 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2523105715978882		[learning rate: 0.00246]
	Learning Rate: 0.00245999
	LOSS [training: 0.2523105715978882 | validation: 0.43723932105321794]
	TIME [epoch: 10.3 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4485125423013942		[learning rate: 0.0024524]
	Learning Rate: 0.00245245
	LOSS [training: 0.4485125423013942 | validation: 0.2804285124906752]
	TIME [epoch: 10.3 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3209624513771575		[learning rate: 0.0024449]
	Learning Rate: 0.00244493
	LOSS [training: 0.3209624513771575 | validation: 0.3694838671444218]
	TIME [epoch: 10.3 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3507172964379136		[learning rate: 0.0024374]
	Learning Rate: 0.00243744
	LOSS [training: 0.3507172964379136 | validation: 0.4522429371784473]
	TIME [epoch: 10.3 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30097995782099485		[learning rate: 0.00243]
	Learning Rate: 0.00242996
	LOSS [training: 0.30097995782099485 | validation: 0.2612396800150308]
	TIME [epoch: 10.3 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22001057286132775		[learning rate: 0.0024225]
	Learning Rate: 0.00242252
	LOSS [training: 0.22001057286132775 | validation: 0.3975715335834634]
	TIME [epoch: 10.3 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3314010229051428		[learning rate: 0.0024151]
	Learning Rate: 0.00241509
	LOSS [training: 0.3314010229051428 | validation: 0.36083755992758776]
	TIME [epoch: 10.3 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4023690567421189		[learning rate: 0.0024077]
	Learning Rate: 0.00240769
	LOSS [training: 0.4023690567421189 | validation: 0.3778135587962798]
	TIME [epoch: 10.3 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35222588105538405		[learning rate: 0.0024003]
	Learning Rate: 0.00240031
	LOSS [training: 0.35222588105538405 | validation: 0.3487212021721494]
	TIME [epoch: 10.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34386640621535475		[learning rate: 0.0023929]
	Learning Rate: 0.00239295
	LOSS [training: 0.34386640621535475 | validation: 0.317962679272425]
	TIME [epoch: 10.3 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47622181625038573		[learning rate: 0.0023856]
	Learning Rate: 0.00238561
	LOSS [training: 0.47622181625038573 | validation: 0.7065272418960341]
	TIME [epoch: 10.3 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5258887682070985		[learning rate: 0.0023783]
	Learning Rate: 0.0023783
	LOSS [training: 0.5258887682070985 | validation: 0.7281693658654698]
	TIME [epoch: 10.3 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6636124833730651		[learning rate: 0.002371]
	Learning Rate: 0.00237101
	LOSS [training: 0.6636124833730651 | validation: 0.7689729977863852]
	TIME [epoch: 10.3 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4368304755922175		[learning rate: 0.0023637]
	Learning Rate: 0.00236374
	LOSS [training: 0.4368304755922175 | validation: 0.4269532026851911]
	TIME [epoch: 10.3 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35012705390753407		[learning rate: 0.0023565]
	Learning Rate: 0.0023565
	LOSS [training: 0.35012705390753407 | validation: 0.4968523368960743]
	TIME [epoch: 10.3 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4592381351288721		[learning rate: 0.0023493]
	Learning Rate: 0.00234927
	LOSS [training: 0.4592381351288721 | validation: 0.27347404609969855]
	TIME [epoch: 10.3 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30813469505657276		[learning rate: 0.0023421]
	Learning Rate: 0.00234207
	LOSS [training: 0.30813469505657276 | validation: 0.26906340653673555]
	TIME [epoch: 10.3 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.292046312701212		[learning rate: 0.0023349]
	Learning Rate: 0.00233489
	LOSS [training: 0.292046312701212 | validation: 0.32727489849177305]
	TIME [epoch: 10.3 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2850970651533461		[learning rate: 0.0023277]
	Learning Rate: 0.00232773
	LOSS [training: 0.2850970651533461 | validation: 0.2577692165330682]
	TIME [epoch: 10.3 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25790876744956975		[learning rate: 0.0023206]
	Learning Rate: 0.0023206
	LOSS [training: 0.25790876744956975 | validation: 0.31551148422569597]
	TIME [epoch: 10.3 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29803299440682196		[learning rate: 0.0023135]
	Learning Rate: 0.00231348
	LOSS [training: 0.29803299440682196 | validation: 0.29372624089225574]
	TIME [epoch: 10.3 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2854710342095621		[learning rate: 0.0023064]
	Learning Rate: 0.00230639
	LOSS [training: 0.2854710342095621 | validation: 0.30384592975513225]
	TIME [epoch: 10.3 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.297211918335771		[learning rate: 0.0022993]
	Learning Rate: 0.00229932
	LOSS [training: 0.297211918335771 | validation: 0.29880207928353175]
	TIME [epoch: 10.3 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27275157759937846		[learning rate: 0.0022923]
	Learning Rate: 0.00229227
	LOSS [training: 0.27275157759937846 | validation: 0.31797905683033756]
	TIME [epoch: 10.3 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3321716394990824		[learning rate: 0.0022852]
	Learning Rate: 0.00228525
	LOSS [training: 0.3321716394990824 | validation: 0.2943201258602579]
	TIME [epoch: 10.3 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27698152486659294		[learning rate: 0.0022782]
	Learning Rate: 0.00227824
	LOSS [training: 0.27698152486659294 | validation: 0.2838711683403055]
	TIME [epoch: 10.3 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.260548763521003		[learning rate: 0.0022713]
	Learning Rate: 0.00227126
	LOSS [training: 0.260548763521003 | validation: 0.2568754640692422]
	TIME [epoch: 10.3 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24202987686546087		[learning rate: 0.0022643]
	Learning Rate: 0.0022643
	LOSS [training: 0.24202987686546087 | validation: 0.2533828243543536]
	TIME [epoch: 10.3 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24058575142847305		[learning rate: 0.0022574]
	Learning Rate: 0.00225736
	LOSS [training: 0.24058575142847305 | validation: 0.27359700521627517]
	TIME [epoch: 10.3 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26015142734308394		[learning rate: 0.0022504]
	Learning Rate: 0.00225044
	LOSS [training: 0.26015142734308394 | validation: 0.29757380917492265]
	TIME [epoch: 10.3 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26344290156597866		[learning rate: 0.0022435]
	Learning Rate: 0.00224354
	LOSS [training: 0.26344290156597866 | validation: 0.25768665403605306]
	TIME [epoch: 10.3 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2502934767926651		[learning rate: 0.0022367]
	Learning Rate: 0.00223666
	LOSS [training: 0.2502934767926651 | validation: 0.28880577418003633]
	TIME [epoch: 10.3 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2733355703941699		[learning rate: 0.0022298]
	Learning Rate: 0.0022298
	LOSS [training: 0.2733355703941699 | validation: 0.31573676834783526]
	TIME [epoch: 10.3 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33259384325703184		[learning rate: 0.002223]
	Learning Rate: 0.00222297
	LOSS [training: 0.33259384325703184 | validation: 0.29114091208667014]
	TIME [epoch: 10.3 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2857031262641924		[learning rate: 0.0022162]
	Learning Rate: 0.00221615
	LOSS [training: 0.2857031262641924 | validation: 0.5096530961464387]
	TIME [epoch: 10.3 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36543381163538713		[learning rate: 0.0022094]
	Learning Rate: 0.00220936
	LOSS [training: 0.36543381163538713 | validation: 0.33119597379643156]
	TIME [epoch: 10.3 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32593320298604844		[learning rate: 0.0022026]
	Learning Rate: 0.00220259
	LOSS [training: 0.32593320298604844 | validation: 0.2982915134426889]
	TIME [epoch: 10.3 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30729312266113534		[learning rate: 0.0021958]
	Learning Rate: 0.00219584
	LOSS [training: 0.30729312266113534 | validation: 0.296473099546864]
	TIME [epoch: 10.3 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27182231095880754		[learning rate: 0.0021891]
	Learning Rate: 0.00218911
	LOSS [training: 0.27182231095880754 | validation: 0.28136122530341107]
	TIME [epoch: 10.3 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24924604548551504		[learning rate: 0.0021824]
	Learning Rate: 0.00218239
	LOSS [training: 0.24924604548551504 | validation: 0.28503139343235245]
	TIME [epoch: 10.6 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2514232023081338		[learning rate: 0.0021757]
	Learning Rate: 0.00217571
	LOSS [training: 0.2514232023081338 | validation: 0.3623298902055646]
	TIME [epoch: 10.3 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29759512347452993		[learning rate: 0.002169]
	Learning Rate: 0.00216904
	LOSS [training: 0.29759512347452993 | validation: 0.3215090346298816]
	TIME [epoch: 10.3 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31309010472941967		[learning rate: 0.0021624]
	Learning Rate: 0.00216239
	LOSS [training: 0.31309010472941967 | validation: 0.3116483122068233]
	TIME [epoch: 10.3 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28445997194720346		[learning rate: 0.0021558]
	Learning Rate: 0.00215576
	LOSS [training: 0.28445997194720346 | validation: 0.2904228681793433]
	TIME [epoch: 10.3 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2812932725721312		[learning rate: 0.0021491]
	Learning Rate: 0.00214915
	LOSS [training: 0.2812932725721312 | validation: 0.2658328981821259]
	TIME [epoch: 10.3 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26404799025708653		[learning rate: 0.0021426]
	Learning Rate: 0.00214256
	LOSS [training: 0.26404799025708653 | validation: 0.33433228583161856]
	TIME [epoch: 10.3 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29666694973076757		[learning rate: 0.002136]
	Learning Rate: 0.00213599
	LOSS [training: 0.29666694973076757 | validation: 0.28847516017630304]
	TIME [epoch: 10.3 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25276409461841504		[learning rate: 0.0021294]
	Learning Rate: 0.00212945
	LOSS [training: 0.25276409461841504 | validation: 0.30143208527205384]
	TIME [epoch: 10.3 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2504791405394744		[learning rate: 0.0021229]
	Learning Rate: 0.00212292
	LOSS [training: 0.2504791405394744 | validation: 0.24608271475812665]
	TIME [epoch: 10.3 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23786664712418534		[learning rate: 0.0021164]
	Learning Rate: 0.00211641
	LOSS [training: 0.23786664712418534 | validation: 0.24346220893208576]
	TIME [epoch: 10.3 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2360643096900128		[learning rate: 0.0021099]
	Learning Rate: 0.00210992
	LOSS [training: 0.2360643096900128 | validation: 0.24804264284991712]
	TIME [epoch: 10.3 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26452568549626504		[learning rate: 0.0021035]
	Learning Rate: 0.00210346
	LOSS [training: 0.26452568549626504 | validation: 0.37680802607584823]
	TIME [epoch: 10.3 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29316444315990514		[learning rate: 0.002097]
	Learning Rate: 0.00209701
	LOSS [training: 0.29316444315990514 | validation: 0.3971601705207445]
	TIME [epoch: 10.3 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41186817140718956		[learning rate: 0.0020906]
	Learning Rate: 0.00209058
	LOSS [training: 0.41186817140718956 | validation: 0.3147636669429022]
	TIME [epoch: 10.3 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29861583214223103		[learning rate: 0.0020842]
	Learning Rate: 0.00208417
	LOSS [training: 0.29861583214223103 | validation: 0.2870828645838]
	TIME [epoch: 10.3 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30208240633748706		[learning rate: 0.0020778]
	Learning Rate: 0.00207778
	LOSS [training: 0.30208240633748706 | validation: 0.25454138737207016]
	TIME [epoch: 10.3 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3088079101709929		[learning rate: 0.0020714]
	Learning Rate: 0.00207141
	LOSS [training: 0.3088079101709929 | validation: 0.3309725192736586]
	TIME [epoch: 10.3 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2918221049220727		[learning rate: 0.0020651]
	Learning Rate: 0.00206506
	LOSS [training: 0.2918221049220727 | validation: 0.30061855721697633]
	TIME [epoch: 10.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27359514729592654		[learning rate: 0.0020587]
	Learning Rate: 0.00205873
	LOSS [training: 0.27359514729592654 | validation: 0.27157242944705967]
	TIME [epoch: 10.3 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2538826122956098		[learning rate: 0.0020524]
	Learning Rate: 0.00205242
	LOSS [training: 0.2538826122956098 | validation: 0.25704793838019646]
	TIME [epoch: 10.3 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25403135140727906		[learning rate: 0.0020461]
	Learning Rate: 0.00204613
	LOSS [training: 0.25403135140727906 | validation: 0.2415993820221957]
	TIME [epoch: 10.3 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3718978769703736		[learning rate: 0.0020399]
	Learning Rate: 0.00203986
	LOSS [training: 0.3718978769703736 | validation: 0.40334046735242374]
	TIME [epoch: 10.3 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2636282008530091		[learning rate: 0.0020336]
	Learning Rate: 0.00203361
	LOSS [training: 0.2636282008530091 | validation: 0.25223242376630167]
	TIME [epoch: 10.3 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2419399905657042		[learning rate: 0.0020274]
	Learning Rate: 0.00202737
	LOSS [training: 0.2419399905657042 | validation: 0.31981538526177034]
	TIME [epoch: 10.3 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2880331365436479		[learning rate: 0.0020212]
	Learning Rate: 0.00202116
	LOSS [training: 0.2880331365436479 | validation: 0.2746642917304349]
	TIME [epoch: 10.3 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24929063023450837		[learning rate: 0.002015]
	Learning Rate: 0.00201496
	LOSS [training: 0.24929063023450837 | validation: 0.25049064241185465]
	TIME [epoch: 10.3 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23747116560640819		[learning rate: 0.0020088]
	Learning Rate: 0.00200878
	LOSS [training: 0.23747116560640819 | validation: 0.24801835868938277]
	TIME [epoch: 10.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2657080922784094		[learning rate: 0.0020026]
	Learning Rate: 0.00200263
	LOSS [training: 0.2657080922784094 | validation: 0.3191445345313059]
	TIME [epoch: 10.3 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3099030529497203		[learning rate: 0.0019965]
	Learning Rate: 0.00199649
	LOSS [training: 0.3099030529497203 | validation: 0.2563445965558664]
	TIME [epoch: 10.3 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2525997492909621		[learning rate: 0.0019904]
	Learning Rate: 0.00199037
	LOSS [training: 0.2525997492909621 | validation: 0.4865518832019694]
	TIME [epoch: 10.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.389854857443926		[learning rate: 0.0019843]
	Learning Rate: 0.00198427
	LOSS [training: 0.389854857443926 | validation: 0.2621602913845434]
	TIME [epoch: 10.3 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2867482067262297		[learning rate: 0.0019782]
	Learning Rate: 0.00197818
	LOSS [training: 0.2867482067262297 | validation: 0.32088573037164564]
	TIME [epoch: 10.3 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2612656024761414		[learning rate: 0.0019721]
	Learning Rate: 0.00197212
	LOSS [training: 0.2612656024761414 | validation: 0.33830502740682183]
	TIME [epoch: 10.3 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30376832882597316		[learning rate: 0.0019661]
	Learning Rate: 0.00196607
	LOSS [training: 0.30376832882597316 | validation: 0.49662134740884184]
	TIME [epoch: 10.3 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168545832119135		[learning rate: 0.00196]
	Learning Rate: 0.00196005
	LOSS [training: 0.3168545832119135 | validation: 0.3686599549695117]
	TIME [epoch: 10.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.280611322634731		[learning rate: 0.001954]
	Learning Rate: 0.00195404
	LOSS [training: 0.280611322634731 | validation: 0.3203914842008207]
	TIME [epoch: 10.3 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35537924686368627		[learning rate: 0.001948]
	Learning Rate: 0.00194805
	LOSS [training: 0.35537924686368627 | validation: 0.564312102396224]
	TIME [epoch: 10.3 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3538662038757195		[learning rate: 0.0019421]
	Learning Rate: 0.00194208
	LOSS [training: 0.3538662038757195 | validation: 0.3270558688243469]
	TIME [epoch: 10.3 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2838942651670443		[learning rate: 0.0019361]
	Learning Rate: 0.00193612
	LOSS [training: 0.2838942651670443 | validation: 0.2632742972151582]
	TIME [epoch: 10.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23798236845200726		[learning rate: 0.0019302]
	Learning Rate: 0.00193019
	LOSS [training: 0.23798236845200726 | validation: 0.2947962827504529]
	TIME [epoch: 10.3 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23935660425929428		[learning rate: 0.0019243]
	Learning Rate: 0.00192427
	LOSS [training: 0.23935660425929428 | validation: 0.31134291964688265]
	TIME [epoch: 10.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2849759205247821		[learning rate: 0.0019184]
	Learning Rate: 0.00191837
	LOSS [training: 0.2849759205247821 | validation: 0.3629067015278142]
	TIME [epoch: 10.3 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30626603675499553		[learning rate: 0.0019125]
	Learning Rate: 0.00191249
	LOSS [training: 0.30626603675499553 | validation: 0.3728727290612893]
	TIME [epoch: 10.3 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29139799115637627		[learning rate: 0.0019066]
	Learning Rate: 0.00190663
	LOSS [training: 0.29139799115637627 | validation: 0.29071373126914196]
	TIME [epoch: 10.3 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2727819257264497		[learning rate: 0.0019008]
	Learning Rate: 0.00190079
	LOSS [training: 0.2727819257264497 | validation: 0.4109184621447157]
	TIME [epoch: 10.3 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3321852926860119		[learning rate: 0.001895]
	Learning Rate: 0.00189496
	LOSS [training: 0.3321852926860119 | validation: 0.3108159424900477]
	TIME [epoch: 10.3 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31061271935542595		[learning rate: 0.0018892]
	Learning Rate: 0.00188915
	LOSS [training: 0.31061271935542595 | validation: 0.4079266841559852]
	TIME [epoch: 10.3 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42467580279771866		[learning rate: 0.0018834]
	Learning Rate: 0.00188336
	LOSS [training: 0.42467580279771866 | validation: 0.3739997775458702]
	TIME [epoch: 10.3 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5361986638938381		[learning rate: 0.0018776]
	Learning Rate: 0.00187759
	LOSS [training: 0.5361986638938381 | validation: 0.513591441968402]
	TIME [epoch: 10.3 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39786414542593607		[learning rate: 0.0018718]
	Learning Rate: 0.00187183
	LOSS [training: 0.39786414542593607 | validation: 0.42327161677765346]
	TIME [epoch: 10.3 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5050396019428508		[learning rate: 0.0018661]
	Learning Rate: 0.00186609
	LOSS [training: 0.5050396019428508 | validation: 0.4525154998551107]
	TIME [epoch: 10.3 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3631685023905386		[learning rate: 0.0018604]
	Learning Rate: 0.00186037
	LOSS [training: 0.3631685023905386 | validation: 0.3070021842511859]
	TIME [epoch: 10.3 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3068632071969752		[learning rate: 0.0018547]
	Learning Rate: 0.00185467
	LOSS [training: 0.3068632071969752 | validation: 0.34574677090508943]
	TIME [epoch: 10.3 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3640302654720094		[learning rate: 0.001849]
	Learning Rate: 0.00184898
	LOSS [training: 0.3640302654720094 | validation: 0.3118346016492133]
	TIME [epoch: 10.3 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28021473911925304		[learning rate: 0.0018433]
	Learning Rate: 0.00184332
	LOSS [training: 0.28021473911925304 | validation: 0.2691650764039192]
	TIME [epoch: 10.3 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2574914048177216		[learning rate: 0.0018377]
	Learning Rate: 0.00183767
	LOSS [training: 0.2574914048177216 | validation: 0.2523454790269733]
	TIME [epoch: 10.3 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25260469749501313		[learning rate: 0.001832]
	Learning Rate: 0.00183203
	LOSS [training: 0.25260469749501313 | validation: 0.2863323623395756]
	TIME [epoch: 10.3 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2494175976392953		[learning rate: 0.0018264]
	Learning Rate: 0.00182642
	LOSS [training: 0.2494175976392953 | validation: 0.2648300333326419]
	TIME [epoch: 10.3 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25648605830474536		[learning rate: 0.0018208]
	Learning Rate: 0.00182082
	LOSS [training: 0.25648605830474536 | validation: 0.3554027763543614]
	TIME [epoch: 10.3 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2888076820027466		[learning rate: 0.0018152]
	Learning Rate: 0.00181524
	LOSS [training: 0.2888076820027466 | validation: 0.2991050632611563]
	TIME [epoch: 10.3 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28913717447102033		[learning rate: 0.0018097]
	Learning Rate: 0.00180967
	LOSS [training: 0.28913717447102033 | validation: 0.2824355792281775]
	TIME [epoch: 10.3 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26888545135040354		[learning rate: 0.0018041]
	Learning Rate: 0.00180412
	LOSS [training: 0.26888545135040354 | validation: 0.3112532475996194]
	TIME [epoch: 10.3 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37269762973363507		[learning rate: 0.0017986]
	Learning Rate: 0.00179859
	LOSS [training: 0.37269762973363507 | validation: 0.38771390858270943]
	TIME [epoch: 10.3 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40304549742565515		[learning rate: 0.0017931]
	Learning Rate: 0.00179308
	LOSS [training: 0.40304549742565515 | validation: 0.35123867670653836]
	TIME [epoch: 10.3 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3353193270584528		[learning rate: 0.0017876]
	Learning Rate: 0.00178758
	LOSS [training: 0.3353193270584528 | validation: 0.32186670572376985]
	TIME [epoch: 10.3 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.346671563481708		[learning rate: 0.0017821]
	Learning Rate: 0.00178211
	LOSS [training: 0.346671563481708 | validation: 0.3518933193908604]
	TIME [epoch: 10.3 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2699799619376022		[learning rate: 0.0017766]
	Learning Rate: 0.00177664
	LOSS [training: 0.2699799619376022 | validation: 0.30037812753297005]
	TIME [epoch: 10.3 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29898748789439217		[learning rate: 0.0017712]
	Learning Rate: 0.0017712
	LOSS [training: 0.29898748789439217 | validation: 0.301782706314451]
	TIME [epoch: 10.3 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31781348642703794		[learning rate: 0.0017658]
	Learning Rate: 0.00176577
	LOSS [training: 0.31781348642703794 | validation: 0.3356911358675738]
	TIME [epoch: 10.3 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40209624058459614		[learning rate: 0.0017604]
	Learning Rate: 0.00176035
	LOSS [training: 0.40209624058459614 | validation: 0.4682071723789103]
	TIME [epoch: 10.3 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4221116599277491		[learning rate: 0.001755]
	Learning Rate: 0.00175496
	LOSS [training: 0.4221116599277491 | validation: 0.34959547055796536]
	TIME [epoch: 10.3 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3297120787920863		[learning rate: 0.0017496]
	Learning Rate: 0.00174958
	LOSS [training: 0.3297120787920863 | validation: 0.27129069821169205]
	TIME [epoch: 10.3 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3240290379605128		[learning rate: 0.0017442]
	Learning Rate: 0.00174421
	LOSS [training: 0.3240290379605128 | validation: 0.3084568463163561]
	TIME [epoch: 10.3 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2820012918642777		[learning rate: 0.0017389]
	Learning Rate: 0.00173887
	LOSS [training: 0.2820012918642777 | validation: 0.2558629626935611]
	TIME [epoch: 10.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2512868189157597		[learning rate: 0.0017335]
	Learning Rate: 0.00173354
	LOSS [training: 0.2512868189157597 | validation: 0.2546046722707119]
	TIME [epoch: 10.3 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2447860915314608		[learning rate: 0.0017282]
	Learning Rate: 0.00172822
	LOSS [training: 0.2447860915314608 | validation: 0.2753176403421443]
	TIME [epoch: 10.3 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29001565807396956		[learning rate: 0.0017229]
	Learning Rate: 0.00172293
	LOSS [training: 0.29001565807396956 | validation: 0.26560539262846267]
	TIME [epoch: 10.3 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2574593019393189		[learning rate: 0.0017176]
	Learning Rate: 0.00171764
	LOSS [training: 0.2574593019393189 | validation: 0.28047345294379866]
	TIME [epoch: 10.3 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28623745284323765		[learning rate: 0.0017124]
	Learning Rate: 0.00171238
	LOSS [training: 0.28623745284323765 | validation: 0.3419024904614927]
	TIME [epoch: 10.3 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30971218400313305		[learning rate: 0.0017071]
	Learning Rate: 0.00170713
	LOSS [training: 0.30971218400313305 | validation: 0.36190767682488156]
	TIME [epoch: 10.3 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33896844137506943		[learning rate: 0.0017019]
	Learning Rate: 0.0017019
	LOSS [training: 0.33896844137506943 | validation: 0.333556537774722]
	TIME [epoch: 10.3 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4283398552332887		[learning rate: 0.0016967]
	Learning Rate: 0.00169668
	LOSS [training: 0.4283398552332887 | validation: 0.4985775597599083]
	TIME [epoch: 10.3 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46068236417091557		[learning rate: 0.0016915]
	Learning Rate: 0.00169148
	LOSS [training: 0.46068236417091557 | validation: 0.3588494963266328]
	TIME [epoch: 10.3 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34579284358922024		[learning rate: 0.0016863]
	Learning Rate: 0.00168629
	LOSS [training: 0.34579284358922024 | validation: 0.3220418324929241]
	TIME [epoch: 10.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34040237780784854		[learning rate: 0.0016811]
	Learning Rate: 0.00168113
	LOSS [training: 0.34040237780784854 | validation: 0.32524117660403756]
	TIME [epoch: 10.3 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3048655009788211		[learning rate: 0.001676]
	Learning Rate: 0.00167597
	LOSS [training: 0.3048655009788211 | validation: 0.3460358298929805]
	TIME [epoch: 10.3 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30117177417214913		[learning rate: 0.0016708]
	Learning Rate: 0.00167083
	LOSS [training: 0.30117177417214913 | validation: 0.307624988571047]
	TIME [epoch: 10.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3550919933449639		[learning rate: 0.0016657]
	Learning Rate: 0.00166571
	LOSS [training: 0.3550919933449639 | validation: 0.32035397467097787]
	TIME [epoch: 10.3 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26168747276474313		[learning rate: 0.0016606]
	Learning Rate: 0.00166061
	LOSS [training: 0.26168747276474313 | validation: 0.2864709234382494]
	TIME [epoch: 10.3 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2557236600473637		[learning rate: 0.0016555]
	Learning Rate: 0.00165552
	LOSS [training: 0.2557236600473637 | validation: 0.28282058195192533]
	TIME [epoch: 10.3 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2629090716548741		[learning rate: 0.0016504]
	Learning Rate: 0.00165044
	LOSS [training: 0.2629090716548741 | validation: 0.2700126997694017]
	TIME [epoch: 10.3 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3098916320839745		[learning rate: 0.0016454]
	Learning Rate: 0.00164538
	LOSS [training: 0.3098916320839745 | validation: 0.2991903102032278]
	TIME [epoch: 10.3 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.277193177420623		[learning rate: 0.0016403]
	Learning Rate: 0.00164034
	LOSS [training: 0.277193177420623 | validation: 0.2616917890089087]
	TIME [epoch: 10.3 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.235312504533359		[learning rate: 0.0016353]
	Learning Rate: 0.00163531
	LOSS [training: 0.235312504533359 | validation: 0.2621957154000545]
	TIME [epoch: 10.3 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24025944102061794		[learning rate: 0.0016303]
	Learning Rate: 0.0016303
	LOSS [training: 0.24025944102061794 | validation: 0.28736199025318226]
	TIME [epoch: 10.3 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29030389995646716		[learning rate: 0.0016253]
	Learning Rate: 0.0016253
	LOSS [training: 0.29030389995646716 | validation: 0.3570334471615312]
	TIME [epoch: 10.3 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30399274819083955		[learning rate: 0.0016203]
	Learning Rate: 0.00162032
	LOSS [training: 0.30399274819083955 | validation: 0.4314984981391787]
	TIME [epoch: 10.3 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35323907691598916		[learning rate: 0.0016154]
	Learning Rate: 0.00161535
	LOSS [training: 0.35323907691598916 | validation: 0.36673357139107227]
	TIME [epoch: 10.3 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3812694325994607		[learning rate: 0.0016104]
	Learning Rate: 0.0016104
	LOSS [training: 0.3812694325994607 | validation: 0.31866337564305974]
	TIME [epoch: 10.3 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29803219492517574		[learning rate: 0.0016055]
	Learning Rate: 0.00160546
	LOSS [training: 0.29803219492517574 | validation: 0.2738998585298615]
	TIME [epoch: 10.3 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2858440803420507		[learning rate: 0.0016005]
	Learning Rate: 0.00160054
	LOSS [training: 0.2858440803420507 | validation: 0.3080866662054283]
	TIME [epoch: 10.3 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3055043736517597		[learning rate: 0.0015956]
	Learning Rate: 0.00159563
	LOSS [training: 0.3055043736517597 | validation: 0.3251583251087277]
	TIME [epoch: 10.3 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29026388635008854		[learning rate: 0.0015907]
	Learning Rate: 0.00159074
	LOSS [training: 0.29026388635008854 | validation: 0.3104999806727337]
	TIME [epoch: 10.3 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27808013705950846		[learning rate: 0.0015859]
	Learning Rate: 0.00158587
	LOSS [training: 0.27808013705950846 | validation: 0.37961675730518474]
	TIME [epoch: 10.3 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3848261818218807		[learning rate: 0.001581]
	Learning Rate: 0.00158101
	LOSS [training: 0.3848261818218807 | validation: 0.3580975405613566]
	TIME [epoch: 10.3 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3079993531239772		[learning rate: 0.0015762]
	Learning Rate: 0.00157616
	LOSS [training: 0.3079993531239772 | validation: 0.27969235986279467]
	TIME [epoch: 10.3 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23008163557973343		[learning rate: 0.0015713]
	Learning Rate: 0.00157133
	LOSS [training: 0.23008163557973343 | validation: 0.23442731230892136]
	TIME [epoch: 10.3 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2264040861979515		[learning rate: 0.0015665]
	Learning Rate: 0.00156651
	LOSS [training: 0.2264040861979515 | validation: 0.34234462677544486]
	TIME [epoch: 10.3 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35698544940092075		[learning rate: 0.0015617]
	Learning Rate: 0.00156171
	LOSS [training: 0.35698544940092075 | validation: 0.3300448259527004]
	TIME [epoch: 10.3 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25444007481857256		[learning rate: 0.0015569]
	Learning Rate: 0.00155692
	LOSS [training: 0.25444007481857256 | validation: 0.27613401957522193]
	TIME [epoch: 10.3 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25144820288849484		[learning rate: 0.0015521]
	Learning Rate: 0.00155215
	LOSS [training: 0.25144820288849484 | validation: 0.43657103041200024]
	TIME [epoch: 10.3 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3027081582722662		[learning rate: 0.0015474]
	Learning Rate: 0.00154739
	LOSS [training: 0.3027081582722662 | validation: 0.26453610537573036]
	TIME [epoch: 10.3 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24687399570383142		[learning rate: 0.0015426]
	Learning Rate: 0.00154265
	LOSS [training: 0.24687399570383142 | validation: 0.2717158432576867]
	TIME [epoch: 10.3 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2505490398905409		[learning rate: 0.0015379]
	Learning Rate: 0.00153792
	LOSS [training: 0.2505490398905409 | validation: 0.26108525702421986]
	TIME [epoch: 10.3 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2840839529583389		[learning rate: 0.0015332]
	Learning Rate: 0.0015332
	LOSS [training: 0.2840839529583389 | validation: 0.3104527389556866]
	TIME [epoch: 10.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29498535665566283		[learning rate: 0.0015285]
	Learning Rate: 0.0015285
	LOSS [training: 0.29498535665566283 | validation: 0.30808712212468187]
	TIME [epoch: 10.3 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27561316369130745		[learning rate: 0.0015238]
	Learning Rate: 0.00152382
	LOSS [training: 0.27561316369130745 | validation: 0.28404475269904345]
	TIME [epoch: 10.3 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.296405877158585		[learning rate: 0.0015191]
	Learning Rate: 0.00151915
	LOSS [training: 0.296405877158585 | validation: 0.3037430511055258]
	TIME [epoch: 10.3 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2841537447883228		[learning rate: 0.0015145]
	Learning Rate: 0.00151449
	LOSS [training: 0.2841537447883228 | validation: 0.3072823278349452]
	TIME [epoch: 10.3 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2772255224185541		[learning rate: 0.0015098]
	Learning Rate: 0.00150985
	LOSS [training: 0.2772255224185541 | validation: 0.2867936892874792]
	TIME [epoch: 10.3 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.327236082127201		[learning rate: 0.0015052]
	Learning Rate: 0.00150522
	LOSS [training: 0.327236082127201 | validation: 0.3607379789887608]
	TIME [epoch: 10.3 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.321808013956661		[learning rate: 0.0015006]
	Learning Rate: 0.00150061
	LOSS [training: 0.321808013956661 | validation: 0.3584646407958566]
	TIME [epoch: 10.3 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29376914120309006		[learning rate: 0.001496]
	Learning Rate: 0.00149601
	LOSS [training: 0.29376914120309006 | validation: 0.2806356221315724]
	TIME [epoch: 10.3 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25136504064258824		[learning rate: 0.0014914]
	Learning Rate: 0.00149142
	LOSS [training: 0.25136504064258824 | validation: 0.2621189980475635]
	TIME [epoch: 10.3 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24598548045042454		[learning rate: 0.0014868]
	Learning Rate: 0.00148685
	LOSS [training: 0.24598548045042454 | validation: 0.2859427456741156]
	TIME [epoch: 10.3 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29555227104613113		[learning rate: 0.0014823]
	Learning Rate: 0.00148229
	LOSS [training: 0.29555227104613113 | validation: 0.2839290362258304]
	TIME [epoch: 10.3 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922465290530716		[learning rate: 0.0014777]
	Learning Rate: 0.00147775
	LOSS [training: 0.2922465290530716 | validation: 0.33203844635589336]
	TIME [epoch: 10.3 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3095962794793389		[learning rate: 0.0014732]
	Learning Rate: 0.00147322
	LOSS [training: 0.3095962794793389 | validation: 0.3085308109815408]
	TIME [epoch: 10.3 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29140670386958956		[learning rate: 0.0014687]
	Learning Rate: 0.0014687
	LOSS [training: 0.29140670386958956 | validation: 0.300974186143891]
	TIME [epoch: 10.3 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26566513203539854		[learning rate: 0.0014642]
	Learning Rate: 0.0014642
	LOSS [training: 0.26566513203539854 | validation: 0.29619025968891516]
	TIME [epoch: 10.3 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2769353790137095		[learning rate: 0.0014597]
	Learning Rate: 0.00145971
	LOSS [training: 0.2769353790137095 | validation: 0.2936983732207461]
	TIME [epoch: 10.3 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2658178976119518		[learning rate: 0.0014552]
	Learning Rate: 0.00145524
	LOSS [training: 0.2658178976119518 | validation: 0.2802639848308371]
	TIME [epoch: 10.3 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2663771820465541		[learning rate: 0.0014508]
	Learning Rate: 0.00145077
	LOSS [training: 0.2663771820465541 | validation: 0.29066297719449147]
	TIME [epoch: 10.3 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2861199663184256		[learning rate: 0.0014463]
	Learning Rate: 0.00144633
	LOSS [training: 0.2861199663184256 | validation: 0.29485211390427524]
	TIME [epoch: 10.3 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2639031514123439		[learning rate: 0.0014419]
	Learning Rate: 0.00144189
	LOSS [training: 0.2639031514123439 | validation: 0.2633260645015889]
	TIME [epoch: 10.3 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25818784341161566		[learning rate: 0.0014375]
	Learning Rate: 0.00143747
	LOSS [training: 0.25818784341161566 | validation: 0.30134507168219615]
	TIME [epoch: 10.3 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29642844457536677		[learning rate: 0.0014331]
	Learning Rate: 0.00143307
	LOSS [training: 0.29642844457536677 | validation: 0.288288919181463]
	TIME [epoch: 10.3 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27304645078017337		[learning rate: 0.0014287]
	Learning Rate: 0.00142867
	LOSS [training: 0.27304645078017337 | validation: 0.29977702349946117]
	TIME [epoch: 10.3 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25085361609423684		[learning rate: 0.0014243]
	Learning Rate: 0.0014243
	LOSS [training: 0.25085361609423684 | validation: 0.2576221805300487]
	TIME [epoch: 10.3 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24985744325363926		[learning rate: 0.0014199]
	Learning Rate: 0.00141993
	LOSS [training: 0.24985744325363926 | validation: 0.2621912605655103]
	TIME [epoch: 10.3 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24365594827868886		[learning rate: 0.0014156]
	Learning Rate: 0.00141558
	LOSS [training: 0.24365594827868886 | validation: 0.2980491786951297]
	TIME [epoch: 10.3 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2613788665178731		[learning rate: 0.0014112]
	Learning Rate: 0.00141124
	LOSS [training: 0.2613788665178731 | validation: 0.24751679278635647]
	TIME [epoch: 10.3 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22727518120555162		[learning rate: 0.0014069]
	Learning Rate: 0.00140691
	LOSS [training: 0.22727518120555162 | validation: 0.3827525969937639]
	TIME [epoch: 10.3 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29731529257606387		[learning rate: 0.0014026]
	Learning Rate: 0.0014026
	LOSS [training: 0.29731529257606387 | validation: 0.3104075741802167]
	TIME [epoch: 10.3 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36328281229211434		[learning rate: 0.0013983]
	Learning Rate: 0.0013983
	LOSS [training: 0.36328281229211434 | validation: 0.3041175215245529]
	TIME [epoch: 10.3 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25315681479085933		[learning rate: 0.001394]
	Learning Rate: 0.00139401
	LOSS [training: 0.25315681479085933 | validation: 0.2796501317716721]
	TIME [epoch: 10.3 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24137121866149144		[learning rate: 0.0013897]
	Learning Rate: 0.00138974
	LOSS [training: 0.24137121866149144 | validation: 0.26931390409051714]
	TIME [epoch: 10.3 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23336313750106225		[learning rate: 0.0013855]
	Learning Rate: 0.00138548
	LOSS [training: 0.23336313750106225 | validation: 0.28893181249228006]
	TIME [epoch: 10.3 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.244467234952793		[learning rate: 0.0013812]
	Learning Rate: 0.00138123
	LOSS [training: 0.244467234952793 | validation: 0.2709268844429903]
	TIME [epoch: 10.3 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23824514245387082		[learning rate: 0.001377]
	Learning Rate: 0.001377
	LOSS [training: 0.23824514245387082 | validation: 0.27593266395505206]
	TIME [epoch: 10.3 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23446631946060856		[learning rate: 0.0013728]
	Learning Rate: 0.00137278
	LOSS [training: 0.23446631946060856 | validation: 0.2602476620442817]
	TIME [epoch: 10.3 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2371445194071245		[learning rate: 0.0013686]
	Learning Rate: 0.00136857
	LOSS [training: 0.2371445194071245 | validation: 0.2763372987044138]
	TIME [epoch: 10.3 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2505103519993931		[learning rate: 0.0013644]
	Learning Rate: 0.00136437
	LOSS [training: 0.2505103519993931 | validation: 0.35896596641614975]
	TIME [epoch: 10.3 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27430443515666614		[learning rate: 0.0013602]
	Learning Rate: 0.00136019
	LOSS [training: 0.27430443515666614 | validation: 0.2762373346603548]
	TIME [epoch: 10.3 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2539374527270772		[learning rate: 0.001356]
	Learning Rate: 0.00135602
	LOSS [training: 0.2539374527270772 | validation: 0.3109129438570456]
	TIME [epoch: 10.3 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25217804904337926		[learning rate: 0.0013519]
	Learning Rate: 0.00135187
	LOSS [training: 0.25217804904337926 | validation: 0.2575176183286729]
	TIME [epoch: 10.3 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24858025001128628		[learning rate: 0.0013477]
	Learning Rate: 0.00134772
	LOSS [training: 0.24858025001128628 | validation: 0.2879572518661989]
	TIME [epoch: 10.3 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2596804532375184		[learning rate: 0.0013436]
	Learning Rate: 0.00134359
	LOSS [training: 0.2596804532375184 | validation: 0.3590582839667063]
	TIME [epoch: 10.3 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2882554574837427		[learning rate: 0.0013395]
	Learning Rate: 0.00133947
	LOSS [training: 0.2882554574837427 | validation: 0.32169924650318293]
	TIME [epoch: 10.3 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28068467865351776		[learning rate: 0.0013354]
	Learning Rate: 0.00133536
	LOSS [training: 0.28068467865351776 | validation: 0.31151084087234876]
	TIME [epoch: 10.3 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2825494924379076		[learning rate: 0.0013313]
	Learning Rate: 0.00133127
	LOSS [training: 0.2825494924379076 | validation: 0.3218448660856805]
	TIME [epoch: 10.3 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2722347480117948		[learning rate: 0.0013272]
	Learning Rate: 0.00132719
	LOSS [training: 0.2722347480117948 | validation: 0.2977628153336508]
	TIME [epoch: 10.3 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2624600548215708		[learning rate: 0.0013231]
	Learning Rate: 0.00132312
	LOSS [training: 0.2624600548215708 | validation: 0.2645903632021962]
	TIME [epoch: 10.3 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25177645150576383		[learning rate: 0.0013191]
	Learning Rate: 0.00131907
	LOSS [training: 0.25177645150576383 | validation: 0.2810460731275739]
	TIME [epoch: 10.3 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2725639079207127		[learning rate: 0.001315]
	Learning Rate: 0.00131502
	LOSS [training: 0.2725639079207127 | validation: 0.27070565558599824]
	TIME [epoch: 10.3 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2834522557637419		[learning rate: 0.001311]
	Learning Rate: 0.00131099
	LOSS [training: 0.2834522557637419 | validation: 0.2875616039786484]
	TIME [epoch: 10.3 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27767160609049196		[learning rate: 0.001307]
	Learning Rate: 0.00130697
	LOSS [training: 0.27767160609049196 | validation: 0.29170270463288644]
	TIME [epoch: 10.3 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2819107113840208		[learning rate: 0.001303]
	Learning Rate: 0.00130297
	LOSS [training: 0.2819107113840208 | validation: 0.3764892793366015]
	TIME [epoch: 10.3 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27981321181620133		[learning rate: 0.001299]
	Learning Rate: 0.00129897
	LOSS [training: 0.27981321181620133 | validation: 0.2679352705064479]
	TIME [epoch: 10.3 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25356284696860604		[learning rate: 0.001295]
	Learning Rate: 0.00129499
	LOSS [training: 0.25356284696860604 | validation: 0.3633653721759781]
	TIME [epoch: 10.3 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2707558325223379		[learning rate: 0.001291]
	Learning Rate: 0.00129102
	LOSS [training: 0.2707558325223379 | validation: 0.29256981475990423]
	TIME [epoch: 10.3 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3200239810872053		[learning rate: 0.0012871]
	Learning Rate: 0.00128706
	LOSS [training: 0.3200239810872053 | validation: 0.3104914530640955]
	TIME [epoch: 10.3 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3492455627338713		[learning rate: 0.0012831]
	Learning Rate: 0.00128312
	LOSS [training: 0.3492455627338713 | validation: 0.4059484233934363]
	TIME [epoch: 10.3 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2874966359628217		[learning rate: 0.0012792]
	Learning Rate: 0.00127918
	LOSS [training: 0.2874966359628217 | validation: 0.26371566659305645]
	TIME [epoch: 10.3 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2537424782409709		[learning rate: 0.0012753]
	Learning Rate: 0.00127526
	LOSS [training: 0.2537424782409709 | validation: 0.2779263852720545]
	TIME [epoch: 10.3 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28024552573718947		[learning rate: 0.0012714]
	Learning Rate: 0.00127135
	LOSS [training: 0.28024552573718947 | validation: 0.30973215240993396]
	TIME [epoch: 10.3 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2708573992563494		[learning rate: 0.0012675]
	Learning Rate: 0.00126746
	LOSS [training: 0.2708573992563494 | validation: 0.29882524859539034]
	TIME [epoch: 10.3 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3131594493015556		[learning rate: 0.0012636]
	Learning Rate: 0.00126357
	LOSS [training: 0.3131594493015556 | validation: 0.38864508641572104]
	TIME [epoch: 10.3 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33581607933983026		[learning rate: 0.0012597]
	Learning Rate: 0.0012597
	LOSS [training: 0.33581607933983026 | validation: 0.35729828169165173]
	TIME [epoch: 10.3 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29287782807605994		[learning rate: 0.0012558]
	Learning Rate: 0.00125584
	LOSS [training: 0.29287782807605994 | validation: 0.30453304743738735]
	TIME [epoch: 10.3 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2747091001305582		[learning rate: 0.001252]
	Learning Rate: 0.00125199
	LOSS [training: 0.2747091001305582 | validation: 0.2733623717368938]
	TIME [epoch: 10.3 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2640503328137536		[learning rate: 0.0012481]
	Learning Rate: 0.00124815
	LOSS [training: 0.2640503328137536 | validation: 0.3006097108527635]
	TIME [epoch: 10.3 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.266558394432463		[learning rate: 0.0012443]
	Learning Rate: 0.00124432
	LOSS [training: 0.266558394432463 | validation: 0.2789457292097943]
	TIME [epoch: 10.3 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23108946196355343		[learning rate: 0.0012405]
	Learning Rate: 0.00124051
	LOSS [training: 0.23108946196355343 | validation: 0.2982159480235487]
	TIME [epoch: 10.3 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25253964509587384		[learning rate: 0.0012367]
	Learning Rate: 0.00123671
	LOSS [training: 0.25253964509587384 | validation: 0.22125960835245054]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1181.pth
	Model improved!!!
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22631826225783253		[learning rate: 0.0012329]
	Learning Rate: 0.00123292
	LOSS [training: 0.22631826225783253 | validation: 0.32389775989021624]
	TIME [epoch: 10.3 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2953893876378152		[learning rate: 0.0012291]
	Learning Rate: 0.00122914
	LOSS [training: 0.2953893876378152 | validation: 0.5490996181023832]
	TIME [epoch: 10.3 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3655188070374246		[learning rate: 0.0012254]
	Learning Rate: 0.00122537
	LOSS [training: 0.3655188070374246 | validation: 0.3445098522014645]
	TIME [epoch: 10.3 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29604213699766363		[learning rate: 0.0012216]
	Learning Rate: 0.00122161
	LOSS [training: 0.29604213699766363 | validation: 0.3731207657489736]
	TIME [epoch: 10.3 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28314920487664175		[learning rate: 0.0012179]
	Learning Rate: 0.00121787
	LOSS [training: 0.28314920487664175 | validation: 0.34957397711713056]
	TIME [epoch: 10.3 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30782491186453326		[learning rate: 0.0012141]
	Learning Rate: 0.00121413
	LOSS [training: 0.30782491186453326 | validation: 0.34233815620510966]
	TIME [epoch: 10.3 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37685006387246406		[learning rate: 0.0012104]
	Learning Rate: 0.00121041
	LOSS [training: 0.37685006387246406 | validation: 0.373225789813024]
	TIME [epoch: 10.3 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33376384220370187		[learning rate: 0.0012067]
	Learning Rate: 0.0012067
	LOSS [training: 0.33376384220370187 | validation: 0.3467673177267993]
	TIME [epoch: 10.3 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3004602219554579		[learning rate: 0.001203]
	Learning Rate: 0.001203
	LOSS [training: 0.3004602219554579 | validation: 0.30626926679947886]
	TIME [epoch: 10.3 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25541224283183006		[learning rate: 0.0011993]
	Learning Rate: 0.00119932
	LOSS [training: 0.25541224283183006 | validation: 0.297729923240123]
	TIME [epoch: 10.3 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2755464737280854		[learning rate: 0.0011956]
	Learning Rate: 0.00119564
	LOSS [training: 0.2755464737280854 | validation: 0.2952147179225277]
	TIME [epoch: 10.3 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2538934475471192		[learning rate: 0.001192]
	Learning Rate: 0.00119197
	LOSS [training: 0.2538934475471192 | validation: 0.3430830874266057]
	TIME [epoch: 10.3 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33656508300185706		[learning rate: 0.0011883]
	Learning Rate: 0.00118832
	LOSS [training: 0.33656508300185706 | validation: 0.4164204542167758]
	TIME [epoch: 10.3 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3318410532448582		[learning rate: 0.0011847]
	Learning Rate: 0.00118468
	LOSS [training: 0.3318410532448582 | validation: 0.2603206266395611]
	TIME [epoch: 10.3 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29711375838463294		[learning rate: 0.001181]
	Learning Rate: 0.00118105
	LOSS [training: 0.29711375838463294 | validation: 0.3779191395287393]
	TIME [epoch: 10.3 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2624226398407801		[learning rate: 0.0011774]
	Learning Rate: 0.00117743
	LOSS [training: 0.2624226398407801 | validation: 0.27020656396731424]
	TIME [epoch: 10.3 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23058828605727316		[learning rate: 0.0011738]
	Learning Rate: 0.00117382
	LOSS [training: 0.23058828605727316 | validation: 0.2504056083790846]
	TIME [epoch: 10.3 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2368230202875785		[learning rate: 0.0011702]
	Learning Rate: 0.00117022
	LOSS [training: 0.2368230202875785 | validation: 0.2352980101539555]
	TIME [epoch: 10.3 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20904591669574885		[learning rate: 0.0011666]
	Learning Rate: 0.00116663
	LOSS [training: 0.20904591669574885 | validation: 0.23964092275988014]
	TIME [epoch: 10.3 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22323359438754475		[learning rate: 0.0011631]
	Learning Rate: 0.00116305
	LOSS [training: 0.22323359438754475 | validation: 0.23279361766090279]
	TIME [epoch: 10.3 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2161818464606914		[learning rate: 0.0011595]
	Learning Rate: 0.00115949
	LOSS [training: 0.2161818464606914 | validation: 0.23322722140781094]
	TIME [epoch: 10.3 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24788355243870508		[learning rate: 0.0011559]
	Learning Rate: 0.00115593
	LOSS [training: 0.24788355243870508 | validation: 0.29845339189661585]
	TIME [epoch: 10.3 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21746718034300297		[learning rate: 0.0011524]
	Learning Rate: 0.00115239
	LOSS [training: 0.21746718034300297 | validation: 0.22457377597383513]
	TIME [epoch: 10.3 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22595222310476837		[learning rate: 0.0011489]
	Learning Rate: 0.00114886
	LOSS [training: 0.22595222310476837 | validation: 0.3841439929538064]
	TIME [epoch: 10.3 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.253988755393945		[learning rate: 0.0011453]
	Learning Rate: 0.00114534
	LOSS [training: 0.253988755393945 | validation: 0.27384053284874876]
	TIME [epoch: 10.3 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23611149053174046		[learning rate: 0.0011418]
	Learning Rate: 0.00114183
	LOSS [training: 0.23611149053174046 | validation: 0.22796713503228427]
	TIME [epoch: 10.3 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22641022351098022		[learning rate: 0.0011383]
	Learning Rate: 0.00113833
	LOSS [training: 0.22641022351098022 | validation: 0.22758671297385796]
	TIME [epoch: 10.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22328793978497385		[learning rate: 0.0011348]
	Learning Rate: 0.00113484
	LOSS [training: 0.22328793978497385 | validation: 0.21066948047009135]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1209.pth
	Model improved!!!
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20052200446809226		[learning rate: 0.0011314]
	Learning Rate: 0.00113136
	LOSS [training: 0.20052200446809226 | validation: 0.22956389182318038]
	TIME [epoch: 10.3 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20908037846077604		[learning rate: 0.0011279]
	Learning Rate: 0.00112789
	LOSS [training: 0.20908037846077604 | validation: 0.29430108521356485]
	TIME [epoch: 10.3 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2260414249885523		[learning rate: 0.0011244]
	Learning Rate: 0.00112443
	LOSS [training: 0.2260414249885523 | validation: 0.28021173792285936]
	TIME [epoch: 10.3 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30005481429600495		[learning rate: 0.001121]
	Learning Rate: 0.00112099
	LOSS [training: 0.30005481429600495 | validation: 0.28374781782236097]
	TIME [epoch: 10.3 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21977807827623427		[learning rate: 0.0011175]
	Learning Rate: 0.00111755
	LOSS [training: 0.21977807827623427 | validation: 0.21889520029589335]
	TIME [epoch: 10.3 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20771304656414044		[learning rate: 0.0011141]
	Learning Rate: 0.00111412
	LOSS [training: 0.20771304656414044 | validation: 0.2811070759630824]
	TIME [epoch: 10.3 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22613417316200407		[learning rate: 0.0011107]
	Learning Rate: 0.00111071
	LOSS [training: 0.22613417316200407 | validation: 0.24596164513435967]
	TIME [epoch: 10.3 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2769117080970325		[learning rate: 0.0011073]
	Learning Rate: 0.0011073
	LOSS [training: 0.2769117080970325 | validation: 0.24451230035968927]
	TIME [epoch: 10.3 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2508192250581659		[learning rate: 0.0011039]
	Learning Rate: 0.00110391
	LOSS [training: 0.2508192250581659 | validation: 0.25063785069975103]
	TIME [epoch: 10.3 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21901939664460332		[learning rate: 0.0011005]
	Learning Rate: 0.00110053
	LOSS [training: 0.21901939664460332 | validation: 0.23534698094877193]
	TIME [epoch: 10.3 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.218681919937424		[learning rate: 0.0010972]
	Learning Rate: 0.00109715
	LOSS [training: 0.218681919937424 | validation: 0.25119239556985884]
	TIME [epoch: 10.3 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25382049947461727		[learning rate: 0.0010938]
	Learning Rate: 0.00109379
	LOSS [training: 0.25382049947461727 | validation: 0.29104043985471]
	TIME [epoch: 10.3 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27808026116987633		[learning rate: 0.0010904]
	Learning Rate: 0.00109044
	LOSS [training: 0.27808026116987633 | validation: 0.2745036384394669]
	TIME [epoch: 10.3 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23599627697125408		[learning rate: 0.0010871]
	Learning Rate: 0.00108709
	LOSS [training: 0.23599627697125408 | validation: 0.29602454934162037]
	TIME [epoch: 10.3 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24457511020544417		[learning rate: 0.0010838]
	Learning Rate: 0.00108376
	LOSS [training: 0.24457511020544417 | validation: 0.3238312231004112]
	TIME [epoch: 10.3 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24042202421942133		[learning rate: 0.0010804]
	Learning Rate: 0.00108044
	LOSS [training: 0.24042202421942133 | validation: 0.22555309703112442]
	TIME [epoch: 10.3 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20664627313955958		[learning rate: 0.0010771]
	Learning Rate: 0.00107713
	LOSS [training: 0.20664627313955958 | validation: 0.21027044987786653]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1226.pth
	Model improved!!!
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19711814464375185		[learning rate: 0.0010738]
	Learning Rate: 0.00107382
	LOSS [training: 0.19711814464375185 | validation: 0.22432607660574516]
	TIME [epoch: 10.3 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20490496022261023		[learning rate: 0.0010705]
	Learning Rate: 0.00107053
	LOSS [training: 0.20490496022261023 | validation: 0.25794649715299534]
	TIME [epoch: 10.3 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21516456730702246		[learning rate: 0.0010673]
	Learning Rate: 0.00106725
	LOSS [training: 0.21516456730702246 | validation: 0.22898346436451897]
	TIME [epoch: 10.3 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23299948306866222		[learning rate: 0.001064]
	Learning Rate: 0.00106398
	LOSS [training: 0.23299948306866222 | validation: 0.26817881162769164]
	TIME [epoch: 10.3 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22726111792132758		[learning rate: 0.0010607]
	Learning Rate: 0.00106072
	LOSS [training: 0.22726111792132758 | validation: 0.23402650789117804]
	TIME [epoch: 10.3 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2127650839101422		[learning rate: 0.0010575]
	Learning Rate: 0.00105747
	LOSS [training: 0.2127650839101422 | validation: 0.21779687605489906]
	TIME [epoch: 10.3 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21182873665212662		[learning rate: 0.0010542]
	Learning Rate: 0.00105422
	LOSS [training: 0.21182873665212662 | validation: 0.2715323500263538]
	TIME [epoch: 10.3 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28643701100404095		[learning rate: 0.001051]
	Learning Rate: 0.00105099
	LOSS [training: 0.28643701100404095 | validation: 0.37302526702364197]
	TIME [epoch: 10.3 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3200353760423006		[learning rate: 0.0010478]
	Learning Rate: 0.00104777
	LOSS [training: 0.3200353760423006 | validation: 0.2667211209258005]
	TIME [epoch: 10.3 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26681880723293866		[learning rate: 0.0010446]
	Learning Rate: 0.00104456
	LOSS [training: 0.26681880723293866 | validation: 0.26404704584355926]
	TIME [epoch: 10.3 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25127488734845227		[learning rate: 0.0010414]
	Learning Rate: 0.00104136
	LOSS [training: 0.25127488734845227 | validation: 0.2608790901738434]
	TIME [epoch: 10.3 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24401594638598464		[learning rate: 0.0010382]
	Learning Rate: 0.00103817
	LOSS [training: 0.24401594638598464 | validation: 0.25238181355750633]
	TIME [epoch: 10.3 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24008248233525803		[learning rate: 0.001035]
	Learning Rate: 0.00103498
	LOSS [training: 0.24008248233525803 | validation: 0.26415765100629146]
	TIME [epoch: 10.3 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2488465682683096		[learning rate: 0.0010318]
	Learning Rate: 0.00103181
	LOSS [training: 0.2488465682683096 | validation: 0.2528520582061668]
	TIME [epoch: 10.3 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25008799275606053		[learning rate: 0.0010286]
	Learning Rate: 0.00102865
	LOSS [training: 0.25008799275606053 | validation: 0.2990124674065057]
	TIME [epoch: 10.3 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27646288515353945		[learning rate: 0.0010255]
	Learning Rate: 0.00102549
	LOSS [training: 0.27646288515353945 | validation: 0.27493780242772303]
	TIME [epoch: 10.3 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25855716888721053		[learning rate: 0.0010224]
	Learning Rate: 0.00102235
	LOSS [training: 0.25855716888721053 | validation: 0.27282992243205817]
	TIME [epoch: 10.3 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2567872350203516		[learning rate: 0.0010192]
	Learning Rate: 0.00101922
	LOSS [training: 0.2567872350203516 | validation: 0.29048682530950104]
	TIME [epoch: 10.3 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25184220678261965		[learning rate: 0.0010161]
	Learning Rate: 0.00101609
	LOSS [training: 0.25184220678261965 | validation: 0.23740729475878095]
	TIME [epoch: 10.3 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22644222030647546		[learning rate: 0.001013]
	Learning Rate: 0.00101298
	LOSS [training: 0.22644222030647546 | validation: 0.24063672251648002]
	TIME [epoch: 10.3 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2468893320936397		[learning rate: 0.0010099]
	Learning Rate: 0.00100987
	LOSS [training: 0.2468893320936397 | validation: 0.32659084070714217]
	TIME [epoch: 10.3 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30692222015655535		[learning rate: 0.0010068]
	Learning Rate: 0.00100678
	LOSS [training: 0.30692222015655535 | validation: 0.2857079509786456]
	TIME [epoch: 10.3 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2761870639111027		[learning rate: 0.0010037]
	Learning Rate: 0.00100369
	LOSS [training: 0.2761870639111027 | validation: 0.3255059975728784]
	TIME [epoch: 10.3 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3836754894286914		[learning rate: 0.0010006]
	Learning Rate: 0.00100061
	LOSS [training: 0.3836754894286914 | validation: 0.2843408165130427]
	TIME [epoch: 10.3 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23374733434111605		[learning rate: 0.00099755]
	Learning Rate: 0.000997547
	LOSS [training: 0.23374733434111605 | validation: 0.2504816676601974]
	TIME [epoch: 10.3 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22770651239772946		[learning rate: 0.00099449]
	Learning Rate: 0.000994489
	LOSS [training: 0.22770651239772946 | validation: 0.2272733190026847]
	TIME [epoch: 10.3 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22555236359282693		[learning rate: 0.00099144]
	Learning Rate: 0.00099144
	LOSS [training: 0.22555236359282693 | validation: 0.2527506966424935]
	TIME [epoch: 10.3 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24452253466831006		[learning rate: 0.0009884]
	Learning Rate: 0.000988401
	LOSS [training: 0.24452253466831006 | validation: 0.2471009650517292]
	TIME [epoch: 10.3 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2336214997348863		[learning rate: 0.00098537]
	Learning Rate: 0.000985371
	LOSS [training: 0.2336214997348863 | validation: 0.21358258870527266]
	TIME [epoch: 10.3 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20964363185626853		[learning rate: 0.00098235]
	Learning Rate: 0.000982351
	LOSS [training: 0.20964363185626853 | validation: 0.2617763709100939]
	TIME [epoch: 10.3 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25952876846476514		[learning rate: 0.00097934]
	Learning Rate: 0.000979339
	LOSS [training: 0.25952876846476514 | validation: 0.26045026558503176]
	TIME [epoch: 10.3 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2162672548063486		[learning rate: 0.00097634]
	Learning Rate: 0.000976337
	LOSS [training: 0.2162672548063486 | validation: 0.23818294190189415]
	TIME [epoch: 10.3 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2314580788042384		[learning rate: 0.00097334]
	Learning Rate: 0.000973345
	LOSS [training: 0.2314580788042384 | validation: 0.24451558708195564]
	TIME [epoch: 10.3 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2240245407659181		[learning rate: 0.00097036]
	Learning Rate: 0.000970361
	LOSS [training: 0.2240245407659181 | validation: 0.2312734776567474]
	TIME [epoch: 10.3 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2227779412400947		[learning rate: 0.00096739]
	Learning Rate: 0.000967386
	LOSS [training: 0.2227779412400947 | validation: 0.23443864723883873]
	TIME [epoch: 10.3 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24064703484656783		[learning rate: 0.00096442]
	Learning Rate: 0.000964421
	LOSS [training: 0.24064703484656783 | validation: 0.25785707833384935]
	TIME [epoch: 10.3 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2275665634317682		[learning rate: 0.00096146]
	Learning Rate: 0.000961464
	LOSS [training: 0.2275665634317682 | validation: 0.2718046944454458]
	TIME [epoch: 10.3 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22808503521488221		[learning rate: 0.00095852]
	Learning Rate: 0.000958517
	LOSS [training: 0.22808503521488221 | validation: 0.25038486781322566]
	TIME [epoch: 10.3 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2512066088226591		[learning rate: 0.00095558]
	Learning Rate: 0.000955579
	LOSS [training: 0.2512066088226591 | validation: 0.2974412033977557]
	TIME [epoch: 10.3 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25292316397415393		[learning rate: 0.00095265]
	Learning Rate: 0.00095265
	LOSS [training: 0.25292316397415393 | validation: 0.25791953409391555]
	TIME [epoch: 10.3 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308532885150658		[learning rate: 0.00094973]
	Learning Rate: 0.00094973
	LOSS [training: 0.308532885150658 | validation: 0.3394767447961867]
	TIME [epoch: 10.3 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4035165312013621		[learning rate: 0.00094682]
	Learning Rate: 0.000946818
	LOSS [training: 0.4035165312013621 | validation: 0.4013041079498341]
	TIME [epoch: 10.3 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40342205154915856		[learning rate: 0.00094392]
	Learning Rate: 0.000943916
	LOSS [training: 0.40342205154915856 | validation: 0.36672476156760025]
	TIME [epoch: 10.3 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3227406778491783		[learning rate: 0.00094102]
	Learning Rate: 0.000941023
	LOSS [training: 0.3227406778491783 | validation: 0.27545635293792875]
	TIME [epoch: 10.3 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2749443569822279		[learning rate: 0.00093814]
	Learning Rate: 0.000938138
	LOSS [training: 0.2749443569822279 | validation: 0.30322470184614836]
	TIME [epoch: 10.3 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31224839347585165		[learning rate: 0.00093526]
	Learning Rate: 0.000935262
	LOSS [training: 0.31224839347585165 | validation: 0.37231679950948776]
	TIME [epoch: 10.3 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3552334261576238		[learning rate: 0.0009324]
	Learning Rate: 0.000932395
	LOSS [training: 0.3552334261576238 | validation: 0.2834405110414821]
	TIME [epoch: 10.3 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2933652489991264		[learning rate: 0.00092954]
	Learning Rate: 0.000929537
	LOSS [training: 0.2933652489991264 | validation: 0.3302902400793606]
	TIME [epoch: 10.3 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30802704047680984		[learning rate: 0.00092669]
	Learning Rate: 0.000926688
	LOSS [training: 0.30802704047680984 | validation: 0.2898656685928862]
	TIME [epoch: 10.3 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3274172864165982		[learning rate: 0.00092385]
	Learning Rate: 0.000923847
	LOSS [training: 0.3274172864165982 | validation: 0.4793850587995675]
	TIME [epoch: 10.3 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3360328907604685		[learning rate: 0.00092101]
	Learning Rate: 0.000921015
	LOSS [training: 0.3360328907604685 | validation: 0.27285934125590494]
	TIME [epoch: 10.3 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2696083454928496		[learning rate: 0.00091819]
	Learning Rate: 0.000918192
	LOSS [training: 0.2696083454928496 | validation: 0.2671104487054987]
	TIME [epoch: 10.3 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26699773376564745		[learning rate: 0.00091538]
	Learning Rate: 0.000915377
	LOSS [training: 0.26699773376564745 | validation: 0.27741781069586163]
	TIME [epoch: 10.3 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24518100113248398		[learning rate: 0.00091257]
	Learning Rate: 0.000912571
	LOSS [training: 0.24518100113248398 | validation: 0.3194680430940616]
	TIME [epoch: 10.3 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2940632806886847		[learning rate: 0.00090977]
	Learning Rate: 0.000909774
	LOSS [training: 0.2940632806886847 | validation: 0.28573093084671003]
	TIME [epoch: 10.3 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2238287702471728		[learning rate: 0.00090698]
	Learning Rate: 0.000906985
	LOSS [training: 0.2238287702471728 | validation: 0.22912240147237867]
	TIME [epoch: 10.3 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20298103154056601		[learning rate: 0.0009042]
	Learning Rate: 0.000904204
	LOSS [training: 0.20298103154056601 | validation: 0.23072686199517756]
	TIME [epoch: 10.3 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20789142185914627		[learning rate: 0.00090143]
	Learning Rate: 0.000901433
	LOSS [training: 0.20789142185914627 | validation: 0.2226076805468874]
	TIME [epoch: 10.3 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19868616317018115		[learning rate: 0.00089867]
	Learning Rate: 0.000898669
	LOSS [training: 0.19868616317018115 | validation: 0.23927483271889166]
	TIME [epoch: 10.3 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2089296924669341		[learning rate: 0.00089591]
	Learning Rate: 0.000895915
	LOSS [training: 0.2089296924669341 | validation: 0.23828318135158896]
	TIME [epoch: 10.3 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2176849644274824		[learning rate: 0.00089317]
	Learning Rate: 0.000893168
	LOSS [training: 0.2176849644274824 | validation: 0.27658476902835716]
	TIME [epoch: 10.3 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22215541916271758		[learning rate: 0.00089043]
	Learning Rate: 0.00089043
	LOSS [training: 0.22215541916271758 | validation: 0.2578657291815659]
	TIME [epoch: 10.3 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2141266681018395		[learning rate: 0.0008877]
	Learning Rate: 0.000887701
	LOSS [training: 0.2141266681018395 | validation: 0.24591235447537166]
	TIME [epoch: 10.3 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25326209770209795		[learning rate: 0.00088498]
	Learning Rate: 0.00088498
	LOSS [training: 0.25326209770209795 | validation: 0.5001300479030062]
	TIME [epoch: 10.3 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5326874681962521		[learning rate: 0.00088227]
	Learning Rate: 0.000882267
	LOSS [training: 0.5326874681962521 | validation: 0.3678789202541084]
	TIME [epoch: 10.3 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3416880000588336		[learning rate: 0.00087956]
	Learning Rate: 0.000879562
	LOSS [training: 0.3416880000588336 | validation: 0.3651579394979714]
	TIME [epoch: 10.3 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28166471410632843		[learning rate: 0.00087687]
	Learning Rate: 0.000876866
	LOSS [training: 0.28166471410632843 | validation: 0.2889406047552722]
	TIME [epoch: 10.3 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2526227669200676		[learning rate: 0.00087418]
	Learning Rate: 0.000874178
	LOSS [training: 0.2526227669200676 | validation: 0.30138550876484393]
	TIME [epoch: 10.3 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3024983630821068		[learning rate: 0.0008715]
	Learning Rate: 0.000871498
	LOSS [training: 0.3024983630821068 | validation: 0.26265668528709896]
	TIME [epoch: 10.3 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24279346123160236		[learning rate: 0.00086883]
	Learning Rate: 0.000868827
	LOSS [training: 0.24279346123160236 | validation: 0.30287905065480525]
	TIME [epoch: 10.3 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2575830279859736		[learning rate: 0.00086616]
	Learning Rate: 0.000866164
	LOSS [training: 0.2575830279859736 | validation: 0.2908307597685959]
	TIME [epoch: 10.3 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2631689199739902		[learning rate: 0.00086351]
	Learning Rate: 0.000863509
	LOSS [training: 0.2631689199739902 | validation: 0.33776504834204946]
	TIME [epoch: 10.3 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35669088099992885		[learning rate: 0.00086086]
	Learning Rate: 0.000860861
	LOSS [training: 0.35669088099992885 | validation: 0.4388953826796955]
	TIME [epoch: 10.3 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38094149631771274		[learning rate: 0.00085822]
	Learning Rate: 0.000858223
	LOSS [training: 0.38094149631771274 | validation: 0.2966637839034015]
	TIME [epoch: 10.3 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2600285292471455		[learning rate: 0.00085559]
	Learning Rate: 0.000855592
	LOSS [training: 0.2600285292471455 | validation: 0.2559223350544601]
	TIME [epoch: 10.3 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24799821449860443		[learning rate: 0.00085297]
	Learning Rate: 0.000852969
	LOSS [training: 0.24799821449860443 | validation: 0.2632748013119841]
	TIME [epoch: 10.3 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2550438071694487		[learning rate: 0.00085035]
	Learning Rate: 0.000850354
	LOSS [training: 0.2550438071694487 | validation: 0.24426345878091912]
	TIME [epoch: 10.3 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23355481623320945		[learning rate: 0.00084775]
	Learning Rate: 0.000847748
	LOSS [training: 0.23355481623320945 | validation: 0.25239940710100306]
	TIME [epoch: 10.3 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24529603804615502		[learning rate: 0.00084515]
	Learning Rate: 0.000845149
	LOSS [training: 0.24529603804615502 | validation: 0.28910115638041856]
	TIME [epoch: 10.3 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2933050814471763		[learning rate: 0.00084256]
	Learning Rate: 0.000842558
	LOSS [training: 0.2933050814471763 | validation: 0.34427293965324246]
	TIME [epoch: 10.3 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32440348187663626		[learning rate: 0.00083998]
	Learning Rate: 0.000839976
	LOSS [training: 0.32440348187663626 | validation: 0.3114518742491194]
	TIME [epoch: 10.3 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27526114950311753		[learning rate: 0.0008374]
	Learning Rate: 0.000837401
	LOSS [training: 0.27526114950311753 | validation: 0.2600511648330033]
	TIME [epoch: 10.3 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25907432864524277		[learning rate: 0.00083483]
	Learning Rate: 0.000834834
	LOSS [training: 0.25907432864524277 | validation: 0.2494700885955502]
	TIME [epoch: 10.3 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2358088869485838		[learning rate: 0.00083227]
	Learning Rate: 0.000832274
	LOSS [training: 0.2358088869485838 | validation: 0.24145851823882786]
	TIME [epoch: 10.3 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2305288723633201		[learning rate: 0.00082972]
	Learning Rate: 0.000829723
	LOSS [training: 0.2305288723633201 | validation: 0.23561104447080947]
	TIME [epoch: 10.3 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24457737698205162		[learning rate: 0.00082718]
	Learning Rate: 0.00082718
	LOSS [training: 0.24457737698205162 | validation: 0.2611151027367699]
	TIME [epoch: 10.3 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23677800084317813		[learning rate: 0.00082464]
	Learning Rate: 0.000824644
	LOSS [training: 0.23677800084317813 | validation: 0.30508595661524146]
	TIME [epoch: 10.3 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2529738857111684		[learning rate: 0.00082212]
	Learning Rate: 0.000822116
	LOSS [training: 0.2529738857111684 | validation: 0.22120574885789346]
	TIME [epoch: 10.3 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21727194807986927		[learning rate: 0.0008196]
	Learning Rate: 0.000819596
	LOSS [training: 0.21727194807986927 | validation: 0.21278797182489878]
	TIME [epoch: 10.3 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22510645071328989		[learning rate: 0.00081708]
	Learning Rate: 0.000817084
	LOSS [training: 0.22510645071328989 | validation: 0.22461210417115418]
	TIME [epoch: 10.3 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23012028840712812		[learning rate: 0.00081458]
	Learning Rate: 0.000814579
	LOSS [training: 0.23012028840712812 | validation: 0.25297804166079024]
	TIME [epoch: 10.3 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22494643761658897		[learning rate: 0.00081208]
	Learning Rate: 0.000812082
	LOSS [training: 0.22494643761658897 | validation: 0.22655550343703967]
	TIME [epoch: 10.3 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25095407216172544		[learning rate: 0.00080959]
	Learning Rate: 0.000809593
	LOSS [training: 0.25095407216172544 | validation: 0.3901267844131825]
	TIME [epoch: 10.3 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31638345004520524		[learning rate: 0.00080711]
	Learning Rate: 0.000807111
	LOSS [training: 0.31638345004520524 | validation: 0.34849185926279014]
	TIME [epoch: 10.3 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2927946604584686		[learning rate: 0.00080464]
	Learning Rate: 0.000804637
	LOSS [training: 0.2927946604584686 | validation: 0.37430080770690055]
	TIME [epoch: 10.3 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31552053250143663		[learning rate: 0.00080217]
	Learning Rate: 0.00080217
	LOSS [training: 0.31552053250143663 | validation: 0.5456235463596676]
	TIME [epoch: 10.3 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3395090409068918		[learning rate: 0.00079971]
	Learning Rate: 0.000799712
	LOSS [training: 0.3395090409068918 | validation: 0.3185251576359388]
	TIME [epoch: 10.3 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3097603948469557		[learning rate: 0.00079726]
	Learning Rate: 0.00079726
	LOSS [training: 0.3097603948469557 | validation: 0.28726126250096523]
	TIME [epoch: 10.3 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26352484605142396		[learning rate: 0.00079482]
	Learning Rate: 0.000794816
	LOSS [training: 0.26352484605142396 | validation: 0.2908933270773754]
	TIME [epoch: 10.3 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24413071127801245		[learning rate: 0.00079238]
	Learning Rate: 0.00079238
	LOSS [training: 0.24413071127801245 | validation: 0.26113100027075453]
	TIME [epoch: 10.3 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2293337214809709		[learning rate: 0.00078995]
	Learning Rate: 0.000789951
	LOSS [training: 0.2293337214809709 | validation: 0.251971841521085]
	TIME [epoch: 10.3 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2588318358432935		[learning rate: 0.00078753]
	Learning Rate: 0.000787529
	LOSS [training: 0.2588318358432935 | validation: 0.23499356152577908]
	TIME [epoch: 10.3 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21304975274553403		[learning rate: 0.00078512]
	Learning Rate: 0.000785115
	LOSS [training: 0.21304975274553403 | validation: 0.2784444441727936]
	TIME [epoch: 10.3 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.296346918448665		[learning rate: 0.00078271]
	Learning Rate: 0.000782708
	LOSS [training: 0.296346918448665 | validation: 0.4028706609841663]
	TIME [epoch: 10.3 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.360502921862755		[learning rate: 0.00078031]
	Learning Rate: 0.000780309
	LOSS [training: 0.360502921862755 | validation: 0.29920720791961264]
	TIME [epoch: 10.3 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2508220057286738		[learning rate: 0.00077792]
	Learning Rate: 0.000777917
	LOSS [training: 0.2508220057286738 | validation: 0.27154061688576453]
	TIME [epoch: 10.3 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.257835635390611		[learning rate: 0.00077553]
	Learning Rate: 0.000775533
	LOSS [training: 0.257835635390611 | validation: 0.29314556914519846]
	TIME [epoch: 10.3 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22147178995962538		[learning rate: 0.00077316]
	Learning Rate: 0.000773155
	LOSS [training: 0.22147178995962538 | validation: 0.2293412543598481]
	TIME [epoch: 10.3 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22192360070604336		[learning rate: 0.00077079]
	Learning Rate: 0.000770785
	LOSS [training: 0.22192360070604336 | validation: 0.23931792275645933]
	TIME [epoch: 10.3 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20792525002332685		[learning rate: 0.00076842]
	Learning Rate: 0.000768422
	LOSS [training: 0.20792525002332685 | validation: 0.22564623170052986]
	TIME [epoch: 10.3 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2112217726176217		[learning rate: 0.00076607]
	Learning Rate: 0.000766067
	LOSS [training: 0.2112217726176217 | validation: 0.24228510669899223]
	TIME [epoch: 10.3 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23496024331641885		[learning rate: 0.00076372]
	Learning Rate: 0.000763719
	LOSS [training: 0.23496024331641885 | validation: 0.2930470423414433]
	TIME [epoch: 10.3 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25568528542886326		[learning rate: 0.00076138]
	Learning Rate: 0.000761377
	LOSS [training: 0.25568528542886326 | validation: 0.26154198221532055]
	TIME [epoch: 10.3 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2203403189811622		[learning rate: 0.00075904]
	Learning Rate: 0.000759043
	LOSS [training: 0.2203403189811622 | validation: 0.22310590003783518]
	TIME [epoch: 10.3 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22024249072474517		[learning rate: 0.00075672]
	Learning Rate: 0.000756717
	LOSS [training: 0.22024249072474517 | validation: 0.25201922861296955]
	TIME [epoch: 10.3 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26588990989808187		[learning rate: 0.0007544]
	Learning Rate: 0.000754397
	LOSS [training: 0.26588990989808187 | validation: 0.46992391249528653]
	TIME [epoch: 10.3 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4445798254410094		[learning rate: 0.00075208]
	Learning Rate: 0.000752084
	LOSS [training: 0.4445798254410094 | validation: 0.31016234327664743]
	TIME [epoch: 10.3 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26403081571465115		[learning rate: 0.00074978]
	Learning Rate: 0.000749779
	LOSS [training: 0.26403081571465115 | validation: 0.2559164175927483]
	TIME [epoch: 10.3 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2448523111096827		[learning rate: 0.00074748]
	Learning Rate: 0.000747481
	LOSS [training: 0.2448523111096827 | validation: 0.26905067608998307]
	TIME [epoch: 10.3 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31819879975903126		[learning rate: 0.00074519]
	Learning Rate: 0.000745189
	LOSS [training: 0.31819879975903126 | validation: 0.36314587042614727]
	TIME [epoch: 10.3 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2853084016806786		[learning rate: 0.0007429]
	Learning Rate: 0.000742905
	LOSS [training: 0.2853084016806786 | validation: 0.2778599638264465]
	TIME [epoch: 10.4 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2799672614074905		[learning rate: 0.00074063]
	Learning Rate: 0.000740628
	LOSS [training: 0.2799672614074905 | validation: 0.3554376386477652]
	TIME [epoch: 10.3 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2871425808350846		[learning rate: 0.00073836]
	Learning Rate: 0.000738357
	LOSS [training: 0.2871425808350846 | validation: 0.2891817793545434]
	TIME [epoch: 10.3 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2699951222488761		[learning rate: 0.00073609]
	Learning Rate: 0.000736094
	LOSS [training: 0.2699951222488761 | validation: 0.31966816993888786]
	TIME [epoch: 10.3 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27513796723863077		[learning rate: 0.00073384]
	Learning Rate: 0.000733838
	LOSS [training: 0.27513796723863077 | validation: 0.3054628276007434]
	TIME [epoch: 10.3 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2744531658824564		[learning rate: 0.00073159]
	Learning Rate: 0.000731588
	LOSS [training: 0.2744531658824564 | validation: 0.31744806590668717]
	TIME [epoch: 10.3 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2693522207372626		[learning rate: 0.00072935]
	Learning Rate: 0.000729345
	LOSS [training: 0.2693522207372626 | validation: 0.2845777452008593]
	TIME [epoch: 10.3 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2734199771177903		[learning rate: 0.00072711]
	Learning Rate: 0.00072711
	LOSS [training: 0.2734199771177903 | validation: 0.30614466738378243]
	TIME [epoch: 10.3 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26475402654552055		[learning rate: 0.00072488]
	Learning Rate: 0.000724881
	LOSS [training: 0.26475402654552055 | validation: 0.29637224335337187]
	TIME [epoch: 10.3 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25672549155795454		[learning rate: 0.00072266]
	Learning Rate: 0.000722659
	LOSS [training: 0.25672549155795454 | validation: 0.26431164324575274]
	TIME [epoch: 10.3 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28709170702815945		[learning rate: 0.00072044]
	Learning Rate: 0.000720444
	LOSS [training: 0.28709170702815945 | validation: 0.3078321918001623]
	TIME [epoch: 10.3 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2972066866541053		[learning rate: 0.00071824]
	Learning Rate: 0.000718235
	LOSS [training: 0.2972066866541053 | validation: 0.3936744735984841]
	TIME [epoch: 10.3 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3078674316510529		[learning rate: 0.00071603]
	Learning Rate: 0.000716033
	LOSS [training: 0.3078674316510529 | validation: 0.2878097240231491]
	TIME [epoch: 10.3 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25721938114596793		[learning rate: 0.00071384]
	Learning Rate: 0.000713839
	LOSS [training: 0.25721938114596793 | validation: 0.25925423880490317]
	TIME [epoch: 10.3 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2930443341590277		[learning rate: 0.00071165]
	Learning Rate: 0.00071165
	LOSS [training: 0.2930443341590277 | validation: 0.31467826649504177]
	TIME [epoch: 10.3 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2670783586221452		[learning rate: 0.00070947]
	Learning Rate: 0.000709469
	LOSS [training: 0.2670783586221452 | validation: 0.2474036078731971]
	TIME [epoch: 10.3 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25757675262917495		[learning rate: 0.00070729]
	Learning Rate: 0.000707294
	LOSS [training: 0.25757675262917495 | validation: 0.2879425996583775]
	TIME [epoch: 10.3 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25427184147118453		[learning rate: 0.00070513]
	Learning Rate: 0.000705126
	LOSS [training: 0.25427184147118453 | validation: 0.30369828304928376]
	TIME [epoch: 10.3 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3405067049766469		[learning rate: 0.00070296]
	Learning Rate: 0.000702964
	LOSS [training: 0.3405067049766469 | validation: 0.4405117086762171]
	TIME [epoch: 10.3 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3240732675404162		[learning rate: 0.00070081]
	Learning Rate: 0.00070081
	LOSS [training: 0.3240732675404162 | validation: 0.3040172195060182]
	TIME [epoch: 10.3 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2929790355821084		[learning rate: 0.00069866]
	Learning Rate: 0.000698661
	LOSS [training: 0.2929790355821084 | validation: 0.33788584452375825]
	TIME [epoch: 10.3 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30525433021759313		[learning rate: 0.00069652]
	Learning Rate: 0.000696519
	LOSS [training: 0.30525433021759313 | validation: 0.3012493105544183]
	TIME [epoch: 10.3 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2945195684173296		[learning rate: 0.00069438]
	Learning Rate: 0.000694384
	LOSS [training: 0.2945195684173296 | validation: 0.41670002050536314]
	TIME [epoch: 10.3 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40062942702401844		[learning rate: 0.00069226]
	Learning Rate: 0.000692256
	LOSS [training: 0.40062942702401844 | validation: 0.4353055597864115]
	TIME [epoch: 10.3 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33120745989291267		[learning rate: 0.00069013]
	Learning Rate: 0.000690134
	LOSS [training: 0.33120745989291267 | validation: 0.3079030993028261]
	TIME [epoch: 10.3 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2725363568740398		[learning rate: 0.00068802]
	Learning Rate: 0.000688018
	LOSS [training: 0.2725363568740398 | validation: 0.2927308206166355]
	TIME [epoch: 10.3 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26429917717804247		[learning rate: 0.00068591]
	Learning Rate: 0.000685909
	LOSS [training: 0.26429917717804247 | validation: 0.31391650160243567]
	TIME [epoch: 10.3 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3045274261182286		[learning rate: 0.00068381]
	Learning Rate: 0.000683807
	LOSS [training: 0.3045274261182286 | validation: 0.3115311387423161]
	TIME [epoch: 10.3 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.305331779902705		[learning rate: 0.00068171]
	Learning Rate: 0.000681711
	LOSS [training: 0.305331779902705 | validation: 0.3091883389931992]
	TIME [epoch: 10.3 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28476105231150706		[learning rate: 0.00067962]
	Learning Rate: 0.000679621
	LOSS [training: 0.28476105231150706 | validation: 0.3338092970994198]
	TIME [epoch: 10.3 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28996486845119956		[learning rate: 0.00067754]
	Learning Rate: 0.000677538
	LOSS [training: 0.28996486845119956 | validation: 0.30582901438909943]
	TIME [epoch: 10.3 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2888664128718464		[learning rate: 0.00067546]
	Learning Rate: 0.000675461
	LOSS [training: 0.2888664128718464 | validation: 0.3441885307369491]
	TIME [epoch: 10.3 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33300226403404815		[learning rate: 0.00067339]
	Learning Rate: 0.00067339
	LOSS [training: 0.33300226403404815 | validation: 0.30744953176214695]
	TIME [epoch: 10.3 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29362078013175513		[learning rate: 0.00067133]
	Learning Rate: 0.000671326
	LOSS [training: 0.29362078013175513 | validation: 0.3834919673464988]
	TIME [epoch: 10.3 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2956856554968851		[learning rate: 0.00066927]
	Learning Rate: 0.000669268
	LOSS [training: 0.2956856554968851 | validation: 0.24425690599147917]
	TIME [epoch: 10.3 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2918214639103426		[learning rate: 0.00066722]
	Learning Rate: 0.000667216
	LOSS [training: 0.2918214639103426 | validation: 0.5702498074457572]
	TIME [epoch: 10.3 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4353534348206532		[learning rate: 0.00066517]
	Learning Rate: 0.000665171
	LOSS [training: 0.4353534348206532 | validation: 0.2730043544984134]
	TIME [epoch: 10.3 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3084657920042759		[learning rate: 0.00066313]
	Learning Rate: 0.000663132
	LOSS [training: 0.3084657920042759 | validation: 0.31940749607805347]
	TIME [epoch: 10.3 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2919234969360871		[learning rate: 0.0006611]
	Learning Rate: 0.000661099
	LOSS [training: 0.2919234969360871 | validation: 0.29829710512816826]
	TIME [epoch: 10.3 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29269162333593324		[learning rate: 0.00065907]
	Learning Rate: 0.000659073
	LOSS [training: 0.29269162333593324 | validation: 0.3973386356007867]
	TIME [epoch: 10.3 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3808462856670529		[learning rate: 0.00065705]
	Learning Rate: 0.000657052
	LOSS [training: 0.3808462856670529 | validation: 0.47184036410659597]
	TIME [epoch: 10.3 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34261267021614406		[learning rate: 0.00065504]
	Learning Rate: 0.000655038
	LOSS [training: 0.34261267021614406 | validation: 0.31597588234150037]
	TIME [epoch: 10.3 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2775012909268857		[learning rate: 0.00065303]
	Learning Rate: 0.00065303
	LOSS [training: 0.2775012909268857 | validation: 0.3180962799781085]
	TIME [epoch: 10.3 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27270037994856		[learning rate: 0.00065103]
	Learning Rate: 0.000651028
	LOSS [training: 0.27270037994856 | validation: 0.2747137943006693]
	TIME [epoch: 10.3 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25288799525194017		[learning rate: 0.00064903]
	Learning Rate: 0.000649033
	LOSS [training: 0.25288799525194017 | validation: 0.2929982964494811]
	TIME [epoch: 10.3 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25867903790080576		[learning rate: 0.00064704]
	Learning Rate: 0.000647043
	LOSS [training: 0.25867903790080576 | validation: 0.2490996440212124]
	TIME [epoch: 10.3 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2489158128069331		[learning rate: 0.00064506]
	Learning Rate: 0.00064506
	LOSS [training: 0.2489158128069331 | validation: 0.2724124124790102]
	TIME [epoch: 10.3 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24787880169575405		[learning rate: 0.00064308]
	Learning Rate: 0.000643082
	LOSS [training: 0.24787880169575405 | validation: 0.30930152301685]
	TIME [epoch: 10.3 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25592143811071405		[learning rate: 0.00064111]
	Learning Rate: 0.000641111
	LOSS [training: 0.25592143811071405 | validation: 0.24331733967011587]
	TIME [epoch: 10.3 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2476702265560223		[learning rate: 0.00063915]
	Learning Rate: 0.000639146
	LOSS [training: 0.2476702265560223 | validation: 0.24372723656987208]
	TIME [epoch: 10.3 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2647185739488753		[learning rate: 0.00063719]
	Learning Rate: 0.000637187
	LOSS [training: 0.2647185739488753 | validation: 0.33388533422383126]
	TIME [epoch: 10.3 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2799995150388041		[learning rate: 0.00063523]
	Learning Rate: 0.000635233
	LOSS [training: 0.2799995150388041 | validation: 0.2633370053246103]
	TIME [epoch: 10.3 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23084013253954838		[learning rate: 0.00063329]
	Learning Rate: 0.000633286
	LOSS [training: 0.23084013253954838 | validation: 0.2192378409042098]
	TIME [epoch: 10.3 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2203115286789754		[learning rate: 0.00063134]
	Learning Rate: 0.000631345
	LOSS [training: 0.2203115286789754 | validation: 0.23428257235509278]
	TIME [epoch: 10.3 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24856648693398048		[learning rate: 0.00062941]
	Learning Rate: 0.000629409
	LOSS [training: 0.24856648693398048 | validation: 0.2544639452923288]
	TIME [epoch: 10.3 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2242184204229427		[learning rate: 0.00062748]
	Learning Rate: 0.00062748
	LOSS [training: 0.2242184204229427 | validation: 0.2414966513937681]
	TIME [epoch: 10.3 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31040341606517574		[learning rate: 0.00062556]
	Learning Rate: 0.000625557
	LOSS [training: 0.31040341606517574 | validation: 0.3686067349063862]
	TIME [epoch: 10.3 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28763430584397337		[learning rate: 0.00062364]
	Learning Rate: 0.000623639
	LOSS [training: 0.28763430584397337 | validation: 0.31344309215177574]
	TIME [epoch: 10.3 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27144712630499307		[learning rate: 0.00062173]
	Learning Rate: 0.000621727
	LOSS [training: 0.27144712630499307 | validation: 0.2694069775657686]
	TIME [epoch: 10.3 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25218835754328567		[learning rate: 0.00061982]
	Learning Rate: 0.000619821
	LOSS [training: 0.25218835754328567 | validation: 0.26264106433744105]
	TIME [epoch: 10.3 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2499259257348677		[learning rate: 0.00061792]
	Learning Rate: 0.000617922
	LOSS [training: 0.2499259257348677 | validation: 0.27341400958995804]
	TIME [epoch: 10.3 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2471612236892609		[learning rate: 0.00061603]
	Learning Rate: 0.000616027
	LOSS [training: 0.2471612236892609 | validation: 0.25662710125146687]
	TIME [epoch: 10.3 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24278257526600844		[learning rate: 0.00061414]
	Learning Rate: 0.000614139
	LOSS [training: 0.24278257526600844 | validation: 0.25757860386205034]
	TIME [epoch: 10.3 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.240927540395996		[learning rate: 0.00061226]
	Learning Rate: 0.000612256
	LOSS [training: 0.240927540395996 | validation: 0.230337493709187]
	TIME [epoch: 10.3 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2274943100905345		[learning rate: 0.00061038]
	Learning Rate: 0.00061038
	LOSS [training: 0.2274943100905345 | validation: 0.2407719847554712]
	TIME [epoch: 10.3 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27943869837023616		[learning rate: 0.00060851]
	Learning Rate: 0.000608509
	LOSS [training: 0.27943869837023616 | validation: 0.27743780351648895]
	TIME [epoch: 10.3 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2394701920848969		[learning rate: 0.00060664]
	Learning Rate: 0.000606643
	LOSS [training: 0.2394701920848969 | validation: 0.2480236129984154]
	TIME [epoch: 10.3 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25728787863925434		[learning rate: 0.00060478]
	Learning Rate: 0.000604784
	LOSS [training: 0.25728787863925434 | validation: 0.2610141735801645]
	TIME [epoch: 10.3 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24228016804640942		[learning rate: 0.00060293]
	Learning Rate: 0.00060293
	LOSS [training: 0.24228016804640942 | validation: 0.2645839176432982]
	TIME [epoch: 10.3 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2521177512804819		[learning rate: 0.00060108]
	Learning Rate: 0.000601081
	LOSS [training: 0.2521177512804819 | validation: 0.2693326486635613]
	TIME [epoch: 10.3 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2694201628947709		[learning rate: 0.00059924]
	Learning Rate: 0.000599239
	LOSS [training: 0.2694201628947709 | validation: 0.27787949447871596]
	TIME [epoch: 10.3 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26051352292592594		[learning rate: 0.0005974]
	Learning Rate: 0.000597402
	LOSS [training: 0.26051352292592594 | validation: 0.30578123946949015]
	TIME [epoch: 10.3 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27338274310803984		[learning rate: 0.00059557]
	Learning Rate: 0.000595571
	LOSS [training: 0.27338274310803984 | validation: 0.2987698134999805]
	TIME [epoch: 10.3 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2495354150370835		[learning rate: 0.00059375]
	Learning Rate: 0.000593745
	LOSS [training: 0.2495354150370835 | validation: 0.2451708446200936]
	TIME [epoch: 10.3 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24014525157982386		[learning rate: 0.00059192]
	Learning Rate: 0.000591925
	LOSS [training: 0.24014525157982386 | validation: 0.27686718643573055]
	TIME [epoch: 10.3 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2394296842071423		[learning rate: 0.00059011]
	Learning Rate: 0.00059011
	LOSS [training: 0.2394296842071423 | validation: 0.26894010800769963]
	TIME [epoch: 10.3 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2509612754567663		[learning rate: 0.0005883]
	Learning Rate: 0.000588302
	LOSS [training: 0.2509612754567663 | validation: 0.3378808010713423]
	TIME [epoch: 10.3 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2855237859872055		[learning rate: 0.0005865]
	Learning Rate: 0.000586498
	LOSS [training: 0.2855237859872055 | validation: 0.23198879534770853]
	TIME [epoch: 10.3 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23193679739412915		[learning rate: 0.0005847]
	Learning Rate: 0.0005847
	LOSS [training: 0.23193679739412915 | validation: 0.2671061612553043]
	TIME [epoch: 10.3 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23764516779063674		[learning rate: 0.00058291]
	Learning Rate: 0.000582908
	LOSS [training: 0.23764516779063674 | validation: 0.23441912976342155]
	TIME [epoch: 10.3 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2351302646300905		[learning rate: 0.00058112]
	Learning Rate: 0.000581121
	LOSS [training: 0.2351302646300905 | validation: 0.2893809208624387]
	TIME [epoch: 10.3 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24155460557099606		[learning rate: 0.00057934]
	Learning Rate: 0.00057934
	LOSS [training: 0.24155460557099606 | validation: 0.22853432925900685]
	TIME [epoch: 10.3 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23157339135227445		[learning rate: 0.00057756]
	Learning Rate: 0.000577564
	LOSS [training: 0.23157339135227445 | validation: 0.23955665888973607]
	TIME [epoch: 10.3 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23715845615950873		[learning rate: 0.00057579]
	Learning Rate: 0.000575793
	LOSS [training: 0.23715845615950873 | validation: 0.2371484078593602]
	TIME [epoch: 10.3 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23952636432926094		[learning rate: 0.00057403]
	Learning Rate: 0.000574028
	LOSS [training: 0.23952636432926094 | validation: 0.26941392481498466]
	TIME [epoch: 10.3 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2515363423480229		[learning rate: 0.00057227]
	Learning Rate: 0.000572269
	LOSS [training: 0.2515363423480229 | validation: 0.25231766256809307]
	TIME [epoch: 10.3 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2400597551484005		[learning rate: 0.00057051]
	Learning Rate: 0.000570514
	LOSS [training: 0.2400597551484005 | validation: 0.2657924170741954]
	TIME [epoch: 10.3 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24328113535330398		[learning rate: 0.00056877]
	Learning Rate: 0.000568766
	LOSS [training: 0.24328113535330398 | validation: 0.25124925778060475]
	TIME [epoch: 10.3 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24850031919926258		[learning rate: 0.00056702]
	Learning Rate: 0.000567022
	LOSS [training: 0.24850031919926258 | validation: 0.2516804948465661]
	TIME [epoch: 10.3 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23055095849746202		[learning rate: 0.00056528]
	Learning Rate: 0.000565284
	LOSS [training: 0.23055095849746202 | validation: 0.27279286125447116]
	TIME [epoch: 10.3 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24247938874721728		[learning rate: 0.00056355]
	Learning Rate: 0.000563551
	LOSS [training: 0.24247938874721728 | validation: 0.25246661206711873]
	TIME [epoch: 10.3 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2530672219494732		[learning rate: 0.00056182]
	Learning Rate: 0.000561824
	LOSS [training: 0.2530672219494732 | validation: 0.27122439413357513]
	TIME [epoch: 10.3 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24772718185548098		[learning rate: 0.0005601]
	Learning Rate: 0.000560101
	LOSS [training: 0.24772718185548098 | validation: 0.24955773530403977]
	TIME [epoch: 10.3 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22821814913742325		[learning rate: 0.00055838]
	Learning Rate: 0.000558385
	LOSS [training: 0.22821814913742325 | validation: 0.2584395218796993]
	TIME [epoch: 10.3 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2305869439445302		[learning rate: 0.00055667]
	Learning Rate: 0.000556673
	LOSS [training: 0.2305869439445302 | validation: 0.2320922892607616]
	TIME [epoch: 10.3 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24842651744328298		[learning rate: 0.00055497]
	Learning Rate: 0.000554966
	LOSS [training: 0.24842651744328298 | validation: 0.3402707163603905]
	TIME [epoch: 10.3 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33131327300533997		[learning rate: 0.00055327]
	Learning Rate: 0.000553265
	LOSS [training: 0.33131327300533997 | validation: 0.38154353922012874]
	TIME [epoch: 10.3 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2882304494502021		[learning rate: 0.00055157]
	Learning Rate: 0.000551569
	LOSS [training: 0.2882304494502021 | validation: 0.2547889062001143]
	TIME [epoch: 10.3 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2628490741574093		[learning rate: 0.00054988]
	Learning Rate: 0.000549878
	LOSS [training: 0.2628490741574093 | validation: 0.23390044590608622]
	TIME [epoch: 10.3 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25699902357511734		[learning rate: 0.00054819]
	Learning Rate: 0.000548193
	LOSS [training: 0.25699902357511734 | validation: 0.29568506687512286]
	TIME [epoch: 10.3 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26419379423299416		[learning rate: 0.00054651]
	Learning Rate: 0.000546512
	LOSS [training: 0.26419379423299416 | validation: 0.26150057859008735]
	TIME [epoch: 10.3 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24229290715106172		[learning rate: 0.00054484]
	Learning Rate: 0.000544837
	LOSS [training: 0.24229290715106172 | validation: 0.25619597351333623]
	TIME [epoch: 10.3 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2508773727849455		[learning rate: 0.00054317]
	Learning Rate: 0.000543167
	LOSS [training: 0.2508773727849455 | validation: 0.2574131689999685]
	TIME [epoch: 10.3 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2411681554758097		[learning rate: 0.0005415]
	Learning Rate: 0.000541502
	LOSS [training: 0.2411681554758097 | validation: 0.27456823679120523]
	TIME [epoch: 10.3 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24448034160143753		[learning rate: 0.00053984]
	Learning Rate: 0.000539842
	LOSS [training: 0.24448034160143753 | validation: 0.2714824658592906]
	TIME [epoch: 10.3 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24785907542354554		[learning rate: 0.00053819]
	Learning Rate: 0.000538187
	LOSS [training: 0.24785907542354554 | validation: 0.26741016547420565]
	TIME [epoch: 10.3 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23807533656866414		[learning rate: 0.00053654]
	Learning Rate: 0.000536537
	LOSS [training: 0.23807533656866414 | validation: 0.23239133656287664]
	TIME [epoch: 10.3 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24244890852936707		[learning rate: 0.00053489]
	Learning Rate: 0.000534893
	LOSS [training: 0.24244890852936707 | validation: 0.3194552539027675]
	TIME [epoch: 10.3 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28987967638362483		[learning rate: 0.00053325]
	Learning Rate: 0.000533253
	LOSS [training: 0.28987967638362483 | validation: 0.26465188839967246]
	TIME [epoch: 10.3 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2693328376326548		[learning rate: 0.00053162]
	Learning Rate: 0.000531618
	LOSS [training: 0.2693328376326548 | validation: 0.3767255309573584]
	TIME [epoch: 10.3 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3026385165073029		[learning rate: 0.00052999]
	Learning Rate: 0.000529989
	LOSS [training: 0.3026385165073029 | validation: 0.28728821263517085]
	TIME [epoch: 10.3 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2602297251206561		[learning rate: 0.00052836]
	Learning Rate: 0.000528364
	LOSS [training: 0.2602297251206561 | validation: 0.27168698885856996]
	TIME [epoch: 10.3 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25300259601228153		[learning rate: 0.00052674]
	Learning Rate: 0.000526744
	LOSS [training: 0.25300259601228153 | validation: 0.2619687742428373]
	TIME [epoch: 10.3 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2438451384523724		[learning rate: 0.00052513]
	Learning Rate: 0.00052513
	LOSS [training: 0.2438451384523724 | validation: 0.25037970057832587]
	TIME [epoch: 10.3 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24742691576415785		[learning rate: 0.00052352]
	Learning Rate: 0.00052352
	LOSS [training: 0.24742691576415785 | validation: 0.2539382913697755]
	TIME [epoch: 10.3 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2393992166765555		[learning rate: 0.00052192]
	Learning Rate: 0.000521915
	LOSS [training: 0.2393992166765555 | validation: 0.23106541063988545]
	TIME [epoch: 10.3 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22881864817173195		[learning rate: 0.00052032]
	Learning Rate: 0.000520315
	LOSS [training: 0.22881864817173195 | validation: 0.2590366292288961]
	TIME [epoch: 10.3 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24151542099068082		[learning rate: 0.00051872]
	Learning Rate: 0.00051872
	LOSS [training: 0.24151542099068082 | validation: 0.25403978397593285]
	TIME [epoch: 10.3 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2367134813402158		[learning rate: 0.00051713]
	Learning Rate: 0.00051713
	LOSS [training: 0.2367134813402158 | validation: 0.26337525573751414]
	TIME [epoch: 10.3 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24594054393852777		[learning rate: 0.00051555]
	Learning Rate: 0.000515545
	LOSS [training: 0.24594054393852777 | validation: 0.2542269935411752]
	TIME [epoch: 10.3 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24081779817649132		[learning rate: 0.00051396]
	Learning Rate: 0.000513965
	LOSS [training: 0.24081779817649132 | validation: 0.2837808460319836]
	TIME [epoch: 10.3 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.266205198645055		[learning rate: 0.00051239]
	Learning Rate: 0.000512389
	LOSS [training: 0.266205198645055 | validation: 0.23091414145071287]
	TIME [epoch: 10.3 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23007639550336584		[learning rate: 0.00051082]
	Learning Rate: 0.000510818
	LOSS [training: 0.23007639550336584 | validation: 0.2642616748497737]
	TIME [epoch: 10.3 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24455676598134318		[learning rate: 0.00050925]
	Learning Rate: 0.000509253
	LOSS [training: 0.24455676598134318 | validation: 0.2537107435393687]
	TIME [epoch: 10.3 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22367867691328777		[learning rate: 0.00050769]
	Learning Rate: 0.000507692
	LOSS [training: 0.22367867691328777 | validation: 0.2527719691228042]
	TIME [epoch: 10.3 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22346322356244067		[learning rate: 0.00050614]
	Learning Rate: 0.000506135
	LOSS [training: 0.22346322356244067 | validation: 0.24562856961671123]
	TIME [epoch: 10.3 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21894201029763982		[learning rate: 0.00050458]
	Learning Rate: 0.000504584
	LOSS [training: 0.21894201029763982 | validation: 0.28308372216506394]
	TIME [epoch: 10.3 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2273415918222947		[learning rate: 0.00050304]
	Learning Rate: 0.000503037
	LOSS [training: 0.2273415918222947 | validation: 0.25767424028576413]
	TIME [epoch: 10.3 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23543043384431767		[learning rate: 0.00050149]
	Learning Rate: 0.000501495
	LOSS [training: 0.23543043384431767 | validation: 0.25495856749386514]
	TIME [epoch: 10.3 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2433775957061711		[learning rate: 0.00049996]
	Learning Rate: 0.000499958
	LOSS [training: 0.2433775957061711 | validation: 0.2468908535372625]
	TIME [epoch: 10.3 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22952873449261074		[learning rate: 0.00049843]
	Learning Rate: 0.000498425
	LOSS [training: 0.22952873449261074 | validation: 0.23174457532836695]
	TIME [epoch: 10.3 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23169745205934272		[learning rate: 0.0004969]
	Learning Rate: 0.000496897
	LOSS [training: 0.23169745205934272 | validation: 0.24370807730030458]
	TIME [epoch: 10.3 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2269846859643902		[learning rate: 0.00049537]
	Learning Rate: 0.000495374
	LOSS [training: 0.2269846859643902 | validation: 0.2627137076921905]
	TIME [epoch: 10.3 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2471531569526392		[learning rate: 0.00049386]
	Learning Rate: 0.000493856
	LOSS [training: 0.2471531569526392 | validation: 0.24758463022282445]
	TIME [epoch: 10.3 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23684918394913757		[learning rate: 0.00049234]
	Learning Rate: 0.000492342
	LOSS [training: 0.23684918394913757 | validation: 0.2459875579640248]
	TIME [epoch: 10.3 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2320017263059536		[learning rate: 0.00049083]
	Learning Rate: 0.000490832
	LOSS [training: 0.2320017263059536 | validation: 0.25991927694215916]
	TIME [epoch: 10.3 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24043522849025076		[learning rate: 0.00048933]
	Learning Rate: 0.000489328
	LOSS [training: 0.24043522849025076 | validation: 0.2553662011932854]
	TIME [epoch: 10.3 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24903073082701166		[learning rate: 0.00048783]
	Learning Rate: 0.000487828
	LOSS [training: 0.24903073082701166 | validation: 0.2526848633790736]
	TIME [epoch: 10.3 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24249281673047252		[learning rate: 0.00048633]
	Learning Rate: 0.000486333
	LOSS [training: 0.24249281673047252 | validation: 0.24502818310930852]
	TIME [epoch: 10.3 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23739062929039378		[learning rate: 0.00048484]
	Learning Rate: 0.000484842
	LOSS [training: 0.23739062929039378 | validation: 0.25925486275431636]
	TIME [epoch: 10.3 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2527863903938532		[learning rate: 0.00048336]
	Learning Rate: 0.000483356
	LOSS [training: 0.2527863903938532 | validation: 0.31065772388841906]
	TIME [epoch: 10.3 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26390325821189925		[learning rate: 0.00048187]
	Learning Rate: 0.000481874
	LOSS [training: 0.26390325821189925 | validation: 0.25774266021089004]
	TIME [epoch: 10.3 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23820212820856362		[learning rate: 0.0004804]
	Learning Rate: 0.000480397
	LOSS [training: 0.23820212820856362 | validation: 0.25972464185224625]
	TIME [epoch: 10.3 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26215980149694107		[learning rate: 0.00047892]
	Learning Rate: 0.000478924
	LOSS [training: 0.26215980149694107 | validation: 0.27113965542471447]
	TIME [epoch: 10.3 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24582422983675195		[learning rate: 0.00047746]
	Learning Rate: 0.000477456
	LOSS [training: 0.24582422983675195 | validation: 0.2593536267536129]
	TIME [epoch: 10.3 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25706312779573337		[learning rate: 0.00047599]
	Learning Rate: 0.000475992
	LOSS [training: 0.25706312779573337 | validation: 0.24997880885603896]
	TIME [epoch: 10.3 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2509956358743744		[learning rate: 0.00047453]
	Learning Rate: 0.000474533
	LOSS [training: 0.2509956358743744 | validation: 0.3083718183818756]
	TIME [epoch: 10.3 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2944947400979173		[learning rate: 0.00047308]
	Learning Rate: 0.000473079
	LOSS [training: 0.2944947400979173 | validation: 0.30276867663072643]
	TIME [epoch: 10.3 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.267686573596274		[learning rate: 0.00047163]
	Learning Rate: 0.000471628
	LOSS [training: 0.267686573596274 | validation: 0.25796024101897996]
	TIME [epoch: 10.3 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26752621281895667		[learning rate: 0.00047018]
	Learning Rate: 0.000470183
	LOSS [training: 0.26752621281895667 | validation: 0.2587661034402026]
	TIME [epoch: 10.3 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24840461927650148		[learning rate: 0.00046874]
	Learning Rate: 0.000468741
	LOSS [training: 0.24840461927650148 | validation: 0.2639422093722005]
	TIME [epoch: 10.3 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24891656018357106		[learning rate: 0.0004673]
	Learning Rate: 0.000467304
	LOSS [training: 0.24891656018357106 | validation: 0.2351135522631065]
	TIME [epoch: 10.3 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23828473137030107		[learning rate: 0.00046587]
	Learning Rate: 0.000465872
	LOSS [training: 0.23828473137030107 | validation: 0.23174198488107167]
	TIME [epoch: 10.3 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23916277934914768		[learning rate: 0.00046444]
	Learning Rate: 0.000464444
	LOSS [training: 0.23916277934914768 | validation: 0.22787855291928488]
	TIME [epoch: 10.3 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2486683176348056		[learning rate: 0.00046302]
	Learning Rate: 0.00046302
	LOSS [training: 0.2486683176348056 | validation: 0.27593577811211945]
	TIME [epoch: 10.3 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26286010927293446		[learning rate: 0.0004616]
	Learning Rate: 0.000461601
	LOSS [training: 0.26286010927293446 | validation: 0.30356900752928134]
	TIME [epoch: 10.3 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2945358363503067		[learning rate: 0.00046019]
	Learning Rate: 0.000460186
	LOSS [training: 0.2945358363503067 | validation: 0.3470006407945133]
	TIME [epoch: 10.3 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27777742947733686		[learning rate: 0.00045878]
	Learning Rate: 0.000458775
	LOSS [training: 0.27777742947733686 | validation: 0.24661264380501885]
	TIME [epoch: 10.3 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2556814632673272		[learning rate: 0.00045737]
	Learning Rate: 0.000457369
	LOSS [training: 0.2556814632673272 | validation: 0.35333112961774804]
	TIME [epoch: 10.3 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2830827534412537		[learning rate: 0.00045597]
	Learning Rate: 0.000455967
	LOSS [training: 0.2830827534412537 | validation: 0.2660579832925092]
	TIME [epoch: 10.3 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24092200888820464		[learning rate: 0.00045457]
	Learning Rate: 0.000454569
	LOSS [training: 0.24092200888820464 | validation: 0.2350923219136594]
	TIME [epoch: 10.3 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22266685478972784		[learning rate: 0.00045318]
	Learning Rate: 0.000453176
	LOSS [training: 0.22266685478972784 | validation: 0.2549701014306675]
	TIME [epoch: 10.3 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2881418777602539		[learning rate: 0.00045179]
	Learning Rate: 0.000451787
	LOSS [training: 0.2881418777602539 | validation: 0.26304808254341716]
	TIME [epoch: 10.3 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22484671333880346		[learning rate: 0.0004504]
	Learning Rate: 0.000450402
	LOSS [training: 0.22484671333880346 | validation: 0.23548538701262903]
	TIME [epoch: 10.3 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2138345567859715		[learning rate: 0.00044902]
	Learning Rate: 0.000449021
	LOSS [training: 0.2138345567859715 | validation: 0.22951556594674694]
	TIME [epoch: 10.3 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22218269627912163		[learning rate: 0.00044764]
	Learning Rate: 0.000447645
	LOSS [training: 0.22218269627912163 | validation: 0.24493820508235054]
	TIME [epoch: 10.3 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22147597002053465		[learning rate: 0.00044627]
	Learning Rate: 0.000446272
	LOSS [training: 0.22147597002053465 | validation: 0.2269198439392166]
	TIME [epoch: 10.3 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2446243508216198		[learning rate: 0.0004449]
	Learning Rate: 0.000444904
	LOSS [training: 0.2446243508216198 | validation: 0.23649577849697118]
	TIME [epoch: 10.3 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21841246981037946		[learning rate: 0.00044354]
	Learning Rate: 0.000443541
	LOSS [training: 0.21841246981037946 | validation: 0.24087011394176977]
	TIME [epoch: 10.3 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21588034189111252		[learning rate: 0.00044218]
	Learning Rate: 0.000442181
	LOSS [training: 0.21588034189111252 | validation: 0.21001747171529503]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1516.pth
	Model improved!!!
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2143017741906244		[learning rate: 0.00044083]
	Learning Rate: 0.000440825
	LOSS [training: 0.2143017741906244 | validation: 0.23238571793207785]
	TIME [epoch: 10.3 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2271730840875273		[learning rate: 0.00043947]
	Learning Rate: 0.000439474
	LOSS [training: 0.2271730840875273 | validation: 0.23424613783895445]
	TIME [epoch: 10.3 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2712178833362572		[learning rate: 0.00043813]
	Learning Rate: 0.000438127
	LOSS [training: 0.2712178833362572 | validation: 0.3073669544208327]
	TIME [epoch: 10.3 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26052036901176623		[learning rate: 0.00043678]
	Learning Rate: 0.000436784
	LOSS [training: 0.26052036901176623 | validation: 0.27451690218979435]
	TIME [epoch: 10.3 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23207810495917963		[learning rate: 0.00043544]
	Learning Rate: 0.000435445
	LOSS [training: 0.23207810495917963 | validation: 0.32132910603369463]
	TIME [epoch: 10.3 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26795118504986787		[learning rate: 0.00043411]
	Learning Rate: 0.00043411
	LOSS [training: 0.26795118504986787 | validation: 0.24281686141818898]
	TIME [epoch: 10.3 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22385241096490066		[learning rate: 0.00043278]
	Learning Rate: 0.00043278
	LOSS [training: 0.22385241096490066 | validation: 0.220201913038464]
	TIME [epoch: 10.3 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23343342941920237		[learning rate: 0.00043145]
	Learning Rate: 0.000431453
	LOSS [training: 0.23343342941920237 | validation: 0.23946716860614936]
	TIME [epoch: 10.3 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22743913860633524		[learning rate: 0.00043013]
	Learning Rate: 0.00043013
	LOSS [training: 0.22743913860633524 | validation: 0.2306159027304902]
	TIME [epoch: 10.3 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23365013865885448		[learning rate: 0.00042881]
	Learning Rate: 0.000428812
	LOSS [training: 0.23365013865885448 | validation: 0.25783972138650735]
	TIME [epoch: 10.3 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23872059168411947		[learning rate: 0.0004275]
	Learning Rate: 0.000427497
	LOSS [training: 0.23872059168411947 | validation: 0.26566207840976147]
	TIME [epoch: 10.3 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22856189541688948		[learning rate: 0.00042619]
	Learning Rate: 0.000426187
	LOSS [training: 0.22856189541688948 | validation: 0.2348582034758654]
	TIME [epoch: 10.3 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2126224668754595		[learning rate: 0.00042488]
	Learning Rate: 0.00042488
	LOSS [training: 0.2126224668754595 | validation: 0.262686411541531]
	TIME [epoch: 10.3 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.254980856559836		[learning rate: 0.00042358]
	Learning Rate: 0.000423578
	LOSS [training: 0.254980856559836 | validation: 0.27299883432324107]
	TIME [epoch: 10.3 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23060242541495496		[learning rate: 0.00042228]
	Learning Rate: 0.000422279
	LOSS [training: 0.23060242541495496 | validation: 0.23487921131287925]
	TIME [epoch: 10.3 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21455691301915764		[learning rate: 0.00042098]
	Learning Rate: 0.000420985
	LOSS [training: 0.21455691301915764 | validation: 0.22053572122883505]
	TIME [epoch: 10.3 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22381205289761108		[learning rate: 0.00041969]
	Learning Rate: 0.000419694
	LOSS [training: 0.22381205289761108 | validation: 0.22123001508161239]
	TIME [epoch: 10.3 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21311661347202385		[learning rate: 0.00041841]
	Learning Rate: 0.000418408
	LOSS [training: 0.21311661347202385 | validation: 0.24274123255682037]
	TIME [epoch: 10.3 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21537216778685792		[learning rate: 0.00041713]
	Learning Rate: 0.000417125
	LOSS [training: 0.21537216778685792 | validation: 0.2085250699172007]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1535.pth
	Model improved!!!
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20386914850294663		[learning rate: 0.00041585]
	Learning Rate: 0.000415847
	LOSS [training: 0.20386914850294663 | validation: 0.2389628674710441]
	TIME [epoch: 10.3 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2215965441166848		[learning rate: 0.00041457]
	Learning Rate: 0.000414572
	LOSS [training: 0.2215965441166848 | validation: 0.2394997154874546]
	TIME [epoch: 10.3 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20956204476095489		[learning rate: 0.0004133]
	Learning Rate: 0.000413301
	LOSS [training: 0.20956204476095489 | validation: 0.22749379781448426]
	TIME [epoch: 10.3 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2166726737560185		[learning rate: 0.00041203]
	Learning Rate: 0.000412034
	LOSS [training: 0.2166726737560185 | validation: 0.2231563934341062]
	TIME [epoch: 10.3 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22079031464445947		[learning rate: 0.00041077]
	Learning Rate: 0.000410771
	LOSS [training: 0.22079031464445947 | validation: 0.25791792319652]
	TIME [epoch: 10.3 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23401177865441136		[learning rate: 0.00040951]
	Learning Rate: 0.000409512
	LOSS [training: 0.23401177865441136 | validation: 0.23518822883057147]
	TIME [epoch: 10.3 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24858345637500304		[learning rate: 0.00040826]
	Learning Rate: 0.000408257
	LOSS [training: 0.24858345637500304 | validation: 0.3137056294877973]
	TIME [epoch: 10.3 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25964571304054884		[learning rate: 0.00040701]
	Learning Rate: 0.000407005
	LOSS [training: 0.25964571304054884 | validation: 0.24472909990528396]
	TIME [epoch: 10.3 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22739629327280203		[learning rate: 0.00040576]
	Learning Rate: 0.000405758
	LOSS [training: 0.22739629327280203 | validation: 0.24564548931916505]
	TIME [epoch: 10.3 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22518484829095603		[learning rate: 0.00040451]
	Learning Rate: 0.000404514
	LOSS [training: 0.22518484829095603 | validation: 0.27758860910339767]
	TIME [epoch: 10.3 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2513007321049186		[learning rate: 0.00040327]
	Learning Rate: 0.000403274
	LOSS [training: 0.2513007321049186 | validation: 0.2502155152403318]
	TIME [epoch: 10.3 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22307214952138815		[learning rate: 0.00040204]
	Learning Rate: 0.000402038
	LOSS [training: 0.22307214952138815 | validation: 0.22116438193473031]
	TIME [epoch: 10.3 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21620128255760956		[learning rate: 0.00040081]
	Learning Rate: 0.000400805
	LOSS [training: 0.21620128255760956 | validation: 0.23492697727113077]
	TIME [epoch: 10.3 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23509664807400815		[learning rate: 0.00039958]
	Learning Rate: 0.000399577
	LOSS [training: 0.23509664807400815 | validation: 0.25014006805707434]
	TIME [epoch: 10.3 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2237061872006283		[learning rate: 0.00039835]
	Learning Rate: 0.000398352
	LOSS [training: 0.2237061872006283 | validation: 0.24017586136368244]
	TIME [epoch: 10.3 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22303330627299373		[learning rate: 0.00039713]
	Learning Rate: 0.000397131
	LOSS [training: 0.22303330627299373 | validation: 0.21865677971031172]
	TIME [epoch: 10.3 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21826034851003567		[learning rate: 0.00039591]
	Learning Rate: 0.000395913
	LOSS [training: 0.21826034851003567 | validation: 0.2244164559685291]
	TIME [epoch: 10.3 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23566546056607587		[learning rate: 0.0003947]
	Learning Rate: 0.0003947
	LOSS [training: 0.23566546056607587 | validation: 0.32717997923627073]
	TIME [epoch: 10.3 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32132894066676077		[learning rate: 0.00039349]
	Learning Rate: 0.00039349
	LOSS [training: 0.32132894066676077 | validation: 0.4327432267839433]
	TIME [epoch: 10.3 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4205719001117852		[learning rate: 0.00039228]
	Learning Rate: 0.000392283
	LOSS [training: 0.4205719001117852 | validation: 0.5796718507213958]
	TIME [epoch: 10.3 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4071138646281173		[learning rate: 0.00039108]
	Learning Rate: 0.000391081
	LOSS [training: 0.4071138646281173 | validation: 0.3016888221727566]
	TIME [epoch: 10.3 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26301442663457125		[learning rate: 0.00038988]
	Learning Rate: 0.000389882
	LOSS [training: 0.26301442663457125 | validation: 0.2704272916982099]
	TIME [epoch: 10.3 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24190800576215477		[learning rate: 0.00038869]
	Learning Rate: 0.000388687
	LOSS [training: 0.24190800576215477 | validation: 0.2756537676246306]
	TIME [epoch: 10.3 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2688923388275364		[learning rate: 0.0003875]
	Learning Rate: 0.000387495
	LOSS [training: 0.2688923388275364 | validation: 0.27991540515506125]
	TIME [epoch: 10.3 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24307167050720152		[learning rate: 0.00038631]
	Learning Rate: 0.000386308
	LOSS [training: 0.24307167050720152 | validation: 0.27549399803044095]
	TIME [epoch: 10.3 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2642661343813624		[learning rate: 0.00038512]
	Learning Rate: 0.000385123
	LOSS [training: 0.2642661343813624 | validation: 0.285163417162932]
	TIME [epoch: 10.3 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25639527467193696		[learning rate: 0.00038394]
	Learning Rate: 0.000383943
	LOSS [training: 0.25639527467193696 | validation: 0.28452481923720657]
	TIME [epoch: 10.3 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2394958821479117		[learning rate: 0.00038277]
	Learning Rate: 0.000382766
	LOSS [training: 0.2394958821479117 | validation: 0.22706766320951613]
	TIME [epoch: 10.3 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22627161337757057		[learning rate: 0.00038159]
	Learning Rate: 0.000381593
	LOSS [training: 0.22627161337757057 | validation: 0.23244702789423305]
	TIME [epoch: 10.3 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23408401872898493		[learning rate: 0.00038042]
	Learning Rate: 0.000380423
	LOSS [training: 0.23408401872898493 | validation: 0.3100175491414115]
	TIME [epoch: 10.3 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2591463593871235		[learning rate: 0.00037926]
	Learning Rate: 0.000379257
	LOSS [training: 0.2591463593871235 | validation: 0.2559508928408987]
	TIME [epoch: 10.3 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22624608185327033		[learning rate: 0.00037809]
	Learning Rate: 0.000378094
	LOSS [training: 0.22624608185327033 | validation: 0.2346172062987233]
	TIME [epoch: 10.3 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23032536405520432		[learning rate: 0.00037694]
	Learning Rate: 0.000376935
	LOSS [training: 0.23032536405520432 | validation: 0.23489987293807402]
	TIME [epoch: 10.3 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23011751900238378		[learning rate: 0.00037578]
	Learning Rate: 0.00037578
	LOSS [training: 0.23011751900238378 | validation: 0.2290811141346476]
	TIME [epoch: 10.3 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2274849601707225		[learning rate: 0.00037463]
	Learning Rate: 0.000374628
	LOSS [training: 0.2274849601707225 | validation: 0.22867492061845887]
	TIME [epoch: 10.3 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23034664110735087		[learning rate: 0.00037348]
	Learning Rate: 0.000373479
	LOSS [training: 0.23034664110735087 | validation: 0.23586405546466174]
	TIME [epoch: 10.3 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21540375813313353		[learning rate: 0.00037233]
	Learning Rate: 0.000372335
	LOSS [training: 0.21540375813313353 | validation: 0.2329104903247234]
	TIME [epoch: 10.3 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21603772780141348		[learning rate: 0.00037119]
	Learning Rate: 0.000371193
	LOSS [training: 0.21603772780141348 | validation: 0.21711241532432396]
	TIME [epoch: 10.3 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21565788228119104		[learning rate: 0.00037006]
	Learning Rate: 0.000370055
	LOSS [training: 0.21565788228119104 | validation: 0.22411605708424673]
	TIME [epoch: 10.3 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2303013330750232		[learning rate: 0.00036892]
	Learning Rate: 0.000368921
	LOSS [training: 0.2303013330750232 | validation: 0.28032580908259347]
	TIME [epoch: 10.3 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22589478769219146		[learning rate: 0.00036779]
	Learning Rate: 0.00036779
	LOSS [training: 0.22589478769219146 | validation: 0.22269949679448048]
	TIME [epoch: 10.3 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21142854650125625		[learning rate: 0.00036666]
	Learning Rate: 0.000366663
	LOSS [training: 0.21142854650125625 | validation: 0.21321632079085973]
	TIME [epoch: 10.3 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19981481439492893		[learning rate: 0.00036554]
	Learning Rate: 0.000365539
	LOSS [training: 0.19981481439492893 | validation: 0.22815806061068933]
	TIME [epoch: 10.3 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20234585321167517		[learning rate: 0.00036442]
	Learning Rate: 0.000364418
	LOSS [training: 0.20234585321167517 | validation: 0.20750795509266026]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1579.pth
	Model improved!!!
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20806065768749962		[learning rate: 0.0003633]
	Learning Rate: 0.000363301
	LOSS [training: 0.20806065768749962 | validation: 0.21837266160053836]
	TIME [epoch: 10.3 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22064710001620677		[learning rate: 0.00036219]
	Learning Rate: 0.000362187
	LOSS [training: 0.22064710001620677 | validation: 0.22667929756103783]
	TIME [epoch: 10.3 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21313466601106984		[learning rate: 0.00036108]
	Learning Rate: 0.000361077
	LOSS [training: 0.21313466601106984 | validation: 0.2399022864919829]
	TIME [epoch: 10.3 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21628187282356928		[learning rate: 0.00035997]
	Learning Rate: 0.00035997
	LOSS [training: 0.21628187282356928 | validation: 0.22149461120956726]
	TIME [epoch: 10.3 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21746462859277288		[learning rate: 0.00035887]
	Learning Rate: 0.000358867
	LOSS [training: 0.21746462859277288 | validation: 0.24306860876994715]
	TIME [epoch: 10.3 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22821975775616488		[learning rate: 0.00035777]
	Learning Rate: 0.000357767
	LOSS [training: 0.22821975775616488 | validation: 0.24045476014102932]
	TIME [epoch: 10.3 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21625268009215173		[learning rate: 0.00035667]
	Learning Rate: 0.00035667
	LOSS [training: 0.21625268009215173 | validation: 0.22292512275054205]
	TIME [epoch: 10.3 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21325907051220744		[learning rate: 0.00035558]
	Learning Rate: 0.000355577
	LOSS [training: 0.21325907051220744 | validation: 0.23015365612305427]
	TIME [epoch: 10.3 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22277616994829566		[learning rate: 0.00035449]
	Learning Rate: 0.000354487
	LOSS [training: 0.22277616994829566 | validation: 0.2561881539226111]
	TIME [epoch: 10.3 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23490401242413358		[learning rate: 0.0003534]
	Learning Rate: 0.0003534
	LOSS [training: 0.23490401242413358 | validation: 0.22451258838225396]
	TIME [epoch: 10.3 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21103782410977576		[learning rate: 0.00035232]
	Learning Rate: 0.000352317
	LOSS [training: 0.21103782410977576 | validation: 0.2147561907228487]
	TIME [epoch: 10.3 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21326266454574636		[learning rate: 0.00035124]
	Learning Rate: 0.000351237
	LOSS [training: 0.21326266454574636 | validation: 0.2375491081067575]
	TIME [epoch: 10.3 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20913035353869805		[learning rate: 0.00035016]
	Learning Rate: 0.00035016
	LOSS [training: 0.20913035353869805 | validation: 0.22549277263461048]
	TIME [epoch: 10.3 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21696870153963163		[learning rate: 0.00034909]
	Learning Rate: 0.000349087
	LOSS [training: 0.21696870153963163 | validation: 0.20725669221060883]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1593.pth
	Model improved!!!
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20919381623909747		[learning rate: 0.00034802]
	Learning Rate: 0.000348017
	LOSS [training: 0.20919381623909747 | validation: 0.20878702819492317]
	TIME [epoch: 10.3 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2055150937226224		[learning rate: 0.00034695]
	Learning Rate: 0.00034695
	LOSS [training: 0.2055150937226224 | validation: 0.20902025175749184]
	TIME [epoch: 10.3 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21286922410765996		[learning rate: 0.00034589]
	Learning Rate: 0.000345886
	LOSS [training: 0.21286922410765996 | validation: 0.21683948907925626]
	TIME [epoch: 10.3 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2074206732211318		[learning rate: 0.00034483]
	Learning Rate: 0.000344826
	LOSS [training: 0.2074206732211318 | validation: 0.21313361810108902]
	TIME [epoch: 10.3 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2098223376857801		[learning rate: 0.00034377]
	Learning Rate: 0.000343769
	LOSS [training: 0.2098223376857801 | validation: 0.22741763610768612]
	TIME [epoch: 10.3 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20266668634117835		[learning rate: 0.00034272]
	Learning Rate: 0.000342715
	LOSS [training: 0.20266668634117835 | validation: 0.22361456952192715]
	TIME [epoch: 10.3 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20536564640768415		[learning rate: 0.00034166]
	Learning Rate: 0.000341665
	LOSS [training: 0.20536564640768415 | validation: 0.22752628592135743]
	TIME [epoch: 10.3 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21566837481815027		[learning rate: 0.00034062]
	Learning Rate: 0.000340617
	LOSS [training: 0.21566837481815027 | validation: 0.19692537459056966]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1601.pth
	Model improved!!!
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20322570512045926		[learning rate: 0.00033957]
	Learning Rate: 0.000339573
	LOSS [training: 0.20322570512045926 | validation: 0.21833117872735963]
	TIME [epoch: 10.3 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20831512367404442		[learning rate: 0.00033853]
	Learning Rate: 0.000338532
	LOSS [training: 0.20831512367404442 | validation: 0.2207503981837344]
	TIME [epoch: 10.3 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2104157113668308		[learning rate: 0.00033749]
	Learning Rate: 0.000337494
	LOSS [training: 0.2104157113668308 | validation: 0.2579978060610884]
	TIME [epoch: 10.3 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2410839041127498		[learning rate: 0.00033646]
	Learning Rate: 0.00033646
	LOSS [training: 0.2410839041127498 | validation: 0.27912770643023055]
	TIME [epoch: 10.3 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2713355486484958		[learning rate: 0.00033543]
	Learning Rate: 0.000335428
	LOSS [training: 0.2713355486484958 | validation: 0.2748174123823936]
	TIME [epoch: 10.3 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24156741423404865		[learning rate: 0.0003344]
	Learning Rate: 0.0003344
	LOSS [training: 0.24156741423404865 | validation: 0.19603954477068475]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1607.pth
	Model improved!!!
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2048128723292443		[learning rate: 0.00033338]
	Learning Rate: 0.000333375
	LOSS [training: 0.2048128723292443 | validation: 0.21881148799999828]
	TIME [epoch: 10.3 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2129865050482238		[learning rate: 0.00033235]
	Learning Rate: 0.000332353
	LOSS [training: 0.2129865050482238 | validation: 0.21077109930831625]
	TIME [epoch: 10.3 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21800681842864406		[learning rate: 0.00033133]
	Learning Rate: 0.000331334
	LOSS [training: 0.21800681842864406 | validation: 0.24359352074647522]
	TIME [epoch: 10.3 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20981693180809122		[learning rate: 0.00033032]
	Learning Rate: 0.000330319
	LOSS [training: 0.20981693180809122 | validation: 0.23377130635769697]
	TIME [epoch: 10.3 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22619191626287213		[learning rate: 0.00032931]
	Learning Rate: 0.000329306
	LOSS [training: 0.22619191626287213 | validation: 0.2253321721460118]
	TIME [epoch: 10.3 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21587266520720155		[learning rate: 0.0003283]
	Learning Rate: 0.000328297
	LOSS [training: 0.21587266520720155 | validation: 0.230761102325919]
	TIME [epoch: 10.3 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2055037437483961		[learning rate: 0.00032729]
	Learning Rate: 0.00032729
	LOSS [training: 0.2055037437483961 | validation: 0.2095870362635381]
	TIME [epoch: 10.3 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21561151580291252		[learning rate: 0.00032629]
	Learning Rate: 0.000326287
	LOSS [training: 0.21561151580291252 | validation: 0.22086322537318828]
	TIME [epoch: 10.3 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2286400521882757		[learning rate: 0.00032529]
	Learning Rate: 0.000325287
	LOSS [training: 0.2286400521882757 | validation: 0.2842474185664449]
	TIME [epoch: 10.3 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23289005293260162		[learning rate: 0.00032429]
	Learning Rate: 0.00032429
	LOSS [training: 0.23289005293260162 | validation: 0.2437612504588735]
	TIME [epoch: 10.3 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2105905149700494		[learning rate: 0.0003233]
	Learning Rate: 0.000323296
	LOSS [training: 0.2105905149700494 | validation: 0.24968031106459251]
	TIME [epoch: 10.3 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22177552033519315		[learning rate: 0.0003223]
	Learning Rate: 0.000322305
	LOSS [training: 0.22177552033519315 | validation: 0.2185135880787587]
	TIME [epoch: 10.3 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20548468594926175		[learning rate: 0.00032132]
	Learning Rate: 0.000321317
	LOSS [training: 0.20548468594926175 | validation: 0.22756117902890707]
	TIME [epoch: 10.3 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20946175177919465		[learning rate: 0.00032033]
	Learning Rate: 0.000320332
	LOSS [training: 0.20946175177919465 | validation: 0.22725057126028542]
	TIME [epoch: 10.3 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20933111513725694		[learning rate: 0.00031935]
	Learning Rate: 0.00031935
	LOSS [training: 0.20933111513725694 | validation: 0.23126124831433842]
	TIME [epoch: 10.3 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.200545107102516		[learning rate: 0.00031837]
	Learning Rate: 0.000318371
	LOSS [training: 0.200545107102516 | validation: 0.23344010553745506]
	TIME [epoch: 10.3 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2144916040812185		[learning rate: 0.00031739]
	Learning Rate: 0.000317395
	LOSS [training: 0.2144916040812185 | validation: 0.2738797016857494]
	TIME [epoch: 10.3 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22033922950530052		[learning rate: 0.00031642]
	Learning Rate: 0.000316422
	LOSS [training: 0.22033922950530052 | validation: 0.23660389898994014]
	TIME [epoch: 10.3 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2070966778325875		[learning rate: 0.00031545]
	Learning Rate: 0.000315452
	LOSS [training: 0.2070966778325875 | validation: 0.21877940742824822]
	TIME [epoch: 10.3 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21195753185227928		[learning rate: 0.00031449]
	Learning Rate: 0.000314485
	LOSS [training: 0.21195753185227928 | validation: 0.26173005358603535]
	TIME [epoch: 10.3 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2357550192946097		[learning rate: 0.00031352]
	Learning Rate: 0.000313521
	LOSS [training: 0.2357550192946097 | validation: 0.24686600892943014]
	TIME [epoch: 10.3 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21350253981083359		[learning rate: 0.00031256]
	Learning Rate: 0.00031256
	LOSS [training: 0.21350253981083359 | validation: 0.22796088647073848]
	TIME [epoch: 10.3 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21786570941186426		[learning rate: 0.0003116]
	Learning Rate: 0.000311602
	LOSS [training: 0.21786570941186426 | validation: 0.22094367166265186]
	TIME [epoch: 10.3 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22976687308479588		[learning rate: 0.00031065]
	Learning Rate: 0.000310647
	LOSS [training: 0.22976687308479588 | validation: 0.22358947885564298]
	TIME [epoch: 10.3 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20572019908518988		[learning rate: 0.00030969]
	Learning Rate: 0.000309694
	LOSS [training: 0.20572019908518988 | validation: 0.2189412637522792]
	TIME [epoch: 10.3 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.206928147216649		[learning rate: 0.00030874]
	Learning Rate: 0.000308745
	LOSS [training: 0.206928147216649 | validation: 0.23736105726835646]
	TIME [epoch: 10.3 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20006792486449038		[learning rate: 0.0003078]
	Learning Rate: 0.000307799
	LOSS [training: 0.20006792486449038 | validation: 0.21914702942987369]
	TIME [epoch: 10.3 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20768963256682388		[learning rate: 0.00030686]
	Learning Rate: 0.000306855
	LOSS [training: 0.20768963256682388 | validation: 0.22333615718258906]
	TIME [epoch: 10.3 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20061576574791334		[learning rate: 0.00030591]
	Learning Rate: 0.000305914
	LOSS [training: 0.20061576574791334 | validation: 0.20840427183748886]
	TIME [epoch: 10.3 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21240159310159465		[learning rate: 0.00030498]
	Learning Rate: 0.000304977
	LOSS [training: 0.21240159310159465 | validation: 0.25702803564265475]
	TIME [epoch: 10.3 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21615669638223958		[learning rate: 0.00030404]
	Learning Rate: 0.000304042
	LOSS [training: 0.21615669638223958 | validation: 0.22624710839899917]
	TIME [epoch: 10.3 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1925294575262641		[learning rate: 0.00030311]
	Learning Rate: 0.00030311
	LOSS [training: 0.1925294575262641 | validation: 0.22497660997736696]
	TIME [epoch: 10.3 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1999580846310556		[learning rate: 0.00030218]
	Learning Rate: 0.000302181
	LOSS [training: 0.1999580846310556 | validation: 0.20692892634905596]
	TIME [epoch: 10.3 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20301676352927606		[learning rate: 0.00030125]
	Learning Rate: 0.000301254
	LOSS [training: 0.20301676352927606 | validation: 0.22226944850282912]
	TIME [epoch: 10.3 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20912227437252523		[learning rate: 0.00030033]
	Learning Rate: 0.000300331
	LOSS [training: 0.20912227437252523 | validation: 0.21210121049265362]
	TIME [epoch: 10.3 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21343537929444406		[learning rate: 0.00029941]
	Learning Rate: 0.00029941
	LOSS [training: 0.21343537929444406 | validation: 0.20995131397495714]
	TIME [epoch: 10.3 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2080289315805603		[learning rate: 0.00029849]
	Learning Rate: 0.000298492
	LOSS [training: 0.2080289315805603 | validation: 0.21545402920118434]
	TIME [epoch: 10.3 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20561257189989451		[learning rate: 0.00029758]
	Learning Rate: 0.000297577
	LOSS [training: 0.20561257189989451 | validation: 0.20602133338672854]
	TIME [epoch: 10.3 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2062895504139369		[learning rate: 0.00029667]
	Learning Rate: 0.000296665
	LOSS [training: 0.2062895504139369 | validation: 0.21696663196682106]
	TIME [epoch: 10.3 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20865114389466433		[learning rate: 0.00029576]
	Learning Rate: 0.000295756
	LOSS [training: 0.20865114389466433 | validation: 0.22277092250975952]
	TIME [epoch: 10.3 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2075933311217284		[learning rate: 0.00029485]
	Learning Rate: 0.000294849
	LOSS [training: 0.2075933311217284 | validation: 0.23283960978829263]
	TIME [epoch: 10.3 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21975521439153495		[learning rate: 0.00029395]
	Learning Rate: 0.000293945
	LOSS [training: 0.21975521439153495 | validation: 0.21958617076208]
	TIME [epoch: 10.3 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21390132973602372		[learning rate: 0.00029304]
	Learning Rate: 0.000293044
	LOSS [training: 0.21390132973602372 | validation: 0.228225265483496]
	TIME [epoch: 10.3 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21770781148270718		[learning rate: 0.00029215]
	Learning Rate: 0.000292146
	LOSS [training: 0.21770781148270718 | validation: 0.2554697778628394]
	TIME [epoch: 10.3 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23878628161657378		[learning rate: 0.00029125]
	Learning Rate: 0.00029125
	LOSS [training: 0.23878628161657378 | validation: 0.23596448427956862]
	TIME [epoch: 10.3 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21468191255611696		[learning rate: 0.00029036]
	Learning Rate: 0.000290358
	LOSS [training: 0.21468191255611696 | validation: 0.21548529805338568]
	TIME [epoch: 10.3 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21850343409257417		[learning rate: 0.00028947]
	Learning Rate: 0.000289468
	LOSS [training: 0.21850343409257417 | validation: 0.2148323952365306]
	TIME [epoch: 10.3 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22249657995565447		[learning rate: 0.00028858]
	Learning Rate: 0.00028858
	LOSS [training: 0.22249657995565447 | validation: 0.24766873258147037]
	TIME [epoch: 10.3 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21756390581319307		[learning rate: 0.0002877]
	Learning Rate: 0.000287696
	LOSS [training: 0.21756390581319307 | validation: 0.21916567093579736]
	TIME [epoch: 10.3 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20838418742943832		[learning rate: 0.00028681]
	Learning Rate: 0.000286814
	LOSS [training: 0.20838418742943832 | validation: 0.2147615361111148]
	TIME [epoch: 10.3 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21870634107245085		[learning rate: 0.00028593]
	Learning Rate: 0.000285935
	LOSS [training: 0.21870634107245085 | validation: 0.2213877849138269]
	TIME [epoch: 10.3 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2034540507088451		[learning rate: 0.00028506]
	Learning Rate: 0.000285058
	LOSS [training: 0.2034540507088451 | validation: 0.21600294895007202]
	TIME [epoch: 10.3 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20053463211096806		[learning rate: 0.00028418]
	Learning Rate: 0.000284184
	LOSS [training: 0.20053463211096806 | validation: 0.19940106767800067]
	TIME [epoch: 10.3 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20348968720849064		[learning rate: 0.00028331]
	Learning Rate: 0.000283313
	LOSS [training: 0.20348968720849064 | validation: 0.2261212158904074]
	TIME [epoch: 10.3 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20459470135749683		[learning rate: 0.00028244]
	Learning Rate: 0.000282445
	LOSS [training: 0.20459470135749683 | validation: 0.2246960936247827]
	TIME [epoch: 10.3 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20454238456947502		[learning rate: 0.00028158]
	Learning Rate: 0.000281579
	LOSS [training: 0.20454238456947502 | validation: 0.21292602992217952]
	TIME [epoch: 10.3 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20361022657816408		[learning rate: 0.00028072]
	Learning Rate: 0.000280716
	LOSS [training: 0.20361022657816408 | validation: 0.21237606817635246]
	TIME [epoch: 10.3 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20162000168194966		[learning rate: 0.00027986]
	Learning Rate: 0.000279855
	LOSS [training: 0.20162000168194966 | validation: 0.21582513899347042]
	TIME [epoch: 10.3 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20502588907406866		[learning rate: 0.000279]
	Learning Rate: 0.000278997
	LOSS [training: 0.20502588907406866 | validation: 0.2338169888432119]
	TIME [epoch: 10.3 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21325004355855331		[learning rate: 0.00027814]
	Learning Rate: 0.000278142
	LOSS [training: 0.21325004355855331 | validation: 0.2175036154804123]
	TIME [epoch: 10.3 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20969671504282114		[learning rate: 0.00027729]
	Learning Rate: 0.000277289
	LOSS [training: 0.20969671504282114 | validation: 0.2165394122264341]
	TIME [epoch: 10.3 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19987149882155025		[learning rate: 0.00027644]
	Learning Rate: 0.000276439
	LOSS [training: 0.19987149882155025 | validation: 0.22516681538879063]
	TIME [epoch: 10.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21327144603020315		[learning rate: 0.00027559]
	Learning Rate: 0.000275592
	LOSS [training: 0.21327144603020315 | validation: 0.23144322723815414]
	TIME [epoch: 10.3 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21042231933885275		[learning rate: 0.00027475]
	Learning Rate: 0.000274747
	LOSS [training: 0.21042231933885275 | validation: 0.2153697341139776]
	TIME [epoch: 10.3 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22820402082227073		[learning rate: 0.00027391]
	Learning Rate: 0.000273905
	LOSS [training: 0.22820402082227073 | validation: 0.2838084083164494]
	TIME [epoch: 10.3 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2416851893300865		[learning rate: 0.00027307]
	Learning Rate: 0.000273065
	LOSS [training: 0.2416851893300865 | validation: 0.22682844188112414]
	TIME [epoch: 10.3 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2039240180501564		[learning rate: 0.00027223]
	Learning Rate: 0.000272228
	LOSS [training: 0.2039240180501564 | validation: 0.22768810240477574]
	TIME [epoch: 10.3 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20724833820783206		[learning rate: 0.00027139]
	Learning Rate: 0.000271394
	LOSS [training: 0.20724833820783206 | validation: 0.22096198236991452]
	TIME [epoch: 10.3 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20827549887057817		[learning rate: 0.00027056]
	Learning Rate: 0.000270562
	LOSS [training: 0.20827549887057817 | validation: 0.22023305704292767]
	TIME [epoch: 10.3 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21275083779113807		[learning rate: 0.00026973]
	Learning Rate: 0.000269733
	LOSS [training: 0.21275083779113807 | validation: 0.25733373434892526]
	TIME [epoch: 10.3 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24724974591979237		[learning rate: 0.00026891]
	Learning Rate: 0.000268906
	LOSS [training: 0.24724974591979237 | validation: 0.2586506259401904]
	TIME [epoch: 10.3 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21830511798810376		[learning rate: 0.00026808]
	Learning Rate: 0.000268081
	LOSS [training: 0.21830511798810376 | validation: 0.21900009569888246]
	TIME [epoch: 10.3 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20826752623564698		[learning rate: 0.00026726]
	Learning Rate: 0.00026726
	LOSS [training: 0.20826752623564698 | validation: 0.22447537564279324]
	TIME [epoch: 10.3 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21116340777933668		[learning rate: 0.00026644]
	Learning Rate: 0.00026644
	LOSS [training: 0.21116340777933668 | validation: 0.25419142311886467]
	TIME [epoch: 10.3 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2118860530919834		[learning rate: 0.00026562]
	Learning Rate: 0.000265624
	LOSS [training: 0.2118860530919834 | validation: 0.24255584205849803]
	TIME [epoch: 10.3 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25225187572067964		[learning rate: 0.00026481]
	Learning Rate: 0.000264809
	LOSS [training: 0.25225187572067964 | validation: 0.2548768086387863]
	TIME [epoch: 10.3 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20996641247701797		[learning rate: 0.000264]
	Learning Rate: 0.000263998
	LOSS [training: 0.20996641247701797 | validation: 0.22299000762622975]
	TIME [epoch: 10.3 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20980052882062283		[learning rate: 0.00026319]
	Learning Rate: 0.000263188
	LOSS [training: 0.20980052882062283 | validation: 0.21873863672837376]
	TIME [epoch: 10.3 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2226285070338903		[learning rate: 0.00026238]
	Learning Rate: 0.000262382
	LOSS [training: 0.2226285070338903 | validation: 0.24662018445883185]
	TIME [epoch: 10.3 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2151237397479575		[learning rate: 0.00026158]
	Learning Rate: 0.000261577
	LOSS [training: 0.2151237397479575 | validation: 0.22719819389235582]
	TIME [epoch: 10.3 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21089684207714615		[learning rate: 0.00026078]
	Learning Rate: 0.000260775
	LOSS [training: 0.21089684207714615 | validation: 0.23159038988878464]
	TIME [epoch: 10.3 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2110572576881872		[learning rate: 0.00025998]
	Learning Rate: 0.000259976
	LOSS [training: 0.2110572576881872 | validation: 0.24366486776194937]
	TIME [epoch: 10.3 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2056369656301916		[learning rate: 0.00025918]
	Learning Rate: 0.000259179
	LOSS [training: 0.2056369656301916 | validation: 0.2291436786046491]
	TIME [epoch: 10.3 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2283880628046724		[learning rate: 0.00025838]
	Learning Rate: 0.000258385
	LOSS [training: 0.2283880628046724 | validation: 0.2749486291373326]
	TIME [epoch: 10.3 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2343097789200143		[learning rate: 0.00025759]
	Learning Rate: 0.000257593
	LOSS [training: 0.2343097789200143 | validation: 0.25008245070707147]
	TIME [epoch: 10.3 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2141819771443308		[learning rate: 0.0002568]
	Learning Rate: 0.000256803
	LOSS [training: 0.2141819771443308 | validation: 0.23377285976775716]
	TIME [epoch: 10.3 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21003654057589452		[learning rate: 0.00025602]
	Learning Rate: 0.000256016
	LOSS [training: 0.21003654057589452 | validation: 0.23328855513329086]
	TIME [epoch: 10.3 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2251302365505956		[learning rate: 0.00025523]
	Learning Rate: 0.000255231
	LOSS [training: 0.2251302365505956 | validation: 0.24610051911757438]
	TIME [epoch: 10.3 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21943375071019727		[learning rate: 0.00025445]
	Learning Rate: 0.000254449
	LOSS [training: 0.21943375071019727 | validation: 0.23344240858827792]
	TIME [epoch: 10.3 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21369024764140673		[learning rate: 0.00025367]
	Learning Rate: 0.000253669
	LOSS [training: 0.21369024764140673 | validation: 0.2204423379372195]
	TIME [epoch: 10.3 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21060483901676022		[learning rate: 0.00025289]
	Learning Rate: 0.000252891
	LOSS [training: 0.21060483901676022 | validation: 0.23329979211306445]
	TIME [epoch: 10.3 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21473678413995909		[learning rate: 0.00025212]
	Learning Rate: 0.000252116
	LOSS [training: 0.21473678413995909 | validation: 0.22703037674721593]
	TIME [epoch: 10.3 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20161769418572617		[learning rate: 0.00025134]
	Learning Rate: 0.000251343
	LOSS [training: 0.20161769418572617 | validation: 0.21627994392414807]
	TIME [epoch: 10.3 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20736483367312214		[learning rate: 0.00025057]
	Learning Rate: 0.000250572
	LOSS [training: 0.20736483367312214 | validation: 0.2269609932020417]
	TIME [epoch: 10.3 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20459147900947694		[learning rate: 0.0002498]
	Learning Rate: 0.000249804
	LOSS [training: 0.20459147900947694 | validation: 0.2306264164268313]
	TIME [epoch: 10.3 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2010558186707067		[learning rate: 0.00024904]
	Learning Rate: 0.000249039
	LOSS [training: 0.2010558186707067 | validation: 0.2263029421532824]
	TIME [epoch: 10.3 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20668274506258882		[learning rate: 0.00024828]
	Learning Rate: 0.000248275
	LOSS [training: 0.20668274506258882 | validation: 0.24498832870167866]
	TIME [epoch: 10.3 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21295170970358837		[learning rate: 0.00024751]
	Learning Rate: 0.000247514
	LOSS [training: 0.21295170970358837 | validation: 0.24324426053062895]
	TIME [epoch: 10.3 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22909143521297248		[learning rate: 0.00024676]
	Learning Rate: 0.000246755
	LOSS [training: 0.22909143521297248 | validation: 0.25665797000430457]
	TIME [epoch: 10.3 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25093680865584045		[learning rate: 0.000246]
	Learning Rate: 0.000245999
	LOSS [training: 0.25093680865584045 | validation: 0.23763544987689905]
	TIME [epoch: 10.3 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21984134656078366		[learning rate: 0.00024524]
	Learning Rate: 0.000245245
	LOSS [training: 0.21984134656078366 | validation: 0.22741632333755005]
	TIME [epoch: 10.3 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21357645414714663		[learning rate: 0.00024449]
	Learning Rate: 0.000244493
	LOSS [training: 0.21357645414714663 | validation: 0.2577829758220396]
	TIME [epoch: 10.3 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22641577316077313		[learning rate: 0.00024374]
	Learning Rate: 0.000243744
	LOSS [training: 0.22641577316077313 | validation: 0.24035480952061108]
	TIME [epoch: 10.3 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2221613011024237		[learning rate: 0.000243]
	Learning Rate: 0.000242996
	LOSS [training: 0.2221613011024237 | validation: 0.2337046987380873]
	TIME [epoch: 10.3 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22076042311727112		[learning rate: 0.00024225]
	Learning Rate: 0.000242252
	LOSS [training: 0.22076042311727112 | validation: 0.23102999658679893]
	TIME [epoch: 10.3 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21946097140800225		[learning rate: 0.00024151]
	Learning Rate: 0.000241509
	LOSS [training: 0.21946097140800225 | validation: 0.22228112995729976]
	TIME [epoch: 10.3 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21107573030076804		[learning rate: 0.00024077]
	Learning Rate: 0.000240769
	LOSS [training: 0.21107573030076804 | validation: 0.22208413851781358]
	TIME [epoch: 10.3 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21035745749327747		[learning rate: 0.00024003]
	Learning Rate: 0.000240031
	LOSS [training: 0.21035745749327747 | validation: 0.21042822823109977]
	TIME [epoch: 10.3 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.212293315557231		[learning rate: 0.00023929]
	Learning Rate: 0.000239295
	LOSS [training: 0.212293315557231 | validation: 0.23124605054925795]
	TIME [epoch: 10.3 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.206499381270595		[learning rate: 0.00023856]
	Learning Rate: 0.000238561
	LOSS [training: 0.206499381270595 | validation: 0.20868500752694105]
	TIME [epoch: 10.3 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2100671584477832		[learning rate: 0.00023783]
	Learning Rate: 0.00023783
	LOSS [training: 0.2100671584477832 | validation: 0.21915336112473965]
	TIME [epoch: 10.3 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.216894275674219		[learning rate: 0.0002371]
	Learning Rate: 0.000237101
	LOSS [training: 0.216894275674219 | validation: 0.2398609306006904]
	TIME [epoch: 10.3 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22946451873068244		[learning rate: 0.00023637]
	Learning Rate: 0.000236374
	LOSS [training: 0.22946451873068244 | validation: 0.25127377832023373]
	TIME [epoch: 10.3 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22023513786769128		[learning rate: 0.00023565]
	Learning Rate: 0.00023565
	LOSS [training: 0.22023513786769128 | validation: 0.22804956543893512]
	TIME [epoch: 10.3 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21164034548619198		[learning rate: 0.00023493]
	Learning Rate: 0.000234927
	LOSS [training: 0.21164034548619198 | validation: 0.2326220875031426]
	TIME [epoch: 10.3 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22455157353928837		[learning rate: 0.00023421]
	Learning Rate: 0.000234207
	LOSS [training: 0.22455157353928837 | validation: 0.2506522331520161]
	TIME [epoch: 10.3 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2291262743479474		[learning rate: 0.00023349]
	Learning Rate: 0.000233489
	LOSS [training: 0.2291262743479474 | validation: 0.234847078240336]
	TIME [epoch: 10.3 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22185819748268515		[learning rate: 0.00023277]
	Learning Rate: 0.000232773
	LOSS [training: 0.22185819748268515 | validation: 0.22597910255392323]
	TIME [epoch: 10.3 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2164176661230838		[learning rate: 0.00023206]
	Learning Rate: 0.00023206
	LOSS [training: 0.2164176661230838 | validation: 0.21286692631018445]
	TIME [epoch: 10.3 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.213473779294255		[learning rate: 0.00023135]
	Learning Rate: 0.000231348
	LOSS [training: 0.213473779294255 | validation: 0.21526669556429887]
	TIME [epoch: 10.3 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2069009602951366		[learning rate: 0.00023064]
	Learning Rate: 0.000230639
	LOSS [training: 0.2069009602951366 | validation: 0.2153866122924621]
	TIME [epoch: 10.3 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21823056963475612		[learning rate: 0.00022993]
	Learning Rate: 0.000229932
	LOSS [training: 0.21823056963475612 | validation: 0.20905645298803094]
	TIME [epoch: 10.3 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20930711755540088		[learning rate: 0.00022923]
	Learning Rate: 0.000229227
	LOSS [training: 0.20930711755540088 | validation: 0.21556390179863372]
	TIME [epoch: 10.3 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21577372526613542		[learning rate: 0.00022852]
	Learning Rate: 0.000228525
	LOSS [training: 0.21577372526613542 | validation: 0.2280770262183468]
	TIME [epoch: 10.3 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20555678087755927		[learning rate: 0.00022782]
	Learning Rate: 0.000227824
	LOSS [training: 0.20555678087755927 | validation: 0.24581043726855734]
	TIME [epoch: 10.3 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21394558255466664		[learning rate: 0.00022713]
	Learning Rate: 0.000227126
	LOSS [training: 0.21394558255466664 | validation: 0.21572308282777247]
	TIME [epoch: 10.3 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20287971373285774		[learning rate: 0.00022643]
	Learning Rate: 0.00022643
	LOSS [training: 0.20287971373285774 | validation: 0.21626258016681404]
	TIME [epoch: 10.3 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2143594395854267		[learning rate: 0.00022574]
	Learning Rate: 0.000225736
	LOSS [training: 0.2143594395854267 | validation: 0.25282112197381745]
	TIME [epoch: 10.3 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24056371089377718		[learning rate: 0.00022504]
	Learning Rate: 0.000225044
	LOSS [training: 0.24056371089377718 | validation: 0.2388159234758932]
	TIME [epoch: 10.3 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2037698697013039		[learning rate: 0.00022435]
	Learning Rate: 0.000224354
	LOSS [training: 0.2037698697013039 | validation: 0.2241111214792799]
	TIME [epoch: 10.3 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19944929178640264		[learning rate: 0.00022367]
	Learning Rate: 0.000223666
	LOSS [training: 0.19944929178640264 | validation: 0.19089075194664076]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1738.pth
	Model improved!!!
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1945666145198499		[learning rate: 0.00022298]
	Learning Rate: 0.00022298
	LOSS [training: 0.1945666145198499 | validation: 0.19271610793701285]
	TIME [epoch: 10.3 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19829640796951947		[learning rate: 0.0002223]
	Learning Rate: 0.000222297
	LOSS [training: 0.19829640796951947 | validation: 0.22869075554833956]
	TIME [epoch: 10.3 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19874595727265937		[learning rate: 0.00022162]
	Learning Rate: 0.000221615
	LOSS [training: 0.19874595727265937 | validation: 0.22098802139932264]
	TIME [epoch: 10.3 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20787812030242891		[learning rate: 0.00022094]
	Learning Rate: 0.000220936
	LOSS [training: 0.20787812030242891 | validation: 0.2183708911875941]
	TIME [epoch: 10.3 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2097406078777367		[learning rate: 0.00022026]
	Learning Rate: 0.000220259
	LOSS [training: 0.2097406078777367 | validation: 0.23599485643025042]
	TIME [epoch: 10.3 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2166323359296359		[learning rate: 0.00021958]
	Learning Rate: 0.000219584
	LOSS [training: 0.2166323359296359 | validation: 0.23146500256968927]
	TIME [epoch: 10.3 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20401125822142027		[learning rate: 0.00021891]
	Learning Rate: 0.000218911
	LOSS [training: 0.20401125822142027 | validation: 0.21572574699409985]
	TIME [epoch: 10.3 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19655113534758828		[learning rate: 0.00021824]
	Learning Rate: 0.000218239
	LOSS [training: 0.19655113534758828 | validation: 0.21230045717964807]
	TIME [epoch: 10.3 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20335324370219254		[learning rate: 0.00021757]
	Learning Rate: 0.00021757
	LOSS [training: 0.20335324370219254 | validation: 0.21859958080634798]
	TIME [epoch: 10.3 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20885535553100745		[learning rate: 0.0002169]
	Learning Rate: 0.000216904
	LOSS [training: 0.20885535553100745 | validation: 0.22339670595934544]
	TIME [epoch: 10.3 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18872048616208853		[learning rate: 0.00021624]
	Learning Rate: 0.000216239
	LOSS [training: 0.18872048616208853 | validation: 0.2142191363586962]
	TIME [epoch: 10.3 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20917143276102204		[learning rate: 0.00021558]
	Learning Rate: 0.000215576
	LOSS [training: 0.20917143276102204 | validation: 0.22830336416063354]
	TIME [epoch: 10.3 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20656046556278412		[learning rate: 0.00021491]
	Learning Rate: 0.000214915
	LOSS [training: 0.20656046556278412 | validation: 0.19656861371913825]
	TIME [epoch: 10.3 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20670587763807458		[learning rate: 0.00021426]
	Learning Rate: 0.000214256
	LOSS [training: 0.20670587763807458 | validation: 0.2509253433579172]
	TIME [epoch: 10.3 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2215834883463807		[learning rate: 0.0002136]
	Learning Rate: 0.000213599
	LOSS [training: 0.2215834883463807 | validation: 0.24586527477362843]
	TIME [epoch: 10.3 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22228648541298254		[learning rate: 0.00021294]
	Learning Rate: 0.000212945
	LOSS [training: 0.22228648541298254 | validation: 0.24962462666098867]
	TIME [epoch: 10.3 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2140336911643152		[learning rate: 0.00021229]
	Learning Rate: 0.000212292
	LOSS [training: 0.2140336911643152 | validation: 0.23816386923436988]
	TIME [epoch: 10.3 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.209548595415541		[learning rate: 0.00021164]
	Learning Rate: 0.000211641
	LOSS [training: 0.209548595415541 | validation: 0.21102067647344547]
	TIME [epoch: 10.3 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20064650717873986		[learning rate: 0.00021099]
	Learning Rate: 0.000210992
	LOSS [training: 0.20064650717873986 | validation: 0.23362067420229388]
	TIME [epoch: 10.3 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20551424570469115		[learning rate: 0.00021035]
	Learning Rate: 0.000210346
	LOSS [training: 0.20551424570469115 | validation: 0.21695633607858134]
	TIME [epoch: 10.3 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20535222065563347		[learning rate: 0.0002097]
	Learning Rate: 0.000209701
	LOSS [training: 0.20535222065563347 | validation: 0.20807003438895735]
	TIME [epoch: 10.3 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20165129414533095		[learning rate: 0.00020906]
	Learning Rate: 0.000209058
	LOSS [training: 0.20165129414533095 | validation: 0.2246863037791031]
	TIME [epoch: 10.3 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2142529329146426		[learning rate: 0.00020842]
	Learning Rate: 0.000208417
	LOSS [training: 0.2142529329146426 | validation: 0.2058072382905365]
	TIME [epoch: 10.3 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20453788079898602		[learning rate: 0.00020778]
	Learning Rate: 0.000207778
	LOSS [training: 0.20453788079898602 | validation: 0.2139912387449857]
	TIME [epoch: 10.3 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20622233154521422		[learning rate: 0.00020714]
	Learning Rate: 0.000207141
	LOSS [training: 0.20622233154521422 | validation: 0.24649393650450274]
	TIME [epoch: 10.3 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22295670669758322		[learning rate: 0.00020651]
	Learning Rate: 0.000206506
	LOSS [training: 0.22295670669758322 | validation: 0.22264866759771912]
	TIME [epoch: 10.3 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2032212681454268		[learning rate: 0.00020587]
	Learning Rate: 0.000205873
	LOSS [training: 0.2032212681454268 | validation: 0.2102968246114126]
	TIME [epoch: 10.3 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20150864071267427		[learning rate: 0.00020524]
	Learning Rate: 0.000205242
	LOSS [training: 0.20150864071267427 | validation: 0.213460383636342]
	TIME [epoch: 10.3 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20433110978697364		[learning rate: 0.00020461]
	Learning Rate: 0.000204613
	LOSS [training: 0.20433110978697364 | validation: 0.22775962889474122]
	TIME [epoch: 10.3 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2052013776537745		[learning rate: 0.00020399]
	Learning Rate: 0.000203986
	LOSS [training: 0.2052013776537745 | validation: 0.21849229131758818]
	TIME [epoch: 10.3 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20610761599384073		[learning rate: 0.00020336]
	Learning Rate: 0.00020336
	LOSS [training: 0.20610761599384073 | validation: 0.20339188092633248]
	TIME [epoch: 10.3 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19619932573793183		[learning rate: 0.00020274]
	Learning Rate: 0.000202737
	LOSS [training: 0.19619932573793183 | validation: 0.22405314772350998]
	TIME [epoch: 10.3 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19799782628901172		[learning rate: 0.00020212]
	Learning Rate: 0.000202116
	LOSS [training: 0.19799782628901172 | validation: 0.2005691053843674]
	TIME [epoch: 10.3 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19340004139515712		[learning rate: 0.0002015]
	Learning Rate: 0.000201496
	LOSS [training: 0.19340004139515712 | validation: 0.20920800864739447]
	TIME [epoch: 10.3 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19931083776541084		[learning rate: 0.00020088]
	Learning Rate: 0.000200878
	LOSS [training: 0.19931083776541084 | validation: 0.20915363952520807]
	TIME [epoch: 10.3 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18759751667340616		[learning rate: 0.00020026]
	Learning Rate: 0.000200263
	LOSS [training: 0.18759751667340616 | validation: 0.21319498411924753]
	TIME [epoch: 10.3 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20161546191536645		[learning rate: 0.00019965]
	Learning Rate: 0.000199649
	LOSS [training: 0.20161546191536645 | validation: 0.22476208557345367]
	TIME [epoch: 10.3 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21779504173388067		[learning rate: 0.00019904]
	Learning Rate: 0.000199037
	LOSS [training: 0.21779504173388067 | validation: 0.23584606068646224]
	TIME [epoch: 10.3 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23715706757846008		[learning rate: 0.00019843]
	Learning Rate: 0.000198427
	LOSS [training: 0.23715706757846008 | validation: 0.23136863327094517]
	TIME [epoch: 10.3 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21425329503196555		[learning rate: 0.00019782]
	Learning Rate: 0.000197818
	LOSS [training: 0.21425329503196555 | validation: 0.21605336571674308]
	TIME [epoch: 10.3 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2115067638608163		[learning rate: 0.00019721]
	Learning Rate: 0.000197212
	LOSS [training: 0.2115067638608163 | validation: 0.2322668436643041]
	TIME [epoch: 10.3 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20417024539718254		[learning rate: 0.00019661]
	Learning Rate: 0.000196607
	LOSS [training: 0.20417024539718254 | validation: 0.21538511536359917]
	TIME [epoch: 10.3 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20078765080223504		[learning rate: 0.000196]
	Learning Rate: 0.000196005
	LOSS [training: 0.20078765080223504 | validation: 0.21877758419846097]
	TIME [epoch: 10.3 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20116812037344428		[learning rate: 0.0001954]
	Learning Rate: 0.000195404
	LOSS [training: 0.20116812037344428 | validation: 0.21300516823584567]
	TIME [epoch: 10.3 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19730894840178465		[learning rate: 0.0001948]
	Learning Rate: 0.000194805
	LOSS [training: 0.19730894840178465 | validation: 0.19597361542527916]
	TIME [epoch: 10.3 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20144713972362646		[learning rate: 0.00019421]
	Learning Rate: 0.000194208
	LOSS [training: 0.20144713972362646 | validation: 0.21174140453617732]
	TIME [epoch: 10.3 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19967997551156866		[learning rate: 0.00019361]
	Learning Rate: 0.000193612
	LOSS [training: 0.19967997551156866 | validation: 0.2076400425448282]
	TIME [epoch: 10.3 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1919848399064608		[learning rate: 0.00019302]
	Learning Rate: 0.000193019
	LOSS [training: 0.1919848399064608 | validation: 0.20681265478596295]
	TIME [epoch: 10.3 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19337997073281937		[learning rate: 0.00019243]
	Learning Rate: 0.000192427
	LOSS [training: 0.19337997073281937 | validation: 0.21876171799373914]
	TIME [epoch: 10.3 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19810992529571486		[learning rate: 0.00019184]
	Learning Rate: 0.000191837
	LOSS [training: 0.19810992529571486 | validation: 0.201965016997614]
	TIME [epoch: 10.3 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19602692715523107		[learning rate: 0.00019125]
	Learning Rate: 0.000191249
	LOSS [training: 0.19602692715523107 | validation: 0.2273250818080315]
	TIME [epoch: 10.3 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20151863666960299		[learning rate: 0.00019066]
	Learning Rate: 0.000190663
	LOSS [training: 0.20151863666960299 | validation: 0.21411916615565893]
	TIME [epoch: 10.3 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19786474066613832		[learning rate: 0.00019008]
	Learning Rate: 0.000190079
	LOSS [training: 0.19786474066613832 | validation: 0.2057197914126664]
	TIME [epoch: 10.3 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20767533920509446		[learning rate: 0.0001895]
	Learning Rate: 0.000189496
	LOSS [training: 0.20767533920509446 | validation: 0.24748051583789643]
	TIME [epoch: 10.3 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2110471452593352		[learning rate: 0.00018892]
	Learning Rate: 0.000188915
	LOSS [training: 0.2110471452593352 | validation: 0.20171835248141]
	TIME [epoch: 10.3 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1949808938582503		[learning rate: 0.00018834]
	Learning Rate: 0.000188336
	LOSS [training: 0.1949808938582503 | validation: 0.2045881780625588]
	TIME [epoch: 10.3 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20138756771662294		[learning rate: 0.00018776]
	Learning Rate: 0.000187759
	LOSS [training: 0.20138756771662294 | validation: 0.20439339130051523]
	TIME [epoch: 10.3 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.200459415083523		[learning rate: 0.00018718]
	Learning Rate: 0.000187183
	LOSS [training: 0.200459415083523 | validation: 0.20565013753027742]
	TIME [epoch: 10.3 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1997061207115237		[learning rate: 0.00018661]
	Learning Rate: 0.000186609
	LOSS [training: 0.1997061207115237 | validation: 0.21331614522001358]
	TIME [epoch: 10.3 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2023326619889822		[learning rate: 0.00018604]
	Learning Rate: 0.000186037
	LOSS [training: 0.2023326619889822 | validation: 0.20795500255742916]
	TIME [epoch: 10.3 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20233081416286525		[learning rate: 0.00018547]
	Learning Rate: 0.000185467
	LOSS [training: 0.20233081416286525 | validation: 0.2231083436691099]
	TIME [epoch: 10.3 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20018327872188477		[learning rate: 0.0001849]
	Learning Rate: 0.000184898
	LOSS [training: 0.20018327872188477 | validation: 0.2127358561415061]
	TIME [epoch: 10.3 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2021212098104425		[learning rate: 0.00018433]
	Learning Rate: 0.000184332
	LOSS [training: 0.2021212098104425 | validation: 0.2214323028693294]
	TIME [epoch: 10.3 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20793702777869885		[learning rate: 0.00018377]
	Learning Rate: 0.000183767
	LOSS [training: 0.20793702777869885 | validation: 0.23746815647496702]
	TIME [epoch: 10.3 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23325888869502504		[learning rate: 0.0001832]
	Learning Rate: 0.000183203
	LOSS [training: 0.23325888869502504 | validation: 0.23563048823514202]
	TIME [epoch: 10.3 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21928785072628482		[learning rate: 0.00018264]
	Learning Rate: 0.000182642
	LOSS [training: 0.21928785072628482 | validation: 0.22975894994992047]
	TIME [epoch: 10.3 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21329611702529663		[learning rate: 0.00018208]
	Learning Rate: 0.000182082
	LOSS [training: 0.21329611702529663 | validation: 0.21466042748923164]
	TIME [epoch: 10.3 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.205238194591501		[learning rate: 0.00018152]
	Learning Rate: 0.000181524
	LOSS [training: 0.205238194591501 | validation: 0.22075469474939324]
	TIME [epoch: 10.3 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20206756980884194		[learning rate: 0.00018097]
	Learning Rate: 0.000180967
	LOSS [training: 0.20206756980884194 | validation: 0.19880768440794933]
	TIME [epoch: 10.3 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2069446560271384		[learning rate: 0.00018041]
	Learning Rate: 0.000180412
	LOSS [training: 0.2069446560271384 | validation: 0.2171492895051028]
	TIME [epoch: 10.3 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19916969961119343		[learning rate: 0.00017986]
	Learning Rate: 0.000179859
	LOSS [training: 0.19916969961119343 | validation: 0.21437684198053858]
	TIME [epoch: 10.3 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20390924025850055		[learning rate: 0.00017931]
	Learning Rate: 0.000179308
	LOSS [training: 0.20390924025850055 | validation: 0.2039862730260554]
	TIME [epoch: 10.3 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19671913875531938		[learning rate: 0.00017876]
	Learning Rate: 0.000178758
	LOSS [training: 0.19671913875531938 | validation: 0.19643723757763415]
	TIME [epoch: 10.3 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1932474808491032		[learning rate: 0.00017821]
	Learning Rate: 0.00017821
	LOSS [training: 0.1932474808491032 | validation: 0.2049696932643418]
	TIME [epoch: 10.3 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19392828369724738		[learning rate: 0.00017766]
	Learning Rate: 0.000177664
	LOSS [training: 0.19392828369724738 | validation: 0.21005875327686135]
	TIME [epoch: 10.3 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19799326914989246		[learning rate: 0.00017712]
	Learning Rate: 0.00017712
	LOSS [training: 0.19799326914989246 | validation: 0.20729133179001827]
	TIME [epoch: 10.3 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1971300317652272		[learning rate: 0.00017658]
	Learning Rate: 0.000176577
	LOSS [training: 0.1971300317652272 | validation: 0.2212549226316414]
	TIME [epoch: 10.3 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20211241836182495		[learning rate: 0.00017604]
	Learning Rate: 0.000176035
	LOSS [training: 0.20211241836182495 | validation: 0.21301455899242236]
	TIME [epoch: 10.3 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20438659243749954		[learning rate: 0.0001755]
	Learning Rate: 0.000175496
	LOSS [training: 0.20438659243749954 | validation: 0.22234085457699138]
	TIME [epoch: 10.3 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19626008693522548		[learning rate: 0.00017496]
	Learning Rate: 0.000174958
	LOSS [training: 0.19626008693522548 | validation: 0.22193383865401312]
	TIME [epoch: 10.3 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20233446398454796		[learning rate: 0.00017442]
	Learning Rate: 0.000174421
	LOSS [training: 0.20233446398454796 | validation: 0.2299577008214642]
	TIME [epoch: 10.3 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21000110385823864		[learning rate: 0.00017389]
	Learning Rate: 0.000173887
	LOSS [training: 0.21000110385823864 | validation: 0.21331261742211283]
	TIME [epoch: 10.3 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19923800398074068		[learning rate: 0.00017335]
	Learning Rate: 0.000173354
	LOSS [training: 0.19923800398074068 | validation: 0.22741695353552216]
	TIME [epoch: 10.3 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20600190688747308		[learning rate: 0.00017282]
	Learning Rate: 0.000172822
	LOSS [training: 0.20600190688747308 | validation: 0.20818641535984314]
	TIME [epoch: 10.3 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1993581980651437		[learning rate: 0.00017229]
	Learning Rate: 0.000172293
	LOSS [training: 0.1993581980651437 | validation: 0.2156052793911713]
	TIME [epoch: 10.3 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19551848803486213		[learning rate: 0.00017176]
	Learning Rate: 0.000171764
	LOSS [training: 0.19551848803486213 | validation: 0.20933855530201748]
	TIME [epoch: 10.3 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1971301265601435		[learning rate: 0.00017124]
	Learning Rate: 0.000171238
	LOSS [training: 0.1971301265601435 | validation: 0.21687033655221974]
	TIME [epoch: 10.3 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2078187746921465		[learning rate: 0.00017071]
	Learning Rate: 0.000170713
	LOSS [training: 0.2078187746921465 | validation: 0.25852068357973657]
	TIME [epoch: 10.3 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22755624492021514		[learning rate: 0.00017019]
	Learning Rate: 0.00017019
	LOSS [training: 0.22755624492021514 | validation: 0.21832545113276283]
	TIME [epoch: 10.3 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20439931784147108		[learning rate: 0.00016967]
	Learning Rate: 0.000169668
	LOSS [training: 0.20439931784147108 | validation: 0.22736889830781246]
	TIME [epoch: 10.3 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20102214890841585		[learning rate: 0.00016915]
	Learning Rate: 0.000169148
	LOSS [training: 0.20102214890841585 | validation: 0.20899025394662693]
	TIME [epoch: 10.3 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1973611244073434		[learning rate: 0.00016863]
	Learning Rate: 0.000168629
	LOSS [training: 0.1973611244073434 | validation: 0.19547343282483987]
	TIME [epoch: 10.3 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1941727512879287		[learning rate: 0.00016811]
	Learning Rate: 0.000168112
	LOSS [training: 0.1941727512879287 | validation: 0.20459757645084395]
	TIME [epoch: 10.3 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19741767381738623		[learning rate: 0.0001676]
	Learning Rate: 0.000167597
	LOSS [training: 0.19741767381738623 | validation: 0.2127038657107818]
	TIME [epoch: 10.3 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20220002202274667		[learning rate: 0.00016708]
	Learning Rate: 0.000167083
	LOSS [training: 0.20220002202274667 | validation: 0.20443814611495717]
	TIME [epoch: 10.3 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19777585995454405		[learning rate: 0.00016657]
	Learning Rate: 0.000166571
	LOSS [training: 0.19777585995454405 | validation: 0.2199587522432296]
	TIME [epoch: 10.3 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20093633587558335		[learning rate: 0.00016606]
	Learning Rate: 0.000166061
	LOSS [training: 0.20093633587558335 | validation: 0.2378438214303109]
	TIME [epoch: 10.3 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23243909434586		[learning rate: 0.00016555]
	Learning Rate: 0.000165552
	LOSS [training: 0.23243909434586 | validation: 0.2784782401965299]
	TIME [epoch: 10.3 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2342174409328197		[learning rate: 0.00016504]
	Learning Rate: 0.000165044
	LOSS [training: 0.2342174409328197 | validation: 0.22318285066856683]
	TIME [epoch: 10.3 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20627044136791634		[learning rate: 0.00016454]
	Learning Rate: 0.000164538
	LOSS [training: 0.20627044136791634 | validation: 0.204812761644999]
	TIME [epoch: 10.3 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19551569331871002		[learning rate: 0.00016403]
	Learning Rate: 0.000164034
	LOSS [training: 0.19551569331871002 | validation: 0.21520053565774191]
	TIME [epoch: 10.3 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1942864145419248		[learning rate: 0.00016353]
	Learning Rate: 0.000163531
	LOSS [training: 0.1942864145419248 | validation: 0.20456512796003753]
	TIME [epoch: 10.3 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18925173847187696		[learning rate: 0.00016303]
	Learning Rate: 0.00016303
	LOSS [training: 0.18925173847187696 | validation: 0.2057539713364464]
	TIME [epoch: 10.3 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19383043038983533		[learning rate: 0.00016253]
	Learning Rate: 0.00016253
	LOSS [training: 0.19383043038983533 | validation: 0.20945627958926227]
	TIME [epoch: 10.3 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1997366580951132		[learning rate: 0.00016203]
	Learning Rate: 0.000162032
	LOSS [training: 0.1997366580951132 | validation: 0.20759203641382748]
	TIME [epoch: 10.3 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19768342169820105		[learning rate: 0.00016153]
	Learning Rate: 0.000161535
	LOSS [training: 0.19768342169820105 | validation: 0.21298320025987585]
	TIME [epoch: 10.3 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19546857213003438		[learning rate: 0.00016104]
	Learning Rate: 0.00016104
	LOSS [training: 0.19546857213003438 | validation: 0.2075960359040111]
	TIME [epoch: 10.3 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1912906426952846		[learning rate: 0.00016055]
	Learning Rate: 0.000160546
	LOSS [training: 0.1912906426952846 | validation: 0.20409891560452348]
	TIME [epoch: 10.3 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18927015869740074		[learning rate: 0.00016005]
	Learning Rate: 0.000160054
	LOSS [training: 0.18927015869740074 | validation: 0.21698083403555277]
	TIME [epoch: 10.3 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1985042263723762		[learning rate: 0.00015956]
	Learning Rate: 0.000159563
	LOSS [training: 0.1985042263723762 | validation: 0.2170639070873363]
	TIME [epoch: 10.3 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20375051230321312		[learning rate: 0.00015907]
	Learning Rate: 0.000159074
	LOSS [training: 0.20375051230321312 | validation: 0.2361080040361025]
	TIME [epoch: 10.3 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21865752584749423		[learning rate: 0.00015859]
	Learning Rate: 0.000158587
	LOSS [training: 0.21865752584749423 | validation: 0.2888814227565499]
	TIME [epoch: 10.3 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2486574872790635		[learning rate: 0.0001581]
	Learning Rate: 0.000158101
	LOSS [training: 0.2486574872790635 | validation: 0.259376622643344]
	TIME [epoch: 10.3 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22283910248559496		[learning rate: 0.00015762]
	Learning Rate: 0.000157616
	LOSS [training: 0.22283910248559496 | validation: 0.23343184563215713]
	TIME [epoch: 10.3 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19903650375509208		[learning rate: 0.00015713]
	Learning Rate: 0.000157133
	LOSS [training: 0.19903650375509208 | validation: 0.21557249433598416]
	TIME [epoch: 10.3 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.197407591912841		[learning rate: 0.00015665]
	Learning Rate: 0.000156651
	LOSS [training: 0.197407591912841 | validation: 0.23042222601121476]
	TIME [epoch: 10.3 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20518628143406623		[learning rate: 0.00015617]
	Learning Rate: 0.000156171
	LOSS [training: 0.20518628143406623 | validation: 0.22354705123131977]
	TIME [epoch: 10.3 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19555001063509195		[learning rate: 0.00015569]
	Learning Rate: 0.000155692
	LOSS [training: 0.19555001063509195 | validation: 0.19853517409657742]
	TIME [epoch: 10.3 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19281689628715493		[learning rate: 0.00015521]
	Learning Rate: 0.000155215
	LOSS [training: 0.19281689628715493 | validation: 0.20907335612319145]
	TIME [epoch: 10.3 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2083774683257627		[learning rate: 0.00015474]
	Learning Rate: 0.000154739
	LOSS [training: 0.2083774683257627 | validation: 0.22700572831021804]
	TIME [epoch: 10.3 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21170726066872786		[learning rate: 0.00015426]
	Learning Rate: 0.000154265
	LOSS [training: 0.21170726066872786 | validation: 0.22797907549848734]
	TIME [epoch: 10.3 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22246543848786637		[learning rate: 0.00015379]
	Learning Rate: 0.000153792
	LOSS [training: 0.22246543848786637 | validation: 0.22198513314054932]
	TIME [epoch: 10.3 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21166639395949477		[learning rate: 0.00015332]
	Learning Rate: 0.00015332
	LOSS [training: 0.21166639395949477 | validation: 0.20956464800339028]
	TIME [epoch: 10.3 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19633605639931637		[learning rate: 0.00015285]
	Learning Rate: 0.00015285
	LOSS [training: 0.19633605639931637 | validation: 0.21602912175135558]
	TIME [epoch: 10.3 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19685735727206533		[learning rate: 0.00015238]
	Learning Rate: 0.000152382
	LOSS [training: 0.19685735727206533 | validation: 0.21678359324232596]
	TIME [epoch: 10.3 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20572771652060173		[learning rate: 0.00015191]
	Learning Rate: 0.000151915
	LOSS [training: 0.20572771652060173 | validation: 0.2024818207464665]
	TIME [epoch: 10.3 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18759369416631735		[learning rate: 0.00015145]
	Learning Rate: 0.000151449
	LOSS [training: 0.18759369416631735 | validation: 0.22151962013276902]
	TIME [epoch: 10.3 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19336001729580768		[learning rate: 0.00015098]
	Learning Rate: 0.000150985
	LOSS [training: 0.19336001729580768 | validation: 0.19401339358198896]
	TIME [epoch: 10.3 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19471626773556644		[learning rate: 0.00015052]
	Learning Rate: 0.000150522
	LOSS [training: 0.19471626773556644 | validation: 0.20004264933805602]
	TIME [epoch: 10.3 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19579247907343472		[learning rate: 0.00015006]
	Learning Rate: 0.000150061
	LOSS [training: 0.19579247907343472 | validation: 0.21185444915948604]
	TIME [epoch: 10.3 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2016504261284376		[learning rate: 0.0001496]
	Learning Rate: 0.000149601
	LOSS [training: 0.2016504261284376 | validation: 0.21622972632179632]
	TIME [epoch: 10.3 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1925495466184084		[learning rate: 0.00014914]
	Learning Rate: 0.000149142
	LOSS [training: 0.1925495466184084 | validation: 0.19235175642647734]
	TIME [epoch: 10.3 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19109933138021154		[learning rate: 0.00014868]
	Learning Rate: 0.000148685
	LOSS [training: 0.19109933138021154 | validation: 0.19582216928181972]
	TIME [epoch: 10.3 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18948417601275386		[learning rate: 0.00014823]
	Learning Rate: 0.000148229
	LOSS [training: 0.18948417601275386 | validation: 0.206754712448201]
	TIME [epoch: 10.3 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19183745104665287		[learning rate: 0.00014777]
	Learning Rate: 0.000147775
	LOSS [training: 0.19183745104665287 | validation: 0.19781044641254839]
	TIME [epoch: 10.3 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1937753229637583		[learning rate: 0.00014732]
	Learning Rate: 0.000147322
	LOSS [training: 0.1937753229637583 | validation: 0.20435165485726026]
	TIME [epoch: 10.3 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1916020649288744		[learning rate: 0.00014687]
	Learning Rate: 0.00014687
	LOSS [training: 0.1916020649288744 | validation: 0.20817875647317718]
	TIME [epoch: 10.3 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19193939916686498		[learning rate: 0.00014642]
	Learning Rate: 0.00014642
	LOSS [training: 0.19193939916686498 | validation: 0.19956582863699196]
	TIME [epoch: 10.3 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19415318893407066		[learning rate: 0.00014597]
	Learning Rate: 0.000145971
	LOSS [training: 0.19415318893407066 | validation: 0.21731661940241032]
	TIME [epoch: 10.3 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19286958108898306		[learning rate: 0.00014552]
	Learning Rate: 0.000145524
	LOSS [training: 0.19286958108898306 | validation: 0.20072431165465227]
	TIME [epoch: 10.3 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19538463813168808		[learning rate: 0.00014508]
	Learning Rate: 0.000145077
	LOSS [training: 0.19538463813168808 | validation: 0.2148553918926114]
	TIME [epoch: 10.3 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20070133556135755		[learning rate: 0.00014463]
	Learning Rate: 0.000144633
	LOSS [training: 0.20070133556135755 | validation: 0.2110193702737552]
	TIME [epoch: 10.3 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19351229119848382		[learning rate: 0.00014419]
	Learning Rate: 0.000144189
	LOSS [training: 0.19351229119848382 | validation: 0.22414206582594623]
	TIME [epoch: 10.3 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20474067604440355		[learning rate: 0.00014375]
	Learning Rate: 0.000143747
	LOSS [training: 0.20474067604440355 | validation: 0.21162550069485173]
	TIME [epoch: 10.3 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19904026553980975		[learning rate: 0.00014331]
	Learning Rate: 0.000143307
	LOSS [training: 0.19904026553980975 | validation: 0.20340668474305737]
	TIME [epoch: 10.3 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1953022603170518		[learning rate: 0.00014287]
	Learning Rate: 0.000142867
	LOSS [training: 0.1953022603170518 | validation: 0.19504168527694454]
	TIME [epoch: 10.3 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1914425763200141		[learning rate: 0.00014243]
	Learning Rate: 0.00014243
	LOSS [training: 0.1914425763200141 | validation: 0.21666219763427802]
	TIME [epoch: 10.3 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19016935410612862		[learning rate: 0.00014199]
	Learning Rate: 0.000141993
	LOSS [training: 0.19016935410612862 | validation: 0.20899402900777875]
	TIME [epoch: 10.3 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19039180255562557		[learning rate: 0.00014156]
	Learning Rate: 0.000141558
	LOSS [training: 0.19039180255562557 | validation: 0.1891778268226103]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_101110/states/model_tr_study6_1887.pth
	Model improved!!!
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19413683199090792		[learning rate: 0.00014112]
	Learning Rate: 0.000141124
	LOSS [training: 0.19413683199090792 | validation: 0.20077185147693272]
	TIME [epoch: 10.3 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19002897426273968		[learning rate: 0.00014069]
	Learning Rate: 0.000140691
	LOSS [training: 0.19002897426273968 | validation: 0.18928761284046033]
	TIME [epoch: 10.3 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19332237033170313		[learning rate: 0.00014026]
	Learning Rate: 0.00014026
	LOSS [training: 0.19332237033170313 | validation: 0.2162101802802826]
	TIME [epoch: 10.3 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19828221961751466		[learning rate: 0.00013983]
	Learning Rate: 0.00013983
	LOSS [training: 0.19828221961751466 | validation: 0.2085845463425212]
	TIME [epoch: 10.3 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18646143722880618		[learning rate: 0.0001394]
	Learning Rate: 0.000139401
	LOSS [training: 0.18646143722880618 | validation: 0.19661353707808737]
	TIME [epoch: 10.3 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1906526725129634		[learning rate: 0.00013897]
	Learning Rate: 0.000138974
	LOSS [training: 0.1906526725129634 | validation: 0.22500808259784083]
	TIME [epoch: 10.3 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19852352801214385		[learning rate: 0.00013855]
	Learning Rate: 0.000138548
	LOSS [training: 0.19852352801214385 | validation: 0.21426703412283915]
	TIME [epoch: 10.3 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19410315637481707		[learning rate: 0.00013812]
	Learning Rate: 0.000138123
	LOSS [training: 0.19410315637481707 | validation: 0.20118052235246653]
	TIME [epoch: 10.3 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1986148504924421		[learning rate: 0.0001377]
	Learning Rate: 0.0001377
	LOSS [training: 0.1986148504924421 | validation: 0.21030456746106477]
	TIME [epoch: 10.3 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19610009060202502		[learning rate: 0.00013728]
	Learning Rate: 0.000137278
	LOSS [training: 0.19610009060202502 | validation: 0.210757834291026]
	TIME [epoch: 10.3 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19080458687482804		[learning rate: 0.00013686]
	Learning Rate: 0.000136857
	LOSS [training: 0.19080458687482804 | validation: 0.20153760638067908]
	TIME [epoch: 10.3 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19343313187496744		[learning rate: 0.00013644]
	Learning Rate: 0.000136437
	LOSS [training: 0.19343313187496744 | validation: 0.20496300588924457]
	TIME [epoch: 10.3 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19662517896309525		[learning rate: 0.00013602]
	Learning Rate: 0.000136019
	LOSS [training: 0.19662517896309525 | validation: 0.2117825661961617]
	TIME [epoch: 10.3 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19755625347768452		[learning rate: 0.0001356]
	Learning Rate: 0.000135602
	LOSS [training: 0.19755625347768452 | validation: 0.20320594691901178]
	TIME [epoch: 10.3 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20117109733855107		[learning rate: 0.00013519]
	Learning Rate: 0.000135186
	LOSS [training: 0.20117109733855107 | validation: 0.22487633287562353]
	TIME [epoch: 10.3 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2110352538837867		[learning rate: 0.00013477]
	Learning Rate: 0.000134772
	LOSS [training: 0.2110352538837867 | validation: 0.21835476662778708]
	TIME [epoch: 10.3 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19557170770561266		[learning rate: 0.00013436]
	Learning Rate: 0.000134359
	LOSS [training: 0.19557170770561266 | validation: 0.2132693652576441]
	TIME [epoch: 10.3 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20050083162376944		[learning rate: 0.00013395]
	Learning Rate: 0.000133947
	LOSS [training: 0.20050083162376944 | validation: 0.2255036911929433]
	TIME [epoch: 10.3 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2038854930184141		[learning rate: 0.00013354]
	Learning Rate: 0.000133536
	LOSS [training: 0.2038854930184141 | validation: 0.22397493544875613]
	TIME [epoch: 10.3 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2033817431311984		[learning rate: 0.00013313]
	Learning Rate: 0.000133127
	LOSS [training: 0.2033817431311984 | validation: 0.21320408135756921]
	TIME [epoch: 10.3 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2015593365488459		[learning rate: 0.00013272]
	Learning Rate: 0.000132719
	LOSS [training: 0.2015593365488459 | validation: 0.2260900525556549]
	TIME [epoch: 10.3 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19289991900876066		[learning rate: 0.00013231]
	Learning Rate: 0.000132312
	LOSS [training: 0.19289991900876066 | validation: 0.2244407350070165]
	TIME [epoch: 10.3 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2086175267082869		[learning rate: 0.00013191]
	Learning Rate: 0.000131907
	LOSS [training: 0.2086175267082869 | validation: 0.25671258084170084]
	TIME [epoch: 10.3 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2223495455619015		[learning rate: 0.0001315]
	Learning Rate: 0.000131502
	LOSS [training: 0.2223495455619015 | validation: 0.28285093312166526]
	TIME [epoch: 10.3 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24574251401948413		[learning rate: 0.0001311]
	Learning Rate: 0.000131099
	LOSS [training: 0.24574251401948413 | validation: 0.2979142631515332]
	TIME [epoch: 10.3 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24801375463825318		[learning rate: 0.0001307]
	Learning Rate: 0.000130697
	LOSS [training: 0.24801375463825318 | validation: 0.25783445578806935]
	TIME [epoch: 10.3 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2127199976825817		[learning rate: 0.0001303]
	Learning Rate: 0.000130297
	LOSS [training: 0.2127199976825817 | validation: 0.22381365280189428]
	TIME [epoch: 10.3 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21944660516215833		[learning rate: 0.0001299]
	Learning Rate: 0.000129897
	LOSS [training: 0.21944660516215833 | validation: 0.23250070844113124]
	TIME [epoch: 10.3 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20586337037172187		[learning rate: 0.0001295]
	Learning Rate: 0.000129499
	LOSS [training: 0.20586337037172187 | validation: 0.2399276273487275]
	TIME [epoch: 10.3 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20229051089604422		[learning rate: 0.0001291]
	Learning Rate: 0.000129102
	LOSS [training: 0.20229051089604422 | validation: 0.21167769427200803]
	TIME [epoch: 10.3 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19780297088168752		[learning rate: 0.00012871]
	Learning Rate: 0.000128706
	LOSS [training: 0.19780297088168752 | validation: 0.21179735374527206]
	TIME [epoch: 10.3 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20600183737229663		[learning rate: 0.00012831]
	Learning Rate: 0.000128312
	LOSS [training: 0.20600183737229663 | validation: 0.227468038341956]
	TIME [epoch: 10.3 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19634220663832255		[learning rate: 0.00012792]
	Learning Rate: 0.000127918
	LOSS [training: 0.19634220663832255 | validation: 0.20649781177920518]
	TIME [epoch: 10.3 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19958285928922143		[learning rate: 0.00012753]
	Learning Rate: 0.000127526
	LOSS [training: 0.19958285928922143 | validation: 0.21695741956049808]
	TIME [epoch: 10.3 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19266756569310434		[learning rate: 0.00012714]
	Learning Rate: 0.000127135
	LOSS [training: 0.19266756569310434 | validation: 0.2117643699064194]
	TIME [epoch: 10.3 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19451334822343155		[learning rate: 0.00012675]
	Learning Rate: 0.000126746
	LOSS [training: 0.19451334822343155 | validation: 0.2026496249438128]
	TIME [epoch: 10.3 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19694546504268412		[learning rate: 0.00012636]
	Learning Rate: 0.000126357
	LOSS [training: 0.19694546504268412 | validation: 0.2073857367714744]
	TIME [epoch: 10.3 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1981094198993803		[learning rate: 0.00012597]
	Learning Rate: 0.00012597
	LOSS [training: 0.1981094198993803 | validation: 0.2103450905211347]
	TIME [epoch: 10.3 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20330753117258568		[learning rate: 0.00012558]
	Learning Rate: 0.000125584
	LOSS [training: 0.20330753117258568 | validation: 0.21929439544916535]
	TIME [epoch: 10.3 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21067359045087852		[learning rate: 0.0001252]
	Learning Rate: 0.000125199
	LOSS [training: 0.21067359045087852 | validation: 0.22891445246734926]
	TIME [epoch: 10.3 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23077359337791323		[learning rate: 0.00012481]
	Learning Rate: 0.000124815
	LOSS [training: 0.23077359337791323 | validation: 0.23928222927210627]
	TIME [epoch: 10.3 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2142851631210382		[learning rate: 0.00012443]
	Learning Rate: 0.000124432
	LOSS [training: 0.2142851631210382 | validation: 0.22670647393945817]
	TIME [epoch: 10.3 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20491993206374498		[learning rate: 0.00012405]
	Learning Rate: 0.000124051
	LOSS [training: 0.20491993206374498 | validation: 0.19967758391170917]
	TIME [epoch: 10.3 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19724205747425927		[learning rate: 0.00012367]
	Learning Rate: 0.000123671
	LOSS [training: 0.19724205747425927 | validation: 0.21727977801631715]
	TIME [epoch: 10.3 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1995479409435208		[learning rate: 0.00012329]
	Learning Rate: 0.000123292
	LOSS [training: 0.1995479409435208 | validation: 0.2223600327720134]
	TIME [epoch: 10.3 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20478534468470788		[learning rate: 0.00012291]
	Learning Rate: 0.000122914
	LOSS [training: 0.20478534468470788 | validation: 0.22222922722710348]
	TIME [epoch: 10.3 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.210268110003007		[learning rate: 0.00012254]
	Learning Rate: 0.000122537
	LOSS [training: 0.210268110003007 | validation: 0.21687334780213094]
	TIME [epoch: 10.3 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19634289611389708		[learning rate: 0.00012216]
	Learning Rate: 0.000122161
	LOSS [training: 0.19634289611389708 | validation: 0.22097919209631442]
	TIME [epoch: 10.3 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1964639334960994		[learning rate: 0.00012179]
	Learning Rate: 0.000121787
	LOSS [training: 0.1964639334960994 | validation: 0.20335532427541808]
	TIME [epoch: 10.3 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20458929221360972		[learning rate: 0.00012141]
	Learning Rate: 0.000121413
	LOSS [training: 0.20458929221360972 | validation: 0.2174682187407921]
	TIME [epoch: 10.3 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21275185510133152		[learning rate: 0.00012104]
	Learning Rate: 0.000121041
	LOSS [training: 0.21275185510133152 | validation: 0.2154822399995441]
	TIME [epoch: 10.3 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20935114149913234		[learning rate: 0.00012067]
	Learning Rate: 0.00012067
	LOSS [training: 0.20935114149913234 | validation: 0.22796389529283176]
	TIME [epoch: 10.3 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2004221847646872		[learning rate: 0.0001203]
	Learning Rate: 0.0001203
	LOSS [training: 0.2004221847646872 | validation: 0.19777915981764105]
	TIME [epoch: 10.3 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19790019530267958		[learning rate: 0.00011993]
	Learning Rate: 0.000119932
	LOSS [training: 0.19790019530267958 | validation: 0.22908693367446933]
	TIME [epoch: 10.3 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19354185683098105		[learning rate: 0.00011956]
	Learning Rate: 0.000119564
	LOSS [training: 0.19354185683098105 | validation: 0.2155711338484862]
	TIME [epoch: 10.3 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20661816957568785		[learning rate: 0.0001192]
	Learning Rate: 0.000119197
	LOSS [training: 0.20661816957568785 | validation: 0.23476260184454606]
	TIME [epoch: 10.3 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2442406293188184		[learning rate: 0.00011883]
	Learning Rate: 0.000118832
	LOSS [training: 0.2442406293188184 | validation: 0.25690908025884185]
	TIME [epoch: 10.3 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2388492543526707		[learning rate: 0.00011847]
	Learning Rate: 0.000118468
	LOSS [training: 0.2388492543526707 | validation: 0.24263352143397068]
	TIME [epoch: 10.3 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22353028738694797		[learning rate: 0.0001181]
	Learning Rate: 0.000118105
	LOSS [training: 0.22353028738694797 | validation: 0.22522645221442494]
	TIME [epoch: 10.3 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20942893542947033		[learning rate: 0.00011774]
	Learning Rate: 0.000117743
	LOSS [training: 0.20942893542947033 | validation: 0.2113345581529309]
	TIME [epoch: 10.3 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19788866068391736		[learning rate: 0.00011738]
	Learning Rate: 0.000117382
	LOSS [training: 0.19788866068391736 | validation: 0.19679289658098692]
	TIME [epoch: 10.3 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19283966914453932		[learning rate: 0.00011702]
	Learning Rate: 0.000117022
	LOSS [training: 0.19283966914453932 | validation: 0.21573925116890721]
	TIME [epoch: 10.3 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.194535287527772		[learning rate: 0.00011666]
	Learning Rate: 0.000116663
	LOSS [training: 0.194535287527772 | validation: 0.19916563088705463]
	TIME [epoch: 10.3 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19962771307617538		[learning rate: 0.00011631]
	Learning Rate: 0.000116305
	LOSS [training: 0.19962771307617538 | validation: 0.21142653761933447]
	TIME [epoch: 10.3 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19493505461695626		[learning rate: 0.00011595]
	Learning Rate: 0.000115949
	LOSS [training: 0.19493505461695626 | validation: 0.216730422504953]
	TIME [epoch: 10.3 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1985855290273268		[learning rate: 0.00011559]
	Learning Rate: 0.000115593
	LOSS [training: 0.1985855290273268 | validation: 0.2261768571485969]
	TIME [epoch: 10.3 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1968001003694725		[learning rate: 0.00011524]
	Learning Rate: 0.000115239
	LOSS [training: 0.1968001003694725 | validation: 0.2183872690098508]
	TIME [epoch: 10.3 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19920349218084352		[learning rate: 0.00011489]
	Learning Rate: 0.000114886
	LOSS [training: 0.19920349218084352 | validation: 0.21024260186679997]
	TIME [epoch: 10.3 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19345719276780093		[learning rate: 0.00011453]
	Learning Rate: 0.000114534
	LOSS [training: 0.19345719276780093 | validation: 0.211519282905136]
	TIME [epoch: 10.3 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19074859389088591		[learning rate: 0.00011418]
	Learning Rate: 0.000114183
	LOSS [training: 0.19074859389088591 | validation: 0.2068852987611327]
	TIME [epoch: 10.3 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18768787526008932		[learning rate: 0.00011383]
	Learning Rate: 0.000113833
	LOSS [training: 0.18768787526008932 | validation: 0.2265918958631679]
	TIME [epoch: 10.3 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2012123821108526		[learning rate: 0.00011348]
	Learning Rate: 0.000113484
	LOSS [training: 0.2012123821108526 | validation: 0.21385284440094565]
	TIME [epoch: 10.3 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19909100670376073		[learning rate: 0.00011314]
	Learning Rate: 0.000113136
	LOSS [training: 0.19909100670376073 | validation: 0.2108386445278846]
	TIME [epoch: 10.3 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19911958345451858		[learning rate: 0.00011279]
	Learning Rate: 0.000112789
	LOSS [training: 0.19911958345451858 | validation: 0.22346157521364737]
	TIME [epoch: 10.3 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20831993959107548		[learning rate: 0.00011244]
	Learning Rate: 0.000112443
	LOSS [training: 0.20831993959107548 | validation: 0.22645112389790945]
	TIME [epoch: 10.3 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2098804494258882		[learning rate: 0.0001121]
	Learning Rate: 0.000112099
	LOSS [training: 0.2098804494258882 | validation: 0.2170098218238332]
	TIME [epoch: 10.3 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2000231483489617		[learning rate: 0.00011175]
	Learning Rate: 0.000111755
	LOSS [training: 0.2000231483489617 | validation: 0.21404809120018048]
	TIME [epoch: 10.3 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19855626752022631		[learning rate: 0.00011141]
	Learning Rate: 0.000111412
	LOSS [training: 0.19855626752022631 | validation: 0.20663221125622733]
	TIME [epoch: 10.3 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1860942255918248		[learning rate: 0.00011107]
	Learning Rate: 0.000111071
	LOSS [training: 0.1860942255918248 | validation: 0.21245280703035485]
	TIME [epoch: 10.3 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18746612791445105		[learning rate: 0.00011073]
	Learning Rate: 0.00011073
	LOSS [training: 0.18746612791445105 | validation: 0.21113005097803705]
	TIME [epoch: 10.3 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1913315901264863		[learning rate: 0.00011039]
	Learning Rate: 0.000110391
	LOSS [training: 0.1913315901264863 | validation: 0.21261955391275403]
	TIME [epoch: 10.3 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18630958667676734		[learning rate: 0.00011005]
	Learning Rate: 0.000110053
	LOSS [training: 0.18630958667676734 | validation: 0.2084886403607304]
	TIME [epoch: 10.3 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18986200242612367		[learning rate: 0.00010972]
	Learning Rate: 0.000109715
	LOSS [training: 0.18986200242612367 | validation: 0.2041386242264307]
	TIME [epoch: 10.3 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19831199324200854		[learning rate: 0.00010938]
	Learning Rate: 0.000109379
	LOSS [training: 0.19831199324200854 | validation: 0.20071384111565]
	TIME [epoch: 10.3 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19067134568344762		[learning rate: 0.00010904]
	Learning Rate: 0.000109044
	LOSS [training: 0.19067134568344762 | validation: 0.2024119318320328]
	TIME [epoch: 10.3 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18601340075744335		[learning rate: 0.00010871]
	Learning Rate: 0.000108709
	LOSS [training: 0.18601340075744335 | validation: 0.20707790332638623]
	TIME [epoch: 10.3 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18905941336982363		[learning rate: 0.00010838]
	Learning Rate: 0.000108376
	LOSS [training: 0.18905941336982363 | validation: 0.20883113020331892]
	TIME [epoch: 10.3 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18853575834147412		[learning rate: 0.00010804]
	Learning Rate: 0.000108044
	LOSS [training: 0.18853575834147412 | validation: 0.21243993302079325]
	TIME [epoch: 10.3 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19488810307142895		[learning rate: 0.00010771]
	Learning Rate: 0.000107713
	LOSS [training: 0.19488810307142895 | validation: 0.22476902948924127]
	TIME [epoch: 10.3 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19570512761514586		[learning rate: 0.00010738]
	Learning Rate: 0.000107382
	LOSS [training: 0.19570512761514586 | validation: 0.21467261761465847]
	TIME [epoch: 10.3 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19730282310071895		[learning rate: 0.00010705]
	Learning Rate: 0.000107053
	LOSS [training: 0.19730282310071895 | validation: 0.22971400881906576]
	TIME [epoch: 10.3 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.195548306617294		[learning rate: 0.00010673]
	Learning Rate: 0.000106725
	LOSS [training: 0.195548306617294 | validation: 0.21285897956248423]
	TIME [epoch: 10.3 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19657148456584744		[learning rate: 0.0001064]
	Learning Rate: 0.000106398
	LOSS [training: 0.19657148456584744 | validation: 0.24508805450214674]
	TIME [epoch: 10.3 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1926899745818891		[learning rate: 0.00010607]
	Learning Rate: 0.000106072
	LOSS [training: 0.1926899745818891 | validation: 0.2163675001785944]
	TIME [epoch: 10.3 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19311730595850074		[learning rate: 0.00010575]
	Learning Rate: 0.000105747
	LOSS [training: 0.19311730595850074 | validation: 0.2072036213014031]
	TIME [epoch: 10.3 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18800482199039764		[learning rate: 0.00010542]
	Learning Rate: 0.000105423
	LOSS [training: 0.18800482199039764 | validation: 0.20577393822319404]
	TIME [epoch: 10.3 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1986006760899242		[learning rate: 0.0001051]
	Learning Rate: 0.000105099
	LOSS [training: 0.1986006760899242 | validation: 0.20692301360488025]
	TIME [epoch: 10.3 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1923359481569606		[learning rate: 0.00010478]
	Learning Rate: 0.000104777
	LOSS [training: 0.1923359481569606 | validation: 0.20939667003061707]
	TIME [epoch: 10.3 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18867181320718718		[learning rate: 0.00010446]
	Learning Rate: 0.000104456
	LOSS [training: 0.18867181320718718 | validation: 0.19917243307225396]
	TIME [epoch: 10.3 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19519439833710922		[learning rate: 0.00010414]
	Learning Rate: 0.000104136
	LOSS [training: 0.19519439833710922 | validation: 0.2086645926770674]
	TIME [epoch: 10.3 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19088016333957167		[learning rate: 0.00010382]
	Learning Rate: 0.000103817
	LOSS [training: 0.19088016333957167 | validation: 0.21834986599862863]
	TIME [epoch: 10.3 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19693889709508763		[learning rate: 0.0001035]
	Learning Rate: 0.000103498
	LOSS [training: 0.19693889709508763 | validation: 0.20337841716076205]
	TIME [epoch: 10.3 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1922114231936131		[learning rate: 0.00010318]
	Learning Rate: 0.000103181
	LOSS [training: 0.1922114231936131 | validation: 0.19826957994257796]
	TIME [epoch: 10.3 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18520687124385143		[learning rate: 0.00010286]
	Learning Rate: 0.000102865
	LOSS [training: 0.18520687124385143 | validation: 0.2098466240560901]
	TIME [epoch: 10.3 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19084139014511853		[learning rate: 0.00010255]
	Learning Rate: 0.000102549
	LOSS [training: 0.19084139014511853 | validation: 0.21357866525930594]
	TIME [epoch: 10.3 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19887616322127627		[learning rate: 0.00010224]
	Learning Rate: 0.000102235
	LOSS [training: 0.19887616322127627 | validation: 0.21736396221406876]
	TIME [epoch: 10.3 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18942412284233287		[learning rate: 0.00010192]
	Learning Rate: 0.000101922
	LOSS [training: 0.18942412284233287 | validation: 0.21251627591841413]
	TIME [epoch: 10.3 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18806573042070804		[learning rate: 0.00010161]
	Learning Rate: 0.000101609
	LOSS [training: 0.18806573042070804 | validation: 0.2267452829366304]
	TIME [epoch: 10.3 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1906527552295393		[learning rate: 0.0001013]
	Learning Rate: 0.000101298
	LOSS [training: 0.1906527552295393 | validation: 0.20009615153480106]
	TIME [epoch: 10.3 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18917135592895795		[learning rate: 0.00010099]
	Learning Rate: 0.000100987
	LOSS [training: 0.18917135592895795 | validation: 0.19442837870905508]
	TIME [epoch: 10.3 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1911276741514507		[learning rate: 0.00010068]
	Learning Rate: 0.000100678
	LOSS [training: 0.1911276741514507 | validation: 0.19633562822190725]
	TIME [epoch: 10.3 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1906733060136089		[learning rate: 0.00010037]
	Learning Rate: 0.000100369
	LOSS [training: 0.1906733060136089 | validation: 0.20684810724174024]
	TIME [epoch: 10.3 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2065849270388757		[learning rate: 0.00010006]
	Learning Rate: 0.000100061
	LOSS [training: 0.2065849270388757 | validation: 0.21782239599571404]
	TIME [epoch: 10.3 sec]
Finished training in 20728.229 seconds.
