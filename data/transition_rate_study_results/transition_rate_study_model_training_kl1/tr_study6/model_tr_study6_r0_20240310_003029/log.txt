Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r0', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3559105884

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.678306652264599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.678306652264599 | validation: 9.697816473512667]
	TIME [epoch: 105 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.103378941156777		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.103378941156777 | validation: 7.811305428344451]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.6278751283667745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6278751283667745 | validation: 6.484322393681999]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.610224586547702		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.610224586547702 | validation: 5.847652018623078]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.777074026140074		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.777074026140074 | validation: 4.694655223886692]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.420189696625816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.420189696625816 | validation: 5.2614107451378835]
	TIME [epoch: 27.6 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.094405480849543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.094405480849543 | validation: 3.542575149429655]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8039251658794213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8039251658794213 | validation: 3.532659519552965]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4840262616200106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4840262616200106 | validation: 3.4234317001900747]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.782217218219995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.782217218219995 | validation: 3.2933710959306346]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.483876244879301		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.483876244879301 | validation: 3.173280064348467]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4420041017944905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4420041017944905 | validation: 3.375341036520299]
	TIME [epoch: 27.6 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.338651502962947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.338651502962947 | validation: 3.382158657740821]
	TIME [epoch: 27.7 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3305280805343207		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3305280805343207 | validation: 3.068854132641576]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1823274118642484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1823274118642484 | validation: 3.0392077886885334]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.097915809718863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.097915809718863 | validation: 4.87837651779781]
	TIME [epoch: 27.7 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9379033713442326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9379033713442326 | validation: 3.0465614568588384]
	TIME [epoch: 27.6 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2208443155260493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2208443155260493 | validation: 3.017303793127831]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.539445737902804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.539445737902804 | validation: 3.4339650037048024]
	TIME [epoch: 27.6 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4820877713342515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4820877713342515 | validation: 3.0466493813725233]
	TIME [epoch: 27.6 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4947582821552174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4947582821552174 | validation: 4.547694797002774]
	TIME [epoch: 27.6 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.934481674780037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.934481674780037 | validation: 4.406795369398544]
	TIME [epoch: 27.6 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6812062937628056		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6812062937628056 | validation: 2.977029791296114]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1232794135351147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1232794135351147 | validation: 3.0284016597469883]
	TIME [epoch: 27.6 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3112853662110338		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3112853662110338 | validation: 3.661698561469202]
	TIME [epoch: 27.6 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.395480247821404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.395480247821404 | validation: 6.493308061468305]
	TIME [epoch: 27.7 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.916427168315597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.916427168315597 | validation: 9.433724273789325]
	TIME [epoch: 27.6 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.427593138128776		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.427593138128776 | validation: 4.711656994837074]
	TIME [epoch: 27.6 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9059505667874324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9059505667874324 | validation: 3.4048182571447194]
	TIME [epoch: 27.6 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3840819779109106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3840819779109106 | validation: 3.2197945409724924]
	TIME [epoch: 27.6 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1896551315422648		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1896551315422648 | validation: 2.9248737258314215]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.15140863218973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.15140863218973 | validation: 3.317938062767687]
	TIME [epoch: 27.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.260199859282871		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.260199859282871 | validation: 2.8387181013429363]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_33.pth
	Model improved!!!
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2466550754116383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2466550754116383 | validation: 3.028321036212544]
	TIME [epoch: 27.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1005788024887977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1005788024887977 | validation: 2.976571765182556]
	TIME [epoch: 27.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.190411359319699		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.190411359319699 | validation: 3.388760200557599]
	TIME [epoch: 27.6 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7723498470244525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7723498470244525 | validation: 3.1812915683226954]
	TIME [epoch: 27.6 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2383204896641296		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2383204896641296 | validation: 3.0102239511553535]
	TIME [epoch: 27.6 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9600821186743014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9600821186743014 | validation: 2.794427745184913]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_39.pth
	Model improved!!!
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8618838718630286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8618838718630286 | validation: 4.463210476741974]
	TIME [epoch: 27.6 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.164290783006919		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.164290783006919 | validation: 3.0945330589742857]
	TIME [epoch: 27.7 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.990851974798709		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.990851974798709 | validation: 3.2339224788930427]
	TIME [epoch: 27.5 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.05865081440953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.05865081440953 | validation: 2.7124914312366846]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_43.pth
	Model improved!!!
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9579789700521877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9579789700521877 | validation: 2.7614123643354653]
	TIME [epoch: 27.6 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9072631711741836		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9072631711741836 | validation: 3.192532932711493]
	TIME [epoch: 27.5 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1504429164409156		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1504429164409156 | validation: 2.839379745655167]
	TIME [epoch: 27.7 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.498262994202789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.498262994202789 | validation: 4.2923066435923936]
	TIME [epoch: 27.7 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.126656074806153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.126656074806153 | validation: 3.1323594013815264]
	TIME [epoch: 27.6 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.24525039874104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.24525039874104 | validation: 2.664029675608588]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2941124654347247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2941124654347247 | validation: 4.0715601182891366]
	TIME [epoch: 27.6 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4988682887751876		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 3.4988682887751876 | validation: 3.813801772611949]
	TIME [epoch: 27.6 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5198713039907186		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.5198713039907186 | validation: 2.8849986216456562]
	TIME [epoch: 27.7 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.928794447307342		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.928794447307342 | validation: 3.5558662307535536]
	TIME [epoch: 27.6 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5337166248799807		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.5337166248799807 | validation: 3.1371847620302695]
	TIME [epoch: 27.7 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5141487830866263		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.5141487830866263 | validation: 3.4440689079648017]
	TIME [epoch: 27.6 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5912830000619174		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.5912830000619174 | validation: 3.38774433184442]
	TIME [epoch: 27.6 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2007779420565763		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.2007779420565763 | validation: 3.1954148980555033]
	TIME [epoch: 27.6 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.648429393349227		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.648429393349227 | validation: 4.341531444622632]
	TIME [epoch: 27.6 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9443714626356585		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.9443714626356585 | validation: 3.404316565461814]
	TIME [epoch: 27.6 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.203127034477067		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.203127034477067 | validation: 2.762704715919408]
	TIME [epoch: 27.6 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.716013178679558		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.716013178679558 | validation: 3.9369520768912447]
	TIME [epoch: 27.6 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.41638001493595		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 4.41638001493595 | validation: 3.713685237356705]
	TIME [epoch: 27.6 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5831701721326095		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 3.5831701721326095 | validation: 3.9416704914976743]
	TIME [epoch: 27.6 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3160784169022586		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 3.3160784169022586 | validation: 2.9112099185875047]
	TIME [epoch: 27.6 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9007020483905466		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.9007020483905466 | validation: 3.6756086916690562]
	TIME [epoch: 27.6 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8527506339248374		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 3.8527506339248374 | validation: 2.952588046359547]
	TIME [epoch: 27.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.911915566074164		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 2.911915566074164 | validation: 2.586561893996202]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_67.pth
	Model improved!!!
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6998311558503576		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 2.6998311558503576 | validation: 2.7557016888908437]
	TIME [epoch: 27.6 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.70609220668158		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 2.70609220668158 | validation: 2.4972654777022347]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.536620660304652		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 2.536620660304652 | validation: 2.7529484265129858]
	TIME [epoch: 27.6 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.021575819344806		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.021575819344806 | validation: 2.7833831144220778]
	TIME [epoch: 27.6 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8270449222494727		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 2.8270449222494727 | validation: 3.5518266401248675]
	TIME [epoch: 27.6 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.435139101637205		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 4.435139101637205 | validation: 3.2276742925196]
	TIME [epoch: 27.6 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8044149589598604		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 2.8044149589598604 | validation: 2.48813298748503]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_74.pth
	Model improved!!!
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9453097655709235		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.9453097655709235 | validation: 4.892076003480703]
	TIME [epoch: 27.6 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.552257886180971		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 5.552257886180971 | validation: 3.6999062718821687]
	TIME [epoch: 27.6 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.028199260626989		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.028199260626989 | validation: 3.0819648830502873]
	TIME [epoch: 27.6 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.895921654797818		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 2.895921654797818 | validation: 2.655862617299722]
	TIME [epoch: 27.6 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6077457265709603		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.6077457265709603 | validation: 2.6701208766866635]
	TIME [epoch: 27.6 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5738357442807107		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.5738357442807107 | validation: 4.0021452136773945]
	TIME [epoch: 27.6 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7271253343229995		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.7271253343229995 | validation: 3.8617821363244444]
	TIME [epoch: 27.6 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2263641344802165		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.2263641344802165 | validation: 3.4556409010229356]
	TIME [epoch: 27.6 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9317300338865393		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 2.9317300338865393 | validation: 2.87246367850542]
	TIME [epoch: 27.6 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.761258212770687		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.761258212770687 | validation: 2.569587985646275]
	TIME [epoch: 27.6 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.621508872791213		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.621508872791213 | validation: 3.212063510082272]
	TIME [epoch: 27.6 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.892714017045611		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.892714017045611 | validation: 2.8686823958745227]
	TIME [epoch: 27.6 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7773059552200063		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.7773059552200063 | validation: 2.6672382528327656]
	TIME [epoch: 27.6 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5813993061095823		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.5813993061095823 | validation: 2.5507390507602405]
	TIME [epoch: 27.6 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6258700972157003		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.6258700972157003 | validation: 2.672802502221577]
	TIME [epoch: 27.6 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5760054906912018		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.5760054906912018 | validation: 2.44834429628325]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4103609281877127		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.4103609281877127 | validation: 2.511121131670025]
	TIME [epoch: 27.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4108982661262193		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 2.4108982661262193 | validation: 2.2853076344970678]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.835162743944302		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.835162743944302 | validation: 2.594441318692807]
	TIME [epoch: 27.6 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.359606695745531		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 2.359606695745531 | validation: 2.4954088603655915]
	TIME [epoch: 27.6 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7895762004816436		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 2.7895762004816436 | validation: 2.4503143242322607]
	TIME [epoch: 27.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2271480083616484		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.2271480083616484 | validation: 2.4126598193657824]
	TIME [epoch: 27.6 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2591208179219886		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.2591208179219886 | validation: 2.3087846898969366]
	TIME [epoch: 27.6 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.195278576598724		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.195278576598724 | validation: 2.582397865860455]
	TIME [epoch: 27.6 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.10145828419854		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.10145828419854 | validation: 2.20286785535478]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_99.pth
	Model improved!!!
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1962038268473396		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.1962038268473396 | validation: 2.182385280666539]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_100.pth
	Model improved!!!
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.998725102024224		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 1.998725102024224 | validation: 2.1114660763510176]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0597920595964836		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.0597920595964836 | validation: 2.600926606804996]
	TIME [epoch: 27.6 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0923500418900614		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.0923500418900614 | validation: 1.8447274068401538]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_103.pth
	Model improved!!!
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7238736011191835		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 1.7238736011191835 | validation: 1.7288237429930728]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_104.pth
	Model improved!!!
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9400580308499777		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 1.9400580308499777 | validation: 1.7910641964701683]
	TIME [epoch: 27.5 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7506064259438423		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 1.7506064259438423 | validation: 1.6376660551594922]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_106.pth
	Model improved!!!
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7863869020174252		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 1.7863869020174252 | validation: 1.6646824993012161]
	TIME [epoch: 27.6 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6992884368850691		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 1.6992884368850691 | validation: 1.8534941353327044]
	TIME [epoch: 27.6 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.619095876004827		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 1.619095876004827 | validation: 1.452649140437577]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_109.pth
	Model improved!!!
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.464970082484979		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 1.464970082484979 | validation: 1.3852294232006932]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4037361361013985		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.4037361361013985 | validation: 1.4421236689915389]
	TIME [epoch: 27.6 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3796229152161363		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 1.3796229152161363 | validation: 1.4406443666237703]
	TIME [epoch: 27.6 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3051544790225895		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.3051544790225895 | validation: 1.2324374281620967]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_113.pth
	Model improved!!!
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2485803597971321		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.2485803597971321 | validation: 2.2040552415606043]
	TIME [epoch: 27.6 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8380384358069708		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 1.8380384358069708 | validation: 1.2276312021345674]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4484056395653147		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 1.4484056395653147 | validation: 1.1513673819584995]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1239419525799283		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.1239419525799283 | validation: 0.9900389050427326]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0689679217295935		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.0689679217295935 | validation: 0.8678669125836262]
	TIME [epoch: 27.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9416843124540758		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 0.9416843124540758 | validation: 1.4432924220508818]
	TIME [epoch: 27.6 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0941846593713398		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 1.0941846593713398 | validation: 1.5080502543545282]
	TIME [epoch: 27.6 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.041697986219436		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 1.041697986219436 | validation: 0.8488998382800839]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_121.pth
	Model improved!!!
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7180442685150523		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 0.7180442685150523 | validation: 0.834414542824906]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_122.pth
	Model improved!!!
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8437907144863229		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 0.8437907144863229 | validation: 1.3067826419059552]
	TIME [epoch: 27.5 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9862320684407795		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 0.9862320684407795 | validation: 1.1713792140155344]
	TIME [epoch: 27.6 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9990972796260777		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 0.9990972796260777 | validation: 0.7062859681663377]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8405665804699505		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 0.8405665804699505 | validation: 0.7609054036911909]
	TIME [epoch: 27.6 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8065524885579524		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 0.8065524885579524 | validation: 0.6645816957533189]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1578887062987246		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 1.1578887062987246 | validation: 0.8843928535140024]
	TIME [epoch: 27.7 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8787532957492058		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 0.8787532957492058 | validation: 0.6694862601182393]
	TIME [epoch: 27.7 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2938596773727524		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.2938596773727524 | validation: 1.1544017538163993]
	TIME [epoch: 27.7 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0413871403439612		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 1.0413871403439612 | validation: 0.7417469379716711]
	TIME [epoch: 27.7 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9116688371319698		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 0.9116688371319698 | validation: 0.7988433778668506]
	TIME [epoch: 27.7 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1697792730392726		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 1.1697792730392726 | validation: 0.6542237796410632]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8056273516580448		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 0.8056273516580448 | validation: 0.6681825735343324]
	TIME [epoch: 27.6 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9235142215601775		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 0.9235142215601775 | validation: 0.663235180341688]
	TIME [epoch: 27.6 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7945578575258755		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 0.7945578575258755 | validation: 0.6456975701614218]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8668085887251324		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 0.8668085887251324 | validation: 0.7114692128245573]
	TIME [epoch: 27.6 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7135217759809351		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 0.7135217759809351 | validation: 0.8910192149314279]
	TIME [epoch: 27.6 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290053207620455		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 0.7290053207620455 | validation: 0.9212928790523719]
	TIME [epoch: 27.6 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7712337685277648		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 0.7712337685277648 | validation: 0.6865250815116895]
	TIME [epoch: 27.6 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8146122422493257		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.8146122422493257 | validation: 0.9395793708764422]
	TIME [epoch: 27.6 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7282950709025895		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 0.7282950709025895 | validation: 1.2919754013946676]
	TIME [epoch: 27.6 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8723453255375994		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 0.8723453255375994 | validation: 0.6059837437525305]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5920194233873461		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.5920194233873461 | validation: 1.0882265693226574]
	TIME [epoch: 27.6 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9345976936059337		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 0.9345976936059337 | validation: 1.2106709681541805]
	TIME [epoch: 27.6 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8429894484605261		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 0.8429894484605261 | validation: 0.5794861188416737]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_146.pth
	Model improved!!!
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6774170529423446		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 0.6774170529423446 | validation: 3.0322101215279447]
	TIME [epoch: 27.6 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8508079198577045		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.8508079198577045 | validation: 0.6853307351709327]
	TIME [epoch: 27.6 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8248841929422093		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 0.8248841929422093 | validation: 1.1030805180326002]
	TIME [epoch: 27.6 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7998781587954934		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 0.7998781587954934 | validation: 0.6585361833218303]
	TIME [epoch: 27.6 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6680887893793273		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 0.6680887893793273 | validation: 1.0056345492062733]
	TIME [epoch: 27.6 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0200458726678183		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.0200458726678183 | validation: 0.9484611907744129]
	TIME [epoch: 27.6 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8038412291808301		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 0.8038412291808301 | validation: 0.7642959100061143]
	TIME [epoch: 27.6 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7859640724704907		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 0.7859640724704907 | validation: 1.4932761165247075]
	TIME [epoch: 27.6 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.050280296789765		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 1.050280296789765 | validation: 0.6549143317153849]
	TIME [epoch: 27.6 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6309817266264302		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 0.6309817266264302 | validation: 2.6451280599304177]
	TIME [epoch: 27.6 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3867899167785338		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 1.3867899167785338 | validation: 0.7622769472904469]
	TIME [epoch: 27.6 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6676042562629589		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 0.6676042562629589 | validation: 0.7429792911839874]
	TIME [epoch: 27.6 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0301475255324752		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.0301475255324752 | validation: 1.1862512200655926]
	TIME [epoch: 27.6 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8792470833236674		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 0.8792470833236674 | validation: 0.9011471530548059]
	TIME [epoch: 27.6 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7120869326026456		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 0.7120869326026456 | validation: 0.7565740948628568]
	TIME [epoch: 27.6 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6086355482563355		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 0.6086355482563355 | validation: 1.4815884968527917]
	TIME [epoch: 27.6 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8165266553442923		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 0.8165266553442923 | validation: 0.9746490361864153]
	TIME [epoch: 27.6 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7542701337134823		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 0.7542701337134823 | validation: 0.5755040269796103]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_164.pth
	Model improved!!!
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7458109819207688		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 0.7458109819207688 | validation: 0.6903569744932484]
	TIME [epoch: 27.6 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7855697418043857		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 0.7855697418043857 | validation: 0.9588425992021694]
	TIME [epoch: 27.6 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6893065857570353		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 0.6893065857570353 | validation: 0.6407968832918269]
	TIME [epoch: 27.6 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6021198583921376		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 0.6021198583921376 | validation: 0.7386976907923828]
	TIME [epoch: 27.6 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8775242175507263		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 0.8775242175507263 | validation: 0.7256291610387586]
	TIME [epoch: 27.6 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6457307190300776		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 0.6457307190300776 | validation: 0.5816730685355401]
	TIME [epoch: 27.6 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6692380416659514		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 0.6692380416659514 | validation: 0.7665869145668459]
	TIME [epoch: 27.6 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6095700088987732		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 0.6095700088987732 | validation: 1.1801682120355748]
	TIME [epoch: 27.6 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0301026612644266		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.0301026612644266 | validation: 0.5449869908114388]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_173.pth
	Model improved!!!
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5550515678060521		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 0.5550515678060521 | validation: 0.563491283117174]
	TIME [epoch: 27.6 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5345589533109282		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 0.5345589533109282 | validation: 0.7892254691364182]
	TIME [epoch: 27.6 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7333244866540405		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 0.7333244866540405 | validation: 2.1565827196312912]
	TIME [epoch: 27.6 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.294829384868851		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.294829384868851 | validation: 0.8725581853313092]
	TIME [epoch: 27.6 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.524936992370828		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.524936992370828 | validation: 1.023895802789204]
	TIME [epoch: 27.6 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7213788128216558		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 0.7213788128216558 | validation: 0.7428196816523002]
	TIME [epoch: 27.6 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236654638138502		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 0.7236654638138502 | validation: 0.7811625813145466]
	TIME [epoch: 27.6 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9075778585244264		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.9075778585244264 | validation: 0.6750320843118169]
	TIME [epoch: 27.6 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6084055292111151		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 0.6084055292111151 | validation: 0.5633674498375182]
	TIME [epoch: 27.6 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770622713148995		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 0.5770622713148995 | validation: 0.4874174858589899]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_183.pth
	Model improved!!!
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5902079606167979		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 0.5902079606167979 | validation: 0.9070916975848978]
	TIME [epoch: 27.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6682934754181198		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 0.6682934754181198 | validation: 0.8042354044331971]
	TIME [epoch: 27.6 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.682939053324759		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 0.682939053324759 | validation: 0.593282187439915]
	TIME [epoch: 27.6 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5774891629854165		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 0.5774891629854165 | validation: 0.5379005200220162]
	TIME [epoch: 27.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5877285897120286		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 0.5877285897120286 | validation: 0.6409462042440436]
	TIME [epoch: 27.6 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1412086667276093		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 1.1412086667276093 | validation: 1.0066871621172313]
	TIME [epoch: 27.7 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0656983446126007		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.0656983446126007 | validation: 0.8054159712467137]
	TIME [epoch: 27.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.677901123278175		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 0.677901123278175 | validation: 0.7198931139535845]
	TIME [epoch: 27.6 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7502065760689212		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 0.7502065760689212 | validation: 0.6659155063197923]
	TIME [epoch: 27.6 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688703692486641		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 0.7688703692486641 | validation: 0.7707950568190611]
	TIME [epoch: 27.6 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.620235836727781		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 0.620235836727781 | validation: 0.6754036330109253]
	TIME [epoch: 27.6 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.663385435820997		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 0.663385435820997 | validation: 1.2053509105751008]
	TIME [epoch: 27.6 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8032621407473389		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.8032621407473389 | validation: 0.6820172164191561]
	TIME [epoch: 27.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7285572694491049		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.7285572694491049 | validation: 1.0504369420396293]
	TIME [epoch: 27.6 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8940809451300653		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.8940809451300653 | validation: 0.6695618160174236]
	TIME [epoch: 27.6 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8264197237923072		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.8264197237923072 | validation: 0.749253978095559]
	TIME [epoch: 27.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6874339604331016		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 0.6874339604331016 | validation: 0.7649054288351925]
	TIME [epoch: 27.6 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.619989355136658		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 0.619989355136658 | validation: 0.6717539722090843]
	TIME [epoch: 27.6 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.638540502181505		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.638540502181505 | validation: 0.7093272738973295]
	TIME [epoch: 27.6 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6505931730665381		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 0.6505931730665381 | validation: 0.8356991289488691]
	TIME [epoch: 27.6 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6073144393373949		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.6073144393373949 | validation: 0.6239818283097504]
	TIME [epoch: 27.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6427653563387583		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.6427653563387583 | validation: 0.8045788841534627]
	TIME [epoch: 27.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6754333297977795		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 0.6754333297977795 | validation: 0.6838799181308322]
	TIME [epoch: 27.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8312281025755004		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 0.8312281025755004 | validation: 2.5332603585567717]
	TIME [epoch: 27.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5301610287712233		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 1.5301610287712233 | validation: 0.5818802301258257]
	TIME [epoch: 27.6 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6213209372890225		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.6213209372890225 | validation: 0.7357850415097713]
	TIME [epoch: 27.6 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6696241851642276		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.6696241851642276 | validation: 0.7218531907099421]
	TIME [epoch: 27.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.709438169414312		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.709438169414312 | validation: 1.4632947930173297]
	TIME [epoch: 27.6 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8141208530163768		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 1.8141208530163768 | validation: 0.8118781626521951]
	TIME [epoch: 27.7 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6924974326574519		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.6924974326574519 | validation: 0.8174745279244812]
	TIME [epoch: 27.6 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7699594878363825		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 0.7699594878363825 | validation: 0.8659337045045092]
	TIME [epoch: 27.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6504081545256895		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.6504081545256895 | validation: 0.6078565144374134]
	TIME [epoch: 27.6 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5784884878102052		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 0.5784884878102052 | validation: 0.8269050901426084]
	TIME [epoch: 27.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6422220123414653		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.6422220123414653 | validation: 0.578345463596063]
	TIME [epoch: 27.6 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5943307405343667		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.5943307405343667 | validation: 0.6194065688307003]
	TIME [epoch: 27.6 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6940536926967604		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 0.6940536926967604 | validation: 0.740972146543682]
	TIME [epoch: 27.6 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7200078836140262		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.7200078836140262 | validation: 1.159741461483284]
	TIME [epoch: 27.7 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7474623267727663		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 0.7474623267727663 | validation: 0.6202457041811783]
	TIME [epoch: 27.6 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6135618186426243		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 0.6135618186426243 | validation: 0.6074665398345791]
	TIME [epoch: 27.6 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5949750390007029		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 0.5949750390007029 | validation: 0.6241222570700308]
	TIME [epoch: 27.6 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6069326402687151		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.6069326402687151 | validation: 0.5728697486763873]
	TIME [epoch: 27.7 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6000663844968924		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 0.6000663844968924 | validation: 0.55132906655857]
	TIME [epoch: 27.6 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508219440213975		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 0.5508219440213975 | validation: 0.8058336262277089]
	TIME [epoch: 27.6 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6787386256215666		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.6787386256215666 | validation: 0.5222051503808208]
	TIME [epoch: 27.6 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6302327532442737		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.6302327532442737 | validation: 0.5764471581195012]
	TIME [epoch: 27.6 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5455742437159055		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.5455742437159055 | validation: 0.5847552784217305]
	TIME [epoch: 27.6 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7795260757487767		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 0.7795260757487767 | validation: 0.5384374396586162]
	TIME [epoch: 27.6 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5176888209564474		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.5176888209564474 | validation: 0.5517647800138805]
	TIME [epoch: 27.6 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960589854050004		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.5960589854050004 | validation: 0.7816667094355498]
	TIME [epoch: 27.7 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6299004180874038		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.6299004180874038 | validation: 0.630772938052735]
	TIME [epoch: 27.7 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5785237524241053		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.5785237524241053 | validation: 0.729938848423495]
	TIME [epoch: 27.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7338874647133833		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.7338874647133833 | validation: 0.60987265638227]
	TIME [epoch: 27.6 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5417036817301606		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.5417036817301606 | validation: 0.5422352986958994]
	TIME [epoch: 27.7 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5656665064425641		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 0.5656665064425641 | validation: 0.6210385368122266]
	TIME [epoch: 27.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7413801579537177		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.7413801579537177 | validation: 0.8106370391539853]
	TIME [epoch: 27.6 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6589821767120287		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.6589821767120287 | validation: 0.6193715541573476]
	TIME [epoch: 27.7 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.609166400677072		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.609166400677072 | validation: 0.6685582000452827]
	TIME [epoch: 27.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6000088764346629		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 0.6000088764346629 | validation: 0.6998179573701768]
	TIME [epoch: 27.7 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5966542672845353		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.5966542672845353 | validation: 0.5990338521057315]
	TIME [epoch: 27.7 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6293710556934878		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 0.6293710556934878 | validation: 0.6905705569627031]
	TIME [epoch: 27.6 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6048298874069119		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.6048298874069119 | validation: 0.6936807903261933]
	TIME [epoch: 27.7 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5896280854619225		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.5896280854619225 | validation: 0.5958707827250684]
	TIME [epoch: 27.6 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.653742934993986		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.653742934993986 | validation: 0.742030914526562]
	TIME [epoch: 27.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5587273695977025		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.5587273695977025 | validation: 0.6777901487098734]
	TIME [epoch: 27.7 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7214189663638466		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.7214189663638466 | validation: 0.7151695097690296]
	TIME [epoch: 27.6 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.597531118442641		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.597531118442641 | validation: 0.5802643225320203]
	TIME [epoch: 27.6 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5313091868776458		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.5313091868776458 | validation: 0.6725928017793237]
	TIME [epoch: 27.7 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5949869033628574		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.5949869033628574 | validation: 0.5513162807053099]
	TIME [epoch: 27.6 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5123879610552323		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.5123879610552323 | validation: 0.6617940079069566]
	TIME [epoch: 27.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5608173875925385		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.5608173875925385 | validation: 0.6096966297550158]
	TIME [epoch: 27.6 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6407272762567496		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.6407272762567496 | validation: 0.6467799246180096]
	TIME [epoch: 27.6 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5741425704780226		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.5741425704780226 | validation: 0.5763225651995082]
	TIME [epoch: 27.6 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6852344618064177		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.6852344618064177 | validation: 0.8597073564541441]
	TIME [epoch: 27.7 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7163659910949135		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.7163659910949135 | validation: 0.6276813242308397]
	TIME [epoch: 27.6 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5862457252326807		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.5862457252326807 | validation: 0.6830049190531813]
	TIME [epoch: 27.6 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6442204286203057		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.6442204286203057 | validation: 0.6410703642592867]
	TIME [epoch: 27.7 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6068949234671787		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 0.6068949234671787 | validation: 0.6158020763265107]
	TIME [epoch: 27.6 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5886033753276156		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.5886033753276156 | validation: 0.8215047379054815]
	TIME [epoch: 27.6 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6319038590390406		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.6319038590390406 | validation: 0.9432850550540641]
	TIME [epoch: 27.7 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7278383130618518		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.7278383130618518 | validation: 0.6471833441382254]
	TIME [epoch: 27.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6037325748737059		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 0.6037325748737059 | validation: 0.6039654671689152]
	TIME [epoch: 27.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.546274791328289		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.546274791328289 | validation: 0.6717403292314466]
	TIME [epoch: 27.6 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6947871168734414		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.6947871168734414 | validation: 0.5762442297074772]
	TIME [epoch: 27.7 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6809494460392936		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 0.6809494460392936 | validation: 0.5912035386655012]
	TIME [epoch: 27.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6549063627280982		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.6549063627280982 | validation: 0.49489490130841546]
	TIME [epoch: 27.6 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44949655356575224		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.44949655356575224 | validation: 0.4629296077005338]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_269.pth
	Model improved!!!
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7596838285356695		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.7596838285356695 | validation: 0.5688612839981191]
	TIME [epoch: 27.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5909787555910898		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.5909787555910898 | validation: 0.5733240613835244]
	TIME [epoch: 27.7 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5420394466773301		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.5420394466773301 | validation: 0.48483028239715503]
	TIME [epoch: 27.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4665423300484592		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.4665423300484592 | validation: 0.4681399788606968]
	TIME [epoch: 27.6 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8295454020092281		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.8295454020092281 | validation: 1.3953550977454514]
	TIME [epoch: 27.7 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0142603140714295		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 1.0142603140714295 | validation: 0.6050280900551772]
	TIME [epoch: 27.6 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5822606935119286		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 0.5822606935119286 | validation: 1.0171636361873608]
	TIME [epoch: 27.6 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9069921088083105		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 0.9069921088083105 | validation: 0.6988757175188366]
	TIME [epoch: 27.7 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5731325476534009		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.5731325476534009 | validation: 0.45832066312580777]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_278.pth
	Model improved!!!
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6422067342263276		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.6422067342263276 | validation: 0.7336496760582031]
	TIME [epoch: 27.7 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6027372254016399		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.6027372254016399 | validation: 0.4875234739316312]
	TIME [epoch: 27.6 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6964055098601112		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 0.6964055098601112 | validation: 0.6026308515033734]
	TIME [epoch: 27.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7030673922532186		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 0.7030673922532186 | validation: 0.5209063204095106]
	TIME [epoch: 27.7 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.621570146163861		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.621570146163861 | validation: 0.8171282718360436]
	TIME [epoch: 27.7 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8221369509642147		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.8221369509642147 | validation: 0.5511944216223984]
	TIME [epoch: 27.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.549196314125725		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.549196314125725 | validation: 0.5497973943930663]
	TIME [epoch: 27.7 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5397049266988356		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 0.5397049266988356 | validation: 0.7113411519426543]
	TIME [epoch: 27.7 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6406652752816694		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 0.6406652752816694 | validation: 0.6606253073704779]
	TIME [epoch: 27.8 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5648782370655113		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.5648782370655113 | validation: 0.5948500841226346]
	TIME [epoch: 27.6 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5471235095681497		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.5471235095681497 | validation: 0.5737265469019458]
	TIME [epoch: 27.7 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5530856753969616		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 0.5530856753969616 | validation: 0.5880151875063507]
	TIME [epoch: 27.6 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5414009238691224		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 0.5414009238691224 | validation: 0.573582667872559]
	TIME [epoch: 27.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5050382149692224		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.5050382149692224 | validation: 0.755528153201981]
	TIME [epoch: 27.7 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9502106972298585		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 0.9502106972298585 | validation: 0.5116317672332757]
	TIME [epoch: 27.6 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49437722099600545		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.49437722099600545 | validation: 0.5023999611681107]
	TIME [epoch: 27.7 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5675772222738036		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.5675772222738036 | validation: 0.6320958911520714]
	TIME [epoch: 27.7 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838131590800625		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.5838131590800625 | validation: 0.6198543982321075]
	TIME [epoch: 27.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231697883830214		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.5231697883830214 | validation: 0.5712866300793686]
	TIME [epoch: 27.7 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.736719522631815		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.736719522631815 | validation: 0.8619504820959613]
	TIME [epoch: 27.6 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.684678658561457		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.684678658561457 | validation: 0.4928474731169182]
	TIME [epoch: 27.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4759008035097725		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.4759008035097725 | validation: 0.4882941957513825]
	TIME [epoch: 27.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6056982355919016		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.6056982355919016 | validation: 0.5317374622174333]
	TIME [epoch: 27.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5987887430849044		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.5987887430849044 | validation: 0.49660869643137134]
	TIME [epoch: 27.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5201198473352773		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.5201198473352773 | validation: 0.53928760333637]
	TIME [epoch: 27.6 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071962197538772		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.5071962197538772 | validation: 0.5056573877661475]
	TIME [epoch: 27.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5882306219542828		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.5882306219542828 | validation: 0.7524299495400502]
	TIME [epoch: 27.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5764208320088257		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.5764208320088257 | validation: 0.44866261102281874]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_306.pth
	Model improved!!!
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5385371041941225		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.5385371041941225 | validation: 0.7905210368731723]
	TIME [epoch: 27.7 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6486720607233988		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.6486720607233988 | validation: 0.5173951745467364]
	TIME [epoch: 27.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.586922605273675		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.586922605273675 | validation: 0.6776336368575495]
	TIME [epoch: 27.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2149130770342438		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.2149130770342438 | validation: 1.0607444786208589]
	TIME [epoch: 27.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7686442238585285		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.7686442238585285 | validation: 0.6545629867562388]
	TIME [epoch: 27.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5790645415043139		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 0.5790645415043139 | validation: 0.599370853911408]
	TIME [epoch: 27.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5501612609876732		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.5501612609876732 | validation: 0.5561898481267408]
	TIME [epoch: 27.7 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5680405213246944		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.5680405213246944 | validation: 0.5898628926541667]
	TIME [epoch: 27.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.53350428227167		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.53350428227167 | validation: 0.5741901091973999]
	TIME [epoch: 27.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5389999379807888		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 0.5389999379807888 | validation: 0.5313119977967884]
	TIME [epoch: 27.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5336578914088648		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 0.5336578914088648 | validation: 0.5365032721650141]
	TIME [epoch: 27.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5134064486865354		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.5134064486865354 | validation: 0.690178276924068]
	TIME [epoch: 27.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6213474394014253		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.6213474394014253 | validation: 0.560513792082994]
	TIME [epoch: 27.8 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7557968277250202		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.7557968277250202 | validation: 0.6032415720066328]
	TIME [epoch: 27.6 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6967988362695966		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.6967988362695966 | validation: 0.5154864439674138]
	TIME [epoch: 27.8 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5051455399552267		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.5051455399552267 | validation: 0.550242217069793]
	TIME [epoch: 27.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7197215782566921		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.7197215782566921 | validation: 0.5481426766510958]
	TIME [epoch: 27.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5288580845267064		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.5288580845267064 | validation: 0.6854805520952513]
	TIME [epoch: 27.7 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8071763854938552		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8071763854938552 | validation: 1.0355965985512625]
	TIME [epoch: 27.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9840633784143945		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.9840633784143945 | validation: 0.6814846912976534]
	TIME [epoch: 27.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6244445143361669		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.6244445143361669 | validation: 0.6816994331790907]
	TIME [epoch: 27.7 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5840616677577148		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.5840616677577148 | validation: 0.6091129750469007]
	TIME [epoch: 27.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6597797141341717		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.6597797141341717 | validation: 0.8750925707623578]
	TIME [epoch: 27.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.565822183976412		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.565822183976412 | validation: 0.516263876921126]
	TIME [epoch: 27.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5246407709927461		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.5246407709927461 | validation: 0.5590576299113991]
	TIME [epoch: 27.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5031729008439403		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.5031729008439403 | validation: 0.4966462048139067]
	TIME [epoch: 27.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5117805214039224		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.5117805214039224 | validation: 0.4889715914215442]
	TIME [epoch: 27.6 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5700742726592006		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.5700742726592006 | validation: 0.5550393312114001]
	TIME [epoch: 27.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5153071170200423		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.5153071170200423 | validation: 0.48389393891487]
	TIME [epoch: 27.6 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6955854998889397		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.6955854998889397 | validation: 1.2565569071784848]
	TIME [epoch: 27.6 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0263610580177494		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.0263610580177494 | validation: 0.6142960711923001]
	TIME [epoch: 27.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5202408019225364		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.5202408019225364 | validation: 0.4186023561147816]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_338.pth
	Model improved!!!
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.491766116967572		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.491766116967572 | validation: 0.6611457283794678]
	TIME [epoch: 27.7 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6392390564374897		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.6392390564374897 | validation: 0.6923131535325482]
	TIME [epoch: 27.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5823931387163667		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.5823931387163667 | validation: 0.5848409021938392]
	TIME [epoch: 27.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5430268573486676		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.5430268573486676 | validation: 0.5801814743790049]
	TIME [epoch: 27.7 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5528961941331589		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.5528961941331589 | validation: 0.6825234070633647]
	TIME [epoch: 27.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0179486823047719		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.0179486823047719 | validation: 0.6075272808008209]
	TIME [epoch: 27.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.542024606581474		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.542024606581474 | validation: 0.5221978392253117]
	TIME [epoch: 27.6 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4650042557170235		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.4650042557170235 | validation: 0.5030615228955243]
	TIME [epoch: 27.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5392496781429098		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.5392496781429098 | validation: 0.6588521385604759]
	TIME [epoch: 27.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6168871878193822		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 0.6168871878193822 | validation: 0.5412152466204421]
	TIME [epoch: 27.7 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5411378076935198		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.5411378076935198 | validation: 0.4558190504771369]
	TIME [epoch: 27.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48602734449995594		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.48602734449995594 | validation: 0.4317137654815264]
	TIME [epoch: 27.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4408716970783436		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 0.4408716970783436 | validation: 0.4742530302814892]
	TIME [epoch: 27.7 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4827992680965977		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 0.4827992680965977 | validation: 0.6836593629929217]
	TIME [epoch: 27.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113721495521406		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.5113721495521406 | validation: 0.3892545026419923]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_353.pth
	Model improved!!!
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4512998602706063		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.4512998602706063 | validation: 0.45119656284982923]
	TIME [epoch: 27.7 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5306540318708786		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 0.5306540318708786 | validation: 0.5573370714550933]
	TIME [epoch: 27.7 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5468193458293129		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.5468193458293129 | validation: 0.5045263971523228]
	TIME [epoch: 27.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205143636368639		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.5205143636368639 | validation: 0.6064862523272345]
	TIME [epoch: 27.7 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5564602955012468		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.5564602955012468 | validation: 0.6425529090403511]
	TIME [epoch: 27.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5423600556871936		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.5423600556871936 | validation: 0.5349072313511762]
	TIME [epoch: 27.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5055266843162244		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.5055266843162244 | validation: 0.48427967491964097]
	TIME [epoch: 27.7 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6092167010034661		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.6092167010034661 | validation: 0.6648512283945774]
	TIME [epoch: 27.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.632427854274791		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.632427854274791 | validation: 0.5770185059938384]
	TIME [epoch: 27.7 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071535743658331		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.5071535743658331 | validation: 0.4726843088583116]
	TIME [epoch: 27.7 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.518312483535825		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.518312483535825 | validation: 0.6204180521379439]
	TIME [epoch: 27.7 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5014217006788325		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.5014217006788325 | validation: 0.49519806251390136]
	TIME [epoch: 27.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5179446656698621		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.5179446656698621 | validation: 0.476326581030049]
	TIME [epoch: 27.7 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037135309340866		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.5037135309340866 | validation: 0.5387438360126916]
	TIME [epoch: 27.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48986304779133144		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.48986304779133144 | validation: 0.49027912212229263]
	TIME [epoch: 27.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4790988659726849		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.4790988659726849 | validation: 0.4725748136100621]
	TIME [epoch: 27.7 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4750311163831869		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.4750311163831869 | validation: 0.6200357315898439]
	TIME [epoch: 27.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399304583874589		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.5399304583874589 | validation: 0.5979386584032979]
	TIME [epoch: 27.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6203470312820136		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.6203470312820136 | validation: 0.7948347597558933]
	TIME [epoch: 27.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.601152274073884		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.601152274073884 | validation: 0.5465854389669061]
	TIME [epoch: 27.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5127849180858475		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.5127849180858475 | validation: 0.514493144423046]
	TIME [epoch: 27.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5418997091729726		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.5418997091729726 | validation: 0.6478141831999684]
	TIME [epoch: 27.7 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.723808553095509		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.723808553095509 | validation: 0.5700902914970003]
	TIME [epoch: 27.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5912869263155894		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.5912869263155894 | validation: 0.5357204411156252]
	TIME [epoch: 27.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5945453489273537		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.5945453489273537 | validation: 0.6376222880684997]
	TIME [epoch: 27.7 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5803551666692948		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.5803551666692948 | validation: 0.8570571279125355]
	TIME [epoch: 27.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6392089994193842		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.6392089994193842 | validation: 0.5669094410126085]
	TIME [epoch: 27.7 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5243538497023762		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5243538497023762 | validation: 0.5027096360115085]
	TIME [epoch: 27.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4858044259593931		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.4858044259593931 | validation: 0.46580401593290405]
	TIME [epoch: 27.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8247863796189701		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.8247863796189701 | validation: 0.8265978383178123]
	TIME [epoch: 27.6 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6128309490376379		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.6128309490376379 | validation: 0.7301098043215566]
	TIME [epoch: 27.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6404049199189895		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.6404049199189895 | validation: 0.5781426556980046]
	TIME [epoch: 27.6 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5536375262825182		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.5536375262825182 | validation: 0.5435501493052197]
	TIME [epoch: 27.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377382034357283		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.5377382034357283 | validation: 0.6496399741839364]
	TIME [epoch: 27.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5774463726128619		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 0.5774463726128619 | validation: 0.5646780590254425]
	TIME [epoch: 27.6 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5060055777822767		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.5060055777822767 | validation: 0.4776990623909862]
	TIME [epoch: 27.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.487273977119526		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 0.487273977119526 | validation: 0.5853523004550735]
	TIME [epoch: 27.6 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6347340421727854		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 0.6347340421727854 | validation: 0.5805533740967291]
	TIME [epoch: 27.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.494986440385463		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.494986440385463 | validation: 0.463196562077037]
	TIME [epoch: 27.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43370567722478415		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.43370567722478415 | validation: 0.7364429373230292]
	TIME [epoch: 27.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6031980028747036		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.6031980028747036 | validation: 0.5204555535217241]
	TIME [epoch: 27.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48248783338500323		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.48248783338500323 | validation: 0.5123107793874297]
	TIME [epoch: 27.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46822772609381225		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.46822772609381225 | validation: 0.4084357573208668]
	TIME [epoch: 27.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5098643009369221		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.5098643009369221 | validation: 0.6154658254201122]
	TIME [epoch: 27.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5662426810338191		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.5662426810338191 | validation: 0.5840588902985304]
	TIME [epoch: 27.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.530939191513579		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.530939191513579 | validation: 0.6248590065358477]
	TIME [epoch: 27.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5567731606228536		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.5567731606228536 | validation: 0.6043404125457609]
	TIME [epoch: 27.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5346206730680245		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.5346206730680245 | validation: 0.5695791759522473]
	TIME [epoch: 27.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5425905041130263		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5425905041130263 | validation: 0.7143229109133218]
	TIME [epoch: 27.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5741742541314012		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.5741742541314012 | validation: 0.5949570180814506]
	TIME [epoch: 27.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5367345675099781		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 0.5367345675099781 | validation: 0.6100797645746279]
	TIME [epoch: 27.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5473016471510623		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 0.5473016471510623 | validation: 0.5899499362637084]
	TIME [epoch: 27.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5524390526066375		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 0.5524390526066375 | validation: 0.6302904908913805]
	TIME [epoch: 27.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5421288427167471		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 0.5421288427167471 | validation: 0.5894046026933547]
	TIME [epoch: 27.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6183191336129339		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 0.6183191336129339 | validation: 0.5728393452175781]
	TIME [epoch: 27.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5262195575500025		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 0.5262195575500025 | validation: 0.5973234922718857]
	TIME [epoch: 27.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.556898111113296		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 0.556898111113296 | validation: 0.585220054446764]
	TIME [epoch: 27.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5617834591924111		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 0.5617834591924111 | validation: 0.6783880038160137]
	TIME [epoch: 27.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6218250523948842		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 0.6218250523948842 | validation: 1.0748518331689025]
	TIME [epoch: 27.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7996589132675773		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 0.7996589132675773 | validation: 0.6651266418888356]
	TIME [epoch: 27.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5675763606794002		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 0.5675763606794002 | validation: 0.5757157653085124]
	TIME [epoch: 27.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5075214667854394		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 0.5075214667854394 | validation: 0.5524760339712776]
	TIME [epoch: 27.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5087148998181702		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 0.5087148998181702 | validation: 0.637147313838469]
	TIME [epoch: 27.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5307813300849773		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 0.5307813300849773 | validation: 0.5448396501897642]
	TIME [epoch: 27.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5139420912789332		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 0.5139420912789332 | validation: 0.5544151499386674]
	TIME [epoch: 27.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5265124598833476		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 0.5265124598833476 | validation: 0.5812829131469801]
	TIME [epoch: 27.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5152668608203075		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 0.5152668608203075 | validation: 0.5708437160751844]
	TIME [epoch: 27.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49463930754595625		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 0.49463930754595625 | validation: 0.5097194804444396]
	TIME [epoch: 27.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5814201964832616		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 0.5814201964832616 | validation: 0.5720775922463586]
	TIME [epoch: 27.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5220735869024813		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 0.5220735869024813 | validation: 0.5062558375786518]
	TIME [epoch: 27.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4815073194110366		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 0.4815073194110366 | validation: 0.6044885930538589]
	TIME [epoch: 27.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5205402264207817		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 0.5205402264207817 | validation: 0.533123208897809]
	TIME [epoch: 27.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48726741134430696		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 0.48726741134430696 | validation: 0.5213280752954333]
	TIME [epoch: 27.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4911768195018387		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 0.4911768195018387 | validation: 0.499666150166442]
	TIME [epoch: 27.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189630454240569		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 0.5189630454240569 | validation: 0.5676382342608305]
	TIME [epoch: 27.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7670198245617512		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 0.7670198245617512 | validation: 0.6333002555662359]
	TIME [epoch: 27.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5636374012454033		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 0.5636374012454033 | validation: 0.5862622173071573]
	TIME [epoch: 27.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5352371788424477		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 0.5352371788424477 | validation: 0.541457234635935]
	TIME [epoch: 27.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4690710021630358		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 0.4690710021630358 | validation: 0.5271666371002307]
	TIME [epoch: 27.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5847510660336629		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 0.5847510660336629 | validation: 0.5704646907902717]
	TIME [epoch: 27.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5294332960444942		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 0.5294332960444942 | validation: 0.45111932262647486]
	TIME [epoch: 27.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4654345521318362		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 0.4654345521318362 | validation: 0.5188262452398845]
	TIME [epoch: 27.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45549377385282996		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 0.45549377385282996 | validation: 0.4299169494523681]
	TIME [epoch: 27.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4382701002588961		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 0.4382701002588961 | validation: 0.48051201367988766]
	TIME [epoch: 27.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4444797628549748		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 0.4444797628549748 | validation: 0.46634874443388846]
	TIME [epoch: 27.6 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5862149535542038		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 0.5862149535542038 | validation: 0.5066693757035714]
	TIME [epoch: 27.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44174076965047154		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 0.44174076965047154 | validation: 0.4601325389677094]
	TIME [epoch: 27.6 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39980068368249705		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 0.39980068368249705 | validation: 0.4837052785678714]
	TIME [epoch: 27.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5058488798338961		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 0.5058488798338961 | validation: 0.6421055247032291]
	TIME [epoch: 27.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5069387944107957		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 0.5069387944107957 | validation: 0.4602397603208395]
	TIME [epoch: 27.6 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6975646595852207		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 0.6975646595852207 | validation: 0.5831522016098453]
	TIME [epoch: 27.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5228543128916826		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 0.5228543128916826 | validation: 0.46259252661317496]
	TIME [epoch: 27.6 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46151369244156887		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 0.46151369244156887 | validation: 0.7649782961729035]
	TIME [epoch: 27.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0691009542442789		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.0691009542442789 | validation: 0.8298137625309725]
	TIME [epoch: 27.6 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.582950426475868		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 0.582950426475868 | validation: 0.4421206452935198]
	TIME [epoch: 27.6 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4068221190461547		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 0.4068221190461547 | validation: 0.4893612533915892]
	TIME [epoch: 27.6 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472588407612001		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 0.4472588407612001 | validation: 0.538561957034002]
	TIME [epoch: 27.6 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6313359165058507		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.6313359165058507 | validation: 0.42810013764145977]
	TIME [epoch: 27.6 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4297017631840871		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.4297017631840871 | validation: 0.4224137047083739]
	TIME [epoch: 27.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4010448721017445		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.4010448721017445 | validation: 0.37151654104897225]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_453.pth
	Model improved!!!
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4043696029054705		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 0.4043696029054705 | validation: 0.47267963883650355]
	TIME [epoch: 27.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4482227165126255		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.4482227165126255 | validation: 0.4327195203167997]
	TIME [epoch: 27.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41000475975111084		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.41000475975111084 | validation: 0.3818952161683429]
	TIME [epoch: 27.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4498687547258751		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.4498687547258751 | validation: 0.5610010224495945]
	TIME [epoch: 27.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4268518820872973		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.4268518820872973 | validation: 0.44838449092878274]
	TIME [epoch: 27.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4134092203914505		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.4134092203914505 | validation: 0.41348991361043574]
	TIME [epoch: 27.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3664741410728266		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.3664741410728266 | validation: 0.4313139888100055]
	TIME [epoch: 27.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3961915620017756		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.3961915620017756 | validation: 0.41912469610071074]
	TIME [epoch: 27.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39854109092464457		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.39854109092464457 | validation: 0.4189874757408152]
	TIME [epoch: 27.7 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.468782187340764		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.468782187340764 | validation: 0.476267584938442]
	TIME [epoch: 27.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4252121960895704		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.4252121960895704 | validation: 0.390504985962158]
	TIME [epoch: 27.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39521331564687334		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.39521331564687334 | validation: 0.41432959722424834]
	TIME [epoch: 27.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5177805579938571		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.5177805579938571 | validation: 0.45388069033691736]
	TIME [epoch: 27.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5244783009776239		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.5244783009776239 | validation: 0.44111044044483694]
	TIME [epoch: 27.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3931727240325401		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.3931727240325401 | validation: 0.4473510348664641]
	TIME [epoch: 27.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3913972475501584		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.3913972475501584 | validation: 0.3925725525354276]
	TIME [epoch: 27.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6033956659688353		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.6033956659688353 | validation: 0.8633038458835628]
	TIME [epoch: 27.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6760105632174824		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6760105632174824 | validation: 0.677503341781789]
	TIME [epoch: 27.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47226137466837015		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.47226137466837015 | validation: 0.4570135268991166]
	TIME [epoch: 27.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5071642202934985		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.5071642202934985 | validation: 0.47446047945173175]
	TIME [epoch: 27.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40510316986217976		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.40510316986217976 | validation: 0.4488754092472898]
	TIME [epoch: 27.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38007160820351277		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.38007160820351277 | validation: 0.3715293868396706]
	TIME [epoch: 27.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34211300806025424		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.34211300806025424 | validation: 0.36919807470293065]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_476.pth
	Model improved!!!
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4718265647273953		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.4718265647273953 | validation: 0.3809213269939381]
	TIME [epoch: 27.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42909008913683977		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.42909008913683977 | validation: 0.45485419188128545]
	TIME [epoch: 27.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47225265617353096		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.47225265617353096 | validation: 0.32935111232181813]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_479.pth
	Model improved!!!
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32885103397871535		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.32885103397871535 | validation: 0.3337048086186067]
	TIME [epoch: 27.6 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32686015027435994		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.32686015027435994 | validation: 0.3303623046845761]
	TIME [epoch: 27.6 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3333629739340133		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.3333629739340133 | validation: 0.3150715829041533]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3645051184363106		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.3645051184363106 | validation: 0.34173423617443066]
	TIME [epoch: 27.5 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3338548312841023		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.3338548312841023 | validation: 0.32866596757973915]
	TIME [epoch: 27.6 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926090066555066		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.3926090066555066 | validation: 0.5310458217539954]
	TIME [epoch: 27.6 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6619128467985056		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.6619128467985056 | validation: 0.410514535051087]
	TIME [epoch: 27.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34740266606538117		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.34740266606538117 | validation: 0.3249395846732809]
	TIME [epoch: 27.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31419856988557077		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.31419856988557077 | validation: 0.35184681364196996]
	TIME [epoch: 27.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3331338438789644		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.3331338438789644 | validation: 0.3346826889569126]
	TIME [epoch: 27.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38103611309948016		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.38103611309948016 | validation: 0.41851671122552364]
	TIME [epoch: 27.6 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3758357080453101		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.3758357080453101 | validation: 0.41191840176943695]
	TIME [epoch: 27.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3894001932180329		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.3894001932180329 | validation: 0.3335779990441121]
	TIME [epoch: 27.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3401555474534371		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.3401555474534371 | validation: 0.33100813036100685]
	TIME [epoch: 27.6 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35355494114373653		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.35355494114373653 | validation: 0.3931031602803376]
	TIME [epoch: 27.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3358225309148897		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.3358225309148897 | validation: 0.3139869166502519]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_495.pth
	Model improved!!!
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43430220719686563		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.43430220719686563 | validation: 0.3952316691046781]
	TIME [epoch: 27.6 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36227689089268234		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.36227689089268234 | validation: 0.3090493086227678]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_497.pth
	Model improved!!!
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3094481386427702		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.3094481386427702 | validation: 0.31359458616015295]
	TIME [epoch: 27.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3501271832516527		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.3501271832516527 | validation: 0.32554565875155134]
	TIME [epoch: 27.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3619896048616255		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.3619896048616255 | validation: 0.499670234413079]
	TIME [epoch: 27.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5483568673371739		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.5483568673371739 | validation: 0.5077211675221877]
	TIME [epoch: 27.6 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4325011770873889		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.4325011770873889 | validation: 0.3637438379084212]
	TIME [epoch: 27.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3497257593079291		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.3497257593079291 | validation: 0.5275276107251846]
	TIME [epoch: 27.6 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4351925742781747		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.4351925742781747 | validation: 0.3664536926215732]
	TIME [epoch: 27.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33772215006891554		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.33772215006891554 | validation: 0.38979163809069123]
	TIME [epoch: 27.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.357973563508867		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.357973563508867 | validation: 0.34297607254563117]
	TIME [epoch: 27.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3522304520272342		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.3522304520272342 | validation: 0.33981637815121146]
	TIME [epoch: 27.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4855407744814327		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.4855407744814327 | validation: 0.5048636475695407]
	TIME [epoch: 27.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5423779463974172		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.5423779463974172 | validation: 0.41191566469630403]
	TIME [epoch: 27.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41293785353590734		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.41293785353590734 | validation: 0.3149768336947569]
	TIME [epoch: 27.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3641154788397493		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.3641154788397493 | validation: 0.31012912781108115]
	TIME [epoch: 27.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33460654548544616		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.33460654548544616 | validation: 0.30157538429145386]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_512.pth
	Model improved!!!
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33814591317090686		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.33814591317090686 | validation: 0.3541552285802573]
	TIME [epoch: 27.6 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44777185127623154		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.44777185127623154 | validation: 0.3192826835247105]
	TIME [epoch: 27.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34026991165749976		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.34026991165749976 | validation: 0.3575625825034319]
	TIME [epoch: 27.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38807044451450207		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.38807044451450207 | validation: 0.4331082725231701]
	TIME [epoch: 27.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3642962409291591		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.3642962409291591 | validation: 0.3221998574605331]
	TIME [epoch: 27.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3681380859510348		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.3681380859510348 | validation: 0.4457763427036066]
	TIME [epoch: 27.7 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36364159161080617		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.36364159161080617 | validation: 0.4240080073239821]
	TIME [epoch: 27.7 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42346625873831545		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.42346625873831545 | validation: 0.4556942329691589]
	TIME [epoch: 27.7 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42090024615320765		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.42090024615320765 | validation: 0.42053021299996735]
	TIME [epoch: 27.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4227519962420945		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.4227519962420945 | validation: 0.42802016861372383]
	TIME [epoch: 27.7 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38091431696826356		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.38091431696826356 | validation: 0.4489785942746736]
	TIME [epoch: 27.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46264796362397664		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.46264796362397664 | validation: 0.43952058345832307]
	TIME [epoch: 27.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3908282452658878		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.3908282452658878 | validation: 0.35378467518082424]
	TIME [epoch: 27.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3851679337662516		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.3851679337662516 | validation: 0.4433320270833201]
	TIME [epoch: 27.6 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41845021896083107		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.41845021896083107 | validation: 0.41808795908984303]
	TIME [epoch: 27.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3852110678601371		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.3852110678601371 | validation: 0.4216906682401405]
	TIME [epoch: 27.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41110977513624536		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.41110977513624536 | validation: 0.4634084766592009]
	TIME [epoch: 27.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42311588686766244		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.42311588686766244 | validation: 0.5531499721557753]
	TIME [epoch: 27.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45677790563897624		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.45677790563897624 | validation: 0.5297997247737176]
	TIME [epoch: 27.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4731880802824975		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.4731880802824975 | validation: 0.4906809003096767]
	TIME [epoch: 27.7 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42538239281212287		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.42538239281212287 | validation: 0.5086578709478909]
	TIME [epoch: 27.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4253825087304866		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.4253825087304866 | validation: 0.5066596112605091]
	TIME [epoch: 27.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6956320687482557		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.6956320687482557 | validation: 0.9794903406261878]
	TIME [epoch: 27.7 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5968375383307116		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.5968375383307116 | validation: 0.48796660014896887]
	TIME [epoch: 27.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45608471534225126		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.45608471534225126 | validation: 0.5167131788246058]
	TIME [epoch: 27.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.432395699309034		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.432395699309034 | validation: 0.47212265405856346]
	TIME [epoch: 27.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4384966476737113		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.4384966476737113 | validation: 0.4812148886657876]
	TIME [epoch: 27.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43853116449702656		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.43853116449702656 | validation: 0.4934663420216164]
	TIME [epoch: 27.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4363979113385766		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.4363979113385766 | validation: 0.46407930064176944]
	TIME [epoch: 27.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4264017272762943		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.4264017272762943 | validation: 0.6480082625814153]
	TIME [epoch: 27.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5195022373360203		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.5195022373360203 | validation: 0.44047067431845677]
	TIME [epoch: 27.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4031733115788199		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.4031733115788199 | validation: 0.449931953206662]
	TIME [epoch: 27.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40831330794475934		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.40831330794475934 | validation: 0.4571736751743169]
	TIME [epoch: 27.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3951657196606248		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.3951657196606248 | validation: 0.4093748460324201]
	TIME [epoch: 27.8 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36847029274411275		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.36847029274411275 | validation: 0.4636531386642915]
	TIME [epoch: 27.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4019296411374128		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.4019296411374128 | validation: 0.3921798177162849]
	TIME [epoch: 27.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38145079178593944		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.38145079178593944 | validation: 0.37830896254750135]
	TIME [epoch: 27.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3497995521957889		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.3497995521957889 | validation: 0.3458270083369709]
	TIME [epoch: 27.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34258975230055716		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.34258975230055716 | validation: 0.46258820842256626]
	TIME [epoch: 27.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4629313468355165		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.4629313468355165 | validation: 0.6670231059717119]
	TIME [epoch: 27.8 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5389065146994947		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.5389065146994947 | validation: 0.4350438631137552]
	TIME [epoch: 27.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3549095541177407		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.3549095541177407 | validation: 0.37271565526324824]
	TIME [epoch: 27.8 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37343313201166306		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.37343313201166306 | validation: 0.4077679569983518]
	TIME [epoch: 27.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.390201236689358		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.390201236689358 | validation: 0.674278182311984]
	TIME [epoch: 27.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47767283434804153		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.47767283434804153 | validation: 0.5441163586651973]
	TIME [epoch: 27.8 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4402775301719458		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.4402775301719458 | validation: 0.484872689603822]
	TIME [epoch: 27.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4452703766948913		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.4452703766948913 | validation: 0.47600659644197135]
	TIME [epoch: 27.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.442429741869249		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.442429741869249 | validation: 0.4138661043163333]
	TIME [epoch: 27.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39426150973074253		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.39426150973074253 | validation: 0.36934633526405564]
	TIME [epoch: 27.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3473973295461942		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.3473973295461942 | validation: 0.3961138203017697]
	TIME [epoch: 27.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3574339932536358		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.3574339932536358 | validation: 0.3788307137108258]
	TIME [epoch: 27.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33881589074293267		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.33881589074293267 | validation: 0.36658740855797534]
	TIME [epoch: 27.8 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3357088967569395		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.3357088967569395 | validation: 0.40030217453044276]
	TIME [epoch: 27.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35306951247122		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.35306951247122 | validation: 0.39757224249443535]
	TIME [epoch: 27.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3533389562527861		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.3533389562527861 | validation: 0.38662338227969345]
	TIME [epoch: 27.8 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33268922354788727		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.33268922354788727 | validation: 0.3774836821535667]
	TIME [epoch: 27.7 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32510550769345714		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.32510550769345714 | validation: 0.38537458504875133]
	TIME [epoch: 27.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.392133550834279		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.392133550834279 | validation: 0.4029542349128921]
	TIME [epoch: 27.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4006761088128601		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.4006761088128601 | validation: 0.4727834478029553]
	TIME [epoch: 27.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37132429598789535		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.37132429598789535 | validation: 0.4150143460622033]
	TIME [epoch: 27.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42617165109253247		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.42617165109253247 | validation: 0.5680358215221573]
	TIME [epoch: 27.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41018300305674965		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.41018300305674965 | validation: 0.3720754768375765]
	TIME [epoch: 27.8 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3746510362414417		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.3746510362414417 | validation: 0.3698840733674979]
	TIME [epoch: 27.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3541985517960185		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.3541985517960185 | validation: 0.4818797995140836]
	TIME [epoch: 27.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37528333737182984		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.37528333737182984 | validation: 0.3449378050542268]
	TIME [epoch: 27.8 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32067433825196157		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.32067433825196157 | validation: 0.3354436243360541]
	TIME [epoch: 27.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3475797318567609		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.3475797318567609 | validation: 0.334010670377687]
	TIME [epoch: 27.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.333121190327864		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.333121190327864 | validation: 0.4041657456487644]
	TIME [epoch: 27.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585344017700258		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5585344017700258 | validation: 1.0494106009642739]
	TIME [epoch: 27.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6356458616918944		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.6356458616918944 | validation: 0.3744791430623744]
	TIME [epoch: 27.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3287221834132675		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.3287221834132675 | validation: 0.35656037079051267]
	TIME [epoch: 27.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36866097540736664		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.36866097540736664 | validation: 0.3516293710292081]
	TIME [epoch: 27.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3667633695267686		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.3667633695267686 | validation: 0.30648097488101195]
	TIME [epoch: 27.8 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3126800108402405		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.3126800108402405 | validation: 0.32768470570498404]
	TIME [epoch: 27.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31736349958268556		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.31736349958268556 | validation: 0.27368368958253686]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_587.pth
	Model improved!!!
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2794682997047366		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.2794682997047366 | validation: 0.30861820159126313]
	TIME [epoch: 27.6 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38011068777159795		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.38011068777159795 | validation: 0.3376985389460296]
	TIME [epoch: 27.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35232563193524724		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.35232563193524724 | validation: 0.3012936985604664]
	TIME [epoch: 27.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30132699784792805		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.30132699784792805 | validation: 0.2743245160727041]
	TIME [epoch: 27.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29527526545456684		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.29527526545456684 | validation: 0.3040591251388359]
	TIME [epoch: 27.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2851727722480696		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.2851727722480696 | validation: 0.278045043115402]
	TIME [epoch: 27.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3123463579772484		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.3123463579772484 | validation: 0.27307146341259647]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_594.pth
	Model improved!!!
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3171638191519971		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.3171638191519971 | validation: 0.37578201809215367]
	TIME [epoch: 27.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3087200463299361		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.3087200463299361 | validation: 0.263345430948495]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_596.pth
	Model improved!!!
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2852756554635163		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.2852756554635163 | validation: 0.3014937879682113]
	TIME [epoch: 27.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3090502170928634		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.3090502170928634 | validation: 0.27719538206078215]
	TIME [epoch: 27.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31190002551581386		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.31190002551581386 | validation: 0.28328609289373563]
	TIME [epoch: 27.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2999817969195891		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.2999817969195891 | validation: 0.24810473695478677]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_600.pth
	Model improved!!!
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26804410345113494		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.26804410345113494 | validation: 0.25004746053482707]
	TIME [epoch: 27.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3077965891014972		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.3077965891014972 | validation: 0.4849883868156445]
	TIME [epoch: 27.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3818187425696481		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.3818187425696481 | validation: 0.3100775510206962]
	TIME [epoch: 27.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3822521110142647		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.3822521110142647 | validation: 0.40792024584619485]
	TIME [epoch: 27.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32400739672373935		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.32400739672373935 | validation: 0.3177916414355875]
	TIME [epoch: 27.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30861384528099217		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.30861384528099217 | validation: 0.31768924298707185]
	TIME [epoch: 27.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32414065849363927		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.32414065849363927 | validation: 0.2690388401349846]
	TIME [epoch: 27.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2906438853358172		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.2906438853358172 | validation: 0.3549966576571832]
	TIME [epoch: 27.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31053263609955545		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.31053263609955545 | validation: 0.30620774146149954]
	TIME [epoch: 27.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30745967403426977		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.30745967403426977 | validation: 0.29250911324725615]
	TIME [epoch: 27.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.393933771782383		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.393933771782383 | validation: 0.44046862093972833]
	TIME [epoch: 27.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3429880693555135		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.3429880693555135 | validation: 0.32647134976683634]
	TIME [epoch: 27.8 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2865399484781436		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.2865399484781436 | validation: 0.2915671315771946]
	TIME [epoch: 27.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3058468583005577		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.3058468583005577 | validation: 0.3536451957535184]
	TIME [epoch: 27.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34832458400079463		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.34832458400079463 | validation: 0.358938720905872]
	TIME [epoch: 27.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30501095438837106		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.30501095438837106 | validation: 0.30462233716799797]
	TIME [epoch: 27.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2890427357024884		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.2890427357024884 | validation: 0.4272124682664591]
	TIME [epoch: 27.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3405256708483094		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.3405256708483094 | validation: 0.3322733318072197]
	TIME [epoch: 27.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2957265072610783		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.2957265072610783 | validation: 0.2841123028304092]
	TIME [epoch: 27.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29403807127685583		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.29403807127685583 | validation: 0.2693231841244467]
	TIME [epoch: 27.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2920808063005331		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.2920808063005331 | validation: 0.285762479621995]
	TIME [epoch: 27.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30189602586910447		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.30189602586910447 | validation: 0.3006426572668011]
	TIME [epoch: 27.8 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3244245703374312		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.3244245703374312 | validation: 0.2866971980333742]
	TIME [epoch: 27.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26478115944220293		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.26478115944220293 | validation: 0.3168080502645815]
	TIME [epoch: 27.8 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27229422502996387		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.27229422502996387 | validation: 0.29418464874534467]
	TIME [epoch: 27.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33730673069250977		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.33730673069250977 | validation: 0.4136750218190109]
	TIME [epoch: 27.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3362933558110083		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.3362933558110083 | validation: 0.2625155501251097]
	TIME [epoch: 27.8 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26319856447367185		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.26319856447367185 | validation: 0.23971481573382178]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_628.pth
	Model improved!!!
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3109852982556204		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.3109852982556204 | validation: 0.29270192791795036]
	TIME [epoch: 27.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2629748764890212		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.2629748764890212 | validation: 0.29083158625645383]
	TIME [epoch: 27.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27793494872420366		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.27793494872420366 | validation: 0.30013376135888475]
	TIME [epoch: 27.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26980627345164027		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.26980627345164027 | validation: 0.23468720669990387]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_632.pth
	Model improved!!!
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.257177861321636		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.257177861321636 | validation: 0.24830565903963694]
	TIME [epoch: 27.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24867889188448355		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.24867889188448355 | validation: 0.26310878155962103]
	TIME [epoch: 27.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2730209406294373		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.2730209406294373 | validation: 0.2646781805624623]
	TIME [epoch: 27.8 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.293667030832591		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.293667030832591 | validation: 0.29642360895014996]
	TIME [epoch: 27.7 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26434833136932		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.26434833136932 | validation: 0.3271349642000375]
	TIME [epoch: 27.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3120210969666141		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.3120210969666141 | validation: 0.25673125777088174]
	TIME [epoch: 27.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26309009465604866		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.26309009465604866 | validation: 0.2651035775929335]
	TIME [epoch: 27.8 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3508466929564901		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.3508466929564901 | validation: 0.31316167757484314]
	TIME [epoch: 27.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28758906518646676		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.28758906518646676 | validation: 0.24200409093998468]
	TIME [epoch: 27.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2590362702166379		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.2590362702166379 | validation: 0.2504586815810654]
	TIME [epoch: 27.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24751009773710547		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.24751009773710547 | validation: 0.27872515144637994]
	TIME [epoch: 27.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2649820573846111		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.2649820573846111 | validation: 0.25132949444127356]
	TIME [epoch: 27.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2668780019393782		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.2668780019393782 | validation: 0.314007667690577]
	TIME [epoch: 27.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2618759652523695		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.2618759652523695 | validation: 0.2590796557366086]
	TIME [epoch: 27.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28941334983090483		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.28941334983090483 | validation: 0.23190982877115424]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_647.pth
	Model improved!!!
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2527709316031976		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.2527709316031976 | validation: 0.24883130680989968]
	TIME [epoch: 27.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2910049053336339		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.2910049053336339 | validation: 0.33942644394096805]
	TIME [epoch: 27.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2926604375145725		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.2926604375145725 | validation: 0.23854773346561167]
	TIME [epoch: 27.8 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28307378013760914		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.28307378013760914 | validation: 0.2783232607537766]
	TIME [epoch: 27.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2825096522859633		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.2825096522859633 | validation: 0.2667516849010522]
	TIME [epoch: 27.8 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3027280994597928		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.3027280994597928 | validation: 0.4286784256805067]
	TIME [epoch: 27.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33888929832610304		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.33888929832610304 | validation: 0.2755534909786188]
	TIME [epoch: 27.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26405883044846135		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.26405883044846135 | validation: 0.2979073105767808]
	TIME [epoch: 27.8 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31924076024514864		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.31924076024514864 | validation: 0.24100990820367493]
	TIME [epoch: 27.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25956200589754563		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.25956200589754563 | validation: 0.3007925747787894]
	TIME [epoch: 27.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25892276222449623		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.25892276222449623 | validation: 0.2507841030474901]
	TIME [epoch: 27.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26978335737645104		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.26978335737645104 | validation: 0.44031793702410527]
	TIME [epoch: 27.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3445055402026774		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.3445055402026774 | validation: 0.24986839952440498]
	TIME [epoch: 27.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2561407785700499		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.2561407785700499 | validation: 0.26871546927703505]
	TIME [epoch: 27.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2546864253679783		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.2546864253679783 | validation: 0.32297410632734763]
	TIME [epoch: 27.8 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2929662036929374		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.2929662036929374 | validation: 0.26653484096824137]
	TIME [epoch: 27.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2675342803489037		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.2675342803489037 | validation: 0.281190852456617]
	TIME [epoch: 27.8 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.262962530074222		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.262962530074222 | validation: 0.2524587638704625]
	TIME [epoch: 27.8 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25593342305054273		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.25593342305054273 | validation: 0.2812443913321409]
	TIME [epoch: 27.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27737893169029315		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.27737893169029315 | validation: 0.31582417439861343]
	TIME [epoch: 27.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.33026783463013876		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.33026783463013876 | validation: 0.2648313170217648]
	TIME [epoch: 27.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26298988330895623		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.26298988330895623 | validation: 0.27001072344167054]
	TIME [epoch: 27.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3072436358835629		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.3072436358835629 | validation: 0.27890090195970674]
	TIME [epoch: 27.8 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2782302906989822		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.2782302906989822 | validation: 0.3149072851139802]
	TIME [epoch: 27.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3301124800752956		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.3301124800752956 | validation: 0.34561246448140737]
	TIME [epoch: 27.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.319603343574508		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.319603343574508 | validation: 0.35203339805279027]
	TIME [epoch: 27.7 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3131487188173634		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.3131487188173634 | validation: 0.2865836256162149]
	TIME [epoch: 27.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.315014558763739		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.315014558763739 | validation: 0.27583863813590315]
	TIME [epoch: 27.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2971513923926747		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.2971513923926747 | validation: 0.262909472821606]
	TIME [epoch: 27.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26298227233913846		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.26298227233913846 | validation: 0.2743282455211862]
	TIME [epoch: 27.8 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29462425385927693		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.29462425385927693 | validation: 0.24835816632512905]
	TIME [epoch: 27.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24944987885521847		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.24944987885521847 | validation: 0.24066642102011218]
	TIME [epoch: 27.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29450460908807996		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.29450460908807996 | validation: 0.27765220714308875]
	TIME [epoch: 27.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28226192024476754		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.28226192024476754 | validation: 0.2653526125181649]
	TIME [epoch: 27.8 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26329393666793033		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.26329393666793033 | validation: 0.23900041041450976]
	TIME [epoch: 27.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.279325819680877		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.279325819680877 | validation: 0.25707023540124463]
	TIME [epoch: 27.8 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24811463798315037		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.24811463798315037 | validation: 0.3327338085238005]
	TIME [epoch: 27.8 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3568369289886746		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.3568369289886746 | validation: 0.3703123330531139]
	TIME [epoch: 27.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3652577785542624		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.3652577785542624 | validation: 0.29061158700902195]
	TIME [epoch: 27.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26875143148574426		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.26875143148574426 | validation: 0.271337843634514]
	TIME [epoch: 27.8 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2670984040073004		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.2670984040073004 | validation: 0.23716495230785423]
	TIME [epoch: 27.8 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2584804535616255		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.2584804535616255 | validation: 0.23806750658188083]
	TIME [epoch: 27.8 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2365869954231567		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.2365869954231567 | validation: 0.2417079898587392]
	TIME [epoch: 27.8 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27491158021970197		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.27491158021970197 | validation: 0.27420762461086035]
	TIME [epoch: 27.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3001005290917489		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.3001005290917489 | validation: 0.2806318533324208]
	TIME [epoch: 27.8 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.339664645029958		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.339664645029958 | validation: 0.3413649420450117]
	TIME [epoch: 27.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2998279618705769		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.2998279618705769 | validation: 0.2566129605143528]
	TIME [epoch: 27.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2848545344908523		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.2848545344908523 | validation: 0.353350995866619]
	TIME [epoch: 27.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31896909384558747		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.31896909384558747 | validation: 0.2843678462523863]
	TIME [epoch: 27.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28697671999335866		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.28697671999335866 | validation: 0.30587015129192235]
	TIME [epoch: 27.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785977363640185		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.2785977363640185 | validation: 0.3599237948049846]
	TIME [epoch: 27.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45250899798726363		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.45250899798726363 | validation: 0.327332349197342]
	TIME [epoch: 27.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27282950719908744		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.27282950719908744 | validation: 0.26096753597623823]
	TIME [epoch: 27.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3042667138468582		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.3042667138468582 | validation: 0.24597632048213985]
	TIME [epoch: 27.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26643752524304587		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.26643752524304587 | validation: 0.236678322339931]
	TIME [epoch: 27.8 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24589339079611106		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.24589339079611106 | validation: 0.2481327011827807]
	TIME [epoch: 27.8 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.254953317685697		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.254953317685697 | validation: 0.33994190098631166]
	TIME [epoch: 27.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3033429252747455		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.3033429252747455 | validation: 0.29385955249379225]
	TIME [epoch: 27.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2886134848106899		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.2886134848106899 | validation: 0.2601725028698146]
	TIME [epoch: 27.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2716829020257941		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.2716829020257941 | validation: 0.29926558819710625]
	TIME [epoch: 27.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29701944053762747		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.29701944053762747 | validation: 0.2514083303888328]
	TIME [epoch: 27.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25138120763032284		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.25138120763032284 | validation: 0.2719403901284845]
	TIME [epoch: 27.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719978758103929		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.2719978758103929 | validation: 0.2345731499256517]
	TIME [epoch: 27.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2510766769601309		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.2510766769601309 | validation: 0.251532556855712]
	TIME [epoch: 27.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28904158932870827		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.28904158932870827 | validation: 0.4256323285921731]
	TIME [epoch: 27.8 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3387433010091717		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.3387433010091717 | validation: 0.2904192430472995]
	TIME [epoch: 27.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26616713897962807		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.26616713897962807 | validation: 0.24004405847271137]
	TIME [epoch: 27.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25279759264177876		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.25279759264177876 | validation: 0.2787320337588983]
	TIME [epoch: 27.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2876544749770722		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.2876544749770722 | validation: 0.3489516578678672]
	TIME [epoch: 27.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31032177313644377		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.31032177313644377 | validation: 0.2810765379273606]
	TIME [epoch: 27.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.257750984078834		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.257750984078834 | validation: 0.27220172374552604]
	TIME [epoch: 27.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2588342715591101		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.2588342715591101 | validation: 0.2765252357277937]
	TIME [epoch: 27.8 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34455599344333604		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.34455599344333604 | validation: 0.3510800689457206]
	TIME [epoch: 27.8 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31975457802222773		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.31975457802222773 | validation: 0.33494536190713337]
	TIME [epoch: 27.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36462074094674324		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.36462074094674324 | validation: 0.31359299698610427]
	TIME [epoch: 27.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2785000228832031		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.2785000228832031 | validation: 0.25126796601576973]
	TIME [epoch: 27.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24831598726810838		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.24831598726810838 | validation: 0.2481065831138865]
	TIME [epoch: 27.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2435203486070071		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.2435203486070071 | validation: 0.24769562204773235]
	TIME [epoch: 27.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27653542989689206		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.27653542989689206 | validation: 0.2847037224076699]
	TIME [epoch: 27.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2889390161070684		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.2889390161070684 | validation: 0.29091881494510796]
	TIME [epoch: 27.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27164308873879855		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.27164308873879855 | validation: 0.25273697823551894]
	TIME [epoch: 27.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2599058167853114		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.2599058167853114 | validation: 0.28573569589198555]
	TIME [epoch: 27.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28526124670464886		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.28526124670464886 | validation: 0.3668828647949717]
	TIME [epoch: 27.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3180574968727251		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.3180574968727251 | validation: 0.3092539256502341]
	TIME [epoch: 27.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2593865999578375		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.2593865999578375 | validation: 0.25480434678434627]
	TIME [epoch: 27.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28072092435534995		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.28072092435534995 | validation: 0.3646773520059453]
	TIME [epoch: 27.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2779397269780549		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.2779397269780549 | validation: 0.24467400128024636]
	TIME [epoch: 27.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2412136708404634		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.2412136708404634 | validation: 0.3046963323576755]
	TIME [epoch: 27.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29552637554326044		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.29552637554326044 | validation: 0.4444855852033555]
	TIME [epoch: 27.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3632353573786557		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.3632353573786557 | validation: 0.35494077697448334]
	TIME [epoch: 27.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.32930199543358163		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.32930199543358163 | validation: 0.3126916646058334]
	TIME [epoch: 27.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2780028761484704		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.2780028761484704 | validation: 0.2822616790278364]
	TIME [epoch: 27.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2845620634188099		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.2845620634188099 | validation: 0.3337223370462507]
	TIME [epoch: 27.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26257356899912127		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.26257356899912127 | validation: 0.2563848492753303]
	TIME [epoch: 27.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26247119830773435		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.26247119830773435 | validation: 0.3642971913214283]
	TIME [epoch: 27.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31775530540004615		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.31775530540004615 | validation: 0.34485469943312924]
	TIME [epoch: 27.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.282719905161824		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.282719905161824 | validation: 0.26832681464759317]
	TIME [epoch: 27.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2530481800890806		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.2530481800890806 | validation: 0.30481470520890147]
	TIME [epoch: 27.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719297501686885		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.2719297501686885 | validation: 0.28444022639952565]
	TIME [epoch: 27.6 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3397432458962911		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.3397432458962911 | validation: 0.28575743921179547]
	TIME [epoch: 27.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25323783937039684		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.25323783937039684 | validation: 0.24220635101174032]
	TIME [epoch: 27.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24310489554877215		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.24310489554877215 | validation: 0.2440332790430405]
	TIME [epoch: 27.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24581241852368857		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.24581241852368857 | validation: 0.25298598414609386]
	TIME [epoch: 27.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23111693167876876		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.23111693167876876 | validation: 0.24035680213642052]
	TIME [epoch: 27.8 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2492362135044685		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.2492362135044685 | validation: 0.2412139755191241]
	TIME [epoch: 27.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2449740171972575		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.2449740171972575 | validation: 0.25607411464394614]
	TIME [epoch: 27.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2502842550298447		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.2502842550298447 | validation: 0.23211938893061715]
	TIME [epoch: 27.6 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24878255083439865		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.24878255083439865 | validation: 0.25651217421223754]
	TIME [epoch: 27.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2561980811529801		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.2561980811529801 | validation: 0.35439264714156943]
	TIME [epoch: 27.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38109106938162357		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.38109106938162357 | validation: 0.503549210744644]
	TIME [epoch: 27.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4120191539379191		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.4120191539379191 | validation: 0.3072312154121658]
	TIME [epoch: 27.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2813825263509069		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.2813825263509069 | validation: 0.260385473836905]
	TIME [epoch: 27.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2929336116754729		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.2929336116754729 | validation: 0.2776768494447838]
	TIME [epoch: 27.8 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3133872606541267		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.3133872606541267 | validation: 0.2285424853590505]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_761.pth
	Model improved!!!
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26952174454820027		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.26952174454820027 | validation: 0.33746834685840316]
	TIME [epoch: 27.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.274351377805775		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.274351377805775 | validation: 0.22194876002231717]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_763.pth
	Model improved!!!
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22767626207737102		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.22767626207737102 | validation: 0.28073012885276266]
	TIME [epoch: 27.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2372342225571208		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.2372342225571208 | validation: 0.25213872328172565]
	TIME [epoch: 27.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2457289308332729		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.2457289308332729 | validation: 0.3015754553993806]
	TIME [epoch: 27.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2745129809117794		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.2745129809117794 | validation: 0.23029794213929536]
	TIME [epoch: 27.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26507765546337225		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.26507765546337225 | validation: 0.3728743086656751]
	TIME [epoch: 27.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.35208165804338964		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.35208165804338964 | validation: 0.37074213904263664]
	TIME [epoch: 27.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3240750577497748		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.3240750577497748 | validation: 0.27050370057752404]
	TIME [epoch: 27.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505777398384303		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.2505777398384303 | validation: 0.21923167328318977]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_771.pth
	Model improved!!!
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23041581321083607		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.23041581321083607 | validation: 0.21251579824918884]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_772.pth
	Model improved!!!
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23274463188457883		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.23274463188457883 | validation: 0.2759066592499368]
	TIME [epoch: 27.8 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2719709364725521		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.2719709364725521 | validation: 0.2911324881075258]
	TIME [epoch: 27.6 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25098901778252103		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.25098901778252103 | validation: 0.2674573545693651]
	TIME [epoch: 27.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28417082539321026		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.28417082539321026 | validation: 0.2586457441840722]
	TIME [epoch: 27.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2828590202903588		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.2828590202903588 | validation: 0.2739805252376046]
	TIME [epoch: 27.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2505242132141467		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.2505242132141467 | validation: 0.22245541798699678]
	TIME [epoch: 27.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2270563964934076		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.2270563964934076 | validation: 0.24259116231939168]
	TIME [epoch: 27.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2344650313580537		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.2344650313580537 | validation: 0.2383807057403076]
	TIME [epoch: 27.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2925687283124033		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.2925687283124033 | validation: 0.4339969751196891]
	TIME [epoch: 27.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3458658154115275		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.3458658154115275 | validation: 0.2775391916143379]
	TIME [epoch: 27.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2556735126446118		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.2556735126446118 | validation: 0.21268364807645998]
	TIME [epoch: 27.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2273189678340032		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.2273189678340032 | validation: 0.23629834021012655]
	TIME [epoch: 27.6 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2292011228671581		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.2292011228671581 | validation: 0.25353222715778584]
	TIME [epoch: 27.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23846734861389696		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.23846734861389696 | validation: 0.2285532300704238]
	TIME [epoch: 27.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2595817543615387		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.2595817543615387 | validation: 0.31518857667937866]
	TIME [epoch: 27.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27477257931233406		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.27477257931233406 | validation: 0.22949502170407968]
	TIME [epoch: 27.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23318250032644816		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.23318250032644816 | validation: 0.27863707751546174]
	TIME [epoch: 27.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.249263932613574		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.249263932613574 | validation: 0.22470030704499247]
	TIME [epoch: 27.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2651305453136895		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.2651305453136895 | validation: 0.3881516553556973]
	TIME [epoch: 27.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3849153286467373		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.3849153286467373 | validation: 0.40958900989145447]
	TIME [epoch: 27.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3038505472291509		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.3038505472291509 | validation: 0.25179131728485915]
	TIME [epoch: 27.7 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23990400780073956		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.23990400780073956 | validation: 0.2342116404808703]
	TIME [epoch: 27.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2481854988316836		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.2481854988316836 | validation: 0.2824995167876855]
	TIME [epoch: 27.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25628215333313115		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.25628215333313115 | validation: 0.2377253405216783]
	TIME [epoch: 27.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28545575259214406		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.28545575259214406 | validation: 0.39323836956315794]
	TIME [epoch: 27.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3436773160425839		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.3436773160425839 | validation: 0.3302404163519353]
	TIME [epoch: 27.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2827548954453504		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.2827548954453504 | validation: 0.2732759374004254]
	TIME [epoch: 27.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2693074961819309		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.2693074961819309 | validation: 0.29772724656425625]
	TIME [epoch: 27.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30691359412688635		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.30691359412688635 | validation: 0.24574123018524469]
	TIME [epoch: 27.7 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2594037594331337		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.2594037594331337 | validation: 0.27168235151900616]
	TIME [epoch: 27.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2578662674460105		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.2578662674460105 | validation: 0.22837844317056133]
	TIME [epoch: 27.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2442687946730141		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.2442687946730141 | validation: 0.3379663538711064]
	TIME [epoch: 27.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3625946739954492		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.3625946739954492 | validation: 0.3762777456285476]
	TIME [epoch: 27.6 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34671928430352017		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.34671928430352017 | validation: 0.30886533425208446]
	TIME [epoch: 27.6 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26746684708257973		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.26746684708257973 | validation: 0.22074678639045822]
	TIME [epoch: 27.6 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23892247127704014		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.23892247127704014 | validation: 0.24379309814801806]
	TIME [epoch: 27.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24472910607578124		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.24472910607578124 | validation: 0.23323692513900962]
	TIME [epoch: 27.6 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2501204063267554		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.2501204063267554 | validation: 0.24182176341789782]
	TIME [epoch: 27.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23966599933678784		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.23966599933678784 | validation: 0.2403808590577158]
	TIME [epoch: 27.6 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2396244418387566		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.2396244418387566 | validation: 0.2437219399334665]
	TIME [epoch: 27.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23908663587810072		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.23908663587810072 | validation: 0.2477154231190219]
	TIME [epoch: 27.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23216228463136815		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.23216228463136815 | validation: 0.24396692655917876]
	TIME [epoch: 27.7 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26078401013293706		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.26078401013293706 | validation: 0.2831038578143189]
	TIME [epoch: 27.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2641760847069438		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.2641760847069438 | validation: 0.2323803469783676]
	TIME [epoch: 27.6 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2303746572063648		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.2303746572063648 | validation: 0.23629791452359306]
	TIME [epoch: 27.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23214945499774609		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.23214945499774609 | validation: 0.2463883136600891]
	TIME [epoch: 27.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2461273008807445		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.2461273008807445 | validation: 0.2535108475270205]
	TIME [epoch: 27.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2950749711573206		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.2950749711573206 | validation: 0.3504170238372609]
	TIME [epoch: 27.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3390752340479495		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.3390752340479495 | validation: 0.3642728888961959]
	TIME [epoch: 27.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3381563783292747		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.3381563783292747 | validation: 0.3449413385901008]
	TIME [epoch: 27.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31755665749819945		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.31755665749819945 | validation: 0.3169538040627627]
	TIME [epoch: 27.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30698465688934296		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.30698465688934296 | validation: 0.3512310973515442]
	TIME [epoch: 27.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29842980712578915		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.29842980712578915 | validation: 0.2683779690734229]
	TIME [epoch: 27.7 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2659087699122624		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.2659087699122624 | validation: 0.2888541302049295]
	TIME [epoch: 27.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3055113763290774		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.3055113763290774 | validation: 0.4027606240290558]
	TIME [epoch: 27.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3492675125215332		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.3492675125215332 | validation: 0.3418146857215721]
	TIME [epoch: 27.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3203380495038618		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.3203380495038618 | validation: 0.31097526505642636]
	TIME [epoch: 27.6 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2790802049530358		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.2790802049530358 | validation: 0.26703516023207585]
	TIME [epoch: 27.8 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2640459144153213		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.2640459144153213 | validation: 0.2681031747843489]
	TIME [epoch: 27.6 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2754999326005531		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.2754999326005531 | validation: 0.29633704528413035]
	TIME [epoch: 27.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.29817681383685346		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.29817681383685346 | validation: 0.30407228565793337]
	TIME [epoch: 27.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30008470344553095		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.30008470344553095 | validation: 0.3281514690944536]
	TIME [epoch: 27.6 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2804496765906665		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.2804496765906665 | validation: 0.24772813453588727]
	TIME [epoch: 27.6 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22877625768457283		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.22877625768457283 | validation: 0.23006057500923036]
	TIME [epoch: 27.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23426407938190125		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.23426407938190125 | validation: 0.2609253680264326]
	TIME [epoch: 27.8 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23545223614983748		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.23545223614983748 | validation: 0.22828065214025928]
	TIME [epoch: 27.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2261371521038268		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.2261371521038268 | validation: 0.25723558591345025]
	TIME [epoch: 27.7 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3788996676668716		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.3788996676668716 | validation: 0.6170618651612624]
	TIME [epoch: 27.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4619858398477288		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.4619858398477288 | validation: 0.2887094727888464]
	TIME [epoch: 27.6 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.279852868528608		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.279852868528608 | validation: 0.28032945909203105]
	TIME [epoch: 27.6 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2416562441895898		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.2416562441895898 | validation: 0.25337506596495674]
	TIME [epoch: 27.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26391046627029197		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.26391046627029197 | validation: 0.3044296550801971]
	TIME [epoch: 27.6 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25268850591857217		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.25268850591857217 | validation: 0.21135064361711334]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_845.pth
	Model improved!!!
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22414137537028694		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.22414137537028694 | validation: 0.239032965970112]
	TIME [epoch: 27.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2321626613214677		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.2321626613214677 | validation: 0.23266207256702248]
	TIME [epoch: 28.1 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2237140894383492		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.2237140894383492 | validation: 0.24177964245041147]
	TIME [epoch: 27.8 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27496196564320136		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.27496196564320136 | validation: 0.24591852758527288]
	TIME [epoch: 27.8 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22790903942381852		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.22790903942381852 | validation: 0.23427106599220093]
	TIME [epoch: 27.8 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2327498538400845		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.2327498538400845 | validation: 0.24645511364243589]
	TIME [epoch: 27.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2528197921143338		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.2528197921143338 | validation: 0.2810391714442689]
	TIME [epoch: 27.8 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2620023005979744		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.2620023005979744 | validation: 0.22168044428776373]
	TIME [epoch: 27.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24428534065521088		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.24428534065521088 | validation: 0.2396512064453596]
	TIME [epoch: 27.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2414612823217188		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.2414612823217188 | validation: 0.22421660548536015]
	TIME [epoch: 27.8 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2210587098650591		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.2210587098650591 | validation: 0.2120413218994643]
	TIME [epoch: 27.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2258491437588725		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.2258491437588725 | validation: 0.2252702140535208]
	TIME [epoch: 27.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22315738513825137		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.22315738513825137 | validation: 0.2177437177120919]
	TIME [epoch: 27.8 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23027086891570114		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.23027086891570114 | validation: 0.22077412196127497]
	TIME [epoch: 27.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22636086466045768		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.22636086466045768 | validation: 0.23084532439287983]
	TIME [epoch: 27.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2226165367243606		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.2226165367243606 | validation: 0.2273062825357647]
	TIME [epoch: 27.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2209314614186693		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.2209314614186693 | validation: 0.22261602651463694]
	TIME [epoch: 27.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22576695963447613		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.22576695963447613 | validation: 0.25032624754322436]
	TIME [epoch: 27.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.265816001301326		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.265816001301326 | validation: 0.2878725619471715]
	TIME [epoch: 27.7 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2704777676792349		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.2704777676792349 | validation: 0.2896849298816029]
	TIME [epoch: 27.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28313261517880717		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.28313261517880717 | validation: 0.25853510952442177]
	TIME [epoch: 27.7 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23594970036867077		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.23594970036867077 | validation: 0.2254006692617917]
	TIME [epoch: 27.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2360944486531221		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.2360944486531221 | validation: 0.24181665226741897]
	TIME [epoch: 27.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2672946379993111		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.2672946379993111 | validation: 0.24226317596472122]
	TIME [epoch: 27.6 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26735809572840696		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.26735809572840696 | validation: 0.34525584926245]
	TIME [epoch: 27.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31802244923406453		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.31802244923406453 | validation: 0.2715221299905553]
	TIME [epoch: 27.6 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2699160406052481		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.2699160406052481 | validation: 0.3010093225526289]
	TIME [epoch: 27.7 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2659032864479918		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.2659032864479918 | validation: 0.2545156469888163]
	TIME [epoch: 27.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24667537978113452		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.24667537978113452 | validation: 0.2416438128363155]
	TIME [epoch: 27.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23145590010140524		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.23145590010140524 | validation: 0.22827965088251667]
	TIME [epoch: 27.7 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22521880282319423		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.22521880282319423 | validation: 0.2427032935781404]
	TIME [epoch: 27.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2367800689134355		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.2367800689134355 | validation: 0.27165710314190816]
	TIME [epoch: 27.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27362590055506814		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.27362590055506814 | validation: 0.2844609911532123]
	TIME [epoch: 27.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.28648318591213656		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.28648318591213656 | validation: 0.3230991207854574]
	TIME [epoch: 27.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3013651200658862		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.3013651200658862 | validation: 0.29671128185758344]
	TIME [epoch: 27.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2655679447847394		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.2655679447847394 | validation: 0.2365010424841203]
	TIME [epoch: 27.7 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23071414480234434		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.23071414480234434 | validation: 0.23082286690770326]
	TIME [epoch: 27.7 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23465345022725564		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.23465345022725564 | validation: 0.2522837542392325]
	TIME [epoch: 27.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24396627890883066		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.24396627890883066 | validation: 0.24566575582171551]
	TIME [epoch: 27.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23722681031488477		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.23722681031488477 | validation: 0.23806952563644904]
	TIME [epoch: 27.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2245144722769382		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.2245144722769382 | validation: 0.23222250618595602]
	TIME [epoch: 27.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22053483121285594		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.22053483121285594 | validation: 0.23551424087354833]
	TIME [epoch: 27.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23249199435676882		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.23249199435676882 | validation: 0.25201823641806154]
	TIME [epoch: 27.8 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24415369013402644		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.24415369013402644 | validation: 0.2850619457481115]
	TIME [epoch: 27.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2528173608579024		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.2528173608579024 | validation: 0.2363314853579623]
	TIME [epoch: 27.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24051116478888662		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.24051116478888662 | validation: 0.2766560816141876]
	TIME [epoch: 27.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2522255712948389		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.2522255712948389 | validation: 0.2552816659213203]
	TIME [epoch: 27.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2589049123436063		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.2589049123436063 | validation: 0.2621228444066776]
	TIME [epoch: 27.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23982788398893112		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.23982788398893112 | validation: 0.23984336527071157]
	TIME [epoch: 27.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.239131966730099		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.239131966730099 | validation: 0.22819396329113492]
	TIME [epoch: 27.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2563363365455318		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.2563363365455318 | validation: 0.2916030157754766]
	TIME [epoch: 27.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2891168769331044		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.2891168769331044 | validation: 0.2792157465073342]
	TIME [epoch: 27.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2939539355889459		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.2939539355889459 | validation: 0.2623356668428864]
	TIME [epoch: 27.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24424495228533527		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.24424495228533527 | validation: 0.2489579080591227]
	TIME [epoch: 27.6 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24438103388448354		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.24438103388448354 | validation: 0.2562591816368524]
	TIME [epoch: 27.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24422883936709636		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.24422883936709636 | validation: 0.2422894117287296]
	TIME [epoch: 27.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23873312233361071		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.23873312233361071 | validation: 0.2524078072402467]
	TIME [epoch: 27.7 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23688228537217498		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.23688228537217498 | validation: 0.270151376235588]
	TIME [epoch: 27.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25296537113629264		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.25296537113629264 | validation: 0.2707795076771025]
	TIME [epoch: 27.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25749551588682607		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.25749551588682607 | validation: 0.27816983070208917]
	TIME [epoch: 27.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2503475590878087		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.2503475590878087 | validation: 0.24979115771913596]
	TIME [epoch: 27.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22963606414117832		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.22963606414117832 | validation: 0.2402411967705477]
	TIME [epoch: 27.8 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2306689281942954		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.2306689281942954 | validation: 0.2627077956880942]
	TIME [epoch: 27.8 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24913294889743967		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.24913294889743967 | validation: 0.23847434472504916]
	TIME [epoch: 27.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23473988414888383		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.23473988414888383 | validation: 0.23196359937903746]
	TIME [epoch: 27.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23074568822459213		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.23074568822459213 | validation: 0.22232397777244828]
	TIME [epoch: 27.6 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22000337049049012		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.22000337049049012 | validation: 0.22072157914343934]
	TIME [epoch: 27.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2280490317253838		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.2280490317253838 | validation: 0.22645855707219512]
	TIME [epoch: 27.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23620372402349485		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.23620372402349485 | validation: 0.2421731561808835]
	TIME [epoch: 27.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23701684047329963		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.23701684047329963 | validation: 0.2321753302234177]
	TIME [epoch: 27.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23863522863628628		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.23863522863628628 | validation: 0.2678679504835835]
	TIME [epoch: 27.7 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23395639587777795		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.23395639587777795 | validation: 0.22179036374089386]
	TIME [epoch: 27.6 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.229661242393719		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.229661242393719 | validation: 0.21862629887182197]
	TIME [epoch: 27.6 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21660656028362557		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.21660656028362557 | validation: 0.21643744974702223]
	TIME [epoch: 27.6 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21797007818144612		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.21797007818144612 | validation: 0.2315074185404837]
	TIME [epoch: 27.6 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22414388849537048		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.22414388849537048 | validation: 0.21178647900469025]
	TIME [epoch: 27.6 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22846662134612244		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.22846662134612244 | validation: 0.2395068708428279]
	TIME [epoch: 27.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22346556748101193		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.22346556748101193 | validation: 0.21943204339562145]
	TIME [epoch: 27.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22124768041034718		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.22124768041034718 | validation: 0.24227513253388594]
	TIME [epoch: 27.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.221582335380871		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.221582335380871 | validation: 0.210241750771623]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_925.pth
	Model improved!!!
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22408644643717543		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.22408644643717543 | validation: 0.2178744509516233]
	TIME [epoch: 27.6 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23883856123979683		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.23883856123979683 | validation: 0.2658043077299718]
	TIME [epoch: 27.7 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24550618576893857		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.24550618576893857 | validation: 0.24068004318139088]
	TIME [epoch: 27.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2354296227812872		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.2354296227812872 | validation: 0.2546363028871062]
	TIME [epoch: 27.7 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24751240075581402		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.24751240075581402 | validation: 0.23303264456558148]
	TIME [epoch: 27.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25046206476549704		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.25046206476549704 | validation: 0.24389438644376984]
	TIME [epoch: 27.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22947267598322046		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.22947267598322046 | validation: 0.23758895367566915]
	TIME [epoch: 27.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23671463575985507		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.23671463575985507 | validation: 0.2586071639013578]
	TIME [epoch: 27.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2524532416044043		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.2524532416044043 | validation: 0.26885030433133283]
	TIME [epoch: 27.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2551587589445528		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.2551587589445528 | validation: 0.27031925876687335]
	TIME [epoch: 27.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2572056865048945		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.2572056865048945 | validation: 0.3040409965729695]
	TIME [epoch: 27.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.30987594260189444		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.30987594260189444 | validation: 0.36234302968552856]
	TIME [epoch: 27.6 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.34818871106785015		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.34818871106785015 | validation: 0.423043944230662]
	TIME [epoch: 27.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3403469136519959		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.3403469136519959 | validation: 0.3368684702968853]
	TIME [epoch: 27.6 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.31019207444700064		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.31019207444700064 | validation: 0.3417810539701022]
	TIME [epoch: 27.8 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.300988702025429		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.300988702025429 | validation: 0.3133388091316469]
	TIME [epoch: 27.7 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2857466476698077		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.2857466476698077 | validation: 0.3187210593013132]
	TIME [epoch: 27.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2906156789039714		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.2906156789039714 | validation: 0.3114385063286099]
	TIME [epoch: 27.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27983574385072085		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.27983574385072085 | validation: 0.305922399452635]
	TIME [epoch: 27.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2620928145488865		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.2620928145488865 | validation: 0.28914901016934186]
	TIME [epoch: 27.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24935794967453112		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.24935794967453112 | validation: 0.25916995214878014]
	TIME [epoch: 27.7 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24515688558332938		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.24515688558332938 | validation: 0.25529117442111077]
	TIME [epoch: 27.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24934463764222853		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.24934463764222853 | validation: 0.24593796516741123]
	TIME [epoch: 27.7 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23479636405761325		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.23479636405761325 | validation: 0.2520890090586303]
	TIME [epoch: 27.6 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24402105220885714		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.24402105220885714 | validation: 0.2570578901588246]
	TIME [epoch: 27.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2406253675594467		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.2406253675594467 | validation: 0.25766503971971855]
	TIME [epoch: 27.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23837968929860126		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.23837968929860126 | validation: 0.23852289014123926]
	TIME [epoch: 27.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22284299476615285		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.22284299476615285 | validation: 0.2387190139094406]
	TIME [epoch: 27.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23241588945204647		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.23241588945204647 | validation: 0.25058994070562823]
	TIME [epoch: 27.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23745506485166362		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.23745506485166362 | validation: 0.2624759628481049]
	TIME [epoch: 27.7 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25380434989293055		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.25380434989293055 | validation: 0.32232871050909817]
	TIME [epoch: 27.6 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2559539843326953		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.2559539843326953 | validation: 0.24037295452928217]
	TIME [epoch: 27.6 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23555387143664008		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.23555387143664008 | validation: 0.2664528918492777]
	TIME [epoch: 27.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24952270538067592		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.24952270538067592 | validation: 0.25579998772437934]
	TIME [epoch: 27.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24305978134091147		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.24305978134091147 | validation: 0.2508372064762436]
	TIME [epoch: 27.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23635566584879297		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.23635566584879297 | validation: 0.25096652622572213]
	TIME [epoch: 27.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2409017563798942		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.2409017563798942 | validation: 0.24770822742738155]
	TIME [epoch: 27.7 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2371885193252541		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.2371885193252541 | validation: 0.23606227922163966]
	TIME [epoch: 27.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.227300983550105		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.227300983550105 | validation: 0.2439258187645863]
	TIME [epoch: 27.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23385056455436903		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.23385056455436903 | validation: 0.24159552980794055]
	TIME [epoch: 27.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24552862751102406		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.24552862751102406 | validation: 0.28003430312952615]
	TIME [epoch: 27.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2470746591813957		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.2470746591813957 | validation: 0.25041164913211467]
	TIME [epoch: 27.7 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23889710555076676		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.23889710555076676 | validation: 0.24491299971489217]
	TIME [epoch: 27.7 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23678283928152366		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.23678283928152366 | validation: 0.24907069828381692]
	TIME [epoch: 27.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23726638933681665		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.23726638933681665 | validation: 0.2508200905163446]
	TIME [epoch: 27.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23684503079370325		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.23684503079370325 | validation: 0.2716208127249877]
	TIME [epoch: 27.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24331356690737174		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.24331356690737174 | validation: 0.2613358991660143]
	TIME [epoch: 27.8 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24795446769598994		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.24795446769598994 | validation: 0.290220602823555]
	TIME [epoch: 27.8 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24986542295146424		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.24986542295146424 | validation: 0.23536952650940215]
	TIME [epoch: 27.8 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22955336541081897		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.22955336541081897 | validation: 0.2417341770008345]
	TIME [epoch: 27.8 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2340060212322282		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.2340060212322282 | validation: 0.22953089392892145]
	TIME [epoch: 27.8 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22408424281618583		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.22408424281618583 | validation: 0.2357842532805987]
	TIME [epoch: 27.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22396802826565831		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.22396802826565831 | validation: 0.23490103809681329]
	TIME [epoch: 27.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2309097191595851		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.2309097191595851 | validation: 0.26138799835741805]
	TIME [epoch: 27.8 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23569794650102466		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.23569794650102466 | validation: 0.24117397686056496]
	TIME [epoch: 27.8 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23208141792019454		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.23208141792019454 | validation: 0.2371630280523244]
	TIME [epoch: 27.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22649653068923611		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.22649653068923611 | validation: 0.24529604329375276]
	TIME [epoch: 27.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22918111874288194		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.22918111874288194 | validation: 0.24410830641060208]
	TIME [epoch: 27.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22568932744100112		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.22568932744100112 | validation: 0.24415738639646062]
	TIME [epoch: 27.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2332094725717556		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.2332094725717556 | validation: 0.2503343737598781]
	TIME [epoch: 27.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.270323938366487		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.270323938366487 | validation: 0.2690025568801511]
	TIME [epoch: 27.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2559613946127292		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.2559613946127292 | validation: 0.2484293079340292]
	TIME [epoch: 27.7 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2509593580262793		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.2509593580262793 | validation: 0.2716943834986628]
	TIME [epoch: 27.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2581621612633246		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.2581621612633246 | validation: 0.22509171943498693]
	TIME [epoch: 27.8 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22478463394839104		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.22478463394839104 | validation: 0.24330843823224393]
	TIME [epoch: 27.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22590993581152824		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.22590993581152824 | validation: 0.24078669899912128]
	TIME [epoch: 27.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22733172628559994		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.22733172628559994 | validation: 0.2278569912301253]
	TIME [epoch: 27.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2162659932971347		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.2162659932971347 | validation: 0.22349980268584815]
	TIME [epoch: 27.8 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21539333655557896		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.21539333655557896 | validation: 0.21931643593886585]
	TIME [epoch: 27.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22119127642873876		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.22119127642873876 | validation: 0.2332842925591445]
	TIME [epoch: 27.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22138179855765003		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.22138179855765003 | validation: 0.23058841079606493]
	TIME [epoch: 27.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21597643441694966		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.21597643441694966 | validation: 0.22178433894302402]
	TIME [epoch: 27.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2144721822318146		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.2144721822318146 | validation: 0.21368159968328215]
	TIME [epoch: 27.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21443902791385977		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.21443902791385977 | validation: 0.22566890835818598]
	TIME [epoch: 27.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21396829084362615		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.21396829084362615 | validation: 0.20772495495811874]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1000.pth
	Model improved!!!
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.207925834572004		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.207925834572004 | validation: 0.22636571487393514]
	TIME [epoch: 27.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22157185252844452		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.22157185252844452 | validation: 0.23531330957865454]
	TIME [epoch: 27.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23109461032981246		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.23109461032981246 | validation: 0.26462008853330515]
	TIME [epoch: 27.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22698840343473348		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.22698840343473348 | validation: 0.2208394558774226]
	TIME [epoch: 27.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2164050568399962		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.2164050568399962 | validation: 0.21048351570548385]
	TIME [epoch: 27.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2056589898543955		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.2056589898543955 | validation: 0.21030034432617456]
	TIME [epoch: 27.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2139711002964752		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.2139711002964752 | validation: 0.22927160190004464]
	TIME [epoch: 27.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.213228200151177		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.213228200151177 | validation: 0.20709941527135725]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1008.pth
	Model improved!!!
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20861106341457392		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.20861106341457392 | validation: 0.2047329316841536]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1009.pth
	Model improved!!!
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20950467239254972		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.20950467239254972 | validation: 0.22850549366125847]
	TIME [epoch: 27.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2234093299722781		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.2234093299722781 | validation: 0.22608267872902243]
	TIME [epoch: 27.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21652534993946104		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.21652534993946104 | validation: 0.22053837192727563]
	TIME [epoch: 27.8 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2142833908600816		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.2142833908600816 | validation: 0.22370782536300204]
	TIME [epoch: 27.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23147003319166662		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.23147003319166662 | validation: 0.22430583373037416]
	TIME [epoch: 27.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2299698727191914		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.2299698727191914 | validation: 0.2536326110974781]
	TIME [epoch: 27.8 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22942745618369004		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.22942745618369004 | validation: 0.2044649193834133]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1016.pth
	Model improved!!!
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21124946056624247		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.21124946056624247 | validation: 0.22419586924292734]
	TIME [epoch: 27.6 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21169914597610984		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.21169914597610984 | validation: 0.20219993152081794]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1018.pth
	Model improved!!!
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20639740293418007		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.20639740293418007 | validation: 0.21638527894658366]
	TIME [epoch: 27.6 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21281023979570163		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.21281023979570163 | validation: 0.20099413533220495]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1020.pth
	Model improved!!!
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21070023749685662		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.21070023749685662 | validation: 0.19666060715595587]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1021.pth
	Model improved!!!
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19970568620552426		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.19970568620552426 | validation: 0.20909958144906968]
	TIME [epoch: 27.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19862788590538438		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.19862788590538438 | validation: 0.20076831544855445]
	TIME [epoch: 27.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21244927534119237		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.21244927534119237 | validation: 0.25365794207821646]
	TIME [epoch: 27.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.244861470218523		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.244861470218523 | validation: 0.22935804705163057]
	TIME [epoch: 27.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21814293839693086		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.21814293839693086 | validation: 0.21739525736072884]
	TIME [epoch: 27.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20983907374260768		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.20983907374260768 | validation: 0.1965040860857612]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1027.pth
	Model improved!!!
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21444519438409076		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.21444519438409076 | validation: 0.20288257041392826]
	TIME [epoch: 27.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22154701901095386		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.22154701901095386 | validation: 0.25256441807489827]
	TIME [epoch: 27.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24369307735362472		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.24369307735362472 | validation: 0.22235473423895522]
	TIME [epoch: 27.8 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23700112182939312		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.23700112182939312 | validation: 0.22874063715192747]
	TIME [epoch: 27.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22003438367910508		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.22003438367910508 | validation: 0.2043550143832081]
	TIME [epoch: 27.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21806371322996732		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.21806371322996732 | validation: 0.2441616301761375]
	TIME [epoch: 27.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2303703609357424		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.2303703609357424 | validation: 0.2226693427416822]
	TIME [epoch: 27.6 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21239011316100018		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.21239011316100018 | validation: 0.19780554277544146]
	TIME [epoch: 27.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.209576894833621		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.209576894833621 | validation: 0.23563764220441563]
	TIME [epoch: 27.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22406705794862739		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.22406705794862739 | validation: 0.219565002861514]
	TIME [epoch: 27.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21254495282255534		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.21254495282255534 | validation: 0.20008701177423027]
	TIME [epoch: 27.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20665143795700905		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.20665143795700905 | validation: 0.20006828184602074]
	TIME [epoch: 27.8 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19899077452731784		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.19899077452731784 | validation: 0.2099521084799177]
	TIME [epoch: 27.7 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.201251993482117		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.201251993482117 | validation: 0.20818605696726386]
	TIME [epoch: 27.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20644494301182179		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.20644494301182179 | validation: 0.2227805134630136]
	TIME [epoch: 27.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21121172580669922		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.21121172580669922 | validation: 0.230922651023711]
	TIME [epoch: 27.8 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21933676886980863		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.21933676886980863 | validation: 0.2445880378690564]
	TIME [epoch: 27.8 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2174465837280804		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.2174465837280804 | validation: 0.19972870544418656]
	TIME [epoch: 27.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.200551860096367		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.200551860096367 | validation: 0.20025757061851893]
	TIME [epoch: 27.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19790103673687076		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.19790103673687076 | validation: 0.20083074530583808]
	TIME [epoch: 27.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20210652180133742		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.20210652180133742 | validation: 0.2025093013204154]
	TIME [epoch: 27.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19591958988641137		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.19591958988641137 | validation: 0.20041363186215694]
	TIME [epoch: 27.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20113820418173808		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.20113820418173808 | validation: 0.2039344099336725]
	TIME [epoch: 27.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2064559800033725		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.2064559800033725 | validation: 0.21091478974162223]
	TIME [epoch: 27.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20656526823241278		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.20656526823241278 | validation: 0.21602683885420854]
	TIME [epoch: 27.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20464938233447239		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.20464938233447239 | validation: 0.21457108005350597]
	TIME [epoch: 27.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21096426403769922		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.21096426403769922 | validation: 0.21356904929044487]
	TIME [epoch: 27.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21103128655075148		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.21103128655075148 | validation: 0.2222716430440284]
	TIME [epoch: 27.8 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21013730953482634		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.21013730953482634 | validation: 0.21154414163564753]
	TIME [epoch: 27.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21378451460028294		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.21378451460028294 | validation: 0.22177302288818482]
	TIME [epoch: 27.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2150335264917994		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.2150335264917994 | validation: 0.2162622201521959]
	TIME [epoch: 27.8 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2202045525632237		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.2202045525632237 | validation: 0.22577297358106208]
	TIME [epoch: 27.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21170241828256747		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.21170241828256747 | validation: 0.2023189041508088]
	TIME [epoch: 27.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20204401038649605		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.20204401038649605 | validation: 0.2131444611473785]
	TIME [epoch: 27.8 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21071971354985908		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.21071971354985908 | validation: 0.21162274677137327]
	TIME [epoch: 27.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21532426991770776		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.21532426991770776 | validation: 0.2448224146925923]
	TIME [epoch: 27.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2445431627727212		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.2445431627727212 | validation: 0.29249167160086137]
	TIME [epoch: 27.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.259456263505198		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.259456263505198 | validation: 0.2577251637427886]
	TIME [epoch: 27.7 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23106704534393369		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.23106704534393369 | validation: 0.24825215117373226]
	TIME [epoch: 27.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22816524584416747		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.22816524584416747 | validation: 0.21997426467868025]
	TIME [epoch: 27.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22125001088522978		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.22125001088522978 | validation: 0.26634397414121]
	TIME [epoch: 27.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24782368079523562		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.24782368079523562 | validation: 0.26731935168582377]
	TIME [epoch: 27.8 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24628990036953474		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.24628990036953474 | validation: 0.26147139618485665]
	TIME [epoch: 27.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2730353395290781		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.2730353395290781 | validation: 0.31165073568432655]
	TIME [epoch: 27.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26801687335455254		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.26801687335455254 | validation: 0.31328440042805755]
	TIME [epoch: 27.7 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2924826257710338		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.2924826257710338 | validation: 0.36140754525662433]
	TIME [epoch: 27.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3153174046422198		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.3153174046422198 | validation: 0.28371320698945196]
	TIME [epoch: 27.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2642089351184886		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.2642089351184886 | validation: 0.28777980271387565]
	TIME [epoch: 27.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26691235327613116		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.26691235327613116 | validation: 0.2606753425466907]
	TIME [epoch: 27.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23902344084537847		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.23902344084537847 | validation: 0.2345030893903958]
	TIME [epoch: 27.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2141473485817379		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.2141473485817379 | validation: 0.1953779405918474]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1078.pth
	Model improved!!!
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20082352447407953		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.20082352447407953 | validation: 0.19412394282724776]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1079.pth
	Model improved!!!
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19610377108137886		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.19610377108137886 | validation: 0.20769659655835132]
	TIME [epoch: 27.8 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20385381066181962		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.20385381066181962 | validation: 0.22116038174402508]
	TIME [epoch: 27.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2104805642395215		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.2104805642395215 | validation: 0.2017991351143846]
	TIME [epoch: 27.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2075779705105198		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.2075779705105198 | validation: 0.21074385097357337]
	TIME [epoch: 27.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2169327845011686		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.2169327845011686 | validation: 0.21100200158299495]
	TIME [epoch: 27.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21169748532370652		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.21169748532370652 | validation: 0.21083614312977225]
	TIME [epoch: 27.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20378247265984878		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.20378247265984878 | validation: 0.2023378810240865]
	TIME [epoch: 27.8 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1936888450311111		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.1936888450311111 | validation: 0.19653226174621197]
	TIME [epoch: 27.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1946229650204139		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.1946229650204139 | validation: 0.19920605661243648]
	TIME [epoch: 27.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19580093359660566		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.19580093359660566 | validation: 0.19981214879947062]
	TIME [epoch: 27.8 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19612989290193572		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.19612989290193572 | validation: 0.20123824113324845]
	TIME [epoch: 27.8 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19103548339766754		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.19103548339766754 | validation: 0.1941463709718976]
	TIME [epoch: 27.8 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19611564563862446		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.19611564563862446 | validation: 0.20179149191838797]
	TIME [epoch: 27.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19768159892878492		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.19768159892878492 | validation: 0.20205228950964582]
	TIME [epoch: 27.8 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20057951754146605		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.20057951754146605 | validation: 0.2072020931040009]
	TIME [epoch: 27.8 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2523292930109951		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.2523292930109951 | validation: 0.30580440499271033]
	TIME [epoch: 27.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.27074592809142495		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.27074592809142495 | validation: 0.2571844516696726]
	TIME [epoch: 27.8 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22998085152044684		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.22998085152044684 | validation: 0.22647305732938222]
	TIME [epoch: 27.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23452245895464668		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.23452245895464668 | validation: 0.2716784813355136]
	TIME [epoch: 27.8 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25980728164706024		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.25980728164706024 | validation: 0.2728269169883483]
	TIME [epoch: 27.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2676333532261008		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.2676333532261008 | validation: 0.2861821972444217]
	TIME [epoch: 27.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26507563709646376		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.26507563709646376 | validation: 0.24080042293128984]
	TIME [epoch: 27.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21648326920512267		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.21648326920512267 | validation: 0.2128372581595466]
	TIME [epoch: 27.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21169290257144155		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.21169290257144155 | validation: 0.2221238549172025]
	TIME [epoch: 27.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22234819759099028		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.22234819759099028 | validation: 0.21915201724975297]
	TIME [epoch: 27.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21114383195775138		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.21114383195775138 | validation: 0.22135515177218026]
	TIME [epoch: 27.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2078206660141078		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.2078206660141078 | validation: 0.20498495017563648]
	TIME [epoch: 27.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20408476699889166		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.20408476699889166 | validation: 0.20355129906558211]
	TIME [epoch: 27.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21077018759864036		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.21077018759864036 | validation: 0.2163187003175275]
	TIME [epoch: 27.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20759992726960255		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.20759992726960255 | validation: 0.22795655002014328]
	TIME [epoch: 27.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2195142923552138		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.2195142923552138 | validation: 0.2341691503046081]
	TIME [epoch: 27.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22449322986298675		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.22449322986298675 | validation: 0.24206171356652825]
	TIME [epoch: 27.8 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.235939224197727		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.235939224197727 | validation: 0.27112466455694445]
	TIME [epoch: 27.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25161651101021765		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.25161651101021765 | validation: 0.2286842024535974]
	TIME [epoch: 27.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22237837377500994		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.22237837377500994 | validation: 0.20034184496603114]
	TIME [epoch: 27.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20394997111339047		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.20394997111339047 | validation: 0.20090712188692114]
	TIME [epoch: 27.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21050956462405623		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.21050956462405623 | validation: 0.20524278824998923]
	TIME [epoch: 27.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2132730802224867		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.2132730802224867 | validation: 0.20677869123581702]
	TIME [epoch: 27.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22673943715134506		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.22673943715134506 | validation: 0.22911589319223197]
	TIME [epoch: 27.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2230523164629903		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.2230523164629903 | validation: 0.21648402704656997]
	TIME [epoch: 27.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2076380525825537		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.2076380525825537 | validation: 0.20137199672760062]
	TIME [epoch: 27.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19402698555439324		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.19402698555439324 | validation: 0.19234416824644102]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1121.pth
	Model improved!!!
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19258756899417306		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.19258756899417306 | validation: 0.2012361956337696]
	TIME [epoch: 27.8 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1960222074950091		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.1960222074950091 | validation: 0.2041761370302136]
	TIME [epoch: 27.8 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21396534703202563		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.21396534703202563 | validation: 0.22006905945929064]
	TIME [epoch: 27.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21236984679571907		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.21236984679571907 | validation: 0.21829391682999813]
	TIME [epoch: 27.8 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22993496009471637		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.22993496009471637 | validation: 0.23117958028812535]
	TIME [epoch: 27.8 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22773442871091937		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.22773442871091937 | validation: 0.1996316654851267]
	TIME [epoch: 27.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20238932939611218		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.20238932939611218 | validation: 0.21106076714523936]
	TIME [epoch: 27.8 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21105679594496346		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.21105679594496346 | validation: 0.2116118036808512]
	TIME [epoch: 27.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22264286115701226		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.22264286115701226 | validation: 0.24102089470959648]
	TIME [epoch: 27.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22508502058027408		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.22508502058027408 | validation: 0.20198963913755372]
	TIME [epoch: 27.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19481487243157994		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.19481487243157994 | validation: 0.18814574230759398]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1132.pth
	Model improved!!!
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1914811640021799		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.1914811640021799 | validation: 0.19630418508953573]
	TIME [epoch: 27.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19315344621797212		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.19315344621797212 | validation: 0.19231699642407107]
	TIME [epoch: 27.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1896113506461708		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.1896113506461708 | validation: 0.18731889278056418]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1135.pth
	Model improved!!!
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19189637957992944		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.19189637957992944 | validation: 0.18651282175472172]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1136.pth
	Model improved!!!
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1880376824076953		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.1880376824076953 | validation: 0.20159714458431946]
	TIME [epoch: 27.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19583626172482985		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.19583626172482985 | validation: 0.19155340387833023]
	TIME [epoch: 27.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1940882649968113		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.1940882649968113 | validation: 0.21021974836981333]
	TIME [epoch: 27.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1966703064524123		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.1966703064524123 | validation: 0.20830332002582386]
	TIME [epoch: 27.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21021260560721178		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.21021260560721178 | validation: 0.21816622004046152]
	TIME [epoch: 27.8 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2241019267747913		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.2241019267747913 | validation: 0.24312087604738059]
	TIME [epoch: 27.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22847137993337122		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.22847137993337122 | validation: 0.22984736034040054]
	TIME [epoch: 27.8 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22498830770621756		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.22498830770621756 | validation: 0.23333207814845958]
	TIME [epoch: 27.8 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.24693159081150806		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.24693159081150806 | validation: 0.3047885099150997]
	TIME [epoch: 27.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2754872459972343		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.2754872459972343 | validation: 0.2776860892698943]
	TIME [epoch: 27.8 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.25425100135634804		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.25425100135634804 | validation: 0.2797803970881376]
	TIME [epoch: 27.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.26145686324768197		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.26145686324768197 | validation: 0.24390325694057638]
	TIME [epoch: 27.8 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2153918242929769		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.2153918242929769 | validation: 0.20638673389427212]
	TIME [epoch: 27.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2015973300083546		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.2015973300083546 | validation: 0.20748424129619444]
	TIME [epoch: 27.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21116596441187582		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.21116596441187582 | validation: 0.20728697792181025]
	TIME [epoch: 27.8 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22067664409176824		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.22067664409176824 | validation: 0.23317291161778989]
	TIME [epoch: 27.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2462080401340801		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.2462080401340801 | validation: 0.2617177330864637]
	TIME [epoch: 27.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2434480935763999		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.2434480935763999 | validation: 0.22016134048039057]
	TIME [epoch: 27.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21575007402899798		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.21575007402899798 | validation: 0.2191670151173502]
	TIME [epoch: 27.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.21631576382596238		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.21631576382596238 | validation: 0.2091868821397504]
	TIME [epoch: 27.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20869102348585553		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.20869102348585553 | validation: 0.20788365136600498]
	TIME [epoch: 27.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20473015607205972		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.20473015607205972 | validation: 0.20689145160131842]
	TIME [epoch: 27.8 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20166386420439547		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.20166386420439547 | validation: 0.19064594170035434]
	TIME [epoch: 27.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19660157683578772		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.19660157683578772 | validation: 0.1970843215354272]
	TIME [epoch: 27.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1942160757777301		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.1942160757777301 | validation: 0.19042447358454445]
	TIME [epoch: 27.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19026280102654755		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.19026280102654755 | validation: 0.19155403464785814]
	TIME [epoch: 27.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19856358896125736		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.19856358896125736 | validation: 0.20015310284007207]
	TIME [epoch: 27.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1924232322158954		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.1924232322158954 | validation: 0.18346548212939864]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240310_003029/states/model_tr_study6_1164.pth
	Model improved!!!
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.19641660028025587		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.19641660028025587 | validation: 0.1903469950419305]
	TIME [epoch: 27.6 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.18923596247141836		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.18923596247141836 | validation: 0.1881485706557776]
	TIME [epoch: 27.6 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20793619544747696		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.20793619544747696 | validation: 0.23256142591171966]
	TIME [epoch: 27.7 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2535568085182946		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.2535568085182946 | validation: 0.2420987827649437]
	TIME [epoch: 27.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23050116168857432		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.23050116168857432 | validation: 0.22119976348652473]
	TIME [epoch: 27.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.20448636858058628		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.20448636858058628 | validation: 0.1957719771148763]
	TIME [epoch: 27.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.1954620228669523		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.1954620228669523 | validation: 0.21106311015751295]
	TIME [epoch: 27.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.22036099884183266		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.22036099884183266 | validation: 0.24549796221997827]
	TIME [epoch: 27.6 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.23063533021669344		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.23063533021669344 | validation: 0.21937974390826143]
	TIME [epoch: 27.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.2096075882041611		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.2096075882041611 | validation: 0.20727108140812106]
	TIME [epoch: 27.6 sec]
EPOCH 1175/2000:
	Training over batches...
