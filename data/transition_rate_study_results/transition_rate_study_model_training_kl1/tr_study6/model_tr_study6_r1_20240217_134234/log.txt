Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r1', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r1', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=500, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2325943182

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.098057296386013		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.098057296386013 | validation: 6.574156979774366]
	TIME [epoch: 49.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.7169437646733385		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7169437646733385 | validation: 5.4637995741333025]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.013477567738711		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.013477567738711 | validation: 6.929290404326698]
	TIME [epoch: 10.2 sec]
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.388535179805103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.388535179805103 | validation: 4.901183336475352]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.863965507142129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.863965507142129 | validation: 4.87459979314678]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.0511246872054745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.0511246872054745 | validation: 4.219927834322155]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.619892082138421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.619892082138421 | validation: 3.9915727027368986]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.761617338169543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.761617338169543 | validation: 4.940310959428757]
	TIME [epoch: 10.2 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.549048308006324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.549048308006324 | validation: 3.714267266744379]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.972172881175178		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.972172881175178 | validation: 3.211918250908763]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7544467020722196		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7544467020722196 | validation: 3.035790870152194]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8555641026698995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8555641026698995 | validation: 3.089136872116961]
	TIME [epoch: 10.2 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.464787221758114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.464787221758114 | validation: 2.833392536914181]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.266899884118054		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.266899884118054 | validation: 2.744647328204668]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3283009879996945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3283009879996945 | validation: 5.103345836684304]
	TIME [epoch: 10.2 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.345128059455698		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.345128059455698 | validation: 3.8682619995288783]
	TIME [epoch: 10.2 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8645979908245778		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8645979908245778 | validation: 2.7920362551179974]
	TIME [epoch: 10.1 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.086751038386774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.086751038386774 | validation: 4.639822509062126]
	TIME [epoch: 10.1 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.04761366164475		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.04761366164475 | validation: 2.955332246855087]
	TIME [epoch: 10.1 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4656844606415937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4656844606415937 | validation: 3.1902397686057373]
	TIME [epoch: 10.1 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.498078122339293		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.498078122339293 | validation: 3.7981044836692277]
	TIME [epoch: 10.2 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.413836393137544		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.413836393137544 | validation: 3.9971086817787715]
	TIME [epoch: 10.1 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9222019346615746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9222019346615746 | validation: 3.482335786456537]
	TIME [epoch: 10.1 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.370029629079795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.370029629079795 | validation: 3.7917018102050997]
	TIME [epoch: 10.1 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.732988976126218		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.732988976126218 | validation: 4.15260250235679]
	TIME [epoch: 10.1 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.350189222174613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.350189222174613 | validation: 3.0867632267932885]
	TIME [epoch: 10.1 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3086245666844234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3086245666844234 | validation: 3.114855432950135]
	TIME [epoch: 10.2 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.410073480930856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.410073480930856 | validation: 3.393755130655777]
	TIME [epoch: 10.1 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.522012409239989		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.522012409239989 | validation: 3.1646197527197892]
	TIME [epoch: 10.1 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.297710151869402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.297710151869402 | validation: 2.9563826480708033]
	TIME [epoch: 10.2 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1303018288485687		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1303018288485687 | validation: 2.994505410489417]
	TIME [epoch: 10.1 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2857329902524044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2857329902524044 | validation: 2.993678408029357]
	TIME [epoch: 10.2 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.659952329471566		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.659952329471566 | validation: 3.6624551579492484]
	TIME [epoch: 10.2 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.942702647429589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.942702647429589 | validation: 3.2472102745949307]
	TIME [epoch: 10.1 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.391749787506556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.391749787506556 | validation: 3.0304498973553873]
	TIME [epoch: 10.2 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2753516715038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2753516715038 | validation: 2.8487858552809646]
	TIME [epoch: 10.2 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.127549883610312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.127549883610312 | validation: 2.7275582392467714]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.493177235563947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.493177235563947 | validation: 2.8922496109386793]
	TIME [epoch: 10.2 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.766583456232916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.766583456232916 | validation: 2.961481695933303]
	TIME [epoch: 10.2 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.164383424222244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.164383424222244 | validation: 3.133552944083248]
	TIME [epoch: 10.2 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.330710094403269		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.330710094403269 | validation: 2.9477562352654774]
	TIME [epoch: 10.1 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8546970151686337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8546970151686337 | validation: 2.852068798128696]
	TIME [epoch: 10.1 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3903742202840816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3903742202840816 | validation: 4.083948168208296]
	TIME [epoch: 10.2 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7266963083272615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7266963083272615 | validation: 3.1259938569569155]
	TIME [epoch: 10.2 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.119051254488247		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.119051254488247 | validation: 2.6549873191574727]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_45.pth
	Model improved!!!
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.995361032936868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.995361032936868 | validation: 3.183806507443437]
	TIME [epoch: 10.1 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.977912332125109		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.977912332125109 | validation: 2.604869635104109]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8469050987108773		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8469050987108773 | validation: 2.8185082533786976]
	TIME [epoch: 10.2 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.439713278970275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.439713278970275 | validation: 2.5181158823761858]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.739096613647079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.739096613647079 | validation: 2.8867991029680162]
	TIME [epoch: 10.2 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.012902326281367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.012902326281367 | validation: 3.077804874546441]
	TIME [epoch: 10.2 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0101785338446927		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0101785338446927 | validation: 2.648533286761499]
	TIME [epoch: 10.2 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8165153939794947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8165153939794947 | validation: 2.4543388536547006]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_53.pth
	Model improved!!!
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.188698220621719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.188698220621719 | validation: 3.5471917226417897]
	TIME [epoch: 10.1 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7299985490198453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7299985490198453 | validation: 3.255790335784517]
	TIME [epoch: 10.1 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6922678190254787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6922678190254787 | validation: 3.172394735062094]
	TIME [epoch: 10.2 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4295430584990987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4295430584990987 | validation: 2.701051603436415]
	TIME [epoch: 10.2 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7339888036997877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7339888036997877 | validation: 2.447195313954235]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7449793002018277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7449793002018277 | validation: 2.678560449005652]
	TIME [epoch: 10.1 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0293852378823125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0293852378823125 | validation: 3.279233076958679]
	TIME [epoch: 10.2 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0713992233336165		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0713992233336165 | validation: 2.875691237137644]
	TIME [epoch: 10.2 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1153888897842092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1153888897842092 | validation: 2.925756487108156]
	TIME [epoch: 10.2 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8768804512799484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8768804512799484 | validation: 3.507338656521122]
	TIME [epoch: 10.2 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1910238463269587		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1910238463269587 | validation: 2.2816490802024343]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_64.pth
	Model improved!!!
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6627831947606024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6627831947606024 | validation: 2.636516913977766]
	TIME [epoch: 10.1 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0511443576741333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0511443576741333 | validation: 2.3308872032836105]
	TIME [epoch: 10.2 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9080590177709325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9080590177709325 | validation: 2.755496900023359]
	TIME [epoch: 10.2 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2233514737124986		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2233514737124986 | validation: 2.885715991004223]
	TIME [epoch: 10.2 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.06765221104443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.06765221104443 | validation: 2.4916144703083996]
	TIME [epoch: 10.2 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.644931844001502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.644931844001502 | validation: 2.594444490567944]
	TIME [epoch: 10.2 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0732999332721973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0732999332721973 | validation: 2.2148260345470017]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7018462666981784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7018462666981784 | validation: 4.129398768843469]
	TIME [epoch: 10.2 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2457789979811116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2457789979811116 | validation: 2.7512414680731836]
	TIME [epoch: 10.2 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3611978745461926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3611978745461926 | validation: 2.7600880483903363]
	TIME [epoch: 10.2 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9726784797531023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9726784797531023 | validation: 2.618420722612674]
	TIME [epoch: 10.2 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.708572387681728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.708572387681728 | validation: 2.608290724666364]
	TIME [epoch: 10.1 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4271820921040765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4271820921040765 | validation: 3.581282845665297]
	TIME [epoch: 10.2 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.551697209452334		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.551697209452334 | validation: 3.2305373499264265]
	TIME [epoch: 10.1 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2759748289477075		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2759748289477075 | validation: 2.762275162460609]
	TIME [epoch: 10.1 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4484081470667363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4484081470667363 | validation: 3.771963346027251]
	TIME [epoch: 10.1 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.387868955542073		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.387868955542073 | validation: 3.4196105077321635]
	TIME [epoch: 10.2 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8635981873862435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8635981873862435 | validation: 2.268317262697214]
	TIME [epoch: 10.2 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2679136464725476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2679136464725476 | validation: 3.1339712403635036]
	TIME [epoch: 10.2 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9308778744569053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9308778744569053 | validation: 2.570088646557825]
	TIME [epoch: 10.2 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3330230431143244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3330230431143244 | validation: 2.409376005842447]
	TIME [epoch: 10.2 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.940786706552189		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.940786706552189 | validation: 2.562113667399808]
	TIME [epoch: 10.2 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.06237141890406		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.06237141890406 | validation: 1.9839282449742512]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2766876287560107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2766876287560107 | validation: 2.190138825197964]
	TIME [epoch: 10.1 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.42545607855896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.42545607855896 | validation: 2.0504183290842954]
	TIME [epoch: 10.2 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7845557087669333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7845557087669333 | validation: 3.6774724659203764]
	TIME [epoch: 10.2 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1504384667808125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1504384667808125 | validation: 3.344797474988498]
	TIME [epoch: 10.2 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6437812013878643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6437812013878643 | validation: 3.33749498581189]
	TIME [epoch: 10.2 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.939497845167998		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.939497845167998 | validation: 2.9659398037895324]
	TIME [epoch: 10.2 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.093203820074888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.093203820074888 | validation: 2.60862152757745]
	TIME [epoch: 10.2 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9549911843448955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9549911843448955 | validation: 3.4335727323643517]
	TIME [epoch: 10.1 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8023086100834327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8023086100834327 | validation: 2.048263517075629]
	TIME [epoch: 10.2 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.393600426231397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.393600426231397 | validation: 1.9512085579681977]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2837559271287597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2837559271287597 | validation: 2.139558165017926]
	TIME [epoch: 10.1 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.385349713230147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.385349713230147 | validation: 2.9105511308655374]
	TIME [epoch: 10.2 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2891576197050254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2891576197050254 | validation: 2.4871753765047915]
	TIME [epoch: 10.2 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5809868947995676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5809868947995676 | validation: 1.8763098503746622]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2527703663469523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2527703663469523 | validation: 1.8561104479289376]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_102.pth
	Model improved!!!
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0391423676599203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0391423676599203 | validation: 1.865815840244091]
	TIME [epoch: 10.2 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.204806766000123		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.204806766000123 | validation: 3.983646363978635]
	TIME [epoch: 10.2 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.846529002144174		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.846529002144174 | validation: 2.5647427702831456]
	TIME [epoch: 10.2 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1072246239980683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1072246239980683 | validation: 2.953221909328832]
	TIME [epoch: 10.1 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3361459656143717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3361459656143717 | validation: 2.6000697322192865]
	TIME [epoch: 10.1 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8783883475135066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8783883475135066 | validation: 2.795514153591865]
	TIME [epoch: 10.2 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2299807215322147		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2299807215322147 | validation: 2.2352542533204516]
	TIME [epoch: 10.2 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.738007928087444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.738007928087444 | validation: 2.3065311588125663]
	TIME [epoch: 10.2 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.913838182959304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.913838182959304 | validation: 2.4914034184630545]
	TIME [epoch: 10.1 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7943963619242966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7943963619242966 | validation: 2.2684459421301133]
	TIME [epoch: 10.2 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.703660411298564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.703660411298564 | validation: 2.667711288616157]
	TIME [epoch: 10.2 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3889613388101716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3889613388101716 | validation: 2.8288695648861335]
	TIME [epoch: 10.2 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9982231770793537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9982231770793537 | validation: 2.6748129293427247]
	TIME [epoch: 10.1 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.14794443244681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.14794443244681 | validation: 2.586164514704219]
	TIME [epoch: 10.1 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7871573192383803		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7871573192383803 | validation: 2.741982631869677]
	TIME [epoch: 10.2 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9352713761042653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9352713761042653 | validation: 4.088315319469882]
	TIME [epoch: 10.2 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.600326289780103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.600326289780103 | validation: 2.6080455715284736]
	TIME [epoch: 10.1 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8663332371235404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8663332371235404 | validation: 2.4190380975417365]
	TIME [epoch: 10.1 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.773719836002617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.773719836002617 | validation: 2.280295665993996]
	TIME [epoch: 10.2 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8315157842402003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8315157842402003 | validation: 2.4561126213080833]
	TIME [epoch: 10.1 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.96419860145298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.96419860145298 | validation: 2.5531101255989683]
	TIME [epoch: 10.1 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.78933263805992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.78933263805992 | validation: 2.365595789807073]
	TIME [epoch: 10.1 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7447366097476342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7447366097476342 | validation: 2.3489068685358627]
	TIME [epoch: 10.2 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7672163313124987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7672163313124987 | validation: 2.3504267735372424]
	TIME [epoch: 10.2 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.752107252883904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.752107252883904 | validation: 2.28311923465536]
	TIME [epoch: 10.2 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.694012758472618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.694012758472618 | validation: 2.2741227080735436]
	TIME [epoch: 10.1 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7354566676236014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7354566676236014 | validation: 2.3238164967773067]
	TIME [epoch: 10.2 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6753529220411987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6753529220411987 | validation: 2.209521601290547]
	TIME [epoch: 10.2 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7250546647616787		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7250546647616787 | validation: 2.1689560232010536]
	TIME [epoch: 10.2 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6252552381295486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6252552381295486 | validation: 2.335970585655639]
	TIME [epoch: 10.2 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.105223707429295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.105223707429295 | validation: 2.381133189606284]
	TIME [epoch: 10.2 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7540067180364756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7540067180364756 | validation: 2.2643945753562913]
	TIME [epoch: 10.1 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.656009579543289		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.656009579543289 | validation: 2.2188880134395896]
	TIME [epoch: 10.2 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.75999619260108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.75999619260108 | validation: 2.3893864457345506]
	TIME [epoch: 10.2 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7302638065746003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7302638065746003 | validation: 2.2437418361972727]
	TIME [epoch: 10.1 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.70898023275231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.70898023275231 | validation: 2.300063037022177]
	TIME [epoch: 10.2 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6570008043839812		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6570008043839812 | validation: 2.1717347693068727]
	TIME [epoch: 10.2 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.702352681994628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.702352681994628 | validation: 2.264010677952402]
	TIME [epoch: 10.2 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6962025908969003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6962025908969003 | validation: 2.2163544424438055]
	TIME [epoch: 10.2 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6545061128486513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6545061128486513 | validation: 2.2459635782551284]
	TIME [epoch: 10.2 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.680550523476014		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.680550523476014 | validation: 2.1322586922784614]
	TIME [epoch: 10.1 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.59566933133213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.59566933133213 | validation: 2.147261913482439]
	TIME [epoch: 10.1 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6537534536428815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6537534536428815 | validation: 2.2182531681682467]
	TIME [epoch: 10.1 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6583610191870766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6583610191870766 | validation: 2.1036378850968886]
	TIME [epoch: 10.1 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.712693138500581		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.712693138500581 | validation: 2.167576556626907]
	TIME [epoch: 10.1 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.595429804152525		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.595429804152525 | validation: 2.1848017191628135]
	TIME [epoch: 10.1 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.577054093624153		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.577054093624153 | validation: 2.5177263515564365]
	TIME [epoch: 10.1 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.661082742373737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.661082742373737 | validation: 2.3237048406113607]
	TIME [epoch: 10.1 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6586992491257697		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6586992491257697 | validation: 2.1568150985499046]
	TIME [epoch: 10.1 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5606203048394955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5606203048394955 | validation: 2.265395388245308]
	TIME [epoch: 10.1 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6258080496354914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6258080496354914 | validation: 3.0157316985582656]
	TIME [epoch: 10.1 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.936604157879826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.936604157879826 | validation: 6.093643781921555]
	TIME [epoch: 10.1 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.776696958809786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.776696958809786 | validation: 2.64773277229926]
	TIME [epoch: 10.1 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.712762486499559		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.712762486499559 | validation: 2.194544819489839]
	TIME [epoch: 10.1 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.615544632696241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.615544632696241 | validation: 2.175799576386128]
	TIME [epoch: 10.1 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7680711750707125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7680711750707125 | validation: 2.1583371008415764]
	TIME [epoch: 10.1 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.592732294254387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.592732294254387 | validation: 2.112581250338115]
	TIME [epoch: 10.1 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5780282142963324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5780282142963324 | validation: 2.099620337758287]
	TIME [epoch: 10.1 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5609987225231947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5609987225231947 | validation: 2.080273069369394]
	TIME [epoch: 10.1 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.638353064538454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.638353064538454 | validation: 2.0647864377421916]
	TIME [epoch: 10.1 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6569292015946497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6569292015946497 | validation: 1.9602138388901755]
	TIME [epoch: 10.2 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.45634567060935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.45634567060935 | validation: 2.080809430868563]
	TIME [epoch: 10.1 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5486667729150954		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5486667729150954 | validation: 1.9885731570558356]
	TIME [epoch: 10.2 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.480974329786273		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.480974329786273 | validation: 2.1054997277453977]
	TIME [epoch: 10.2 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4856885411601963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4856885411601963 | validation: 2.322799081486424]
	TIME [epoch: 10.2 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6199622534452125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6199622534452125 | validation: 2.0016018011902172]
	TIME [epoch: 10.2 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5044438111632616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5044438111632616 | validation: 2.1253008902385857]
	TIME [epoch: 10.1 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4671270536391057		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4671270536391057 | validation: 2.275741443524992]
	TIME [epoch: 10.2 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5874665746306893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5874665746306893 | validation: 2.299552615346669]
	TIME [epoch: 10.2 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7180179066479297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7180179066479297 | validation: 2.1244279242805613]
	TIME [epoch: 10.1 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6254211737885282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6254211737885282 | validation: 2.1998702267158916]
	TIME [epoch: 10.2 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.631254355557816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.631254355557816 | validation: 2.2055369602593795]
	TIME [epoch: 10.2 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6090724547382447		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6090724547382447 | validation: 2.2143911743862]
	TIME [epoch: 10.1 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.629490874199285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.629490874199285 | validation: 2.241046940330856]
	TIME [epoch: 10.2 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6019116473364305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6019116473364305 | validation: 2.040520254110073]
	TIME [epoch: 10.1 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4631722553736655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4631722553736655 | validation: 1.9709775153804878]
	TIME [epoch: 10.1 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5831815785706467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5831815785706467 | validation: 2.1462104028290137]
	TIME [epoch: 10.2 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5432593602067337		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5432593602067337 | validation: 2.46550634900434]
	TIME [epoch: 10.1 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7265389573567615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7265389573567615 | validation: 2.5505432616552732]
	TIME [epoch: 10.1 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7461728715854568		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7461728715854568 | validation: 2.192591514775838]
	TIME [epoch: 10.1 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5627272716588125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5627272716588125 | validation: 2.15277150612872]
	TIME [epoch: 10.2 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.546153846924683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.546153846924683 | validation: 2.079203268574216]
	TIME [epoch: 10.1 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5368019160591264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5368019160591264 | validation: 2.163012842327344]
	TIME [epoch: 10.1 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5886217438040173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5886217438040173 | validation: 2.092819372692943]
	TIME [epoch: 10.1 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6309265152480608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6309265152480608 | validation: 2.0753233046664015]
	TIME [epoch: 10.1 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5438796551618617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5438796551618617 | validation: 2.334137646331159]
	TIME [epoch: 10.1 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.575811661857445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.575811661857445 | validation: 2.3127958560981505]
	TIME [epoch: 10.1 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5430889871628883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5430889871628883 | validation: 2.103352653041584]
	TIME [epoch: 10.1 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5400493299504383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5400493299504383 | validation: 2.180385801110695]
	TIME [epoch: 10.1 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.605896750339906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.605896750339906 | validation: 2.157688711894076]
	TIME [epoch: 10.1 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.52007830306754		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.52007830306754 | validation: 2.0566311560337547]
	TIME [epoch: 10.1 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.880078521952325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.880078521952325 | validation: 3.187461514544271]
	TIME [epoch: 10.1 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.005590224374486		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.005590224374486 | validation: 1.8973752771840862]
	TIME [epoch: 10.1 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.50784245430861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.50784245430861 | validation: 4.208614477134644]
	TIME [epoch: 10.1 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5018456827269175		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5018456827269175 | validation: 3.1427553202453398]
	TIME [epoch: 10.2 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8308148755874996		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8308148755874996 | validation: 2.1881172922650634]
	TIME [epoch: 10.1 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.542439059778634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.542439059778634 | validation: 2.1296740547664075]
	TIME [epoch: 10.2 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.450265228199327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.450265228199327 | validation: 1.9057563732322051]
	TIME [epoch: 10.1 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3682121143367114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3682121143367114 | validation: 1.8310916958970094]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_201.pth
	Model improved!!!
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7970058220305907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7970058220305907 | validation: 3.5521270999474837]
	TIME [epoch: 10.1 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.99893336205298		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.99893336205298 | validation: 1.8886355195940818]
	TIME [epoch: 10.2 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.444883389000853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.444883389000853 | validation: 1.896583717390617]
	TIME [epoch: 10.2 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.408845029108461		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.408845029108461 | validation: 1.8656852879755201]
	TIME [epoch: 10.1 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.429521717021765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.429521717021765 | validation: 1.8547803584925548]
	TIME [epoch: 10.1 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0370250977448765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0370250977448765 | validation: 2.3403951402190817]
	TIME [epoch: 10.2 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5580471255541086		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5580471255541086 | validation: 1.88891515191194]
	TIME [epoch: 10.2 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3795017412506096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3795017412506096 | validation: 1.8412013709410227]
	TIME [epoch: 10.2 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.447786980779964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.447786980779964 | validation: 1.9648604925629738]
	TIME [epoch: 10.1 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4794319511037783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4794319511037783 | validation: 2.097653242622966]
	TIME [epoch: 10.2 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.512000684819244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.512000684819244 | validation: 2.1413593628913294]
	TIME [epoch: 10.2 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.92952439438452		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.92952439438452 | validation: 4.642712387708578]
	TIME [epoch: 10.2 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.139525725464226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.139525725464226 | validation: 2.1015603854582943]
	TIME [epoch: 10.2 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5593968426660445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5593968426660445 | validation: 2.1408066358837927]
	TIME [epoch: 10.2 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5889917392176316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5889917392176316 | validation: 2.0409102087401116]
	TIME [epoch: 10.2 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4838831137417765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4838831137417765 | validation: 1.9482639221163771]
	TIME [epoch: 10.2 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4342130739018795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4342130739018795 | validation: 2.0169008930458143]
	TIME [epoch: 10.2 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.443448368437024		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.443448368437024 | validation: 1.8116542522136272]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_219.pth
	Model improved!!!
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3583866073511275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3583866073511275 | validation: 3.4185383153477256]
	TIME [epoch: 10.2 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.007336260503613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.007336260503613 | validation: 2.0102241822624594]
	TIME [epoch: 10.2 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3835036015427047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3835036015427047 | validation: 1.8187335694144926]
	TIME [epoch: 10.2 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2902159880979704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2902159880979704 | validation: 1.85154994626019]
	TIME [epoch: 10.2 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.399110928278317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.399110928278317 | validation: 1.948183523134382]
	TIME [epoch: 10.2 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.33585951050254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.33585951050254 | validation: 6.957653577576182]
	TIME [epoch: 10.2 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.035908473942497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.035908473942497 | validation: 7.080312055214782]
	TIME [epoch: 10.2 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.06484626189823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.06484626189823 | validation: 6.908496534107934]
	TIME [epoch: 10.2 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.02735539486188		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.02735539486188 | validation: 6.823477763288363]
	TIME [epoch: 10.2 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.262929236148015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.262929236148015 | validation: 5.412650857463297]
	TIME [epoch: 10.2 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2683955749358633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2683955749358633 | validation: 1.6147271974871469]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.444803969390911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.444803969390911 | validation: 2.3309794491304676]
	TIME [epoch: 10.1 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.641805314121993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.641805314121993 | validation: 2.516249144910253]
	TIME [epoch: 10.2 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6449606314712533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6449606314712533 | validation: 1.9035184444967654]
	TIME [epoch: 10.1 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2932078353390266		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2932078353390266 | validation: 1.9655381415848008]
	TIME [epoch: 10.1 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.396439545751643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.396439545751643 | validation: 2.6026503834456505]
	TIME [epoch: 10.1 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7427586314405126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7427586314405126 | validation: 2.0234876504163903]
	TIME [epoch: 10.1 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.989050850502141		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.989050850502141 | validation: 3.8487852382173338]
	TIME [epoch: 10.1 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6743867682166877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6743867682166877 | validation: 3.6402596010767367]
	TIME [epoch: 10.1 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4887011629162963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4887011629162963 | validation: 2.723840605395639]
	TIME [epoch: 10.1 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9250079475965487		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9250079475965487 | validation: 2.2318424874248897]
	TIME [epoch: 10.1 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6997347369206457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6997347369206457 | validation: 2.874010947064253]
	TIME [epoch: 10.1 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9104644736430823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9104644736430823 | validation: 2.2214257104089845]
	TIME [epoch: 10.1 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8041489015993926		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8041489015993926 | validation: 2.224171377655974]
	TIME [epoch: 10.1 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7800631749652003		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7800631749652003 | validation: 2.2195781713526346]
	TIME [epoch: 10.2 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7003437441282125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7003437441282125 | validation: 2.1257855401145562]
	TIME [epoch: 10.1 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.557393563406124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.557393563406124 | validation: 1.9612190571058308]
	TIME [epoch: 10.1 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4676921038313413		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4676921038313413 | validation: 1.8705544116487918]
	TIME [epoch: 10.2 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4325201910868914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4325201910868914 | validation: 1.9406555142989772]
	TIME [epoch: 10.2 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3960759168434693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3960759168434693 | validation: 1.9476781448621387]
	TIME [epoch: 10.2 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3245318520169853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3245318520169853 | validation: 1.763222144894732]
	TIME [epoch: 10.2 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.028619693882019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.028619693882019 | validation: 2.216729798750692]
	TIME [epoch: 10.2 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.588159709671058		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.588159709671058 | validation: 2.11600362140474]
	TIME [epoch: 10.2 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.398859627044459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.398859627044459 | validation: 1.920093230721863]
	TIME [epoch: 10.2 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.386969113573236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.386969113573236 | validation: 2.313212606507079]
	TIME [epoch: 10.2 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5663982018628033		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5663982018628033 | validation: 1.9055235440603224]
	TIME [epoch: 10.2 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.37802332156942		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.37802332156942 | validation: 1.8325181485084228]
	TIME [epoch: 10.3 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3761448200884234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3761448200884234 | validation: 1.8670102209018475]
	TIME [epoch: 10.3 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3369290285951707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3369290285951707 | validation: 1.7710549401490472]
	TIME [epoch: 10.2 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.335543534483609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.335543534483609 | validation: 1.8648017547172788]
	TIME [epoch: 10.2 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3623241983135204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3623241983135204 | validation: 1.8120562448663275]
	TIME [epoch: 10.2 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.292021168949554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.292021168949554 | validation: 1.892481057721895]
	TIME [epoch: 10.3 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.308224922545652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.308224922545652 | validation: 2.2334908018782897]
	TIME [epoch: 10.2 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5572933519850203		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5572933519850203 | validation: 1.9824482635759575]
	TIME [epoch: 10.2 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4341173417311417		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4341173417311417 | validation: 2.061746342046786]
	TIME [epoch: 10.2 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4543791024646198		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4543791024646198 | validation: 1.9228422192198409]
	TIME [epoch: 10.2 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.345693050987285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.345693050987285 | validation: 1.7843635853275297]
	TIME [epoch: 10.2 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0630144142007554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0630144142007554 | validation: 2.556768278515617]
	TIME [epoch: 10.3 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6715792358661163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6715792358661163 | validation: 2.2509927835473396]
	TIME [epoch: 10.2 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5658099476573826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5658099476573826 | validation: 2.097604272225712]
	TIME [epoch: 10.2 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5664551396340896		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5664551396340896 | validation: 2.026842407229027]
	TIME [epoch: 10.2 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.463738265351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.463738265351 | validation: 1.977298220322387]
	TIME [epoch: 10.2 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.426050548370939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.426050548370939 | validation: 1.957001447489012]
	TIME [epoch: 10.2 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.421447979960672		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.421447979960672 | validation: 1.9191724655934477]
	TIME [epoch: 10.2 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4057128459473267		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4057128459473267 | validation: 1.9038313808275291]
	TIME [epoch: 10.2 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.50156093624442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.50156093624442 | validation: 2.1142606925289433]
	TIME [epoch: 10.2 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.513078412357477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.513078412357477 | validation: 2.1435178110977775]
	TIME [epoch: 10.2 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.51111577659623		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.51111577659623 | validation: 1.9698536050172282]
	TIME [epoch: 10.2 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.406331571701105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.406331571701105 | validation: 1.9401913845281302]
	TIME [epoch: 10.1 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7438224373999507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7438224373999507 | validation: 3.312815895638488]
	TIME [epoch: 10.2 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.990124988255535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.990124988255535 | validation: 2.0231631319534378]
	TIME [epoch: 10.1 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7006074221009357		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7006074221009357 | validation: 2.0124945106780867]
	TIME [epoch: 10.2 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.492636198515937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.492636198515937 | validation: 1.9934716252744846]
	TIME [epoch: 10.2 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.492388302499335		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.492388302499335 | validation: 2.0439297916522867]
	TIME [epoch: 10.2 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5760298806807653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.5760298806807653 | validation: 1.9757060789072458]
	TIME [epoch: 10.2 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.355389071383723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.355389071383723 | validation: 1.5117653566295233]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_285.pth
	Model improved!!!
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9518420893650597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9518420893650597 | validation: 2.4922003944846303]
	TIME [epoch: 10.2 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.270193286941469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.270193286941469 | validation: 2.2236416184498173]
	TIME [epoch: 10.2 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.436528401022862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.436528401022862 | validation: 0.9414262736746061]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8267159625740949		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8267159625740949 | validation: 0.6471646484363095]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_289.pth
	Model improved!!!
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7130585936963814		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7130585936963814 | validation: 0.5088407117383946]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_290.pth
	Model improved!!!
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7461404057686909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7461404057686909 | validation: 0.6583676830644464]
	TIME [epoch: 10.2 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9706207447466291		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9706207447466291 | validation: 0.8441141721201286]
	TIME [epoch: 10.2 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6435691582557229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6435691582557229 | validation: 0.5248512893061009]
	TIME [epoch: 10.2 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6024275926619229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6024275926619229 | validation: 0.6166963830706547]
	TIME [epoch: 10.2 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5673724921496128		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5673724921496128 | validation: 0.6395696730073188]
	TIME [epoch: 10.2 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5411729650509752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5411729650509752 | validation: 0.40482071887428456]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_296.pth
	Model improved!!!
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8494235367580132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8494235367580132 | validation: 0.6938521968654052]
	TIME [epoch: 10.1 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6559167568742358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6559167568742358 | validation: 0.6085856140981577]
	TIME [epoch: 10.1 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6005338554641166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6005338554641166 | validation: 0.598912773161169]
	TIME [epoch: 10.1 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6740954588009107		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6740954588009107 | validation: 0.7737910699123706]
	TIME [epoch: 10.1 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7105031556438652		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7105031556438652 | validation: 0.6272716773279916]
	TIME [epoch: 10.1 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8742353048133049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8742353048133049 | validation: 1.2171735161086117]
	TIME [epoch: 10.1 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8921857812568739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8921857812568739 | validation: 0.6535590431613486]
	TIME [epoch: 10.1 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6020748348013176		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6020748348013176 | validation: 0.7724093414967268]
	TIME [epoch: 10.2 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6662057726689384		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6662057726689384 | validation: 0.5957664753711645]
	TIME [epoch: 10.1 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6837601134547749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6837601134547749 | validation: 0.866255962671585]
	TIME [epoch: 10.2 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6433928584260442		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6433928584260442 | validation: 0.5736569262215386]
	TIME [epoch: 10.1 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6321311781832061		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6321311781832061 | validation: 0.75888389634362]
	TIME [epoch: 10.1 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6768137858857171		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6768137858857171 | validation: 0.5287838345573838]
	TIME [epoch: 10.2 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.689553519133197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.689553519133197 | validation: 0.6574457483448012]
	TIME [epoch: 10.1 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6340428328670874		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6340428328670874 | validation: 0.7207855792672321]
	TIME [epoch: 10.1 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6318793049810943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6318793049810943 | validation: 0.6070533870719439]
	TIME [epoch: 10.1 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6058154651003649		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6058154651003649 | validation: 0.574263580348214]
	TIME [epoch: 10.1 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5601643966973047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5601643966973047 | validation: 0.7324555534686317]
	TIME [epoch: 10.2 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6327013752487597		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6327013752487597 | validation: 0.7172006733159523]
	TIME [epoch: 10.1 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6088375219625783		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6088375219625783 | validation: 0.5374275006653604]
	TIME [epoch: 10.1 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5665656026233292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5665656026233292 | validation: 0.6045757863169461]
	TIME [epoch: 10.1 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7025252441388191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7025252441388191 | validation: 0.559896538132835]
	TIME [epoch: 10.2 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5995140351883961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5995140351883961 | validation: 0.5761841685120018]
	TIME [epoch: 10.1 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5574281556817593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5574281556817593 | validation: 0.5778520053351626]
	TIME [epoch: 10.1 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5497926446228065		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5497926446228065 | validation: 0.6679669435260219]
	TIME [epoch: 10.1 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6060697858626745		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6060697858626745 | validation: 0.5811816757844531]
	TIME [epoch: 10.1 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6213566221668241		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6213566221668241 | validation: 0.5006505467940916]
	TIME [epoch: 10.1 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5554045663664235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5554045663664235 | validation: 0.5674184377207452]
	TIME [epoch: 10.2 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5860140825252561		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5860140825252561 | validation: 0.4681627328378428]
	TIME [epoch: 10.1 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5190256697810607		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5190256697810607 | validation: 0.6812098860856325]
	TIME [epoch: 10.1 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5764264743280629		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5764264743280629 | validation: 0.6610975487236224]
	TIME [epoch: 10.2 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5088114159080664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5088114159080664 | validation: 0.5274668034745974]
	TIME [epoch: 10.1 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8507981126331956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8507981126331956 | validation: 0.6352920747974724]
	TIME [epoch: 10.1 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6956003139906455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6956003139906455 | validation: 0.5737462777318686]
	TIME [epoch: 10.2 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5167939587011292		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5167939587011292 | validation: 0.6461777329744084]
	TIME [epoch: 10.1 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6828988213549847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6828988213549847 | validation: 0.5806271838401424]
	TIME [epoch: 10.2 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.528418749326834		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.528418749326834 | validation: 0.5044240069267412]
	TIME [epoch: 10.1 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5254927381892194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5254927381892194 | validation: 0.43531335534156085]
	TIME [epoch: 10.2 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47196511682204817		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47196511682204817 | validation: 0.8363567769194044]
	TIME [epoch: 10.1 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6061118351148468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6061118351148468 | validation: 0.7760862607415356]
	TIME [epoch: 10.1 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7401118651368739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7401118651368739 | validation: 0.4781287579373793]
	TIME [epoch: 10.1 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5513004298727625		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5513004298727625 | validation: 0.5163834158465981]
	TIME [epoch: 10.1 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5258344144113439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5258344144113439 | validation: 0.48452232551417396]
	TIME [epoch: 10.2 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8372607835463398		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8372607835463398 | validation: 0.5622018026598743]
	TIME [epoch: 10.1 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5601667117076496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5601667117076496 | validation: 0.4982708095069623]
	TIME [epoch: 10.1 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5812692628177472		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5812692628177472 | validation: 0.6063947051180963]
	TIME [epoch: 10.1 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5470585062399342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5470585062399342 | validation: 0.6051641895313585]
	TIME [epoch: 10.2 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5772583455444841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5772583455444841 | validation: 0.4925948121387792]
	TIME [epoch: 10.1 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5877309916899083		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5877309916899083 | validation: 0.5985060210948245]
	TIME [epoch: 10.2 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5100787363988853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5100787363988853 | validation: 0.5045191611756951]
	TIME [epoch: 10.1 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5205918625305149		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5205918625305149 | validation: 0.46363045649377077]
	TIME [epoch: 10.1 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5558586296684881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5558586296684881 | validation: 0.5406459660792889]
	TIME [epoch: 10.1 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5121369664407974		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5121369664407974 | validation: 0.5185870218117637]
	TIME [epoch: 10.1 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6999745519165878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6999745519165878 | validation: 0.5147890024712971]
	TIME [epoch: 10.1 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5653271223388421		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5653271223388421 | validation: 0.4635384522297045]
	TIME [epoch: 10.2 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4785930377841585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4785930377841585 | validation: 0.5381787826526204]
	TIME [epoch: 10.1 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5533560208406738		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5533560208406738 | validation: 0.5826518873269403]
	TIME [epoch: 10.1 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7943915834992453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7943915834992453 | validation: 0.6361479710205711]
	TIME [epoch: 10.2 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.052413020358993		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.052413020358993 | validation: 2.004562679882525]
	TIME [epoch: 10.2 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4205904812575443		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4205904812575443 | validation: 2.0491863148528338]
	TIME [epoch: 10.2 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4165687270331317		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4165687270331317 | validation: 2.2882662873443174]
	TIME [epoch: 10.2 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.472793285591435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.472793285591435 | validation: 2.0175375721336657]
	TIME [epoch: 10.1 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4046842446163943		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4046842446163943 | validation: 1.9980013005904744]
	TIME [epoch: 10.2 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1735777282108897		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1735777282108897 | validation: 0.6120704518474446]
	TIME [epoch: 10.2 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4468764834521735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4468764834521735 | validation: 4.034870791376024]
	TIME [epoch: 10.2 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2558980940453734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2558980940453734 | validation: 3.3148985166751856]
	TIME [epoch: 10.2 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.876110588970367		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.876110588970367 | validation: 1.325656795636419]
	TIME [epoch: 10.2 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8498206907820038		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8498206907820038 | validation: 1.862958403998726]
	TIME [epoch: 10.2 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9326000821850474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9326000821850474 | validation: 0.9578586252922459]
	TIME [epoch: 10.2 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0488639674825166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0488639674825166 | validation: 2.6904586029053315]
	TIME [epoch: 10.2 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2349988922985204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2349988922985204 | validation: 0.7238947747581722]
	TIME [epoch: 10.2 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6227997982303437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6227997982303437 | validation: 0.7086298618737178]
	TIME [epoch: 10.1 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6567920795196092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6567920795196092 | validation: 0.6207576828034282]
	TIME [epoch: 10.1 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.659257952022592		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.659257952022592 | validation: 0.5781380202286386]
	TIME [epoch: 10.1 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5781816610333145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5781816610333145 | validation: 0.7604127992128742]
	TIME [epoch: 10.2 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5958749012323934		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5958749012323934 | validation: 0.6311443301534828]
	TIME [epoch: 10.1 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.536324291065862		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.536324291065862 | validation: 0.4024978478571377]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_373.pth
	Model improved!!!
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.80247779089965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.80247779089965 | validation: 0.4788056913028225]
	TIME [epoch: 10.1 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5881048847047048		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5881048847047048 | validation: 0.4793449668169963]
	TIME [epoch: 10.1 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.482357654095937		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.482357654095937 | validation: 0.5267228699142092]
	TIME [epoch: 10.1 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45487662176359667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.45487662176359667 | validation: 0.421529784344234]
	TIME [epoch: 10.1 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7906261600949861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7906261600949861 | validation: 0.5845758513290593]
	TIME [epoch: 10.1 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5863756606392134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5863756606392134 | validation: 0.7418852334777367]
	TIME [epoch: 10.2 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5828084277429667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5828084277429667 | validation: 0.5111369969821449]
	TIME [epoch: 10.2 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5790313838954081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5790313838954081 | validation: 0.562444786813071]
	TIME [epoch: 10.2 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5633140744913161		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5633140744913161 | validation: 1.6709309015881173]
	TIME [epoch: 10.2 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3413200868586055		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3413200868586055 | validation: 0.6032820235356701]
	TIME [epoch: 10.2 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5707650035224411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5707650035224411 | validation: 0.5272832663217353]
	TIME [epoch: 10.2 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7571386721101686		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7571386721101686 | validation: 0.4509968583978531]
	TIME [epoch: 10.2 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7797435374594801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7797435374594801 | validation: 1.5629741774401935]
	TIME [epoch: 10.2 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9735496077507373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9735496077507373 | validation: 0.5167411879788644]
	TIME [epoch: 10.2 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48383130160891225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48383130160891225 | validation: 1.3307678003197918]
	TIME [epoch: 10.1 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4800351198573316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4800351198573316 | validation: 1.9392368029337632]
	TIME [epoch: 10.2 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9331415463164425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9331415463164425 | validation: 1.1915785604158915]
	TIME [epoch: 10.2 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2449121709644018		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2449121709644018 | validation: 0.8573954292707492]
	TIME [epoch: 10.2 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6785528694290253		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6785528694290253 | validation: 0.45541607494051484]
	TIME [epoch: 10.2 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6095590262744396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6095590262744396 | validation: 0.6824685214746525]
	TIME [epoch: 10.1 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5010786460362238		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5010786460362238 | validation: 0.4072960657163302]
	TIME [epoch: 10.1 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4769168889932297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4769168889932297 | validation: 0.43296001923987776]
	TIME [epoch: 10.1 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46242414511162816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46242414511162816 | validation: 1.1403163235266545]
	TIME [epoch: 10.2 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7928252453534358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7928252453534358 | validation: 0.5843904096329287]
	TIME [epoch: 10.2 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.484970146655631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.484970146655631 | validation: 0.5278886366165539]
	TIME [epoch: 10.2 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4962540658050575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4962540658050575 | validation: 1.9817511139647832]
	TIME [epoch: 10.2 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6869878184545999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6869878184545999 | validation: 1.5560194760367103]
	TIME [epoch: 10.2 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2491455225146064		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2491455225146064 | validation: 0.3736672165985816]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_401.pth
	Model improved!!!
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48040763198437286		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48040763198437286 | validation: 0.6017753612414833]
	TIME [epoch: 10.1 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.533895260782223		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.533895260782223 | validation: 0.8213705824234563]
	TIME [epoch: 10.2 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.776849200554661		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.776849200554661 | validation: 0.5266339890996137]
	TIME [epoch: 10.2 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5138092521665513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5138092521665513 | validation: 0.6885218263283145]
	TIME [epoch: 10.2 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5593668498562957		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5593668498562957 | validation: 0.5957816220267275]
	TIME [epoch: 10.2 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.515728071005822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.515728071005822 | validation: 0.5894664268271202]
	TIME [epoch: 10.2 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46383188076424925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46383188076424925 | validation: 0.39652904418168033]
	TIME [epoch: 10.2 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8131335358673676		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8131335358673676 | validation: 0.7621933804251628]
	TIME [epoch: 10.2 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5515997381917264		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5515997381917264 | validation: 0.49164064113459743]
	TIME [epoch: 10.2 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5690921986322723		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5690921986322723 | validation: 0.5353238019426821]
	TIME [epoch: 10.2 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47349566121837217		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47349566121837217 | validation: 0.4027880111075803]
	TIME [epoch: 10.2 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4460589358076712		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4460589358076712 | validation: 0.43891681756172474]
	TIME [epoch: 10.2 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4721237899809946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4721237899809946 | validation: 0.49161422168895585]
	TIME [epoch: 10.2 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4925399345440063		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4925399345440063 | validation: 0.9113613588647168]
	TIME [epoch: 10.2 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9524293576335884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9524293576335884 | validation: 0.771722456506416]
	TIME [epoch: 10.2 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0047584933009628		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0047584933009628 | validation: 1.8940680962878096]
	TIME [epoch: 10.2 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.835543724379497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.835543724379497 | validation: 0.6177485268363027]
	TIME [epoch: 10.2 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5977748503144407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5977748503144407 | validation: 0.3493634682780353]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_419.pth
	Model improved!!!
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46406907245399476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46406907245399476 | validation: 0.6190365806391529]
	TIME [epoch: 10.2 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4905003728719852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4905003728719852 | validation: 0.26911000895648923]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_421.pth
	Model improved!!!
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4003869058887502		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4003869058887502 | validation: 0.3576759802213769]
	TIME [epoch: 10.2 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47683439373720704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.47683439373720704 | validation: 0.8162239513969815]
	TIME [epoch: 10.2 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.56370884620163		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.56370884620163 | validation: 0.5093926700503475]
	TIME [epoch: 10.2 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3926098540678842		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3926098540678842 | validation: 0.43050234452375924]
	TIME [epoch: 10.2 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4242679138753239		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4242679138753239 | validation: 0.46634109795090795]
	TIME [epoch: 10.1 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3962732980506805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3962732980506805 | validation: 0.33099660535078806]
	TIME [epoch: 10.2 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4328931104497092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4328931104497092 | validation: 0.6691305172147236]
	TIME [epoch: 10.2 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7579538700118116		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7579538700118116 | validation: 0.5518707934434548]
	TIME [epoch: 10.2 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7446879893804489		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7446879893804489 | validation: 0.4629952414041004]
	TIME [epoch: 10.1 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48414875642499944		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48414875642499944 | validation: 0.332830748289973]
	TIME [epoch: 10.2 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.543956645921248		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.543956645921248 | validation: 0.3767538901018129]
	TIME [epoch: 10.2 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39549376062720853		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39549376062720853 | validation: 0.2438469480167241]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_433.pth
	Model improved!!!
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5049116579778363		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5049116579778363 | validation: 0.43783381638629026]
	TIME [epoch: 10.2 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217270590302119		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5217270590302119 | validation: 0.2967296011445742]
	TIME [epoch: 10.2 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6566372547867763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6566372547867763 | validation: 0.5998029540388691]
	TIME [epoch: 10.2 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4890464592113341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4890464592113341 | validation: 0.44331684800030446]
	TIME [epoch: 10.2 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4092781128473469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4092781128473469 | validation: 1.6774073301545867]
	TIME [epoch: 10.2 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.292108324599488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.292108324599488 | validation: 0.44617529446176407]
	TIME [epoch: 10.2 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.882799485342856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.882799485342856 | validation: 0.718260832883691]
	TIME [epoch: 10.2 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6900081746377655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6900081746377655 | validation: 0.5997364464390363]
	TIME [epoch: 10.2 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7054511728425379		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7054511728425379 | validation: 1.6290315334119674]
	TIME [epoch: 10.2 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9895932042475255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9895932042475255 | validation: 0.7373232052416122]
	TIME [epoch: 10.2 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9801901777248977		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9801901777248977 | validation: 1.3356191144315432]
	TIME [epoch: 10.2 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2920339728234822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2920339728234822 | validation: 0.5624843602144506]
	TIME [epoch: 10.2 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.572018631702746		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.572018631702746 | validation: 0.6093204217775537]
	TIME [epoch: 10.2 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48470046121161375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48470046121161375 | validation: 0.4142420402204776]
	TIME [epoch: 10.2 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44973292133871795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.44973292133871795 | validation: 0.5629440536514705]
	TIME [epoch: 10.2 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.515201953902656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.515201953902656 | validation: 0.28260258689019524]
	TIME [epoch: 10.2 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32946680513916504		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.32946680513916504 | validation: 0.48863576203012715]
	TIME [epoch: 10.2 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.130731900447366		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.130731900447366 | validation: 0.31922535449391276]
	TIME [epoch: 10.2 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46994909149032543		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46994909149032543 | validation: 0.3657386201852257]
	TIME [epoch: 10.2 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5512800800904315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5512800800904315 | validation: 0.5496121174962868]
	TIME [epoch: 10.2 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4917712023294184		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4917712023294184 | validation: 0.429405947226478]
	TIME [epoch: 10.2 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4587879818014876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4587879818014876 | validation: 0.8539212683394786]
	TIME [epoch: 10.2 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.692547323977869		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.692547323977869 | validation: 0.4591123046282885]
	TIME [epoch: 10.2 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4514262819277115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4514262819277115 | validation: 0.4919158210014763]
	TIME [epoch: 10.2 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4599340239820523		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.4599340239820523 | validation: 0.4457981587037745]
	TIME [epoch: 10.2 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5941763763967947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5941763763967947 | validation: 0.7179046238233708]
	TIME [epoch: 10.2 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49663485748503805		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.49663485748503805 | validation: 0.27730217196427964]
	TIME [epoch: 10.2 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31249511392241675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.31249511392241675 | validation: 0.33563280386605937]
	TIME [epoch: 10.2 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48972903205112284		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48972903205112284 | validation: 0.38689050148790116]
	TIME [epoch: 10.2 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48382277318289313		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.48382277318289313 | validation: 0.4496759597424628]
	TIME [epoch: 10.2 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5875599154739322		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5875599154739322 | validation: 0.3644067447291057]
	TIME [epoch: 10.2 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5451217762836469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5451217762836469 | validation: 2.057336331002569]
	TIME [epoch: 10.2 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.520790768246324		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.520790768246324 | validation: 2.000860492667498]
	TIME [epoch: 10.2 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.544048002540939		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.544048002540939 | validation: 2.1277793720622418]
	TIME [epoch: 10.2 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.268878682305009		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.268878682305009 | validation: 0.3755046483016215]
	TIME [epoch: 10.2 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.320484882876538		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.320484882876538 | validation: 0.33084025130287337]
	TIME [epoch: 10.2 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6574008585454287		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6574008585454287 | validation: 1.786438224962273]
	TIME [epoch: 10.2 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3647460747247715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3647460747247715 | validation: 1.8567976466857032]
	TIME [epoch: 10.2 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.468472519797132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.468472519797132 | validation: 1.8959001377042046]
	TIME [epoch: 10.2 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4791731469769496		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4791731469769496 | validation: 1.8543436908956807]
	TIME [epoch: 10.2 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.43178171902784		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.43178171902784 | validation: 1.8439379456255045]
	TIME [epoch: 10.2 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.181586567863576		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.181586567863576 | validation: 0.4308106718663363]
	TIME [epoch: 10.2 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7593543763298987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7593543763298987 | validation: 0.19146229731814565]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_476.pth
	Model improved!!!
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38050102999879865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.38050102999879865 | validation: 1.4181113969075796]
	TIME [epoch: 10.2 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3535896228185704		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3535896228185704 | validation: 1.9970498727521502]
	TIME [epoch: 10.2 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.441136823180208		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.441136823180208 | validation: 1.9665690689212938]
	TIME [epoch: 10.2 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.489575625760752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.489575625760752 | validation: 1.9601210990453688]
	TIME [epoch: 10.2 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4142724416489254		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4142724416489254 | validation: 2.21902624395918]
	TIME [epoch: 10.2 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.485807297734964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.485807297734964 | validation: 1.9800238158716619]
	TIME [epoch: 10.2 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4121891206486956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4121891206486956 | validation: 1.94575249338359]
	TIME [epoch: 10.2 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3547520377298428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.3547520377298428 | validation: 1.4370955988202037]
	TIME [epoch: 10.2 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2403645654972029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2403645654972029 | validation: 0.5165458016117662]
	TIME [epoch: 10.2 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9287470368710837		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9287470368710837 | validation: 1.3269888175285411]
	TIME [epoch: 10.2 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7206269689326946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7206269689326946 | validation: 0.4165233573793895]
	TIME [epoch: 10.2 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3309912666951133		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.3309912666951133 | validation: 0.23148135675530607]
	TIME [epoch: 10.2 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2872212665428457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.2872212665428457 | validation: 0.29975738756538867]
	TIME [epoch: 10.1 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36807467462219023		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.36807467462219023 | validation: 0.395568434589435]
	TIME [epoch: 10.2 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7724722898566025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7724722898566025 | validation: 0.5317947091762294]
	TIME [epoch: 10.2 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39701261334517984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.39701261334517984 | validation: 0.25296952591460553]
	TIME [epoch: 10.2 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46151541517914224		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.46151541517914224 | validation: 0.6271378099967235]
	TIME [epoch: 10.1 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7662064086924761		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7662064086924761 | validation: 0.7496116703222387]
	TIME [epoch: 10.2 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5994484566819795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5994484566819795 | validation: 0.4892544931025606]
	TIME [epoch: 10.2 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.592346622276705		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.592346622276705 | validation: 0.5820489502783515]
	TIME [epoch: 10.2 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6138247455248008		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.6138247455248008 | validation: 0.511646587531615]
	TIME [epoch: 10.2 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.529119222939231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.529119222939231 | validation: 0.5730358991107636]
	TIME [epoch: 10.2 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5652540283994524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.5652540283994524 | validation: 0.49723048222633837]
	TIME [epoch: 10.2 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.546871493939374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.546871493939374 | validation: 0.8389815670222766]
	TIME [epoch: 10.2 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.528965614460466		[learning rate: 0.0099755]
	Learning Rate: 0.00997547
	LOSS [training: 0.528965614460466 | validation: 0.4638924321542987]
	TIME [epoch: 10.2 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8813819503132485		[learning rate: 0.0099449]
	Learning Rate: 0.00994489
	LOSS [training: 0.8813819503132485 | validation: 0.4640339917324224]
	TIME [epoch: 10.2 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.685579263978149		[learning rate: 0.0099144]
	Learning Rate: 0.0099144
	LOSS [training: 0.685579263978149 | validation: 0.8818967180383425]
	TIME [epoch: 10.2 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3109593480693906		[learning rate: 0.009884]
	Learning Rate: 0.00988401
	LOSS [training: 1.3109593480693906 | validation: 0.5150599310066653]
	TIME [epoch: 10.2 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4181229808816654		[learning rate: 0.0098537]
	Learning Rate: 0.00985371
	LOSS [training: 0.4181229808816654 | validation: 0.5891527115306334]
	TIME [epoch: 10.2 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5293120815179542		[learning rate: 0.0098235]
	Learning Rate: 0.00982351
	LOSS [training: 0.5293120815179542 | validation: 0.7056593118276547]
	TIME [epoch: 10.2 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5960072267685701		[learning rate: 0.0097934]
	Learning Rate: 0.0097934
	LOSS [training: 0.5960072267685701 | validation: 0.5096062789477449]
	TIME [epoch: 10.2 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5103396130035097		[learning rate: 0.0097634]
	Learning Rate: 0.00976337
	LOSS [training: 0.5103396130035097 | validation: 1.5391552931426549]
	TIME [epoch: 10.2 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6984551949358977		[learning rate: 0.0097334]
	Learning Rate: 0.00973345
	LOSS [training: 0.6984551949358977 | validation: 0.4543133511620252]
	TIME [epoch: 10.2 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39686802502407137		[learning rate: 0.0097036]
	Learning Rate: 0.00970361
	LOSS [training: 0.39686802502407137 | validation: 0.4730590472587194]
	TIME [epoch: 10.2 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5846937768188833		[learning rate: 0.0096739]
	Learning Rate: 0.00967386
	LOSS [training: 0.5846937768188833 | validation: 0.5849785394606465]
	TIME [epoch: 10.2 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.444599046044753		[learning rate: 0.0096442]
	Learning Rate: 0.00964421
	LOSS [training: 0.444599046044753 | validation: 0.34828229014489]
	TIME [epoch: 10.2 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2950151151797177		[learning rate: 0.0096146]
	Learning Rate: 0.00961465
	LOSS [training: 0.2950151151797177 | validation: 0.363158085950076]
	TIME [epoch: 10.2 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4561824962057851		[learning rate: 0.0095852]
	Learning Rate: 0.00958517
	LOSS [training: 0.4561824962057851 | validation: 0.5587568095580019]
	TIME [epoch: 10.2 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5041597380207052		[learning rate: 0.0095558]
	Learning Rate: 0.00955579
	LOSS [training: 0.5041597380207052 | validation: 0.5309439061483849]
	TIME [epoch: 10.2 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.516550033928941		[learning rate: 0.0095265]
	Learning Rate: 0.0095265
	LOSS [training: 0.516550033928941 | validation: 0.39423401479597053]
	TIME [epoch: 10.2 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5875140919569486		[learning rate: 0.0094973]
	Learning Rate: 0.0094973
	LOSS [training: 0.5875140919569486 | validation: 0.4393086362677419]
	TIME [epoch: 10.2 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.430327276218768		[learning rate: 0.0094682]
	Learning Rate: 0.00946818
	LOSS [training: 0.430327276218768 | validation: 0.3329378500691436]
	TIME [epoch: 10.2 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9107919061546083		[learning rate: 0.0094392]
	Learning Rate: 0.00943916
	LOSS [training: 0.9107919061546083 | validation: 0.7654815965976896]
	TIME [epoch: 10.2 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4509983657955548		[learning rate: 0.0094102]
	Learning Rate: 0.00941022
	LOSS [training: 0.4509983657955548 | validation: 0.5268380788079035]
	TIME [epoch: 10.2 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5675460856770724		[learning rate: 0.0093814]
	Learning Rate: 0.00938138
	LOSS [training: 0.5675460856770724 | validation: 2.5915502808394275]
	TIME [epoch: 10.2 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4326619880833378		[learning rate: 0.0093526]
	Learning Rate: 0.00935262
	LOSS [training: 1.4326619880833378 | validation: 0.3781178345815826]
	TIME [epoch: 10.2 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46866633462086116		[learning rate: 0.009324]
	Learning Rate: 0.00932395
	LOSS [training: 0.46866633462086116 | validation: 0.5827200888967591]
	TIME [epoch: 10.2 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9210258095768789		[learning rate: 0.0092954]
	Learning Rate: 0.00929537
	LOSS [training: 0.9210258095768789 | validation: 1.530369385358477]
	TIME [epoch: 10.2 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3762516693374427		[learning rate: 0.0092669]
	Learning Rate: 0.00926687
	LOSS [training: 1.3762516693374427 | validation: 0.44005346445403226]
	TIME [epoch: 10.2 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48165124384720787		[learning rate: 0.0092385]
	Learning Rate: 0.00923847
	LOSS [training: 0.48165124384720787 | validation: 0.32552395449146376]
	TIME [epoch: 10.2 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3698541303994666		[learning rate: 0.0092101]
	Learning Rate: 0.00921015
	LOSS [training: 0.3698541303994666 | validation: 0.3599087338702164]
	TIME [epoch: 10.2 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3977275488571974		[learning rate: 0.0091819]
	Learning Rate: 0.00918192
	LOSS [training: 0.3977275488571974 | validation: 0.46703979790275607]
	TIME [epoch: 10.2 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47981107337107687		[learning rate: 0.0091538]
	Learning Rate: 0.00915377
	LOSS [training: 0.47981107337107687 | validation: 0.606048379489285]
	TIME [epoch: 10.2 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5519960937083029		[learning rate: 0.0091257]
	Learning Rate: 0.00912571
	LOSS [training: 0.5519960937083029 | validation: 0.447146403944755]
	TIME [epoch: 10.2 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4151329980888834		[learning rate: 0.0090977]
	Learning Rate: 0.00909774
	LOSS [training: 0.4151329980888834 | validation: 0.28392410775806276]
	TIME [epoch: 10.2 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29761838036457405		[learning rate: 0.0090698]
	Learning Rate: 0.00906985
	LOSS [training: 0.29761838036457405 | validation: 0.3487272231311501]
	TIME [epoch: 10.2 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44534886074828933		[learning rate: 0.009042]
	Learning Rate: 0.00904205
	LOSS [training: 0.44534886074828933 | validation: 0.31146486177519356]
	TIME [epoch: 10.2 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4194346440738381		[learning rate: 0.0090143]
	Learning Rate: 0.00901433
	LOSS [training: 0.4194346440738381 | validation: 0.5702049907714785]
	TIME [epoch: 10.2 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49350956156473613		[learning rate: 0.0089867]
	Learning Rate: 0.00898669
	LOSS [training: 0.49350956156473613 | validation: 0.3695960475983162]
	TIME [epoch: 10.2 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4101562815095826		[learning rate: 0.0089591]
	Learning Rate: 0.00895915
	LOSS [training: 0.4101562815095826 | validation: 0.43322200527295435]
	TIME [epoch: 10.2 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3671399092691397		[learning rate: 0.0089317]
	Learning Rate: 0.00893168
	LOSS [training: 0.3671399092691397 | validation: 0.3009213384659906]
	TIME [epoch: 10.2 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35776174377156783		[learning rate: 0.0089043]
	Learning Rate: 0.0089043
	LOSS [training: 0.35776174377156783 | validation: 0.5210687935252869]
	TIME [epoch: 10.2 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5787740553052834		[learning rate: 0.008877]
	Learning Rate: 0.00887701
	LOSS [training: 0.5787740553052834 | validation: 0.2592924188928051]
	TIME [epoch: 10.2 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25986666533495173		[learning rate: 0.0088498]
	Learning Rate: 0.0088498
	LOSS [training: 0.25986666533495173 | validation: 0.23876838929461563]
	TIME [epoch: 10.2 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3208403140326439		[learning rate: 0.0088227]
	Learning Rate: 0.00882267
	LOSS [training: 0.3208403140326439 | validation: 0.3347095240470463]
	TIME [epoch: 10.2 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4196650999391983		[learning rate: 0.0087956]
	Learning Rate: 0.00879562
	LOSS [training: 0.4196650999391983 | validation: 0.2422126866015367]
	TIME [epoch: 10.2 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28815357499003014		[learning rate: 0.0087687]
	Learning Rate: 0.00876866
	LOSS [training: 0.28815357499003014 | validation: 0.23672617425843526]
	TIME [epoch: 10.2 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36759294123483954		[learning rate: 0.0087418]
	Learning Rate: 0.00874178
	LOSS [training: 0.36759294123483954 | validation: 0.47731863811697617]
	TIME [epoch: 10.2 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3575005881165004		[learning rate: 0.008715]
	Learning Rate: 0.00871499
	LOSS [training: 0.3575005881165004 | validation: 0.36398297962921616]
	TIME [epoch: 10.2 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0160116043953553		[learning rate: 0.0086883]
	Learning Rate: 0.00868827
	LOSS [training: 1.0160116043953553 | validation: 0.8367104567505362]
	TIME [epoch: 10.2 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5541047433475179		[learning rate: 0.0086616]
	Learning Rate: 0.00866164
	LOSS [training: 0.5541047433475179 | validation: 0.3179384397568343]
	TIME [epoch: 10.2 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3487850589534692		[learning rate: 0.0086351]
	Learning Rate: 0.00863509
	LOSS [training: 0.3487850589534692 | validation: 0.3773156471932686]
	TIME [epoch: 10.2 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4027443143394954		[learning rate: 0.0086086]
	Learning Rate: 0.00860862
	LOSS [training: 0.4027443143394954 | validation: 0.3764774277772952]
	TIME [epoch: 10.2 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38385731605270135		[learning rate: 0.0085822]
	Learning Rate: 0.00858223
	LOSS [training: 0.38385731605270135 | validation: 0.2945417135476155]
	TIME [epoch: 10.2 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39519562594846996		[learning rate: 0.0085559]
	Learning Rate: 0.00855592
	LOSS [training: 0.39519562594846996 | validation: 0.3004049893659781]
	TIME [epoch: 10.2 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31087030757604134		[learning rate: 0.0085297]
	Learning Rate: 0.00852969
	LOSS [training: 0.31087030757604134 | validation: 0.30676661239255326]
	TIME [epoch: 10.2 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177821740090707		[learning rate: 0.0085035]
	Learning Rate: 0.00850354
	LOSS [training: 0.4177821740090707 | validation: 0.4201800500427983]
	TIME [epoch: 10.2 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3950866568801877		[learning rate: 0.0084775]
	Learning Rate: 0.00847748
	LOSS [training: 0.3950866568801877 | validation: 0.28825170800746647]
	TIME [epoch: 10.2 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3527071987368099		[learning rate: 0.0084515]
	Learning Rate: 0.00845149
	LOSS [training: 0.3527071987368099 | validation: 0.37780055327356354]
	TIME [epoch: 10.2 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43533823392484583		[learning rate: 0.0084256]
	Learning Rate: 0.00842558
	LOSS [training: 0.43533823392484583 | validation: 0.9063423276826528]
	TIME [epoch: 10.2 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.009915354006552		[learning rate: 0.0083998]
	Learning Rate: 0.00839976
	LOSS [training: 1.009915354006552 | validation: 1.074479306879744]
	TIME [epoch: 10.2 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7644015514081314		[learning rate: 0.008374]
	Learning Rate: 0.00837401
	LOSS [training: 0.7644015514081314 | validation: 0.3990230602289059]
	TIME [epoch: 10.2 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30365744223489		[learning rate: 0.0083483]
	Learning Rate: 0.00834834
	LOSS [training: 0.30365744223489 | validation: 0.3430809732481168]
	TIME [epoch: 10.2 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.523469295104211		[learning rate: 0.0083227]
	Learning Rate: 0.00832275
	LOSS [training: 0.523469295104211 | validation: 0.4179970662422069]
	TIME [epoch: 10.2 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.285106260242842		[learning rate: 0.0082972]
	Learning Rate: 0.00829723
	LOSS [training: 0.285106260242842 | validation: 0.27389284792741103]
	TIME [epoch: 10.2 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24186440783455226		[learning rate: 0.0082718]
	Learning Rate: 0.0082718
	LOSS [training: 0.24186440783455226 | validation: 0.30300898552972944]
	TIME [epoch: 10.2 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27094510273332395		[learning rate: 0.0082464]
	Learning Rate: 0.00824644
	LOSS [training: 0.27094510273332395 | validation: 0.3023595964159592]
	TIME [epoch: 10.2 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2989235369919987		[learning rate: 0.0082212]
	Learning Rate: 0.00822116
	LOSS [training: 0.2989235369919987 | validation: 0.38272050032840044]
	TIME [epoch: 10.2 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40951916852306497		[learning rate: 0.008196]
	Learning Rate: 0.00819596
	LOSS [training: 0.40951916852306497 | validation: 0.372209840752926]
	TIME [epoch: 10.2 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077774139783228		[learning rate: 0.0081708]
	Learning Rate: 0.00817084
	LOSS [training: 0.3077774139783228 | validation: 0.26113017993468574]
	TIME [epoch: 10.2 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22680744671239808		[learning rate: 0.0081458]
	Learning Rate: 0.00814579
	LOSS [training: 0.22680744671239808 | validation: 0.3489262413027946]
	TIME [epoch: 10.2 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3094498266156497		[learning rate: 0.0081208]
	Learning Rate: 0.00812082
	LOSS [training: 0.3094498266156497 | validation: 0.40538496354716175]
	TIME [epoch: 10.2 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38135090125608984		[learning rate: 0.0080959]
	Learning Rate: 0.00809593
	LOSS [training: 0.38135090125608984 | validation: 0.3200081695836716]
	TIME [epoch: 10.2 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5529553544011783		[learning rate: 0.0080711]
	Learning Rate: 0.00807111
	LOSS [training: 0.5529553544011783 | validation: 0.7314012216108745]
	TIME [epoch: 10.2 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.558841793867739		[learning rate: 0.0080464]
	Learning Rate: 0.00804637
	LOSS [training: 0.558841793867739 | validation: 0.3693476981964298]
	TIME [epoch: 10.2 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37580993152218617		[learning rate: 0.0080217]
	Learning Rate: 0.0080217
	LOSS [training: 0.37580993152218617 | validation: 0.36083563525041273]
	TIME [epoch: 10.2 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2633523424141815		[learning rate: 0.0079971]
	Learning Rate: 0.00799711
	LOSS [training: 0.2633523424141815 | validation: 0.3084169335134397]
	TIME [epoch: 10.2 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2742443890403375		[learning rate: 0.0079726]
	Learning Rate: 0.0079726
	LOSS [training: 0.2742443890403375 | validation: 0.23895616250022073]
	TIME [epoch: 10.2 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18382321328537427		[learning rate: 0.0079482]
	Learning Rate: 0.00794816
	LOSS [training: 0.18382321328537427 | validation: 0.25695537472247976]
	TIME [epoch: 10.2 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44146036642206654		[learning rate: 0.0079238]
	Learning Rate: 0.0079238
	LOSS [training: 0.44146036642206654 | validation: 0.6506916411213131]
	TIME [epoch: 10.2 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5201394731573366		[learning rate: 0.0078995]
	Learning Rate: 0.00789951
	LOSS [training: 0.5201394731573366 | validation: 0.2731760210235824]
	TIME [epoch: 10.2 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3049365682037911		[learning rate: 0.0078753]
	Learning Rate: 0.00787529
	LOSS [training: 0.3049365682037911 | validation: 0.22108695955761845]
	TIME [epoch: 10.2 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9781295208442167		[learning rate: 0.0078512]
	Learning Rate: 0.00785115
	LOSS [training: 0.9781295208442167 | validation: 2.135465885756894]
	TIME [epoch: 10.2 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1046243572407872		[learning rate: 0.0078271]
	Learning Rate: 0.00782708
	LOSS [training: 1.1046243572407872 | validation: 0.19559621787685133]
	TIME [epoch: 10.2 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1747005547700417		[learning rate: 0.0078031]
	Learning Rate: 0.00780309
	LOSS [training: 0.1747005547700417 | validation: 0.2631330170261853]
	TIME [epoch: 10.2 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2940481336180511		[learning rate: 0.0077792]
	Learning Rate: 0.00777917
	LOSS [training: 0.2940481336180511 | validation: 0.18397169195973848]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_582.pth
	Model improved!!!
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6848304247924777		[learning rate: 0.0077553]
	Learning Rate: 0.00775532
	LOSS [training: 0.6848304247924777 | validation: 2.0138174046728103]
	TIME [epoch: 10.2 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4239313083674063		[learning rate: 0.0077316]
	Learning Rate: 0.00773155
	LOSS [training: 1.4239313083674063 | validation: 0.5691939076986292]
	TIME [epoch: 10.2 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4679249793681722		[learning rate: 0.0077079]
	Learning Rate: 0.00770785
	LOSS [training: 0.4679249793681722 | validation: 0.48069665056484256]
	TIME [epoch: 10.2 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3647028895953988		[learning rate: 0.0076842]
	Learning Rate: 0.00768422
	LOSS [training: 0.3647028895953988 | validation: 0.2960014876372038]
	TIME [epoch: 10.2 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29614479230651747		[learning rate: 0.0076607]
	Learning Rate: 0.00766067
	LOSS [training: 0.29614479230651747 | validation: 0.2131095165508422]
	TIME [epoch: 10.2 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23658373224016577		[learning rate: 0.0076372]
	Learning Rate: 0.00763718
	LOSS [training: 0.23658373224016577 | validation: 0.5390379850768972]
	TIME [epoch: 10.2 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6498281168482647		[learning rate: 0.0076138]
	Learning Rate: 0.00761377
	LOSS [training: 0.6498281168482647 | validation: 0.31410007057607353]
	TIME [epoch: 10.2 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3411292961292136		[learning rate: 0.0075904]
	Learning Rate: 0.00759043
	LOSS [training: 0.3411292961292136 | validation: 0.34478690568513004]
	TIME [epoch: 10.2 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3423985340627952		[learning rate: 0.0075672]
	Learning Rate: 0.00756717
	LOSS [training: 0.3423985340627952 | validation: 0.16417626754468298]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_591.pth
	Model improved!!!
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18955759579346992		[learning rate: 0.007544]
	Learning Rate: 0.00754397
	LOSS [training: 0.18955759579346992 | validation: 0.25171536226689367]
	TIME [epoch: 10.2 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3532473499704901		[learning rate: 0.0075208]
	Learning Rate: 0.00752085
	LOSS [training: 0.3532473499704901 | validation: 0.3817571101763076]
	TIME [epoch: 10.2 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27778563872107276		[learning rate: 0.0074978]
	Learning Rate: 0.00749779
	LOSS [training: 0.27778563872107276 | validation: 0.44367666509622006]
	TIME [epoch: 10.2 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5537682867119489		[learning rate: 0.0074748]
	Learning Rate: 0.00747481
	LOSS [training: 0.5537682867119489 | validation: 0.6274597945092439]
	TIME [epoch: 10.2 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39170793944102855		[learning rate: 0.0074519]
	Learning Rate: 0.00745189
	LOSS [training: 0.39170793944102855 | validation: 0.2577509802876526]
	TIME [epoch: 10.2 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36470659851960496		[learning rate: 0.0074291]
	Learning Rate: 0.00742905
	LOSS [training: 0.36470659851960496 | validation: 0.87964054922999]
	TIME [epoch: 10.2 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5749883893650436		[learning rate: 0.0074063]
	Learning Rate: 0.00740628
	LOSS [training: 0.5749883893650436 | validation: 0.2611433452993903]
	TIME [epoch: 10.3 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34151558124531844		[learning rate: 0.0073836]
	Learning Rate: 0.00738357
	LOSS [training: 0.34151558124531844 | validation: 0.44151669993417025]
	TIME [epoch: 10.2 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4312325005054939		[learning rate: 0.0073609]
	Learning Rate: 0.00736094
	LOSS [training: 0.4312325005054939 | validation: 0.20485011325637875]
	TIME [epoch: 10.2 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2965886450232361		[learning rate: 0.0073384]
	Learning Rate: 0.00733838
	LOSS [training: 0.2965886450232361 | validation: 0.7208872796722707]
	TIME [epoch: 10.2 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.812567226305522		[learning rate: 0.0073159]
	Learning Rate: 0.00731588
	LOSS [training: 1.812567226305522 | validation: 1.7201110130602337]
	TIME [epoch: 10.2 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1597230017471936		[learning rate: 0.0072935]
	Learning Rate: 0.00729345
	LOSS [training: 2.1597230017471936 | validation: 1.6933395568354808]
	TIME [epoch: 10.2 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0688018850251777		[learning rate: 0.0072711]
	Learning Rate: 0.0072711
	LOSS [training: 2.0688018850251777 | validation: 1.3200300699740557]
	TIME [epoch: 10.2 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9422999646924854		[learning rate: 0.0072488]
	Learning Rate: 0.00724881
	LOSS [training: 0.9422999646924854 | validation: 0.4110469196884789]
	TIME [epoch: 10.2 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36371334658718657		[learning rate: 0.0072266]
	Learning Rate: 0.00722659
	LOSS [training: 0.36371334658718657 | validation: 0.525469220919246]
	TIME [epoch: 10.2 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6426931003898961		[learning rate: 0.0072044]
	Learning Rate: 0.00720444
	LOSS [training: 0.6426931003898961 | validation: 0.3212859743858405]
	TIME [epoch: 10.2 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23444121005430887		[learning rate: 0.0071824]
	Learning Rate: 0.00718235
	LOSS [training: 0.23444121005430887 | validation: 0.3027593872564034]
	TIME [epoch: 10.2 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2804151882029512		[learning rate: 0.0071603]
	Learning Rate: 0.00716033
	LOSS [training: 0.2804151882029512 | validation: 0.15677413719095867]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_609.pth
	Model improved!!!
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25266838296079364		[learning rate: 0.0071384]
	Learning Rate: 0.00713838
	LOSS [training: 0.25266838296079364 | validation: 0.2062445811340926]
	TIME [epoch: 10.2 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23665655951109305		[learning rate: 0.0071165]
	Learning Rate: 0.0071165
	LOSS [training: 0.23665655951109305 | validation: 0.35113896937737016]
	TIME [epoch: 10.2 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29642895912094835		[learning rate: 0.0070947]
	Learning Rate: 0.00709469
	LOSS [training: 0.29642895912094835 | validation: 0.22643363464332364]
	TIME [epoch: 10.2 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2493548841314473		[learning rate: 0.0070729]
	Learning Rate: 0.00707294
	LOSS [training: 0.2493548841314473 | validation: 0.338445688880845]
	TIME [epoch: 10.2 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22796060483047847		[learning rate: 0.0070513]
	Learning Rate: 0.00705126
	LOSS [training: 0.22796060483047847 | validation: 0.2774478960342798]
	TIME [epoch: 10.2 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19754471464078888		[learning rate: 0.0070296]
	Learning Rate: 0.00702964
	LOSS [training: 0.19754471464078888 | validation: 0.1253096753432206]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_615.pth
	Model improved!!!
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20132277797529122		[learning rate: 0.0070081]
	Learning Rate: 0.00700809
	LOSS [training: 0.20132277797529122 | validation: 0.4887259541244394]
	TIME [epoch: 10.2 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3734625768302568		[learning rate: 0.0069866]
	Learning Rate: 0.00698661
	LOSS [training: 0.3734625768302568 | validation: 0.24997568516400934]
	TIME [epoch: 10.2 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40957770242313074		[learning rate: 0.0069652]
	Learning Rate: 0.0069652
	LOSS [training: 0.40957770242313074 | validation: 0.5598301626872114]
	TIME [epoch: 10.1 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28023112443473186		[learning rate: 0.0069438]
	Learning Rate: 0.00694384
	LOSS [training: 0.28023112443473186 | validation: 0.19193715454728974]
	TIME [epoch: 10.2 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2770279995059534		[learning rate: 0.0069226]
	Learning Rate: 0.00692256
	LOSS [training: 0.2770279995059534 | validation: 0.2620272125813773]
	TIME [epoch: 10.2 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27963010110122444		[learning rate: 0.0069013]
	Learning Rate: 0.00690134
	LOSS [training: 0.27963010110122444 | validation: 0.4057724158453873]
	TIME [epoch: 10.2 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7253837908531484		[learning rate: 0.0068802]
	Learning Rate: 0.00688018
	LOSS [training: 0.7253837908531484 | validation: 0.20707001124073598]
	TIME [epoch: 10.2 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24040745764740712		[learning rate: 0.0068591]
	Learning Rate: 0.00685909
	LOSS [training: 0.24040745764740712 | validation: 0.17382091525448265]
	TIME [epoch: 10.2 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19809666093436867		[learning rate: 0.0068381]
	Learning Rate: 0.00683807
	LOSS [training: 0.19809666093436867 | validation: 0.1966458867315086]
	TIME [epoch: 10.2 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22665489683276765		[learning rate: 0.0068171]
	Learning Rate: 0.0068171
	LOSS [training: 0.22665489683276765 | validation: 0.16529503528931663]
	TIME [epoch: 10.1 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20553452877538553		[learning rate: 0.0067962]
	Learning Rate: 0.00679621
	LOSS [training: 0.20553452877538553 | validation: 0.16517966638255835]
	TIME [epoch: 10.2 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2247748224264261		[learning rate: 0.0067754]
	Learning Rate: 0.00677537
	LOSS [training: 0.2247748224264261 | validation: 0.274984978753854]
	TIME [epoch: 10.2 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24411919708894544		[learning rate: 0.0067546]
	Learning Rate: 0.00675461
	LOSS [training: 0.24411919708894544 | validation: 0.16550790872877347]
	TIME [epoch: 10.2 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2066423192016142		[learning rate: 0.0067339]
	Learning Rate: 0.0067339
	LOSS [training: 0.2066423192016142 | validation: 0.17297448991775596]
	TIME [epoch: 10.2 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17591500594620216		[learning rate: 0.0067133]
	Learning Rate: 0.00671326
	LOSS [training: 0.17591500594620216 | validation: 0.1710734338355472]
	TIME [epoch: 10.2 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23633590826598633		[learning rate: 0.0066927]
	Learning Rate: 0.00669268
	LOSS [training: 0.23633590826598633 | validation: 0.40616207416402844]
	TIME [epoch: 10.2 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26130060224647655		[learning rate: 0.0066722]
	Learning Rate: 0.00667216
	LOSS [training: 0.26130060224647655 | validation: 0.26129997517804937]
	TIME [epoch: 10.2 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8346449646054396		[learning rate: 0.0066517]
	Learning Rate: 0.00665171
	LOSS [training: 0.8346449646054396 | validation: 0.3008112671557088]
	TIME [epoch: 10.2 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3646138287665652		[learning rate: 0.0066313]
	Learning Rate: 0.00663132
	LOSS [training: 0.3646138287665652 | validation: 0.9586362217215509]
	TIME [epoch: 10.2 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1618677051172064		[learning rate: 0.006611]
	Learning Rate: 0.00661099
	LOSS [training: 1.1618677051172064 | validation: 0.38444358890171726]
	TIME [epoch: 10.2 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24857971997457035		[learning rate: 0.0065907]
	Learning Rate: 0.00659073
	LOSS [training: 0.24857971997457035 | validation: 0.15064622316847515]
	TIME [epoch: 10.2 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18545691835814568		[learning rate: 0.0065705]
	Learning Rate: 0.00657052
	LOSS [training: 0.18545691835814568 | validation: 0.1749553442753667]
	TIME [epoch: 10.2 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22032252275728603		[learning rate: 0.0065504]
	Learning Rate: 0.00655038
	LOSS [training: 0.22032252275728603 | validation: 0.3411573800126581]
	TIME [epoch: 10.2 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3450324780294348		[learning rate: 0.0065303]
	Learning Rate: 0.0065303
	LOSS [training: 0.3450324780294348 | validation: 0.2555871649851221]
	TIME [epoch: 10.2 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30280484944163427		[learning rate: 0.0065103]
	Learning Rate: 0.00651028
	LOSS [training: 0.30280484944163427 | validation: 0.39051977137635974]
	TIME [epoch: 10.1 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3517364133475838		[learning rate: 0.0064903]
	Learning Rate: 0.00649033
	LOSS [training: 0.3517364133475838 | validation: 0.2415578004627259]
	TIME [epoch: 10.2 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27365060496756705		[learning rate: 0.0064704]
	Learning Rate: 0.00647043
	LOSS [training: 0.27365060496756705 | validation: 0.24070646576015256]
	TIME [epoch: 10.2 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2776987293849883		[learning rate: 0.0064506]
	Learning Rate: 0.0064506
	LOSS [training: 0.2776987293849883 | validation: 0.26989253868808966]
	TIME [epoch: 10.2 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30897145781379753		[learning rate: 0.0064308]
	Learning Rate: 0.00643082
	LOSS [training: 0.30897145781379753 | validation: 0.29220996819737577]
	TIME [epoch: 10.1 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32394123578230366		[learning rate: 0.0064111]
	Learning Rate: 0.00641111
	LOSS [training: 0.32394123578230366 | validation: 0.3427315041072487]
	TIME [epoch: 10.2 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2506147076579515		[learning rate: 0.0063915]
	Learning Rate: 0.00639146
	LOSS [training: 0.2506147076579515 | validation: 0.22556869350022518]
	TIME [epoch: 10.2 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22699274214194864		[learning rate: 0.0063719]
	Learning Rate: 0.00637187
	LOSS [training: 0.22699274214194864 | validation: 0.19035317731239926]
	TIME [epoch: 10.1 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2236965273405108		[learning rate: 0.0063523]
	Learning Rate: 0.00635233
	LOSS [training: 0.2236965273405108 | validation: 0.3822959158303085]
	TIME [epoch: 10.2 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26816346909566874		[learning rate: 0.0063329]
	Learning Rate: 0.00633286
	LOSS [training: 0.26816346909566874 | validation: 0.2650002844993882]
	TIME [epoch: 10.2 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2167427944959473		[learning rate: 0.0063134]
	Learning Rate: 0.00631345
	LOSS [training: 0.2167427944959473 | validation: 0.2584725206144721]
	TIME [epoch: 10.1 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2623914952800054		[learning rate: 0.0062941]
	Learning Rate: 0.0062941
	LOSS [training: 0.2623914952800054 | validation: 0.31392861264992006]
	TIME [epoch: 10.2 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30141885902947185		[learning rate: 0.0062748]
	Learning Rate: 0.0062748
	LOSS [training: 0.30141885902947185 | validation: 0.32141018284921713]
	TIME [epoch: 10.1 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26689359448607874		[learning rate: 0.0062556]
	Learning Rate: 0.00625557
	LOSS [training: 0.26689359448607874 | validation: 0.37374205084647116]
	TIME [epoch: 10.2 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41089244012659387		[learning rate: 0.0062364]
	Learning Rate: 0.00623639
	LOSS [training: 0.41089244012659387 | validation: 0.3363667473982563]
	TIME [epoch: 10.1 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25019065395186874		[learning rate: 0.0062173]
	Learning Rate: 0.00621727
	LOSS [training: 0.25019065395186874 | validation: 0.2659714962422197]
	TIME [epoch: 10.2 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26902613977586		[learning rate: 0.0061982]
	Learning Rate: 0.00619822
	LOSS [training: 0.26902613977586 | validation: 0.28545304269713484]
	TIME [epoch: 10.2 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2649455311690604		[learning rate: 0.0061792]
	Learning Rate: 0.00617922
	LOSS [training: 0.2649455311690604 | validation: 0.6169363732871121]
	TIME [epoch: 10.2 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38551534388758973		[learning rate: 0.0061603]
	Learning Rate: 0.00616027
	LOSS [training: 0.38551534388758973 | validation: 0.3188726683465988]
	TIME [epoch: 10.2 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25903821184207726		[learning rate: 0.0061414]
	Learning Rate: 0.00614139
	LOSS [training: 0.25903821184207726 | validation: 0.26230098940001656]
	TIME [epoch: 10.2 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2778020383254421		[learning rate: 0.0061226]
	Learning Rate: 0.00612256
	LOSS [training: 0.2778020383254421 | validation: 0.3506370838632472]
	TIME [epoch: 10.2 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29928997621930226		[learning rate: 0.0061038]
	Learning Rate: 0.0061038
	LOSS [training: 0.29928997621930226 | validation: 0.29978406697925736]
	TIME [epoch: 10.2 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2526874544429455		[learning rate: 0.0060851]
	Learning Rate: 0.00608508
	LOSS [training: 0.2526874544429455 | validation: 0.2967174028130475]
	TIME [epoch: 10.2 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2866027753377729		[learning rate: 0.0060664]
	Learning Rate: 0.00606643
	LOSS [training: 0.2866027753377729 | validation: 0.28855678846725386]
	TIME [epoch: 10.2 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3360378455742187		[learning rate: 0.0060478]
	Learning Rate: 0.00604784
	LOSS [training: 0.3360378455742187 | validation: 0.3042774224484062]
	TIME [epoch: 10.1 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2774971901599181		[learning rate: 0.0060293]
	Learning Rate: 0.0060293
	LOSS [training: 0.2774971901599181 | validation: 0.22568286921577746]
	TIME [epoch: 10.2 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21053765698849597		[learning rate: 0.0060108]
	Learning Rate: 0.00601081
	LOSS [training: 0.21053765698849597 | validation: 0.25714384280493613]
	TIME [epoch: 10.2 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41575438136587534		[learning rate: 0.0059924]
	Learning Rate: 0.00599239
	LOSS [training: 0.41575438136587534 | validation: 0.290060086025976]
	TIME [epoch: 10.2 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21965570093220954		[learning rate: 0.005974]
	Learning Rate: 0.00597402
	LOSS [training: 0.21965570093220954 | validation: 0.22240701837695823]
	TIME [epoch: 10.2 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2700857760675216		[learning rate: 0.0059557]
	Learning Rate: 0.00595571
	LOSS [training: 0.2700857760675216 | validation: 0.17890593469964203]
	TIME [epoch: 10.2 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20996125280332353		[learning rate: 0.0059375]
	Learning Rate: 0.00593745
	LOSS [training: 0.20996125280332353 | validation: 0.38337483767811964]
	TIME [epoch: 10.2 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28914014708842184		[learning rate: 0.0059192]
	Learning Rate: 0.00591925
	LOSS [training: 0.28914014708842184 | validation: 0.21718092954486876]
	TIME [epoch: 10.2 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22908801591538172		[learning rate: 0.0059011]
	Learning Rate: 0.0059011
	LOSS [training: 0.22908801591538172 | validation: 0.23099131797871686]
	TIME [epoch: 10.2 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4362126329736974		[learning rate: 0.005883]
	Learning Rate: 0.00588302
	LOSS [training: 0.4362126329736974 | validation: 0.4574724417884575]
	TIME [epoch: 10.2 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44035942560561303		[learning rate: 0.005865]
	Learning Rate: 0.00586498
	LOSS [training: 0.44035942560561303 | validation: 0.23703144548156124]
	TIME [epoch: 10.2 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4767345586060213		[learning rate: 0.005847]
	Learning Rate: 0.005847
	LOSS [training: 0.4767345586060213 | validation: 0.3997663537461742]
	TIME [epoch: 10.2 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29132253349635473		[learning rate: 0.0058291]
	Learning Rate: 0.00582908
	LOSS [training: 0.29132253349635473 | validation: 0.4221309961598395]
	TIME [epoch: 10.2 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45445539385961464		[learning rate: 0.0058112]
	Learning Rate: 0.00581121
	LOSS [training: 0.45445539385961464 | validation: 0.17778041532614183]
	TIME [epoch: 10.2 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2517148205184473		[learning rate: 0.0057934]
	Learning Rate: 0.0057934
	LOSS [training: 0.2517148205184473 | validation: 0.2182613033325199]
	TIME [epoch: 10.2 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24118257070286053		[learning rate: 0.0057756]
	Learning Rate: 0.00577564
	LOSS [training: 0.24118257070286053 | validation: 0.2282795627331965]
	TIME [epoch: 10.2 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22619398643993102		[learning rate: 0.0057579]
	Learning Rate: 0.00575793
	LOSS [training: 0.22619398643993102 | validation: 0.22526386836787396]
	TIME [epoch: 10.2 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1921945890071591		[learning rate: 0.0057403]
	Learning Rate: 0.00574028
	LOSS [training: 0.1921945890071591 | validation: 0.14028088667535296]
	TIME [epoch: 10.2 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22662696693474443		[learning rate: 0.0057227]
	Learning Rate: 0.00572269
	LOSS [training: 0.22662696693474443 | validation: 0.22673789051496315]
	TIME [epoch: 10.2 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2383455981870899		[learning rate: 0.0057051]
	Learning Rate: 0.00570514
	LOSS [training: 0.2383455981870899 | validation: 0.1730421655531616]
	TIME [epoch: 10.2 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31076568565609797		[learning rate: 0.0056877]
	Learning Rate: 0.00568766
	LOSS [training: 0.31076568565609797 | validation: 0.23039797482681387]
	TIME [epoch: 10.2 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2198655459847454		[learning rate: 0.0056702]
	Learning Rate: 0.00567022
	LOSS [training: 0.2198655459847454 | validation: 0.19927735857256998]
	TIME [epoch: 10.2 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2141403906979198		[learning rate: 0.0056528]
	Learning Rate: 0.00565284
	LOSS [training: 0.2141403906979198 | validation: 0.27232493185576667]
	TIME [epoch: 10.3 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1847266547561798		[learning rate: 0.0056355]
	Learning Rate: 0.00563551
	LOSS [training: 0.1847266547561798 | validation: 0.16913128279559864]
	TIME [epoch: 10.2 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18140490655579394		[learning rate: 0.0056182]
	Learning Rate: 0.00561824
	LOSS [training: 0.18140490655579394 | validation: 0.16183415428970477]
	TIME [epoch: 10.2 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1893116721794351		[learning rate: 0.005601]
	Learning Rate: 0.00560101
	LOSS [training: 0.1893116721794351 | validation: 0.5472019754805045]
	TIME [epoch: 10.2 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6096552771868792		[learning rate: 0.0055838]
	Learning Rate: 0.00558384
	LOSS [training: 0.6096552771868792 | validation: 0.2931965594076504]
	TIME [epoch: 10.2 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29374127676954315		[learning rate: 0.0055667]
	Learning Rate: 0.00556673
	LOSS [training: 0.29374127676954315 | validation: 0.24036578595074137]
	TIME [epoch: 10.2 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2535499191633354		[learning rate: 0.0055497]
	Learning Rate: 0.00554966
	LOSS [training: 0.2535499191633354 | validation: 0.22741297212626221]
	TIME [epoch: 10.2 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3701523575649646		[learning rate: 0.0055327]
	Learning Rate: 0.00553265
	LOSS [training: 0.3701523575649646 | validation: 0.4488843372573888]
	TIME [epoch: 10.2 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30675609636225465		[learning rate: 0.0055157]
	Learning Rate: 0.00551569
	LOSS [training: 0.30675609636225465 | validation: 0.30865870426219255]
	TIME [epoch: 10.2 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4916848111908231		[learning rate: 0.0054988]
	Learning Rate: 0.00549878
	LOSS [training: 0.4916848111908231 | validation: 0.2583811519885967]
	TIME [epoch: 10.2 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21825338449418616		[learning rate: 0.0054819]
	Learning Rate: 0.00548193
	LOSS [training: 0.21825338449418616 | validation: 0.2902446224028339]
	TIME [epoch: 10.2 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27937572982350173		[learning rate: 0.0054651]
	Learning Rate: 0.00546512
	LOSS [training: 0.27937572982350173 | validation: 0.2597980364390304]
	TIME [epoch: 10.2 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3077944738845856		[learning rate: 0.0054484]
	Learning Rate: 0.00544837
	LOSS [training: 0.3077944738845856 | validation: 0.31855382304708063]
	TIME [epoch: 10.2 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23776956255464485		[learning rate: 0.0054317]
	Learning Rate: 0.00543167
	LOSS [training: 0.23776956255464485 | validation: 0.24098849616502627]
	TIME [epoch: 10.1 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39157914969389274		[learning rate: 0.005415]
	Learning Rate: 0.00541502
	LOSS [training: 0.39157914969389274 | validation: 0.48037928656900064]
	TIME [epoch: 10.2 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.088724615395657		[learning rate: 0.0053984]
	Learning Rate: 0.00539842
	LOSS [training: 1.088724615395657 | validation: 0.3869049785681487]
	TIME [epoch: 10.2 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38850055948620293		[learning rate: 0.0053819]
	Learning Rate: 0.00538187
	LOSS [training: 0.38850055948620293 | validation: 0.22270346301776672]
	TIME [epoch: 10.2 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2314607419962868		[learning rate: 0.0053654]
	Learning Rate: 0.00536537
	LOSS [training: 0.2314607419962868 | validation: 0.27855072377323603]
	TIME [epoch: 10.2 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2701918620763573		[learning rate: 0.0053489]
	Learning Rate: 0.00534893
	LOSS [training: 0.2701918620763573 | validation: 0.33186224304677864]
	TIME [epoch: 10.2 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24985940024207456		[learning rate: 0.0053325]
	Learning Rate: 0.00533253
	LOSS [training: 0.24985940024207456 | validation: 0.2481211427027926]
	TIME [epoch: 10.2 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25048269622040553		[learning rate: 0.0053162]
	Learning Rate: 0.00531618
	LOSS [training: 0.25048269622040553 | validation: 0.2867306203726858]
	TIME [epoch: 10.2 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22487525075132128		[learning rate: 0.0052999]
	Learning Rate: 0.00529989
	LOSS [training: 0.22487525075132128 | validation: 0.15779125771683955]
	TIME [epoch: 10.2 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1504631761314029		[learning rate: 0.0052836]
	Learning Rate: 0.00528364
	LOSS [training: 0.1504631761314029 | validation: 0.11011934895616193]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_708.pth
	Model improved!!!
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1737915233440599		[learning rate: 0.0052674]
	Learning Rate: 0.00526744
	LOSS [training: 0.1737915233440599 | validation: 0.18131005160736333]
	TIME [epoch: 10.2 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4091055785624416		[learning rate: 0.0052513]
	Learning Rate: 0.0052513
	LOSS [training: 0.4091055785624416 | validation: 0.3859159013940102]
	TIME [epoch: 10.2 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31216784795777563		[learning rate: 0.0052352]
	Learning Rate: 0.0052352
	LOSS [training: 0.31216784795777563 | validation: 0.1403730644054735]
	TIME [epoch: 10.2 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29453520399864436		[learning rate: 0.0052192]
	Learning Rate: 0.00521915
	LOSS [training: 0.29453520399864436 | validation: 0.37187482234823604]
	TIME [epoch: 10.2 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2964380563751522		[learning rate: 0.0052032]
	Learning Rate: 0.00520315
	LOSS [training: 0.2964380563751522 | validation: 0.19911303198171332]
	TIME [epoch: 10.2 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19148805624155546		[learning rate: 0.0051872]
	Learning Rate: 0.0051872
	LOSS [training: 0.19148805624155546 | validation: 0.2929621149874591]
	TIME [epoch: 10.2 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22479949212696893		[learning rate: 0.0051713]
	Learning Rate: 0.0051713
	LOSS [training: 0.22479949212696893 | validation: 0.287605754198854]
	TIME [epoch: 10.3 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4980118914707948		[learning rate: 0.0051555]
	Learning Rate: 0.00515545
	LOSS [training: 0.4980118914707948 | validation: 0.33849233152414643]
	TIME [epoch: 10.2 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3445196307191338		[learning rate: 0.0051396]
	Learning Rate: 0.00513965
	LOSS [training: 0.3445196307191338 | validation: 0.3524672390479281]
	TIME [epoch: 10.2 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20689129843934326		[learning rate: 0.0051239]
	Learning Rate: 0.00512389
	LOSS [training: 0.20689129843934326 | validation: 0.14646357740958027]
	TIME [epoch: 10.2 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342294652047355		[learning rate: 0.0051082]
	Learning Rate: 0.00510819
	LOSS [training: 0.1342294652047355 | validation: 0.248102418624169]
	TIME [epoch: 10.2 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26781751295644735		[learning rate: 0.0050925]
	Learning Rate: 0.00509253
	LOSS [training: 0.26781751295644735 | validation: 0.28667812567727735]
	TIME [epoch: 10.2 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24597464562306953		[learning rate: 0.0050769]
	Learning Rate: 0.00507692
	LOSS [training: 0.24597464562306953 | validation: 0.19218463472588632]
	TIME [epoch: 10.2 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20906876851912548		[learning rate: 0.0050614]
	Learning Rate: 0.00506135
	LOSS [training: 0.20906876851912548 | validation: 0.18470190752592922]
	TIME [epoch: 10.2 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17488603205525804		[learning rate: 0.0050458]
	Learning Rate: 0.00504584
	LOSS [training: 0.17488603205525804 | validation: 0.17580713245885116]
	TIME [epoch: 10.2 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11623472242017574		[learning rate: 0.0050304]
	Learning Rate: 0.00503037
	LOSS [training: 0.11623472242017574 | validation: 0.13343425934025313]
	TIME [epoch: 10.2 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11370227192345879		[learning rate: 0.005015]
	Learning Rate: 0.00501495
	LOSS [training: 0.11370227192345879 | validation: 0.10277561780809738]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_725.pth
	Model improved!!!
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16565792572460603		[learning rate: 0.0049996]
	Learning Rate: 0.00499958
	LOSS [training: 0.16565792572460603 | validation: 0.21118949783219715]
	TIME [epoch: 10.2 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1431062568024823		[learning rate: 0.0049843]
	Learning Rate: 0.00498425
	LOSS [training: 0.1431062568024823 | validation: 0.11735892503506243]
	TIME [epoch: 10.2 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11236018031944559		[learning rate: 0.004969]
	Learning Rate: 0.00496897
	LOSS [training: 0.11236018031944559 | validation: 0.16502049478587646]
	TIME [epoch: 10.2 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16918505993227057		[learning rate: 0.0049537]
	Learning Rate: 0.00495374
	LOSS [training: 0.16918505993227057 | validation: 0.13678205966029844]
	TIME [epoch: 10.2 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16982866081328632		[learning rate: 0.0049386]
	Learning Rate: 0.00493856
	LOSS [training: 0.16982866081328632 | validation: 0.12339298735783548]
	TIME [epoch: 10.2 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19816436900358006		[learning rate: 0.0049234]
	Learning Rate: 0.00492342
	LOSS [training: 0.19816436900358006 | validation: 0.15644673215468086]
	TIME [epoch: 10.2 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1455430811186982		[learning rate: 0.0049083]
	Learning Rate: 0.00490832
	LOSS [training: 0.1455430811186982 | validation: 0.13965236419224233]
	TIME [epoch: 10.2 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1488413692329311		[learning rate: 0.0048933]
	Learning Rate: 0.00489328
	LOSS [training: 0.1488413692329311 | validation: 0.114558621763385]
	TIME [epoch: 10.2 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13116444154644008		[learning rate: 0.0048783]
	Learning Rate: 0.00487828
	LOSS [training: 0.13116444154644008 | validation: 0.06948678727420408]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_734.pth
	Model improved!!!
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14206078217938473		[learning rate: 0.0048633]
	Learning Rate: 0.00486333
	LOSS [training: 0.14206078217938473 | validation: 0.12151981727115985]
	TIME [epoch: 10.2 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13862932598223315		[learning rate: 0.0048484]
	Learning Rate: 0.00484842
	LOSS [training: 0.13862932598223315 | validation: 0.12316004681604845]
	TIME [epoch: 10.2 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16894045488925677		[learning rate: 0.0048336]
	Learning Rate: 0.00483355
	LOSS [training: 0.16894045488925677 | validation: 0.12685535160456238]
	TIME [epoch: 10.2 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17118428495148197		[learning rate: 0.0048187]
	Learning Rate: 0.00481874
	LOSS [training: 0.17118428495148197 | validation: 0.08438307597936459]
	TIME [epoch: 10.2 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12200293076508331		[learning rate: 0.004804]
	Learning Rate: 0.00480397
	LOSS [training: 0.12200293076508331 | validation: 0.21285093781248518]
	TIME [epoch: 10.2 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2100235484094078		[learning rate: 0.0047892]
	Learning Rate: 0.00478924
	LOSS [training: 0.2100235484094078 | validation: 0.15655486277869674]
	TIME [epoch: 10.2 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29981435689692704		[learning rate: 0.0047746]
	Learning Rate: 0.00477456
	LOSS [training: 0.29981435689692704 | validation: 0.7833073916651941]
	TIME [epoch: 10.2 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0084179926628432		[learning rate: 0.0047599]
	Learning Rate: 0.00475992
	LOSS [training: 1.0084179926628432 | validation: 1.0120647006632786]
	TIME [epoch: 10.2 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8715373832445676		[learning rate: 0.0047453]
	Learning Rate: 0.00474533
	LOSS [training: 0.8715373832445676 | validation: 0.8686050752975326]
	TIME [epoch: 10.2 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5074933013550718		[learning rate: 0.0047308]
	Learning Rate: 0.00473079
	LOSS [training: 0.5074933013550718 | validation: 0.1699485540069794]
	TIME [epoch: 10.2 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3607041043672125		[learning rate: 0.0047163]
	Learning Rate: 0.00471628
	LOSS [training: 0.3607041043672125 | validation: 0.41965570490362264]
	TIME [epoch: 10.2 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32342509083464965		[learning rate: 0.0047018]
	Learning Rate: 0.00470183
	LOSS [training: 0.32342509083464965 | validation: 0.2577589417807091]
	TIME [epoch: 10.2 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21405945497706833		[learning rate: 0.0046874]
	Learning Rate: 0.00468741
	LOSS [training: 0.21405945497706833 | validation: 0.1256846348473821]
	TIME [epoch: 10.2 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1583322006325169		[learning rate: 0.004673]
	Learning Rate: 0.00467305
	LOSS [training: 0.1583322006325169 | validation: 0.0725119528301361]
	TIME [epoch: 10.2 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11260046803446863		[learning rate: 0.0046587]
	Learning Rate: 0.00465872
	LOSS [training: 0.11260046803446863 | validation: 0.1520251955601056]
	TIME [epoch: 10.2 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1637729091235037		[learning rate: 0.0046444]
	Learning Rate: 0.00464444
	LOSS [training: 0.1637729091235037 | validation: 0.1872856264056754]
	TIME [epoch: 10.2 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23786098487692886		[learning rate: 0.0046302]
	Learning Rate: 0.0046302
	LOSS [training: 0.23786098487692886 | validation: 0.3151126236403025]
	TIME [epoch: 10.2 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2827995841896921		[learning rate: 0.004616]
	Learning Rate: 0.00461601
	LOSS [training: 0.2827995841896921 | validation: 0.18962024657297313]
	TIME [epoch: 10.2 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3839745784589893		[learning rate: 0.0046019]
	Learning Rate: 0.00460186
	LOSS [training: 0.3839745784589893 | validation: 0.9705932850640946]
	TIME [epoch: 10.2 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8354946115137919		[learning rate: 0.0045878]
	Learning Rate: 0.00458775
	LOSS [training: 0.8354946115137919 | validation: 0.2581445416796101]
	TIME [epoch: 10.2 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27060362423382867		[learning rate: 0.0045737]
	Learning Rate: 0.00457369
	LOSS [training: 0.27060362423382867 | validation: 0.16197702262019373]
	TIME [epoch: 10.2 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3065662638681085		[learning rate: 0.0045597]
	Learning Rate: 0.00455967
	LOSS [training: 0.3065662638681085 | validation: 0.5262685167570667]
	TIME [epoch: 10.2 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.518092128319644		[learning rate: 0.0045457]
	Learning Rate: 0.00454569
	LOSS [training: 0.518092128319644 | validation: 0.3419774799084524]
	TIME [epoch: 10.2 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36573809974926685		[learning rate: 0.0045318]
	Learning Rate: 0.00453176
	LOSS [training: 0.36573809974926685 | validation: 0.22446539456694656]
	TIME [epoch: 10.2 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20925709183698488		[learning rate: 0.0045179]
	Learning Rate: 0.00451787
	LOSS [training: 0.20925709183698488 | validation: 0.12147137610979913]
	TIME [epoch: 10.3 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18784720426691892		[learning rate: 0.004504]
	Learning Rate: 0.00450402
	LOSS [training: 0.18784720426691892 | validation: 0.11734479154765477]
	TIME [epoch: 10.2 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14761977231700782		[learning rate: 0.0044902]
	Learning Rate: 0.00449021
	LOSS [training: 0.14761977231700782 | validation: 0.18689815174462354]
	TIME [epoch: 10.2 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15935563379892068		[learning rate: 0.0044764]
	Learning Rate: 0.00447645
	LOSS [training: 0.15935563379892068 | validation: 0.08298884516787972]
	TIME [epoch: 10.2 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19436235249575762		[learning rate: 0.0044627]
	Learning Rate: 0.00446272
	LOSS [training: 0.19436235249575762 | validation: 0.2388030028987695]
	TIME [epoch: 10.2 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2077998620545618		[learning rate: 0.004449]
	Learning Rate: 0.00444904
	LOSS [training: 0.2077998620545618 | validation: 0.1574228239599033]
	TIME [epoch: 10.2 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13567777561398475		[learning rate: 0.0044354]
	Learning Rate: 0.0044354
	LOSS [training: 0.13567777561398475 | validation: 0.08063080678700354]
	TIME [epoch: 10.2 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10990575873627773		[learning rate: 0.0044218]
	Learning Rate: 0.00442181
	LOSS [training: 0.10990575873627773 | validation: 0.10111086076144453]
	TIME [epoch: 10.2 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2875974303317147		[learning rate: 0.0044083]
	Learning Rate: 0.00440825
	LOSS [training: 0.2875974303317147 | validation: 0.3901951856412146]
	TIME [epoch: 10.2 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3657783012793689		[learning rate: 0.0043947]
	Learning Rate: 0.00439474
	LOSS [training: 0.3657783012793689 | validation: 0.23720954467971012]
	TIME [epoch: 10.2 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19939279108643493		[learning rate: 0.0043813]
	Learning Rate: 0.00438127
	LOSS [training: 0.19939279108643493 | validation: 0.09743520120916589]
	TIME [epoch: 10.2 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15557213295884273		[learning rate: 0.0043678]
	Learning Rate: 0.00436784
	LOSS [training: 0.15557213295884273 | validation: 0.11554630040207586]
	TIME [epoch: 10.2 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12494463703768854		[learning rate: 0.0043544]
	Learning Rate: 0.00435445
	LOSS [training: 0.12494463703768854 | validation: 0.1101076638477639]
	TIME [epoch: 10.2 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18020787054968102		[learning rate: 0.0043411]
	Learning Rate: 0.0043411
	LOSS [training: 0.18020787054968102 | validation: 0.17852448707417623]
	TIME [epoch: 10.2 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1788657980279312		[learning rate: 0.0043278]
	Learning Rate: 0.0043278
	LOSS [training: 0.1788657980279312 | validation: 0.08272746634860784]
	TIME [epoch: 10.2 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1388551459757724		[learning rate: 0.0043145]
	Learning Rate: 0.00431453
	LOSS [training: 0.1388551459757724 | validation: 0.10109869448990352]
	TIME [epoch: 10.2 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1962358827137176		[learning rate: 0.0043013]
	Learning Rate: 0.0043013
	LOSS [training: 0.1962358827137176 | validation: 0.16975698061460817]
	TIME [epoch: 10.2 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5391318210722149		[learning rate: 0.0042881]
	Learning Rate: 0.00428812
	LOSS [training: 0.5391318210722149 | validation: 0.13466237001844458]
	TIME [epoch: 10.2 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18207985625969697		[learning rate: 0.004275]
	Learning Rate: 0.00427497
	LOSS [training: 0.18207985625969697 | validation: 0.11523413967761885]
	TIME [epoch: 10.2 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18242186226339557		[learning rate: 0.0042619]
	Learning Rate: 0.00426187
	LOSS [training: 0.18242186226339557 | validation: 0.13073038481911983]
	TIME [epoch: 10.2 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15109839009092943		[learning rate: 0.0042488]
	Learning Rate: 0.0042488
	LOSS [training: 0.15109839009092943 | validation: 0.12859230322041348]
	TIME [epoch: 10.2 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14005382837137068		[learning rate: 0.0042358]
	Learning Rate: 0.00423578
	LOSS [training: 0.14005382837137068 | validation: 0.16849845011710088]
	TIME [epoch: 10.2 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19342792031756167		[learning rate: 0.0042228]
	Learning Rate: 0.00422279
	LOSS [training: 0.19342792031756167 | validation: 0.10408554422606268]
	TIME [epoch: 10.2 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16441123431346066		[learning rate: 0.0042098]
	Learning Rate: 0.00420985
	LOSS [training: 0.16441123431346066 | validation: 0.08187793440172034]
	TIME [epoch: 10.2 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18322689416927376		[learning rate: 0.0041969]
	Learning Rate: 0.00419695
	LOSS [training: 0.18322689416927376 | validation: 0.127284993047878]
	TIME [epoch: 10.2 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15924868692256972		[learning rate: 0.0041841]
	Learning Rate: 0.00418408
	LOSS [training: 0.15924868692256972 | validation: 0.160023692897807]
	TIME [epoch: 10.2 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10939849186087117		[learning rate: 0.0041713]
	Learning Rate: 0.00417125
	LOSS [training: 0.10939849186087117 | validation: 0.10733607590085185]
	TIME [epoch: 10.2 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14947859173747535		[learning rate: 0.0041585]
	Learning Rate: 0.00415847
	LOSS [training: 0.14947859173747535 | validation: 0.11677193776691994]
	TIME [epoch: 10.3 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13567917193121679		[learning rate: 0.0041457]
	Learning Rate: 0.00414572
	LOSS [training: 0.13567917193121679 | validation: 0.1067573191529669]
	TIME [epoch: 10.3 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08873354633605149		[learning rate: 0.004133]
	Learning Rate: 0.00413301
	LOSS [training: 0.08873354633605149 | validation: 0.08478885813146594]
	TIME [epoch: 10.3 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0993771217059938		[learning rate: 0.0041203]
	Learning Rate: 0.00412034
	LOSS [training: 0.0993771217059938 | validation: 0.1260677935803344]
	TIME [epoch: 10.3 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28886089610080445		[learning rate: 0.0041077]
	Learning Rate: 0.00410771
	LOSS [training: 0.28886089610080445 | validation: 0.5438313089933707]
	TIME [epoch: 10.3 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5314939800363288		[learning rate: 0.0040951]
	Learning Rate: 0.00409512
	LOSS [training: 0.5314939800363288 | validation: 0.2685151827867951]
	TIME [epoch: 10.2 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2842646980983611		[learning rate: 0.0040826]
	Learning Rate: 0.00408257
	LOSS [training: 0.2842646980983611 | validation: 0.14516747841492564]
	TIME [epoch: 10.3 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4660346591146357		[learning rate: 0.0040701]
	Learning Rate: 0.00407005
	LOSS [training: 0.4660346591146357 | validation: 0.9872203598794406]
	TIME [epoch: 10.2 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5645797638221819		[learning rate: 0.0040576]
	Learning Rate: 0.00405758
	LOSS [training: 0.5645797638221819 | validation: 0.12412098775472753]
	TIME [epoch: 10.2 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1955542573812194		[learning rate: 0.0040451]
	Learning Rate: 0.00404514
	LOSS [training: 0.1955542573812194 | validation: 0.12392730845422752]
	TIME [epoch: 10.3 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2041922485099809		[learning rate: 0.0040327]
	Learning Rate: 0.00403274
	LOSS [training: 0.2041922485099809 | validation: 0.15691574594995097]
	TIME [epoch: 10.3 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3275217842939754		[learning rate: 0.0040204]
	Learning Rate: 0.00402038
	LOSS [training: 0.3275217842939754 | validation: 0.790756299267628]
	TIME [epoch: 10.3 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3796316629116219		[learning rate: 0.0040081]
	Learning Rate: 0.00400805
	LOSS [training: 0.3796316629116219 | validation: 0.14479054527327478]
	TIME [epoch: 10.3 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21949754312689937		[learning rate: 0.0039958]
	Learning Rate: 0.00399577
	LOSS [training: 0.21949754312689937 | validation: 0.19639859903647025]
	TIME [epoch: 10.3 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27041934678645396		[learning rate: 0.0039835]
	Learning Rate: 0.00398352
	LOSS [training: 0.27041934678645396 | validation: 0.3511948574386278]
	TIME [epoch: 10.3 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26711337884459335		[learning rate: 0.0039713]
	Learning Rate: 0.00397131
	LOSS [training: 0.26711337884459335 | validation: 0.2591519315783113]
	TIME [epoch: 10.3 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42232665505620054		[learning rate: 0.0039591]
	Learning Rate: 0.00395913
	LOSS [training: 0.42232665505620054 | validation: 0.41039100496002834]
	TIME [epoch: 10.3 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41862737873629696		[learning rate: 0.003947]
	Learning Rate: 0.003947
	LOSS [training: 0.41862737873629696 | validation: 0.2450056941086254]
	TIME [epoch: 10.3 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3050502899401625		[learning rate: 0.0039349]
	Learning Rate: 0.0039349
	LOSS [training: 0.3050502899401625 | validation: 0.30082557244877733]
	TIME [epoch: 10.3 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25980952855989603		[learning rate: 0.0039228]
	Learning Rate: 0.00392283
	LOSS [training: 0.25980952855989603 | validation: 0.12720499777586042]
	TIME [epoch: 10.3 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16989445960251529		[learning rate: 0.0039108]
	Learning Rate: 0.00391081
	LOSS [training: 0.16989445960251529 | validation: 0.12980498100093082]
	TIME [epoch: 10.2 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13626613271828814		[learning rate: 0.0038988]
	Learning Rate: 0.00389882
	LOSS [training: 0.13626613271828814 | validation: 0.10125595552188923]
	TIME [epoch: 10.3 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12001506778974602		[learning rate: 0.0038869]
	Learning Rate: 0.00388687
	LOSS [training: 0.12001506778974602 | validation: 0.17087137873084537]
	TIME [epoch: 10.3 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1541015066402733		[learning rate: 0.003875]
	Learning Rate: 0.00387495
	LOSS [training: 0.1541015066402733 | validation: 0.05971418579438205]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_809.pth
	Model improved!!!
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0914755644968854		[learning rate: 0.0038631]
	Learning Rate: 0.00386308
	LOSS [training: 0.0914755644968854 | validation: 0.05469605812059365]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_810.pth
	Model improved!!!
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08422806020120716		[learning rate: 0.0038512]
	Learning Rate: 0.00385123
	LOSS [training: 0.08422806020120716 | validation: 0.06813953405691878]
	TIME [epoch: 10.3 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1476213486424805		[learning rate: 0.0038394]
	Learning Rate: 0.00383943
	LOSS [training: 0.1476213486424805 | validation: 0.14390826535482995]
	TIME [epoch: 10.3 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08325519971450913		[learning rate: 0.0038277]
	Learning Rate: 0.00382766
	LOSS [training: 0.08325519971450913 | validation: 0.08536375509922796]
	TIME [epoch: 10.3 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16501584206324177		[learning rate: 0.0038159]
	Learning Rate: 0.00381593
	LOSS [training: 0.16501584206324177 | validation: 0.21765934292642986]
	TIME [epoch: 10.3 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18943534627942687		[learning rate: 0.0038042]
	Learning Rate: 0.00380423
	LOSS [training: 0.18943534627942687 | validation: 0.19273986955241806]
	TIME [epoch: 10.3 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10885241709750557		[learning rate: 0.0037926]
	Learning Rate: 0.00379257
	LOSS [training: 0.10885241709750557 | validation: 0.06311592098372498]
	TIME [epoch: 10.3 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12353844654344719		[learning rate: 0.0037809]
	Learning Rate: 0.00378094
	LOSS [training: 0.12353844654344719 | validation: 0.2607336721014866]
	TIME [epoch: 10.2 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26226622727160476		[learning rate: 0.0037694]
	Learning Rate: 0.00376935
	LOSS [training: 0.26226622727160476 | validation: 0.13871326661609254]
	TIME [epoch: 10.3 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30096702181751117		[learning rate: 0.0037578]
	Learning Rate: 0.0037578
	LOSS [training: 0.30096702181751117 | validation: 0.648778882599031]
	TIME [epoch: 10.2 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6918121173513634		[learning rate: 0.0037463]
	Learning Rate: 0.00374628
	LOSS [training: 0.6918121173513634 | validation: 0.511818554580966]
	TIME [epoch: 10.3 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5752043005944036		[learning rate: 0.0037348]
	Learning Rate: 0.00373479
	LOSS [training: 0.5752043005944036 | validation: 0.22719377262266988]
	TIME [epoch: 10.3 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16701524382425356		[learning rate: 0.0037233]
	Learning Rate: 0.00372335
	LOSS [training: 0.16701524382425356 | validation: 0.2735808492290086]
	TIME [epoch: 10.3 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45399428013119847		[learning rate: 0.0037119]
	Learning Rate: 0.00371193
	LOSS [training: 0.45399428013119847 | validation: 0.25753719277878945]
	TIME [epoch: 10.3 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2209648192651536		[learning rate: 0.0037006]
	Learning Rate: 0.00370055
	LOSS [training: 0.2209648192651536 | validation: 0.3033994899390429]
	TIME [epoch: 10.3 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29316815918706024		[learning rate: 0.0036892]
	Learning Rate: 0.00368921
	LOSS [training: 0.29316815918706024 | validation: 0.13633530965206933]
	TIME [epoch: 10.3 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13909416839474514		[learning rate: 0.0036779]
	Learning Rate: 0.0036779
	LOSS [training: 0.13909416839474514 | validation: 0.11249611801124906]
	TIME [epoch: 10.3 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12868983808761442		[learning rate: 0.0036666]
	Learning Rate: 0.00366663
	LOSS [training: 0.12868983808761442 | validation: 0.25383846458462683]
	TIME [epoch: 10.2 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31906652327887164		[learning rate: 0.0036554]
	Learning Rate: 0.00365539
	LOSS [training: 0.31906652327887164 | validation: 0.20068274516083898]
	TIME [epoch: 10.2 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1898657332085521		[learning rate: 0.0036442]
	Learning Rate: 0.00364418
	LOSS [training: 0.1898657332085521 | validation: 0.1785849114968724]
	TIME [epoch: 10.2 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13481552451076004		[learning rate: 0.003633]
	Learning Rate: 0.00363301
	LOSS [training: 0.13481552451076004 | validation: 0.05985212140735503]
	TIME [epoch: 10.3 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10884472899626627		[learning rate: 0.0036219]
	Learning Rate: 0.00362187
	LOSS [training: 0.10884472899626627 | validation: 0.13644218131052704]
	TIME [epoch: 10.3 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12105418418634346		[learning rate: 0.0036108]
	Learning Rate: 0.00361077
	LOSS [training: 0.12105418418634346 | validation: 0.12243333312943627]
	TIME [epoch: 10.3 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12943314755704022		[learning rate: 0.0035997]
	Learning Rate: 0.0035997
	LOSS [training: 0.12943314755704022 | validation: 0.05058089651367533]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_833.pth
	Model improved!!!
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08692971568206286		[learning rate: 0.0035887]
	Learning Rate: 0.00358867
	LOSS [training: 0.08692971568206286 | validation: 0.11200517295148014]
	TIME [epoch: 10.3 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18146034866838717		[learning rate: 0.0035777]
	Learning Rate: 0.00357767
	LOSS [training: 0.18146034866838717 | validation: 0.17369189878619054]
	TIME [epoch: 10.3 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19248744697064274		[learning rate: 0.0035667]
	Learning Rate: 0.0035667
	LOSS [training: 0.19248744697064274 | validation: 0.19156774901573262]
	TIME [epoch: 10.3 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16035725267275597		[learning rate: 0.0035558]
	Learning Rate: 0.00355577
	LOSS [training: 0.16035725267275597 | validation: 0.10736068947497547]
	TIME [epoch: 10.3 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1764029338729573		[learning rate: 0.0035449]
	Learning Rate: 0.00354487
	LOSS [training: 0.1764029338729573 | validation: 0.08159330198190029]
	TIME [epoch: 10.3 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14924337744397514		[learning rate: 0.003534]
	Learning Rate: 0.003534
	LOSS [training: 0.14924337744397514 | validation: 0.11928330365566508]
	TIME [epoch: 10.3 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19380188176408958		[learning rate: 0.0035232]
	Learning Rate: 0.00352317
	LOSS [training: 0.19380188176408958 | validation: 0.126023650098442]
	TIME [epoch: 10.3 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16792400991659612		[learning rate: 0.0035124]
	Learning Rate: 0.00351237
	LOSS [training: 0.16792400991659612 | validation: 0.21140111154076305]
	TIME [epoch: 10.3 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17985006148817176		[learning rate: 0.0035016]
	Learning Rate: 0.0035016
	LOSS [training: 0.17985006148817176 | validation: 0.19699717034264272]
	TIME [epoch: 10.3 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2190161220978537		[learning rate: 0.0034909]
	Learning Rate: 0.00349087
	LOSS [training: 0.2190161220978537 | validation: 0.1828217288117436]
	TIME [epoch: 10.3 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15635329105207588		[learning rate: 0.0034802]
	Learning Rate: 0.00348017
	LOSS [training: 0.15635329105207588 | validation: 0.1524717478826737]
	TIME [epoch: 10.3 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19800366802799613		[learning rate: 0.0034695]
	Learning Rate: 0.0034695
	LOSS [training: 0.19800366802799613 | validation: 0.058963533961102085]
	TIME [epoch: 10.3 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0863966001155733		[learning rate: 0.0034589]
	Learning Rate: 0.00345886
	LOSS [training: 0.0863966001155733 | validation: 0.10974307708150491]
	TIME [epoch: 10.3 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12320340701606344		[learning rate: 0.0034483]
	Learning Rate: 0.00344826
	LOSS [training: 0.12320340701606344 | validation: 0.11870562362781195]
	TIME [epoch: 10.3 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14623122061785343		[learning rate: 0.0034377]
	Learning Rate: 0.00343769
	LOSS [training: 0.14623122061785343 | validation: 0.13981256389758012]
	TIME [epoch: 10.3 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15769862221062575		[learning rate: 0.0034272]
	Learning Rate: 0.00342715
	LOSS [training: 0.15769862221062575 | validation: 0.07861078101546991]
	TIME [epoch: 10.2 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09281017902312552		[learning rate: 0.0034166]
	Learning Rate: 0.00341665
	LOSS [training: 0.09281017902312552 | validation: 0.09011852566026679]
	TIME [epoch: 10.3 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08845128275372718		[learning rate: 0.0034062]
	Learning Rate: 0.00340617
	LOSS [training: 0.08845128275372718 | validation: 0.10091637942257084]
	TIME [epoch: 10.2 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0962624807671285		[learning rate: 0.0033957]
	Learning Rate: 0.00339573
	LOSS [training: 0.0962624807671285 | validation: 0.07685485034609191]
	TIME [epoch: 10.3 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07250444493096528		[learning rate: 0.0033853]
	Learning Rate: 0.00338532
	LOSS [training: 0.07250444493096528 | validation: 0.06606470776919687]
	TIME [epoch: 10.2 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07703942933646964		[learning rate: 0.0033749]
	Learning Rate: 0.00337494
	LOSS [training: 0.07703942933646964 | validation: 0.07515362396905552]
	TIME [epoch: 10.3 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08053655269728446		[learning rate: 0.0033646]
	Learning Rate: 0.0033646
	LOSS [training: 0.08053655269728446 | validation: 0.06980120337376775]
	TIME [epoch: 10.3 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07733853541213984		[learning rate: 0.0033543]
	Learning Rate: 0.00335428
	LOSS [training: 0.07733853541213984 | validation: 0.07316828132249588]
	TIME [epoch: 10.3 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11297773737286072		[learning rate: 0.003344]
	Learning Rate: 0.003344
	LOSS [training: 0.11297773737286072 | validation: 0.15669300282394166]
	TIME [epoch: 10.3 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10515662371112675		[learning rate: 0.0033338]
	Learning Rate: 0.00333375
	LOSS [training: 0.10515662371112675 | validation: 0.09191228595537217]
	TIME [epoch: 10.3 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10077367609651726		[learning rate: 0.0033235]
	Learning Rate: 0.00332353
	LOSS [training: 0.10077367609651726 | validation: 0.15553367362482212]
	TIME [epoch: 10.3 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17196988880590452		[learning rate: 0.0033133]
	Learning Rate: 0.00331334
	LOSS [training: 0.17196988880590452 | validation: 0.08011987560020833]
	TIME [epoch: 10.3 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09351190015930291		[learning rate: 0.0033032]
	Learning Rate: 0.00330319
	LOSS [training: 0.09351190015930291 | validation: 0.04257634267790554]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_861.pth
	Model improved!!!
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18683690444455375		[learning rate: 0.0032931]
	Learning Rate: 0.00329306
	LOSS [training: 0.18683690444455375 | validation: 0.12469656367006973]
	TIME [epoch: 10.2 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1302043567542716		[learning rate: 0.003283]
	Learning Rate: 0.00328297
	LOSS [training: 0.1302043567542716 | validation: 0.21860155948235577]
	TIME [epoch: 10.2 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20675572265409098		[learning rate: 0.0032729]
	Learning Rate: 0.0032729
	LOSS [training: 0.20675572265409098 | validation: 0.17032498663786347]
	TIME [epoch: 10.3 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11758680976568217		[learning rate: 0.0032629]
	Learning Rate: 0.00326287
	LOSS [training: 0.11758680976568217 | validation: 0.16022761547949377]
	TIME [epoch: 10.3 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21412838324668698		[learning rate: 0.0032529]
	Learning Rate: 0.00325287
	LOSS [training: 0.21412838324668698 | validation: 0.05725821645233823]
	TIME [epoch: 10.3 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18701250511407247		[learning rate: 0.0032429]
	Learning Rate: 0.0032429
	LOSS [training: 0.18701250511407247 | validation: 0.43007215954600186]
	TIME [epoch: 10.3 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2897445132123643		[learning rate: 0.003233]
	Learning Rate: 0.00323296
	LOSS [training: 0.2897445132123643 | validation: 0.08547858782267179]
	TIME [epoch: 10.3 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1343865217145602		[learning rate: 0.003223]
	Learning Rate: 0.00322305
	LOSS [training: 0.1343865217145602 | validation: 0.3769571460747628]
	TIME [epoch: 10.3 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3214908700590859		[learning rate: 0.0032132]
	Learning Rate: 0.00321317
	LOSS [training: 0.3214908700590859 | validation: 0.3266614894958178]
	TIME [epoch: 10.3 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41104469357864326		[learning rate: 0.0032033]
	Learning Rate: 0.00320332
	LOSS [training: 0.41104469357864326 | validation: 0.19400567525343312]
	TIME [epoch: 10.3 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17178962773503917		[learning rate: 0.0031935]
	Learning Rate: 0.0031935
	LOSS [training: 0.17178962773503917 | validation: 0.11405361318291457]
	TIME [epoch: 10.3 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10732852308307554		[learning rate: 0.0031837]
	Learning Rate: 0.00318371
	LOSS [training: 0.10732852308307554 | validation: 0.09046466071800552]
	TIME [epoch: 10.3 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1735445152151509		[learning rate: 0.0031739]
	Learning Rate: 0.00317395
	LOSS [training: 0.1735445152151509 | validation: 0.22495529631353048]
	TIME [epoch: 10.2 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2240006434679711		[learning rate: 0.0031642]
	Learning Rate: 0.00316422
	LOSS [training: 0.2240006434679711 | validation: 0.14627549226479475]
	TIME [epoch: 10.3 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12442844651392349		[learning rate: 0.0031545]
	Learning Rate: 0.00315452
	LOSS [training: 0.12442844651392349 | validation: 0.08938184596107085]
	TIME [epoch: 10.3 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12440997306584042		[learning rate: 0.0031449]
	Learning Rate: 0.00314485
	LOSS [training: 0.12440997306584042 | validation: 0.10254098696464851]
	TIME [epoch: 10.3 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12365869388388237		[learning rate: 0.0031352]
	Learning Rate: 0.00313521
	LOSS [training: 0.12365869388388237 | validation: 0.08886474758153988]
	TIME [epoch: 10.2 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09598893054830207		[learning rate: 0.0031256]
	Learning Rate: 0.0031256
	LOSS [training: 0.09598893054830207 | validation: 0.0745188466936155]
	TIME [epoch: 10.3 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21983725028655413		[learning rate: 0.003116]
	Learning Rate: 0.00311602
	LOSS [training: 0.21983725028655413 | validation: 0.37343889060029856]
	TIME [epoch: 10.3 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3420125606732424		[learning rate: 0.0031065]
	Learning Rate: 0.00310647
	LOSS [training: 0.3420125606732424 | validation: 0.24091269100263119]
	TIME [epoch: 10.3 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20982994450518566		[learning rate: 0.0030969]
	Learning Rate: 0.00309694
	LOSS [training: 0.20982994450518566 | validation: 0.5196810724281634]
	TIME [epoch: 10.2 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5081495989393803		[learning rate: 0.0030875]
	Learning Rate: 0.00308745
	LOSS [training: 0.5081495989393803 | validation: 0.4936101662274409]
	TIME [epoch: 10.2 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6002819410585424		[learning rate: 0.003078]
	Learning Rate: 0.00307799
	LOSS [training: 0.6002819410585424 | validation: 0.7234208436004893]
	TIME [epoch: 10.3 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8848154797940178		[learning rate: 0.0030686]
	Learning Rate: 0.00306855
	LOSS [training: 0.8848154797940178 | validation: 0.49693852784729886]
	TIME [epoch: 10.3 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7537534218688597		[learning rate: 0.0030591]
	Learning Rate: 0.00305914
	LOSS [training: 0.7537534218688597 | validation: 0.5775465564166787]
	TIME [epoch: 10.2 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5059593460928848		[learning rate: 0.0030498]
	Learning Rate: 0.00304977
	LOSS [training: 0.5059593460928848 | validation: 0.23519110315501876]
	TIME [epoch: 10.2 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31297434760815845		[learning rate: 0.0030404]
	Learning Rate: 0.00304042
	LOSS [training: 0.31297434760815845 | validation: 0.29599020851040575]
	TIME [epoch: 10.2 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3607019583307702		[learning rate: 0.0030311]
	Learning Rate: 0.0030311
	LOSS [training: 0.3607019583307702 | validation: 0.3030615829197402]
	TIME [epoch: 10.3 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.455457633027826		[learning rate: 0.0030218]
	Learning Rate: 0.00302181
	LOSS [training: 0.455457633027826 | validation: 0.3515430608687896]
	TIME [epoch: 10.2 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.516980002418245		[learning rate: 0.0030125]
	Learning Rate: 0.00301254
	LOSS [training: 0.516980002418245 | validation: 0.34051688753666626]
	TIME [epoch: 10.3 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36068523051694656		[learning rate: 0.0030033]
	Learning Rate: 0.00300331
	LOSS [training: 0.36068523051694656 | validation: 0.45696458182800287]
	TIME [epoch: 10.2 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9895202264296401		[learning rate: 0.0029941]
	Learning Rate: 0.0029941
	LOSS [training: 0.9895202264296401 | validation: 1.290148485735234]
	TIME [epoch: 10.3 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5028225499068117		[learning rate: 0.0029849]
	Learning Rate: 0.00298492
	LOSS [training: 1.5028225499068117 | validation: 1.2271813273913725]
	TIME [epoch: 10.3 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.977648535138963		[learning rate: 0.0029758]
	Learning Rate: 0.00297577
	LOSS [training: 0.977648535138963 | validation: 0.2606992703581093]
	TIME [epoch: 10.3 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2080036834992875		[learning rate: 0.0029667]
	Learning Rate: 0.00296665
	LOSS [training: 0.2080036834992875 | validation: 0.1224320766939185]
	TIME [epoch: 10.3 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1636392363820896		[learning rate: 0.0029576]
	Learning Rate: 0.00295756
	LOSS [training: 0.1636392363820896 | validation: 0.27434357193695774]
	TIME [epoch: 10.3 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32053359844012685		[learning rate: 0.0029485]
	Learning Rate: 0.00294849
	LOSS [training: 0.32053359844012685 | validation: 0.145362953088005]
	TIME [epoch: 10.2 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2146574434235279		[learning rate: 0.0029395]
	Learning Rate: 0.00293945
	LOSS [training: 0.2146574434235279 | validation: 0.20643982763267843]
	TIME [epoch: 10.2 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17776754993659571		[learning rate: 0.0029304]
	Learning Rate: 0.00293044
	LOSS [training: 0.17776754993659571 | validation: 0.11695672782961054]
	TIME [epoch: 10.3 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12419665294324578		[learning rate: 0.0029215]
	Learning Rate: 0.00292146
	LOSS [training: 0.12419665294324578 | validation: 0.14046460107738779]
	TIME [epoch: 10.3 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11507647987236638		[learning rate: 0.0029125]
	Learning Rate: 0.0029125
	LOSS [training: 0.11507647987236638 | validation: 0.11798586141610351]
	TIME [epoch: 10.3 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10132573317874391		[learning rate: 0.0029036]
	Learning Rate: 0.00290358
	LOSS [training: 0.10132573317874391 | validation: 0.07569065918438443]
	TIME [epoch: 10.3 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12319996343388182		[learning rate: 0.0028947]
	Learning Rate: 0.00289468
	LOSS [training: 0.12319996343388182 | validation: 0.15126176962697255]
	TIME [epoch: 10.2 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27590820638124064		[learning rate: 0.0028858]
	Learning Rate: 0.0028858
	LOSS [training: 0.27590820638124064 | validation: 0.37415226426048764]
	TIME [epoch: 10.3 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33454053387600735		[learning rate: 0.002877]
	Learning Rate: 0.00287696
	LOSS [training: 0.33454053387600735 | validation: 0.179168766057586]
	TIME [epoch: 10.3 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15681196636113337		[learning rate: 0.0028681]
	Learning Rate: 0.00286814
	LOSS [training: 0.15681196636113337 | validation: 0.20095222037683727]
	TIME [epoch: 10.3 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21444886004352207		[learning rate: 0.0028593]
	Learning Rate: 0.00285935
	LOSS [training: 0.21444886004352207 | validation: 0.16725516628821865]
	TIME [epoch: 10.3 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2422018620838192		[learning rate: 0.0028506]
	Learning Rate: 0.00285058
	LOSS [training: 0.2422018620838192 | validation: 0.2627453628807243]
	TIME [epoch: 10.3 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1793037203304128		[learning rate: 0.0028418]
	Learning Rate: 0.00284184
	LOSS [training: 0.1793037203304128 | validation: 0.09398581123332464]
	TIME [epoch: 10.2 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07095238648911503		[learning rate: 0.0028331]
	Learning Rate: 0.00283313
	LOSS [training: 0.07095238648911503 | validation: 0.06453838176340794]
	TIME [epoch: 10.3 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10288778514019396		[learning rate: 0.0028244]
	Learning Rate: 0.00282445
	LOSS [training: 0.10288778514019396 | validation: 0.1212919967439753]
	TIME [epoch: 10.2 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29714140085436247		[learning rate: 0.0028158]
	Learning Rate: 0.00281579
	LOSS [training: 0.29714140085436247 | validation: 0.33056831407359083]
	TIME [epoch: 10.3 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22744008154219642		[learning rate: 0.0028072]
	Learning Rate: 0.00280716
	LOSS [training: 0.22744008154219642 | validation: 0.11453716167885312]
	TIME [epoch: 10.3 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11358192984245878		[learning rate: 0.0027986]
	Learning Rate: 0.00279855
	LOSS [training: 0.11358192984245878 | validation: 0.10934424330951081]
	TIME [epoch: 10.3 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10676221667735102		[learning rate: 0.00279]
	Learning Rate: 0.00278997
	LOSS [training: 0.10676221667735102 | validation: 0.08557835105192893]
	TIME [epoch: 10.2 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08414236927606965		[learning rate: 0.0027814]
	Learning Rate: 0.00278142
	LOSS [training: 0.08414236927606965 | validation: 0.06785711151928016]
	TIME [epoch: 10.3 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07944093133028163		[learning rate: 0.0027729]
	Learning Rate: 0.00277289
	LOSS [training: 0.07944093133028163 | validation: 0.058331861767543416]
	TIME [epoch: 10.3 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10135923878840328		[learning rate: 0.0027644]
	Learning Rate: 0.00276439
	LOSS [training: 0.10135923878840328 | validation: 0.0799556676788885]
	TIME [epoch: 10.3 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08954572994274004		[learning rate: 0.0027559]
	Learning Rate: 0.00275592
	LOSS [training: 0.08954572994274004 | validation: 0.12741582376856278]
	TIME [epoch: 10.3 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10577076740491742		[learning rate: 0.0027475]
	Learning Rate: 0.00274747
	LOSS [training: 0.10577076740491742 | validation: 0.03915585651393326]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_921.pth
	Model improved!!!
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05673886733443099		[learning rate: 0.002739]
	Learning Rate: 0.00273905
	LOSS [training: 0.05673886733443099 | validation: 0.09803468476951736]
	TIME [epoch: 10.2 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06464237894757567		[learning rate: 0.0027307]
	Learning Rate: 0.00273065
	LOSS [training: 0.06464237894757567 | validation: 0.07911680848307195]
	TIME [epoch: 10.2 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11695688780768229		[learning rate: 0.0027223]
	Learning Rate: 0.00272228
	LOSS [training: 0.11695688780768229 | validation: 0.14289312602921672]
	TIME [epoch: 10.2 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2804601515970056		[learning rate: 0.0027139]
	Learning Rate: 0.00271394
	LOSS [training: 0.2804601515970056 | validation: 0.17418343596043695]
	TIME [epoch: 10.3 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1252744829262963		[learning rate: 0.0027056]
	Learning Rate: 0.00270562
	LOSS [training: 0.1252744829262963 | validation: 0.06025262534440033]
	TIME [epoch: 10.2 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06478962240607924		[learning rate: 0.0026973]
	Learning Rate: 0.00269733
	LOSS [training: 0.06478962240607924 | validation: 0.08438515147780935]
	TIME [epoch: 10.3 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08347613690097223		[learning rate: 0.0026891]
	Learning Rate: 0.00268906
	LOSS [training: 0.08347613690097223 | validation: 0.038719983549790254]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_928.pth
	Model improved!!!
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05335356430604071		[learning rate: 0.0026808]
	Learning Rate: 0.00268081
	LOSS [training: 0.05335356430604071 | validation: 0.05591129644623131]
	TIME [epoch: 10.2 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07701728137271714		[learning rate: 0.0026726]
	Learning Rate: 0.0026726
	LOSS [training: 0.07701728137271714 | validation: 0.11871924324530878]
	TIME [epoch: 10.2 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1458449733644619		[learning rate: 0.0026644]
	Learning Rate: 0.0026644
	LOSS [training: 0.1458449733644619 | validation: 0.08984221326688709]
	TIME [epoch: 10.2 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09374927075585382		[learning rate: 0.0026562]
	Learning Rate: 0.00265624
	LOSS [training: 0.09374927075585382 | validation: 0.11736106459213921]
	TIME [epoch: 10.2 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1268800215750899		[learning rate: 0.0026481]
	Learning Rate: 0.00264809
	LOSS [training: 0.1268800215750899 | validation: 0.061757610658888934]
	TIME [epoch: 10.2 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06280929427297152		[learning rate: 0.00264]
	Learning Rate: 0.00263998
	LOSS [training: 0.06280929427297152 | validation: 0.05783059985552621]
	TIME [epoch: 10.2 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09553368881956256		[learning rate: 0.0026319]
	Learning Rate: 0.00263188
	LOSS [training: 0.09553368881956256 | validation: 0.08960045932131798]
	TIME [epoch: 10.2 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14593216898467248		[learning rate: 0.0026238]
	Learning Rate: 0.00262382
	LOSS [training: 0.14593216898467248 | validation: 0.14654029963672371]
	TIME [epoch: 10.2 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1312946301609703		[learning rate: 0.0026158]
	Learning Rate: 0.00261577
	LOSS [training: 0.1312946301609703 | validation: 0.09117699352570974]
	TIME [epoch: 10.2 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09539477247664438		[learning rate: 0.0026078]
	Learning Rate: 0.00260775
	LOSS [training: 0.09539477247664438 | validation: 0.09458051633739778]
	TIME [epoch: 10.2 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0996618697988398		[learning rate: 0.0025998]
	Learning Rate: 0.00259976
	LOSS [training: 0.0996618697988398 | validation: 0.08081598977067403]
	TIME [epoch: 10.3 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07126826709073804		[learning rate: 0.0025918]
	Learning Rate: 0.00259179
	LOSS [training: 0.07126826709073804 | validation: 0.09057533147062034]
	TIME [epoch: 10.2 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13474727582755602		[learning rate: 0.0025838]
	Learning Rate: 0.00258385
	LOSS [training: 0.13474727582755602 | validation: 0.248381119082165]
	TIME [epoch: 10.2 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17568344821616072		[learning rate: 0.0025759]
	Learning Rate: 0.00257593
	LOSS [training: 0.17568344821616072 | validation: 0.11685470757812035]
	TIME [epoch: 10.2 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2000376270462274		[learning rate: 0.002568]
	Learning Rate: 0.00256803
	LOSS [training: 0.2000376270462274 | validation: 0.19518050797350525]
	TIME [epoch: 10.2 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16917220656301887		[learning rate: 0.0025602]
	Learning Rate: 0.00256016
	LOSS [training: 0.16917220656301887 | validation: 0.1458219434955128]
	TIME [epoch: 10.2 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3592120151796362		[learning rate: 0.0025523]
	Learning Rate: 0.00255231
	LOSS [training: 0.3592120151796362 | validation: 0.29904590559255706]
	TIME [epoch: 10.2 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32175689268066204		[learning rate: 0.0025445]
	Learning Rate: 0.00254449
	LOSS [training: 0.32175689268066204 | validation: 0.2148003060237174]
	TIME [epoch: 10.2 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2895961463550848		[learning rate: 0.0025367]
	Learning Rate: 0.00253669
	LOSS [training: 0.2895961463550848 | validation: 0.23971683864873541]
	TIME [epoch: 10.2 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2622395197728225		[learning rate: 0.0025289]
	Learning Rate: 0.00252891
	LOSS [training: 0.2622395197728225 | validation: 0.2548985033116153]
	TIME [epoch: 10.3 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39681845772777485		[learning rate: 0.0025212]
	Learning Rate: 0.00252116
	LOSS [training: 0.39681845772777485 | validation: 0.3141886253087674]
	TIME [epoch: 10.3 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25298682414522305		[learning rate: 0.0025134]
	Learning Rate: 0.00251343
	LOSS [training: 0.25298682414522305 | validation: 0.16116570019135876]
	TIME [epoch: 10.3 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1275570105727031		[learning rate: 0.0025057]
	Learning Rate: 0.00250572
	LOSS [training: 0.1275570105727031 | validation: 0.13652751012001832]
	TIME [epoch: 10.3 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1441427149374488		[learning rate: 0.002498]
	Learning Rate: 0.00249804
	LOSS [training: 0.1441427149374488 | validation: 0.08782662126909047]
	TIME [epoch: 10.2 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14050019103628514		[learning rate: 0.0024904]
	Learning Rate: 0.00249039
	LOSS [training: 0.14050019103628514 | validation: 0.18213998685116284]
	TIME [epoch: 10.3 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2294107444976648		[learning rate: 0.0024828]
	Learning Rate: 0.00248275
	LOSS [training: 0.2294107444976648 | validation: 0.1317047983985514]
	TIME [epoch: 10.3 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12341176671002745		[learning rate: 0.0024751]
	Learning Rate: 0.00247514
	LOSS [training: 0.12341176671002745 | validation: 0.07931883077092199]
	TIME [epoch: 10.3 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10057122241400614		[learning rate: 0.0024676]
	Learning Rate: 0.00246755
	LOSS [training: 0.10057122241400614 | validation: 0.09225797163925281]
	TIME [epoch: 10.2 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09083922268014524		[learning rate: 0.00246]
	Learning Rate: 0.00245999
	LOSS [training: 0.09083922268014524 | validation: 0.053353411187132826]
	TIME [epoch: 10.3 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09235154244922186		[learning rate: 0.0024524]
	Learning Rate: 0.00245245
	LOSS [training: 0.09235154244922186 | validation: 0.1490092249111621]
	TIME [epoch: 10.2 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22245599210838513		[learning rate: 0.0024449]
	Learning Rate: 0.00244493
	LOSS [training: 0.22245599210838513 | validation: 0.3264413750933827]
	TIME [epoch: 10.3 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2635843886011056		[learning rate: 0.0024374]
	Learning Rate: 0.00243744
	LOSS [training: 0.2635843886011056 | validation: 0.1915518934525435]
	TIME [epoch: 10.3 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15170525988225714		[learning rate: 0.00243]
	Learning Rate: 0.00242996
	LOSS [training: 0.15170525988225714 | validation: 0.14093081664011486]
	TIME [epoch: 10.3 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11916242405084305		[learning rate: 0.0024225]
	Learning Rate: 0.00242252
	LOSS [training: 0.11916242405084305 | validation: 0.10241027103911375]
	TIME [epoch: 10.3 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08408811314505382		[learning rate: 0.0024151]
	Learning Rate: 0.00241509
	LOSS [training: 0.08408811314505382 | validation: 0.08432075021267138]
	TIME [epoch: 10.3 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10361279654262094		[learning rate: 0.0024077]
	Learning Rate: 0.00240769
	LOSS [training: 0.10361279654262094 | validation: 0.2186437283497788]
	TIME [epoch: 10.2 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2554894975191911		[learning rate: 0.0024003]
	Learning Rate: 0.00240031
	LOSS [training: 0.2554894975191911 | validation: 0.17486998512794238]
	TIME [epoch: 10.3 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12574940026844483		[learning rate: 0.0023929]
	Learning Rate: 0.00239295
	LOSS [training: 0.12574940026844483 | validation: 0.03937132488065003]
	TIME [epoch: 10.3 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08325927357063258		[learning rate: 0.0023856]
	Learning Rate: 0.00238561
	LOSS [training: 0.08325927357063258 | validation: 0.15111714233711263]
	TIME [epoch: 10.3 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515546181951214		[learning rate: 0.0023783]
	Learning Rate: 0.0023783
	LOSS [training: 0.1515546181951214 | validation: 0.13575160909615208]
	TIME [epoch: 10.3 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1514363483956686		[learning rate: 0.002371]
	Learning Rate: 0.00237101
	LOSS [training: 0.1514363483956686 | validation: 0.2035079679230605]
	TIME [epoch: 10.3 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.187046082780389		[learning rate: 0.0023637]
	Learning Rate: 0.00236374
	LOSS [training: 0.187046082780389 | validation: 0.16714068807865595]
	TIME [epoch: 10.3 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19037771793705524		[learning rate: 0.0023565]
	Learning Rate: 0.0023565
	LOSS [training: 0.19037771793705524 | validation: 0.1248796221201631]
	TIME [epoch: 10.2 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1055117119178575		[learning rate: 0.0023493]
	Learning Rate: 0.00234927
	LOSS [training: 0.1055117119178575 | validation: 0.05728884559264771]
	TIME [epoch: 10.3 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09709241853453443		[learning rate: 0.0023421]
	Learning Rate: 0.00234207
	LOSS [training: 0.09709241853453443 | validation: 0.0923403886973616]
	TIME [epoch: 10.3 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17205951771872877		[learning rate: 0.0023349]
	Learning Rate: 0.00233489
	LOSS [training: 0.17205951771872877 | validation: 0.27753118195957277]
	TIME [epoch: 10.3 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31574340430888226		[learning rate: 0.0023277]
	Learning Rate: 0.00232773
	LOSS [training: 0.31574340430888226 | validation: 0.3938537203857186]
	TIME [epoch: 10.3 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34829948218583395		[learning rate: 0.0023206]
	Learning Rate: 0.0023206
	LOSS [training: 0.34829948218583395 | validation: 0.1940424861702763]
	TIME [epoch: 10.3 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1268997686498679		[learning rate: 0.0023135]
	Learning Rate: 0.00231348
	LOSS [training: 0.1268997686498679 | validation: 0.0676857041397325]
	TIME [epoch: 10.3 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06406955962641239		[learning rate: 0.0023064]
	Learning Rate: 0.00230639
	LOSS [training: 0.06406955962641239 | validation: 0.039843198727690654]
	TIME [epoch: 10.3 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06468740281076447		[learning rate: 0.0022993]
	Learning Rate: 0.00229932
	LOSS [training: 0.06468740281076447 | validation: 0.0728374650387054]
	TIME [epoch: 10.2 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08881590072588508		[learning rate: 0.0022923]
	Learning Rate: 0.00229227
	LOSS [training: 0.08881590072588508 | validation: 0.06598818668406786]
	TIME [epoch: 10.2 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07749127881418529		[learning rate: 0.0022852]
	Learning Rate: 0.00228525
	LOSS [training: 0.07749127881418529 | validation: 0.09015369893568936]
	TIME [epoch: 10.2 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11892602289296945		[learning rate: 0.0022782]
	Learning Rate: 0.00227824
	LOSS [training: 0.11892602289296945 | validation: 0.08264247963179655]
	TIME [epoch: 10.2 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08634433150447078		[learning rate: 0.0022713]
	Learning Rate: 0.00227126
	LOSS [training: 0.08634433150447078 | validation: 0.06315684492496765]
	TIME [epoch: 10.3 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08785278643707414		[learning rate: 0.0022643]
	Learning Rate: 0.0022643
	LOSS [training: 0.08785278643707414 | validation: 0.08010021687739491]
	TIME [epoch: 10.3 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14425660361307208		[learning rate: 0.0022574]
	Learning Rate: 0.00225736
	LOSS [training: 0.14425660361307208 | validation: 0.18146985467201923]
	TIME [epoch: 10.2 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11656158086854788		[learning rate: 0.0022504]
	Learning Rate: 0.00225044
	LOSS [training: 0.11656158086854788 | validation: 0.07628071496112954]
	TIME [epoch: 10.3 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06368601822648398		[learning rate: 0.0022435]
	Learning Rate: 0.00224354
	LOSS [training: 0.06368601822648398 | validation: 0.08162869228615248]
	TIME [epoch: 10.3 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0658570448401875		[learning rate: 0.0022367]
	Learning Rate: 0.00223666
	LOSS [training: 0.0658570448401875 | validation: 0.0335269273186566]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_988.pth
	Model improved!!!
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039431871268951105		[learning rate: 0.0022298]
	Learning Rate: 0.0022298
	LOSS [training: 0.039431871268951105 | validation: 0.05163129776628738]
	TIME [epoch: 10.2 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04856282770484721		[learning rate: 0.002223]
	Learning Rate: 0.00222297
	LOSS [training: 0.04856282770484721 | validation: 0.06055800890502212]
	TIME [epoch: 10.2 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06101068094829374		[learning rate: 0.0022162]
	Learning Rate: 0.00221615
	LOSS [training: 0.06101068094829374 | validation: 0.07509599278032138]
	TIME [epoch: 10.2 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11209761153791156		[learning rate: 0.0022094]
	Learning Rate: 0.00220936
	LOSS [training: 0.11209761153791156 | validation: 0.08815468352923077]
	TIME [epoch: 10.2 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07673498265429995		[learning rate: 0.0022026]
	Learning Rate: 0.00220259
	LOSS [training: 0.07673498265429995 | validation: 0.07367535066073072]
	TIME [epoch: 10.2 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07483494732636889		[learning rate: 0.0021958]
	Learning Rate: 0.00219584
	LOSS [training: 0.07483494732636889 | validation: 0.05001389611099853]
	TIME [epoch: 10.2 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04147553380180892		[learning rate: 0.0021891]
	Learning Rate: 0.00218911
	LOSS [training: 0.04147553380180892 | validation: 0.06156670079750996]
	TIME [epoch: 10.2 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0988099964992659		[learning rate: 0.0021824]
	Learning Rate: 0.00218239
	LOSS [training: 0.0988099964992659 | validation: 0.09903781187590358]
	TIME [epoch: 10.3 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13173465692404213		[learning rate: 0.0021757]
	Learning Rate: 0.00217571
	LOSS [training: 0.13173465692404213 | validation: 0.07446985777626271]
	TIME [epoch: 10.3 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09595663755526782		[learning rate: 0.002169]
	Learning Rate: 0.00216904
	LOSS [training: 0.09595663755526782 | validation: 0.30030866925981886]
	TIME [epoch: 10.3 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.361324184641669		[learning rate: 0.0021624]
	Learning Rate: 0.00216239
	LOSS [training: 0.361324184641669 | validation: 0.30431591456139273]
	TIME [epoch: 10.3 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2867619342384674		[learning rate: 0.0021558]
	Learning Rate: 0.00215576
	LOSS [training: 0.2867619342384674 | validation: 0.1597671632328774]
	TIME [epoch: 10.3 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10077661364625772		[learning rate: 0.0021491]
	Learning Rate: 0.00214915
	LOSS [training: 0.10077661364625772 | validation: 0.1358259503789144]
	TIME [epoch: 10.3 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.160958122525581		[learning rate: 0.0021426]
	Learning Rate: 0.00214256
	LOSS [training: 0.160958122525581 | validation: 0.09498506302822551]
	TIME [epoch: 10.3 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08162617643930711		[learning rate: 0.002136]
	Learning Rate: 0.00213599
	LOSS [training: 0.08162617643930711 | validation: 0.06426208590614042]
	TIME [epoch: 10.2 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06658477911512516		[learning rate: 0.0021294]
	Learning Rate: 0.00212945
	LOSS [training: 0.06658477911512516 | validation: 0.03611303410005476]
	TIME [epoch: 10.2 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07089463104361438		[learning rate: 0.0021229]
	Learning Rate: 0.00212292
	LOSS [training: 0.07089463104361438 | validation: 0.12186511224088864]
	TIME [epoch: 10.3 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08958954870470731		[learning rate: 0.0021164]
	Learning Rate: 0.00211641
	LOSS [training: 0.08958954870470731 | validation: 0.08191313301906426]
	TIME [epoch: 10.3 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11174656148469579		[learning rate: 0.0021099]
	Learning Rate: 0.00210992
	LOSS [training: 0.11174656148469579 | validation: 0.11774340995238407]
	TIME [epoch: 10.3 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09945694590299739		[learning rate: 0.0021035]
	Learning Rate: 0.00210346
	LOSS [training: 0.09945694590299739 | validation: 0.05125792295622291]
	TIME [epoch: 10.2 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050855936855613716		[learning rate: 0.002097]
	Learning Rate: 0.00209701
	LOSS [training: 0.050855936855613716 | validation: 0.039225106705617234]
	TIME [epoch: 10.2 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05228803362169672		[learning rate: 0.0020906]
	Learning Rate: 0.00209058
	LOSS [training: 0.05228803362169672 | validation: 0.04991171809697005]
	TIME [epoch: 10.3 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04976076151165761		[learning rate: 0.0020842]
	Learning Rate: 0.00208417
	LOSS [training: 0.04976076151165761 | validation: 0.10134576786044029]
	TIME [epoch: 10.3 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12684211147234103		[learning rate: 0.0020778]
	Learning Rate: 0.00207778
	LOSS [training: 0.12684211147234103 | validation: 0.12448082012611629]
	TIME [epoch: 10.3 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10079383763036039		[learning rate: 0.0020714]
	Learning Rate: 0.00207141
	LOSS [training: 0.10079383763036039 | validation: 0.08508947586057852]
	TIME [epoch: 10.2 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0903398708154136		[learning rate: 0.0020651]
	Learning Rate: 0.00206506
	LOSS [training: 0.0903398708154136 | validation: 0.08766176869323761]
	TIME [epoch: 10.3 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10580832219349837		[learning rate: 0.0020587]
	Learning Rate: 0.00205873
	LOSS [training: 0.10580832219349837 | validation: 0.06926001259592773]
	TIME [epoch: 10.3 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06866132740041589		[learning rate: 0.0020524]
	Learning Rate: 0.00205242
	LOSS [training: 0.06866132740041589 | validation: 0.08689339165288057]
	TIME [epoch: 10.3 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07334879390029232		[learning rate: 0.0020461]
	Learning Rate: 0.00204613
	LOSS [training: 0.07334879390029232 | validation: 0.04198978438110165]
	TIME [epoch: 10.2 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05606566291027887		[learning rate: 0.0020399]
	Learning Rate: 0.00203986
	LOSS [training: 0.05606566291027887 | validation: 0.04741888628010503]
	TIME [epoch: 10.3 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049545065870120954		[learning rate: 0.0020336]
	Learning Rate: 0.00203361
	LOSS [training: 0.049545065870120954 | validation: 0.06520640334980118]
	TIME [epoch: 10.3 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06846170248596363		[learning rate: 0.0020274]
	Learning Rate: 0.00202737
	LOSS [training: 0.06846170248596363 | validation: 0.052525488532966624]
	TIME [epoch: 10.2 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060910014178398954		[learning rate: 0.0020212]
	Learning Rate: 0.00202116
	LOSS [training: 0.060910014178398954 | validation: 0.0362809072847421]
	TIME [epoch: 10.3 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07379501490542564		[learning rate: 0.002015]
	Learning Rate: 0.00201496
	LOSS [training: 0.07379501490542564 | validation: 0.12420291317992188]
	TIME [epoch: 10.3 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1439452812778902		[learning rate: 0.0020088]
	Learning Rate: 0.00200878
	LOSS [training: 0.1439452812778902 | validation: 0.1111960362835996]
	TIME [epoch: 10.3 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09535835014648988		[learning rate: 0.0020026]
	Learning Rate: 0.00200263
	LOSS [training: 0.09535835014648988 | validation: 0.1004216106537777]
	TIME [epoch: 10.3 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10052855566520172		[learning rate: 0.0019965]
	Learning Rate: 0.00199649
	LOSS [training: 0.10052855566520172 | validation: 0.07835141080018636]
	TIME [epoch: 10.3 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09342721319424929		[learning rate: 0.0019904]
	Learning Rate: 0.00199037
	LOSS [training: 0.09342721319424929 | validation: 0.0612110372535331]
	TIME [epoch: 10.3 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08906670474858173		[learning rate: 0.0019843]
	Learning Rate: 0.00198427
	LOSS [training: 0.08906670474858173 | validation: 0.0975718329552617]
	TIME [epoch: 10.3 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10038756854431904		[learning rate: 0.0019782]
	Learning Rate: 0.00197818
	LOSS [training: 0.10038756854431904 | validation: 0.07778509405210075]
	TIME [epoch: 10.2 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09230961898020122		[learning rate: 0.0019721]
	Learning Rate: 0.00197212
	LOSS [training: 0.09230961898020122 | validation: 0.14715822808316487]
	TIME [epoch: 10.2 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14839750078052388		[learning rate: 0.0019661]
	Learning Rate: 0.00196607
	LOSS [training: 0.14839750078052388 | validation: 0.1217520935600836]
	TIME [epoch: 10.3 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1525085043848852		[learning rate: 0.00196]
	Learning Rate: 0.00196005
	LOSS [training: 0.1525085043848852 | validation: 0.13579663524457405]
	TIME [epoch: 10.3 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11787215130434456		[learning rate: 0.001954]
	Learning Rate: 0.00195404
	LOSS [training: 0.11787215130434456 | validation: 0.04890102807038359]
	TIME [epoch: 10.3 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052737329609209474		[learning rate: 0.001948]
	Learning Rate: 0.00194805
	LOSS [training: 0.052737329609209474 | validation: 0.04875345594454355]
	TIME [epoch: 10.3 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04939216775430418		[learning rate: 0.0019421]
	Learning Rate: 0.00194208
	LOSS [training: 0.04939216775430418 | validation: 0.03833606274669617]
	TIME [epoch: 10.3 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04836190561505817		[learning rate: 0.0019361]
	Learning Rate: 0.00193612
	LOSS [training: 0.04836190561505817 | validation: 0.03431804721324617]
	TIME [epoch: 10.3 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06242657244928512		[learning rate: 0.0019302]
	Learning Rate: 0.00193019
	LOSS [training: 0.06242657244928512 | validation: 0.044588261225312176]
	TIME [epoch: 10.3 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07142631759603293		[learning rate: 0.0019243]
	Learning Rate: 0.00192427
	LOSS [training: 0.07142631759603293 | validation: 0.04386494608085331]
	TIME [epoch: 10.3 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04744145796974822		[learning rate: 0.0019184]
	Learning Rate: 0.00191837
	LOSS [training: 0.04744145796974822 | validation: 0.019429960158257164]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_1038.pth
	Model improved!!!
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048317077309352856		[learning rate: 0.0019125]
	Learning Rate: 0.00191249
	LOSS [training: 0.048317077309352856 | validation: 0.04630612326863859]
	TIME [epoch: 10.2 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0557002653527595		[learning rate: 0.0019066]
	Learning Rate: 0.00190663
	LOSS [training: 0.0557002653527595 | validation: 0.08763517047342693]
	TIME [epoch: 10.2 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09870553919691698		[learning rate: 0.0019008]
	Learning Rate: 0.00190079
	LOSS [training: 0.09870553919691698 | validation: 0.07908649500207404]
	TIME [epoch: 10.2 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08477979006720493		[learning rate: 0.001895]
	Learning Rate: 0.00189496
	LOSS [training: 0.08477979006720493 | validation: 0.06755127441451644]
	TIME [epoch: 10.2 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07071552925124908		[learning rate: 0.0018892]
	Learning Rate: 0.00188915
	LOSS [training: 0.07071552925124908 | validation: 0.05237554672742584]
	TIME [epoch: 10.3 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12432120056566767		[learning rate: 0.0018834]
	Learning Rate: 0.00188336
	LOSS [training: 0.12432120056566767 | validation: 0.2055570199679138]
	TIME [epoch: 10.2 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22848004561637122		[learning rate: 0.0018776]
	Learning Rate: 0.00187759
	LOSS [training: 0.22848004561637122 | validation: 0.19141707701601515]
	TIME [epoch: 10.2 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18977540051885358		[learning rate: 0.0018718]
	Learning Rate: 0.00187183
	LOSS [training: 0.18977540051885358 | validation: 0.19547382752229556]
	TIME [epoch: 10.2 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25067650994023066		[learning rate: 0.0018661]
	Learning Rate: 0.00186609
	LOSS [training: 0.25067650994023066 | validation: 0.28697032828508645]
	TIME [epoch: 10.3 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23526315153205646		[learning rate: 0.0018604]
	Learning Rate: 0.00186037
	LOSS [training: 0.23526315153205646 | validation: 0.1453036562781588]
	TIME [epoch: 10.2 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11760798250404278		[learning rate: 0.0018547]
	Learning Rate: 0.00185467
	LOSS [training: 0.11760798250404278 | validation: 0.0982463015308737]
	TIME [epoch: 10.2 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10583116032579043		[learning rate: 0.001849]
	Learning Rate: 0.00184898
	LOSS [training: 0.10583116032579043 | validation: 0.12869507286705834]
	TIME [epoch: 10.2 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09562246928569615		[learning rate: 0.0018433]
	Learning Rate: 0.00184332
	LOSS [training: 0.09562246928569615 | validation: 0.09464535559538949]
	TIME [epoch: 10.2 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0800451464319027		[learning rate: 0.0018377]
	Learning Rate: 0.00183767
	LOSS [training: 0.0800451464319027 | validation: 0.08716470823065667]
	TIME [epoch: 10.2 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0889182444631335		[learning rate: 0.001832]
	Learning Rate: 0.00183203
	LOSS [training: 0.0889182444631335 | validation: 0.09254632995091841]
	TIME [epoch: 10.2 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09548702791898085		[learning rate: 0.0018264]
	Learning Rate: 0.00182642
	LOSS [training: 0.09548702791898085 | validation: 0.12279984277267346]
	TIME [epoch: 10.2 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11309930884702402		[learning rate: 0.0018208]
	Learning Rate: 0.00182082
	LOSS [training: 0.11309930884702402 | validation: 0.11965035344343694]
	TIME [epoch: 10.3 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08512145048151416		[learning rate: 0.0018152]
	Learning Rate: 0.00181524
	LOSS [training: 0.08512145048151416 | validation: 0.07916748810824445]
	TIME [epoch: 10.2 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12074646450111252		[learning rate: 0.0018097]
	Learning Rate: 0.00180967
	LOSS [training: 0.12074646450111252 | validation: 0.1473066155199643]
	TIME [epoch: 10.2 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2622923749911539		[learning rate: 0.0018041]
	Learning Rate: 0.00180412
	LOSS [training: 0.2622923749911539 | validation: 0.25083440352907505]
	TIME [epoch: 10.2 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.321280918746787		[learning rate: 0.0017986]
	Learning Rate: 0.00179859
	LOSS [training: 0.321280918746787 | validation: 0.22865011276505257]
	TIME [epoch: 10.3 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4634116857307573		[learning rate: 0.0017931]
	Learning Rate: 0.00179308
	LOSS [training: 0.4634116857307573 | validation: 0.3075354736845812]
	TIME [epoch: 10.2 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31782291049250894		[learning rate: 0.0017876]
	Learning Rate: 0.00178758
	LOSS [training: 0.31782291049250894 | validation: 0.19180804581850985]
	TIME [epoch: 10.2 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22935984637670787		[learning rate: 0.0017821]
	Learning Rate: 0.00178211
	LOSS [training: 0.22935984637670787 | validation: 0.29065532014383727]
	TIME [epoch: 10.2 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34525808197717156		[learning rate: 0.0017766]
	Learning Rate: 0.00177664
	LOSS [training: 0.34525808197717156 | validation: 0.16794666212433199]
	TIME [epoch: 10.2 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17319635013651155		[learning rate: 0.0017712]
	Learning Rate: 0.0017712
	LOSS [training: 0.17319635013651155 | validation: 0.12323845001230403]
	TIME [epoch: 10.2 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11872885505130737		[learning rate: 0.0017658]
	Learning Rate: 0.00176577
	LOSS [training: 0.11872885505130737 | validation: 0.10360609544498228]
	TIME [epoch: 10.2 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10750552923255478		[learning rate: 0.0017604]
	Learning Rate: 0.00176035
	LOSS [training: 0.10750552923255478 | validation: 0.12909405354683406]
	TIME [epoch: 10.3 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15849358679769196		[learning rate: 0.001755]
	Learning Rate: 0.00175496
	LOSS [training: 0.15849358679769196 | validation: 0.15727862227077552]
	TIME [epoch: 10.3 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15819730666351098		[learning rate: 0.0017496]
	Learning Rate: 0.00174958
	LOSS [training: 0.15819730666351098 | validation: 0.14639423954191813]
	TIME [epoch: 10.3 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13824945268590216		[learning rate: 0.0017442]
	Learning Rate: 0.00174421
	LOSS [training: 0.13824945268590216 | validation: 0.150730930454819]
	TIME [epoch: 10.3 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1098582769418571		[learning rate: 0.0017389]
	Learning Rate: 0.00173887
	LOSS [training: 0.1098582769418571 | validation: 0.10465541006545255]
	TIME [epoch: 10.3 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08714109623173875		[learning rate: 0.0017335]
	Learning Rate: 0.00173354
	LOSS [training: 0.08714109623173875 | validation: 0.10109502215733804]
	TIME [epoch: 10.3 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1517121954210697		[learning rate: 0.0017282]
	Learning Rate: 0.00172822
	LOSS [training: 0.1517121954210697 | validation: 0.09633862046700359]
	TIME [epoch: 10.2 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06997973343410188		[learning rate: 0.0017229]
	Learning Rate: 0.00172293
	LOSS [training: 0.06997973343410188 | validation: 0.06147810199650786]
	TIME [epoch: 10.3 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0803816472523079		[learning rate: 0.0017176]
	Learning Rate: 0.00171764
	LOSS [training: 0.0803816472523079 | validation: 0.1055835889061775]
	TIME [epoch: 10.2 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14412468568516523		[learning rate: 0.0017124]
	Learning Rate: 0.00171238
	LOSS [training: 0.14412468568516523 | validation: 0.13898655533717091]
	TIME [epoch: 10.3 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1120585817721917		[learning rate: 0.0017071]
	Learning Rate: 0.00170713
	LOSS [training: 0.1120585817721917 | validation: 0.06737764142536007]
	TIME [epoch: 10.2 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06734815925151041		[learning rate: 0.0017019]
	Learning Rate: 0.0017019
	LOSS [training: 0.06734815925151041 | validation: 0.10400399796714536]
	TIME [epoch: 10.3 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10963353957405397		[learning rate: 0.0016967]
	Learning Rate: 0.00169668
	LOSS [training: 0.10963353957405397 | validation: 0.1862730776719537]
	TIME [epoch: 10.3 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1456120230396368		[learning rate: 0.0016915]
	Learning Rate: 0.00169148
	LOSS [training: 0.1456120230396368 | validation: 0.09014628103585905]
	TIME [epoch: 10.3 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07724251298590887		[learning rate: 0.0016863]
	Learning Rate: 0.00168629
	LOSS [training: 0.07724251298590887 | validation: 0.08696460193632646]
	TIME [epoch: 10.3 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07596735736490878		[learning rate: 0.0016811]
	Learning Rate: 0.00168113
	LOSS [training: 0.07596735736490878 | validation: 0.06515260270446255]
	TIME [epoch: 10.2 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.073354461140524		[learning rate: 0.001676]
	Learning Rate: 0.00167597
	LOSS [training: 0.073354461140524 | validation: 0.04580844478404576]
	TIME [epoch: 10.2 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07200550008816743		[learning rate: 0.0016708]
	Learning Rate: 0.00167083
	LOSS [training: 0.07200550008816743 | validation: 0.06941569835786444]
	TIME [epoch: 10.3 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0652089562912983		[learning rate: 0.0016657]
	Learning Rate: 0.00166571
	LOSS [training: 0.0652089562912983 | validation: 0.07537105931310124]
	TIME [epoch: 10.2 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06966269519669654		[learning rate: 0.0016606]
	Learning Rate: 0.00166061
	LOSS [training: 0.06966269519669654 | validation: 0.0648535270595071]
	TIME [epoch: 10.2 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0676715879911118		[learning rate: 0.0016555]
	Learning Rate: 0.00165552
	LOSS [training: 0.0676715879911118 | validation: 0.07465276529718626]
	TIME [epoch: 10.2 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06786266360858074		[learning rate: 0.0016504]
	Learning Rate: 0.00165044
	LOSS [training: 0.06786266360858074 | validation: 0.054328745910750036]
	TIME [epoch: 10.2 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06615373589921675		[learning rate: 0.0016454]
	Learning Rate: 0.00164538
	LOSS [training: 0.06615373589921675 | validation: 0.10827388361493072]
	TIME [epoch: 10.2 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16810850806457966		[learning rate: 0.0016403]
	Learning Rate: 0.00164034
	LOSS [training: 0.16810850806457966 | validation: 0.23206164987027472]
	TIME [epoch: 10.2 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1880811592331892		[learning rate: 0.0016353]
	Learning Rate: 0.00163531
	LOSS [training: 0.1880811592331892 | validation: 0.13296357606520384]
	TIME [epoch: 10.2 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10626706701685158		[learning rate: 0.0016303]
	Learning Rate: 0.0016303
	LOSS [training: 0.10626706701685158 | validation: 0.1073906889143584]
	TIME [epoch: 10.3 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13147266881902703		[learning rate: 0.0016253]
	Learning Rate: 0.0016253
	LOSS [training: 0.13147266881902703 | validation: 0.20312309988097071]
	TIME [epoch: 10.2 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22878547219329085		[learning rate: 0.0016203]
	Learning Rate: 0.00162032
	LOSS [training: 0.22878547219329085 | validation: 0.1777138325224612]
	TIME [epoch: 10.2 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15797359399554364		[learning rate: 0.0016154]
	Learning Rate: 0.00161535
	LOSS [training: 0.15797359399554364 | validation: 0.10035030498365613]
	TIME [epoch: 10.2 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11129882527696851		[learning rate: 0.0016104]
	Learning Rate: 0.0016104
	LOSS [training: 0.11129882527696851 | validation: 0.07884615237926969]
	TIME [epoch: 10.2 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10735164721096765		[learning rate: 0.0016055]
	Learning Rate: 0.00160546
	LOSS [training: 0.10735164721096765 | validation: 0.052636810606181986]
	TIME [epoch: 10.2 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1297075394293416		[learning rate: 0.0016005]
	Learning Rate: 0.00160054
	LOSS [training: 0.1297075394293416 | validation: 0.13164024486997863]
	TIME [epoch: 10.2 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1504488829094338		[learning rate: 0.0015956]
	Learning Rate: 0.00159563
	LOSS [training: 0.1504488829094338 | validation: 0.07267524139862667]
	TIME [epoch: 10.1 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07890383678024875		[learning rate: 0.0015907]
	Learning Rate: 0.00159074
	LOSS [training: 0.07890383678024875 | validation: 0.07318714613303935]
	TIME [epoch: 10.2 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0747681657028524		[learning rate: 0.0015859]
	Learning Rate: 0.00158587
	LOSS [training: 0.0747681657028524 | validation: 0.05946261593900043]
	TIME [epoch: 10.2 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0602980861810581		[learning rate: 0.001581]
	Learning Rate: 0.00158101
	LOSS [training: 0.0602980861810581 | validation: 0.055702390387293466]
	TIME [epoch: 10.2 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08218593787706066		[learning rate: 0.0015762]
	Learning Rate: 0.00157616
	LOSS [training: 0.08218593787706066 | validation: 0.09313030853897432]
	TIME [epoch: 10.2 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07265106570149972		[learning rate: 0.0015713]
	Learning Rate: 0.00157133
	LOSS [training: 0.07265106570149972 | validation: 0.082692806085111]
	TIME [epoch: 10.2 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0732897369366628		[learning rate: 0.0015665]
	Learning Rate: 0.00156651
	LOSS [training: 0.0732897369366628 | validation: 0.04918334913211002]
	TIME [epoch: 10.2 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06382183340667402		[learning rate: 0.0015617]
	Learning Rate: 0.00156171
	LOSS [training: 0.06382183340667402 | validation: 0.050505184173153826]
	TIME [epoch: 10.2 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05710891908178667		[learning rate: 0.0015569]
	Learning Rate: 0.00155692
	LOSS [training: 0.05710891908178667 | validation: 0.04669893898312131]
	TIME [epoch: 10.2 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04715546348757415		[learning rate: 0.0015521]
	Learning Rate: 0.00155215
	LOSS [training: 0.04715546348757415 | validation: 0.06949571639153458]
	TIME [epoch: 10.2 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08918661995882883		[learning rate: 0.0015474]
	Learning Rate: 0.00154739
	LOSS [training: 0.08918661995882883 | validation: 0.06464934980845623]
	TIME [epoch: 10.2 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05674514171780588		[learning rate: 0.0015426]
	Learning Rate: 0.00154265
	LOSS [training: 0.05674514171780588 | validation: 0.049198025712341685]
	TIME [epoch: 10.3 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08880580298344751		[learning rate: 0.0015379]
	Learning Rate: 0.00153792
	LOSS [training: 0.08880580298344751 | validation: 0.07490243427005316]
	TIME [epoch: 10.2 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11775519113684123		[learning rate: 0.0015332]
	Learning Rate: 0.0015332
	LOSS [training: 0.11775519113684123 | validation: 0.11721817932520617]
	TIME [epoch: 10.3 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11613940258405661		[learning rate: 0.0015285]
	Learning Rate: 0.0015285
	LOSS [training: 0.11613940258405661 | validation: 0.08556494995604247]
	TIME [epoch: 10.3 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11363868187314252		[learning rate: 0.0015238]
	Learning Rate: 0.00152382
	LOSS [training: 0.11363868187314252 | validation: 0.10126409344786304]
	TIME [epoch: 10.2 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09314367776440786		[learning rate: 0.0015191]
	Learning Rate: 0.00151915
	LOSS [training: 0.09314367776440786 | validation: 0.06067410870505463]
	TIME [epoch: 10.2 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06112707714937783		[learning rate: 0.0015145]
	Learning Rate: 0.00151449
	LOSS [training: 0.06112707714937783 | validation: 0.06037745545540403]
	TIME [epoch: 10.2 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07594195557994664		[learning rate: 0.0015098]
	Learning Rate: 0.00150985
	LOSS [training: 0.07594195557994664 | validation: 0.0698324710307505]
	TIME [epoch: 10.3 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05204640091780779		[learning rate: 0.0015052]
	Learning Rate: 0.00150522
	LOSS [training: 0.05204640091780779 | validation: 0.04983329464360267]
	TIME [epoch: 10.2 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0459895395004583		[learning rate: 0.0015006]
	Learning Rate: 0.00150061
	LOSS [training: 0.0459895395004583 | validation: 0.04990691886810821]
	TIME [epoch: 10.2 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04985744641946606		[learning rate: 0.001496]
	Learning Rate: 0.00149601
	LOSS [training: 0.04985744641946606 | validation: 0.05004292645045507]
	TIME [epoch: 10.2 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06559272954076034		[learning rate: 0.0014914]
	Learning Rate: 0.00149142
	LOSS [training: 0.06559272954076034 | validation: 0.08780426123405909]
	TIME [epoch: 10.2 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07499569971078289		[learning rate: 0.0014868]
	Learning Rate: 0.00148685
	LOSS [training: 0.07499569971078289 | validation: 0.06096850421472318]
	TIME [epoch: 10.2 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06528999108861007		[learning rate: 0.0014823]
	Learning Rate: 0.00148229
	LOSS [training: 0.06528999108861007 | validation: 0.05363194298999648]
	TIME [epoch: 10.2 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08607922802152705		[learning rate: 0.0014777]
	Learning Rate: 0.00147775
	LOSS [training: 0.08607922802152705 | validation: 0.10588499976087562]
	TIME [epoch: 10.2 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10105963173390808		[learning rate: 0.0014732]
	Learning Rate: 0.00147322
	LOSS [training: 0.10105963173390808 | validation: 0.07602685261121811]
	TIME [epoch: 10.3 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09054726019475354		[learning rate: 0.0014687]
	Learning Rate: 0.0014687
	LOSS [training: 0.09054726019475354 | validation: 0.06585934544578233]
	TIME [epoch: 10.2 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0865160987097048		[learning rate: 0.0014642]
	Learning Rate: 0.0014642
	LOSS [training: 0.0865160987097048 | validation: 0.08879868466926105]
	TIME [epoch: 10.2 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08000068176101749		[learning rate: 0.0014597]
	Learning Rate: 0.00145971
	LOSS [training: 0.08000068176101749 | validation: 0.05041668662300373]
	TIME [epoch: 10.2 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06949582167820142		[learning rate: 0.0014552]
	Learning Rate: 0.00145524
	LOSS [training: 0.06949582167820142 | validation: 0.06419543381016482]
	TIME [epoch: 10.2 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05747797841878046		[learning rate: 0.0014508]
	Learning Rate: 0.00145077
	LOSS [training: 0.05747797841878046 | validation: 0.07330080725130061]
	TIME [epoch: 10.2 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055793351031082114		[learning rate: 0.0014463]
	Learning Rate: 0.00144633
	LOSS [training: 0.055793351031082114 | validation: 0.059167463780416124]
	TIME [epoch: 10.2 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05156142333154937		[learning rate: 0.0014419]
	Learning Rate: 0.00144189
	LOSS [training: 0.05156142333154937 | validation: 0.04453096074520535]
	TIME [epoch: 10.1 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04269140048858154		[learning rate: 0.0014375]
	Learning Rate: 0.00143747
	LOSS [training: 0.04269140048858154 | validation: 0.028767785901381928]
	TIME [epoch: 10.2 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04400672254027436		[learning rate: 0.0014331]
	Learning Rate: 0.00143307
	LOSS [training: 0.04400672254027436 | validation: 0.049017873586339925]
	TIME [epoch: 10.2 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04244578705248565		[learning rate: 0.0014287]
	Learning Rate: 0.00142867
	LOSS [training: 0.04244578705248565 | validation: 0.05808214984497406]
	TIME [epoch: 10.2 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04730891993531136		[learning rate: 0.0014243]
	Learning Rate: 0.0014243
	LOSS [training: 0.04730891993531136 | validation: 0.03680043573047448]
	TIME [epoch: 10.2 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053048716527504744		[learning rate: 0.0014199]
	Learning Rate: 0.00141993
	LOSS [training: 0.053048716527504744 | validation: 0.0306942023151108]
	TIME [epoch: 10.2 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0434286654722066		[learning rate: 0.0014156]
	Learning Rate: 0.00141558
	LOSS [training: 0.0434286654722066 | validation: 0.02416395598360794]
	TIME [epoch: 10.2 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04034647053688077		[learning rate: 0.0014112]
	Learning Rate: 0.00141124
	LOSS [training: 0.04034647053688077 | validation: 0.05829201137064824]
	TIME [epoch: 10.2 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047220944469257994		[learning rate: 0.0014069]
	Learning Rate: 0.00140691
	LOSS [training: 0.047220944469257994 | validation: 0.05334730968441233]
	TIME [epoch: 10.2 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0453410395114213		[learning rate: 0.0014026]
	Learning Rate: 0.0014026
	LOSS [training: 0.0453410395114213 | validation: 0.03322283615818053]
	TIME [epoch: 10.2 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04507464595871428		[learning rate: 0.0013983]
	Learning Rate: 0.0013983
	LOSS [training: 0.04507464595871428 | validation: 0.04457522621563023]
	TIME [epoch: 10.2 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04487449419670811		[learning rate: 0.001394]
	Learning Rate: 0.00139401
	LOSS [training: 0.04487449419670811 | validation: 0.04049726708465511]
	TIME [epoch: 10.2 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06017546236314224		[learning rate: 0.0013897]
	Learning Rate: 0.00138974
	LOSS [training: 0.06017546236314224 | validation: 0.11817895788991717]
	TIME [epoch: 10.2 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1765294374800722		[learning rate: 0.0013855]
	Learning Rate: 0.00138548
	LOSS [training: 0.1765294374800722 | validation: 0.16620925214601812]
	TIME [epoch: 10.2 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20846653406725957		[learning rate: 0.0013812]
	Learning Rate: 0.00138123
	LOSS [training: 0.20846653406725957 | validation: 0.16009351998364862]
	TIME [epoch: 10.2 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2509752237143404		[learning rate: 0.001377]
	Learning Rate: 0.001377
	LOSS [training: 0.2509752237143404 | validation: 0.25508524105659414]
	TIME [epoch: 10.2 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2936715599406515		[learning rate: 0.0013728]
	Learning Rate: 0.00137278
	LOSS [training: 0.2936715599406515 | validation: 0.15072020147174864]
	TIME [epoch: 10.2 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10455842948416745		[learning rate: 0.0013686]
	Learning Rate: 0.00136857
	LOSS [training: 0.10455842948416745 | validation: 0.0564368498011185]
	TIME [epoch: 10.2 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06360694799973017		[learning rate: 0.0013644]
	Learning Rate: 0.00136437
	LOSS [training: 0.06360694799973017 | validation: 0.07861627485057435]
	TIME [epoch: 10.2 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09930438005341716		[learning rate: 0.0013602]
	Learning Rate: 0.00136019
	LOSS [training: 0.09930438005341716 | validation: 0.08836244228662572]
	TIME [epoch: 10.2 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07812526477921793		[learning rate: 0.001356]
	Learning Rate: 0.00135602
	LOSS [training: 0.07812526477921793 | validation: 0.07153484142666795]
	TIME [epoch: 10.2 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06008156727114754		[learning rate: 0.0013519]
	Learning Rate: 0.00135187
	LOSS [training: 0.06008156727114754 | validation: 0.051173848426840925]
	TIME [epoch: 10.2 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055092016953685416		[learning rate: 0.0013477]
	Learning Rate: 0.00134772
	LOSS [training: 0.055092016953685416 | validation: 0.06204440793506467]
	TIME [epoch: 10.2 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05068019977437752		[learning rate: 0.0013436]
	Learning Rate: 0.00134359
	LOSS [training: 0.05068019977437752 | validation: 0.0623052113578129]
	TIME [epoch: 10.2 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07602621852823496		[learning rate: 0.0013395]
	Learning Rate: 0.00133947
	LOSS [training: 0.07602621852823496 | validation: 0.08866268590818037]
	TIME [epoch: 10.2 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08181234186519823		[learning rate: 0.0013354]
	Learning Rate: 0.00133536
	LOSS [training: 0.08181234186519823 | validation: 0.06362009338885102]
	TIME [epoch: 10.1 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062302670720589134		[learning rate: 0.0013313]
	Learning Rate: 0.00133127
	LOSS [training: 0.062302670720589134 | validation: 0.04519373531305696]
	TIME [epoch: 10.2 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04114251199466194		[learning rate: 0.0013272]
	Learning Rate: 0.00132719
	LOSS [training: 0.04114251199466194 | validation: 0.029361661959640833]
	TIME [epoch: 10.2 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04702430226360456		[learning rate: 0.0013231]
	Learning Rate: 0.00132312
	LOSS [training: 0.04702430226360456 | validation: 0.04985381501441392]
	TIME [epoch: 10.2 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04250215083378138		[learning rate: 0.0013191]
	Learning Rate: 0.00131907
	LOSS [training: 0.04250215083378138 | validation: 0.04701395938598633]
	TIME [epoch: 10.2 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05640869130074712		[learning rate: 0.001315]
	Learning Rate: 0.00131502
	LOSS [training: 0.05640869130074712 | validation: 0.0552784466366955]
	TIME [epoch: 10.2 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061313497613145494		[learning rate: 0.001311]
	Learning Rate: 0.00131099
	LOSS [training: 0.061313497613145494 | validation: 0.055735264269148654]
	TIME [epoch: 10.2 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05811339628214657		[learning rate: 0.001307]
	Learning Rate: 0.00130697
	LOSS [training: 0.05811339628214657 | validation: 0.07312818634422333]
	TIME [epoch: 10.2 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06395541712779601		[learning rate: 0.001303]
	Learning Rate: 0.00130297
	LOSS [training: 0.06395541712779601 | validation: 0.05986183492624148]
	TIME [epoch: 10.2 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05798788178274553		[learning rate: 0.001299]
	Learning Rate: 0.00129897
	LOSS [training: 0.05798788178274553 | validation: 0.09670364407607526]
	TIME [epoch: 10.3 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06952568423330688		[learning rate: 0.001295]
	Learning Rate: 0.00129499
	LOSS [training: 0.06952568423330688 | validation: 0.08608896630232547]
	TIME [epoch: 10.2 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08106537111432163		[learning rate: 0.001291]
	Learning Rate: 0.00129102
	LOSS [training: 0.08106537111432163 | validation: 0.10579905742858887]
	TIME [epoch: 10.2 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10483982064154877		[learning rate: 0.0012871]
	Learning Rate: 0.00128706
	LOSS [training: 0.10483982064154877 | validation: 0.11643726057159455]
	TIME [epoch: 10.2 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12777735687879396		[learning rate: 0.0012831]
	Learning Rate: 0.00128312
	LOSS [training: 0.12777735687879396 | validation: 0.21149831360579163]
	TIME [epoch: 10.3 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16319717550393475		[learning rate: 0.0012792]
	Learning Rate: 0.00127918
	LOSS [training: 0.16319717550393475 | validation: 0.13490221664006996]
	TIME [epoch: 10.2 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10032492062304454		[learning rate: 0.0012753]
	Learning Rate: 0.00127526
	LOSS [training: 0.10032492062304454 | validation: 0.10219725141736405]
	TIME [epoch: 10.2 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07813769547350724		[learning rate: 0.0012714]
	Learning Rate: 0.00127135
	LOSS [training: 0.07813769547350724 | validation: 0.1003042345123172]
	TIME [epoch: 10.2 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0898316828529052		[learning rate: 0.0012675]
	Learning Rate: 0.00126746
	LOSS [training: 0.0898316828529052 | validation: 0.09444888996718558]
	TIME [epoch: 10.2 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10718008826995928		[learning rate: 0.0012636]
	Learning Rate: 0.00126357
	LOSS [training: 0.10718008826995928 | validation: 0.11001979055033052]
	TIME [epoch: 10.2 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12829281926537514		[learning rate: 0.0012597]
	Learning Rate: 0.0012597
	LOSS [training: 0.12829281926537514 | validation: 0.20213400924927682]
	TIME [epoch: 10.2 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18359211701527173		[learning rate: 0.0012558]
	Learning Rate: 0.00125584
	LOSS [training: 0.18359211701527173 | validation: 0.212342714637713]
	TIME [epoch: 10.2 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15402195180052067		[learning rate: 0.001252]
	Learning Rate: 0.00125199
	LOSS [training: 0.15402195180052067 | validation: 0.13844599764599413]
	TIME [epoch: 10.3 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1110373111021663		[learning rate: 0.0012481]
	Learning Rate: 0.00124815
	LOSS [training: 0.1110373111021663 | validation: 0.11722798703724344]
	TIME [epoch: 10.2 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10940861628682888		[learning rate: 0.0012443]
	Learning Rate: 0.00124432
	LOSS [training: 0.10940861628682888 | validation: 0.1390587314384494]
	TIME [epoch: 10.2 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09772919717765483		[learning rate: 0.0012405]
	Learning Rate: 0.00124051
	LOSS [training: 0.09772919717765483 | validation: 0.1123179205379927]
	TIME [epoch: 10.2 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08575319730290638		[learning rate: 0.0012367]
	Learning Rate: 0.00123671
	LOSS [training: 0.08575319730290638 | validation: 0.09772318258098181]
	TIME [epoch: 10.3 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08703430792198948		[learning rate: 0.0012329]
	Learning Rate: 0.00123292
	LOSS [training: 0.08703430792198948 | validation: 0.06517482057093502]
	TIME [epoch: 10.3 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09834503060530937		[learning rate: 0.0012291]
	Learning Rate: 0.00122914
	LOSS [training: 0.09834503060530937 | validation: 0.1008986854830604]
	TIME [epoch: 10.3 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10402058555699308		[learning rate: 0.0012254]
	Learning Rate: 0.00122537
	LOSS [training: 0.10402058555699308 | validation: 0.08025357620056156]
	TIME [epoch: 10.2 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12069416194952431		[learning rate: 0.0012216]
	Learning Rate: 0.00122161
	LOSS [training: 0.12069416194952431 | validation: 0.09703652835724619]
	TIME [epoch: 10.3 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13060331681045584		[learning rate: 0.0012179]
	Learning Rate: 0.00121787
	LOSS [training: 0.13060331681045584 | validation: 0.09083585793102256]
	TIME [epoch: 10.2 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10807247861857186		[learning rate: 0.0012141]
	Learning Rate: 0.00121413
	LOSS [training: 0.10807247861857186 | validation: 0.04111997633047384]
	TIME [epoch: 10.3 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050520489847771924		[learning rate: 0.0012104]
	Learning Rate: 0.00121041
	LOSS [training: 0.050520489847771924 | validation: 0.04118958404127401]
	TIME [epoch: 10.3 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05076887897880492		[learning rate: 0.0012067]
	Learning Rate: 0.0012067
	LOSS [training: 0.05076887897880492 | validation: 0.03707390235138056]
	TIME [epoch: 10.3 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0449841541335231		[learning rate: 0.001203]
	Learning Rate: 0.001203
	LOSS [training: 0.0449841541335231 | validation: 0.0329553326607928]
	TIME [epoch: 10.2 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05485410159860711		[learning rate: 0.0011993]
	Learning Rate: 0.00119932
	LOSS [training: 0.05485410159860711 | validation: 0.06649495688594335]
	TIME [epoch: 10.2 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04593851712788537		[learning rate: 0.0011956]
	Learning Rate: 0.00119564
	LOSS [training: 0.04593851712788537 | validation: 0.04291103898713417]
	TIME [epoch: 10.2 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048411622662677754		[learning rate: 0.001192]
	Learning Rate: 0.00119197
	LOSS [training: 0.048411622662677754 | validation: 0.03882083633477882]
	TIME [epoch: 10.3 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03546339994101005		[learning rate: 0.0011883]
	Learning Rate: 0.00118832
	LOSS [training: 0.03546339994101005 | validation: 0.04204746523102456]
	TIME [epoch: 10.3 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039751716263862126		[learning rate: 0.0011847]
	Learning Rate: 0.00118468
	LOSS [training: 0.039751716263862126 | validation: 0.07322471747081052]
	TIME [epoch: 10.3 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08668488675874822		[learning rate: 0.001181]
	Learning Rate: 0.00118105
	LOSS [training: 0.08668488675874822 | validation: 0.05064103495176998]
	TIME [epoch: 10.3 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05168639149282288		[learning rate: 0.0011774]
	Learning Rate: 0.00117743
	LOSS [training: 0.05168639149282288 | validation: 0.03275135507532744]
	TIME [epoch: 10.3 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03922706362738711		[learning rate: 0.0011738]
	Learning Rate: 0.00117382
	LOSS [training: 0.03922706362738711 | validation: 0.049627153255461895]
	TIME [epoch: 10.3 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047332394897113994		[learning rate: 0.0011702]
	Learning Rate: 0.00117022
	LOSS [training: 0.047332394897113994 | validation: 0.04874018235192111]
	TIME [epoch: 10.3 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07474326623066592		[learning rate: 0.0011666]
	Learning Rate: 0.00116663
	LOSS [training: 0.07474326623066592 | validation: 0.06961782474479308]
	TIME [epoch: 10.3 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07205534726957444		[learning rate: 0.0011631]
	Learning Rate: 0.00116305
	LOSS [training: 0.07205534726957444 | validation: 0.08097529797838877]
	TIME [epoch: 10.3 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08799403531375889		[learning rate: 0.0011595]
	Learning Rate: 0.00115949
	LOSS [training: 0.08799403531375889 | validation: 0.07309210574694174]
	TIME [epoch: 10.2 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06522431832392364		[learning rate: 0.0011559]
	Learning Rate: 0.00115593
	LOSS [training: 0.06522431832392364 | validation: 0.05649013108379625]
	TIME [epoch: 10.2 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053319388634009715		[learning rate: 0.0011524]
	Learning Rate: 0.00115239
	LOSS [training: 0.053319388634009715 | validation: 0.05028422551124476]
	TIME [epoch: 10.3 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057936636495781756		[learning rate: 0.0011489]
	Learning Rate: 0.00114886
	LOSS [training: 0.057936636495781756 | validation: 0.06598086979428588]
	TIME [epoch: 10.3 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06086922668361454		[learning rate: 0.0011453]
	Learning Rate: 0.00114534
	LOSS [training: 0.06086922668361454 | validation: 0.037615709492927904]
	TIME [epoch: 10.2 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05043680733198751		[learning rate: 0.0011418]
	Learning Rate: 0.00114183
	LOSS [training: 0.05043680733198751 | validation: 0.050714350319979735]
	TIME [epoch: 10.3 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04264862489706508		[learning rate: 0.0011383]
	Learning Rate: 0.00113833
	LOSS [training: 0.04264862489706508 | validation: 0.045753006919970106]
	TIME [epoch: 10.3 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047601051693507264		[learning rate: 0.0011348]
	Learning Rate: 0.00113484
	LOSS [training: 0.047601051693507264 | validation: 0.06443197873780046]
	TIME [epoch: 10.3 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053125992534938084		[learning rate: 0.0011314]
	Learning Rate: 0.00113136
	LOSS [training: 0.053125992534938084 | validation: 0.05356502287835825]
	TIME [epoch: 10.3 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05883600926603024		[learning rate: 0.0011279]
	Learning Rate: 0.00112789
	LOSS [training: 0.05883600926603024 | validation: 0.0647573376884939]
	TIME [epoch: 10.3 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0781534336173945		[learning rate: 0.0011244]
	Learning Rate: 0.00112443
	LOSS [training: 0.0781534336173945 | validation: 0.09213300305919882]
	TIME [epoch: 10.3 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08541150109889181		[learning rate: 0.001121]
	Learning Rate: 0.00112099
	LOSS [training: 0.08541150109889181 | validation: 0.05901574766619529]
	TIME [epoch: 10.3 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05911453579669777		[learning rate: 0.0011175]
	Learning Rate: 0.00111755
	LOSS [training: 0.05911453579669777 | validation: 0.0750362172010919]
	TIME [epoch: 10.3 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06248461748127202		[learning rate: 0.0011141]
	Learning Rate: 0.00111412
	LOSS [training: 0.06248461748127202 | validation: 0.043945828431244296]
	TIME [epoch: 10.3 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05170443020491246		[learning rate: 0.0011107]
	Learning Rate: 0.00111071
	LOSS [training: 0.05170443020491246 | validation: 0.0399152741245222]
	TIME [epoch: 10.3 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03807153473978719		[learning rate: 0.0011073]
	Learning Rate: 0.0011073
	LOSS [training: 0.03807153473978719 | validation: 0.029842975507329252]
	TIME [epoch: 10.3 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04239016728473531		[learning rate: 0.0011039]
	Learning Rate: 0.00110391
	LOSS [training: 0.04239016728473531 | validation: 0.05965928543979557]
	TIME [epoch: 10.3 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061783978960116614		[learning rate: 0.0011005]
	Learning Rate: 0.00110053
	LOSS [training: 0.061783978960116614 | validation: 0.05596719076099385]
	TIME [epoch: 10.2 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045447033717685506		[learning rate: 0.0010972]
	Learning Rate: 0.00109715
	LOSS [training: 0.045447033717685506 | validation: 0.05536371737090379]
	TIME [epoch: 10.2 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05741875071686851		[learning rate: 0.0010938]
	Learning Rate: 0.00109379
	LOSS [training: 0.05741875071686851 | validation: 0.06317209174861692]
	TIME [epoch: 10.3 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07261378519545693		[learning rate: 0.0010904]
	Learning Rate: 0.00109044
	LOSS [training: 0.07261378519545693 | validation: 0.0723192973012816]
	TIME [epoch: 10.3 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06145809650906271		[learning rate: 0.0010871]
	Learning Rate: 0.00108709
	LOSS [training: 0.06145809650906271 | validation: 0.06321853834579756]
	TIME [epoch: 10.3 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06820989171013073		[learning rate: 0.0010838]
	Learning Rate: 0.00108376
	LOSS [training: 0.06820989171013073 | validation: 0.0778112091224791]
	TIME [epoch: 10.3 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07312668023708108		[learning rate: 0.0010804]
	Learning Rate: 0.00108044
	LOSS [training: 0.07312668023708108 | validation: 0.07167019938382793]
	TIME [epoch: 10.2 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061320072000071765		[learning rate: 0.0010771]
	Learning Rate: 0.00107713
	LOSS [training: 0.061320072000071765 | validation: 0.06475962143490457]
	TIME [epoch: 10.2 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05670200874085653		[learning rate: 0.0010738]
	Learning Rate: 0.00107382
	LOSS [training: 0.05670200874085653 | validation: 0.0561683941654374]
	TIME [epoch: 10.2 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05794945068498464		[learning rate: 0.0010705]
	Learning Rate: 0.00107053
	LOSS [training: 0.05794945068498464 | validation: 0.056174974633189885]
	TIME [epoch: 10.3 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059632448693975736		[learning rate: 0.0010673]
	Learning Rate: 0.00106725
	LOSS [training: 0.059632448693975736 | validation: 0.03323620516380686]
	TIME [epoch: 10.3 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04098444023842765		[learning rate: 0.001064]
	Learning Rate: 0.00106398
	LOSS [training: 0.04098444023842765 | validation: 0.04633555465712476]
	TIME [epoch: 10.3 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046868483949824846		[learning rate: 0.0010607]
	Learning Rate: 0.00106072
	LOSS [training: 0.046868483949824846 | validation: 0.05152755723965597]
	TIME [epoch: 10.3 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08290373839491623		[learning rate: 0.0010575]
	Learning Rate: 0.00105747
	LOSS [training: 0.08290373839491623 | validation: 0.0804971194657985]
	TIME [epoch: 10.3 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08307266132951076		[learning rate: 0.0010542]
	Learning Rate: 0.00105422
	LOSS [training: 0.08307266132951076 | validation: 0.07313667086600671]
	TIME [epoch: 10.3 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1015139144451022		[learning rate: 0.001051]
	Learning Rate: 0.00105099
	LOSS [training: 0.1015139144451022 | validation: 0.08688608673086058]
	TIME [epoch: 10.3 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0656796522486067		[learning rate: 0.0010478]
	Learning Rate: 0.00104777
	LOSS [training: 0.0656796522486067 | validation: 0.05248426557494394]
	TIME [epoch: 10.3 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04486082832394923		[learning rate: 0.0010446]
	Learning Rate: 0.00104456
	LOSS [training: 0.04486082832394923 | validation: 0.03889379538203778]
	TIME [epoch: 10.2 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04643560666016659		[learning rate: 0.0010414]
	Learning Rate: 0.00104136
	LOSS [training: 0.04643560666016659 | validation: 0.03182598091261767]
	TIME [epoch: 10.3 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048245861725808685		[learning rate: 0.0010382]
	Learning Rate: 0.00103817
	LOSS [training: 0.048245861725808685 | validation: 0.06630316988637487]
	TIME [epoch: 10.3 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06973330150974563		[learning rate: 0.001035]
	Learning Rate: 0.00103498
	LOSS [training: 0.06973330150974563 | validation: 0.06654135864125538]
	TIME [epoch: 10.3 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05533667880439893		[learning rate: 0.0010318]
	Learning Rate: 0.00103181
	LOSS [training: 0.05533667880439893 | validation: 0.06449757784439086]
	TIME [epoch: 10.3 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057924013281751764		[learning rate: 0.0010286]
	Learning Rate: 0.00102865
	LOSS [training: 0.057924013281751764 | validation: 0.08812114277187728]
	TIME [epoch: 10.3 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06514188017368033		[learning rate: 0.0010255]
	Learning Rate: 0.00102549
	LOSS [training: 0.06514188017368033 | validation: 0.06024158572666316]
	TIME [epoch: 10.3 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058574962317732224		[learning rate: 0.0010224]
	Learning Rate: 0.00102235
	LOSS [training: 0.058574962317732224 | validation: 0.062166026543072524]
	TIME [epoch: 10.3 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06492985077829741		[learning rate: 0.0010192]
	Learning Rate: 0.00101922
	LOSS [training: 0.06492985077829741 | validation: 0.04680632587325222]
	TIME [epoch: 10.3 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06095284142437688		[learning rate: 0.0010161]
	Learning Rate: 0.00101609
	LOSS [training: 0.06095284142437688 | validation: 0.07905372460136552]
	TIME [epoch: 10.3 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11651101309901712		[learning rate: 0.001013]
	Learning Rate: 0.00101298
	LOSS [training: 0.11651101309901712 | validation: 0.12294087064605552]
	TIME [epoch: 10.3 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11808238775936915		[learning rate: 0.0010099]
	Learning Rate: 0.00100987
	LOSS [training: 0.11808238775936915 | validation: 0.09542437279082805]
	TIME [epoch: 10.3 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07140442678953378		[learning rate: 0.0010068]
	Learning Rate: 0.00100678
	LOSS [training: 0.07140442678953378 | validation: 0.05775796841307752]
	TIME [epoch: 10.2 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05330574234493357		[learning rate: 0.0010037]
	Learning Rate: 0.00100369
	LOSS [training: 0.05330574234493357 | validation: 0.0510939540029392]
	TIME [epoch: 10.3 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04902265643402607		[learning rate: 0.0010006]
	Learning Rate: 0.00100061
	LOSS [training: 0.04902265643402607 | validation: 0.04443157472638868]
	TIME [epoch: 10.3 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053064704000082286		[learning rate: 0.00099755]
	Learning Rate: 0.000997547
	LOSS [training: 0.053064704000082286 | validation: 0.04649862970713551]
	TIME [epoch: 10.3 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05208648408448822		[learning rate: 0.00099449]
	Learning Rate: 0.000994489
	LOSS [training: 0.05208648408448822 | validation: 0.05118611185597725]
	TIME [epoch: 10.3 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04636251149433678		[learning rate: 0.00099144]
	Learning Rate: 0.00099144
	LOSS [training: 0.04636251149433678 | validation: 0.05929324437244407]
	TIME [epoch: 10.3 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05178186788701196		[learning rate: 0.0009884]
	Learning Rate: 0.000988401
	LOSS [training: 0.05178186788701196 | validation: 0.07052954052863554]
	TIME [epoch: 10.3 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08287117810846595		[learning rate: 0.00098537]
	Learning Rate: 0.000985371
	LOSS [training: 0.08287117810846595 | validation: 0.12368507189637182]
	TIME [epoch: 10.3 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13893937934406117		[learning rate: 0.00098235]
	Learning Rate: 0.000982351
	LOSS [training: 0.13893937934406117 | validation: 0.15165652981511785]
	TIME [epoch: 10.3 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12151582238324939		[learning rate: 0.00097934]
	Learning Rate: 0.000979339
	LOSS [training: 0.12151582238324939 | validation: 0.10629131551213644]
	TIME [epoch: 10.3 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09467875571739111		[learning rate: 0.00097634]
	Learning Rate: 0.000976337
	LOSS [training: 0.09467875571739111 | validation: 0.0927571594138528]
	TIME [epoch: 10.3 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0732443635421925		[learning rate: 0.00097334]
	Learning Rate: 0.000973345
	LOSS [training: 0.0732443635421925 | validation: 0.08750768539732459]
	TIME [epoch: 10.2 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08728234006058455		[learning rate: 0.00097036]
	Learning Rate: 0.000970361
	LOSS [training: 0.08728234006058455 | validation: 0.07188162397187826]
	TIME [epoch: 10.3 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.081681081107532		[learning rate: 0.00096739]
	Learning Rate: 0.000967386
	LOSS [training: 0.081681081107532 | validation: 0.07575465682554848]
	TIME [epoch: 10.3 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056968514843885674		[learning rate: 0.00096442]
	Learning Rate: 0.000964421
	LOSS [training: 0.056968514843885674 | validation: 0.06407389339910796]
	TIME [epoch: 10.3 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06329916130601336		[learning rate: 0.00096146]
	Learning Rate: 0.000961464
	LOSS [training: 0.06329916130601336 | validation: 0.0697016042159914]
	TIME [epoch: 10.2 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08806539889137925		[learning rate: 0.00095852]
	Learning Rate: 0.000958517
	LOSS [training: 0.08806539889137925 | validation: 0.10322030531276342]
	TIME [epoch: 10.3 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09954603757414768		[learning rate: 0.00095558]
	Learning Rate: 0.000955579
	LOSS [training: 0.09954603757414768 | validation: 0.15276482108375283]
	TIME [epoch: 10.3 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12970897514430443		[learning rate: 0.00095265]
	Learning Rate: 0.00095265
	LOSS [training: 0.12970897514430443 | validation: 0.10733344277401478]
	TIME [epoch: 10.3 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13716046544240434		[learning rate: 0.00094973]
	Learning Rate: 0.00094973
	LOSS [training: 0.13716046544240434 | validation: 0.1690992778830615]
	TIME [epoch: 10.3 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20914629194870163		[learning rate: 0.00094682]
	Learning Rate: 0.000946818
	LOSS [training: 0.20914629194870163 | validation: 0.2143197864874506]
	TIME [epoch: 10.3 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19814035379008335		[learning rate: 0.00094392]
	Learning Rate: 0.000943916
	LOSS [training: 0.19814035379008335 | validation: 0.23341029389979764]
	TIME [epoch: 10.3 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25660433924214443		[learning rate: 0.00094102]
	Learning Rate: 0.000941023
	LOSS [training: 0.25660433924214443 | validation: 0.3450387510971013]
	TIME [epoch: 10.3 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3712183084220189		[learning rate: 0.00093814]
	Learning Rate: 0.000938138
	LOSS [training: 0.3712183084220189 | validation: 0.3417277318024196]
	TIME [epoch: 10.3 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3022988876129319		[learning rate: 0.00093526]
	Learning Rate: 0.000935262
	LOSS [training: 0.3022988876129319 | validation: 0.25167781196733324]
	TIME [epoch: 10.3 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1895094059986941		[learning rate: 0.0009324]
	Learning Rate: 0.000932395
	LOSS [training: 0.1895094059986941 | validation: 0.1342020003900318]
	TIME [epoch: 10.3 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16968332306181944		[learning rate: 0.00092954]
	Learning Rate: 0.000929537
	LOSS [training: 0.16968332306181944 | validation: 0.202590108762516]
	TIME [epoch: 10.3 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24917932459454764		[learning rate: 0.00092669]
	Learning Rate: 0.000926688
	LOSS [training: 0.24917932459454764 | validation: 0.25016452954265883]
	TIME [epoch: 10.3 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1805685910911201		[learning rate: 0.00092385]
	Learning Rate: 0.000923847
	LOSS [training: 0.1805685910911201 | validation: 0.13951783203972726]
	TIME [epoch: 10.3 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16312486189211678		[learning rate: 0.00092101]
	Learning Rate: 0.000921015
	LOSS [training: 0.16312486189211678 | validation: 0.20245196888791583]
	TIME [epoch: 10.3 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1955601515426721		[learning rate: 0.00091819]
	Learning Rate: 0.000918192
	LOSS [training: 0.1955601515426721 | validation: 0.1751158451277368]
	TIME [epoch: 10.3 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17492432892541823		[learning rate: 0.00091538]
	Learning Rate: 0.000915377
	LOSS [training: 0.17492432892541823 | validation: 0.13347991665372205]
	TIME [epoch: 10.3 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14357321200632553		[learning rate: 0.00091257]
	Learning Rate: 0.000912571
	LOSS [training: 0.14357321200632553 | validation: 0.12787001014434055]
	TIME [epoch: 10.3 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12098689524864818		[learning rate: 0.00090977]
	Learning Rate: 0.000909774
	LOSS [training: 0.12098689524864818 | validation: 0.09793437958162786]
	TIME [epoch: 10.3 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1001351326994119		[learning rate: 0.00090698]
	Learning Rate: 0.000906985
	LOSS [training: 0.1001351326994119 | validation: 0.07100420244799788]
	TIME [epoch: 10.3 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0992868496720518		[learning rate: 0.0009042]
	Learning Rate: 0.000904204
	LOSS [training: 0.0992868496720518 | validation: 0.08256144530793436]
	TIME [epoch: 10.2 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1387526156616409		[learning rate: 0.00090143]
	Learning Rate: 0.000901433
	LOSS [training: 0.1387526156616409 | validation: 0.07730843791414657]
	TIME [epoch: 10.3 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11234428751698944		[learning rate: 0.00089867]
	Learning Rate: 0.000898669
	LOSS [training: 0.11234428751698944 | validation: 0.09555083983951654]
	TIME [epoch: 10.2 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1188554268642212		[learning rate: 0.00089591]
	Learning Rate: 0.000895915
	LOSS [training: 0.1188554268642212 | validation: 0.08581870745009589]
	TIME [epoch: 10.3 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11824984553710902		[learning rate: 0.00089317]
	Learning Rate: 0.000893168
	LOSS [training: 0.11824984553710902 | validation: 0.08278754237142115]
	TIME [epoch: 10.2 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10238961969810156		[learning rate: 0.00089043]
	Learning Rate: 0.00089043
	LOSS [training: 0.10238961969810156 | validation: 0.06701576667491978]
	TIME [epoch: 10.3 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09558948745676028		[learning rate: 0.0008877]
	Learning Rate: 0.000887701
	LOSS [training: 0.09558948745676028 | validation: 0.05838957359089097]
	TIME [epoch: 10.3 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08779000342200885		[learning rate: 0.00088498]
	Learning Rate: 0.00088498
	LOSS [training: 0.08779000342200885 | validation: 0.06396582599090876]
	TIME [epoch: 10.3 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08375638094943967		[learning rate: 0.00088227]
	Learning Rate: 0.000882267
	LOSS [training: 0.08375638094943967 | validation: 0.06319305628430305]
	TIME [epoch: 10.3 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08824916228843259		[learning rate: 0.00087956]
	Learning Rate: 0.000879562
	LOSS [training: 0.08824916228843259 | validation: 0.08474508289401826]
	TIME [epoch: 10.3 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1112927425271975		[learning rate: 0.00087687]
	Learning Rate: 0.000876866
	LOSS [training: 0.1112927425271975 | validation: 0.11018798162637886]
	TIME [epoch: 10.3 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1138247931053539		[learning rate: 0.00087418]
	Learning Rate: 0.000874178
	LOSS [training: 0.1138247931053539 | validation: 0.07556327573927624]
	TIME [epoch: 10.3 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10280631844860574		[learning rate: 0.0008715]
	Learning Rate: 0.000871498
	LOSS [training: 0.10280631844860574 | validation: 0.11340512390191532]
	TIME [epoch: 10.2 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10706199420341603		[learning rate: 0.00086883]
	Learning Rate: 0.000868827
	LOSS [training: 0.10706199420341603 | validation: 0.079773493732835]
	TIME [epoch: 10.3 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08607844622952451		[learning rate: 0.00086616]
	Learning Rate: 0.000866164
	LOSS [training: 0.08607844622952451 | validation: 0.0965243059185405]
	TIME [epoch: 10.2 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1194593422409905		[learning rate: 0.00086351]
	Learning Rate: 0.000863509
	LOSS [training: 0.1194593422409905 | validation: 0.11174101904867927]
	TIME [epoch: 10.3 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08938021564381131		[learning rate: 0.00086086]
	Learning Rate: 0.000860861
	LOSS [training: 0.08938021564381131 | validation: 0.1002297493140637]
	TIME [epoch: 10.3 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09469490471785375		[learning rate: 0.00085822]
	Learning Rate: 0.000858223
	LOSS [training: 0.09469490471785375 | validation: 0.09343901327050974]
	TIME [epoch: 10.3 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08533803491492448		[learning rate: 0.00085559]
	Learning Rate: 0.000855592
	LOSS [training: 0.08533803491492448 | validation: 0.07095528853648948]
	TIME [epoch: 10.3 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05676661802610058		[learning rate: 0.00085297]
	Learning Rate: 0.000852969
	LOSS [training: 0.05676661802610058 | validation: 0.041135949048875846]
	TIME [epoch: 10.3 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04419171937480183		[learning rate: 0.00085035]
	Learning Rate: 0.000850354
	LOSS [training: 0.04419171937480183 | validation: 0.04335522061881073]
	TIME [epoch: 10.3 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050299788919349844		[learning rate: 0.00084775]
	Learning Rate: 0.000847748
	LOSS [training: 0.050299788919349844 | validation: 0.028201509254923804]
	TIME [epoch: 10.3 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04252799321049582		[learning rate: 0.00084515]
	Learning Rate: 0.000845149
	LOSS [training: 0.04252799321049582 | validation: 0.034258906970925165]
	TIME [epoch: 10.3 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04955602415849088		[learning rate: 0.00084256]
	Learning Rate: 0.000842558
	LOSS [training: 0.04955602415849088 | validation: 0.0701403194567201]
	TIME [epoch: 10.3 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06895016519824616		[learning rate: 0.00083998]
	Learning Rate: 0.000839976
	LOSS [training: 0.06895016519824616 | validation: 0.07801009444088183]
	TIME [epoch: 10.3 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08895178283629442		[learning rate: 0.0008374]
	Learning Rate: 0.000837401
	LOSS [training: 0.08895178283629442 | validation: 0.08501253571091746]
	TIME [epoch: 10.3 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0771687595563466		[learning rate: 0.00083483]
	Learning Rate: 0.000834834
	LOSS [training: 0.0771687595563466 | validation: 0.06960939988836465]
	TIME [epoch: 10.3 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07107561740444553		[learning rate: 0.00083227]
	Learning Rate: 0.000832274
	LOSS [training: 0.07107561740444553 | validation: 0.059225278992443176]
	TIME [epoch: 10.3 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08673804174981173		[learning rate: 0.00082972]
	Learning Rate: 0.000829723
	LOSS [training: 0.08673804174981173 | validation: 0.06811483326753877]
	TIME [epoch: 10.3 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07561088725222818		[learning rate: 0.00082718]
	Learning Rate: 0.00082718
	LOSS [training: 0.07561088725222818 | validation: 0.05131431467601809]
	TIME [epoch: 10.3 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0606262792082907		[learning rate: 0.00082464]
	Learning Rate: 0.000824644
	LOSS [training: 0.0606262792082907 | validation: 0.04218036767693411]
	TIME [epoch: 10.3 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06186594406400333		[learning rate: 0.00082212]
	Learning Rate: 0.000822116
	LOSS [training: 0.06186594406400333 | validation: 0.03531771842776876]
	TIME [epoch: 10.3 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04897433095706338		[learning rate: 0.0008196]
	Learning Rate: 0.000819596
	LOSS [training: 0.04897433095706338 | validation: 0.04987386891557996]
	TIME [epoch: 10.3 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05715209845299675		[learning rate: 0.00081708]
	Learning Rate: 0.000817084
	LOSS [training: 0.05715209845299675 | validation: 0.047849483314788874]
	TIME [epoch: 10.3 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04803846470188324		[learning rate: 0.00081458]
	Learning Rate: 0.000814579
	LOSS [training: 0.04803846470188324 | validation: 0.047689833962118844]
	TIME [epoch: 10.3 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04316165448169035		[learning rate: 0.00081208]
	Learning Rate: 0.000812082
	LOSS [training: 0.04316165448169035 | validation: 0.03826863224451206]
	TIME [epoch: 10.3 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06276423744316675		[learning rate: 0.00080959]
	Learning Rate: 0.000809593
	LOSS [training: 0.06276423744316675 | validation: 0.041227381322249776]
	TIME [epoch: 10.3 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05290004137501927		[learning rate: 0.00080711]
	Learning Rate: 0.000807111
	LOSS [training: 0.05290004137501927 | validation: 0.044641534524794066]
	TIME [epoch: 10.3 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06675460063029845		[learning rate: 0.00080464]
	Learning Rate: 0.000804637
	LOSS [training: 0.06675460063029845 | validation: 0.06929541899083728]
	TIME [epoch: 10.3 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06527015156949459		[learning rate: 0.00080217]
	Learning Rate: 0.00080217
	LOSS [training: 0.06527015156949459 | validation: 0.055136181245433936]
	TIME [epoch: 10.3 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05181408104203924		[learning rate: 0.00079971]
	Learning Rate: 0.000799712
	LOSS [training: 0.05181408104203924 | validation: 0.049322920830940795]
	TIME [epoch: 10.3 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06703700516143879		[learning rate: 0.00079726]
	Learning Rate: 0.00079726
	LOSS [training: 0.06703700516143879 | validation: 0.07544984797496604]
	TIME [epoch: 10.3 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09576359923691873		[learning rate: 0.00079482]
	Learning Rate: 0.000794816
	LOSS [training: 0.09576359923691873 | validation: 0.06408052433950395]
	TIME [epoch: 10.3 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07350048833570606		[learning rate: 0.00079238]
	Learning Rate: 0.00079238
	LOSS [training: 0.07350048833570606 | validation: 0.04847529044762821]
	TIME [epoch: 10.3 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05904282538395694		[learning rate: 0.00078995]
	Learning Rate: 0.000789951
	LOSS [training: 0.05904282538395694 | validation: 0.04426887786688601]
	TIME [epoch: 10.3 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049674061023647964		[learning rate: 0.00078753]
	Learning Rate: 0.000787529
	LOSS [training: 0.049674061023647964 | validation: 0.026183679783518973]
	TIME [epoch: 10.3 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052779540153593804		[learning rate: 0.00078512]
	Learning Rate: 0.000785115
	LOSS [training: 0.052779540153593804 | validation: 0.03570937501724171]
	TIME [epoch: 10.3 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04803880386094454		[learning rate: 0.00078271]
	Learning Rate: 0.000782708
	LOSS [training: 0.04803880386094454 | validation: 0.04888993100778232]
	TIME [epoch: 10.3 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07386050319644524		[learning rate: 0.00078031]
	Learning Rate: 0.000780309
	LOSS [training: 0.07386050319644524 | validation: 0.06542999889424263]
	TIME [epoch: 10.3 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0848334684390214		[learning rate: 0.00077792]
	Learning Rate: 0.000777917
	LOSS [training: 0.0848334684390214 | validation: 0.09065578157872907]
	TIME [epoch: 10.3 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.090538397803542		[learning rate: 0.00077553]
	Learning Rate: 0.000775533
	LOSS [training: 0.090538397803542 | validation: 0.07980092369985833]
	TIME [epoch: 10.3 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0767197629870319		[learning rate: 0.00077316]
	Learning Rate: 0.000773155
	LOSS [training: 0.0767197629870319 | validation: 0.06780683394343458]
	TIME [epoch: 10.3 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10248022036678495		[learning rate: 0.00077079]
	Learning Rate: 0.000770785
	LOSS [training: 0.10248022036678495 | validation: 0.07857850789555887]
	TIME [epoch: 10.3 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08986264149432646		[learning rate: 0.00076842]
	Learning Rate: 0.000768422
	LOSS [training: 0.08986264149432646 | validation: 0.06185586907116816]
	TIME [epoch: 10.3 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09150249842810235		[learning rate: 0.00076607]
	Learning Rate: 0.000766067
	LOSS [training: 0.09150249842810235 | validation: 0.09536827003562913]
	TIME [epoch: 10.3 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11060192807989386		[learning rate: 0.00076372]
	Learning Rate: 0.000763719
	LOSS [training: 0.11060192807989386 | validation: 0.09136529791805309]
	TIME [epoch: 10.3 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09744907478959691		[learning rate: 0.00076138]
	Learning Rate: 0.000761377
	LOSS [training: 0.09744907478959691 | validation: 0.07353702260984314]
	TIME [epoch: 10.3 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08063682589107185		[learning rate: 0.00075904]
	Learning Rate: 0.000759043
	LOSS [training: 0.08063682589107185 | validation: 0.05678913551490664]
	TIME [epoch: 10.3 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08164169433328311		[learning rate: 0.00075672]
	Learning Rate: 0.000756717
	LOSS [training: 0.08164169433328311 | validation: 0.05822611211811658]
	TIME [epoch: 10.3 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07274170763384608		[learning rate: 0.0007544]
	Learning Rate: 0.000754397
	LOSS [training: 0.07274170763384608 | validation: 0.06954167657711642]
	TIME [epoch: 10.3 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07022773775842604		[learning rate: 0.00075208]
	Learning Rate: 0.000752084
	LOSS [training: 0.07022773775842604 | validation: 0.037138204125065334]
	TIME [epoch: 10.3 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06316336017584043		[learning rate: 0.00074978]
	Learning Rate: 0.000749779
	LOSS [training: 0.06316336017584043 | validation: 0.05288137973957322]
	TIME [epoch: 10.3 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055765075351735506		[learning rate: 0.00074748]
	Learning Rate: 0.000747481
	LOSS [training: 0.055765075351735506 | validation: 0.03489769101064297]
	TIME [epoch: 10.3 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0671323943288346		[learning rate: 0.00074519]
	Learning Rate: 0.000745189
	LOSS [training: 0.0671323943288346 | validation: 0.04870110164958584]
	TIME [epoch: 10.3 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06703664556015351		[learning rate: 0.0007429]
	Learning Rate: 0.000742905
	LOSS [training: 0.06703664556015351 | validation: 0.047286299258674315]
	TIME [epoch: 10.3 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05644525040747058		[learning rate: 0.00074063]
	Learning Rate: 0.000740628
	LOSS [training: 0.05644525040747058 | validation: 0.05066341270827225]
	TIME [epoch: 10.3 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05519136414529484		[learning rate: 0.00073836]
	Learning Rate: 0.000738357
	LOSS [training: 0.05519136414529484 | validation: 0.043918683132064686]
	TIME [epoch: 10.2 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054705138928863986		[learning rate: 0.00073609]
	Learning Rate: 0.000736094
	LOSS [training: 0.054705138928863986 | validation: 0.05259223828900687]
	TIME [epoch: 10.3 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059242315668632264		[learning rate: 0.00073384]
	Learning Rate: 0.000733838
	LOSS [training: 0.059242315668632264 | validation: 0.04128612130865388]
	TIME [epoch: 10.2 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06016816933343645		[learning rate: 0.00073159]
	Learning Rate: 0.000731588
	LOSS [training: 0.06016816933343645 | validation: 0.04695104856031426]
	TIME [epoch: 10.2 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05191964915495506		[learning rate: 0.00072935]
	Learning Rate: 0.000729345
	LOSS [training: 0.05191964915495506 | validation: 0.03769827128509908]
	TIME [epoch: 10.2 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05219444780023845		[learning rate: 0.00072711]
	Learning Rate: 0.00072711
	LOSS [training: 0.05219444780023845 | validation: 0.03489541776982348]
	TIME [epoch: 10.2 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05718047443015758		[learning rate: 0.00072488]
	Learning Rate: 0.000724881
	LOSS [training: 0.05718047443015758 | validation: 0.03305819845459848]
	TIME [epoch: 10.3 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05389265306151776		[learning rate: 0.00072266]
	Learning Rate: 0.000722659
	LOSS [training: 0.05389265306151776 | validation: 0.03290609863541252]
	TIME [epoch: 10.2 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04811262080360333		[learning rate: 0.00072044]
	Learning Rate: 0.000720444
	LOSS [training: 0.04811262080360333 | validation: 0.04356744807000139]
	TIME [epoch: 10.3 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04939464254887138		[learning rate: 0.00071824]
	Learning Rate: 0.000718235
	LOSS [training: 0.04939464254887138 | validation: 0.043145750547708826]
	TIME [epoch: 10.2 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05014697103890052		[learning rate: 0.00071603]
	Learning Rate: 0.000716033
	LOSS [training: 0.05014697103890052 | validation: 0.04722995558804216]
	TIME [epoch: 10.3 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051910822894951116		[learning rate: 0.00071384]
	Learning Rate: 0.000713839
	LOSS [training: 0.051910822894951116 | validation: 0.053149903069775926]
	TIME [epoch: 10.2 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06361444011942634		[learning rate: 0.00071165]
	Learning Rate: 0.00071165
	LOSS [training: 0.06361444011942634 | validation: 0.04541322635559071]
	TIME [epoch: 10.2 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0519075144482774		[learning rate: 0.00070947]
	Learning Rate: 0.000709469
	LOSS [training: 0.0519075144482774 | validation: 0.03833262688938481]
	TIME [epoch: 10.2 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04835746300360675		[learning rate: 0.00070729]
	Learning Rate: 0.000707294
	LOSS [training: 0.04835746300360675 | validation: 0.05077604578125927]
	TIME [epoch: 10.2 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05531079170762247		[learning rate: 0.00070513]
	Learning Rate: 0.000705126
	LOSS [training: 0.05531079170762247 | validation: 0.03769632615058366]
	TIME [epoch: 10.2 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04344349260829733		[learning rate: 0.00070296]
	Learning Rate: 0.000702964
	LOSS [training: 0.04344349260829733 | validation: 0.038675262440052365]
	TIME [epoch: 10.2 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04547386003162834		[learning rate: 0.00070081]
	Learning Rate: 0.00070081
	LOSS [training: 0.04547386003162834 | validation: 0.039758777936190745]
	TIME [epoch: 10.2 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043692563637980186		[learning rate: 0.00069866]
	Learning Rate: 0.000698661
	LOSS [training: 0.043692563637980186 | validation: 0.03921350678678014]
	TIME [epoch: 10.2 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04273555296613162		[learning rate: 0.00069652]
	Learning Rate: 0.000696519
	LOSS [training: 0.04273555296613162 | validation: 0.04634237397938362]
	TIME [epoch: 10.2 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042430343280993474		[learning rate: 0.00069438]
	Learning Rate: 0.000694384
	LOSS [training: 0.042430343280993474 | validation: 0.05165375504223937]
	TIME [epoch: 10.2 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04549586348491125		[learning rate: 0.00069226]
	Learning Rate: 0.000692256
	LOSS [training: 0.04549586348491125 | validation: 0.026996203773850497]
	TIME [epoch: 10.2 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04525887390014538		[learning rate: 0.00069013]
	Learning Rate: 0.000690134
	LOSS [training: 0.04525887390014538 | validation: 0.03957730722415369]
	TIME [epoch: 10.2 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042352901538467026		[learning rate: 0.00068802]
	Learning Rate: 0.000688018
	LOSS [training: 0.042352901538467026 | validation: 0.03172258893828049]
	TIME [epoch: 10.3 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04110543445670574		[learning rate: 0.00068591]
	Learning Rate: 0.000685909
	LOSS [training: 0.04110543445670574 | validation: 0.040832588388282964]
	TIME [epoch: 10.2 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040316501801030635		[learning rate: 0.00068381]
	Learning Rate: 0.000683807
	LOSS [training: 0.040316501801030635 | validation: 0.03261220601499061]
	TIME [epoch: 10.3 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03514305845313871		[learning rate: 0.00068171]
	Learning Rate: 0.000681711
	LOSS [training: 0.03514305845313871 | validation: 0.04510099299880287]
	TIME [epoch: 10.3 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04520436830323094		[learning rate: 0.00067962]
	Learning Rate: 0.000679621
	LOSS [training: 0.04520436830323094 | validation: 0.03758994255485149]
	TIME [epoch: 10.2 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03711813445555646		[learning rate: 0.00067754]
	Learning Rate: 0.000677538
	LOSS [training: 0.03711813445555646 | validation: 0.04004617562926824]
	TIME [epoch: 10.2 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04685979261313099		[learning rate: 0.00067546]
	Learning Rate: 0.000675461
	LOSS [training: 0.04685979261313099 | validation: 0.02953370091449376]
	TIME [epoch: 10.3 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04359347278043464		[learning rate: 0.00067339]
	Learning Rate: 0.00067339
	LOSS [training: 0.04359347278043464 | validation: 0.04851558463224913]
	TIME [epoch: 10.3 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0434432280855684		[learning rate: 0.00067133]
	Learning Rate: 0.000671326
	LOSS [training: 0.0434432280855684 | validation: 0.04102713136237273]
	TIME [epoch: 10.3 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03895358331854783		[learning rate: 0.00066927]
	Learning Rate: 0.000669268
	LOSS [training: 0.03895358331854783 | validation: 0.02849553851204832]
	TIME [epoch: 10.2 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04043105777700159		[learning rate: 0.00066722]
	Learning Rate: 0.000667216
	LOSS [training: 0.04043105777700159 | validation: 0.02732377235271981]
	TIME [epoch: 10.3 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039261466404036126		[learning rate: 0.00066517]
	Learning Rate: 0.000665171
	LOSS [training: 0.039261466404036126 | validation: 0.033982909981541465]
	TIME [epoch: 10.2 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0446002151077706		[learning rate: 0.00066313]
	Learning Rate: 0.000663132
	LOSS [training: 0.0446002151077706 | validation: 0.03643301483582181]
	TIME [epoch: 10.3 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055951638500811904		[learning rate: 0.0006611]
	Learning Rate: 0.000661099
	LOSS [training: 0.055951638500811904 | validation: 0.03852943372463929]
	TIME [epoch: 10.3 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07488031249771022		[learning rate: 0.00065907]
	Learning Rate: 0.000659073
	LOSS [training: 0.07488031249771022 | validation: 0.0684073258487666]
	TIME [epoch: 10.3 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09413265867292424		[learning rate: 0.00065705]
	Learning Rate: 0.000657052
	LOSS [training: 0.09413265867292424 | validation: 0.06223331565119795]
	TIME [epoch: 10.3 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06940001638854669		[learning rate: 0.00065504]
	Learning Rate: 0.000655038
	LOSS [training: 0.06940001638854669 | validation: 0.04476528343022142]
	TIME [epoch: 10.3 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05228169260454398		[learning rate: 0.00065303]
	Learning Rate: 0.00065303
	LOSS [training: 0.05228169260454398 | validation: 0.043266100696892094]
	TIME [epoch: 10.3 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04160719657152681		[learning rate: 0.00065103]
	Learning Rate: 0.000651028
	LOSS [training: 0.04160719657152681 | validation: 0.037105564805293596]
	TIME [epoch: 10.3 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04341868709996309		[learning rate: 0.00064903]
	Learning Rate: 0.000649033
	LOSS [training: 0.04341868709996309 | validation: 0.051477531444066485]
	TIME [epoch: 10.3 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05549997062174874		[learning rate: 0.00064704]
	Learning Rate: 0.000647043
	LOSS [training: 0.05549997062174874 | validation: 0.05997588238310225]
	TIME [epoch: 10.3 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06816233182311718		[learning rate: 0.00064506]
	Learning Rate: 0.00064506
	LOSS [training: 0.06816233182311718 | validation: 0.06415876499254555]
	TIME [epoch: 10.3 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06346309621046356		[learning rate: 0.00064308]
	Learning Rate: 0.000643082
	LOSS [training: 0.06346309621046356 | validation: 0.06170961572769471]
	TIME [epoch: 10.3 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0666307586775137		[learning rate: 0.00064111]
	Learning Rate: 0.000641111
	LOSS [training: 0.0666307586775137 | validation: 0.048040309705626276]
	TIME [epoch: 10.3 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07784428142244533		[learning rate: 0.00063915]
	Learning Rate: 0.000639146
	LOSS [training: 0.07784428142244533 | validation: 0.05284298603717529]
	TIME [epoch: 10.3 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.088016185870953		[learning rate: 0.00063719]
	Learning Rate: 0.000637187
	LOSS [training: 0.088016185870953 | validation: 0.061421447015789735]
	TIME [epoch: 10.3 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06316800952580227		[learning rate: 0.00063523]
	Learning Rate: 0.000635233
	LOSS [training: 0.06316800952580227 | validation: 0.04189503588545301]
	TIME [epoch: 10.3 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05053555001542391		[learning rate: 0.00063329]
	Learning Rate: 0.000633286
	LOSS [training: 0.05053555001542391 | validation: 0.050856753508320224]
	TIME [epoch: 10.3 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04724072441255447		[learning rate: 0.00063134]
	Learning Rate: 0.000631345
	LOSS [training: 0.04724072441255447 | validation: 0.03996396850073772]
	TIME [epoch: 10.3 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050559596397936134		[learning rate: 0.00062941]
	Learning Rate: 0.000629409
	LOSS [training: 0.050559596397936134 | validation: 0.04318773998761893]
	TIME [epoch: 10.3 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05085457901157818		[learning rate: 0.00062748]
	Learning Rate: 0.00062748
	LOSS [training: 0.05085457901157818 | validation: 0.03907863033653763]
	TIME [epoch: 10.3 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05753991254789487		[learning rate: 0.00062556]
	Learning Rate: 0.000625557
	LOSS [training: 0.05753991254789487 | validation: 0.05157787685873222]
	TIME [epoch: 10.3 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052039088334264016		[learning rate: 0.00062364]
	Learning Rate: 0.000623639
	LOSS [training: 0.052039088334264016 | validation: 0.06458864325349448]
	TIME [epoch: 10.3 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07302810132230023		[learning rate: 0.00062173]
	Learning Rate: 0.000621727
	LOSS [training: 0.07302810132230023 | validation: 0.0624581658492985]
	TIME [epoch: 10.3 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06857386813949852		[learning rate: 0.00061982]
	Learning Rate: 0.000619821
	LOSS [training: 0.06857386813949852 | validation: 0.06198925816077401]
	TIME [epoch: 10.3 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06246611393975617		[learning rate: 0.00061792]
	Learning Rate: 0.000617922
	LOSS [training: 0.06246611393975617 | validation: 0.05770509681685862]
	TIME [epoch: 10.3 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0649057872127255		[learning rate: 0.00061603]
	Learning Rate: 0.000616027
	LOSS [training: 0.0649057872127255 | validation: 0.0538324453367306]
	TIME [epoch: 10.3 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06098349217988099		[learning rate: 0.00061414]
	Learning Rate: 0.000614139
	LOSS [training: 0.06098349217988099 | validation: 0.059962167378002036]
	TIME [epoch: 10.3 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04667993525735006		[learning rate: 0.00061226]
	Learning Rate: 0.000612256
	LOSS [training: 0.04667993525735006 | validation: 0.032988913622437284]
	TIME [epoch: 10.3 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04500362466526053		[learning rate: 0.00061038]
	Learning Rate: 0.00061038
	LOSS [training: 0.04500362466526053 | validation: 0.02855657711611343]
	TIME [epoch: 10.2 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038756599668914274		[learning rate: 0.00060851]
	Learning Rate: 0.000608509
	LOSS [training: 0.038756599668914274 | validation: 0.05214205060641776]
	TIME [epoch: 10.2 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05525886756008419		[learning rate: 0.00060664]
	Learning Rate: 0.000606643
	LOSS [training: 0.05525886756008419 | validation: 0.0669460313742122]
	TIME [epoch: 10.2 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06127886338076681		[learning rate: 0.00060478]
	Learning Rate: 0.000604784
	LOSS [training: 0.06127886338076681 | validation: 0.05910471732215841]
	TIME [epoch: 10.3 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06358557620633316		[learning rate: 0.00060293]
	Learning Rate: 0.00060293
	LOSS [training: 0.06358557620633316 | validation: 0.07798596469013559]
	TIME [epoch: 10.3 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061457483856141394		[learning rate: 0.00060108]
	Learning Rate: 0.000601081
	LOSS [training: 0.061457483856141394 | validation: 0.05619329043176546]
	TIME [epoch: 10.3 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04931561415557884		[learning rate: 0.00059924]
	Learning Rate: 0.000599239
	LOSS [training: 0.04931561415557884 | validation: 0.049912288763650635]
	TIME [epoch: 10.3 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05115944436246136		[learning rate: 0.0005974]
	Learning Rate: 0.000597402
	LOSS [training: 0.05115944436246136 | validation: 0.06509367187354342]
	TIME [epoch: 10.3 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05087241010850633		[learning rate: 0.00059557]
	Learning Rate: 0.000595571
	LOSS [training: 0.05087241010850633 | validation: 0.03034639540924307]
	TIME [epoch: 10.2 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053018016487578645		[learning rate: 0.00059375]
	Learning Rate: 0.000593745
	LOSS [training: 0.053018016487578645 | validation: 0.052141434401280176]
	TIME [epoch: 10.3 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0536255831805598		[learning rate: 0.00059192]
	Learning Rate: 0.000591925
	LOSS [training: 0.0536255831805598 | validation: 0.033780910571395484]
	TIME [epoch: 10.3 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058397395408558615		[learning rate: 0.00059011]
	Learning Rate: 0.00059011
	LOSS [training: 0.058397395408558615 | validation: 0.043267614054647886]
	TIME [epoch: 10.3 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058722451066352155		[learning rate: 0.0005883]
	Learning Rate: 0.000588302
	LOSS [training: 0.058722451066352155 | validation: 0.0357839626739864]
	TIME [epoch: 10.2 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0605940738048622		[learning rate: 0.0005865]
	Learning Rate: 0.000586498
	LOSS [training: 0.0605940738048622 | validation: 0.03063945682801226]
	TIME [epoch: 10.3 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059278843477006314		[learning rate: 0.0005847]
	Learning Rate: 0.0005847
	LOSS [training: 0.059278843477006314 | validation: 0.03601287052089769]
	TIME [epoch: 10.2 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055662183292863966		[learning rate: 0.00058291]
	Learning Rate: 0.000582908
	LOSS [training: 0.055662183292863966 | validation: 0.04286655593000465]
	TIME [epoch: 10.3 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05846925517622468		[learning rate: 0.00058112]
	Learning Rate: 0.000581121
	LOSS [training: 0.05846925517622468 | validation: 0.041558916706758764]
	TIME [epoch: 10.3 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054906432591405596		[learning rate: 0.00057934]
	Learning Rate: 0.00057934
	LOSS [training: 0.054906432591405596 | validation: 0.04854857116906468]
	TIME [epoch: 10.3 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06269571614852808		[learning rate: 0.00057756]
	Learning Rate: 0.000577564
	LOSS [training: 0.06269571614852808 | validation: 0.058736889694471286]
	TIME [epoch: 10.3 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04979344679370773		[learning rate: 0.00057579]
	Learning Rate: 0.000575793
	LOSS [training: 0.04979344679370773 | validation: 0.047845351599327464]
	TIME [epoch: 10.3 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04303267593357687		[learning rate: 0.00057403]
	Learning Rate: 0.000574028
	LOSS [training: 0.04303267593357687 | validation: 0.03930099765548371]
	TIME [epoch: 10.2 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04340652332012203		[learning rate: 0.00057227]
	Learning Rate: 0.000572269
	LOSS [training: 0.04340652332012203 | validation: 0.03970043894287777]
	TIME [epoch: 10.3 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.047611363427848774		[learning rate: 0.00057051]
	Learning Rate: 0.000570514
	LOSS [training: 0.047611363427848774 | validation: 0.04729618588805131]
	TIME [epoch: 10.3 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0513483569895389		[learning rate: 0.00056877]
	Learning Rate: 0.000568766
	LOSS [training: 0.0513483569895389 | validation: 0.042987987790335594]
	TIME [epoch: 10.2 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0499954473759074		[learning rate: 0.00056702]
	Learning Rate: 0.000567022
	LOSS [training: 0.0499954473759074 | validation: 0.055509380157381674]
	TIME [epoch: 10.2 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059790567479019396		[learning rate: 0.00056528]
	Learning Rate: 0.000565284
	LOSS [training: 0.059790567479019396 | validation: 0.039011858584628856]
	TIME [epoch: 10.3 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04930085483698506		[learning rate: 0.00056355]
	Learning Rate: 0.000563551
	LOSS [training: 0.04930085483698506 | validation: 0.044775086146981974]
	TIME [epoch: 10.3 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04110508765233386		[learning rate: 0.00056182]
	Learning Rate: 0.000561824
	LOSS [training: 0.04110508765233386 | validation: 0.029316294399782505]
	TIME [epoch: 10.3 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0382847226714349		[learning rate: 0.0005601]
	Learning Rate: 0.000560101
	LOSS [training: 0.0382847226714349 | validation: 0.03406896241441176]
	TIME [epoch: 10.3 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03948452194406289		[learning rate: 0.00055838]
	Learning Rate: 0.000558385
	LOSS [training: 0.03948452194406289 | validation: 0.03984786935373994]
	TIME [epoch: 10.3 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04713050001317063		[learning rate: 0.00055667]
	Learning Rate: 0.000556673
	LOSS [training: 0.04713050001317063 | validation: 0.04494257652840352]
	TIME [epoch: 10.2 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05049690011428176		[learning rate: 0.00055497]
	Learning Rate: 0.000554966
	LOSS [training: 0.05049690011428176 | validation: 0.043145929559490065]
	TIME [epoch: 10.3 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052806982970752966		[learning rate: 0.00055327]
	Learning Rate: 0.000553265
	LOSS [training: 0.052806982970752966 | validation: 0.04269757856176571]
	TIME [epoch: 10.3 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03790735290723165		[learning rate: 0.00055157]
	Learning Rate: 0.000551569
	LOSS [training: 0.03790735290723165 | validation: 0.03727881983081645]
	TIME [epoch: 10.3 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041971070463905344		[learning rate: 0.00054988]
	Learning Rate: 0.000549878
	LOSS [training: 0.041971070463905344 | validation: 0.024706705830880544]
	TIME [epoch: 10.3 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043821280757973		[learning rate: 0.00054819]
	Learning Rate: 0.000548193
	LOSS [training: 0.043821280757973 | validation: 0.033805989259209086]
	TIME [epoch: 10.3 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0503336291498704		[learning rate: 0.00054651]
	Learning Rate: 0.000546512
	LOSS [training: 0.0503336291498704 | validation: 0.048218697079105775]
	TIME [epoch: 10.2 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055362161686712395		[learning rate: 0.00054484]
	Learning Rate: 0.000544837
	LOSS [training: 0.055362161686712395 | validation: 0.037763131887801886]
	TIME [epoch: 10.3 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046510357498109556		[learning rate: 0.00054317]
	Learning Rate: 0.000543167
	LOSS [training: 0.046510357498109556 | validation: 0.03609907935788433]
	TIME [epoch: 10.3 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050691044462533585		[learning rate: 0.0005415]
	Learning Rate: 0.000541502
	LOSS [training: 0.050691044462533585 | validation: 0.032992408560864044]
	TIME [epoch: 10.3 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04598396969086084		[learning rate: 0.00053984]
	Learning Rate: 0.000539842
	LOSS [training: 0.04598396969086084 | validation: 0.04744524968992437]
	TIME [epoch: 10.3 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06125816562658136		[learning rate: 0.00053819]
	Learning Rate: 0.000538187
	LOSS [training: 0.06125816562658136 | validation: 0.045394463428482315]
	TIME [epoch: 10.3 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050568231947019426		[learning rate: 0.00053654]
	Learning Rate: 0.000536537
	LOSS [training: 0.050568231947019426 | validation: 0.043855583617398136]
	TIME [epoch: 10.3 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04501749690762642		[learning rate: 0.00053489]
	Learning Rate: 0.000534893
	LOSS [training: 0.04501749690762642 | validation: 0.047480771724296565]
	TIME [epoch: 10.3 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04254001488642358		[learning rate: 0.00053325]
	Learning Rate: 0.000533253
	LOSS [training: 0.04254001488642358 | validation: 0.042255767966071826]
	TIME [epoch: 10.3 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0438634945067488		[learning rate: 0.00053162]
	Learning Rate: 0.000531618
	LOSS [training: 0.0438634945067488 | validation: 0.03322512325687474]
	TIME [epoch: 10.3 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03636093403605049		[learning rate: 0.00052999]
	Learning Rate: 0.000529989
	LOSS [training: 0.03636093403605049 | validation: 0.027592254836338675]
	TIME [epoch: 10.3 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03823494303478825		[learning rate: 0.00052836]
	Learning Rate: 0.000528364
	LOSS [training: 0.03823494303478825 | validation: 0.04084692826014498]
	TIME [epoch: 10.2 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04537954188011946		[learning rate: 0.00052674]
	Learning Rate: 0.000526744
	LOSS [training: 0.04537954188011946 | validation: 0.058250343700654725]
	TIME [epoch: 10.2 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05929932532968174		[learning rate: 0.00052513]
	Learning Rate: 0.00052513
	LOSS [training: 0.05929932532968174 | validation: 0.0584466830333945]
	TIME [epoch: 10.3 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05595271561738089		[learning rate: 0.00052352]
	Learning Rate: 0.00052352
	LOSS [training: 0.05595271561738089 | validation: 0.05387074829004854]
	TIME [epoch: 10.3 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05651822377215191		[learning rate: 0.00052192]
	Learning Rate: 0.000521915
	LOSS [training: 0.05651822377215191 | validation: 0.05788922135136322]
	TIME [epoch: 10.3 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053508381678710984		[learning rate: 0.00052032]
	Learning Rate: 0.000520315
	LOSS [training: 0.053508381678710984 | validation: 0.053732545369398414]
	TIME [epoch: 10.3 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058687160024087914		[learning rate: 0.00051872]
	Learning Rate: 0.00051872
	LOSS [training: 0.058687160024087914 | validation: 0.05599559885728754]
	TIME [epoch: 10.3 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05349100591436038		[learning rate: 0.00051713]
	Learning Rate: 0.00051713
	LOSS [training: 0.05349100591436038 | validation: 0.06469895484546599]
	TIME [epoch: 10.3 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0577030989796347		[learning rate: 0.00051555]
	Learning Rate: 0.000515545
	LOSS [training: 0.0577030989796347 | validation: 0.04306975741502113]
	TIME [epoch: 10.3 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054853639396264045		[learning rate: 0.00051396]
	Learning Rate: 0.000513965
	LOSS [training: 0.054853639396264045 | validation: 0.07096711486754481]
	TIME [epoch: 10.3 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06261208865328174		[learning rate: 0.00051239]
	Learning Rate: 0.000512389
	LOSS [training: 0.06261208865328174 | validation: 0.04818843556585657]
	TIME [epoch: 10.3 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06269053490938148		[learning rate: 0.00051082]
	Learning Rate: 0.000510818
	LOSS [training: 0.06269053490938148 | validation: 0.047507257868082145]
	TIME [epoch: 10.2 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045540884682942526		[learning rate: 0.00050925]
	Learning Rate: 0.000509253
	LOSS [training: 0.045540884682942526 | validation: 0.05398324756255247]
	TIME [epoch: 10.2 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040439371508365116		[learning rate: 0.00050769]
	Learning Rate: 0.000507692
	LOSS [training: 0.040439371508365116 | validation: 0.06319635474633238]
	TIME [epoch: 10.2 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04528234203945834		[learning rate: 0.00050614]
	Learning Rate: 0.000506135
	LOSS [training: 0.04528234203945834 | validation: 0.04365010193281611]
	TIME [epoch: 10.3 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04333118868364437		[learning rate: 0.00050458]
	Learning Rate: 0.000504584
	LOSS [training: 0.04333118868364437 | validation: 0.03468212432753517]
	TIME [epoch: 10.3 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043676804099876475		[learning rate: 0.00050304]
	Learning Rate: 0.000503037
	LOSS [training: 0.043676804099876475 | validation: 0.03655661583617163]
	TIME [epoch: 10.3 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045992409172417		[learning rate: 0.00050149]
	Learning Rate: 0.000501495
	LOSS [training: 0.045992409172417 | validation: 0.033195905822549464]
	TIME [epoch: 10.2 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048973868217397507		[learning rate: 0.00049996]
	Learning Rate: 0.000499958
	LOSS [training: 0.048973868217397507 | validation: 0.04948875230697189]
	TIME [epoch: 10.3 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052349917684548684		[learning rate: 0.00049843]
	Learning Rate: 0.000498425
	LOSS [training: 0.052349917684548684 | validation: 0.04198257107671779]
	TIME [epoch: 10.3 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04098350736310225		[learning rate: 0.0004969]
	Learning Rate: 0.000496897
	LOSS [training: 0.04098350736310225 | validation: 0.052184639809223374]
	TIME [epoch: 10.3 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05070324367213992		[learning rate: 0.00049537]
	Learning Rate: 0.000495374
	LOSS [training: 0.05070324367213992 | validation: 0.052179436245923826]
	TIME [epoch: 10.3 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05176424295359228		[learning rate: 0.00049386]
	Learning Rate: 0.000493856
	LOSS [training: 0.05176424295359228 | validation: 0.05895502349660883]
	TIME [epoch: 10.3 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04705594363988573		[learning rate: 0.00049234]
	Learning Rate: 0.000492342
	LOSS [training: 0.04705594363988573 | validation: 0.06876702014524029]
	TIME [epoch: 10.3 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050481485040293816		[learning rate: 0.00049083]
	Learning Rate: 0.000490832
	LOSS [training: 0.050481485040293816 | validation: 0.05028277963237494]
	TIME [epoch: 10.3 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05347703056394278		[learning rate: 0.00048933]
	Learning Rate: 0.000489328
	LOSS [training: 0.05347703056394278 | validation: 0.035112902226393586]
	TIME [epoch: 10.3 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0521603427343227		[learning rate: 0.00048783]
	Learning Rate: 0.000487828
	LOSS [training: 0.0521603427343227 | validation: 0.0490016004501833]
	TIME [epoch: 10.3 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04475899566662252		[learning rate: 0.00048633]
	Learning Rate: 0.000486333
	LOSS [training: 0.04475899566662252 | validation: 0.04125342146124245]
	TIME [epoch: 10.3 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046272818250307365		[learning rate: 0.00048484]
	Learning Rate: 0.000484842
	LOSS [training: 0.046272818250307365 | validation: 0.04680844590018131]
	TIME [epoch: 10.3 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04867270986680561		[learning rate: 0.00048336]
	Learning Rate: 0.000483356
	LOSS [training: 0.04867270986680561 | validation: 0.033108235750492564]
	TIME [epoch: 10.3 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04817800585399088		[learning rate: 0.00048187]
	Learning Rate: 0.000481874
	LOSS [training: 0.04817800585399088 | validation: 0.03963632634569168]
	TIME [epoch: 10.3 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060267865496378414		[learning rate: 0.0004804]
	Learning Rate: 0.000480397
	LOSS [training: 0.060267865496378414 | validation: 0.04594079854173778]
	TIME [epoch: 10.3 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059181554241424725		[learning rate: 0.00047892]
	Learning Rate: 0.000478924
	LOSS [training: 0.059181554241424725 | validation: 0.035720955401063105]
	TIME [epoch: 10.3 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05792173858937029		[learning rate: 0.00047746]
	Learning Rate: 0.000477456
	LOSS [training: 0.05792173858937029 | validation: 0.03569483335932553]
	TIME [epoch: 10.3 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054440438120568424		[learning rate: 0.00047599]
	Learning Rate: 0.000475992
	LOSS [training: 0.054440438120568424 | validation: 0.03103845308558488]
	TIME [epoch: 10.3 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041404582431727614		[learning rate: 0.00047453]
	Learning Rate: 0.000474533
	LOSS [training: 0.041404582431727614 | validation: 0.031372215641466535]
	TIME [epoch: 10.3 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.046974533219992835		[learning rate: 0.00047308]
	Learning Rate: 0.000473079
	LOSS [training: 0.046974533219992835 | validation: 0.050011912287370744]
	TIME [epoch: 10.3 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05400944844917542		[learning rate: 0.00047163]
	Learning Rate: 0.000471628
	LOSS [training: 0.05400944844917542 | validation: 0.03732233632074345]
	TIME [epoch: 10.2 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050122822542425435		[learning rate: 0.00047018]
	Learning Rate: 0.000470183
	LOSS [training: 0.050122822542425435 | validation: 0.038330901370827855]
	TIME [epoch: 10.3 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051798345706502005		[learning rate: 0.00046874]
	Learning Rate: 0.000468741
	LOSS [training: 0.051798345706502005 | validation: 0.03566743223540793]
	TIME [epoch: 10.3 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03826148709111761		[learning rate: 0.0004673]
	Learning Rate: 0.000467304
	LOSS [training: 0.03826148709111761 | validation: 0.044229800587014784]
	TIME [epoch: 10.3 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05009203318075337		[learning rate: 0.00046587]
	Learning Rate: 0.000465872
	LOSS [training: 0.05009203318075337 | validation: 0.03603135852076437]
	TIME [epoch: 10.3 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04756878815788239		[learning rate: 0.00046444]
	Learning Rate: 0.000464444
	LOSS [training: 0.04756878815788239 | validation: 0.042509558744839054]
	TIME [epoch: 10.3 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04923120361263446		[learning rate: 0.00046302]
	Learning Rate: 0.00046302
	LOSS [training: 0.04923120361263446 | validation: 0.06599136247735718]
	TIME [epoch: 10.3 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0570751254716864		[learning rate: 0.0004616]
	Learning Rate: 0.000461601
	LOSS [training: 0.0570751254716864 | validation: 0.04736792661610301]
	TIME [epoch: 10.3 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054660671954290904		[learning rate: 0.00046019]
	Learning Rate: 0.000460186
	LOSS [training: 0.054660671954290904 | validation: 0.09001038668883504]
	TIME [epoch: 10.3 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07104689106106142		[learning rate: 0.00045878]
	Learning Rate: 0.000458775
	LOSS [training: 0.07104689106106142 | validation: 0.07167337760179537]
	TIME [epoch: 10.2 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08340828209036011		[learning rate: 0.00045737]
	Learning Rate: 0.000457369
	LOSS [training: 0.08340828209036011 | validation: 0.06910039943448298]
	TIME [epoch: 10.3 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08279037526000756		[learning rate: 0.00045597]
	Learning Rate: 0.000455967
	LOSS [training: 0.08279037526000756 | validation: 0.0858414178973771]
	TIME [epoch: 10.2 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07605905533798629		[learning rate: 0.00045457]
	Learning Rate: 0.000454569
	LOSS [training: 0.07605905533798629 | validation: 0.07413244453347435]
	TIME [epoch: 10.3 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07143244213948932		[learning rate: 0.00045318]
	Learning Rate: 0.000453176
	LOSS [training: 0.07143244213948932 | validation: 0.06810918051162478]
	TIME [epoch: 10.2 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07635837810459507		[learning rate: 0.00045179]
	Learning Rate: 0.000451787
	LOSS [training: 0.07635837810459507 | validation: 0.08148606593258176]
	TIME [epoch: 10.3 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07537829138089477		[learning rate: 0.0004504]
	Learning Rate: 0.000450402
	LOSS [training: 0.07537829138089477 | validation: 0.051284531751848904]
	TIME [epoch: 10.3 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04924939955330529		[learning rate: 0.00044902]
	Learning Rate: 0.000449021
	LOSS [training: 0.04924939955330529 | validation: 0.050149439748378606]
	TIME [epoch: 10.3 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06182357948393043		[learning rate: 0.00044764]
	Learning Rate: 0.000447645
	LOSS [training: 0.06182357948393043 | validation: 0.06062486322141847]
	TIME [epoch: 10.3 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05502266304474683		[learning rate: 0.00044627]
	Learning Rate: 0.000446272
	LOSS [training: 0.05502266304474683 | validation: 0.0467047989789613]
	TIME [epoch: 10.3 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050389917813511584		[learning rate: 0.0004449]
	Learning Rate: 0.000444904
	LOSS [training: 0.050389917813511584 | validation: 0.05242398398823455]
	TIME [epoch: 10.3 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04859061976060032		[learning rate: 0.00044354]
	Learning Rate: 0.000443541
	LOSS [training: 0.04859061976060032 | validation: 0.04588004733825036]
	TIME [epoch: 10.3 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05798893193062606		[learning rate: 0.00044218]
	Learning Rate: 0.000442181
	LOSS [training: 0.05798893193062606 | validation: 0.04562741075393449]
	TIME [epoch: 10.3 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06823145510628		[learning rate: 0.00044083]
	Learning Rate: 0.000440825
	LOSS [training: 0.06823145510628 | validation: 0.05979880974604107]
	TIME [epoch: 10.3 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0645211745362059		[learning rate: 0.00043947]
	Learning Rate: 0.000439474
	LOSS [training: 0.0645211745362059 | validation: 0.04892527678435487]
	TIME [epoch: 10.3 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054504927672774026		[learning rate: 0.00043813]
	Learning Rate: 0.000438127
	LOSS [training: 0.054504927672774026 | validation: 0.03879621561263386]
	TIME [epoch: 10.3 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05587687047821144		[learning rate: 0.00043678]
	Learning Rate: 0.000436784
	LOSS [training: 0.05587687047821144 | validation: 0.06391792687582376]
	TIME [epoch: 10.3 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0610656970353685		[learning rate: 0.00043544]
	Learning Rate: 0.000435445
	LOSS [training: 0.0610656970353685 | validation: 0.05298333173858429]
	TIME [epoch: 10.3 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06552984167111742		[learning rate: 0.00043411]
	Learning Rate: 0.00043411
	LOSS [training: 0.06552984167111742 | validation: 0.055802711475363614]
	TIME [epoch: 10.3 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05995435544882077		[learning rate: 0.00043278]
	Learning Rate: 0.00043278
	LOSS [training: 0.05995435544882077 | validation: 0.04638509566493276]
	TIME [epoch: 10.2 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06459568516730525		[learning rate: 0.00043145]
	Learning Rate: 0.000431453
	LOSS [training: 0.06459568516730525 | validation: 0.055834521840310514]
	TIME [epoch: 10.3 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053721972685301156		[learning rate: 0.00043013]
	Learning Rate: 0.00043013
	LOSS [training: 0.053721972685301156 | validation: 0.06277007562534219]
	TIME [epoch: 10.3 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05828432047093144		[learning rate: 0.00042881]
	Learning Rate: 0.000428812
	LOSS [training: 0.05828432047093144 | validation: 0.04824464076125736]
	TIME [epoch: 10.3 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05457845577422761		[learning rate: 0.0004275]
	Learning Rate: 0.000427497
	LOSS [training: 0.05457845577422761 | validation: 0.0509909878327159]
	TIME [epoch: 10.3 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054482321029116355		[learning rate: 0.00042619]
	Learning Rate: 0.000426187
	LOSS [training: 0.054482321029116355 | validation: 0.05354793990523767]
	TIME [epoch: 10.2 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06383799611700736		[learning rate: 0.00042488]
	Learning Rate: 0.00042488
	LOSS [training: 0.06383799611700736 | validation: 0.054484597393630325]
	TIME [epoch: 10.3 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07063964511242556		[learning rate: 0.00042358]
	Learning Rate: 0.000423578
	LOSS [training: 0.07063964511242556 | validation: 0.04904755805116246]
	TIME [epoch: 10.3 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06877297584925225		[learning rate: 0.00042228]
	Learning Rate: 0.000422279
	LOSS [training: 0.06877297584925225 | validation: 0.042154085470375316]
	TIME [epoch: 10.2 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05747906695783807		[learning rate: 0.00042098]
	Learning Rate: 0.000420985
	LOSS [training: 0.05747906695783807 | validation: 0.043300515324704955]
	TIME [epoch: 10.3 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06595333546470986		[learning rate: 0.00041969]
	Learning Rate: 0.000419694
	LOSS [training: 0.06595333546470986 | validation: 0.05099553437213196]
	TIME [epoch: 10.3 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06238215291733995		[learning rate: 0.00041841]
	Learning Rate: 0.000418408
	LOSS [training: 0.06238215291733995 | validation: 0.04811132809910898]
	TIME [epoch: 10.3 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05778260173920204		[learning rate: 0.00041713]
	Learning Rate: 0.000417125
	LOSS [training: 0.05778260173920204 | validation: 0.06027794247240697]
	TIME [epoch: 10.3 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07031328085619679		[learning rate: 0.00041585]
	Learning Rate: 0.000415847
	LOSS [training: 0.07031328085619679 | validation: 0.057646671265799476]
	TIME [epoch: 10.3 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0609819876728123		[learning rate: 0.00041457]
	Learning Rate: 0.000414572
	LOSS [training: 0.0609819876728123 | validation: 0.05639025972608211]
	TIME [epoch: 10.3 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052728603270495555		[learning rate: 0.0004133]
	Learning Rate: 0.000413301
	LOSS [training: 0.052728603270495555 | validation: 0.03757368002418263]
	TIME [epoch: 10.3 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04944775228251691		[learning rate: 0.00041203]
	Learning Rate: 0.000412034
	LOSS [training: 0.04944775228251691 | validation: 0.049075607068468176]
	TIME [epoch: 10.2 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05328542810184391		[learning rate: 0.00041077]
	Learning Rate: 0.000410771
	LOSS [training: 0.05328542810184391 | validation: 0.053526039350997694]
	TIME [epoch: 10.3 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05450648051912703		[learning rate: 0.00040951]
	Learning Rate: 0.000409512
	LOSS [training: 0.05450648051912703 | validation: 0.040403001206136956]
	TIME [epoch: 10.3 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06109311500960522		[learning rate: 0.00040826]
	Learning Rate: 0.000408257
	LOSS [training: 0.06109311500960522 | validation: 0.04884386503604027]
	TIME [epoch: 10.3 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05039088689052067		[learning rate: 0.00040701]
	Learning Rate: 0.000407005
	LOSS [training: 0.05039088689052067 | validation: 0.045414655608742]
	TIME [epoch: 10.3 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045704533733152364		[learning rate: 0.00040576]
	Learning Rate: 0.000405758
	LOSS [training: 0.045704533733152364 | validation: 0.043949739849451844]
	TIME [epoch: 10.3 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04844062025715593		[learning rate: 0.00040451]
	Learning Rate: 0.000404514
	LOSS [training: 0.04844062025715593 | validation: 0.03903477115494617]
	TIME [epoch: 10.3 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04987630306246822		[learning rate: 0.00040327]
	Learning Rate: 0.000403274
	LOSS [training: 0.04987630306246822 | validation: 0.025883613728992165]
	TIME [epoch: 10.3 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045507840528549726		[learning rate: 0.00040204]
	Learning Rate: 0.000402038
	LOSS [training: 0.045507840528549726 | validation: 0.050743489466164304]
	TIME [epoch: 10.3 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04645008928898041		[learning rate: 0.00040081]
	Learning Rate: 0.000400805
	LOSS [training: 0.04645008928898041 | validation: 0.03825095461297342]
	TIME [epoch: 10.3 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04703016266980915		[learning rate: 0.00039958]
	Learning Rate: 0.000399577
	LOSS [training: 0.04703016266980915 | validation: 0.04381108805145963]
	TIME [epoch: 10.3 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04995256556748458		[learning rate: 0.00039835]
	Learning Rate: 0.000398352
	LOSS [training: 0.04995256556748458 | validation: 0.031788427476097905]
	TIME [epoch: 10.3 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05119114584372007		[learning rate: 0.00039713]
	Learning Rate: 0.000397131
	LOSS [training: 0.05119114584372007 | validation: 0.03583431475336923]
	TIME [epoch: 10.2 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04501501418955598		[learning rate: 0.00039591]
	Learning Rate: 0.000395913
	LOSS [training: 0.04501501418955598 | validation: 0.045235977217973955]
	TIME [epoch: 10.3 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036094804687903236		[learning rate: 0.0003947]
	Learning Rate: 0.0003947
	LOSS [training: 0.036094804687903236 | validation: 0.04411652391086867]
	TIME [epoch: 10.3 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04504686234675108		[learning rate: 0.00039349]
	Learning Rate: 0.00039349
	LOSS [training: 0.04504686234675108 | validation: 0.04613575222397685]
	TIME [epoch: 10.3 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04607924982607394		[learning rate: 0.00039228]
	Learning Rate: 0.000392283
	LOSS [training: 0.04607924982607394 | validation: 0.041021184534853615]
	TIME [epoch: 10.3 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036467209032032315		[learning rate: 0.00039108]
	Learning Rate: 0.000391081
	LOSS [training: 0.036467209032032315 | validation: 0.04169569312788802]
	TIME [epoch: 10.3 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04829151727815284		[learning rate: 0.00038988]
	Learning Rate: 0.000389882
	LOSS [training: 0.04829151727815284 | validation: 0.04908888831409246]
	TIME [epoch: 10.3 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05545007776764695		[learning rate: 0.00038869]
	Learning Rate: 0.000388687
	LOSS [training: 0.05545007776764695 | validation: 0.05838617959584392]
	TIME [epoch: 10.3 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0619127862095588		[learning rate: 0.0003875]
	Learning Rate: 0.000387495
	LOSS [training: 0.0619127862095588 | validation: 0.05935469051022338]
	TIME [epoch: 10.3 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06743003095657923		[learning rate: 0.00038631]
	Learning Rate: 0.000386308
	LOSS [training: 0.06743003095657923 | validation: 0.08066540375353798]
	TIME [epoch: 10.3 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07891431240034925		[learning rate: 0.00038512]
	Learning Rate: 0.000385123
	LOSS [training: 0.07891431240034925 | validation: 0.07339887892050383]
	TIME [epoch: 10.3 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07013297982648628		[learning rate: 0.00038394]
	Learning Rate: 0.000383943
	LOSS [training: 0.07013297982648628 | validation: 0.0676212750104397]
	TIME [epoch: 10.3 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07176433094488736		[learning rate: 0.00038277]
	Learning Rate: 0.000382766
	LOSS [training: 0.07176433094488736 | validation: 0.0829137247951312]
	TIME [epoch: 10.3 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06207540191196276		[learning rate: 0.00038159]
	Learning Rate: 0.000381593
	LOSS [training: 0.06207540191196276 | validation: 0.058169630343073084]
	TIME [epoch: 10.3 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05214693640250495		[learning rate: 0.00038042]
	Learning Rate: 0.000380423
	LOSS [training: 0.05214693640250495 | validation: 0.04959488587694063]
	TIME [epoch: 10.3 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053704671059428256		[learning rate: 0.00037926]
	Learning Rate: 0.000379257
	LOSS [training: 0.053704671059428256 | validation: 0.04606020305349575]
	TIME [epoch: 10.3 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04092757676035926		[learning rate: 0.00037809]
	Learning Rate: 0.000378094
	LOSS [training: 0.04092757676035926 | validation: 0.03031735712030352]
	TIME [epoch: 10.3 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04348082601524774		[learning rate: 0.00037694]
	Learning Rate: 0.000376935
	LOSS [training: 0.04348082601524774 | validation: 0.046637214373904445]
	TIME [epoch: 10.3 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04639034780801824		[learning rate: 0.00037578]
	Learning Rate: 0.00037578
	LOSS [training: 0.04639034780801824 | validation: 0.050250474787105176]
	TIME [epoch: 10.3 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044328161548961645		[learning rate: 0.00037463]
	Learning Rate: 0.000374628
	LOSS [training: 0.044328161548961645 | validation: 0.04814929172526144]
	TIME [epoch: 10.3 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05123142278397458		[learning rate: 0.00037348]
	Learning Rate: 0.000373479
	LOSS [training: 0.05123142278397458 | validation: 0.044709980159725646]
	TIME [epoch: 10.3 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04997713230708996		[learning rate: 0.00037233]
	Learning Rate: 0.000372335
	LOSS [training: 0.04997713230708996 | validation: 0.05160871933035269]
	TIME [epoch: 10.3 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05669396897348187		[learning rate: 0.00037119]
	Learning Rate: 0.000371193
	LOSS [training: 0.05669396897348187 | validation: 0.04614908607398001]
	TIME [epoch: 10.3 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05319725744469879		[learning rate: 0.00037006]
	Learning Rate: 0.000370055
	LOSS [training: 0.05319725744469879 | validation: 0.05076663080261923]
	TIME [epoch: 10.3 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05211261362666168		[learning rate: 0.00036892]
	Learning Rate: 0.000368921
	LOSS [training: 0.05211261362666168 | validation: 0.04060241910007103]
	TIME [epoch: 10.3 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05246074033074064		[learning rate: 0.00036779]
	Learning Rate: 0.00036779
	LOSS [training: 0.05246074033074064 | validation: 0.04544774268414695]
	TIME [epoch: 10.3 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05291886200994722		[learning rate: 0.00036666]
	Learning Rate: 0.000366663
	LOSS [training: 0.05291886200994722 | validation: 0.04973372431589715]
	TIME [epoch: 10.3 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06698661349288171		[learning rate: 0.00036554]
	Learning Rate: 0.000365539
	LOSS [training: 0.06698661349288171 | validation: 0.05941264357879252]
	TIME [epoch: 10.3 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06649945716065284		[learning rate: 0.00036442]
	Learning Rate: 0.000364418
	LOSS [training: 0.06649945716065284 | validation: 0.04877648603679232]
	TIME [epoch: 10.3 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050729708149638605		[learning rate: 0.0003633]
	Learning Rate: 0.000363301
	LOSS [training: 0.050729708149638605 | validation: 0.04827703315184299]
	TIME [epoch: 10.3 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04814794985304409		[learning rate: 0.00036219]
	Learning Rate: 0.000362187
	LOSS [training: 0.04814794985304409 | validation: 0.046345242256368026]
	TIME [epoch: 10.3 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04495224284328949		[learning rate: 0.00036108]
	Learning Rate: 0.000361077
	LOSS [training: 0.04495224284328949 | validation: 0.02308897931242404]
	TIME [epoch: 10.3 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.050041175362491454		[learning rate: 0.00035997]
	Learning Rate: 0.00035997
	LOSS [training: 0.050041175362491454 | validation: 0.046691916742761366]
	TIME [epoch: 10.3 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049032370029545524		[learning rate: 0.00035887]
	Learning Rate: 0.000358867
	LOSS [training: 0.049032370029545524 | validation: 0.03430761588953216]
	TIME [epoch: 10.3 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04384238482665263		[learning rate: 0.00035777]
	Learning Rate: 0.000357767
	LOSS [training: 0.04384238482665263 | validation: 0.035551276225793405]
	TIME [epoch: 10.3 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043269632475882155		[learning rate: 0.00035667]
	Learning Rate: 0.00035667
	LOSS [training: 0.043269632475882155 | validation: 0.03641528457187863]
	TIME [epoch: 10.3 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05124307485618732		[learning rate: 0.00035558]
	Learning Rate: 0.000355577
	LOSS [training: 0.05124307485618732 | validation: 0.04489853918818794]
	TIME [epoch: 10.3 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04213591204605299		[learning rate: 0.00035449]
	Learning Rate: 0.000354487
	LOSS [training: 0.04213591204605299 | validation: 0.029471323923691665]
	TIME [epoch: 10.3 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04078765288290846		[learning rate: 0.0003534]
	Learning Rate: 0.0003534
	LOSS [training: 0.04078765288290846 | validation: 0.03361950137014724]
	TIME [epoch: 10.3 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03660061661562768		[learning rate: 0.00035232]
	Learning Rate: 0.000352317
	LOSS [training: 0.03660061661562768 | validation: 0.022152020478601743]
	TIME [epoch: 10.3 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03608571014764577		[learning rate: 0.00035124]
	Learning Rate: 0.000351237
	LOSS [training: 0.03608571014764577 | validation: 0.03867160914840125]
	TIME [epoch: 10.3 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04380309474048557		[learning rate: 0.00035016]
	Learning Rate: 0.00035016
	LOSS [training: 0.04380309474048557 | validation: 0.0222037223148132]
	TIME [epoch: 10.3 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03909532350417364		[learning rate: 0.00034909]
	Learning Rate: 0.000349087
	LOSS [training: 0.03909532350417364 | validation: 0.04257970001057834]
	TIME [epoch: 10.3 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036813418852270484		[learning rate: 0.00034802]
	Learning Rate: 0.000348017
	LOSS [training: 0.036813418852270484 | validation: 0.033263667361862384]
	TIME [epoch: 10.3 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03893967297458704		[learning rate: 0.00034695]
	Learning Rate: 0.00034695
	LOSS [training: 0.03893967297458704 | validation: 0.03950115401083341]
	TIME [epoch: 10.3 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03712425758109822		[learning rate: 0.00034589]
	Learning Rate: 0.000345886
	LOSS [training: 0.03712425758109822 | validation: 0.03757704522479935]
	TIME [epoch: 10.3 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03974559110726491		[learning rate: 0.00034483]
	Learning Rate: 0.000344826
	LOSS [training: 0.03974559110726491 | validation: 0.020467353428662044]
	TIME [epoch: 10.3 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03102756389369027		[learning rate: 0.00034377]
	Learning Rate: 0.000343769
	LOSS [training: 0.03102756389369027 | validation: 0.03667707001418453]
	TIME [epoch: 10.3 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03698519171055279		[learning rate: 0.00034272]
	Learning Rate: 0.000342715
	LOSS [training: 0.03698519171055279 | validation: 0.03704017031793268]
	TIME [epoch: 10.3 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03705260509452837		[learning rate: 0.00034166]
	Learning Rate: 0.000341665
	LOSS [training: 0.03705260509452837 | validation: 0.03914147315454902]
	TIME [epoch: 10.3 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042778647433383325		[learning rate: 0.00034062]
	Learning Rate: 0.000340617
	LOSS [training: 0.042778647433383325 | validation: 0.038314382733447616]
	TIME [epoch: 10.3 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040512836221705435		[learning rate: 0.00033957]
	Learning Rate: 0.000339573
	LOSS [training: 0.040512836221705435 | validation: 0.03065632903263466]
	TIME [epoch: 10.3 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04176238686951933		[learning rate: 0.00033853]
	Learning Rate: 0.000338532
	LOSS [training: 0.04176238686951933 | validation: 0.02696823707388079]
	TIME [epoch: 10.3 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0388242150675002		[learning rate: 0.00033749]
	Learning Rate: 0.000337494
	LOSS [training: 0.0388242150675002 | validation: 0.03367210038640859]
	TIME [epoch: 10.2 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03737090317238584		[learning rate: 0.00033646]
	Learning Rate: 0.00033646
	LOSS [training: 0.03737090317238584 | validation: 0.03350456114619762]
	TIME [epoch: 10.3 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03890038160447048		[learning rate: 0.00033543]
	Learning Rate: 0.000335428
	LOSS [training: 0.03890038160447048 | validation: 0.03140382874201994]
	TIME [epoch: 10.3 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03801414332025862		[learning rate: 0.0003344]
	Learning Rate: 0.0003344
	LOSS [training: 0.03801414332025862 | validation: 0.03035959080643848]
	TIME [epoch: 10.3 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039681183047399704		[learning rate: 0.00033338]
	Learning Rate: 0.000333375
	LOSS [training: 0.039681183047399704 | validation: 0.03953352318616575]
	TIME [epoch: 10.3 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04093270875645983		[learning rate: 0.00033235]
	Learning Rate: 0.000332353
	LOSS [training: 0.04093270875645983 | validation: 0.01798475409763453]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_1609.pth
	Model improved!!!
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04445483489701453		[learning rate: 0.00033133]
	Learning Rate: 0.000331334
	LOSS [training: 0.04445483489701453 | validation: 0.03903965092680213]
	TIME [epoch: 10.3 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04945517038278904		[learning rate: 0.00033032]
	Learning Rate: 0.000330319
	LOSS [training: 0.04945517038278904 | validation: 0.05693513222608644]
	TIME [epoch: 10.3 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05272986701566608		[learning rate: 0.00032931]
	Learning Rate: 0.000329306
	LOSS [training: 0.05272986701566608 | validation: 0.04474544926361145]
	TIME [epoch: 10.3 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04735902616732633		[learning rate: 0.0003283]
	Learning Rate: 0.000328297
	LOSS [training: 0.04735902616732633 | validation: 0.03430706758372896]
	TIME [epoch: 10.3 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0387982462406994		[learning rate: 0.00032729]
	Learning Rate: 0.00032729
	LOSS [training: 0.0387982462406994 | validation: 0.02683760023559323]
	TIME [epoch: 10.3 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04661215328739808		[learning rate: 0.00032629]
	Learning Rate: 0.000326287
	LOSS [training: 0.04661215328739808 | validation: 0.04279034558212463]
	TIME [epoch: 10.3 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04248689325372333		[learning rate: 0.00032529]
	Learning Rate: 0.000325287
	LOSS [training: 0.04248689325372333 | validation: 0.0373781345492855]
	TIME [epoch: 10.3 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04137984226447654		[learning rate: 0.00032429]
	Learning Rate: 0.00032429
	LOSS [training: 0.04137984226447654 | validation: 0.03978956742391501]
	TIME [epoch: 10.3 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033038295695629424		[learning rate: 0.0003233]
	Learning Rate: 0.000323296
	LOSS [training: 0.033038295695629424 | validation: 0.03493833564430374]
	TIME [epoch: 10.3 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036599409108873306		[learning rate: 0.0003223]
	Learning Rate: 0.000322305
	LOSS [training: 0.036599409108873306 | validation: 0.025305867868269587]
	TIME [epoch: 10.3 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04296563405246104		[learning rate: 0.00032132]
	Learning Rate: 0.000321317
	LOSS [training: 0.04296563405246104 | validation: 0.01722700051010236]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_1620.pth
	Model improved!!!
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03802729657224757		[learning rate: 0.00032033]
	Learning Rate: 0.000320332
	LOSS [training: 0.03802729657224757 | validation: 0.034295699697333586]
	TIME [epoch: 10.3 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0332082559197046		[learning rate: 0.00031935]
	Learning Rate: 0.00031935
	LOSS [training: 0.0332082559197046 | validation: 0.034317486986076416]
	TIME [epoch: 10.3 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03393226965043433		[learning rate: 0.00031837]
	Learning Rate: 0.000318371
	LOSS [training: 0.03393226965043433 | validation: 0.03146465342579162]
	TIME [epoch: 10.3 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04105005339039518		[learning rate: 0.00031739]
	Learning Rate: 0.000317395
	LOSS [training: 0.04105005339039518 | validation: 0.03936576990582058]
	TIME [epoch: 10.3 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03540963577410909		[learning rate: 0.00031642]
	Learning Rate: 0.000316422
	LOSS [training: 0.03540963577410909 | validation: 0.03013377179747778]
	TIME [epoch: 10.3 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03740391272908986		[learning rate: 0.00031545]
	Learning Rate: 0.000315452
	LOSS [training: 0.03740391272908986 | validation: 0.03408399154859326]
	TIME [epoch: 10.3 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03322999165076692		[learning rate: 0.00031449]
	Learning Rate: 0.000314485
	LOSS [training: 0.03322999165076692 | validation: 0.019690421231561048]
	TIME [epoch: 10.3 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034575434420314785		[learning rate: 0.00031352]
	Learning Rate: 0.000313521
	LOSS [training: 0.034575434420314785 | validation: 0.03467260811607156]
	TIME [epoch: 10.3 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03130901193682846		[learning rate: 0.00031256]
	Learning Rate: 0.00031256
	LOSS [training: 0.03130901193682846 | validation: 0.02730754841112259]
	TIME [epoch: 10.3 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0343344679779035		[learning rate: 0.0003116]
	Learning Rate: 0.000311602
	LOSS [training: 0.0343344679779035 | validation: 0.026072349292063396]
	TIME [epoch: 10.3 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036190233674618835		[learning rate: 0.00031065]
	Learning Rate: 0.000310647
	LOSS [training: 0.036190233674618835 | validation: 0.041313265293578254]
	TIME [epoch: 10.3 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037505977754851635		[learning rate: 0.00030969]
	Learning Rate: 0.000309694
	LOSS [training: 0.037505977754851635 | validation: 0.02883809798424988]
	TIME [epoch: 10.3 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04142588304038583		[learning rate: 0.00030874]
	Learning Rate: 0.000308745
	LOSS [training: 0.04142588304038583 | validation: 0.044486245608392025]
	TIME [epoch: 10.2 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03746262446927177		[learning rate: 0.0003078]
	Learning Rate: 0.000307799
	LOSS [training: 0.03746262446927177 | validation: 0.029533341160370662]
	TIME [epoch: 10.3 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03634947467171841		[learning rate: 0.00030686]
	Learning Rate: 0.000306855
	LOSS [training: 0.03634947467171841 | validation: 0.040846007713034815]
	TIME [epoch: 10.3 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03217403080335961		[learning rate: 0.00030591]
	Learning Rate: 0.000305914
	LOSS [training: 0.03217403080335961 | validation: 0.04160952748180201]
	TIME [epoch: 10.3 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03798954336431366		[learning rate: 0.00030498]
	Learning Rate: 0.000304977
	LOSS [training: 0.03798954336431366 | validation: 0.03151853749802073]
	TIME [epoch: 10.3 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03928467572074539		[learning rate: 0.00030404]
	Learning Rate: 0.000304042
	LOSS [training: 0.03928467572074539 | validation: 0.03443619903714459]
	TIME [epoch: 10.3 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038683836822784645		[learning rate: 0.00030311]
	Learning Rate: 0.00030311
	LOSS [training: 0.038683836822784645 | validation: 0.04166665670373403]
	TIME [epoch: 10.3 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03773272790848729		[learning rate: 0.00030218]
	Learning Rate: 0.000302181
	LOSS [training: 0.03773272790848729 | validation: 0.04334940036636004]
	TIME [epoch: 10.3 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03723879345006686		[learning rate: 0.00030125]
	Learning Rate: 0.000301254
	LOSS [training: 0.03723879345006686 | validation: 0.04446140348680865]
	TIME [epoch: 10.3 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037783432700950866		[learning rate: 0.00030033]
	Learning Rate: 0.000300331
	LOSS [training: 0.037783432700950866 | validation: 0.02960775682597338]
	TIME [epoch: 10.3 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04506808497166277		[learning rate: 0.00029941]
	Learning Rate: 0.00029941
	LOSS [training: 0.04506808497166277 | validation: 0.03512346213321559]
	TIME [epoch: 10.3 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04095437660541016		[learning rate: 0.00029849]
	Learning Rate: 0.000298492
	LOSS [training: 0.04095437660541016 | validation: 0.03181909519746731]
	TIME [epoch: 10.3 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03587577667034214		[learning rate: 0.00029758]
	Learning Rate: 0.000297577
	LOSS [training: 0.03587577667034214 | validation: 0.028332470782535802]
	TIME [epoch: 10.3 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03455262546143682		[learning rate: 0.00029667]
	Learning Rate: 0.000296665
	LOSS [training: 0.03455262546143682 | validation: 0.026070436063474322]
	TIME [epoch: 10.3 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03270323131166947		[learning rate: 0.00029576]
	Learning Rate: 0.000295756
	LOSS [training: 0.03270323131166947 | validation: 0.029881026753641484]
	TIME [epoch: 10.3 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044219153647522914		[learning rate: 0.00029485]
	Learning Rate: 0.000294849
	LOSS [training: 0.044219153647522914 | validation: 0.02932825937934544]
	TIME [epoch: 10.3 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03977837444676473		[learning rate: 0.00029395]
	Learning Rate: 0.000293945
	LOSS [training: 0.03977837444676473 | validation: 0.04985741728780102]
	TIME [epoch: 10.3 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04192640651834681		[learning rate: 0.00029304]
	Learning Rate: 0.000293044
	LOSS [training: 0.04192640651834681 | validation: 0.04344348791448519]
	TIME [epoch: 10.3 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045811898282331884		[learning rate: 0.00029215]
	Learning Rate: 0.000292146
	LOSS [training: 0.045811898282331884 | validation: 0.04334055124393138]
	TIME [epoch: 10.3 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04872631781937042		[learning rate: 0.00029125]
	Learning Rate: 0.00029125
	LOSS [training: 0.04872631781937042 | validation: 0.03691156594713591]
	TIME [epoch: 10.3 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03929025803838132		[learning rate: 0.00029036]
	Learning Rate: 0.000290358
	LOSS [training: 0.03929025803838132 | validation: 0.03120765027482267]
	TIME [epoch: 10.3 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04625770413400759		[learning rate: 0.00028947]
	Learning Rate: 0.000289468
	LOSS [training: 0.04625770413400759 | validation: 0.04281469333971983]
	TIME [epoch: 10.3 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038576928153214306		[learning rate: 0.00028858]
	Learning Rate: 0.00028858
	LOSS [training: 0.038576928153214306 | validation: 0.03320848330735753]
	TIME [epoch: 10.3 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03544120104874849		[learning rate: 0.0002877]
	Learning Rate: 0.000287696
	LOSS [training: 0.03544120104874849 | validation: 0.030993784541825595]
	TIME [epoch: 10.3 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03946551249625431		[learning rate: 0.00028681]
	Learning Rate: 0.000286814
	LOSS [training: 0.03946551249625431 | validation: 0.03216874347274666]
	TIME [epoch: 10.3 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03721332137862767		[learning rate: 0.00028593]
	Learning Rate: 0.000285935
	LOSS [training: 0.03721332137862767 | validation: 0.017491176813345773]
	TIME [epoch: 10.3 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04356171514756061		[learning rate: 0.00028506]
	Learning Rate: 0.000285058
	LOSS [training: 0.04356171514756061 | validation: 0.04182813224863256]
	TIME [epoch: 10.3 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.043468295576559526		[learning rate: 0.00028418]
	Learning Rate: 0.000284184
	LOSS [training: 0.043468295576559526 | validation: 0.030832359966504408]
	TIME [epoch: 10.3 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03791249349106422		[learning rate: 0.00028331]
	Learning Rate: 0.000283313
	LOSS [training: 0.03791249349106422 | validation: 0.02390558147271463]
	TIME [epoch: 10.3 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03975431809031451		[learning rate: 0.00028244]
	Learning Rate: 0.000282445
	LOSS [training: 0.03975431809031451 | validation: 0.02223272378414517]
	TIME [epoch: 10.3 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04183000239077137		[learning rate: 0.00028158]
	Learning Rate: 0.000281579
	LOSS [training: 0.04183000239077137 | validation: 0.026783464772761053]
	TIME [epoch: 10.3 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03806965301975388		[learning rate: 0.00028072]
	Learning Rate: 0.000280716
	LOSS [training: 0.03806965301975388 | validation: 0.03468794185699212]
	TIME [epoch: 10.3 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03850298813962805		[learning rate: 0.00027986]
	Learning Rate: 0.000279855
	LOSS [training: 0.03850298813962805 | validation: 0.03065114612100897]
	TIME [epoch: 10.3 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04015938773893096		[learning rate: 0.000279]
	Learning Rate: 0.000278997
	LOSS [training: 0.04015938773893096 | validation: 0.03715287840128653]
	TIME [epoch: 10.3 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03726329490625062		[learning rate: 0.00027814]
	Learning Rate: 0.000278142
	LOSS [training: 0.03726329490625062 | validation: 0.030055337282138616]
	TIME [epoch: 10.3 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03440157608157895		[learning rate: 0.00027729]
	Learning Rate: 0.000277289
	LOSS [training: 0.03440157608157895 | validation: 0.02782571823716567]
	TIME [epoch: 10.3 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03767014065439759		[learning rate: 0.00027644]
	Learning Rate: 0.000276439
	LOSS [training: 0.03767014065439759 | validation: 0.031131053568369708]
	TIME [epoch: 10.3 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040821440535418925		[learning rate: 0.00027559]
	Learning Rate: 0.000275592
	LOSS [training: 0.040821440535418925 | validation: 0.028358197670435997]
	TIME [epoch: 10.3 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03702840747349005		[learning rate: 0.00027475]
	Learning Rate: 0.000274747
	LOSS [training: 0.03702840747349005 | validation: 0.036406049121565996]
	TIME [epoch: 10.3 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03576126101456084		[learning rate: 0.00027391]
	Learning Rate: 0.000273905
	LOSS [training: 0.03576126101456084 | validation: 0.0434338465592648]
	TIME [epoch: 10.3 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036116113461918994		[learning rate: 0.00027307]
	Learning Rate: 0.000273065
	LOSS [training: 0.036116113461918994 | validation: 0.021565410996811557]
	TIME [epoch: 10.3 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03682199706768245		[learning rate: 0.00027223]
	Learning Rate: 0.000272228
	LOSS [training: 0.03682199706768245 | validation: 0.03191587403171881]
	TIME [epoch: 10.3 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035288776059520854		[learning rate: 0.00027139]
	Learning Rate: 0.000271394
	LOSS [training: 0.035288776059520854 | validation: 0.04348129717521488]
	TIME [epoch: 10.3 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04340456237150552		[learning rate: 0.00027056]
	Learning Rate: 0.000270562
	LOSS [training: 0.04340456237150552 | validation: 0.03472273323300156]
	TIME [epoch: 10.3 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03997207108535179		[learning rate: 0.00026973]
	Learning Rate: 0.000269733
	LOSS [training: 0.03997207108535179 | validation: 0.036870892513940164]
	TIME [epoch: 10.3 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03360091648226988		[learning rate: 0.00026891]
	Learning Rate: 0.000268906
	LOSS [training: 0.03360091648226988 | validation: 0.029480274673213538]
	TIME [epoch: 10.3 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033258071137390856		[learning rate: 0.00026808]
	Learning Rate: 0.000268081
	LOSS [training: 0.033258071137390856 | validation: 0.027739419618990815]
	TIME [epoch: 10.3 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031419927128312694		[learning rate: 0.00026726]
	Learning Rate: 0.00026726
	LOSS [training: 0.031419927128312694 | validation: 0.02710645006718217]
	TIME [epoch: 10.3 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0325252865750516		[learning rate: 0.00026644]
	Learning Rate: 0.00026644
	LOSS [training: 0.0325252865750516 | validation: 0.0369092758672641]
	TIME [epoch: 10.3 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03246379022085798		[learning rate: 0.00026562]
	Learning Rate: 0.000265624
	LOSS [training: 0.03246379022085798 | validation: 0.05214867705325137]
	TIME [epoch: 10.3 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03472200846655009		[learning rate: 0.00026481]
	Learning Rate: 0.000264809
	LOSS [training: 0.03472200846655009 | validation: 0.021476460813414713]
	TIME [epoch: 10.3 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02999732595805128		[learning rate: 0.000264]
	Learning Rate: 0.000263998
	LOSS [training: 0.02999732595805128 | validation: 0.019965767736417613]
	TIME [epoch: 10.2 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037446723311497135		[learning rate: 0.00026319]
	Learning Rate: 0.000263188
	LOSS [training: 0.037446723311497135 | validation: 0.031114419688335344]
	TIME [epoch: 10.3 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03363606529415823		[learning rate: 0.00026238]
	Learning Rate: 0.000262382
	LOSS [training: 0.03363606529415823 | validation: 0.04324311626737318]
	TIME [epoch: 10.3 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0364069062118836		[learning rate: 0.00026158]
	Learning Rate: 0.000261577
	LOSS [training: 0.0364069062118836 | validation: 0.020528688267144334]
	TIME [epoch: 10.3 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03191148902574825		[learning rate: 0.00026078]
	Learning Rate: 0.000260775
	LOSS [training: 0.03191148902574825 | validation: 0.023257358386879288]
	TIME [epoch: 10.3 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03746242958134689		[learning rate: 0.00025998]
	Learning Rate: 0.000259976
	LOSS [training: 0.03746242958134689 | validation: 0.048535774868879084]
	TIME [epoch: 10.3 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03448845285223455		[learning rate: 0.00025918]
	Learning Rate: 0.000259179
	LOSS [training: 0.03448845285223455 | validation: 0.0156051058388611]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_1690.pth
	Model improved!!!
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03781150016288724		[learning rate: 0.00025838]
	Learning Rate: 0.000258385
	LOSS [training: 0.03781150016288724 | validation: 0.028273722639643114]
	TIME [epoch: 10.3 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04094231066678252		[learning rate: 0.00025759]
	Learning Rate: 0.000257593
	LOSS [training: 0.04094231066678252 | validation: 0.03235310484978132]
	TIME [epoch: 10.3 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041626647616593716		[learning rate: 0.0002568]
	Learning Rate: 0.000256803
	LOSS [training: 0.041626647616593716 | validation: 0.041340671861329295]
	TIME [epoch: 10.3 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03832548600461989		[learning rate: 0.00025602]
	Learning Rate: 0.000256016
	LOSS [training: 0.03832548600461989 | validation: 0.022538971054994538]
	TIME [epoch: 10.3 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03879810752049663		[learning rate: 0.00025523]
	Learning Rate: 0.000255231
	LOSS [training: 0.03879810752049663 | validation: 0.0386883651462245]
	TIME [epoch: 10.3 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0398375380034942		[learning rate: 0.00025445]
	Learning Rate: 0.000254449
	LOSS [training: 0.0398375380034942 | validation: 0.04048322438591863]
	TIME [epoch: 10.3 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04334366480876097		[learning rate: 0.00025367]
	Learning Rate: 0.000253669
	LOSS [training: 0.04334366480876097 | validation: 0.03912678915183895]
	TIME [epoch: 10.3 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042831005579298954		[learning rate: 0.00025289]
	Learning Rate: 0.000252891
	LOSS [training: 0.042831005579298954 | validation: 0.03955518875156554]
	TIME [epoch: 10.3 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04205439426672114		[learning rate: 0.00025212]
	Learning Rate: 0.000252116
	LOSS [training: 0.04205439426672114 | validation: 0.03534397085815573]
	TIME [epoch: 10.3 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03669794656221365		[learning rate: 0.00025134]
	Learning Rate: 0.000251343
	LOSS [training: 0.03669794656221365 | validation: 0.040344494317933764]
	TIME [epoch: 10.3 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030658837593186182		[learning rate: 0.00025057]
	Learning Rate: 0.000250572
	LOSS [training: 0.030658837593186182 | validation: 0.02567105675695546]
	TIME [epoch: 10.3 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03690405815972188		[learning rate: 0.0002498]
	Learning Rate: 0.000249804
	LOSS [training: 0.03690405815972188 | validation: 0.04119970426829231]
	TIME [epoch: 10.3 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040958864148666625		[learning rate: 0.00024904]
	Learning Rate: 0.000249039
	LOSS [training: 0.040958864148666625 | validation: 0.02944829214967121]
	TIME [epoch: 10.3 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03683919677403449		[learning rate: 0.00024828]
	Learning Rate: 0.000248275
	LOSS [training: 0.03683919677403449 | validation: 0.035371055935463504]
	TIME [epoch: 10.3 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.049017102724558864		[learning rate: 0.00024751]
	Learning Rate: 0.000247514
	LOSS [training: 0.049017102724558864 | validation: 0.027750990485439966]
	TIME [epoch: 10.3 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04626542687304498		[learning rate: 0.00024676]
	Learning Rate: 0.000246755
	LOSS [training: 0.04626542687304498 | validation: 0.0384423116846268]
	TIME [epoch: 10.3 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0515129503611079		[learning rate: 0.000246]
	Learning Rate: 0.000245999
	LOSS [training: 0.0515129503611079 | validation: 0.06165185994590493]
	TIME [epoch: 10.3 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04974786673888692		[learning rate: 0.00024524]
	Learning Rate: 0.000245245
	LOSS [training: 0.04974786673888692 | validation: 0.04914614020429793]
	TIME [epoch: 10.3 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03667628445602779		[learning rate: 0.00024449]
	Learning Rate: 0.000244493
	LOSS [training: 0.03667628445602779 | validation: 0.0338103370380232]
	TIME [epoch: 10.3 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03513939945678547		[learning rate: 0.00024374]
	Learning Rate: 0.000243744
	LOSS [training: 0.03513939945678547 | validation: 0.035809533125228006]
	TIME [epoch: 10.3 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04166568936969102		[learning rate: 0.000243]
	Learning Rate: 0.000242996
	LOSS [training: 0.04166568936969102 | validation: 0.038328371459695906]
	TIME [epoch: 10.3 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04490501649000098		[learning rate: 0.00024225]
	Learning Rate: 0.000242252
	LOSS [training: 0.04490501649000098 | validation: 0.04302653669425209]
	TIME [epoch: 10.3 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042945674922547535		[learning rate: 0.00024151]
	Learning Rate: 0.000241509
	LOSS [training: 0.042945674922547535 | validation: 0.04000698008869561]
	TIME [epoch: 10.3 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03584724479091851		[learning rate: 0.00024077]
	Learning Rate: 0.000240769
	LOSS [training: 0.03584724479091851 | validation: 0.047163482702408714]
	TIME [epoch: 10.3 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03782447527464557		[learning rate: 0.00024003]
	Learning Rate: 0.000240031
	LOSS [training: 0.03782447527464557 | validation: 0.03399447802383812]
	TIME [epoch: 10.3 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03678484137869207		[learning rate: 0.00023929]
	Learning Rate: 0.000239295
	LOSS [training: 0.03678484137869207 | validation: 0.03735510353346912]
	TIME [epoch: 10.3 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03910487017746196		[learning rate: 0.00023856]
	Learning Rate: 0.000238561
	LOSS [training: 0.03910487017746196 | validation: 0.02613273963302032]
	TIME [epoch: 10.3 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03471451176571294		[learning rate: 0.00023783]
	Learning Rate: 0.00023783
	LOSS [training: 0.03471451176571294 | validation: 0.024124117939445352]
	TIME [epoch: 10.3 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03971854296098273		[learning rate: 0.0002371]
	Learning Rate: 0.000237101
	LOSS [training: 0.03971854296098273 | validation: 0.03802217333792875]
	TIME [epoch: 10.3 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031155979534740995		[learning rate: 0.00023637]
	Learning Rate: 0.000236374
	LOSS [training: 0.031155979534740995 | validation: 0.026138258229696003]
	TIME [epoch: 10.3 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035188874074409966		[learning rate: 0.00023565]
	Learning Rate: 0.00023565
	LOSS [training: 0.035188874074409966 | validation: 0.024318214361890748]
	TIME [epoch: 10.3 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03802572307233436		[learning rate: 0.00023493]
	Learning Rate: 0.000234927
	LOSS [training: 0.03802572307233436 | validation: 0.03277625323819836]
	TIME [epoch: 10.3 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03589266515565494		[learning rate: 0.00023421]
	Learning Rate: 0.000234207
	LOSS [training: 0.03589266515565494 | validation: 0.02749018163288403]
	TIME [epoch: 10.3 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034577799970581594		[learning rate: 0.00023349]
	Learning Rate: 0.000233489
	LOSS [training: 0.034577799970581594 | validation: 0.023117148931707823]
	TIME [epoch: 10.3 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042453762936301646		[learning rate: 0.00023277]
	Learning Rate: 0.000232773
	LOSS [training: 0.042453762936301646 | validation: 0.03167798943077535]
	TIME [epoch: 10.3 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038355770738588396		[learning rate: 0.00023206]
	Learning Rate: 0.00023206
	LOSS [training: 0.038355770738588396 | validation: 0.028768510016095063]
	TIME [epoch: 10.3 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035519359534293256		[learning rate: 0.00023135]
	Learning Rate: 0.000231348
	LOSS [training: 0.035519359534293256 | validation: 0.039770799458298874]
	TIME [epoch: 10.3 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030036244059453526		[learning rate: 0.00023064]
	Learning Rate: 0.000230639
	LOSS [training: 0.030036244059453526 | validation: 0.0300367004122702]
	TIME [epoch: 10.3 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036286895888446316		[learning rate: 0.00022993]
	Learning Rate: 0.000229932
	LOSS [training: 0.036286895888446316 | validation: 0.016532450235447724]
	TIME [epoch: 10.3 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038689870818794714		[learning rate: 0.00022923]
	Learning Rate: 0.000229227
	LOSS [training: 0.038689870818794714 | validation: 0.02547553603109847]
	TIME [epoch: 10.3 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0402989622466859		[learning rate: 0.00022852]
	Learning Rate: 0.000228525
	LOSS [training: 0.0402989622466859 | validation: 0.033255927797634026]
	TIME [epoch: 10.3 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03544758072300218		[learning rate: 0.00022782]
	Learning Rate: 0.000227824
	LOSS [training: 0.03544758072300218 | validation: 0.02264003330155791]
	TIME [epoch: 10.3 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03797841670213276		[learning rate: 0.00022713]
	Learning Rate: 0.000227126
	LOSS [training: 0.03797841670213276 | validation: 0.04035069799364233]
	TIME [epoch: 10.3 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04427539744828211		[learning rate: 0.00022643]
	Learning Rate: 0.00022643
	LOSS [training: 0.04427539744828211 | validation: 0.038678333483046064]
	TIME [epoch: 10.3 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03953095746730657		[learning rate: 0.00022574]
	Learning Rate: 0.000225736
	LOSS [training: 0.03953095746730657 | validation: 0.03585459365869587]
	TIME [epoch: 10.3 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045225671338547616		[learning rate: 0.00022504]
	Learning Rate: 0.000225044
	LOSS [training: 0.045225671338547616 | validation: 0.054182748799308234]
	TIME [epoch: 10.3 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05810351320809416		[learning rate: 0.00022435]
	Learning Rate: 0.000224354
	LOSS [training: 0.05810351320809416 | validation: 0.06059099983961045]
	TIME [epoch: 10.3 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05791402907897558		[learning rate: 0.00022367]
	Learning Rate: 0.000223666
	LOSS [training: 0.05791402907897558 | validation: 0.04173390572447011]
	TIME [epoch: 10.3 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05237680788782941		[learning rate: 0.00022298]
	Learning Rate: 0.00022298
	LOSS [training: 0.05237680788782941 | validation: 0.0460603895803396]
	TIME [epoch: 10.3 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04780229435894815		[learning rate: 0.0002223]
	Learning Rate: 0.000222297
	LOSS [training: 0.04780229435894815 | validation: 0.04197160056220167]
	TIME [epoch: 10.3 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03900394256814228		[learning rate: 0.00022162]
	Learning Rate: 0.000221615
	LOSS [training: 0.03900394256814228 | validation: 0.041280412727565975]
	TIME [epoch: 10.3 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03878106588752358		[learning rate: 0.00022094]
	Learning Rate: 0.000220936
	LOSS [training: 0.03878106588752358 | validation: 0.03720045301727347]
	TIME [epoch: 10.3 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04669693884296734		[learning rate: 0.00022026]
	Learning Rate: 0.000220259
	LOSS [training: 0.04669693884296734 | validation: 0.04598478790521009]
	TIME [epoch: 10.3 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.045872410451440054		[learning rate: 0.00021958]
	Learning Rate: 0.000219584
	LOSS [training: 0.045872410451440054 | validation: 0.03548821292427923]
	TIME [epoch: 10.3 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031353873026028455		[learning rate: 0.00021891]
	Learning Rate: 0.000218911
	LOSS [training: 0.031353873026028455 | validation: 0.020403601133978037]
	TIME [epoch: 10.3 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036700661766722834		[learning rate: 0.00021824]
	Learning Rate: 0.000218239
	LOSS [training: 0.036700661766722834 | validation: 0.033253736999459244]
	TIME [epoch: 10.3 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03890283016346106		[learning rate: 0.00021757]
	Learning Rate: 0.00021757
	LOSS [training: 0.03890283016346106 | validation: 0.030971712033345224]
	TIME [epoch: 10.4 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035116483933639794		[learning rate: 0.0002169]
	Learning Rate: 0.000216904
	LOSS [training: 0.035116483933639794 | validation: 0.03143763466605833]
	TIME [epoch: 10.3 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03953003278479335		[learning rate: 0.00021624]
	Learning Rate: 0.000216239
	LOSS [training: 0.03953003278479335 | validation: 0.03104811139350894]
	TIME [epoch: 10.3 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03627780898164608		[learning rate: 0.00021558]
	Learning Rate: 0.000215576
	LOSS [training: 0.03627780898164608 | validation: 0.026782317782234596]
	TIME [epoch: 10.3 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031588113827672404		[learning rate: 0.00021491]
	Learning Rate: 0.000214915
	LOSS [training: 0.031588113827672404 | validation: 0.029529273948266814]
	TIME [epoch: 10.3 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02683096013053853		[learning rate: 0.00021426]
	Learning Rate: 0.000214256
	LOSS [training: 0.02683096013053853 | validation: 0.028317822246208324]
	TIME [epoch: 10.3 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024044684182197257		[learning rate: 0.0002136]
	Learning Rate: 0.000213599
	LOSS [training: 0.024044684182197257 | validation: 0.01482605790226324]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_1753.pth
	Model improved!!!
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031235169724906014		[learning rate: 0.00021294]
	Learning Rate: 0.000212945
	LOSS [training: 0.031235169724906014 | validation: 0.014988089559493201]
	TIME [epoch: 10.3 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03363531664370343		[learning rate: 0.00021229]
	Learning Rate: 0.000212292
	LOSS [training: 0.03363531664370343 | validation: 0.023103077238089385]
	TIME [epoch: 10.3 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03028392254303272		[learning rate: 0.00021164]
	Learning Rate: 0.000211641
	LOSS [training: 0.03028392254303272 | validation: 0.027324083383502652]
	TIME [epoch: 10.3 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03634319973971624		[learning rate: 0.00021099]
	Learning Rate: 0.000210992
	LOSS [training: 0.03634319973971624 | validation: 0.04363765675061913]
	TIME [epoch: 10.3 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036228090187980906		[learning rate: 0.00021035]
	Learning Rate: 0.000210346
	LOSS [training: 0.036228090187980906 | validation: 0.02034519916108799]
	TIME [epoch: 10.3 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031849316481527536		[learning rate: 0.0002097]
	Learning Rate: 0.000209701
	LOSS [training: 0.031849316481527536 | validation: 0.02249192472330324]
	TIME [epoch: 10.3 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042929766866723666		[learning rate: 0.00020906]
	Learning Rate: 0.000209058
	LOSS [training: 0.042929766866723666 | validation: 0.026891899499281315]
	TIME [epoch: 10.3 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03307455532559659		[learning rate: 0.00020842]
	Learning Rate: 0.000208417
	LOSS [training: 0.03307455532559659 | validation: 0.013954914124758116]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_1761.pth
	Model improved!!!
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031995910005476316		[learning rate: 0.00020778]
	Learning Rate: 0.000207778
	LOSS [training: 0.031995910005476316 | validation: 0.02212546098294486]
	TIME [epoch: 10.3 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03871323355971547		[learning rate: 0.00020714]
	Learning Rate: 0.000207141
	LOSS [training: 0.03871323355971547 | validation: 0.03217204747003654]
	TIME [epoch: 10.3 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04244765913324074		[learning rate: 0.00020651]
	Learning Rate: 0.000206506
	LOSS [training: 0.04244765913324074 | validation: 0.03418620208696048]
	TIME [epoch: 10.3 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.044577697988001326		[learning rate: 0.00020587]
	Learning Rate: 0.000205873
	LOSS [training: 0.044577697988001326 | validation: 0.034798139904536625]
	TIME [epoch: 10.3 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0369030364977279		[learning rate: 0.00020524]
	Learning Rate: 0.000205242
	LOSS [training: 0.0369030364977279 | validation: 0.030069431003766207]
	TIME [epoch: 10.3 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04836286581685411		[learning rate: 0.00020461]
	Learning Rate: 0.000204613
	LOSS [training: 0.04836286581685411 | validation: 0.027669040018673218]
	TIME [epoch: 10.3 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04139878217580849		[learning rate: 0.00020399]
	Learning Rate: 0.000203986
	LOSS [training: 0.04139878217580849 | validation: 0.037867231258044115]
	TIME [epoch: 10.3 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03897021413546198		[learning rate: 0.00020336]
	Learning Rate: 0.00020336
	LOSS [training: 0.03897021413546198 | validation: 0.021141480539889734]
	TIME [epoch: 10.3 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03404307938216439		[learning rate: 0.00020274]
	Learning Rate: 0.000202737
	LOSS [training: 0.03404307938216439 | validation: 0.0355638179942492]
	TIME [epoch: 10.3 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03517925447222007		[learning rate: 0.00020212]
	Learning Rate: 0.000202116
	LOSS [training: 0.03517925447222007 | validation: 0.03025900833530679]
	TIME [epoch: 10.3 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03388817596331058		[learning rate: 0.0002015]
	Learning Rate: 0.000201496
	LOSS [training: 0.03388817596331058 | validation: 0.02814266629232342]
	TIME [epoch: 10.3 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03146251403769976		[learning rate: 0.00020088]
	Learning Rate: 0.000200878
	LOSS [training: 0.03146251403769976 | validation: 0.0174803028150612]
	TIME [epoch: 10.3 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.042730783021547133		[learning rate: 0.00020026]
	Learning Rate: 0.000200263
	LOSS [training: 0.042730783021547133 | validation: 0.026085788328158277]
	TIME [epoch: 10.3 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03650937664744629		[learning rate: 0.00019965]
	Learning Rate: 0.000199649
	LOSS [training: 0.03650937664744629 | validation: 0.025857060077069276]
	TIME [epoch: 10.3 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03486264923657297		[learning rate: 0.00019904]
	Learning Rate: 0.000199037
	LOSS [training: 0.03486264923657297 | validation: 0.019930073671364085]
	TIME [epoch: 10.3 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029379690704302318		[learning rate: 0.00019843]
	Learning Rate: 0.000198427
	LOSS [training: 0.029379690704302318 | validation: 0.030297707899778283]
	TIME [epoch: 10.3 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03686832428747864		[learning rate: 0.00019782]
	Learning Rate: 0.000197818
	LOSS [training: 0.03686832428747864 | validation: 0.02803303187577539]
	TIME [epoch: 10.3 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03861781186553635		[learning rate: 0.00019721]
	Learning Rate: 0.000197212
	LOSS [training: 0.03861781186553635 | validation: 0.039698503573458804]
	TIME [epoch: 10.3 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037107596065820425		[learning rate: 0.00019661]
	Learning Rate: 0.000196607
	LOSS [training: 0.037107596065820425 | validation: 0.020932531442858667]
	TIME [epoch: 10.3 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030529371696416407		[learning rate: 0.000196]
	Learning Rate: 0.000196005
	LOSS [training: 0.030529371696416407 | validation: 0.024997492185189145]
	TIME [epoch: 10.3 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03525394676093494		[learning rate: 0.0001954]
	Learning Rate: 0.000195404
	LOSS [training: 0.03525394676093494 | validation: 0.020017560589377145]
	TIME [epoch: 10.3 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033856341122398326		[learning rate: 0.0001948]
	Learning Rate: 0.000194805
	LOSS [training: 0.033856341122398326 | validation: 0.016130285403292685]
	TIME [epoch: 10.3 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03753120498102597		[learning rate: 0.00019421]
	Learning Rate: 0.000194208
	LOSS [training: 0.03753120498102597 | validation: 0.010573666789589336]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_1784.pth
	Model improved!!!
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03577991202708742		[learning rate: 0.00019361]
	Learning Rate: 0.000193612
	LOSS [training: 0.03577991202708742 | validation: 0.019890616790676368]
	TIME [epoch: 10.3 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032682009335327465		[learning rate: 0.00019302]
	Learning Rate: 0.000193019
	LOSS [training: 0.032682009335327465 | validation: 0.030092015421360283]
	TIME [epoch: 10.3 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04113584138816293		[learning rate: 0.00019243]
	Learning Rate: 0.000192427
	LOSS [training: 0.04113584138816293 | validation: 0.021822642577644574]
	TIME [epoch: 10.3 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03607252577490417		[learning rate: 0.00019184]
	Learning Rate: 0.000191837
	LOSS [training: 0.03607252577490417 | validation: 0.027349114000110034]
	TIME [epoch: 10.3 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03070040916583171		[learning rate: 0.00019125]
	Learning Rate: 0.000191249
	LOSS [training: 0.03070040916583171 | validation: 0.01754069895895835]
	TIME [epoch: 10.3 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03885875445191959		[learning rate: 0.00019066]
	Learning Rate: 0.000190663
	LOSS [training: 0.03885875445191959 | validation: 0.026942043857165827]
	TIME [epoch: 10.3 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.039082792880976054		[learning rate: 0.00019008]
	Learning Rate: 0.000190079
	LOSS [training: 0.039082792880976054 | validation: 0.03066196527885389]
	TIME [epoch: 10.3 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03639810671227506		[learning rate: 0.0001895]
	Learning Rate: 0.000189496
	LOSS [training: 0.03639810671227506 | validation: 0.02415175573776089]
	TIME [epoch: 10.3 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03209619618549905		[learning rate: 0.00018892]
	Learning Rate: 0.000188915
	LOSS [training: 0.03209619618549905 | validation: 0.020343267688772464]
	TIME [epoch: 10.3 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03636546086608266		[learning rate: 0.00018834]
	Learning Rate: 0.000188336
	LOSS [training: 0.03636546086608266 | validation: 0.020343501622372164]
	TIME [epoch: 10.3 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03633472808518394		[learning rate: 0.00018776]
	Learning Rate: 0.000187759
	LOSS [training: 0.03633472808518394 | validation: 0.02051532948982701]
	TIME [epoch: 10.3 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03673848843527118		[learning rate: 0.00018718]
	Learning Rate: 0.000187183
	LOSS [training: 0.03673848843527118 | validation: 0.02741174401467536]
	TIME [epoch: 10.3 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03182598861096103		[learning rate: 0.00018661]
	Learning Rate: 0.000186609
	LOSS [training: 0.03182598861096103 | validation: 0.020507368913430947]
	TIME [epoch: 10.3 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030173121018021592		[learning rate: 0.00018604]
	Learning Rate: 0.000186037
	LOSS [training: 0.030173121018021592 | validation: 0.018177525441757096]
	TIME [epoch: 10.3 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03388773065243021		[learning rate: 0.00018547]
	Learning Rate: 0.000185467
	LOSS [training: 0.03388773065243021 | validation: 0.034365115055882994]
	TIME [epoch: 10.3 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034085030034391194		[learning rate: 0.0001849]
	Learning Rate: 0.000184898
	LOSS [training: 0.034085030034391194 | validation: 0.03017180452300426]
	TIME [epoch: 10.3 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03839181346119809		[learning rate: 0.00018433]
	Learning Rate: 0.000184332
	LOSS [training: 0.03839181346119809 | validation: 0.04041833836515032]
	TIME [epoch: 10.3 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03835998677699297		[learning rate: 0.00018377]
	Learning Rate: 0.000183767
	LOSS [training: 0.03835998677699297 | validation: 0.03559450775001121]
	TIME [epoch: 10.3 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030992089173013816		[learning rate: 0.0001832]
	Learning Rate: 0.000183203
	LOSS [training: 0.030992089173013816 | validation: 0.02512550009523527]
	TIME [epoch: 10.3 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.041816051429421124		[learning rate: 0.00018264]
	Learning Rate: 0.000182642
	LOSS [training: 0.041816051429421124 | validation: 0.023688827842970266]
	TIME [epoch: 10.3 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04700068492536352		[learning rate: 0.00018208]
	Learning Rate: 0.000182082
	LOSS [training: 0.04700068492536352 | validation: 0.03962362699738257]
	TIME [epoch: 10.3 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035956231840964734		[learning rate: 0.00018152]
	Learning Rate: 0.000181524
	LOSS [training: 0.035956231840964734 | validation: 0.024027748966309895]
	TIME [epoch: 10.3 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03469176467313588		[learning rate: 0.00018097]
	Learning Rate: 0.000180967
	LOSS [training: 0.03469176467313588 | validation: 0.011427198878332174]
	TIME [epoch: 10.3 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03075920755570481		[learning rate: 0.00018041]
	Learning Rate: 0.000180412
	LOSS [training: 0.03075920755570481 | validation: 0.01772444592134457]
	TIME [epoch: 10.3 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03674804138818995		[learning rate: 0.00017986]
	Learning Rate: 0.000179859
	LOSS [training: 0.03674804138818995 | validation: 0.014848639825768175]
	TIME [epoch: 10.3 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034319762906006905		[learning rate: 0.00017931]
	Learning Rate: 0.000179308
	LOSS [training: 0.034319762906006905 | validation: 0.01871571050345169]
	TIME [epoch: 10.3 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035013402516173325		[learning rate: 0.00017876]
	Learning Rate: 0.000178758
	LOSS [training: 0.035013402516173325 | validation: 0.01680808417784008]
	TIME [epoch: 10.3 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035927055932552104		[learning rate: 0.00017821]
	Learning Rate: 0.00017821
	LOSS [training: 0.035927055932552104 | validation: 0.029049930275878523]
	TIME [epoch: 10.3 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02810681821590206		[learning rate: 0.00017766]
	Learning Rate: 0.000177664
	LOSS [training: 0.02810681821590206 | validation: 0.030140770504368204]
	TIME [epoch: 10.3 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03224145905924612		[learning rate: 0.00017712]
	Learning Rate: 0.00017712
	LOSS [training: 0.03224145905924612 | validation: 0.01409579463861574]
	TIME [epoch: 10.2 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03130593662397674		[learning rate: 0.00017658]
	Learning Rate: 0.000176577
	LOSS [training: 0.03130593662397674 | validation: 0.015600319304658253]
	TIME [epoch: 10.3 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030607346722910565		[learning rate: 0.00017604]
	Learning Rate: 0.000176035
	LOSS [training: 0.030607346722910565 | validation: 0.026149097107775913]
	TIME [epoch: 10.3 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028300334381599023		[learning rate: 0.0001755]
	Learning Rate: 0.000175496
	LOSS [training: 0.028300334381599023 | validation: 0.024370156052317214]
	TIME [epoch: 10.3 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03754295950101224		[learning rate: 0.00017496]
	Learning Rate: 0.000174958
	LOSS [training: 0.03754295950101224 | validation: 0.020288042846204814]
	TIME [epoch: 10.2 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03395465125111961		[learning rate: 0.00017442]
	Learning Rate: 0.000174421
	LOSS [training: 0.03395465125111961 | validation: 0.02483409202603264]
	TIME [epoch: 10.3 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0331851700673995		[learning rate: 0.00017389]
	Learning Rate: 0.000173887
	LOSS [training: 0.0331851700673995 | validation: 0.03223185422480936]
	TIME [epoch: 10.3 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03947387845579243		[learning rate: 0.00017335]
	Learning Rate: 0.000173354
	LOSS [training: 0.03947387845579243 | validation: 0.021721860448347233]
	TIME [epoch: 10.3 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0323838586809534		[learning rate: 0.00017282]
	Learning Rate: 0.000172822
	LOSS [training: 0.0323838586809534 | validation: 0.03362611233529607]
	TIME [epoch: 10.3 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03588776150502002		[learning rate: 0.00017229]
	Learning Rate: 0.000172293
	LOSS [training: 0.03588776150502002 | validation: 0.03175674080798634]
	TIME [epoch: 10.3 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03144858424594734		[learning rate: 0.00017176]
	Learning Rate: 0.000171764
	LOSS [training: 0.03144858424594734 | validation: 0.03297043692112429]
	TIME [epoch: 10.3 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031421891792903105		[learning rate: 0.00017124]
	Learning Rate: 0.000171238
	LOSS [training: 0.031421891792903105 | validation: 0.028608328027018105]
	TIME [epoch: 10.3 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03399836410316791		[learning rate: 0.00017071]
	Learning Rate: 0.000170713
	LOSS [training: 0.03399836410316791 | validation: 0.02440057901722531]
	TIME [epoch: 10.3 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033496478177605385		[learning rate: 0.00017019]
	Learning Rate: 0.00017019
	LOSS [training: 0.033496478177605385 | validation: 0.033942414473513635]
	TIME [epoch: 10.3 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036421906132538186		[learning rate: 0.00016967]
	Learning Rate: 0.000169668
	LOSS [training: 0.036421906132538186 | validation: 0.022009824782309045]
	TIME [epoch: 10.3 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03234172116366473		[learning rate: 0.00016915]
	Learning Rate: 0.000169148
	LOSS [training: 0.03234172116366473 | validation: 0.024543153158175048]
	TIME [epoch: 10.3 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031907695435508844		[learning rate: 0.00016863]
	Learning Rate: 0.000168629
	LOSS [training: 0.031907695435508844 | validation: 0.027426642174978078]
	TIME [epoch: 10.2 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03338160894258227		[learning rate: 0.00016811]
	Learning Rate: 0.000168112
	LOSS [training: 0.03338160894258227 | validation: 0.02950771483549614]
	TIME [epoch: 10.3 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0314556798288539		[learning rate: 0.0001676]
	Learning Rate: 0.000167597
	LOSS [training: 0.0314556798288539 | validation: 0.019706938213916926]
	TIME [epoch: 10.3 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03381261084156068		[learning rate: 0.00016708]
	Learning Rate: 0.000167083
	LOSS [training: 0.03381261084156068 | validation: 0.027211611563801547]
	TIME [epoch: 10.3 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03296902856643434		[learning rate: 0.00016657]
	Learning Rate: 0.000166571
	LOSS [training: 0.03296902856643434 | validation: 0.01819705750543633]
	TIME [epoch: 10.3 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036044310238077186		[learning rate: 0.00016606]
	Learning Rate: 0.000166061
	LOSS [training: 0.036044310238077186 | validation: 0.016945587783721777]
	TIME [epoch: 10.3 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033965710203707596		[learning rate: 0.00016555]
	Learning Rate: 0.000165552
	LOSS [training: 0.033965710203707596 | validation: 0.0353552528610724]
	TIME [epoch: 10.3 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036708376778542606		[learning rate: 0.00016504]
	Learning Rate: 0.000165044
	LOSS [training: 0.036708376778542606 | validation: 0.026953070776082187]
	TIME [epoch: 10.3 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036084998712314166		[learning rate: 0.00016454]
	Learning Rate: 0.000164538
	LOSS [training: 0.036084998712314166 | validation: 0.03556626343164736]
	TIME [epoch: 10.3 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03464015153923729		[learning rate: 0.00016403]
	Learning Rate: 0.000164034
	LOSS [training: 0.03464015153923729 | validation: 0.019261194596546617]
	TIME [epoch: 10.3 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03248441148716548		[learning rate: 0.00016353]
	Learning Rate: 0.000163531
	LOSS [training: 0.03248441148716548 | validation: 0.017277595912389487]
	TIME [epoch: 10.3 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027184571603207097		[learning rate: 0.00016303]
	Learning Rate: 0.00016303
	LOSS [training: 0.027184571603207097 | validation: 0.01970894175142174]
	TIME [epoch: 10.2 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03428307479923862		[learning rate: 0.00016253]
	Learning Rate: 0.00016253
	LOSS [training: 0.03428307479923862 | validation: 0.03130126465688046]
	TIME [epoch: 10.3 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03487071678368675		[learning rate: 0.00016203]
	Learning Rate: 0.000162032
	LOSS [training: 0.03487071678368675 | validation: 0.037975593676262215]
	TIME [epoch: 10.3 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0354395152753144		[learning rate: 0.00016153]
	Learning Rate: 0.000161535
	LOSS [training: 0.0354395152753144 | validation: 0.025382716026267214]
	TIME [epoch: 10.3 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04128822900589146		[learning rate: 0.00016104]
	Learning Rate: 0.00016104
	LOSS [training: 0.04128822900589146 | validation: 0.03442769200127029]
	TIME [epoch: 10.3 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03034726115413669		[learning rate: 0.00016055]
	Learning Rate: 0.000160546
	LOSS [training: 0.03034726115413669 | validation: 0.023588198888920928]
	TIME [epoch: 10.4 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03361238011641314		[learning rate: 0.00016005]
	Learning Rate: 0.000160054
	LOSS [training: 0.03361238011641314 | validation: 0.023522929055023133]
	TIME [epoch: 10.3 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0293115727777023		[learning rate: 0.00015956]
	Learning Rate: 0.000159563
	LOSS [training: 0.0293115727777023 | validation: 0.0255096600116307]
	TIME [epoch: 10.3 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032823787586475424		[learning rate: 0.00015907]
	Learning Rate: 0.000159074
	LOSS [training: 0.032823787586475424 | validation: 0.019962783847967784]
	TIME [epoch: 10.3 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028996877406819666		[learning rate: 0.00015859]
	Learning Rate: 0.000158587
	LOSS [training: 0.028996877406819666 | validation: 0.025065649748868993]
	TIME [epoch: 10.3 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03012323790972176		[learning rate: 0.0001581]
	Learning Rate: 0.000158101
	LOSS [training: 0.03012323790972176 | validation: 0.02354302639896575]
	TIME [epoch: 10.3 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02917641173464731		[learning rate: 0.00015762]
	Learning Rate: 0.000157616
	LOSS [training: 0.02917641173464731 | validation: 0.020121031751964447]
	TIME [epoch: 10.3 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0295336236161916		[learning rate: 0.00015713]
	Learning Rate: 0.000157133
	LOSS [training: 0.0295336236161916 | validation: 0.02759897122827765]
	TIME [epoch: 10.3 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034484646351087486		[learning rate: 0.00015665]
	Learning Rate: 0.000156651
	LOSS [training: 0.034484646351087486 | validation: 0.017427218263829307]
	TIME [epoch: 10.3 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03220821927454064		[learning rate: 0.00015617]
	Learning Rate: 0.000156171
	LOSS [training: 0.03220821927454064 | validation: 0.029856338292495472]
	TIME [epoch: 10.3 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026541777698614467		[learning rate: 0.00015569]
	Learning Rate: 0.000155692
	LOSS [training: 0.026541777698614467 | validation: 0.030593388182665434]
	TIME [epoch: 10.3 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03203457791626477		[learning rate: 0.00015521]
	Learning Rate: 0.000155215
	LOSS [training: 0.03203457791626477 | validation: 0.026814428965721056]
	TIME [epoch: 10.3 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03531736234771505		[learning rate: 0.00015474]
	Learning Rate: 0.000154739
	LOSS [training: 0.03531736234771505 | validation: 0.039192993898844314]
	TIME [epoch: 10.3 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.040462394709788116		[learning rate: 0.00015426]
	Learning Rate: 0.000154265
	LOSS [training: 0.040462394709788116 | validation: 0.03070993632404451]
	TIME [epoch: 10.3 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031134000669601276		[learning rate: 0.00015379]
	Learning Rate: 0.000153792
	LOSS [training: 0.031134000669601276 | validation: 0.02980125909831322]
	TIME [epoch: 10.3 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02969372793137357		[learning rate: 0.00015332]
	Learning Rate: 0.00015332
	LOSS [training: 0.02969372793137357 | validation: 0.01772724116504386]
	TIME [epoch: 10.3 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03350682434831204		[learning rate: 0.00015285]
	Learning Rate: 0.00015285
	LOSS [training: 0.03350682434831204 | validation: 0.024864700844492882]
	TIME [epoch: 10.3 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03027366660783694		[learning rate: 0.00015238]
	Learning Rate: 0.000152382
	LOSS [training: 0.03027366660783694 | validation: 0.027933583183122106]
	TIME [epoch: 10.3 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031854546696449285		[learning rate: 0.00015191]
	Learning Rate: 0.000151915
	LOSS [training: 0.031854546696449285 | validation: 0.020957453801247167]
	TIME [epoch: 10.3 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03485507131316399		[learning rate: 0.00015145]
	Learning Rate: 0.000151449
	LOSS [training: 0.03485507131316399 | validation: 0.037252174488885834]
	TIME [epoch: 10.3 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03302930326539222		[learning rate: 0.00015098]
	Learning Rate: 0.000150985
	LOSS [training: 0.03302930326539222 | validation: 0.038005855732402616]
	TIME [epoch: 10.3 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03565207972357981		[learning rate: 0.00015052]
	Learning Rate: 0.000150522
	LOSS [training: 0.03565207972357981 | validation: 0.025068310338607708]
	TIME [epoch: 10.3 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033383808744642154		[learning rate: 0.00015006]
	Learning Rate: 0.000150061
	LOSS [training: 0.033383808744642154 | validation: 0.033708834613703165]
	TIME [epoch: 10.3 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03657837748796437		[learning rate: 0.0001496]
	Learning Rate: 0.000149601
	LOSS [training: 0.03657837748796437 | validation: 0.019032105560900826]
	TIME [epoch: 10.3 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035326211077119675		[learning rate: 0.00014914]
	Learning Rate: 0.000149142
	LOSS [training: 0.035326211077119675 | validation: 0.03382916896657109]
	TIME [epoch: 10.3 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038771957792532674		[learning rate: 0.00014868]
	Learning Rate: 0.000148685
	LOSS [training: 0.038771957792532674 | validation: 0.030371984219239853]
	TIME [epoch: 10.3 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02694503602266939		[learning rate: 0.00014823]
	Learning Rate: 0.000148229
	LOSS [training: 0.02694503602266939 | validation: 0.018645521440729226]
	TIME [epoch: 10.3 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0343249212465154		[learning rate: 0.00014777]
	Learning Rate: 0.000147775
	LOSS [training: 0.0343249212465154 | validation: 0.02562736966672222]
	TIME [epoch: 10.3 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03012432419954661		[learning rate: 0.00014732]
	Learning Rate: 0.000147322
	LOSS [training: 0.03012432419954661 | validation: 0.03160765703488663]
	TIME [epoch: 10.3 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0324295134570885		[learning rate: 0.00014687]
	Learning Rate: 0.00014687
	LOSS [training: 0.0324295134570885 | validation: 0.014006827136308875]
	TIME [epoch: 10.2 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03338130373006282		[learning rate: 0.00014642]
	Learning Rate: 0.00014642
	LOSS [training: 0.03338130373006282 | validation: 0.02144890607036997]
	TIME [epoch: 10.3 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.032934485236461086		[learning rate: 0.00014597]
	Learning Rate: 0.000145971
	LOSS [training: 0.032934485236461086 | validation: 0.02511585059615985]
	TIME [epoch: 10.2 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0340603127227881		[learning rate: 0.00014552]
	Learning Rate: 0.000145524
	LOSS [training: 0.0340603127227881 | validation: 0.03437840923017237]
	TIME [epoch: 10.3 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03334043539362155		[learning rate: 0.00014508]
	Learning Rate: 0.000145077
	LOSS [training: 0.03334043539362155 | validation: 0.02462353645422616]
	TIME [epoch: 10.3 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029977322489245173		[learning rate: 0.00014463]
	Learning Rate: 0.000144633
	LOSS [training: 0.029977322489245173 | validation: 0.018439357758458088]
	TIME [epoch: 10.3 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03317869676643906		[learning rate: 0.00014419]
	Learning Rate: 0.000144189
	LOSS [training: 0.03317869676643906 | validation: 0.018169750535279045]
	TIME [epoch: 10.3 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030342039507230655		[learning rate: 0.00014375]
	Learning Rate: 0.000143747
	LOSS [training: 0.030342039507230655 | validation: 0.037029502182559765]
	TIME [epoch: 10.3 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03229416759073692		[learning rate: 0.00014331]
	Learning Rate: 0.000143307
	LOSS [training: 0.03229416759073692 | validation: 0.01383559957645896]
	TIME [epoch: 10.3 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03326056226710393		[learning rate: 0.00014287]
	Learning Rate: 0.000142867
	LOSS [training: 0.03326056226710393 | validation: 0.03224037740425388]
	TIME [epoch: 10.3 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03048130318907752		[learning rate: 0.00014243]
	Learning Rate: 0.00014243
	LOSS [training: 0.03048130318907752 | validation: 0.017437969805550176]
	TIME [epoch: 10.3 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030402767669745933		[learning rate: 0.00014199]
	Learning Rate: 0.000141993
	LOSS [training: 0.030402767669745933 | validation: 0.023745571203273405]
	TIME [epoch: 10.3 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030223184265636104		[learning rate: 0.00014156]
	Learning Rate: 0.000141558
	LOSS [training: 0.030223184265636104 | validation: 0.03127414680949474]
	TIME [epoch: 10.3 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029880628882564302		[learning rate: 0.00014112]
	Learning Rate: 0.000141124
	LOSS [training: 0.029880628882564302 | validation: 0.0246915955824808]
	TIME [epoch: 10.3 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03188766096162661		[learning rate: 0.00014069]
	Learning Rate: 0.000140691
	LOSS [training: 0.03188766096162661 | validation: 0.025636353788968006]
	TIME [epoch: 10.3 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028174199481853828		[learning rate: 0.00014026]
	Learning Rate: 0.00014026
	LOSS [training: 0.028174199481853828 | validation: 0.016222913791420795]
	TIME [epoch: 10.3 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025417005410709563		[learning rate: 0.00013983]
	Learning Rate: 0.00013983
	LOSS [training: 0.025417005410709563 | validation: 0.0235721781418456]
	TIME [epoch: 10.3 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03174653593083533		[learning rate: 0.0001394]
	Learning Rate: 0.000139401
	LOSS [training: 0.03174653593083533 | validation: 0.03074659827337657]
	TIME [epoch: 10.3 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031032006849102796		[learning rate: 0.00013897]
	Learning Rate: 0.000138974
	LOSS [training: 0.031032006849102796 | validation: 0.007717209766196078]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r1_20240217_134234/states/model_tr_study6_1893.pth
	Model improved!!!
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029306123696340836		[learning rate: 0.00013855]
	Learning Rate: 0.000138548
	LOSS [training: 0.029306123696340836 | validation: 0.013613554527075102]
	TIME [epoch: 10.3 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0315544858694818		[learning rate: 0.00013812]
	Learning Rate: 0.000138123
	LOSS [training: 0.0315544858694818 | validation: 0.012902538277074304]
	TIME [epoch: 10.3 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029799149024691628		[learning rate: 0.0001377]
	Learning Rate: 0.0001377
	LOSS [training: 0.029799149024691628 | validation: 0.02677675357967401]
	TIME [epoch: 10.3 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029450481344072393		[learning rate: 0.00013728]
	Learning Rate: 0.000137278
	LOSS [training: 0.029450481344072393 | validation: 0.023710913024640044]
	TIME [epoch: 10.3 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.037706334079706604		[learning rate: 0.00013686]
	Learning Rate: 0.000136857
	LOSS [training: 0.037706334079706604 | validation: 0.02459241528731257]
	TIME [epoch: 10.3 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03109311775197272		[learning rate: 0.00013644]
	Learning Rate: 0.000136437
	LOSS [training: 0.03109311775197272 | validation: 0.023323845010395163]
	TIME [epoch: 10.3 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03188742004181144		[learning rate: 0.00013602]
	Learning Rate: 0.000136019
	LOSS [training: 0.03188742004181144 | validation: 0.023501565133588517]
	TIME [epoch: 10.3 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038415522692246816		[learning rate: 0.0001356]
	Learning Rate: 0.000135602
	LOSS [training: 0.038415522692246816 | validation: 0.0315351946429986]
	TIME [epoch: 10.3 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030358692864409807		[learning rate: 0.00013519]
	Learning Rate: 0.000135186
	LOSS [training: 0.030358692864409807 | validation: 0.01808939048923549]
	TIME [epoch: 10.3 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03222454592052494		[learning rate: 0.00013477]
	Learning Rate: 0.000134772
	LOSS [training: 0.03222454592052494 | validation: 0.021141178135468678]
	TIME [epoch: 10.3 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03545533502806117		[learning rate: 0.00013436]
	Learning Rate: 0.000134359
	LOSS [training: 0.03545533502806117 | validation: 0.03617752354117473]
	TIME [epoch: 10.3 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02978969866783318		[learning rate: 0.00013395]
	Learning Rate: 0.000133947
	LOSS [training: 0.02978969866783318 | validation: 0.017924774471945928]
	TIME [epoch: 10.3 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028956478040019405		[learning rate: 0.00013354]
	Learning Rate: 0.000133536
	LOSS [training: 0.028956478040019405 | validation: 0.03539980777163493]
	TIME [epoch: 10.3 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02293272779828324		[learning rate: 0.00013313]
	Learning Rate: 0.000133127
	LOSS [training: 0.02293272779828324 | validation: 0.020643829321553703]
	TIME [epoch: 10.3 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030464140099568014		[learning rate: 0.00013272]
	Learning Rate: 0.000132719
	LOSS [training: 0.030464140099568014 | validation: 0.01901873004737467]
	TIME [epoch: 10.3 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024820287539384204		[learning rate: 0.00013231]
	Learning Rate: 0.000132312
	LOSS [training: 0.024820287539384204 | validation: 0.0250770064225417]
	TIME [epoch: 10.3 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02633378152466697		[learning rate: 0.00013191]
	Learning Rate: 0.000131907
	LOSS [training: 0.02633378152466697 | validation: 0.038824568840637896]
	TIME [epoch: 10.3 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03320626142976919		[learning rate: 0.0001315]
	Learning Rate: 0.000131502
	LOSS [training: 0.03320626142976919 | validation: 0.008359438685876682]
	TIME [epoch: 10.3 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035914810596421876		[learning rate: 0.0001311]
	Learning Rate: 0.000131099
	LOSS [training: 0.035914810596421876 | validation: 0.02699147065910871]
	TIME [epoch: 10.3 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.033401549564831504		[learning rate: 0.0001307]
	Learning Rate: 0.000130697
	LOSS [training: 0.033401549564831504 | validation: 0.021384292104589014]
	TIME [epoch: 10.3 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03151010707893306		[learning rate: 0.0001303]
	Learning Rate: 0.000130297
	LOSS [training: 0.03151010707893306 | validation: 0.02360565283676585]
	TIME [epoch: 10.3 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03224705081563437		[learning rate: 0.0001299]
	Learning Rate: 0.000129897
	LOSS [training: 0.03224705081563437 | validation: 0.014096326110030363]
	TIME [epoch: 10.3 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03139353565728971		[learning rate: 0.0001295]
	Learning Rate: 0.000129499
	LOSS [training: 0.03139353565728971 | validation: 0.02931314117029551]
	TIME [epoch: 10.3 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03014353192761039		[learning rate: 0.0001291]
	Learning Rate: 0.000129102
	LOSS [training: 0.03014353192761039 | validation: 0.014710783062989707]
	TIME [epoch: 10.3 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028204925246008823		[learning rate: 0.00012871]
	Learning Rate: 0.000128706
	LOSS [training: 0.028204925246008823 | validation: 0.021585554703971967]
	TIME [epoch: 10.3 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026390297689525555		[learning rate: 0.00012831]
	Learning Rate: 0.000128312
	LOSS [training: 0.026390297689525555 | validation: 0.03028021668417784]
	TIME [epoch: 10.3 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028916262438505307		[learning rate: 0.00012792]
	Learning Rate: 0.000127918
	LOSS [training: 0.028916262438505307 | validation: 0.02142462311466068]
	TIME [epoch: 10.3 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030518693436325163		[learning rate: 0.00012753]
	Learning Rate: 0.000127526
	LOSS [training: 0.030518693436325163 | validation: 0.022191113594924008]
	TIME [epoch: 10.3 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03267099233607394		[learning rate: 0.00012714]
	Learning Rate: 0.000127135
	LOSS [training: 0.03267099233607394 | validation: 0.014370346429948246]
	TIME [epoch: 10.3 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029564570665767537		[learning rate: 0.00012675]
	Learning Rate: 0.000126746
	LOSS [training: 0.029564570665767537 | validation: 0.025851347994508393]
	TIME [epoch: 10.3 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029920450752923454		[learning rate: 0.00012636]
	Learning Rate: 0.000126357
	LOSS [training: 0.029920450752923454 | validation: 0.031153486205073768]
	TIME [epoch: 10.3 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027564683586044247		[learning rate: 0.00012597]
	Learning Rate: 0.00012597
	LOSS [training: 0.027564683586044247 | validation: 0.027710708094057228]
	TIME [epoch: 10.3 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027013726412035744		[learning rate: 0.00012558]
	Learning Rate: 0.000125584
	LOSS [training: 0.027013726412035744 | validation: 0.019178497023491232]
	TIME [epoch: 10.3 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03096714820207286		[learning rate: 0.0001252]
	Learning Rate: 0.000125199
	LOSS [training: 0.03096714820207286 | validation: 0.016381116782004584]
	TIME [epoch: 10.3 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03430812916200411		[learning rate: 0.00012481]
	Learning Rate: 0.000124815
	LOSS [training: 0.03430812916200411 | validation: 0.01068759820294502]
	TIME [epoch: 10.3 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028273817824662907		[learning rate: 0.00012443]
	Learning Rate: 0.000124432
	LOSS [training: 0.028273817824662907 | validation: 0.02118082501672256]
	TIME [epoch: 10.3 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034856899794776255		[learning rate: 0.00012405]
	Learning Rate: 0.000124051
	LOSS [training: 0.034856899794776255 | validation: 0.02023063143039688]
	TIME [epoch: 10.3 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0226586394127724		[learning rate: 0.00012367]
	Learning Rate: 0.000123671
	LOSS [training: 0.0226586394127724 | validation: 0.020735602751220755]
	TIME [epoch: 10.3 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026794860850466784		[learning rate: 0.00012329]
	Learning Rate: 0.000123292
	LOSS [training: 0.026794860850466784 | validation: 0.03186540175558266]
	TIME [epoch: 10.3 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027678453361526335		[learning rate: 0.00012291]
	Learning Rate: 0.000122914
	LOSS [training: 0.027678453361526335 | validation: 0.02322619273313309]
	TIME [epoch: 10.3 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.031720131376928876		[learning rate: 0.00012254]
	Learning Rate: 0.000122537
	LOSS [training: 0.031720131376928876 | validation: 0.022928923794564335]
	TIME [epoch: 10.3 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03279731394801229		[learning rate: 0.00012216]
	Learning Rate: 0.000122161
	LOSS [training: 0.03279731394801229 | validation: 0.021542931254055278]
	TIME [epoch: 10.3 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027736420492700208		[learning rate: 0.00012179]
	Learning Rate: 0.000121787
	LOSS [training: 0.027736420492700208 | validation: 0.02260346536698272]
	TIME [epoch: 10.3 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03109695076814345		[learning rate: 0.00012141]
	Learning Rate: 0.000121413
	LOSS [training: 0.03109695076814345 | validation: 0.018550010799242077]
	TIME [epoch: 10.3 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0289664668131576		[learning rate: 0.00012104]
	Learning Rate: 0.000121041
	LOSS [training: 0.0289664668131576 | validation: 0.016989336466774217]
	TIME [epoch: 10.3 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03155580237502165		[learning rate: 0.00012067]
	Learning Rate: 0.00012067
	LOSS [training: 0.03155580237502165 | validation: 0.038059901269681944]
	TIME [epoch: 10.3 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030020030069235863		[learning rate: 0.0001203]
	Learning Rate: 0.0001203
	LOSS [training: 0.030020030069235863 | validation: 0.03298460133188834]
	TIME [epoch: 10.3 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03438147078877375		[learning rate: 0.00011993]
	Learning Rate: 0.000119932
	LOSS [training: 0.03438147078877375 | validation: 0.022537275868696867]
	TIME [epoch: 10.3 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029820718494909186		[learning rate: 0.00011956]
	Learning Rate: 0.000119564
	LOSS [training: 0.029820718494909186 | validation: 0.03159871941508105]
	TIME [epoch: 10.3 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03155065136017094		[learning rate: 0.0001192]
	Learning Rate: 0.000119197
	LOSS [training: 0.03155065136017094 | validation: 0.013726057900275796]
	TIME [epoch: 10.3 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02936977262832552		[learning rate: 0.00011883]
	Learning Rate: 0.000118832
	LOSS [training: 0.02936977262832552 | validation: 0.025450946280846445]
	TIME [epoch: 10.3 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0234622273185894		[learning rate: 0.00011847]
	Learning Rate: 0.000118468
	LOSS [training: 0.0234622273185894 | validation: 0.02659457861224975]
	TIME [epoch: 10.3 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03467603365952533		[learning rate: 0.0001181]
	Learning Rate: 0.000118105
	LOSS [training: 0.03467603365952533 | validation: 0.018705564519992755]
	TIME [epoch: 10.3 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.038194388113799334		[learning rate: 0.00011774]
	Learning Rate: 0.000117743
	LOSS [training: 0.038194388113799334 | validation: 0.026964237451803253]
	TIME [epoch: 10.3 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03227870940402448		[learning rate: 0.00011738]
	Learning Rate: 0.000117382
	LOSS [training: 0.03227870940402448 | validation: 0.021076538253546665]
	TIME [epoch: 10.3 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03100221210560431		[learning rate: 0.00011702]
	Learning Rate: 0.000117022
	LOSS [training: 0.03100221210560431 | validation: 0.017100353462875348]
	TIME [epoch: 10.3 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03143108208420807		[learning rate: 0.00011666]
	Learning Rate: 0.000116663
	LOSS [training: 0.03143108208420807 | validation: 0.02996215314068802]
	TIME [epoch: 10.3 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03885900164680996		[learning rate: 0.00011631]
	Learning Rate: 0.000116305
	LOSS [training: 0.03885900164680996 | validation: 0.019851387438514955]
	TIME [epoch: 10.3 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028921444696072374		[learning rate: 0.00011595]
	Learning Rate: 0.000115949
	LOSS [training: 0.028921444696072374 | validation: 0.025876099433499493]
	TIME [epoch: 10.3 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0339908226450676		[learning rate: 0.00011559]
	Learning Rate: 0.000115593
	LOSS [training: 0.0339908226450676 | validation: 0.022769037367685298]
	TIME [epoch: 10.3 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025021337965144476		[learning rate: 0.00011524]
	Learning Rate: 0.000115239
	LOSS [training: 0.025021337965144476 | validation: 0.027895481996359616]
	TIME [epoch: 10.3 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03004239324533654		[learning rate: 0.00011489]
	Learning Rate: 0.000114886
	LOSS [training: 0.03004239324533654 | validation: 0.02135896879179243]
	TIME [epoch: 10.3 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02895420785828721		[learning rate: 0.00011453]
	Learning Rate: 0.000114534
	LOSS [training: 0.02895420785828721 | validation: 0.028622807658338675]
	TIME [epoch: 10.3 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028365730636646935		[learning rate: 0.00011418]
	Learning Rate: 0.000114183
	LOSS [training: 0.028365730636646935 | validation: 0.024817784950349184]
	TIME [epoch: 10.3 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027060299179451963		[learning rate: 0.00011383]
	Learning Rate: 0.000113833
	LOSS [training: 0.027060299179451963 | validation: 0.02760594337174817]
	TIME [epoch: 10.3 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.034195505597937194		[learning rate: 0.00011348]
	Learning Rate: 0.000113484
	LOSS [training: 0.034195505597937194 | validation: 0.013507029528717896]
	TIME [epoch: 10.3 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0328181217684724		[learning rate: 0.00011314]
	Learning Rate: 0.000113136
	LOSS [training: 0.0328181217684724 | validation: 0.02384009276144797]
	TIME [epoch: 10.3 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030040690587595353		[learning rate: 0.00011279]
	Learning Rate: 0.000112789
	LOSS [training: 0.030040690587595353 | validation: 0.02776348567339493]
	TIME [epoch: 10.3 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.029083522337338564		[learning rate: 0.00011244]
	Learning Rate: 0.000112443
	LOSS [training: 0.029083522337338564 | validation: 0.01809898144164208]
	TIME [epoch: 10.3 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03331490804769147		[learning rate: 0.0001121]
	Learning Rate: 0.000112099
	LOSS [training: 0.03331490804769147 | validation: 0.029601780584258927]
	TIME [epoch: 10.3 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024379809038764227		[learning rate: 0.00011175]
	Learning Rate: 0.000111755
	LOSS [training: 0.024379809038764227 | validation: 0.02899857664535036]
	TIME [epoch: 10.3 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028740613418185585		[learning rate: 0.00011141]
	Learning Rate: 0.000111412
	LOSS [training: 0.028740613418185585 | validation: 0.0239878490039275]
	TIME [epoch: 10.3 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027311227366563516		[learning rate: 0.00011107]
	Learning Rate: 0.000111071
	LOSS [training: 0.027311227366563516 | validation: 0.01056541517951636]
	TIME [epoch: 10.3 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027295839057989935		[learning rate: 0.00011073]
	Learning Rate: 0.00011073
	LOSS [training: 0.027295839057989935 | validation: 0.034080233864148206]
	TIME [epoch: 10.3 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.025452898431271843		[learning rate: 0.00011039]
	Learning Rate: 0.000110391
	LOSS [training: 0.025452898431271843 | validation: 0.03254865444365656]
	TIME [epoch: 10.3 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02778072674932658		[learning rate: 0.00011005]
	Learning Rate: 0.000110053
	LOSS [training: 0.02778072674932658 | validation: 0.024238010550310857]
	TIME [epoch: 10.3 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03132307744913178		[learning rate: 0.00010972]
	Learning Rate: 0.000109715
	LOSS [training: 0.03132307744913178 | validation: 0.021273300189810006]
	TIME [epoch: 10.3 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024752867303053337		[learning rate: 0.00010938]
	Learning Rate: 0.000109379
	LOSS [training: 0.024752867303053337 | validation: 0.024311583111596743]
	TIME [epoch: 10.3 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03130750590199937		[learning rate: 0.00010904]
	Learning Rate: 0.000109044
	LOSS [training: 0.03130750590199937 | validation: 0.030517405014393463]
	TIME [epoch: 10.3 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02603677964339495		[learning rate: 0.00010871]
	Learning Rate: 0.000108709
	LOSS [training: 0.02603677964339495 | validation: 0.030646253452934567]
	TIME [epoch: 10.3 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03081236550590232		[learning rate: 0.00010838]
	Learning Rate: 0.000108376
	LOSS [training: 0.03081236550590232 | validation: 0.019534514429526466]
	TIME [epoch: 10.3 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027690811541201323		[learning rate: 0.00010804]
	Learning Rate: 0.000108044
	LOSS [training: 0.027690811541201323 | validation: 0.026221553087589233]
	TIME [epoch: 10.3 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026451091064328247		[learning rate: 0.00010771]
	Learning Rate: 0.000107713
	LOSS [training: 0.026451091064328247 | validation: 0.02677814786637693]
	TIME [epoch: 10.3 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03072634268254859		[learning rate: 0.00010738]
	Learning Rate: 0.000107382
	LOSS [training: 0.03072634268254859 | validation: 0.027709322257022648]
	TIME [epoch: 10.3 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026903225785061102		[learning rate: 0.00010705]
	Learning Rate: 0.000107053
	LOSS [training: 0.026903225785061102 | validation: 0.02051774592818402]
	TIME [epoch: 10.3 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.036578728483910514		[learning rate: 0.00010673]
	Learning Rate: 0.000106725
	LOSS [training: 0.036578728483910514 | validation: 0.02825392115598836]
	TIME [epoch: 10.3 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023501255936285333		[learning rate: 0.0001064]
	Learning Rate: 0.000106398
	LOSS [training: 0.023501255936285333 | validation: 0.015260205668697907]
	TIME [epoch: 10.3 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03051808279238729		[learning rate: 0.00010607]
	Learning Rate: 0.000106072
	LOSS [training: 0.03051808279238729 | validation: 0.024991427273170528]
	TIME [epoch: 10.3 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02505774524440693		[learning rate: 0.00010575]
	Learning Rate: 0.000105747
	LOSS [training: 0.02505774524440693 | validation: 0.01980650950664854]
	TIME [epoch: 10.3 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.024143284508168876		[learning rate: 0.00010542]
	Learning Rate: 0.000105423
	LOSS [training: 0.024143284508168876 | validation: 0.015131268746852932]
	TIME [epoch: 10.3 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027223324023731447		[learning rate: 0.0001051]
	Learning Rate: 0.000105099
	LOSS [training: 0.027223324023731447 | validation: 0.031712124021351866]
	TIME [epoch: 10.3 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.028727207665272685		[learning rate: 0.00010478]
	Learning Rate: 0.000104777
	LOSS [training: 0.028727207665272685 | validation: 0.011249325847711584]
	TIME [epoch: 10.3 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027432791789249823		[learning rate: 0.00010446]
	Learning Rate: 0.000104456
	LOSS [training: 0.027432791789249823 | validation: 0.021987037251381143]
	TIME [epoch: 10.3 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.03305690062780835		[learning rate: 0.00010414]
	Learning Rate: 0.000104136
	LOSS [training: 0.03305690062780835 | validation: 0.02679416353068574]
	TIME [epoch: 10.3 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030717853386613758		[learning rate: 0.00010382]
	Learning Rate: 0.000103817
	LOSS [training: 0.030717853386613758 | validation: 0.021610205464388202]
	TIME [epoch: 10.3 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02942861328676379		[learning rate: 0.0001035]
	Learning Rate: 0.000103498
	LOSS [training: 0.02942861328676379 | validation: 0.020259509073710148]
	TIME [epoch: 10.3 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02614367912940892		[learning rate: 0.00010318]
	Learning Rate: 0.000103181
	LOSS [training: 0.02614367912940892 | validation: 0.014744635831811063]
	TIME [epoch: 10.3 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030995415348640597		[learning rate: 0.00010286]
	Learning Rate: 0.000102865
	LOSS [training: 0.030995415348640597 | validation: 0.03532032705305228]
	TIME [epoch: 10.3 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.035667175760677336		[learning rate: 0.00010255]
	Learning Rate: 0.000102549
	LOSS [training: 0.035667175760677336 | validation: 0.037069833660994235]
	TIME [epoch: 10.3 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02583262703646213		[learning rate: 0.00010224]
	Learning Rate: 0.000102235
	LOSS [training: 0.02583262703646213 | validation: 0.03077770346912109]
	TIME [epoch: 10.3 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0380717772771784		[learning rate: 0.00010192]
	Learning Rate: 0.000101922
	LOSS [training: 0.0380717772771784 | validation: 0.021086603545978643]
	TIME [epoch: 10.3 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.023523913185313404		[learning rate: 0.00010161]
	Learning Rate: 0.000101609
	LOSS [training: 0.023523913185313404 | validation: 0.042816776185876086]
	TIME [epoch: 10.3 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02845730160524259		[learning rate: 0.0001013]
	Learning Rate: 0.000101298
	LOSS [training: 0.02845730160524259 | validation: 0.020953257837909592]
	TIME [epoch: 10.3 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.030651842279880125		[learning rate: 0.00010099]
	Learning Rate: 0.000100987
	LOSS [training: 0.030651842279880125 | validation: 0.03271695419443973]
	TIME [epoch: 10.3 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.02750391199565282		[learning rate: 0.00010068]
	Learning Rate: 0.000100678
	LOSS [training: 0.02750391199565282 | validation: 0.02147553466059747]
	TIME [epoch: 10.3 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.026288597709731222		[learning rate: 0.00010037]
	Learning Rate: 0.000100369
	LOSS [training: 0.026288597709731222 | validation: 0.025148877423778346]
	TIME [epoch: 10.3 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.027843936316862918		[learning rate: 0.00010006]
	Learning Rate: 0.000100061
	LOSS [training: 0.027843936316862918 | validation: 0.016507483113400806]
	TIME [epoch: 10.3 sec]
Finished training in 20579.175 seconds.
