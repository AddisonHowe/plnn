Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r2', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2028758748

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.505355287589609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.505355287589609 | validation: 9.617814970152407]
	TIME [epoch: 80.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.764469329113984		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.764469329113984 | validation: 8.361597052431183]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.042206480575816		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.042206480575816 | validation: 7.927622890858918]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.591698708495594		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.591698708495594 | validation: 7.572083802414791]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.31273059226497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.31273059226497 | validation: 7.208643330425693]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.186211431219618		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.186211431219618 | validation: 7.380755123175125]
	TIME [epoch: 9.75 sec]
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.147164205415818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.147164205415818 | validation: 6.947624473620515]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.960193878224589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.960193878224589 | validation: 7.716486153461242]
	TIME [epoch: 9.77 sec]
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.098950069078232		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.098950069078232 | validation: 7.22636792198362]
	TIME [epoch: 9.74 sec]
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.8231911963410115		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8231911963410115 | validation: 6.995810347564091]
	TIME [epoch: 9.74 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.869056117940428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.869056117940428 | validation: 8.227725970429335]
	TIME [epoch: 9.76 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.29979021506872		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.29979021506872 | validation: 6.827697321637068]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.73080436568402		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.73080436568402 | validation: 6.884126842213917]
	TIME [epoch: 9.75 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.415580951992965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.415580951992965 | validation: 7.136069341180523]
	TIME [epoch: 9.76 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.903910946045535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.903910946045535 | validation: 7.190993464216739]
	TIME [epoch: 9.78 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.832073778576186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.832073778576186 | validation: 7.0138027608442215]
	TIME [epoch: 9.76 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6471408771782166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6471408771782166 | validation: 6.822551705026457]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.483399916384881		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.483399916384881 | validation: 6.647687242229256]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.766566016293062		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.766566016293062 | validation: 7.300742291451809]
	TIME [epoch: 9.78 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.690082915272457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.690082915272457 | validation: 6.816357423215597]
	TIME [epoch: 9.75 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.849534618338294		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.849534618338294 | validation: 6.705477882755104]
	TIME [epoch: 9.75 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.439793416359092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.439793416359092 | validation: 7.735919262865985]
	TIME [epoch: 9.76 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.942396718245179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.942396718245179 | validation: 7.048873923117096]
	TIME [epoch: 9.77 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.568322388686885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.568322388686885 | validation: 6.62317719173823]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.554475382127433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.554475382127433 | validation: 6.937847937293291]
	TIME [epoch: 9.75 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.817659347122765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.817659347122765 | validation: 7.3296603101007305]
	TIME [epoch: 9.76 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.018085061249636		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.018085061249636 | validation: 7.013952910450205]
	TIME [epoch: 9.75 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.260765157770312		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.260765157770312 | validation: 9.588547853809562]
	TIME [epoch: 9.75 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.63539849961999		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.63539849961999 | validation: 7.040929616917919]
	TIME [epoch: 9.75 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.592710920083053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.592710920083053 | validation: 6.770810619192019]
	TIME [epoch: 9.76 sec]
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.967297798755226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.967297798755226 | validation: 6.826717807501566]
	TIME [epoch: 9.75 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.902092448989755		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.902092448989755 | validation: 8.744385008842139]
	TIME [epoch: 9.75 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.7234826886822985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.7234826886822985 | validation: 6.995314090722843]
	TIME [epoch: 9.76 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.518390541160795		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.518390541160795 | validation: 7.009938346546203]
	TIME [epoch: 9.77 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.595732034002593		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.595732034002593 | validation: 6.715760963902309]
	TIME [epoch: 9.75 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.913765346402281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.913765346402281 | validation: 8.550235494913322]
	TIME [epoch: 9.75 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.057654628127278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.057654628127278 | validation: 7.279915456012738]
	TIME [epoch: 9.77 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.810915678697535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.810915678697535 | validation: 7.0093434451318855]
	TIME [epoch: 9.75 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.727165869392169		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.727165869392169 | validation: 6.956172232864296]
	TIME [epoch: 9.74 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.593906767659179		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.593906767659179 | validation: 6.892528549010174]
	TIME [epoch: 9.75 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.188196337779351		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.188196337779351 | validation: 6.906711592472191]
	TIME [epoch: 9.77 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.919933660733236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.919933660733236 | validation: 6.815448122730343]
	TIME [epoch: 9.75 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.883310432341233		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.883310432341233 | validation: 7.143845698016392]
	TIME [epoch: 9.75 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.952451423213285		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.952451423213285 | validation: 6.814777070516823]
	TIME [epoch: 9.75 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6624083796068785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.6624083796068785 | validation: 6.920546679592258]
	TIME [epoch: 9.77 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.474732131792689		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.474732131792689 | validation: 6.939050265352129]
	TIME [epoch: 9.75 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.793766964190304		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.793766964190304 | validation: 6.803281472641558]
	TIME [epoch: 9.74 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.4738462875018765		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4738462875018765 | validation: 7.899848941151792]
	TIME [epoch: 9.77 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.054931823885804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.054931823885804 | validation: 7.308017836235252]
	TIME [epoch: 9.75 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.24489037301205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.24489037301205 | validation: 8.653204201707391]
	TIME [epoch: 9.75 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.61568669690259		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 7.61568669690259 | validation: 7.024194727677678]
	TIME [epoch: 9.74 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.465195793019272		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 7.465195793019272 | validation: 7.112706686128809]
	TIME [epoch: 9.76 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.952226427169757		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 6.952226427169757 | validation: 6.950566993420234]
	TIME [epoch: 9.75 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.744721875861906		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 6.744721875861906 | validation: 6.880242915790589]
	TIME [epoch: 9.75 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.787963479896338		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 6.787963479896338 | validation: 6.976244179598093]
	TIME [epoch: 9.74 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.992952850131249		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 6.992952850131249 | validation: 6.712122506368342]
	TIME [epoch: 9.78 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.02210061765425		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 7.02210061765425 | validation: 8.38046109024167]
	TIME [epoch: 9.75 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.440468176871245		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 7.440468176871245 | validation: 7.128275545058118]
	TIME [epoch: 9.75 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6186063454263735		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 6.6186063454263735 | validation: 6.722860407241974]
	TIME [epoch: 9.76 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.707380979627983		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 6.707380979627983 | validation: 6.968253695429394]
	TIME [epoch: 9.76 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.703042507459474		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 6.703042507459474 | validation: 6.956985356708203]
	TIME [epoch: 9.75 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.510112307287469		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 6.510112307287469 | validation: 6.905188440160191]
	TIME [epoch: 9.75 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.548143374141946		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 6.548143374141946 | validation: 6.827901786980601]
	TIME [epoch: 9.77 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.484437925181799		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 6.484437925181799 | validation: 7.204695279079372]
	TIME [epoch: 9.75 sec]
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.620025715263681		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 6.620025715263681 | validation: 6.692025989382826]
	TIME [epoch: 9.75 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.56300331167174		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 6.56300331167174 | validation: 6.621552753250428]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_66.pth
	Model improved!!!
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.318570473813052		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 6.318570473813052 | validation: 6.434461864069127]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_67.pth
	Model improved!!!
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.814536559049782		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 5.814536559049782 | validation: 6.417955928426072]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240217_140924/states/model_tr_study6_68.pth
	Model improved!!!
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: nan		[learning rate: 0.009129]
ERROR:
nan encountered in epoch 68 (training loss).
