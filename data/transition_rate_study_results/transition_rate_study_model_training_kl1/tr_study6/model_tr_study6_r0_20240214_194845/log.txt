Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r0', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2994185378

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 5/5] avg loss: 9.129504444746278		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.129504444746278 | validation: 8.283531332756667]
	TIME [epoch: 49.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 5/5] avg loss: 7.93593249196785		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.93593249196785 | validation: 7.781381525845878]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 5/5] avg loss: 7.265517138973671		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.265517138973671 | validation: 7.6925992242808094]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 5/5] avg loss: 6.954183364301002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.954183364301002 | validation: 7.321914004563906]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 5/5] avg loss: 6.825255493915262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.825255493915262 | validation: 7.4012292536681255]
	TIME [epoch: 10.5 sec]
EPOCH 6/500:
	Training over batches...
		[batch 5/5] avg loss: 6.532511901393309		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.532511901393309 | validation: 8.508921568403608]
	TIME [epoch: 10.5 sec]
EPOCH 7/500:
	Training over batches...
		[batch 5/5] avg loss: 7.885842764301415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.885842764301415 | validation: 6.375515693427028]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 5/5] avg loss: 7.332858143395272		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.332858143395272 | validation: 9.80798939246922]
	TIME [epoch: 10.5 sec]
EPOCH 9/500:
	Training over batches...
		[batch 5/5] avg loss: 8.22553434705333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.22553434705333 | validation: 6.395137048062729]
	TIME [epoch: 10.5 sec]
EPOCH 10/500:
	Training over batches...
		[batch 5/5] avg loss: 6.049629614911316		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.049629614911316 | validation: 6.283903194646881]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/500:
	Training over batches...
		[batch 5/5] avg loss: 5.692273958178592		[learning rate: 0.0099625]
	Learning Rate: 0.00996248
	LOSS [training: 5.692273958178592 | validation: 5.655167758666842]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 5/5] avg loss: 5.4188588317277455		[learning rate: 0.0099158]
	Learning Rate: 0.00991577
	LOSS [training: 5.4188588317277455 | validation: 5.353326717141714]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 5/5] avg loss: 5.275221379495838		[learning rate: 0.0098693]
	Learning Rate: 0.00986928
	LOSS [training: 5.275221379495838 | validation: 5.236784110654504]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 5/5] avg loss: 4.790257667934972		[learning rate: 0.009823]
	Learning Rate: 0.00982302
	LOSS [training: 4.790257667934972 | validation: 4.5101632254770125]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 5/5] avg loss: 4.382425268884412		[learning rate: 0.009777]
	Learning Rate: 0.00977696
	LOSS [training: 4.382425268884412 | validation: 5.235458847467249]
	TIME [epoch: 10.5 sec]
EPOCH 16/500:
	Training over batches...
		[batch 5/5] avg loss: 6.430784157949224		[learning rate: 0.0097311]
	Learning Rate: 0.00973113
	LOSS [training: 6.430784157949224 | validation: 4.346446042157825]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 5/5] avg loss: 4.236328060905879		[learning rate: 0.0096855]
	Learning Rate: 0.00968551
	LOSS [training: 4.236328060905879 | validation: 3.9935419930148988]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 5/5] avg loss: 4.054576051244387		[learning rate: 0.0096401]
	Learning Rate: 0.0096401
	LOSS [training: 4.054576051244387 | validation: 3.769615248583577]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9472059496067877		[learning rate: 0.0095949]
	Learning Rate: 0.00959491
	LOSS [training: 3.9472059496067877 | validation: 3.5394869414031476]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 5/5] avg loss: 4.403712638537573		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 4.403712638537573 | validation: 3.594756850769341]
	TIME [epoch: 10.5 sec]
EPOCH 21/500:
	Training over batches...
		[batch 5/5] avg loss: 3.75094944542014		[learning rate: 0.0095052]
	Learning Rate: 0.00950515
	LOSS [training: 3.75094944542014 | validation: 4.13927235976871]
	TIME [epoch: 10.5 sec]
EPOCH 22/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9892008105625285		[learning rate: 0.0094606]
	Learning Rate: 0.00946059
	LOSS [training: 3.9892008105625285 | validation: 3.7255471229018036]
	TIME [epoch: 10.5 sec]
EPOCH 23/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6818790257148826		[learning rate: 0.0094162]
	Learning Rate: 0.00941624
	LOSS [training: 3.6818790257148826 | validation: 3.4784730871771172]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/500:
	Training over batches...
		[batch 5/5] avg loss: 3.609195767197231		[learning rate: 0.0093721]
	Learning Rate: 0.0093721
	LOSS [training: 3.609195767197231 | validation: 3.4057092286556405]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6010371712958316		[learning rate: 0.0093282]
	Learning Rate: 0.00932816
	LOSS [training: 3.6010371712958316 | validation: 3.3648126459401704]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7764375691953		[learning rate: 0.0092844]
	Learning Rate: 0.00928443
	LOSS [training: 3.7764375691953 | validation: 3.541593775624912]
	TIME [epoch: 10.5 sec]
EPOCH 27/500:
	Training over batches...
		[batch 5/5] avg loss: 3.70285278488047		[learning rate: 0.0092409]
	Learning Rate: 0.0092409
	LOSS [training: 3.70285278488047 | validation: 3.654564839904899]
	TIME [epoch: 10.5 sec]
EPOCH 28/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6067323072861477		[learning rate: 0.0091976]
	Learning Rate: 0.00919758
	LOSS [training: 3.6067323072861477 | validation: 3.3156722436134918]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4695223789281484		[learning rate: 0.0091545]
	Learning Rate: 0.00915446
	LOSS [training: 3.4695223789281484 | validation: 3.2459705848477247]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_29.pth
	Model improved!!!
EPOCH 30/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3874235791221237		[learning rate: 0.0091115]
	Learning Rate: 0.00911154
	LOSS [training: 3.3874235791221237 | validation: 3.255680076494414]
	TIME [epoch: 10.5 sec]
EPOCH 31/500:
	Training over batches...
		[batch 5/5] avg loss: 3.489838446736994		[learning rate: 0.0090688]
	Learning Rate: 0.00906882
	LOSS [training: 3.489838446736994 | validation: 3.591052839034717]
	TIME [epoch: 10.5 sec]
EPOCH 32/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8019523191395037		[learning rate: 0.0090263]
	Learning Rate: 0.00902631
	LOSS [training: 3.8019523191395037 | validation: 3.999230098887391]
	TIME [epoch: 10.5 sec]
EPOCH 33/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7358682546727495		[learning rate: 0.008984]
	Learning Rate: 0.00898399
	LOSS [training: 3.7358682546727495 | validation: 3.385545546430773]
	TIME [epoch: 10.5 sec]
EPOCH 34/500:
	Training over batches...
		[batch 5/5] avg loss: 3.479008412545538		[learning rate: 0.0089419]
	Learning Rate: 0.00894187
	LOSS [training: 3.479008412545538 | validation: 3.289408529571297]
	TIME [epoch: 10.5 sec]
EPOCH 35/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3654062225460586		[learning rate: 0.0089]
	Learning Rate: 0.00889995
	LOSS [training: 3.3654062225460586 | validation: 3.109739357692497]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2678971976438134		[learning rate: 0.0088582]
	Learning Rate: 0.00885823
	LOSS [training: 3.2678971976438134 | validation: 3.356434247929907]
	TIME [epoch: 10.5 sec]
EPOCH 37/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4302276235797953		[learning rate: 0.0088167]
	Learning Rate: 0.0088167
	LOSS [training: 3.4302276235797953 | validation: 3.087562480551936]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_37.pth
	Model improved!!!
EPOCH 38/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2259375531358643		[learning rate: 0.0087754]
	Learning Rate: 0.00877537
	LOSS [training: 3.2259375531358643 | validation: 3.11885783078499]
	TIME [epoch: 10.5 sec]
EPOCH 39/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7601616193425165		[learning rate: 0.0087342]
	Learning Rate: 0.00873423
	LOSS [training: 3.7601616193425165 | validation: 4.817420509216778]
	TIME [epoch: 10.5 sec]
EPOCH 40/500:
	Training over batches...
		[batch 5/5] avg loss: 4.846760799655758		[learning rate: 0.0086933]
	Learning Rate: 0.00869328
	LOSS [training: 4.846760799655758 | validation: 3.7705304393099155]
	TIME [epoch: 10.5 sec]
EPOCH 41/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8004867736092196		[learning rate: 0.0086525]
	Learning Rate: 0.00865253
	LOSS [training: 3.8004867736092196 | validation: 5.450093947128563]
	TIME [epoch: 10.5 sec]
EPOCH 42/500:
	Training over batches...
		[batch 5/5] avg loss: 4.935124404179037		[learning rate: 0.008612]
	Learning Rate: 0.00861196
	LOSS [training: 4.935124404179037 | validation: 3.333777261945408]
	TIME [epoch: 10.5 sec]
EPOCH 43/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5116865865299163		[learning rate: 0.0085716]
	Learning Rate: 0.00857159
	LOSS [training: 3.5116865865299163 | validation: 3.1536801488519393]
	TIME [epoch: 10.5 sec]
EPOCH 44/500:
	Training over batches...
		[batch 5/5] avg loss: 3.276263478094871		[learning rate: 0.0085314]
	Learning Rate: 0.0085314
	LOSS [training: 3.276263478094871 | validation: 3.2338138038014517]
	TIME [epoch: 10.5 sec]
EPOCH 45/500:
	Training over batches...
		[batch 5/5] avg loss: 3.714591688662666		[learning rate: 0.0084914]
	Learning Rate: 0.00849141
	LOSS [training: 3.714591688662666 | validation: 4.323560561168171]
	TIME [epoch: 10.5 sec]
EPOCH 46/500:
	Training over batches...
		[batch 5/5] avg loss: 3.620382935483628		[learning rate: 0.0084516]
	Learning Rate: 0.0084516
	LOSS [training: 3.620382935483628 | validation: 3.0835301904930703]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2962586823161715		[learning rate: 0.008412]
	Learning Rate: 0.00841197
	LOSS [training: 3.2962586823161715 | validation: 3.1762484276699166]
	TIME [epoch: 10.5 sec]
EPOCH 48/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8895767813069684		[learning rate: 0.0083725]
	Learning Rate: 0.00837254
	LOSS [training: 3.8895767813069684 | validation: 3.14374926932707]
	TIME [epoch: 10.5 sec]
EPOCH 49/500:
	Training over batches...
		[batch 5/5] avg loss: 3.784040686209162		[learning rate: 0.0083333]
	Learning Rate: 0.00833329
	LOSS [training: 3.784040686209162 | validation: 4.577044938337671]
	TIME [epoch: 10.5 sec]
EPOCH 50/500:
	Training over batches...
		[batch 5/5] avg loss: 4.1108913064915225		[learning rate: 0.0082942]
	Learning Rate: 0.00829422
	LOSS [training: 4.1108913064915225 | validation: 3.4047751958883303]
	TIME [epoch: 10.5 sec]
EPOCH 51/500:
	Training over batches...
		[batch 5/5] avg loss: 3.384933397512543		[learning rate: 0.0082553]
	Learning Rate: 0.00825533
	LOSS [training: 3.384933397512543 | validation: 3.5004315383356746]
	TIME [epoch: 10.5 sec]
EPOCH 52/500:
	Training over batches...
		[batch 5/5] avg loss: 3.471648622533062		[learning rate: 0.0082166]
	Learning Rate: 0.00821663
	LOSS [training: 3.471648622533062 | validation: 3.063798067028347]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_52.pth
	Model improved!!!
EPOCH 53/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1386314688815475		[learning rate: 0.0081781]
	Learning Rate: 0.00817811
	LOSS [training: 3.1386314688815475 | validation: 2.9892169001499247]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_53.pth
	Model improved!!!
EPOCH 54/500:
	Training over batches...
		[batch 5/5] avg loss: 3.403692533333829		[learning rate: 0.0081398]
	Learning Rate: 0.00813977
	LOSS [training: 3.403692533333829 | validation: 3.1059854592545846]
	TIME [epoch: 10.5 sec]
EPOCH 55/500:
	Training over batches...
		[batch 5/5] avg loss: 4.005797183268207		[learning rate: 0.0081016]
	Learning Rate: 0.00810161
	LOSS [training: 4.005797183268207 | validation: 4.150572462138681]
	TIME [epoch: 10.5 sec]
EPOCH 56/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7339696690172817		[learning rate: 0.0080636]
	Learning Rate: 0.00806363
	LOSS [training: 3.7339696690172817 | validation: 3.749347728954011]
	TIME [epoch: 10.5 sec]
EPOCH 57/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4173478286694845		[learning rate: 0.0080258]
	Learning Rate: 0.00802583
	LOSS [training: 3.4173478286694845 | validation: 4.516506834283295]
	TIME [epoch: 10.5 sec]
EPOCH 58/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8776223265287753		[learning rate: 0.0079882]
	Learning Rate: 0.0079882
	LOSS [training: 3.8776223265287753 | validation: 3.8173316546038794]
	TIME [epoch: 10.5 sec]
EPOCH 59/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3933803156162243		[learning rate: 0.0079508]
	Learning Rate: 0.00795075
	LOSS [training: 3.3933803156162243 | validation: 2.978757177880339]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 5/5] avg loss: 3.034972491189295		[learning rate: 0.0079135]
	Learning Rate: 0.00791348
	LOSS [training: 3.034972491189295 | validation: 3.1521275195851297]
	TIME [epoch: 10.5 sec]
EPOCH 61/500:
	Training over batches...
		[batch 5/5] avg loss: 3.065799890658753		[learning rate: 0.0078764]
	Learning Rate: 0.00787638
	LOSS [training: 3.065799890658753 | validation: 3.111006699724105]
	TIME [epoch: 10.5 sec]
EPOCH 62/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9623878171149314		[learning rate: 0.0078395]
	Learning Rate: 0.00783945
	LOSS [training: 3.9623878171149314 | validation: 2.8737812458855236]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5710893209277215		[learning rate: 0.0078027]
	Learning Rate: 0.0078027
	LOSS [training: 3.5710893209277215 | validation: 3.474388932255439]
	TIME [epoch: 10.5 sec]
EPOCH 64/500:
	Training over batches...
		[batch 5/5] avg loss: 3.301159895492238		[learning rate: 0.0077661]
	Learning Rate: 0.00776612
	LOSS [training: 3.301159895492238 | validation: 3.1026220945973684]
	TIME [epoch: 10.5 sec]
EPOCH 65/500:
	Training over batches...
		[batch 5/5] avg loss: 3.288552980065339		[learning rate: 0.0077297]
	Learning Rate: 0.00772971
	LOSS [training: 3.288552980065339 | validation: 3.1115156478713]
	TIME [epoch: 10.5 sec]
EPOCH 66/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1095081544010337		[learning rate: 0.0076935]
	Learning Rate: 0.00769347
	LOSS [training: 3.1095081544010337 | validation: 3.0632935702917945]
	TIME [epoch: 10.5 sec]
EPOCH 67/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1293809138232938		[learning rate: 0.0076574]
	Learning Rate: 0.0076574
	LOSS [training: 3.1293809138232938 | validation: 3.1054142628040236]
	TIME [epoch: 10.5 sec]
EPOCH 68/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3252904823310607		[learning rate: 0.0076215]
	Learning Rate: 0.00762151
	LOSS [training: 3.3252904823310607 | validation: 2.907163945552021]
	TIME [epoch: 10.5 sec]
EPOCH 69/500:
	Training over batches...
		[batch 5/5] avg loss: 3.037671534866805		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 3.037671534866805 | validation: 3.046793154760684]
	TIME [epoch: 10.5 sec]
EPOCH 70/500:
	Training over batches...
		[batch 5/5] avg loss: 3.072838307726221		[learning rate: 0.0075502]
	Learning Rate: 0.00755021
	LOSS [training: 3.072838307726221 | validation: 3.009486631151051]
	TIME [epoch: 10.5 sec]
EPOCH 71/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9651376527935716		[learning rate: 0.0075148]
	Learning Rate: 0.00751482
	LOSS [training: 2.9651376527935716 | validation: 3.008091430396456]
	TIME [epoch: 10.5 sec]
EPOCH 72/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0243835903177887		[learning rate: 0.0074796]
	Learning Rate: 0.00747959
	LOSS [training: 3.0243835903177887 | validation: 3.085373926812547]
	TIME [epoch: 10.5 sec]
EPOCH 73/500:
	Training over batches...
		[batch 5/5] avg loss: 3.250860375697016		[learning rate: 0.0074445]
	Learning Rate: 0.00744452
	LOSS [training: 3.250860375697016 | validation: 2.7347646580108553]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_73.pth
	Model improved!!!
EPOCH 74/500:
	Training over batches...
		[batch 5/5] avg loss: 2.810641127835223		[learning rate: 0.0074096]
	Learning Rate: 0.00740962
	LOSS [training: 2.810641127835223 | validation: 2.913456003305354]
	TIME [epoch: 10.5 sec]
EPOCH 75/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2528896481215694		[learning rate: 0.0073749]
	Learning Rate: 0.00737488
	LOSS [training: 3.2528896481215694 | validation: 4.236728660407979]
	TIME [epoch: 10.5 sec]
EPOCH 76/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2395607671614832		[learning rate: 0.0073403]
	Learning Rate: 0.00734031
	LOSS [training: 3.2395607671614832 | validation: 2.7934914544934206]
	TIME [epoch: 10.5 sec]
EPOCH 77/500:
	Training over batches...
		[batch 5/5] avg loss: 2.929711752400956		[learning rate: 0.0073059]
	Learning Rate: 0.00730589
	LOSS [training: 2.929711752400956 | validation: 2.766405117203167]
	TIME [epoch: 10.5 sec]
EPOCH 78/500:
	Training over batches...
		[batch 5/5] avg loss: 2.845985880378361		[learning rate: 0.0072716]
	Learning Rate: 0.00727164
	LOSS [training: 2.845985880378361 | validation: 2.892431455215408]
	TIME [epoch: 10.5 sec]
EPOCH 79/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0996341389711737		[learning rate: 0.0072376]
	Learning Rate: 0.00723755
	LOSS [training: 3.0996341389711737 | validation: 2.9019384846076344]
	TIME [epoch: 10.5 sec]
EPOCH 80/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7921761668437926		[learning rate: 0.0072036]
	Learning Rate: 0.00720362
	LOSS [training: 3.7921761668437926 | validation: 3.0083495212906137]
	TIME [epoch: 10.5 sec]
EPOCH 81/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1837829102409163		[learning rate: 0.0071699]
	Learning Rate: 0.00716985
	LOSS [training: 3.1837829102409163 | validation: 3.724445732498362]
	TIME [epoch: 10.5 sec]
EPOCH 82/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2586434807931597		[learning rate: 0.0071362]
	Learning Rate: 0.00713624
	LOSS [training: 3.2586434807931597 | validation: 2.5811697235368927]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/500:
	Training over batches...
		[batch 5/5] avg loss: 2.736920435118736		[learning rate: 0.0071028]
	Learning Rate: 0.00710278
	LOSS [training: 2.736920435118736 | validation: 2.7410758607861725]
	TIME [epoch: 10.5 sec]
EPOCH 84/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8220115671609403		[learning rate: 0.0070695]
	Learning Rate: 0.00706948
	LOSS [training: 2.8220115671609403 | validation: 2.6855712878318774]
	TIME [epoch: 10.5 sec]
EPOCH 85/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7346553853173754		[learning rate: 0.0070363]
	Learning Rate: 0.00703634
	LOSS [training: 2.7346553853173754 | validation: 2.618670153662038]
	TIME [epoch: 10.5 sec]
EPOCH 86/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6541359276964847		[learning rate: 0.0070034]
	Learning Rate: 0.00700335
	LOSS [training: 2.6541359276964847 | validation: 2.5087130385518885]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_86.pth
	Model improved!!!
EPOCH 87/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6044901322958083		[learning rate: 0.0069705]
	Learning Rate: 0.00697052
	LOSS [training: 2.6044901322958083 | validation: 2.588095103975301]
	TIME [epoch: 10.5 sec]
EPOCH 88/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4747471736155164		[learning rate: 0.0069378]
	Learning Rate: 0.00693784
	LOSS [training: 2.4747471736155164 | validation: 2.4292048581402343]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_88.pth
	Model improved!!!
EPOCH 89/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4443582794948733		[learning rate: 0.0069053]
	Learning Rate: 0.00690532
	LOSS [training: 2.4443582794948733 | validation: 2.385270977723278]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_89.pth
	Model improved!!!
EPOCH 90/500:
	Training over batches...
		[batch 5/5] avg loss: 2.434735205947831		[learning rate: 0.0068729]
	Learning Rate: 0.00687294
	LOSS [training: 2.434735205947831 | validation: 2.6097708115965816]
	TIME [epoch: 10.5 sec]
EPOCH 91/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3939427292762074		[learning rate: 0.0068407]
	Learning Rate: 0.00684072
	LOSS [training: 2.3939427292762074 | validation: 2.3172092964933104]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_91.pth
	Model improved!!!
EPOCH 92/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1976469830587577		[learning rate: 0.0068087]
	Learning Rate: 0.00680865
	LOSS [training: 2.1976469830587577 | validation: 2.7821136706291374]
	TIME [epoch: 10.5 sec]
EPOCH 93/500:
	Training over batches...
		[batch 5/5] avg loss: 2.609588597939777		[learning rate: 0.0067767]
	Learning Rate: 0.00677673
	LOSS [training: 2.609588597939777 | validation: 2.0424057883916333]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_93.pth
	Model improved!!!
EPOCH 94/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0979450158049864		[learning rate: 0.006745]
	Learning Rate: 0.00674496
	LOSS [training: 2.0979450158049864 | validation: 2.0456156711506974]
	TIME [epoch: 10.5 sec]
EPOCH 95/500:
	Training over batches...
		[batch 5/5] avg loss: 2.040751071165135		[learning rate: 0.0067133]
	Learning Rate: 0.00671334
	LOSS [training: 2.040751071165135 | validation: 1.8799298061378829]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_95.pth
	Model improved!!!
EPOCH 96/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0568049591871143		[learning rate: 0.0066819]
	Learning Rate: 0.00668187
	LOSS [training: 2.0568049591871143 | validation: 2.784964810860586]
	TIME [epoch: 10.5 sec]
EPOCH 97/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4115276636025587		[learning rate: 0.0066505]
	Learning Rate: 0.00665054
	LOSS [training: 2.4115276636025587 | validation: 1.924219233216751]
	TIME [epoch: 10.5 sec]
EPOCH 98/500:
	Training over batches...
		[batch 5/5] avg loss: 2.596581011424887		[learning rate: 0.0066194]
	Learning Rate: 0.00661936
	LOSS [training: 2.596581011424887 | validation: 4.160278662653938]
	TIME [epoch: 10.5 sec]
EPOCH 99/500:
	Training over batches...
		[batch 5/5] avg loss: 2.888282373002854		[learning rate: 0.0065883]
	Learning Rate: 0.00658833
	LOSS [training: 2.888282373002854 | validation: 1.842915791845925]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_99.pth
	Model improved!!!
EPOCH 100/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8831688676735847		[learning rate: 0.0065574]
	Learning Rate: 0.00655745
	LOSS [training: 1.8831688676735847 | validation: 1.7927827689733744]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_100.pth
	Model improved!!!
EPOCH 101/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7630561236011804		[learning rate: 0.0065267]
	Learning Rate: 0.0065267
	LOSS [training: 1.7630561236011804 | validation: 2.4132934943387276]
	TIME [epoch: 10.5 sec]
EPOCH 102/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8223863515995795		[learning rate: 0.0064961]
	Learning Rate: 0.0064961
	LOSS [training: 1.8223863515995795 | validation: 1.562163513900311]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_102.pth
	Model improved!!!
EPOCH 103/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7646988814161264		[learning rate: 0.0064657]
	Learning Rate: 0.00646565
	LOSS [training: 1.7646988814161264 | validation: 1.9457048087477835]
	TIME [epoch: 10.5 sec]
EPOCH 104/500:
	Training over batches...
		[batch 5/5] avg loss: 1.573906755738042		[learning rate: 0.0064353]
	Learning Rate: 0.00643534
	LOSS [training: 1.573906755738042 | validation: 2.0373587873277903]
	TIME [epoch: 10.5 sec]
EPOCH 105/500:
	Training over batches...
		[batch 5/5] avg loss: 1.328650206020643		[learning rate: 0.0064052]
	Learning Rate: 0.00640517
	LOSS [training: 1.328650206020643 | validation: 1.3974007738806635]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_105.pth
	Model improved!!!
EPOCH 106/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5149566097379366		[learning rate: 0.0063751]
	Learning Rate: 0.00637514
	LOSS [training: 1.5149566097379366 | validation: 1.4141946172513324]
	TIME [epoch: 10.5 sec]
EPOCH 107/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2320840147503198		[learning rate: 0.0063453]
	Learning Rate: 0.00634525
	LOSS [training: 1.2320840147503198 | validation: 1.078939585785804]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_107.pth
	Model improved!!!
EPOCH 108/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0638585045452942		[learning rate: 0.0063155]
	Learning Rate: 0.00631551
	LOSS [training: 1.0638585045452942 | validation: 1.1528724711800964]
	TIME [epoch: 10.5 sec]
EPOCH 109/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1638474440173407		[learning rate: 0.0062859]
	Learning Rate: 0.0062859
	LOSS [training: 1.1638474440173407 | validation: 0.9711475421912567]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_109.pth
	Model improved!!!
EPOCH 110/500:
	Training over batches...
		[batch 5/5] avg loss: 1.068466093278327		[learning rate: 0.0062564]
	Learning Rate: 0.00625643
	LOSS [training: 1.068466093278327 | validation: 0.8994016143437427]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9721140281586085		[learning rate: 0.0062271]
	Learning Rate: 0.0062271
	LOSS [training: 0.9721140281586085 | validation: 0.7012446209827295]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_111.pth
	Model improved!!!
EPOCH 112/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8012778436793291		[learning rate: 0.0061979]
	Learning Rate: 0.0061979
	LOSS [training: 0.8012778436793291 | validation: 0.8376409347349227]
	TIME [epoch: 10.5 sec]
EPOCH 113/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8728754522591448		[learning rate: 0.0061688]
	Learning Rate: 0.00616885
	LOSS [training: 0.8728754522591448 | validation: 0.9920294610576947]
	TIME [epoch: 10.5 sec]
EPOCH 114/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8938603798697695		[learning rate: 0.0061399]
	Learning Rate: 0.00613993
	LOSS [training: 0.8938603798697695 | validation: 0.6900852950580401]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_114.pth
	Model improved!!!
EPOCH 115/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7118742985870607		[learning rate: 0.0061111]
	Learning Rate: 0.00611114
	LOSS [training: 0.7118742985870607 | validation: 0.8705767972098581]
	TIME [epoch: 10.5 sec]
EPOCH 116/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6736056243830489		[learning rate: 0.0060825]
	Learning Rate: 0.00608249
	LOSS [training: 0.6736056243830489 | validation: 1.121725104112967]
	TIME [epoch: 10.5 sec]
EPOCH 117/500:
	Training over batches...
		[batch 5/5] avg loss: 0.817079318302552		[learning rate: 0.006054]
	Learning Rate: 0.00605398
	LOSS [training: 0.817079318302552 | validation: 0.844016421836521]
	TIME [epoch: 10.5 sec]
EPOCH 118/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7591580107318759		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.7591580107318759 | validation: 0.7469035827137]
	TIME [epoch: 10.5 sec]
EPOCH 119/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6692958937867545		[learning rate: 0.0059973]
	Learning Rate: 0.00599735
	LOSS [training: 0.6692958937867545 | validation: 0.4912312078376686]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_119.pth
	Model improved!!!
EPOCH 120/500:
	Training over batches...
		[batch 5/5] avg loss: 1.640702135662936		[learning rate: 0.0059692]
	Learning Rate: 0.00596923
	LOSS [training: 1.640702135662936 | validation: 0.7610875641731152]
	TIME [epoch: 10.5 sec]
EPOCH 121/500:
	Training over batches...
		[batch 5/5] avg loss: 1.9629502375879722		[learning rate: 0.0059412]
	Learning Rate: 0.00594125
	LOSS [training: 1.9629502375879722 | validation: 2.6630300943325365]
	TIME [epoch: 10.5 sec]
EPOCH 122/500:
	Training over batches...
		[batch 5/5] avg loss: 2.80329055423959		[learning rate: 0.0059134]
	Learning Rate: 0.00591339
	LOSS [training: 2.80329055423959 | validation: 2.714055784536305]
	TIME [epoch: 10.5 sec]
EPOCH 123/500:
	Training over batches...
		[batch 5/5] avg loss: 2.547830506198636		[learning rate: 0.0058857]
	Learning Rate: 0.00588567
	LOSS [training: 2.547830506198636 | validation: 2.6659801264266028]
	TIME [epoch: 10.5 sec]
EPOCH 124/500:
	Training over batches...
		[batch 5/5] avg loss: 2.591853177792435		[learning rate: 0.0058581]
	Learning Rate: 0.00585808
	LOSS [training: 2.591853177792435 | validation: 2.7139034347726843]
	TIME [epoch: 10.5 sec]
EPOCH 125/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4984002335690847		[learning rate: 0.0058306]
	Learning Rate: 0.00583061
	LOSS [training: 2.4984002335690847 | validation: 2.79516371556036]
	TIME [epoch: 10.5 sec]
EPOCH 126/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5352458885480713		[learning rate: 0.0058033]
	Learning Rate: 0.00580328
	LOSS [training: 2.5352458885480713 | validation: 2.9944694006826906]
	TIME [epoch: 10.5 sec]
EPOCH 127/500:
	Training over batches...
		[batch 5/5] avg loss: 2.651191405362245		[learning rate: 0.0057761]
	Learning Rate: 0.00577607
	LOSS [training: 2.651191405362245 | validation: 2.7687904237889494]
	TIME [epoch: 10.5 sec]
EPOCH 128/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0074725356173326		[learning rate: 0.005749]
	Learning Rate: 0.00574899
	LOSS [training: 3.0074725356173326 | validation: 3.3246202168612076]
	TIME [epoch: 10.5 sec]
EPOCH 129/500:
	Training over batches...
		[batch 5/5] avg loss: 2.750782861521425		[learning rate: 0.005722]
	Learning Rate: 0.00572204
	LOSS [training: 2.750782861521425 | validation: 2.7112183491550024]
	TIME [epoch: 10.5 sec]
EPOCH 130/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5942450372737937		[learning rate: 0.0056952]
	Learning Rate: 0.00569522
	LOSS [training: 2.5942450372737937 | validation: 3.085470666568822]
	TIME [epoch: 10.5 sec]
EPOCH 131/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6787195962445414		[learning rate: 0.0056685]
	Learning Rate: 0.00566852
	LOSS [training: 2.6787195962445414 | validation: 2.748023306280386]
	TIME [epoch: 10.5 sec]
EPOCH 132/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5123807515999883		[learning rate: 0.0056419]
	Learning Rate: 0.00564194
	LOSS [training: 2.5123807515999883 | validation: 2.6747988203024953]
	TIME [epoch: 10.5 sec]
EPOCH 133/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5041587078365843		[learning rate: 0.0056155]
	Learning Rate: 0.00561549
	LOSS [training: 2.5041587078365843 | validation: 2.6887606894290346]
	TIME [epoch: 10.5 sec]
EPOCH 134/500:
	Training over batches...
		[batch 5/5] avg loss: 2.512443875369702		[learning rate: 0.0055892]
	Learning Rate: 0.00558916
	LOSS [training: 2.512443875369702 | validation: 2.7540254833928324]
	TIME [epoch: 10.5 sec]
EPOCH 135/500:
	Training over batches...
		[batch 5/5] avg loss: 2.58599338915052		[learning rate: 0.005563]
	Learning Rate: 0.00556296
	LOSS [training: 2.58599338915052 | validation: 3.1585038537981105]
	TIME [epoch: 10.5 sec]
EPOCH 136/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6333470417392304		[learning rate: 0.0055369]
	Learning Rate: 0.00553688
	LOSS [training: 2.6333470417392304 | validation: 2.7511362623082753]
	TIME [epoch: 10.5 sec]
EPOCH 137/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5567485931675615		[learning rate: 0.0055109]
	Learning Rate: 0.00551092
	LOSS [training: 2.5567485931675615 | validation: 2.7864905042398678]
	TIME [epoch: 10.5 sec]
EPOCH 138/500:
	Training over batches...
		[batch 5/5] avg loss: 2.63307232862221		[learning rate: 0.0054851]
	Learning Rate: 0.00548509
	LOSS [training: 2.63307232862221 | validation: 2.6572431014534983]
	TIME [epoch: 10.5 sec]
EPOCH 139/500:
	Training over batches...
		[batch 5/5] avg loss: 2.526177223086935		[learning rate: 0.0054594]
	Learning Rate: 0.00545937
	LOSS [training: 2.526177223086935 | validation: 2.7375096448433647]
	TIME [epoch: 10.5 sec]
EPOCH 140/500:
	Training over batches...
		[batch 5/5] avg loss: 2.524395440427812		[learning rate: 0.0054338]
	Learning Rate: 0.00543378
	LOSS [training: 2.524395440427812 | validation: 2.7292719884348027]
	TIME [epoch: 10.5 sec]
EPOCH 141/500:
	Training over batches...
		[batch 5/5] avg loss: 2.510422533478738		[learning rate: 0.0054083]
	Learning Rate: 0.00540831
	LOSS [training: 2.510422533478738 | validation: 2.8045867411945014]
	TIME [epoch: 10.5 sec]
EPOCH 142/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5379985974559807		[learning rate: 0.005383]
	Learning Rate: 0.00538295
	LOSS [training: 2.5379985974559807 | validation: 2.667588721352599]
	TIME [epoch: 10.5 sec]
EPOCH 143/500:
	Training over batches...
		[batch 5/5] avg loss: 2.512543507925801		[learning rate: 0.0053577]
	Learning Rate: 0.00535771
	LOSS [training: 2.512543507925801 | validation: 2.6840260279879162]
	TIME [epoch: 10.5 sec]
EPOCH 144/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5355338321846093		[learning rate: 0.0053326]
	Learning Rate: 0.0053326
	LOSS [training: 2.5355338321846093 | validation: 2.661931090380498]
	TIME [epoch: 10.5 sec]
EPOCH 145/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5078969134549483		[learning rate: 0.0053076]
	Learning Rate: 0.0053076
	LOSS [training: 2.5078969134549483 | validation: 2.7380320381825722]
	TIME [epoch: 10.5 sec]
EPOCH 146/500:
	Training over batches...
		[batch 5/5] avg loss: 3.109013388480973		[learning rate: 0.0052827]
	Learning Rate: 0.00528271
	LOSS [training: 3.109013388480973 | validation: 3.511112104084061]
	TIME [epoch: 10.5 sec]
EPOCH 147/500:
	Training over batches...
		[batch 5/5] avg loss: 2.865333287126061		[learning rate: 0.0052579]
	Learning Rate: 0.00525795
	LOSS [training: 2.865333287126061 | validation: 2.8007322570498308]
	TIME [epoch: 10.5 sec]
EPOCH 148/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6001849053903436		[learning rate: 0.0052333]
	Learning Rate: 0.0052333
	LOSS [training: 2.6001849053903436 | validation: 2.813101443820879]
	TIME [epoch: 10.5 sec]
EPOCH 149/500:
	Training over batches...
		[batch 5/5] avg loss: 2.600994905942165		[learning rate: 0.0052088]
	Learning Rate: 0.00520876
	LOSS [training: 2.600994905942165 | validation: 2.7747602639151285]
	TIME [epoch: 10.5 sec]
EPOCH 150/500:
	Training over batches...
		[batch 5/5] avg loss: 2.594577728625409		[learning rate: 0.0051843]
	Learning Rate: 0.00518434
	LOSS [training: 2.594577728625409 | validation: 2.737215239464281]
	TIME [epoch: 10.5 sec]
EPOCH 151/500:
	Training over batches...
		[batch 5/5] avg loss: 2.59564690221608		[learning rate: 0.00516]
	Learning Rate: 0.00516004
	LOSS [training: 2.59564690221608 | validation: 2.6974271186105963]
	TIME [epoch: 10.5 sec]
EPOCH 152/500:
	Training over batches...
		[batch 5/5] avg loss: 2.547512772481001		[learning rate: 0.0051358]
	Learning Rate: 0.00513585
	LOSS [training: 2.547512772481001 | validation: 3.381938540692385]
	TIME [epoch: 10.5 sec]
EPOCH 153/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8758436856435723		[learning rate: 0.0051118]
	Learning Rate: 0.00511177
	LOSS [training: 2.8758436856435723 | validation: 2.7642596480449964]
	TIME [epoch: 10.5 sec]
EPOCH 154/500:
	Training over batches...
		[batch 5/5] avg loss: 2.606136079025571		[learning rate: 0.0050878]
	Learning Rate: 0.00508781
	LOSS [training: 2.606136079025571 | validation: 2.7346411533939765]
	TIME [epoch: 10.5 sec]
EPOCH 155/500:
	Training over batches...
		[batch 5/5] avg loss: 2.638619234483017		[learning rate: 0.005064]
	Learning Rate: 0.00506395
	LOSS [training: 2.638619234483017 | validation: 2.833180358685981]
	TIME [epoch: 10.5 sec]
EPOCH 156/500:
	Training over batches...
		[batch 5/5] avg loss: 2.639268850739719		[learning rate: 0.0050402]
	Learning Rate: 0.00504021
	LOSS [training: 2.639268850739719 | validation: 2.758214539093404]
	TIME [epoch: 10.5 sec]
EPOCH 157/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6289139257767062		[learning rate: 0.0050166]
	Learning Rate: 0.00501658
	LOSS [training: 2.6289139257767062 | validation: 3.7328192896255405]
	TIME [epoch: 10.5 sec]
EPOCH 158/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1397728942534258		[learning rate: 0.0049931]
	Learning Rate: 0.00499307
	LOSS [training: 3.1397728942534258 | validation: 2.9218691274886215]
	TIME [epoch: 10.5 sec]
EPOCH 159/500:
	Training over batches...
		[batch 5/5] avg loss: 2.643656955452829		[learning rate: 0.0049697]
	Learning Rate: 0.00496966
	LOSS [training: 2.643656955452829 | validation: 2.8107871825755892]
	TIME [epoch: 10.5 sec]
EPOCH 160/500:
	Training over batches...
		[batch 5/5] avg loss: 2.691535082436882		[learning rate: 0.0049464]
	Learning Rate: 0.00494636
	LOSS [training: 2.691535082436882 | validation: 2.810648595514828]
	TIME [epoch: 10.5 sec]
EPOCH 161/500:
	Training over batches...
		[batch 5/5] avg loss: 2.672757910780178		[learning rate: 0.0049232]
	Learning Rate: 0.00492317
	LOSS [training: 2.672757910780178 | validation: 2.837740716483486]
	TIME [epoch: 10.5 sec]
EPOCH 162/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6378180971780956		[learning rate: 0.0049001]
	Learning Rate: 0.00490009
	LOSS [training: 2.6378180971780956 | validation: 2.8672355825428633]
	TIME [epoch: 10.5 sec]
EPOCH 163/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6685351147916463		[learning rate: 0.0048771]
	Learning Rate: 0.00487712
	LOSS [training: 2.6685351147916463 | validation: 3.0254705735345944]
	TIME [epoch: 10.5 sec]
EPOCH 164/500:
	Training over batches...
		[batch 5/5] avg loss: 2.683079973170823		[learning rate: 0.0048543]
	Learning Rate: 0.00485425
	LOSS [training: 2.683079973170823 | validation: 2.837821510512274]
	TIME [epoch: 10.5 sec]
EPOCH 165/500:
	Training over batches...
		[batch 5/5] avg loss: 2.655431163928335		[learning rate: 0.0048315]
	Learning Rate: 0.0048315
	LOSS [training: 2.655431163928335 | validation: 2.8643109730189042]
	TIME [epoch: 10.5 sec]
EPOCH 166/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6478734833067334		[learning rate: 0.0048088]
	Learning Rate: 0.00480885
	LOSS [training: 2.6478734833067334 | validation: 2.839318320792405]
	TIME [epoch: 10.5 sec]
EPOCH 167/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6520067997763674		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 2.6520067997763674 | validation: 2.8022110672898464]
	TIME [epoch: 10.5 sec]
EPOCH 168/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7014825383502092		[learning rate: 0.0047639]
	Learning Rate: 0.00476386
	LOSS [training: 2.7014825383502092 | validation: 2.7296520541604083]
	TIME [epoch: 10.5 sec]
EPOCH 169/500:
	Training over batches...
		[batch 5/5] avg loss: 2.647191761352924		[learning rate: 0.0047415]
	Learning Rate: 0.00474153
	LOSS [training: 2.647191761352924 | validation: 2.9315222814286814]
	TIME [epoch: 10.5 sec]
EPOCH 170/500:
	Training over batches...
		[batch 5/5] avg loss: 2.641088937893865		[learning rate: 0.0047193]
	Learning Rate: 0.0047193
	LOSS [training: 2.641088937893865 | validation: 2.8276182617541226]
	TIME [epoch: 10.5 sec]
EPOCH 171/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6573246791671346		[learning rate: 0.0046972]
	Learning Rate: 0.00469718
	LOSS [training: 2.6573246791671346 | validation: 2.7671610251460903]
	TIME [epoch: 10.5 sec]
EPOCH 172/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6260933512810505		[learning rate: 0.0046752]
	Learning Rate: 0.00467515
	LOSS [training: 2.6260933512810505 | validation: 2.7499470615865427]
	TIME [epoch: 10.5 sec]
EPOCH 173/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6332417917600566		[learning rate: 0.0046532]
	Learning Rate: 0.00465324
	LOSS [training: 2.6332417917600566 | validation: 3.25490903156465]
	TIME [epoch: 10.5 sec]
EPOCH 174/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7243040739828746		[learning rate: 0.0046314]
	Learning Rate: 0.00463142
	LOSS [training: 2.7243040739828746 | validation: 2.8124408654405126]
	TIME [epoch: 10.5 sec]
EPOCH 175/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6164443014103957		[learning rate: 0.0046097]
	Learning Rate: 0.00460971
	LOSS [training: 2.6164443014103957 | validation: 2.755916030861082]
	TIME [epoch: 10.5 sec]
EPOCH 176/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8808560461320556		[learning rate: 0.0045881]
	Learning Rate: 0.0045881
	LOSS [training: 2.8808560461320556 | validation: 2.8557394664239486]
	TIME [epoch: 10.5 sec]
EPOCH 177/500:
	Training over batches...
		[batch 5/5] avg loss: 2.717486301196147		[learning rate: 0.0045666]
	Learning Rate: 0.00456659
	LOSS [training: 2.717486301196147 | validation: 2.7701695438488465]
	TIME [epoch: 10.5 sec]
EPOCH 178/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6133847216208292		[learning rate: 0.0045452]
	Learning Rate: 0.00454518
	LOSS [training: 2.6133847216208292 | validation: 2.7506418119346168]
	TIME [epoch: 10.5 sec]
EPOCH 179/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6209045996265883		[learning rate: 0.0045239]
	Learning Rate: 0.00452387
	LOSS [training: 2.6209045996265883 | validation: 2.692125855009516]
	TIME [epoch: 10.5 sec]
EPOCH 180/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6486354457428396		[learning rate: 0.0045027]
	Learning Rate: 0.00450266
	LOSS [training: 2.6486354457428396 | validation: 2.743686806004205]
	TIME [epoch: 10.6 sec]
EPOCH 181/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5735655351244446		[learning rate: 0.0044816]
	Learning Rate: 0.00448155
	LOSS [training: 2.5735655351244446 | validation: 2.756058603542158]
	TIME [epoch: 10.5 sec]
EPOCH 182/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5774415747159054		[learning rate: 0.0044605]
	Learning Rate: 0.00446054
	LOSS [training: 2.5774415747159054 | validation: 3.2843482023431125]
	TIME [epoch: 10.5 sec]
EPOCH 183/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8194503581257377		[learning rate: 0.0044396]
	Learning Rate: 0.00443963
	LOSS [training: 2.8194503581257377 | validation: 2.7935668650266905]
	TIME [epoch: 10.5 sec]
EPOCH 184/500:
	Training over batches...
		[batch 5/5] avg loss: 2.673317952955319		[learning rate: 0.0044188]
	Learning Rate: 0.00441882
	LOSS [training: 2.673317952955319 | validation: 2.819705591871184]
	TIME [epoch: 10.5 sec]
EPOCH 185/500:
	Training over batches...
		[batch 5/5] avg loss: 2.755146156975242		[learning rate: 0.0043981]
	Learning Rate: 0.0043981
	LOSS [training: 2.755146156975242 | validation: 2.909358947528192]
	TIME [epoch: 10.5 sec]
EPOCH 186/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7225685535602673		[learning rate: 0.0043775]
	Learning Rate: 0.00437748
	LOSS [training: 2.7225685535602673 | validation: 2.772863548751052]
	TIME [epoch: 10.5 sec]
EPOCH 187/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6174875248075358		[learning rate: 0.004357]
	Learning Rate: 0.00435696
	LOSS [training: 2.6174875248075358 | validation: 2.7323145100515895]
	TIME [epoch: 10.5 sec]
EPOCH 188/500:
	Training over batches...
		[batch 5/5] avg loss: 2.608166823511383		[learning rate: 0.0043365]
	Learning Rate: 0.00433654
	LOSS [training: 2.608166823511383 | validation: 2.73285675772658]
	TIME [epoch: 10.5 sec]
EPOCH 189/500:
	Training over batches...
		[batch 5/5] avg loss: 2.561165865837027		[learning rate: 0.0043162]
	Learning Rate: 0.0043162
	LOSS [training: 2.561165865837027 | validation: 2.719734735469003]
	TIME [epoch: 10.5 sec]
EPOCH 190/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6217147498177016		[learning rate: 0.004296]
	Learning Rate: 0.00429597
	LOSS [training: 2.6217147498177016 | validation: 2.908760981935845]
	TIME [epoch: 10.5 sec]
EPOCH 191/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6353328210995124		[learning rate: 0.0042758]
	Learning Rate: 0.00427583
	LOSS [training: 2.6353328210995124 | validation: 2.7282138523804833]
	TIME [epoch: 10.5 sec]
EPOCH 192/500:
	Training over batches...
		[batch 5/5] avg loss: 2.603982655650485		[learning rate: 0.0042558]
	Learning Rate: 0.00425578
	LOSS [training: 2.603982655650485 | validation: 2.8003780372553515]
	TIME [epoch: 10.5 sec]
EPOCH 193/500:
	Training over batches...
		[batch 5/5] avg loss: 2.620890119811892		[learning rate: 0.0042358]
	Learning Rate: 0.00423583
	LOSS [training: 2.620890119811892 | validation: 2.86027430692062]
	TIME [epoch: 10.5 sec]
EPOCH 194/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6463866598036154		[learning rate: 0.004216]
	Learning Rate: 0.00421597
	LOSS [training: 2.6463866598036154 | validation: 2.735121541956263]
	TIME [epoch: 10.5 sec]
EPOCH 195/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5605028573114645		[learning rate: 0.0041962]
	Learning Rate: 0.00419621
	LOSS [training: 2.5605028573114645 | validation: 2.7142845560478315]
	TIME [epoch: 10.5 sec]
EPOCH 196/500:
	Training over batches...
		[batch 5/5] avg loss: 2.546016351620385		[learning rate: 0.0041765]
	Learning Rate: 0.00417654
	LOSS [training: 2.546016351620385 | validation: 2.8288849568496572]
	TIME [epoch: 10.5 sec]
EPOCH 197/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7141609410795056		[learning rate: 0.004157]
	Learning Rate: 0.00415696
	LOSS [training: 2.7141609410795056 | validation: 2.8301729382065295]
	TIME [epoch: 10.5 sec]
EPOCH 198/500:
	Training over batches...
		[batch 5/5] avg loss: 2.590732538685947		[learning rate: 0.0041375]
	Learning Rate: 0.00413747
	LOSS [training: 2.590732538685947 | validation: 2.6999946549685037]
	TIME [epoch: 10.5 sec]
EPOCH 199/500:
	Training over batches...
		[batch 5/5] avg loss: 2.613960270367266		[learning rate: 0.0041181]
	Learning Rate: 0.00411807
	LOSS [training: 2.613960270367266 | validation: 2.7529818058052955]
	TIME [epoch: 10.5 sec]
EPOCH 200/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5754071929428215		[learning rate: 0.0040988]
	Learning Rate: 0.00409877
	LOSS [training: 2.5754071929428215 | validation: 2.669048877073686]
	TIME [epoch: 10.5 sec]
EPOCH 201/500:
	Training over batches...
		[batch 5/5] avg loss: 2.540777127713975		[learning rate: 0.0040795]
	Learning Rate: 0.00407955
	LOSS [training: 2.540777127713975 | validation: 2.6559236825237202]
	TIME [epoch: 10.5 sec]
EPOCH 202/500:
	Training over batches...
		[batch 5/5] avg loss: 2.480529364411202		[learning rate: 0.0040604]
	Learning Rate: 0.00406042
	LOSS [training: 2.480529364411202 | validation: 2.636541341984563]
	TIME [epoch: 10.5 sec]
EPOCH 203/500:
	Training over batches...
		[batch 5/5] avg loss: 2.467980853759417		[learning rate: 0.0040414]
	Learning Rate: 0.00404139
	LOSS [training: 2.467980853759417 | validation: 2.624764389620442]
	TIME [epoch: 10.5 sec]
EPOCH 204/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4480656266898992		[learning rate: 0.0040224]
	Learning Rate: 0.00402244
	LOSS [training: 2.4480656266898992 | validation: 2.6038432172086234]
	TIME [epoch: 10.5 sec]
EPOCH 205/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4775528761887005		[learning rate: 0.0040036]
	Learning Rate: 0.00400358
	LOSS [training: 2.4775528761887005 | validation: 2.7057905495251213]
	TIME [epoch: 10.5 sec]
EPOCH 206/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4739376655484486		[learning rate: 0.0039848]
	Learning Rate: 0.00398481
	LOSS [training: 2.4739376655484486 | validation: 2.6008973563873075]
	TIME [epoch: 10.5 sec]
EPOCH 207/500:
	Training over batches...
		[batch 5/5] avg loss: 2.39145244112473		[learning rate: 0.0039661]
	Learning Rate: 0.00396613
	LOSS [training: 2.39145244112473 | validation: 2.618569945371612]
	TIME [epoch: 10.5 sec]
EPOCH 208/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4250559453078657		[learning rate: 0.0039475]
	Learning Rate: 0.00394754
	LOSS [training: 2.4250559453078657 | validation: 2.588613830021076]
	TIME [epoch: 10.5 sec]
EPOCH 209/500:
	Training over batches...
		[batch 5/5] avg loss: 2.391111727579694		[learning rate: 0.003929]
	Learning Rate: 0.00392903
	LOSS [training: 2.391111727579694 | validation: 2.5859794608024296]
	TIME [epoch: 10.5 sec]
EPOCH 210/500:
	Training over batches...
		[batch 5/5] avg loss: 2.441946094725033		[learning rate: 0.0039106]
	Learning Rate: 0.00391061
	LOSS [training: 2.441946094725033 | validation: 2.5660310196501035]
	TIME [epoch: 10.5 sec]
EPOCH 211/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6263378482547686		[learning rate: 0.0038923]
	Learning Rate: 0.00389228
	LOSS [training: 2.6263378482547686 | validation: 2.6782385282956467]
	TIME [epoch: 10.5 sec]
EPOCH 212/500:
	Training over batches...
		[batch 5/5] avg loss: 2.435544446755916		[learning rate: 0.003874]
	Learning Rate: 0.00387403
	LOSS [training: 2.435544446755916 | validation: 2.623746760627638]
	TIME [epoch: 10.5 sec]
EPOCH 213/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4464743538767695		[learning rate: 0.0038559]
	Learning Rate: 0.00385587
	LOSS [training: 2.4464743538767695 | validation: 2.657873176421465]
	TIME [epoch: 11.2 sec]
EPOCH 214/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4326387786920134		[learning rate: 0.0038378]
	Learning Rate: 0.00383779
	LOSS [training: 2.4326387786920134 | validation: 2.6071940875552793]
	TIME [epoch: 10.5 sec]
EPOCH 215/500:
	Training over batches...
		[batch 5/5] avg loss: 2.594349955993547		[learning rate: 0.0038198]
	Learning Rate: 0.0038198
	LOSS [training: 2.594349955993547 | validation: 2.5826675556834524]
	TIME [epoch: 10.5 sec]
EPOCH 216/500:
	Training over batches...
		[batch 5/5] avg loss: 2.412577338914801		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 2.412577338914801 | validation: 2.5686394329918096]
	TIME [epoch: 10.5 sec]
EPOCH 217/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5064058246859338		[learning rate: 0.0037841]
	Learning Rate: 0.00378407
	LOSS [training: 2.5064058246859338 | validation: 2.707942322009801]
	TIME [epoch: 10.5 sec]
EPOCH 218/500:
	Training over batches...
		[batch 5/5] avg loss: 2.434070314916222		[learning rate: 0.0037663]
	Learning Rate: 0.00376633
	LOSS [training: 2.434070314916222 | validation: 2.596980379545937]
	TIME [epoch: 10.5 sec]
EPOCH 219/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4066452774237184		[learning rate: 0.0037487]
	Learning Rate: 0.00374867
	LOSS [training: 2.4066452774237184 | validation: 2.584711523856179]
	TIME [epoch: 10.5 sec]
EPOCH 220/500:
	Training over batches...
		[batch 5/5] avg loss: 2.422421731744653		[learning rate: 0.0037311]
	Learning Rate: 0.0037311
	LOSS [training: 2.422421731744653 | validation: 2.5789781185145593]
	TIME [epoch: 10.5 sec]
EPOCH 221/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4636787381864127		[learning rate: 0.0037136]
	Learning Rate: 0.00371361
	LOSS [training: 2.4636787381864127 | validation: 2.7042751836414625]
	TIME [epoch: 10.5 sec]
EPOCH 222/500:
	Training over batches...
		[batch 5/5] avg loss: 2.448274260563509		[learning rate: 0.0036962]
	Learning Rate: 0.0036962
	LOSS [training: 2.448274260563509 | validation: 2.6694356671952857]
	TIME [epoch: 10.5 sec]
EPOCH 223/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4644449557853942		[learning rate: 0.0036789]
	Learning Rate: 0.00367887
	LOSS [training: 2.4644449557853942 | validation: 2.61404401197]
	TIME [epoch: 10.5 sec]
EPOCH 224/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4708908495284487		[learning rate: 0.0036616]
	Learning Rate: 0.00366162
	LOSS [training: 2.4708908495284487 | validation: 2.9860671774497614]
	TIME [epoch: 10.5 sec]
EPOCH 225/500:
	Training over batches...
		[batch 5/5] avg loss: 2.70780471357381		[learning rate: 0.0036445]
	Learning Rate: 0.00364446
	LOSS [training: 2.70780471357381 | validation: 2.7919662950391886]
	TIME [epoch: 10.5 sec]
EPOCH 226/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5560357258967152		[learning rate: 0.0036274]
	Learning Rate: 0.00362737
	LOSS [training: 2.5560357258967152 | validation: 2.621405891474519]
	TIME [epoch: 10.5 sec]
EPOCH 227/500:
	Training over batches...
		[batch 5/5] avg loss: 2.420935084871304		[learning rate: 0.0036104]
	Learning Rate: 0.00361036
	LOSS [training: 2.420935084871304 | validation: 2.576758374723347]
	TIME [epoch: 10.5 sec]
EPOCH 228/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4165922938746864		[learning rate: 0.0035934]
	Learning Rate: 0.00359344
	LOSS [training: 2.4165922938746864 | validation: 2.59481097108488]
	TIME [epoch: 10.5 sec]
EPOCH 229/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4716806195471563		[learning rate: 0.0035766]
	Learning Rate: 0.00357659
	LOSS [training: 2.4716806195471563 | validation: 2.631577673854358]
	TIME [epoch: 10.5 sec]
EPOCH 230/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4269118180057543		[learning rate: 0.0035598]
	Learning Rate: 0.00355982
	LOSS [training: 2.4269118180057543 | validation: 2.9286826595993127]
	TIME [epoch: 10.5 sec]
EPOCH 231/500:
	Training over batches...
		[batch 5/5] avg loss: 2.677593956067144		[learning rate: 0.0035431]
	Learning Rate: 0.00354314
	LOSS [training: 2.677593956067144 | validation: 2.7497679243595887]
	TIME [epoch: 10.5 sec]
EPOCH 232/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5005038766943124		[learning rate: 0.0035265]
	Learning Rate: 0.00352652
	LOSS [training: 2.5005038766943124 | validation: 2.724480877343977]
	TIME [epoch: 10.5 sec]
EPOCH 233/500:
	Training over batches...
		[batch 5/5] avg loss: 2.704479613233377		[learning rate: 0.00351]
	Learning Rate: 0.00350999
	LOSS [training: 2.704479613233377 | validation: 3.0155198139519106]
	TIME [epoch: 10.5 sec]
EPOCH 234/500:
	Training over batches...
		[batch 5/5] avg loss: 2.600443804882773		[learning rate: 0.0034935]
	Learning Rate: 0.00349354
	LOSS [training: 2.600443804882773 | validation: 2.6589412350549675]
	TIME [epoch: 10.5 sec]
EPOCH 235/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4410565883754045		[learning rate: 0.0034772]
	Learning Rate: 0.00347716
	LOSS [training: 2.4410565883754045 | validation: 2.6365176730635516]
	TIME [epoch: 10.5 sec]
EPOCH 236/500:
	Training over batches...
		[batch 5/5] avg loss: 2.448562769011798		[learning rate: 0.0034609]
	Learning Rate: 0.00346086
	LOSS [training: 2.448562769011798 | validation: 2.6374669474737344]
	TIME [epoch: 10.5 sec]
EPOCH 237/500:
	Training over batches...
		[batch 5/5] avg loss: 2.472366590934281		[learning rate: 0.0034446]
	Learning Rate: 0.00344463
	LOSS [training: 2.472366590934281 | validation: 2.6738777903333273]
	TIME [epoch: 10.5 sec]
EPOCH 238/500:
	Training over batches...
		[batch 5/5] avg loss: 2.626688208197575		[learning rate: 0.0034285]
	Learning Rate: 0.00342848
	LOSS [training: 2.626688208197575 | validation: 2.6694970635550797]
	TIME [epoch: 10.5 sec]
EPOCH 239/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4448339601784106		[learning rate: 0.0034124]
	Learning Rate: 0.00341241
	LOSS [training: 2.4448339601784106 | validation: 2.5833338374322654]
	TIME [epoch: 10.5 sec]
EPOCH 240/500:
	Training over batches...
		[batch 5/5] avg loss: 2.560580960480377		[learning rate: 0.0033964]
	Learning Rate: 0.00339641
	LOSS [training: 2.560580960480377 | validation: 3.093651647005633]
	TIME [epoch: 10.5 sec]
EPOCH 241/500:
	Training over batches...
		[batch 5/5] avg loss: 2.598243018504717		[learning rate: 0.0033805]
	Learning Rate: 0.00338049
	LOSS [training: 2.598243018504717 | validation: 2.6379224322243777]
	TIME [epoch: 10.5 sec]
EPOCH 242/500:
	Training over batches...
		[batch 5/5] avg loss: 2.399835382366949		[learning rate: 0.0033646]
	Learning Rate: 0.00336464
	LOSS [training: 2.399835382366949 | validation: 2.6036050202662055]
	TIME [epoch: 10.5 sec]
EPOCH 243/500:
	Training over batches...
		[batch 5/5] avg loss: 2.416685110634122		[learning rate: 0.0033489]
	Learning Rate: 0.00334887
	LOSS [training: 2.416685110634122 | validation: 2.539036116793816]
	TIME [epoch: 10.5 sec]
EPOCH 244/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5282000847891237		[learning rate: 0.0033332]
	Learning Rate: 0.00333317
	LOSS [training: 2.5282000847891237 | validation: 2.7183090310934017]
	TIME [epoch: 10.5 sec]
EPOCH 245/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4302217770164036		[learning rate: 0.0033175]
	Learning Rate: 0.00331754
	LOSS [training: 2.4302217770164036 | validation: 2.6122758365964343]
	TIME [epoch: 10.5 sec]
EPOCH 246/500:
	Training over batches...
		[batch 5/5] avg loss: 2.536235506356564		[learning rate: 0.003302]
	Learning Rate: 0.00330199
	LOSS [training: 2.536235506356564 | validation: 2.6676825578982744]
	TIME [epoch: 10.5 sec]
EPOCH 247/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4522994235323585		[learning rate: 0.0032865]
	Learning Rate: 0.00328651
	LOSS [training: 2.4522994235323585 | validation: 2.6660484344083093]
	TIME [epoch: 10.6 sec]
EPOCH 248/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4463352635121303		[learning rate: 0.0032711]
	Learning Rate: 0.0032711
	LOSS [training: 2.4463352635121303 | validation: 2.6000448667981435]
	TIME [epoch: 10.5 sec]
EPOCH 249/500:
	Training over batches...
		[batch 5/5] avg loss: 2.420148120760179		[learning rate: 0.0032558]
	Learning Rate: 0.00325576
	LOSS [training: 2.420148120760179 | validation: 2.6478109650243926]
	TIME [epoch: 10.5 sec]
EPOCH 250/500:
	Training over batches...
		[batch 5/5] avg loss: 2.489399429190204		[learning rate: 0.0032405]
	Learning Rate: 0.0032405
	LOSS [training: 2.489399429190204 | validation: 2.5956646040845537]
	TIME [epoch: 10.5 sec]
EPOCH 251/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4193567092906783		[learning rate: 0.0032253]
	Learning Rate: 0.00322531
	LOSS [training: 2.4193567092906783 | validation: 2.595225833478911]
	TIME [epoch: 10.5 sec]
EPOCH 252/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4633859360094426		[learning rate: 0.0032102]
	Learning Rate: 0.00321019
	LOSS [training: 2.4633859360094426 | validation: 3.0314012274650257]
	TIME [epoch: 10.5 sec]
EPOCH 253/500:
	Training over batches...
		[batch 5/5] avg loss: 2.684712430592114		[learning rate: 0.0031951]
	Learning Rate: 0.00319514
	LOSS [training: 2.684712430592114 | validation: 2.5926191649259454]
	TIME [epoch: 10.5 sec]
EPOCH 254/500:
	Training over batches...
		[batch 5/5] avg loss: 2.408564243142587		[learning rate: 0.0031802]
	Learning Rate: 0.00318016
	LOSS [training: 2.408564243142587 | validation: 2.576869957752373]
	TIME [epoch: 10.5 sec]
EPOCH 255/500:
	Training over batches...
		[batch 5/5] avg loss: 2.437036840451415		[learning rate: 0.0031653]
	Learning Rate: 0.00316525
	LOSS [training: 2.437036840451415 | validation: 2.5932011086884326]
	TIME [epoch: 10.5 sec]
EPOCH 256/500:
	Training over batches...
		[batch 5/5] avg loss: 2.428971072349365		[learning rate: 0.0031504]
	Learning Rate: 0.00315041
	LOSS [training: 2.428971072349365 | validation: 2.658705046398334]
	TIME [epoch: 10.5 sec]
EPOCH 257/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4374222686007863		[learning rate: 0.0031356]
	Learning Rate: 0.00313564
	LOSS [training: 2.4374222686007863 | validation: 2.6301284565963865]
	TIME [epoch: 10.5 sec]
EPOCH 258/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4698711481245015		[learning rate: 0.0031209]
	Learning Rate: 0.00312094
	LOSS [training: 2.4698711481245015 | validation: 2.642951836953923]
	TIME [epoch: 10.5 sec]
EPOCH 259/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4804082329415116		[learning rate: 0.0031063]
	Learning Rate: 0.00310631
	LOSS [training: 2.4804082329415116 | validation: 2.6777384872962857]
	TIME [epoch: 10.5 sec]
EPOCH 260/500:
	Training over batches...
		[batch 5/5] avg loss: 2.508991678125107		[learning rate: 0.0030917]
	Learning Rate: 0.00309175
	LOSS [training: 2.508991678125107 | validation: 2.665867723028533]
	TIME [epoch: 10.5 sec]
EPOCH 261/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4196302049152636		[learning rate: 0.0030773]
	Learning Rate: 0.00307725
	LOSS [training: 2.4196302049152636 | validation: 2.6449127105683155]
	TIME [epoch: 10.5 sec]
EPOCH 262/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4259579636097035		[learning rate: 0.0030628]
	Learning Rate: 0.00306283
	LOSS [training: 2.4259579636097035 | validation: 2.5956287099040036]
	TIME [epoch: 10.5 sec]
EPOCH 263/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4094551514314064		[learning rate: 0.0030485]
	Learning Rate: 0.00304847
	LOSS [training: 2.4094551514314064 | validation: 2.5850793243108856]
	TIME [epoch: 10.5 sec]
EPOCH 264/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4405545291500923		[learning rate: 0.0030342]
	Learning Rate: 0.00303418
	LOSS [training: 2.4405545291500923 | validation: 2.748831068447801]
	TIME [epoch: 10.5 sec]
EPOCH 265/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6487807709839		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 2.6487807709839 | validation: 2.617431739145709]
	TIME [epoch: 10.5 sec]
EPOCH 266/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4227342619878405		[learning rate: 0.0030058]
	Learning Rate: 0.00300579
	LOSS [training: 2.4227342619878405 | validation: 2.5701525862161687]
	TIME [epoch: 10.5 sec]
EPOCH 267/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3924362933185477		[learning rate: 0.0029917]
	Learning Rate: 0.0029917
	LOSS [training: 2.3924362933185477 | validation: 2.5791701708040184]
	TIME [epoch: 10.5 sec]
EPOCH 268/500:
	Training over batches...
		[batch 5/5] avg loss: 2.600487347136601		[learning rate: 0.0029777]
	Learning Rate: 0.00297768
	LOSS [training: 2.600487347136601 | validation: 2.6799047863924694]
	TIME [epoch: 10.5 sec]
EPOCH 269/500:
	Training over batches...
		[batch 5/5] avg loss: 2.542732991141851		[learning rate: 0.0029637]
	Learning Rate: 0.00296372
	LOSS [training: 2.542732991141851 | validation: 2.602982990141027]
	TIME [epoch: 10.5 sec]
EPOCH 270/500:
	Training over batches...
		[batch 5/5] avg loss: 2.395466378711243		[learning rate: 0.0029498]
	Learning Rate: 0.00294982
	LOSS [training: 2.395466378711243 | validation: 2.5833398711771567]
	TIME [epoch: 10.5 sec]
EPOCH 271/500:
	Training over batches...
		[batch 5/5] avg loss: 2.398829722933643		[learning rate: 0.002936]
	Learning Rate: 0.00293599
	LOSS [training: 2.398829722933643 | validation: 2.57879599012704]
	TIME [epoch: 10.5 sec]
EPOCH 272/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4119902096074544		[learning rate: 0.0029222]
	Learning Rate: 0.00292223
	LOSS [training: 2.4119902096074544 | validation: 2.560629258478347]
	TIME [epoch: 10.5 sec]
EPOCH 273/500:
	Training over batches...
		[batch 5/5] avg loss: 2.373930191486534		[learning rate: 0.0029085]
	Learning Rate: 0.00290853
	LOSS [training: 2.373930191486534 | validation: 2.5563290439104995]
	TIME [epoch: 10.5 sec]
EPOCH 274/500:
	Training over batches...
		[batch 5/5] avg loss: 2.38795127225655		[learning rate: 0.0028949]
	Learning Rate: 0.00289489
	LOSS [training: 2.38795127225655 | validation: 2.5783297816709525]
	TIME [epoch: 10.5 sec]
EPOCH 275/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3768267552047098		[learning rate: 0.0028813]
	Learning Rate: 0.00288132
	LOSS [training: 2.3768267552047098 | validation: 2.5515843583348197]
	TIME [epoch: 10.5 sec]
EPOCH 276/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4015499282155837		[learning rate: 0.0028678]
	Learning Rate: 0.00286781
	LOSS [training: 2.4015499282155837 | validation: 2.5903690524936867]
	TIME [epoch: 10.5 sec]
EPOCH 277/500:
	Training over batches...
		[batch 5/5] avg loss: 2.369996965474086		[learning rate: 0.0028544]
	Learning Rate: 0.00285437
	LOSS [training: 2.369996965474086 | validation: 2.631073255756943]
	TIME [epoch: 10.5 sec]
EPOCH 278/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3974263594565244		[learning rate: 0.002841]
	Learning Rate: 0.00284099
	LOSS [training: 2.3974263594565244 | validation: 2.575252665362397]
	TIME [epoch: 10.5 sec]
EPOCH 279/500:
	Training over batches...
		[batch 5/5] avg loss: 2.373469789581705		[learning rate: 0.0028277]
	Learning Rate: 0.00282767
	LOSS [training: 2.373469789581705 | validation: 2.594632354580115]
	TIME [epoch: 10.5 sec]
EPOCH 280/500:
	Training over batches...
		[batch 5/5] avg loss: 2.361068259364142		[learning rate: 0.0028144]
	Learning Rate: 0.00281441
	LOSS [training: 2.361068259364142 | validation: 2.7267977686010285]
	TIME [epoch: 10.5 sec]
EPOCH 281/500:
	Training over batches...
		[batch 5/5] avg loss: 2.53846477768905		[learning rate: 0.0028012]
	Learning Rate: 0.00280122
	LOSS [training: 2.53846477768905 | validation: 2.5835204138063426]
	TIME [epoch: 10.5 sec]
EPOCH 282/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4502832740422673		[learning rate: 0.0027881]
	Learning Rate: 0.00278809
	LOSS [training: 2.4502832740422673 | validation: 2.8595643628071126]
	TIME [epoch: 10.5 sec]
EPOCH 283/500:
	Training over batches...
		[batch 5/5] avg loss: 2.584561608442499		[learning rate: 0.002775]
	Learning Rate: 0.00277501
	LOSS [training: 2.584561608442499 | validation: 2.575548093840573]
	TIME [epoch: 10.5 sec]
EPOCH 284/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3626355781388315		[learning rate: 0.002762]
	Learning Rate: 0.002762
	LOSS [training: 2.3626355781388315 | validation: 2.5916253092815045]
	TIME [epoch: 10.5 sec]
EPOCH 285/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3938308258338887		[learning rate: 0.0027491]
	Learning Rate: 0.00274906
	LOSS [training: 2.3938308258338887 | validation: 2.6994290132322725]
	TIME [epoch: 10.5 sec]
EPOCH 286/500:
	Training over batches...
		[batch 5/5] avg loss: 2.438206265528425		[learning rate: 0.0027362]
	Learning Rate: 0.00273617
	LOSS [training: 2.438206265528425 | validation: 2.5830758640623435]
	TIME [epoch: 10.5 sec]
EPOCH 287/500:
	Training over batches...
		[batch 5/5] avg loss: 2.352723919690838		[learning rate: 0.0027233]
	Learning Rate: 0.00272334
	LOSS [training: 2.352723919690838 | validation: 2.5395559610260263]
	TIME [epoch: 10.5 sec]
EPOCH 288/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4051134328043458		[learning rate: 0.0027106]
	Learning Rate: 0.00271057
	LOSS [training: 2.4051134328043458 | validation: 2.5764178186557745]
	TIME [epoch: 10.5 sec]
EPOCH 289/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3659112110515914		[learning rate: 0.0026979]
	Learning Rate: 0.00269787
	LOSS [training: 2.3659112110515914 | validation: 2.575951567180277]
	TIME [epoch: 10.5 sec]
EPOCH 290/500:
	Training over batches...
		[batch 5/5] avg loss: 2.347192597468458		[learning rate: 0.0026852]
	Learning Rate: 0.00268522
	LOSS [training: 2.347192597468458 | validation: 2.561379019264024]
	TIME [epoch: 10.5 sec]
EPOCH 291/500:
	Training over batches...
		[batch 5/5] avg loss: 2.421414498569896		[learning rate: 0.0026726]
	Learning Rate: 0.00267263
	LOSS [training: 2.421414498569896 | validation: 2.5839873103586566]
	TIME [epoch: 10.5 sec]
EPOCH 292/500:
	Training over batches...
		[batch 5/5] avg loss: 2.362980683301964		[learning rate: 0.0026601]
	Learning Rate: 0.0026601
	LOSS [training: 2.362980683301964 | validation: 2.536059388213423]
	TIME [epoch: 10.5 sec]
EPOCH 293/500:
	Training over batches...
		[batch 5/5] avg loss: 2.368951724379115		[learning rate: 0.0026476]
	Learning Rate: 0.00264763
	LOSS [training: 2.368951724379115 | validation: 2.5839513682534108]
	TIME [epoch: 10.5 sec]
EPOCH 294/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3908930461369287		[learning rate: 0.0026352]
	Learning Rate: 0.00263522
	LOSS [training: 2.3908930461369287 | validation: 2.5338417871402217]
	TIME [epoch: 10.5 sec]
EPOCH 295/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3518406455662486		[learning rate: 0.0026229]
	Learning Rate: 0.00262286
	LOSS [training: 2.3518406455662486 | validation: 2.5432761394559846]
	TIME [epoch: 10.5 sec]
EPOCH 296/500:
	Training over batches...
		[batch 5/5] avg loss: 2.533608755727813		[learning rate: 0.0026106]
	Learning Rate: 0.00261057
	LOSS [training: 2.533608755727813 | validation: 2.5927357941646854]
	TIME [epoch: 10.5 sec]
EPOCH 297/500:
	Training over batches...
		[batch 5/5] avg loss: 2.454495429555447		[learning rate: 0.0025983]
	Learning Rate: 0.00259833
	LOSS [training: 2.454495429555447 | validation: 3.018062709292323]
	TIME [epoch: 10.5 sec]
EPOCH 298/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7672345206786253		[learning rate: 0.0025861]
	Learning Rate: 0.00258615
	LOSS [training: 2.7672345206786253 | validation: 2.7159983541873545]
	TIME [epoch: 10.5 sec]
EPOCH 299/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5835004289797245		[learning rate: 0.002574]
	Learning Rate: 0.00257402
	LOSS [training: 2.5835004289797245 | validation: 2.867314247574235]
	TIME [epoch: 10.5 sec]
EPOCH 300/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5432615637770803		[learning rate: 0.002562]
	Learning Rate: 0.00256195
	LOSS [training: 2.5432615637770803 | validation: 2.73906777616682]
	TIME [epoch: 10.5 sec]
EPOCH 301/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5435820530825586		[learning rate: 0.0025499]
	Learning Rate: 0.00254994
	LOSS [training: 2.5435820530825586 | validation: 2.665675658119336]
	TIME [epoch: 10.5 sec]
EPOCH 302/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5183014961030605		[learning rate: 0.002538]
	Learning Rate: 0.00253799
	LOSS [training: 2.5183014961030605 | validation: 2.6984382196216212]
	TIME [epoch: 10.5 sec]
EPOCH 303/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5012717104426656		[learning rate: 0.0025261]
	Learning Rate: 0.00252609
	LOSS [training: 2.5012717104426656 | validation: 2.6731727734965682]
	TIME [epoch: 10.5 sec]
EPOCH 304/500:
	Training over batches...
		[batch 5/5] avg loss: 2.48723715685042		[learning rate: 0.0025142]
	Learning Rate: 0.00251425
	LOSS [training: 2.48723715685042 | validation: 2.6618931515600277]
	TIME [epoch: 10.5 sec]
EPOCH 305/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5106995986316796		[learning rate: 0.0025025]
	Learning Rate: 0.00250246
	LOSS [training: 2.5106995986316796 | validation: 2.891219108930513]
	TIME [epoch: 10.5 sec]
EPOCH 306/500:
	Training over batches...
		[batch 5/5] avg loss: 3.372382915592398		[learning rate: 0.0024907]
	Learning Rate: 0.00249073
	LOSS [training: 3.372382915592398 | validation: 2.775502916503473]
	TIME [epoch: 10.5 sec]
EPOCH 307/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6310275468352797		[learning rate: 0.0024791]
	Learning Rate: 0.00247905
	LOSS [training: 2.6310275468352797 | validation: 2.7206256139579277]
	TIME [epoch: 10.5 sec]
EPOCH 308/500:
	Training over batches...
		[batch 5/5] avg loss: 2.537414729120878		[learning rate: 0.0024674]
	Learning Rate: 0.00246743
	LOSS [training: 2.537414729120878 | validation: 2.7630910144086114]
	TIME [epoch: 10.5 sec]
EPOCH 309/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4906970619457196		[learning rate: 0.0024559]
	Learning Rate: 0.00245586
	LOSS [training: 2.4906970619457196 | validation: 2.7585992445031535]
	TIME [epoch: 10.5 sec]
EPOCH 310/500:
	Training over batches...
		[batch 5/5] avg loss: 2.511237477252729		[learning rate: 0.0024443]
	Learning Rate: 0.00244435
	LOSS [training: 2.511237477252729 | validation: 2.675053199776398]
	TIME [epoch: 10.5 sec]
EPOCH 311/500:
	Training over batches...
		[batch 5/5] avg loss: 2.592790565479308		[learning rate: 0.0024329]
	Learning Rate: 0.00243289
	LOSS [training: 2.592790565479308 | validation: 2.8928488725328374]
	TIME [epoch: 10.5 sec]
EPOCH 312/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7338762668677408		[learning rate: 0.0024215]
	Learning Rate: 0.00242148
	LOSS [training: 2.7338762668677408 | validation: 2.6768006652164904]
	TIME [epoch: 10.5 sec]
EPOCH 313/500:
	Training over batches...
		[batch 5/5] avg loss: 2.574079594835982		[learning rate: 0.0024101]
	Learning Rate: 0.00241013
	LOSS [training: 2.574079594835982 | validation: 2.660714018217184]
	TIME [epoch: 10.5 sec]
EPOCH 314/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5006867138448383		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 2.5006867138448383 | validation: 2.9704253741123696]
	TIME [epoch: 10.5 sec]
EPOCH 315/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7642096466224344		[learning rate: 0.0023876]
	Learning Rate: 0.00238759
	LOSS [training: 2.7642096466224344 | validation: 2.7089381886944612]
	TIME [epoch: 10.5 sec]
EPOCH 316/500:
	Training over batches...
		[batch 5/5] avg loss: 2.502321061366935		[learning rate: 0.0023764]
	Learning Rate: 0.00237639
	LOSS [training: 2.502321061366935 | validation: 2.7662019991072855]
	TIME [epoch: 10.5 sec]
EPOCH 317/500:
	Training over batches...
		[batch 5/5] avg loss: 2.4730732445524697		[learning rate: 0.0023653]
	Learning Rate: 0.00236525
	LOSS [training: 2.4730732445524697 | validation: 2.6803130090042173]
	TIME [epoch: 10.5 sec]
EPOCH 318/500:
	Training over batches...
		[batch 5/5] avg loss: 2.465214614304975		[learning rate: 0.0023542]
	Learning Rate: 0.00235416
	LOSS [training: 2.465214614304975 | validation: 2.5396354395917706]
	TIME [epoch: 10.5 sec]
EPOCH 319/500:
	Training over batches...
		[batch 5/5] avg loss: 2.2061854264914658		[learning rate: 0.0023431]
	Learning Rate: 0.00234313
	LOSS [training: 2.2061854264914658 | validation: 2.0667798026325075]
	TIME [epoch: 10.5 sec]
EPOCH 320/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8346431846277245		[learning rate: 0.0023321]
	Learning Rate: 0.00233214
	LOSS [training: 1.8346431846277245 | validation: 1.7985434424340991]
	TIME [epoch: 10.5 sec]
EPOCH 321/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3735672738467208		[learning rate: 0.0023212]
	Learning Rate: 0.00232121
	LOSS [training: 1.3735672738467208 | validation: 1.0122539064020528]
	TIME [epoch: 10.5 sec]
EPOCH 322/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8247345409335984		[learning rate: 0.0023103]
	Learning Rate: 0.00231033
	LOSS [training: 0.8247345409335984 | validation: 0.6753218785188034]
	TIME [epoch: 10.5 sec]
EPOCH 323/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6233957389005729		[learning rate: 0.0022995]
	Learning Rate: 0.0022995
	LOSS [training: 0.6233957389005729 | validation: 1.2487423817098662]
	TIME [epoch: 10.5 sec]
EPOCH 324/500:
	Training over batches...
		[batch 5/5] avg loss: 1.009819243614754		[learning rate: 0.0022887]
	Learning Rate: 0.00228872
	LOSS [training: 1.009819243614754 | validation: 0.7370397462792042]
	TIME [epoch: 10.5 sec]
EPOCH 325/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8268668722568686		[learning rate: 0.002278]
	Learning Rate: 0.00227799
	LOSS [training: 0.8268668722568686 | validation: 0.6259928931593456]
	TIME [epoch: 10.5 sec]
EPOCH 326/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7394939344885583		[learning rate: 0.0022673]
	Learning Rate: 0.00226731
	LOSS [training: 0.7394939344885583 | validation: 0.5882224638113214]
	TIME [epoch: 10.5 sec]
EPOCH 327/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5657482787414767		[learning rate: 0.0022567]
	Learning Rate: 0.00225668
	LOSS [training: 0.5657482787414767 | validation: 0.7327454871695666]
	TIME [epoch: 10.5 sec]
EPOCH 328/500:
	Training over batches...
		[batch 5/5] avg loss: 0.692860911813302		[learning rate: 0.0022461]
	Learning Rate: 0.0022461
	LOSS [training: 0.692860911813302 | validation: 0.7686975069609026]
	TIME [epoch: 10.5 sec]
EPOCH 329/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7755498915298877		[learning rate: 0.0022356]
	Learning Rate: 0.00223557
	LOSS [training: 0.7755498915298877 | validation: 0.5844479879481382]
	TIME [epoch: 10.5 sec]
EPOCH 330/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5789461380304728		[learning rate: 0.0022251]
	Learning Rate: 0.00222509
	LOSS [training: 0.5789461380304728 | validation: 0.5222438611275732]
	TIME [epoch: 10.5 sec]
EPOCH 331/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6518432383662836		[learning rate: 0.0022147]
	Learning Rate: 0.00221466
	LOSS [training: 0.6518432383662836 | validation: 0.7014894256055542]
	TIME [epoch: 10.5 sec]
EPOCH 332/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5306831203418666		[learning rate: 0.0022043]
	Learning Rate: 0.00220427
	LOSS [training: 0.5306831203418666 | validation: 0.4840762561005986]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_332.pth
	Model improved!!!
EPOCH 333/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6505963167395793		[learning rate: 0.0021939]
	Learning Rate: 0.00219394
	LOSS [training: 0.6505963167395793 | validation: 0.6521461589608982]
	TIME [epoch: 10.5 sec]
EPOCH 334/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5831547972196045		[learning rate: 0.0021837]
	Learning Rate: 0.00218365
	LOSS [training: 0.5831547972196045 | validation: 0.5060634372539835]
	TIME [epoch: 10.5 sec]
EPOCH 335/500:
	Training over batches...
		[batch 5/5] avg loss: 0.670247231263514		[learning rate: 0.0021734]
	Learning Rate: 0.00217342
	LOSS [training: 0.670247231263514 | validation: 0.4389736097454872]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_335.pth
	Model improved!!!
EPOCH 336/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43020732734245115		[learning rate: 0.0021632]
	Learning Rate: 0.00216323
	LOSS [training: 0.43020732734245115 | validation: 0.4774711515067253]
	TIME [epoch: 10.5 sec]
EPOCH 337/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6221494372873806		[learning rate: 0.0021531]
	Learning Rate: 0.00215309
	LOSS [training: 0.6221494372873806 | validation: 0.7165886049601534]
	TIME [epoch: 10.5 sec]
EPOCH 338/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48721202671524927		[learning rate: 0.002143]
	Learning Rate: 0.00214299
	LOSS [training: 0.48721202671524927 | validation: 0.3652684577671038]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_338.pth
	Model improved!!!
EPOCH 339/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6324748170593274		[learning rate: 0.0021329]
	Learning Rate: 0.00213294
	LOSS [training: 0.6324748170593274 | validation: 0.45332159903366614]
	TIME [epoch: 10.5 sec]
EPOCH 340/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5113613301902619		[learning rate: 0.0021229]
	Learning Rate: 0.00212294
	LOSS [training: 0.5113613301902619 | validation: 0.4911616190586565]
	TIME [epoch: 10.5 sec]
EPOCH 341/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7224829672137243		[learning rate: 0.002113]
	Learning Rate: 0.00211299
	LOSS [training: 0.7224829672137243 | validation: 0.4987776017623594]
	TIME [epoch: 10.5 sec]
EPOCH 342/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6380968639297646		[learning rate: 0.0021031]
	Learning Rate: 0.00210309
	LOSS [training: 0.6380968639297646 | validation: 0.7744949390915901]
	TIME [epoch: 10.5 sec]
EPOCH 343/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6673349453962838		[learning rate: 0.0020932]
	Learning Rate: 0.00209323
	LOSS [training: 0.6673349453962838 | validation: 0.45817334160322143]
	TIME [epoch: 10.5 sec]
EPOCH 344/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4351631813419415		[learning rate: 0.0020834]
	Learning Rate: 0.00208341
	LOSS [training: 0.4351631813419415 | validation: 0.37983427867661884]
	TIME [epoch: 10.5 sec]
EPOCH 345/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5720210968346511		[learning rate: 0.0020736]
	Learning Rate: 0.00207365
	LOSS [training: 0.5720210968346511 | validation: 2.101024638160262]
	TIME [epoch: 10.5 sec]
EPOCH 346/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7945817471648094		[learning rate: 0.0020639]
	Learning Rate: 0.00206392
	LOSS [training: 0.7945817471648094 | validation: 0.4509733635857838]
	TIME [epoch: 10.5 sec]
EPOCH 347/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4733823929856881		[learning rate: 0.0020542]
	Learning Rate: 0.00205425
	LOSS [training: 0.4733823929856881 | validation: 0.6051688466340237]
	TIME [epoch: 10.5 sec]
EPOCH 348/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4806821625811075		[learning rate: 0.0020446]
	Learning Rate: 0.00204462
	LOSS [training: 0.4806821625811075 | validation: 0.3944694285259719]
	TIME [epoch: 10.5 sec]
EPOCH 349/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5493987473654672		[learning rate: 0.002035]
	Learning Rate: 0.00203503
	LOSS [training: 0.5493987473654672 | validation: 0.5926072332128794]
	TIME [epoch: 10.5 sec]
EPOCH 350/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5372855795494831		[learning rate: 0.0020255]
	Learning Rate: 0.00202549
	LOSS [training: 0.5372855795494831 | validation: 0.6052530094238663]
	TIME [epoch: 10.5 sec]
EPOCH 351/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5252062195148854		[learning rate: 0.002016]
	Learning Rate: 0.002016
	LOSS [training: 0.5252062195148854 | validation: 0.4702517713372912]
	TIME [epoch: 10.5 sec]
EPOCH 352/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46885476881118393		[learning rate: 0.0020065]
	Learning Rate: 0.00200655
	LOSS [training: 0.46885476881118393 | validation: 0.538956870798698]
	TIME [epoch: 10.5 sec]
EPOCH 353/500:
	Training over batches...
		[batch 5/5] avg loss: 0.607933680201103		[learning rate: 0.0019971]
	Learning Rate: 0.00199714
	LOSS [training: 0.607933680201103 | validation: 0.8900730304967938]
	TIME [epoch: 10.5 sec]
EPOCH 354/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6817282011967382		[learning rate: 0.0019878]
	Learning Rate: 0.00198778
	LOSS [training: 0.6817282011967382 | validation: 2.8701444035082377]
	TIME [epoch: 10.5 sec]
EPOCH 355/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3478207178660633		[learning rate: 0.0019785]
	Learning Rate: 0.00197846
	LOSS [training: 1.3478207178660633 | validation: 0.5277156675976646]
	TIME [epoch: 10.5 sec]
EPOCH 356/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5273048712340147		[learning rate: 0.0019692]
	Learning Rate: 0.00196918
	LOSS [training: 0.5273048712340147 | validation: 0.5155298286827292]
	TIME [epoch: 10.5 sec]
EPOCH 357/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5278845249955821		[learning rate: 0.0019599]
	Learning Rate: 0.00195995
	LOSS [training: 0.5278845249955821 | validation: 0.42560439636970243]
	TIME [epoch: 10.5 sec]
EPOCH 358/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4879380757117565		[learning rate: 0.0019508]
	Learning Rate: 0.00195076
	LOSS [training: 0.4879380757117565 | validation: 0.4525933483340161]
	TIME [epoch: 10.5 sec]
EPOCH 359/500:
	Training over batches...
		[batch 5/5] avg loss: 0.34210525075956344		[learning rate: 0.0019416]
	Learning Rate: 0.00194162
	LOSS [training: 0.34210525075956344 | validation: 0.40074606877064695]
	TIME [epoch: 10.5 sec]
EPOCH 360/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43856682298903954		[learning rate: 0.0019325]
	Learning Rate: 0.00193251
	LOSS [training: 0.43856682298903954 | validation: 0.34304831546999637]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_360.pth
	Model improved!!!
EPOCH 361/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4415658796322558		[learning rate: 0.0019235]
	Learning Rate: 0.00192345
	LOSS [training: 0.4415658796322558 | validation: 0.34890545193083405]
	TIME [epoch: 10.5 sec]
EPOCH 362/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3847576798902798		[learning rate: 0.0019144]
	Learning Rate: 0.00191444
	LOSS [training: 0.3847576798902798 | validation: 0.41507365832942184]
	TIME [epoch: 10.5 sec]
EPOCH 363/500:
	Training over batches...
		[batch 5/5] avg loss: 0.441927091633627		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.441927091633627 | validation: 0.3705561405366709]
	TIME [epoch: 10.5 sec]
EPOCH 364/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5072346656102846		[learning rate: 0.0018965]
	Learning Rate: 0.00189653
	LOSS [training: 0.5072346656102846 | validation: 0.43898840925927685]
	TIME [epoch: 10.5 sec]
EPOCH 365/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6830336783573913		[learning rate: 0.0018876]
	Learning Rate: 0.00188764
	LOSS [training: 0.6830336783573913 | validation: 0.49011880945869724]
	TIME [epoch: 10.5 sec]
EPOCH 366/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43672945434660815		[learning rate: 0.0018788]
	Learning Rate: 0.00187879
	LOSS [training: 0.43672945434660815 | validation: 0.39729928174652385]
	TIME [epoch: 10.5 sec]
EPOCH 367/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43720114327748016		[learning rate: 0.00187]
	Learning Rate: 0.00186998
	LOSS [training: 0.43720114327748016 | validation: 0.6463314598496214]
	TIME [epoch: 10.6 sec]
EPOCH 368/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3984018561857443		[learning rate: 0.0018612]
	Learning Rate: 0.00186121
	LOSS [training: 0.3984018561857443 | validation: 1.5565768617850504]
	TIME [epoch: 10.5 sec]
EPOCH 369/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1395358891051286		[learning rate: 0.0018525]
	Learning Rate: 0.00185249
	LOSS [training: 1.1395358891051286 | validation: 0.4784609388782039]
	TIME [epoch: 10.5 sec]
EPOCH 370/500:
	Training over batches...
		[batch 5/5] avg loss: 1.052635887852077		[learning rate: 0.0018438]
	Learning Rate: 0.0018438
	LOSS [training: 1.052635887852077 | validation: 0.563439460011431]
	TIME [epoch: 10.5 sec]
EPOCH 371/500:
	Training over batches...
		[batch 5/5] avg loss: 0.49502184040184377		[learning rate: 0.0018352]
	Learning Rate: 0.00183516
	LOSS [training: 0.49502184040184377 | validation: 0.5941047983684952]
	TIME [epoch: 10.5 sec]
EPOCH 372/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5151235587064666		[learning rate: 0.0018266]
	Learning Rate: 0.00182655
	LOSS [training: 0.5151235587064666 | validation: 0.38958964471777735]
	TIME [epoch: 10.5 sec]
EPOCH 373/500:
	Training over batches...
		[batch 5/5] avg loss: 0.37721926763978975		[learning rate: 0.001818]
	Learning Rate: 0.00181799
	LOSS [training: 0.37721926763978975 | validation: 0.36745452866091577]
	TIME [epoch: 10.5 sec]
EPOCH 374/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3794390804364324		[learning rate: 0.0018095]
	Learning Rate: 0.00180947
	LOSS [training: 0.3794390804364324 | validation: 0.3118720074351106]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_374.pth
	Model improved!!!
EPOCH 375/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6241468811136522		[learning rate: 0.001801]
	Learning Rate: 0.00180099
	LOSS [training: 0.6241468811136522 | validation: 0.2909089763588721]
	TIME [epoch: 10.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_375.pth
	Model improved!!!
EPOCH 376/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3248086147834888		[learning rate: 0.0017925]
	Learning Rate: 0.00179254
	LOSS [training: 0.3248086147834888 | validation: 0.2990271761613962]
	TIME [epoch: 10.5 sec]
EPOCH 377/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4792085456054105		[learning rate: 0.0017841]
	Learning Rate: 0.00178414
	LOSS [training: 0.4792085456054105 | validation: 1.0943695406500065]
	TIME [epoch: 10.5 sec]
EPOCH 378/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7376982030441094		[learning rate: 0.0017758]
	Learning Rate: 0.00177577
	LOSS [training: 0.7376982030441094 | validation: 0.4708591897714743]
	TIME [epoch: 10.5 sec]
EPOCH 379/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4631942247170427		[learning rate: 0.0017674]
	Learning Rate: 0.00176745
	LOSS [training: 0.4631942247170427 | validation: 0.2963364489266]
	TIME [epoch: 10.5 sec]
EPOCH 380/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3643306489524606		[learning rate: 0.0017592]
	Learning Rate: 0.00175916
	LOSS [training: 0.3643306489524606 | validation: 0.4462212309605104]
	TIME [epoch: 10.5 sec]
EPOCH 381/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4262841152997021		[learning rate: 0.0017509]
	Learning Rate: 0.00175092
	LOSS [training: 0.4262841152997021 | validation: 0.5429303331703763]
	TIME [epoch: 10.5 sec]
EPOCH 382/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47771359010083475		[learning rate: 0.0017427]
	Learning Rate: 0.00174271
	LOSS [training: 0.47771359010083475 | validation: 0.3746214568886269]
	TIME [epoch: 10.5 sec]
EPOCH 383/500:
	Training over batches...
		[batch 5/5] avg loss: 0.28205426401551886		[learning rate: 0.0017345]
	Learning Rate: 0.00173454
	LOSS [training: 0.28205426401551886 | validation: 0.2767441736434216]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_383.pth
	Model improved!!!
EPOCH 384/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46225482725678313		[learning rate: 0.0017264]
	Learning Rate: 0.00172641
	LOSS [training: 0.46225482725678313 | validation: 0.5304817505836082]
	TIME [epoch: 10.5 sec]
EPOCH 385/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46767562861776313		[learning rate: 0.0017183]
	Learning Rate: 0.00171831
	LOSS [training: 0.46767562861776313 | validation: 0.29144034456407136]
	TIME [epoch: 10.5 sec]
EPOCH 386/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2499084221952756		[learning rate: 0.0017103]
	Learning Rate: 0.00171026
	LOSS [training: 0.2499084221952756 | validation: 0.4010117635463831]
	TIME [epoch: 10.5 sec]
EPOCH 387/500:
	Training over batches...
		[batch 5/5] avg loss: 0.36461428460489553		[learning rate: 0.0017022]
	Learning Rate: 0.00170224
	LOSS [training: 0.36461428460489553 | validation: 0.41146885831029845]
	TIME [epoch: 10.5 sec]
EPOCH 388/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3738094646100346		[learning rate: 0.0016943]
	Learning Rate: 0.00169426
	LOSS [training: 0.3738094646100346 | validation: 0.4939893687293926]
	TIME [epoch: 10.5 sec]
EPOCH 389/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5369319476624149		[learning rate: 0.0016863]
	Learning Rate: 0.00168632
	LOSS [training: 0.5369319476624149 | validation: 0.4701817232474993]
	TIME [epoch: 10.5 sec]
EPOCH 390/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4262426686920917		[learning rate: 0.0016784]
	Learning Rate: 0.00167841
	LOSS [training: 0.4262426686920917 | validation: 0.39817814005050706]
	TIME [epoch: 10.5 sec]
EPOCH 391/500:
	Training over batches...
		[batch 5/5] avg loss: 0.34282704149252524		[learning rate: 0.0016705]
	Learning Rate: 0.00167054
	LOSS [training: 0.34282704149252524 | validation: 0.267428846530927]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_391.pth
	Model improved!!!
EPOCH 392/500:
	Training over batches...
		[batch 5/5] avg loss: 0.37913014927565186		[learning rate: 0.0016627]
	Learning Rate: 0.00166271
	LOSS [training: 0.37913014927565186 | validation: 0.5745007436039316]
	TIME [epoch: 10.5 sec]
EPOCH 393/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4162122189307391		[learning rate: 0.0016549]
	Learning Rate: 0.00165491
	LOSS [training: 0.4162122189307391 | validation: 0.24089520097258357]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_393.pth
	Model improved!!!
EPOCH 394/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0324753099053086		[learning rate: 0.0016472]
	Learning Rate: 0.00164716
	LOSS [training: 1.0324753099053086 | validation: 0.27629695755352013]
	TIME [epoch: 10.5 sec]
EPOCH 395/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4328015310253207		[learning rate: 0.0016394]
	Learning Rate: 0.00163943
	LOSS [training: 0.4328015310253207 | validation: 0.478149904746784]
	TIME [epoch: 10.5 sec]
EPOCH 396/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4693536493686164		[learning rate: 0.0016317]
	Learning Rate: 0.00163175
	LOSS [training: 0.4693536493686164 | validation: 0.43781589108079316]
	TIME [epoch: 10.5 sec]
EPOCH 397/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4244172929881188		[learning rate: 0.0016241]
	Learning Rate: 0.0016241
	LOSS [training: 0.4244172929881188 | validation: 0.41166119682302227]
	TIME [epoch: 10.6 sec]
EPOCH 398/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45093202449304554		[learning rate: 0.0016165]
	Learning Rate: 0.00161648
	LOSS [training: 0.45093202449304554 | validation: 0.4563260492514574]
	TIME [epoch: 10.5 sec]
EPOCH 399/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4415514124492887		[learning rate: 0.0016089]
	Learning Rate: 0.00160891
	LOSS [training: 0.4415514124492887 | validation: 0.3434242644771808]
	TIME [epoch: 10.5 sec]
EPOCH 400/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3554681311437872		[learning rate: 0.0016014]
	Learning Rate: 0.00160136
	LOSS [training: 0.3554681311437872 | validation: 1.2965131367297686]
	TIME [epoch: 10.5 sec]
EPOCH 401/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7697839041493186		[learning rate: 0.0015939]
	Learning Rate: 0.00159386
	LOSS [training: 0.7697839041493186 | validation: 0.36440649190943986]
	TIME [epoch: 10.5 sec]
EPOCH 402/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3483138784117764		[learning rate: 0.0015864]
	Learning Rate: 0.00158638
	LOSS [training: 0.3483138784117764 | validation: 0.8326161392863765]
	TIME [epoch: 10.5 sec]
EPOCH 403/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4573909425850434		[learning rate: 0.0015789]
	Learning Rate: 0.00157895
	LOSS [training: 0.4573909425850434 | validation: 0.502360204709637]
	TIME [epoch: 10.5 sec]
EPOCH 404/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4581117537447138		[learning rate: 0.0015715]
	Learning Rate: 0.00157154
	LOSS [training: 0.4581117537447138 | validation: 0.4738693275597203]
	TIME [epoch: 10.5 sec]
EPOCH 405/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4732827530287006		[learning rate: 0.0015642]
	Learning Rate: 0.00156418
	LOSS [training: 0.4732827530287006 | validation: 0.37251846708513825]
	TIME [epoch: 10.5 sec]
EPOCH 406/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5376272502552105		[learning rate: 0.0015568]
	Learning Rate: 0.00155684
	LOSS [training: 0.5376272502552105 | validation: 0.693672275085848]
	TIME [epoch: 10.5 sec]
EPOCH 407/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4815699532373984		[learning rate: 0.0015495]
	Learning Rate: 0.00154954
	LOSS [training: 0.4815699532373984 | validation: 0.47962735148316554]
	TIME [epoch: 10.5 sec]
EPOCH 408/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6076048475203224		[learning rate: 0.0015423]
	Learning Rate: 0.00154228
	LOSS [training: 0.6076048475203224 | validation: 0.44761033271603445]
	TIME [epoch: 10.5 sec]
EPOCH 409/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46582782817574825		[learning rate: 0.001535]
	Learning Rate: 0.00153505
	LOSS [training: 0.46582782817574825 | validation: 0.5442278545959747]
	TIME [epoch: 10.6 sec]
EPOCH 410/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5062233616503649		[learning rate: 0.0015279]
	Learning Rate: 0.00152785
	LOSS [training: 0.5062233616503649 | validation: 0.40881976949896753]
	TIME [epoch: 10.5 sec]
EPOCH 411/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43084314143285213		[learning rate: 0.0015207]
	Learning Rate: 0.00152069
	LOSS [training: 0.43084314143285213 | validation: 0.4051309337001123]
	TIME [epoch: 10.5 sec]
EPOCH 412/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4518362113771618		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.4518362113771618 | validation: 0.48203618221146327]
	TIME [epoch: 10.5 sec]
EPOCH 413/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4630403152402941		[learning rate: 0.0015065]
	Learning Rate: 0.00150647
	LOSS [training: 0.4630403152402941 | validation: 0.46676304716787065]
	TIME [epoch: 10.5 sec]
EPOCH 414/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5137866340860512		[learning rate: 0.0014994]
	Learning Rate: 0.0014994
	LOSS [training: 0.5137866340860512 | validation: 0.446718089518764]
	TIME [epoch: 10.5 sec]
EPOCH 415/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48339885396650467		[learning rate: 0.0014924]
	Learning Rate: 0.00149237
	LOSS [training: 0.48339885396650467 | validation: 0.4155647291071368]
	TIME [epoch: 10.5 sec]
EPOCH 416/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43818529544365736		[learning rate: 0.0014854]
	Learning Rate: 0.00148538
	LOSS [training: 0.43818529544365736 | validation: 0.41276325619214677]
	TIME [epoch: 10.5 sec]
EPOCH 417/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4230699082455912		[learning rate: 0.0014784]
	Learning Rate: 0.00147841
	LOSS [training: 0.4230699082455912 | validation: 0.40319382253626124]
	TIME [epoch: 10.5 sec]
EPOCH 418/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4352420397192559		[learning rate: 0.0014715]
	Learning Rate: 0.00147148
	LOSS [training: 0.4352420397192559 | validation: 0.46749950654118777]
	TIME [epoch: 10.5 sec]
EPOCH 419/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4271861010510742		[learning rate: 0.0014646]
	Learning Rate: 0.00146458
	LOSS [training: 0.4271861010510742 | validation: 0.31919519967183335]
	TIME [epoch: 10.5 sec]
EPOCH 420/500:
	Training over batches...
		[batch 5/5] avg loss: 0.31225713893941653		[learning rate: 0.0014577]
	Learning Rate: 0.00145772
	LOSS [training: 0.31225713893941653 | validation: 0.3305608815394123]
	TIME [epoch: 10.5 sec]
EPOCH 421/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4819681179629036		[learning rate: 0.0014509]
	Learning Rate: 0.00145088
	LOSS [training: 0.4819681179629036 | validation: 0.32759987531127316]
	TIME [epoch: 10.5 sec]
EPOCH 422/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47300145511801484		[learning rate: 0.0014441]
	Learning Rate: 0.00144408
	LOSS [training: 0.47300145511801484 | validation: 0.4001271936864737]
	TIME [epoch: 10.5 sec]
EPOCH 423/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3673417407817766		[learning rate: 0.0014373]
	Learning Rate: 0.00143731
	LOSS [training: 0.3673417407817766 | validation: 0.9292250906579955]
	TIME [epoch: 10.5 sec]
EPOCH 424/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5535128708414274		[learning rate: 0.0014306]
	Learning Rate: 0.00143057
	LOSS [training: 0.5535128708414274 | validation: 0.9993005465678343]
	TIME [epoch: 10.5 sec]
EPOCH 425/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5538754901939905		[learning rate: 0.0014239]
	Learning Rate: 0.00142387
	LOSS [training: 0.5538754901939905 | validation: 0.2408389247309998]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_425.pth
	Model improved!!!
EPOCH 426/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3889763587374903		[learning rate: 0.0014172]
	Learning Rate: 0.00141719
	LOSS [training: 0.3889763587374903 | validation: 0.28815925193311986]
	TIME [epoch: 10.5 sec]
EPOCH 427/500:
	Training over batches...
		[batch 5/5] avg loss: 0.288170860311744		[learning rate: 0.0014105]
	Learning Rate: 0.00141055
	LOSS [training: 0.288170860311744 | validation: 0.5155682029401267]
	TIME [epoch: 10.5 sec]
EPOCH 428/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5632013987020723		[learning rate: 0.0014039]
	Learning Rate: 0.00140393
	LOSS [training: 0.5632013987020723 | validation: 0.4710548461164057]
	TIME [epoch: 10.5 sec]
EPOCH 429/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4769072261024516		[learning rate: 0.0013974]
	Learning Rate: 0.00139735
	LOSS [training: 0.4769072261024516 | validation: 0.458765545657771]
	TIME [epoch: 10.5 sec]
EPOCH 430/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47023175920310234		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.47023175920310234 | validation: 0.5037246195999942]
	TIME [epoch: 10.5 sec]
EPOCH 431/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45924797003036144		[learning rate: 0.0013843]
	Learning Rate: 0.00138428
	LOSS [training: 0.45924797003036144 | validation: 0.45677131004134125]
	TIME [epoch: 10.5 sec]
EPOCH 432/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4375480512260446		[learning rate: 0.0013778]
	Learning Rate: 0.00137779
	LOSS [training: 0.4375480512260446 | validation: 0.36501322566415867]
	TIME [epoch: 10.5 sec]
EPOCH 433/500:
	Training over batches...
		[batch 5/5] avg loss: 0.42811302864713463		[learning rate: 0.0013713]
	Learning Rate: 0.00137133
	LOSS [training: 0.42811302864713463 | validation: 0.42810185545583046]
	TIME [epoch: 10.5 sec]
EPOCH 434/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4308157352202212		[learning rate: 0.0013649]
	Learning Rate: 0.0013649
	LOSS [training: 0.4308157352202212 | validation: 0.779366242265931]
	TIME [epoch: 10.5 sec]
EPOCH 435/500:
	Training over batches...
		[batch 5/5] avg loss: 0.44702446704349885		[learning rate: 0.0013585]
	Learning Rate: 0.0013585
	LOSS [training: 0.44702446704349885 | validation: 0.26393260585538036]
	TIME [epoch: 10.5 sec]
EPOCH 436/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48913959885984665		[learning rate: 0.0013521]
	Learning Rate: 0.00135214
	LOSS [training: 0.48913959885984665 | validation: 0.9397601255221147]
	TIME [epoch: 10.5 sec]
EPOCH 437/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45234082027345524		[learning rate: 0.0013458]
	Learning Rate: 0.0013458
	LOSS [training: 0.45234082027345524 | validation: 0.2277168277120198]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_437.pth
	Model improved!!!
EPOCH 438/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3060847105900713		[learning rate: 0.0013395]
	Learning Rate: 0.00133949
	LOSS [training: 0.3060847105900713 | validation: 0.6051581414259177]
	TIME [epoch: 10.5 sec]
EPOCH 439/500:
	Training over batches...
		[batch 5/5] avg loss: 0.36592874509398937		[learning rate: 0.0013332]
	Learning Rate: 0.00133321
	LOSS [training: 0.36592874509398937 | validation: 0.24488745273057425]
	TIME [epoch: 10.5 sec]
EPOCH 440/500:
	Training over batches...
		[batch 5/5] avg loss: 0.35300028582243154		[learning rate: 0.001327]
	Learning Rate: 0.00132696
	LOSS [training: 0.35300028582243154 | validation: 0.4238997845420473]
	TIME [epoch: 10.5 sec]
EPOCH 441/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4039165743395855		[learning rate: 0.0013207]
	Learning Rate: 0.00132074
	LOSS [training: 0.4039165743395855 | validation: 0.38134448402663995]
	TIME [epoch: 10.5 sec]
EPOCH 442/500:
	Training over batches...
		[batch 5/5] avg loss: 0.371055784511181		[learning rate: 0.0013145]
	Learning Rate: 0.00131454
	LOSS [training: 0.371055784511181 | validation: 0.28936015132271514]
	TIME [epoch: 10.5 sec]
EPOCH 443/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2856742692523123		[learning rate: 0.0013084]
	Learning Rate: 0.00130838
	LOSS [training: 0.2856742692523123 | validation: 0.6176240020331868]
	TIME [epoch: 10.5 sec]
EPOCH 444/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7065410003225405		[learning rate: 0.0013022]
	Learning Rate: 0.00130225
	LOSS [training: 0.7065410003225405 | validation: 0.5120184259644015]
	TIME [epoch: 10.5 sec]
EPOCH 445/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3308768759746916		[learning rate: 0.0012961]
	Learning Rate: 0.00129614
	LOSS [training: 0.3308768759746916 | validation: 0.39328907671855445]
	TIME [epoch: 10.5 sec]
EPOCH 446/500:
	Training over batches...
		[batch 5/5] avg loss: 0.36227807337164813		[learning rate: 0.0012901]
	Learning Rate: 0.00129007
	LOSS [training: 0.36227807337164813 | validation: 0.3999794498460733]
	TIME [epoch: 10.5 sec]
EPOCH 447/500:
	Training over batches...
		[batch 5/5] avg loss: 0.38979344920944425		[learning rate: 0.001284]
	Learning Rate: 0.00128402
	LOSS [training: 0.38979344920944425 | validation: 0.4406219676766595]
	TIME [epoch: 10.5 sec]
EPOCH 448/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4333328554455182		[learning rate: 0.001278]
	Learning Rate: 0.001278
	LOSS [training: 0.4333328554455182 | validation: 0.454766470969063]
	TIME [epoch: 10.5 sec]
EPOCH 449/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3951709084929823		[learning rate: 0.001272]
	Learning Rate: 0.00127201
	LOSS [training: 0.3951709084929823 | validation: 0.3554792540347067]
	TIME [epoch: 10.5 sec]
EPOCH 450/500:
	Training over batches...
		[batch 5/5] avg loss: 0.32606409411353565		[learning rate: 0.001266]
	Learning Rate: 0.00126604
	LOSS [training: 0.32606409411353565 | validation: 0.32884748752990806]
	TIME [epoch: 10.5 sec]
EPOCH 451/500:
	Training over batches...
		[batch 5/5] avg loss: 0.34968209760753555		[learning rate: 0.0012601]
	Learning Rate: 0.00126011
	LOSS [training: 0.34968209760753555 | validation: 0.41032757348952004]
	TIME [epoch: 10.5 sec]
EPOCH 452/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2976985934750105		[learning rate: 0.0012542]
	Learning Rate: 0.0012542
	LOSS [training: 0.2976985934750105 | validation: 0.2781997550645806]
	TIME [epoch: 10.5 sec]
EPOCH 453/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2320907321334217		[learning rate: 0.0012483]
	Learning Rate: 0.00124832
	LOSS [training: 0.2320907321334217 | validation: 0.21835886794266998]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_453.pth
	Model improved!!!
EPOCH 454/500:
	Training over batches...
		[batch 5/5] avg loss: 0.249170654141518		[learning rate: 0.0012425]
	Learning Rate: 0.00124247
	LOSS [training: 0.249170654141518 | validation: 0.2670613058370382]
	TIME [epoch: 10.5 sec]
EPOCH 455/500:
	Training over batches...
		[batch 5/5] avg loss: 0.30201893337361235		[learning rate: 0.0012366]
	Learning Rate: 0.00123664
	LOSS [training: 0.30201893337361235 | validation: 0.2437415067591448]
	TIME [epoch: 10.5 sec]
EPOCH 456/500:
	Training over batches...
		[batch 5/5] avg loss: 0.358467261886171		[learning rate: 0.0012308]
	Learning Rate: 0.00123085
	LOSS [training: 0.358467261886171 | validation: 0.2503793960005871]
	TIME [epoch: 10.5 sec]
EPOCH 457/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3316901381125561		[learning rate: 0.0012251]
	Learning Rate: 0.00122508
	LOSS [training: 0.3316901381125561 | validation: 0.5106026452124265]
	TIME [epoch: 10.5 sec]
EPOCH 458/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4129454816426231		[learning rate: 0.0012193]
	Learning Rate: 0.00121933
	LOSS [training: 0.4129454816426231 | validation: 0.26140189191400665]
	TIME [epoch: 10.5 sec]
EPOCH 459/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2210026041093614		[learning rate: 0.0012136]
	Learning Rate: 0.00121362
	LOSS [training: 0.2210026041093614 | validation: 0.2193968587304586]
	TIME [epoch: 10.5 sec]
EPOCH 460/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5845641013885722		[learning rate: 0.0012079]
	Learning Rate: 0.00120793
	LOSS [training: 0.5845641013885722 | validation: 0.28400710702265314]
	TIME [epoch: 10.5 sec]
EPOCH 461/500:
	Training over batches...
		[batch 5/5] avg loss: 0.29325570832079884		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.29325570832079884 | validation: 0.4435521084247185]
	TIME [epoch: 10.5 sec]
EPOCH 462/500:
	Training over batches...
		[batch 5/5] avg loss: 0.40220144205581754		[learning rate: 0.0011966]
	Learning Rate: 0.00119663
	LOSS [training: 0.40220144205581754 | validation: 0.48930517943336627]
	TIME [epoch: 10.5 sec]
EPOCH 463/500:
	Training over batches...
		[batch 5/5] avg loss: 0.33268571986727646		[learning rate: 0.001191]
	Learning Rate: 0.00119102
	LOSS [training: 0.33268571986727646 | validation: 0.21069539239817914]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240214_194845/states/model_tr_study6_463.pth
	Model improved!!!
EPOCH 464/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3046514895299107		[learning rate: 0.0011854]
	Learning Rate: 0.00118543
	LOSS [training: 0.3046514895299107 | validation: 0.26883585396981013]
	TIME [epoch: 10.5 sec]
EPOCH 465/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24793397836960676		[learning rate: 0.0011799]
	Learning Rate: 0.00117988
	LOSS [training: 0.24793397836960676 | validation: 0.28229218400174944]
	TIME [epoch: 10.5 sec]
EPOCH 466/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9553301943631954		[learning rate: 0.0011743]
	Learning Rate: 0.00117435
	LOSS [training: 0.9553301943631954 | validation: 2.1725703802516567]
	TIME [epoch: 10.5 sec]
EPOCH 467/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1573632418500255		[learning rate: 0.0011688]
	Learning Rate: 0.00116884
	LOSS [training: 2.1573632418500255 | validation: 2.654826667025535]
	TIME [epoch: 10.5 sec]
EPOCH 468/500:
	Training over batches...
		[batch 5/5] avg loss: 2.349273664136751		[learning rate: 0.0011634]
	Learning Rate: 0.00116336
	LOSS [training: 2.349273664136751 | validation: 2.4967652367925717]
	TIME [epoch: 10.5 sec]
EPOCH 469/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3214989129315127		[learning rate: 0.0011579]
	Learning Rate: 0.00115791
	LOSS [training: 2.3214989129315127 | validation: 2.467089215632859]
	TIME [epoch: 10.5 sec]
EPOCH 470/500:
	Training over batches...
		[batch 5/5] avg loss: 2.360319733950937		[learning rate: 0.0011525]
	Learning Rate: 0.00115248
	LOSS [training: 2.360319733950937 | validation: 2.7470611960389726]
	TIME [epoch: 10.5 sec]
EPOCH 471/500:
	Training over batches...
		[batch 5/5] avg loss: 2.670717759851173		[learning rate: 0.0011471]
	Learning Rate: 0.00114708
	LOSS [training: 2.670717759851173 | validation: 2.7136415284677007]
	TIME [epoch: 10.5 sec]
EPOCH 472/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6577842936120915		[learning rate: 0.0011417]
	Learning Rate: 0.0011417
	LOSS [training: 2.6577842936120915 | validation: 2.9471391234094875]
	TIME [epoch: 10.5 sec]
EPOCH 473/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8250231995943285		[learning rate: 0.0011363]
	Learning Rate: 0.00113635
	LOSS [training: 2.8250231995943285 | validation: 2.7151282184682817]
	TIME [epoch: 10.5 sec]
EPOCH 474/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7908814144381828		[learning rate: 0.001131]
	Learning Rate: 0.00113102
	LOSS [training: 1.7908814144381828 | validation: 0.6533941944354861]
	TIME [epoch: 10.5 sec]
EPOCH 475/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5876223248590795		[learning rate: 0.0011257]
	Learning Rate: 0.00112572
	LOSS [training: 0.5876223248590795 | validation: 0.48736417306693985]
	TIME [epoch: 10.5 sec]
EPOCH 476/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5030614462333041		[learning rate: 0.0011204]
	Learning Rate: 0.00112044
	LOSS [training: 0.5030614462333041 | validation: 0.493845434026954]
	TIME [epoch: 10.5 sec]
EPOCH 477/500:
	Training over batches...
		[batch 5/5] avg loss: 0.41505696482486953		[learning rate: 0.0011152]
	Learning Rate: 0.00111518
	LOSS [training: 0.41505696482486953 | validation: 0.3440680988592119]
	TIME [epoch: 10.5 sec]
EPOCH 478/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5368377411351001		[learning rate: 0.00111]
	Learning Rate: 0.00110996
	LOSS [training: 0.5368377411351001 | validation: 0.9335273500212601]
	TIME [epoch: 10.5 sec]
EPOCH 479/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5888806715597585		[learning rate: 0.0011048]
	Learning Rate: 0.00110475
	LOSS [training: 0.5888806715597585 | validation: 0.42671924333632627]
	TIME [epoch: 10.5 sec]
EPOCH 480/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3845588004551512		[learning rate: 0.0010996]
	Learning Rate: 0.00109957
	LOSS [training: 0.3845588004551512 | validation: 0.3058012701409711]
	TIME [epoch: 10.5 sec]
EPOCH 481/500:
	Training over batches...
		[batch 5/5] avg loss: 0.34438468586552157		[learning rate: 0.0010944]
	Learning Rate: 0.00109442
	LOSS [training: 0.34438468586552157 | validation: 0.37671386375085136]
	TIME [epoch: 10.5 sec]
EPOCH 482/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3176376191392848		[learning rate: 0.0010893]
	Learning Rate: 0.00108929
	LOSS [training: 0.3176376191392848 | validation: 0.3492278590173954]
	TIME [epoch: 10.5 sec]
EPOCH 483/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3919522729796229		[learning rate: 0.0010842]
	Learning Rate: 0.00108418
	LOSS [training: 0.3919522729796229 | validation: 0.3233681898190862]
	TIME [epoch: 10.5 sec]
EPOCH 484/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3324318059899452		[learning rate: 0.0010791]
	Learning Rate: 0.0010791
	LOSS [training: 0.3324318059899452 | validation: 0.45950259664593135]
	TIME [epoch: 10.5 sec]
EPOCH 485/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4621740172390306		[learning rate: 0.001074]
	Learning Rate: 0.00107404
	LOSS [training: 0.4621740172390306 | validation: 0.2688688678841799]
	TIME [epoch: 10.5 sec]
EPOCH 486/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24436191221159625		[learning rate: 0.001069]
	Learning Rate: 0.001069
	LOSS [training: 0.24436191221159625 | validation: 0.4320154979159591]
	TIME [epoch: 10.5 sec]
EPOCH 487/500:
	Training over batches...
		[batch 5/5] avg loss: 0.410596335661479		[learning rate: 0.001064]
	Learning Rate: 0.00106399
	LOSS [training: 0.410596335661479 | validation: 0.32726190993455745]
	TIME [epoch: 10.5 sec]
EPOCH 488/500:
	Training over batches...
		[batch 5/5] avg loss: 0.290330358975189		[learning rate: 0.001059]
	Learning Rate: 0.001059
	LOSS [training: 0.290330358975189 | validation: 0.3189569139597754]
	TIME [epoch: 10.5 sec]
EPOCH 489/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4134622400523448		[learning rate: 0.001054]
	Learning Rate: 0.00105404
	LOSS [training: 0.4134622400523448 | validation: 0.39531987659102724]
	TIME [epoch: 10.5 sec]
EPOCH 490/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4925162625379369		[learning rate: 0.0010491]
	Learning Rate: 0.0010491
	LOSS [training: 0.4925162625379369 | validation: 0.40519979219379537]
	TIME [epoch: 10.5 sec]
EPOCH 491/500:
	Training over batches...
		[batch 5/5] avg loss: 0.44874223440716676		[learning rate: 0.0010442]
	Learning Rate: 0.00104418
	LOSS [training: 0.44874223440716676 | validation: 0.35625000548836383]
	TIME [epoch: 10.5 sec]
EPOCH 492/500:
	Training over batches...
		[batch 5/5] avg loss: 0.34341256043623414		[learning rate: 0.0010393]
	Learning Rate: 0.00103929
	LOSS [training: 0.34341256043623414 | validation: 0.26431553384421164]
	TIME [epoch: 10.5 sec]
EPOCH 493/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2741245258789184		[learning rate: 0.0010344]
	Learning Rate: 0.00103441
	LOSS [training: 0.2741245258789184 | validation: 0.3818712153953773]
	TIME [epoch: 10.5 sec]
EPOCH 494/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3825399298721063		[learning rate: 0.0010296]
	Learning Rate: 0.00102956
	LOSS [training: 0.3825399298721063 | validation: 0.40743469824191425]
	TIME [epoch: 10.5 sec]
EPOCH 495/500:
	Training over batches...
		[batch 5/5] avg loss: 0.36962392812983813		[learning rate: 0.0010247]
	Learning Rate: 0.00102474
	LOSS [training: 0.36962392812983813 | validation: 0.3173937571710601]
	TIME [epoch: 10.5 sec]
EPOCH 496/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3289759805548927		[learning rate: 0.0010199]
	Learning Rate: 0.00101993
	LOSS [training: 0.3289759805548927 | validation: 0.3396648034231987]
	TIME [epoch: 10.5 sec]
EPOCH 497/500:
	Training over batches...
		[batch 5/5] avg loss: 0.26893996004401954		[learning rate: 0.0010152]
	Learning Rate: 0.00101515
	LOSS [training: 0.26893996004401954 | validation: 0.2557025241053351]
	TIME [epoch: 10.5 sec]
EPOCH 498/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2591061456375797		[learning rate: 0.0010104]
	Learning Rate: 0.00101039
	LOSS [training: 0.2591061456375797 | validation: 0.4877339664965231]
	TIME [epoch: 10.5 sec]
EPOCH 499/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3122980411914663		[learning rate: 0.0010057]
	Learning Rate: 0.00100565
	LOSS [training: 0.3122980411914663 | validation: 0.23636716433961671]
	TIME [epoch: 10.5 sec]
EPOCH 500/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21514846351594824		[learning rate: 0.0010009]
	Learning Rate: 0.00100094
	LOSS [training: 0.21514846351594824 | validation: 0.27918115634920077]
	TIME [epoch: 10.5 sec]
Finished training in 5326.233 seconds.
