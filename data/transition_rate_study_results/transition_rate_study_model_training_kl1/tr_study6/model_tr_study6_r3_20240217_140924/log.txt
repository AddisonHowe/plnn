Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r3', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3462687314

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.340695272326995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.340695272326995 | validation: 9.350132150835826]
	TIME [epoch: 80.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.14856461569376		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.14856461569376 | validation: 9.424606517887243]
	TIME [epoch: 9.76 sec]
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.968484189909407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.968484189909407 | validation: 9.158922424884516]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.81072071076846		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.81072071076846 | validation: 8.716481050265621]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.65953345115145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.65953345115145 | validation: 8.972884796644585]
	TIME [epoch: 9.72 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.60654537877868		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.60654537877868 | validation: 8.0758431182295]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.955977176493327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.955977176493327 | validation: 8.05377036129864]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.742524095629103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.742524095629103 | validation: 7.850036739886519]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.550108244432353		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.550108244432353 | validation: 7.6287618438028355]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.530968909253462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.530968909253462 | validation: 8.016579573232672]
	TIME [epoch: 9.74 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.544769274477963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.544769274477963 | validation: 7.942355197511785]
	TIME [epoch: 9.76 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.758417994291039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.758417994291039 | validation: 7.859276945468235]
	TIME [epoch: 9.74 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.452849131737092		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.452849131737092 | validation: 7.502570814734269]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.498280770511656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.498280770511656 | validation: 7.674936984335864]
	TIME [epoch: 9.73 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.717554842078888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.717554842078888 | validation: 7.582253658272519]
	TIME [epoch: 9.76 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.463702725520809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.463702725520809 | validation: 7.5697354503978795]
	TIME [epoch: 9.73 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.445315307754948		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.445315307754948 | validation: 7.944536395810567]
	TIME [epoch: 9.73 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.410742854871894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.410742854871894 | validation: 7.811772321681344]
	TIME [epoch: 9.73 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.3474803586673305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3474803586673305 | validation: 7.566821578797831]
	TIME [epoch: 9.75 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.3231391363957865		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3231391363957865 | validation: 7.6260078353947724]
	TIME [epoch: 9.73 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.281988455443958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.281988455443958 | validation: 7.4669155453442135]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.2359476647292595		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2359476647292595 | validation: 7.632853030076356]
	TIME [epoch: 9.74 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.566781014494393		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.566781014494393 | validation: 7.468910568346703]
	TIME [epoch: 9.74 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.4664419018315655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.4664419018315655 | validation: 7.900480557074423]
	TIME [epoch: 9.73 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.370834712373032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.370834712373032 | validation: 7.8325501210574044]
	TIME [epoch: 9.73 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.492683467010401		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.492683467010401 | validation: 7.607766690917522]
	TIME [epoch: 9.74 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.252471262437766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.252471262437766 | validation: 7.550759814235462]
	TIME [epoch: 9.73 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.277866762816295		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.277866762816295 | validation: 7.502195876789524]
	TIME [epoch: 9.72 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.535582691709001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.535582691709001 | validation: 7.433222538879606]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.2459553882039796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2459553882039796 | validation: 7.350818954150516]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.27958564093728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.27958564093728 | validation: 7.48758033458945]
	TIME [epoch: 9.73 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.218771997437924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.218771997437924 | validation: 7.3870405290870895]
	TIME [epoch: 9.73 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.185055959074089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.185055959074089 | validation: 7.308718726179409]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_33.pth
	Model improved!!!
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.144456314068085		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.144456314068085 | validation: 7.284791403217456]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_34.pth
	Model improved!!!
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.125723739867735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.125723739867735 | validation: 7.333651254299232]
	TIME [epoch: 9.73 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.130475282146797		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.130475282146797 | validation: 7.3294894710058145]
	TIME [epoch: 9.73 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.1800574465471145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.1800574465471145 | validation: 7.215617874074728]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.161620899793206		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.161620899793206 | validation: 7.2583025392169205]
	TIME [epoch: 9.73 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.058910773347806		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.058910773347806 | validation: 7.26301996940966]
	TIME [epoch: 9.72 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.029056773989325		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.029056773989325 | validation: 7.479460241095758]
	TIME [epoch: 9.72 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.01524034720245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.01524034720245 | validation: 7.493662788742254]
	TIME [epoch: 9.74 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.133495748642827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.133495748642827 | validation: 7.6697371534310115]
	TIME [epoch: 9.73 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.296298596367554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.296298596367554 | validation: 7.303840980870594]
	TIME [epoch: 9.72 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.039660287659468		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.039660287659468 | validation: 7.181423722400052]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.92720552672005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.92720552672005 | validation: 7.334416029381835]
	TIME [epoch: 9.74 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.916771563624076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.916771563624076 | validation: 7.53853136846282]
	TIME [epoch: 9.72 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.971286622451457		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.971286622451457 | validation: 7.340193707082301]
	TIME [epoch: 9.72 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.923030925276089		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.923030925276089 | validation: 7.169101576573945]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.869753202305477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.869753202305477 | validation: 7.0772419420522015]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.106084973055888		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.106084973055888 | validation: 7.410992221228183]
	TIME [epoch: 9.72 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.925298779042497		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 6.925298779042497 | validation: 7.1717313797680315]
	TIME [epoch: 9.72 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.770073628875993		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 6.770073628875993 | validation: 7.227547369396705]
	TIME [epoch: 9.75 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.791659023241797		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 6.791659023241797 | validation: 7.109906921087959]
	TIME [epoch: 9.72 sec]
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.685206066747841		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 6.685206066747841 | validation: 7.21122351642126]
	TIME [epoch: 9.73 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.762348640953443		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 6.762348640953443 | validation: 7.102953847341172]
	TIME [epoch: 9.72 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.716370010917619		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 6.716370010917619 | validation: 7.256256326272419]
	TIME [epoch: 9.74 sec]
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.726390490595739		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 6.726390490595739 | validation: 7.029425260406681]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.749752053198404		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 6.749752053198404 | validation: 7.09014821068015]
	TIME [epoch: 9.71 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.674197066545553		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 6.674197066545553 | validation: 6.941702992766998]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_59.pth
	Model improved!!!
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.576305699794567		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 6.576305699794567 | validation: 7.452656172740178]
	TIME [epoch: 9.73 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.723161465286758		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 6.723161465286758 | validation: 7.069665519060293]
	TIME [epoch: 9.73 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.689101761126908		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 6.689101761126908 | validation: 7.024337082271029]
	TIME [epoch: 9.72 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.59477968963441		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 6.59477968963441 | validation: 6.966850484691454]
	TIME [epoch: 9.74 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.661649805506235		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 6.661649805506235 | validation: 6.933128986298045]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.735008802009046		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 6.735008802009046 | validation: 7.008900800608297]
	TIME [epoch: 9.73 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.597092030401706		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 6.597092030401706 | validation: 6.948235337563578]
	TIME [epoch: 9.73 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.669939512800245		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 6.669939512800245 | validation: 6.952964631162329]
	TIME [epoch: 9.74 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.6164670416488205		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 6.6164670416488205 | validation: 7.302997929678512]
	TIME [epoch: 9.72 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.727721084040075		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 6.727721084040075 | validation: 6.852522458507369]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_69.pth
	Model improved!!!
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.580912243732806		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 6.580912243732806 | validation: 7.613880513047956]
	TIME [epoch: 9.75 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.667008026862217		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 6.667008026862217 | validation: 6.823823582669133]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_71.pth
	Model improved!!!
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.604784031731808		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 6.604784031731808 | validation: 6.8311707689936885]
	TIME [epoch: 9.71 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.513756775426503		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 6.513756775426503 | validation: 6.885777399343067]
	TIME [epoch: 9.71 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.59843078615229		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 6.59843078615229 | validation: 6.759057503687558]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_74.pth
	Model improved!!!
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.48969640059646		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 6.48969640059646 | validation: 7.110969792090002]
	TIME [epoch: 9.72 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.4757904005579245		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 6.4757904005579245 | validation: 6.7250615348602585]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.410784462921596		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 6.410784462921596 | validation: 6.584354523957054]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_77.pth
	Model improved!!!
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.176433062368956		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 6.176433062368956 | validation: 6.513621583529897]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_78.pth
	Model improved!!!
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.002089390627608		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 6.002089390627608 | validation: 6.088186276026859]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.617035721390368		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 5.617035721390368 | validation: 5.283289318268742]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_80.pth
	Model improved!!!
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.879345288068107		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 4.879345288068107 | validation: 6.510726784379547]
	TIME [epoch: 9.74 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.042230461287319		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 7.042230461287319 | validation: 7.912191661981422]
	TIME [epoch: 9.74 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.3852316883099665		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 7.3852316883099665 | validation: 7.678063590734833]
	TIME [epoch: 9.72 sec]
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.148407983639349		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 7.148407983639349 | validation: 7.9215457138470535]
	TIME [epoch: 9.72 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.137869698896436		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 6.137869698896436 | validation: 6.373131047729512]
	TIME [epoch: 9.74 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.559720136020589		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 5.559720136020589 | validation: 5.5084626219621]
	TIME [epoch: 9.71 sec]
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.160847313709278		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 5.160847313709278 | validation: 5.4397321575175]
	TIME [epoch: 9.72 sec]
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.013065621404899		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 5.013065621404899 | validation: 5.242427581673758]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_88.pth
	Model improved!!!
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.831471420897863		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 4.831471420897863 | validation: 5.383671791870199]
	TIME [epoch: 9.74 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.996868965356152		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 4.996868965356152 | validation: 5.007852607512898]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_90.pth
	Model improved!!!
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.5678176439234885		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 4.5678176439234885 | validation: 4.8916672503298955]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_91.pth
	Model improved!!!
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.2373697114929		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 4.2373697114929 | validation: 4.433318950990138]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_92.pth
	Model improved!!!
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.138839005206812		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 4.138839005206812 | validation: 5.437769739386036]
	TIME [epoch: 9.71 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.117983074051587		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 4.117983074051587 | validation: 4.265084170431306]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_94.pth
	Model improved!!!
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.424488904580907		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 4.424488904580907 | validation: 4.20755593282595]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.741984891655143		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 3.741984891655143 | validation: 4.210116796567077]
	TIME [epoch: 9.72 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.970018933233986		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 3.970018933233986 | validation: 4.008179047467908]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.960441397804754		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 3.960441397804754 | validation: 4.007485605424472]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6839189912221677		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 3.6839189912221677 | validation: 3.9510749508776133]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_99.pth
	Model improved!!!
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5214670067215375		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 3.5214670067215375 | validation: 4.985559379885041]
	TIME [epoch: 9.73 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6173287123296767		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 3.6173287123296767 | validation: 3.2525877396341487]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_101.pth
	Model improved!!!
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.085847459429822		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 3.085847459429822 | validation: 2.697094015757189]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_102.pth
	Model improved!!!
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.825023893679488		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 2.825023893679488 | validation: 3.358376150893022]
	TIME [epoch: 9.74 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6421197876251705		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 2.6421197876251705 | validation: 2.187727976637414]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_104.pth
	Model improved!!!
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5462707553747674		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 2.5462707553747674 | validation: 2.16625188842676]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_105.pth
	Model improved!!!
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3430372067885363		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 2.3430372067885363 | validation: 2.4571692454792764]
	TIME [epoch: 9.71 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4946928385535387		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 2.4946928385535387 | validation: 3.04318434754216]
	TIME [epoch: 9.74 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8181387232737003		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 2.8181387232737003 | validation: 2.6704741595220014]
	TIME [epoch: 9.72 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3617115658150922		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 3.3617115658150922 | validation: 2.776739272275273]
	TIME [epoch: 9.72 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4176215316742296		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 2.4176215316742296 | validation: 3.5300204342094617]
	TIME [epoch: 9.72 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.475056773815561		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 3.475056773815561 | validation: 2.575554980428251]
	TIME [epoch: 9.74 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7182268035074606		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 2.7182268035074606 | validation: 2.5300804367785648]
	TIME [epoch: 9.71 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4152821459119944		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 2.4152821459119944 | validation: 2.92660572072857]
	TIME [epoch: 9.72 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.435284296217151		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 2.435284296217151 | validation: 2.767388773570452]
	TIME [epoch: 9.73 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5526961469748817		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 2.5526961469748817 | validation: 2.1126543072280857]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_115.pth
	Model improved!!!
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3002442025182632		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 2.3002442025182632 | validation: 2.3446100763228857]
	TIME [epoch: 9.71 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5331709306310843		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 2.5331709306310843 | validation: 2.5639699269618275]
	TIME [epoch: 9.7 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5534428449525484		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 2.5534428449525484 | validation: 2.1035712665389115]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_118.pth
	Model improved!!!
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5430799000228417		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 2.5430799000228417 | validation: 1.8606271884490442]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_119.pth
	Model improved!!!
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9882026882533002		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 1.9882026882533002 | validation: 2.159960021580474]
	TIME [epoch: 9.72 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4206032564671207		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 2.4206032564671207 | validation: 2.1201904430058818]
	TIME [epoch: 9.72 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.207119577093974		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 2.207119577093974 | validation: 2.1427406526876975]
	TIME [epoch: 9.72 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1267372718294237		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 2.1267372718294237 | validation: 2.3286237581124727]
	TIME [epoch: 9.71 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1948461039158755		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 2.1948461039158755 | validation: 2.7814658963253573]
	TIME [epoch: 9.71 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6213243162081388		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 2.6213243162081388 | validation: 2.0948072452673134]
	TIME [epoch: 9.72 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2556376010358514		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 2.2556376010358514 | validation: 2.4198441682809713]
	TIME [epoch: 9.71 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.152672394025766		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 2.152672394025766 | validation: 1.851658854883567]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_127.pth
	Model improved!!!
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0535872001780158		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 2.0535872001780158 | validation: 1.7020602206432744]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_128.pth
	Model improved!!!
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9735737060607057		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 1.9735737060607057 | validation: 3.3250053634265146]
	TIME [epoch: 9.74 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.623091276982648		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 2.623091276982648 | validation: 2.3630201668064483]
	TIME [epoch: 9.71 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1699906740309793		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 2.1699906740309793 | validation: 2.040789862678058]
	TIME [epoch: 9.71 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9404799360967047		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 1.9404799360967047 | validation: 1.6153864387356793]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_132.pth
	Model improved!!!
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1907845060614126		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 2.1907845060614126 | validation: 1.9601625463988444]
	TIME [epoch: 9.74 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9998046929309674		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 1.9998046929309674 | validation: 1.8138442669941364]
	TIME [epoch: 9.71 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.250910686759733		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 2.250910686759733 | validation: 2.2370222399852673]
	TIME [epoch: 9.71 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2615692543456642		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 2.2615692543456642 | validation: 1.5872166125225278]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_136.pth
	Model improved!!!
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9945443048991873		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 1.9945443048991873 | validation: 1.7775045003192753]
	TIME [epoch: 9.72 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3888261109582585		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 2.3888261109582585 | validation: 1.7414954420964868]
	TIME [epoch: 9.71 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5110481944540837		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 2.5110481944540837 | validation: 3.4404203045179123]
	TIME [epoch: 9.71 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.633673444558961		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 2.633673444558961 | validation: 1.752615018513331]
	TIME [epoch: 9.73 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8748737764471985		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 1.8748737764471985 | validation: 2.1809611102874613]
	TIME [epoch: 9.7 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9506043695443966		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 1.9506043695443966 | validation: 3.3941163231006715]
	TIME [epoch: 9.7 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3780385875002787		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 2.3780385875002787 | validation: 1.5712886507940733]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_143.pth
	Model improved!!!
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1671132691161796		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 2.1671132691161796 | validation: 2.1229127006247355]
	TIME [epoch: 9.73 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.949813392052987		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 1.949813392052987 | validation: 3.0001911899325244]
	TIME [epoch: 9.7 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1239305409016103		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 2.1239305409016103 | validation: 1.623224489491748]
	TIME [epoch: 9.71 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8620819988941755		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 1.8620819988941755 | validation: 1.9240099252684144]
	TIME [epoch: 9.71 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6324298937145456		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 2.6324298937145456 | validation: 2.5869553169939987]
	TIME [epoch: 9.73 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0640082714557897		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 2.0640082714557897 | validation: 1.848989929600275]
	TIME [epoch: 9.71 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8730237479654093		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 1.8730237479654093 | validation: 1.83986753867512]
	TIME [epoch: 9.7 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0097635269598877		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 2.0097635269598877 | validation: 1.474163255974403]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_151.pth
	Model improved!!!
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.074638418656462		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 2.074638418656462 | validation: 1.6781818313606027]
	TIME [epoch: 9.71 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8658692422590903		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 1.8658692422590903 | validation: 2.007299865776398]
	TIME [epoch: 9.7 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8564680195704402		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 1.8564680195704402 | validation: 1.8513184368612532]
	TIME [epoch: 9.71 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8145382383913868		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 1.8145382383913868 | validation: 1.6743187329147673]
	TIME [epoch: 9.73 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8325087206163555		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 1.8325087206163555 | validation: 2.350857990989555]
	TIME [epoch: 9.7 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0562765489033943		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 2.0562765489033943 | validation: 1.5479988700271683]
	TIME [epoch: 9.7 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.723945366821037		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 1.723945366821037 | validation: 1.6458068541722413]
	TIME [epoch: 9.7 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7961269650182736		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 1.7961269650182736 | validation: 1.5740426347684053]
	TIME [epoch: 9.73 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.685679504614384		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 1.685679504614384 | validation: 1.729410179195332]
	TIME [epoch: 9.71 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5933487320076316		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 1.5933487320076316 | validation: 1.4397963771205344]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_161.pth
	Model improved!!!
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5675450681835046		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 1.5675450681835046 | validation: 1.5802124685264283]
	TIME [epoch: 9.72 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4824529604107837		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 1.4824529604107837 | validation: 1.787309540588261]
	TIME [epoch: 9.72 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5837281338548972		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 1.5837281338548972 | validation: 1.363232848486987]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_164.pth
	Model improved!!!
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5847897546213208		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 1.5847897546213208 | validation: 1.7829888306612334]
	TIME [epoch: 9.71 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.719071493751303		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 1.719071493751303 | validation: 1.2552510591144224]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_166.pth
	Model improved!!!
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6583947833406842		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 1.6583947833406842 | validation: 1.6491641306364044]
	TIME [epoch: 9.71 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8392621820081512		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 1.8392621820081512 | validation: 2.8903538574502807]
	TIME [epoch: 9.71 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1048096348210033		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 2.1048096348210033 | validation: 1.2740009577076459]
	TIME [epoch: 9.71 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.722834431913077		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 1.722834431913077 | validation: 2.3026912625866283]
	TIME [epoch: 9.73 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.800407830625445		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 1.800407830625445 | validation: 1.649880025793375]
	TIME [epoch: 9.71 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.605745871621835		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 1.605745871621835 | validation: 1.456073608222032]
	TIME [epoch: 9.7 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.024139491240409		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 2.024139491240409 | validation: 1.626049515007492]
	TIME [epoch: 9.72 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9556486223429705		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 1.9556486223429705 | validation: 1.3292175415122185]
	TIME [epoch: 9.72 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.473122459615239		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 1.473122459615239 | validation: 2.98220796889917]
	TIME [epoch: 9.71 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.367712017687423		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 2.367712017687423 | validation: 1.7577551112715588]
	TIME [epoch: 9.7 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8484944696521892		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 1.8484944696521892 | validation: 1.3394777851984194]
	TIME [epoch: 9.73 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8298560163717053		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 1.8298560163717053 | validation: 1.723955634040375]
	TIME [epoch: 9.71 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6873213172662958		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 1.6873213172662958 | validation: 2.834863226099636]
	TIME [epoch: 9.71 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9470535571276897		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 1.9470535571276897 | validation: 1.412290822788373]
	TIME [epoch: 9.71 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8371038097500338		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 1.8371038097500338 | validation: 3.6520822041668444]
	TIME [epoch: 9.73 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.190683858205833		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 2.190683858205833 | validation: 1.775224337119794]
	TIME [epoch: 9.7 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6175184275312802		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 1.6175184275312802 | validation: 1.6366561057564197]
	TIME [epoch: 9.71 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3667692599165797		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 1.3667692599165797 | validation: 2.3566417603181185]
	TIME [epoch: 9.71 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7061366202939958		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 1.7061366202939958 | validation: 2.2411249326225744]
	TIME [epoch: 9.73 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.498755530695762		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 2.498755530695762 | validation: 3.8429430506954643]
	TIME [epoch: 9.71 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6612256788175537		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 2.6612256788175537 | validation: 1.5155324545828632]
	TIME [epoch: 9.7 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7624496616925154		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 1.7624496616925154 | validation: 1.6228278505909575]
	TIME [epoch: 9.73 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8544981168755448		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 1.8544981168755448 | validation: 2.3126876473843745]
	TIME [epoch: 9.71 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8676865276451469		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 1.8676865276451469 | validation: 1.4808487719632846]
	TIME [epoch: 9.71 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6665081077447517		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 1.6665081077447517 | validation: 1.2622090294686958]
	TIME [epoch: 9.7 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2801781098805116		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 2.2801781098805116 | validation: 1.3227704295167058]
	TIME [epoch: 9.73 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7232338717245437		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 1.7232338717245437 | validation: 1.1395034535847832]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_193.pth
	Model improved!!!
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9381402708869764		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 1.9381402708869764 | validation: 1.8318232835160433]
	TIME [epoch: 9.7 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9460566983427376		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 1.9460566983427376 | validation: 1.7828345985480851]
	TIME [epoch: 9.7 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.731751587666891		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 1.731751587666891 | validation: 1.5796351052995032]
	TIME [epoch: 9.72 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6856683060697253		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 1.6856683060697253 | validation: 1.895232823715133]
	TIME [epoch: 9.7 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.060995833604854		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 2.060995833604854 | validation: 3.4003703987207166]
	TIME [epoch: 9.71 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8310303402824875		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 1.8310303402824875 | validation: 1.7132741239959353]
	TIME [epoch: 9.71 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0796561674331344		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 2.0796561674331344 | validation: 2.0071517393023246]
	TIME [epoch: 9.72 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.623275328016625		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 1.623275328016625 | validation: 1.3792669844473489]
	TIME [epoch: 9.71 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.60477127250997		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 1.60477127250997 | validation: 1.1743938154206364]
	TIME [epoch: 9.7 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7239983799914445		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 1.7239983799914445 | validation: 1.455578641223014]
	TIME [epoch: 9.72 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.800228060631909		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 1.800228060631909 | validation: 2.7628625127482986]
	TIME [epoch: 9.7 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7969993095543402		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 1.7969993095543402 | validation: 1.8101232851193882]
	TIME [epoch: 9.71 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2254955079588292		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 2.2254955079588292 | validation: 5.322468969006196]
	TIME [epoch: 9.7 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.725963746149549		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 2.725963746149549 | validation: 1.3330135633778262]
	TIME [epoch: 9.73 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4035751119420954		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 1.4035751119420954 | validation: 3.2778526872487617]
	TIME [epoch: 9.7 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.955499948897409		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 1.955499948897409 | validation: 1.2741036594451842]
	TIME [epoch: 9.71 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9625831484788692		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 1.9625831484788692 | validation: 1.5172500009745478]
	TIME [epoch: 9.7 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6035726375746875		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 1.6035726375746875 | validation: 1.6501891462309568]
	TIME [epoch: 9.72 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5133720777008215		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 1.5133720777008215 | validation: 2.333274409597509]
	TIME [epoch: 9.71 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8944230590447326		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 1.8944230590447326 | validation: 4.370578139790667]
	TIME [epoch: 9.71 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6426928716577844		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 2.6426928716577844 | validation: 1.9820960906618967]
	TIME [epoch: 9.71 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7022411747409791		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 1.7022411747409791 | validation: 1.395720172382717]
	TIME [epoch: 9.71 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5471672860890475		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 1.5471672860890475 | validation: 2.4196832330714155]
	TIME [epoch: 9.7 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6170216175260705		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 1.6170216175260705 | validation: 1.3987030124966326]
	TIME [epoch: 9.71 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.60645903740288		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 1.60645903740288 | validation: 1.8679331222268223]
	TIME [epoch: 9.72 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6699826934630893		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 1.6699826934630893 | validation: 1.2561189811403322]
	TIME [epoch: 9.7 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.54702692353007		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 1.54702692353007 | validation: 1.2070273949515313]
	TIME [epoch: 9.7 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4847226467896466		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 1.4847226467896466 | validation: 1.7483709544418964]
	TIME [epoch: 9.71 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7146931541505328		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 1.7146931541505328 | validation: 1.8523382676982092]
	TIME [epoch: 9.72 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5935007924770677		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 1.5935007924770677 | validation: 1.5391951336441696]
	TIME [epoch: 9.7 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3806324603803377		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 1.3806324603803377 | validation: 1.687697705540819]
	TIME [epoch: 9.7 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7665152973212912		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 1.7665152973212912 | validation: 1.8408856946853187]
	TIME [epoch: 9.71 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.429832071958229		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 1.429832071958229 | validation: 2.3627420813219624]
	TIME [epoch: 9.72 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.585836880858053		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 1.585836880858053 | validation: 2.0160727722590535]
	TIME [epoch: 9.69 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9708883826687003		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 1.9708883826687003 | validation: 1.7892913048613206]
	TIME [epoch: 9.7 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.630744438787596		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 1.630744438787596 | validation: 1.2814455544475665]
	TIME [epoch: 9.72 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3797431291798803		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 1.3797431291798803 | validation: 1.8947691221872793]
	TIME [epoch: 9.71 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4240863736095344		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 1.4240863736095344 | validation: 2.10534734058099]
	TIME [epoch: 9.7 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5819245104245092		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 1.5819245104245092 | validation: 1.3387054561634282]
	TIME [epoch: 9.71 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3846645208154116		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 1.3846645208154116 | validation: 2.4772974503567005]
	TIME [epoch: 9.73 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7330447500174997		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 1.7330447500174997 | validation: 1.299160785581927]
	TIME [epoch: 9.7 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.498076836668209		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 1.498076836668209 | validation: 1.8493110779688777]
	TIME [epoch: 9.71 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.444721762980534		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 1.444721762980534 | validation: 1.1850201437068841]
	TIME [epoch: 9.7 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3781256514016587		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 1.3781256514016587 | validation: 1.5932959829098219]
	TIME [epoch: 9.73 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.504465301236085		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 1.504465301236085 | validation: 1.707681838972001]
	TIME [epoch: 9.71 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5306112523521391		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 1.5306112523521391 | validation: 1.2561597568082759]
	TIME [epoch: 9.7 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2158594486268908		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 1.2158594486268908 | validation: 1.5764197596372498]
	TIME [epoch: 9.72 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4767611419133038		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 1.4767611419133038 | validation: 1.5417334641097045]
	TIME [epoch: 9.72 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6240305959727372		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 1.6240305959727372 | validation: 1.566672368157836]
	TIME [epoch: 9.7 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.278114567357394		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 1.278114567357394 | validation: 1.8515513522459934]
	TIME [epoch: 9.7 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6426058104575376		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 1.6426058104575376 | validation: 1.0947538637623995]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_244.pth
	Model improved!!!
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8452965126852015		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 1.8452965126852015 | validation: 1.5410974947170981]
	TIME [epoch: 9.71 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3127556483367657		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 1.3127556483367657 | validation: 2.587738120461682]
	TIME [epoch: 9.71 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.0242782593772386		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 2.0242782593772386 | validation: 2.037675888388407]
	TIME [epoch: 9.7 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8261333080954738		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 1.8261333080954738 | validation: 1.455340760473197]
	TIME [epoch: 9.73 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2775428266871236		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 1.2775428266871236 | validation: 1.3546389922362676]
	TIME [epoch: 9.7 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8896594760759835		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 1.8896594760759835 | validation: 1.4832104313192889]
	TIME [epoch: 9.7 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4380451855711864		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 1.4380451855711864 | validation: 1.3006048453097279]
	TIME [epoch: 9.71 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.457987324229761		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 1.457987324229761 | validation: 1.3090072315311494]
	TIME [epoch: 9.72 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6527186274045313		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 1.6527186274045313 | validation: 1.9575598298779386]
	TIME [epoch: 9.7 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5340808215297628		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 1.5340808215297628 | validation: 1.2740357546577445]
	TIME [epoch: 9.71 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3793677149086458		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 1.3793677149086458 | validation: 2.7508534486533773]
	TIME [epoch: 9.72 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9461557156911689		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 1.9461557156911689 | validation: 1.1439547985220129]
	TIME [epoch: 9.71 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.471770206372298		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 1.471770206372298 | validation: 1.4932639154062688]
	TIME [epoch: 9.71 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5227884224945747		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 1.5227884224945747 | validation: 1.2694629159967667]
	TIME [epoch: 9.7 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0992707588232067		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 1.0992707588232067 | validation: 1.3484595748370303]
	TIME [epoch: 9.73 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4551234603514727		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 1.4551234603514727 | validation: 1.77087123881814]
	TIME [epoch: 9.71 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6446399935883353		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 1.6446399935883353 | validation: 1.2204293575429128]
	TIME [epoch: 9.7 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3013994129484512		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 1.3013994129484512 | validation: 1.05992173485673]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_262.pth
	Model improved!!!
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6743107957984407		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 1.6743107957984407 | validation: 1.3904910539056488]
	TIME [epoch: 9.72 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.504075142845629		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 1.504075142845629 | validation: 1.3918266174163472]
	TIME [epoch: 9.7 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6293408034204877		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 1.6293408034204877 | validation: 1.8905928172744144]
	TIME [epoch: 9.69 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5893082592244365		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 1.5893082592244365 | validation: 1.2194738979486641]
	TIME [epoch: 9.72 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2831014804884195		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 1.2831014804884195 | validation: 1.4183251368840035]
	TIME [epoch: 9.72 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1712038947482302		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 1.1712038947482302 | validation: 1.306270703703966]
	TIME [epoch: 9.71 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6886702755023482		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 1.6886702755023482 | validation: 1.316122589822636]
	TIME [epoch: 9.7 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3367626230990082		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 1.3367626230990082 | validation: 1.189670646801001]
	TIME [epoch: 9.72 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4045412191837174		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 1.4045412191837174 | validation: 1.3044036415891147]
	TIME [epoch: 9.7 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.396911925465147		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 1.396911925465147 | validation: 1.4398437023720427]
	TIME [epoch: 9.72 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2411832617600158		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 1.2411832617600158 | validation: 1.2496994132091779]
	TIME [epoch: 9.7 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2688865204315656		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 1.2688865204315656 | validation: 1.4842934392198097]
	TIME [epoch: 9.72 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.504348648074728		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 1.504348648074728 | validation: 3.246933098567126]
	TIME [epoch: 9.71 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1464779725701004		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 3.1464779725701004 | validation: 1.4931925152239658]
	TIME [epoch: 9.71 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3915106936985588		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 1.3915106936985588 | validation: 1.3417456626507618]
	TIME [epoch: 9.72 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2697096695130445		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 1.2697096695130445 | validation: 1.3121561817668022]
	TIME [epoch: 9.72 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5559882292308207		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 1.5559882292308207 | validation: 1.8356724397209767]
	TIME [epoch: 9.7 sec]
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6566644850905274		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 1.6566644850905274 | validation: 1.3120442592894141]
	TIME [epoch: 9.71 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.245022673685822		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 1.245022673685822 | validation: 1.8728664326750915]
	TIME [epoch: 9.72 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1116097490330152		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 2.1116097490330152 | validation: 3.016137121177718]
	TIME [epoch: 9.72 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.345301464428172		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 2.345301464428172 | validation: 1.555994766896643]
	TIME [epoch: 9.71 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.571731025537281		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 1.571731025537281 | validation: 1.1968893866864203]
	TIME [epoch: 9.7 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4664760384985627		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 1.4664760384985627 | validation: 1.4950352483046951]
	TIME [epoch: 9.73 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.621637867202858		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 1.621637867202858 | validation: 2.1407239440964254]
	TIME [epoch: 9.71 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.473829966979317		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 1.473829966979317 | validation: 1.151168604342054]
	TIME [epoch: 9.72 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2138678236534013		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 1.2138678236534013 | validation: 1.4973428179997776]
	TIME [epoch: 9.71 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4190831449686274		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 1.4190831449686274 | validation: 1.1381944521696785]
	TIME [epoch: 9.73 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5184928402123083		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 1.5184928402123083 | validation: 1.0762358737015059]
	TIME [epoch: 9.71 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5877760034859705		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 1.5877760034859705 | validation: 1.1343005622580546]
	TIME [epoch: 9.7 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4174250205242673		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 1.4174250205242673 | validation: 1.0303889281871006]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_292.pth
	Model improved!!!
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8496657635205884		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 1.8496657635205884 | validation: 1.2427671016652304]
	TIME [epoch: 9.74 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.588851445034058		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 1.588851445034058 | validation: 1.5159570297980929]
	TIME [epoch: 9.71 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5536710216059926		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 1.5536710216059926 | validation: 1.6279610095639754]
	TIME [epoch: 9.7 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6013126328931968		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 1.6013126328931968 | validation: 1.609423603566796]
	TIME [epoch: 9.72 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4646488381502736		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 1.4646488381502736 | validation: 1.608631725533842]
	TIME [epoch: 9.7 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5393500535591857		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 1.5393500535591857 | validation: 1.3571130377297267]
	TIME [epoch: 9.7 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5352295160637135		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 1.5352295160637135 | validation: 1.488852703829782]
	TIME [epoch: 9.7 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2630368898832895		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 1.2630368898832895 | validation: 1.2161333373943333]
	TIME [epoch: 9.72 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5748224032581435		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 1.5748224032581435 | validation: 1.5622345494063212]
	TIME [epoch: 9.7 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3850536868719483		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 1.3850536868719483 | validation: 1.156391960614066]
	TIME [epoch: 9.7 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2041473930842037		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 1.2041473930842037 | validation: 1.3197168888301047]
	TIME [epoch: 9.7 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2666491749949285		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 1.2666491749949285 | validation: 1.0826111896310129]
	TIME [epoch: 9.72 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1163013508635609		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 1.1163013508635609 | validation: 1.3008309798993123]
	TIME [epoch: 9.7 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3232633207413445		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 1.3232633207413445 | validation: 1.9216364803982462]
	TIME [epoch: 9.7 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.491908654219005		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 1.491908654219005 | validation: 1.1449423155365568]
	TIME [epoch: 9.71 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3016413880331235		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 1.3016413880331235 | validation: 2.3604994031185815]
	TIME [epoch: 9.71 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6589471005523102		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 1.6589471005523102 | validation: 1.1457815999014525]
	TIME [epoch: 9.7 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3010032576451973		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 1.3010032576451973 | validation: 2.233158764239418]
	TIME [epoch: 9.7 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7162883178236292		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 1.7162883178236292 | validation: 1.721070833400795]
	TIME [epoch: 9.71 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3975354144901702		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 1.3975354144901702 | validation: 1.2937791845627544]
	TIME [epoch: 9.69 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.288215528099327		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 1.288215528099327 | validation: 1.0079174963991142]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_313.pth
	Model improved!!!
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5388137453206476		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 1.5388137453206476 | validation: 1.4436194409645546]
	TIME [epoch: 9.71 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.415005163492848		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 1.415005163492848 | validation: 1.7086924640429098]
	TIME [epoch: 9.71 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.716225698997371		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 1.716225698997371 | validation: 1.226063832997813]
	TIME [epoch: 9.7 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3607525203114545		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 1.3607525203114545 | validation: 1.239260434066277]
	TIME [epoch: 9.7 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3594262584130223		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 1.3594262584130223 | validation: 1.5810041362732188]
	TIME [epoch: 9.7 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2956838321423452		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 1.2956838321423452 | validation: 0.9739600170992125]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_319.pth
	Model improved!!!
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1978014825510122		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 1.1978014825510122 | validation: 1.525206889430273]
	TIME [epoch: 9.71 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2764397653998458		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 1.2764397653998458 | validation: 1.0146215940301344]
	TIME [epoch: 9.7 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5406717493598885		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 2.5406717493598885 | validation: 3.440859933343371]
	TIME [epoch: 9.72 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9749321254664816		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 3.9749321254664816 | validation: 3.9059487952492704]
	TIME [epoch: 9.7 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.093171271459278		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 4.093171271459278 | validation: 3.3733221228708024]
	TIME [epoch: 9.7 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.518645377248882		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 2.518645377248882 | validation: 1.5548184131825133]
	TIME [epoch: 9.7 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6418759230078463		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 1.6418759230078463 | validation: 1.2440636254465696]
	TIME [epoch: 9.72 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.329818269613894		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 1.329818269613894 | validation: 2.327418472521188]
	TIME [epoch: 9.7 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.263103083848954		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 2.263103083848954 | validation: 1.2485122441867416]
	TIME [epoch: 9.71 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3796346295860495		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 1.3796346295860495 | validation: 1.3683538216694535]
	TIME [epoch: 9.7 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4124093928467762		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 1.4124093928467762 | validation: 1.7284565602647104]
	TIME [epoch: 9.72 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2844917403842626		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 1.2844917403842626 | validation: 1.1120516087406107]
	TIME [epoch: 9.71 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3445213523988042		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 1.3445213523988042 | validation: 1.0405421587196073]
	TIME [epoch: 9.7 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.428782460712932		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 1.428782460712932 | validation: 1.3433560773312128]
	TIME [epoch: 9.72 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1251800627410244		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 1.1251800627410244 | validation: 0.9672314514582746]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_334.pth
	Model improved!!!
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3577694133525502		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 1.3577694133525502 | validation: 1.3241505283744441]
	TIME [epoch: 9.71 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4532234125438648		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 1.4532234125438648 | validation: 0.9598880074707664]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_336.pth
	Model improved!!!
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0571052644859735		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 1.0571052644859735 | validation: 1.5562761467745483]
	TIME [epoch: 9.73 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4432627712828048		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 1.4432627712828048 | validation: 1.019667939489036]
	TIME [epoch: 9.7 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4829761633690164		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 1.4829761633690164 | validation: 1.147567831368526]
	TIME [epoch: 9.7 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1106522575006075		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 1.1106522575006075 | validation: 1.0254053472824014]
	TIME [epoch: 9.69 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1359028563228464		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 1.1359028563228464 | validation: 1.5712719625934906]
	TIME [epoch: 9.73 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3104502084543228		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 1.3104502084543228 | validation: 1.3966927238556253]
	TIME [epoch: 9.71 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.216914285400159		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 1.216914285400159 | validation: 1.0016798879181226]
	TIME [epoch: 9.7 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.305982455758209		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 1.305982455758209 | validation: 1.1613382578043348]
	TIME [epoch: 9.71 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2428590937822979		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 1.2428590937822979 | validation: 0.9748820125955906]
	TIME [epoch: 9.72 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2427168588570265		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 1.2427168588570265 | validation: 1.6573023515419656]
	TIME [epoch: 9.71 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2511295914614222		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 1.2511295914614222 | validation: 1.2242972205705578]
	TIME [epoch: 9.7 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3542546789128143		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 1.3542546789128143 | validation: 1.2197593836754828]
	TIME [epoch: 9.71 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1098754173324277		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 1.1098754173324277 | validation: 1.3019392324602503]
	TIME [epoch: 9.73 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1922694475227524		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 1.1922694475227524 | validation: 1.8669272557537526]
	TIME [epoch: 9.7 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.291248590362369		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 1.291248590362369 | validation: 2.2251647846159397]
	TIME [epoch: 9.7 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4693735882828383		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 1.4693735882828383 | validation: 1.2440508799927594]
	TIME [epoch: 9.72 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1408302126511973		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 1.1408302126511973 | validation: 1.5774209578344387]
	TIME [epoch: 9.7 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2446932836653277		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 1.2446932836653277 | validation: 0.9102111034721262]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_354.pth
	Model improved!!!
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0984146185042147		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 1.0984146185042147 | validation: 1.4112747270952313]
	TIME [epoch: 9.71 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1955353843502974		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 1.1955353843502974 | validation: 1.797936873200526]
	TIME [epoch: 9.72 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.179584063684731		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 1.179584063684731 | validation: 1.2477412694546826]
	TIME [epoch: 9.71 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.314275722622676		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 1.314275722622676 | validation: 1.0801298547144966]
	TIME [epoch: 9.7 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.22227319193212		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 1.22227319193212 | validation: 1.0138683775232693]
	TIME [epoch: 9.73 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9990396380883055		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 0.9990396380883055 | validation: 1.1628766015116854]
	TIME [epoch: 9.71 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4929150435800256		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 1.4929150435800256 | validation: 1.0276919058166094]
	TIME [epoch: 9.71 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3583640472501028		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 1.3583640472501028 | validation: 1.346544374741701]
	TIME [epoch: 9.71 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2406045491879594		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 1.2406045491879594 | validation: 1.2393392183815257]
	TIME [epoch: 9.73 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.370413492756506		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 1.370413492756506 | validation: 1.0026663578113966]
	TIME [epoch: 9.71 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2658976990159858		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 1.2658976990159858 | validation: 0.9307738173354421]
	TIME [epoch: 9.71 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1621708376985669		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 1.1621708376985669 | validation: 0.987166875477919]
	TIME [epoch: 9.71 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.510845975774878		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 1.510845975774878 | validation: 0.8628016249087134]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_367.pth
	Model improved!!!
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1358636791373187		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 1.1358636791373187 | validation: 0.9699877575537427]
	TIME [epoch: 9.7 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0476873598169445		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 1.0476873598169445 | validation: 0.924662927185558]
	TIME [epoch: 9.69 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2008944978290352		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 1.2008944978290352 | validation: 1.6790486949590309]
	TIME [epoch: 9.71 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.229377461862262		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 1.229377461862262 | validation: 0.9034536516857073]
	TIME [epoch: 9.71 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0846203165301194		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 1.0846203165301194 | validation: 1.0749075722237986]
	TIME [epoch: 9.71 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8368384130470878		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 1.8368384130470878 | validation: 1.6541307421150495]
	TIME [epoch: 9.69 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1731111361909057		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 1.1731111361909057 | validation: 1.2115080459676408]
	TIME [epoch: 9.71 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1644663415613064		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 1.1644663415613064 | validation: 1.4469116241733604]
	TIME [epoch: 9.7 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.464609467960725		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 1.464609467960725 | validation: 1.0858895834070525]
	TIME [epoch: 9.71 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1715241093348705		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 1.1715241093348705 | validation: 0.9063828468184427]
	TIME [epoch: 9.7 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4100050375455662		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 1.4100050375455662 | validation: 1.7973655913554953]
	TIME [epoch: 9.72 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3162128394171893		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 1.3162128394171893 | validation: 1.1402063882913682]
	TIME [epoch: 9.7 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1306425561662306		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 1.1306425561662306 | validation: 1.629855408611756]
	TIME [epoch: 9.7 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2171043523068596		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 1.2171043523068596 | validation: 1.1294206164107852]
	TIME [epoch: 9.71 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1122536544754633		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 1.1122536544754633 | validation: 0.9639151643866452]
	TIME [epoch: 9.72 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0940547536650418		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 1.0940547536650418 | validation: 2.8182509458918985]
	TIME [epoch: 9.71 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6607726477394649		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 1.6607726477394649 | validation: 0.9379180903056255]
	TIME [epoch: 9.7 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.252226247596901		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 1.252226247596901 | validation: 1.5482437291709326]
	TIME [epoch: 9.72 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1215187232603288		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 1.1215187232603288 | validation: 0.9353483692125236]
	TIME [epoch: 9.71 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.11312268106454		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 1.11312268106454 | validation: 1.111421398537409]
	TIME [epoch: 9.71 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2061325934855849		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 1.2061325934855849 | validation: 1.249200865814429]
	TIME [epoch: 9.71 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.167852654857961		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 1.167852654857961 | validation: 1.1072283498341735]
	TIME [epoch: 9.73 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2903242328404358		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 1.2903242328404358 | validation: 1.0936636993102231]
	TIME [epoch: 9.71 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.141309721097963		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 1.141309721097963 | validation: 1.4581874791274978]
	TIME [epoch: 9.71 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.237015335236096		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 1.237015335236096 | validation: 1.6635700173347834]
	TIME [epoch: 9.7 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1044983005307594		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 1.1044983005307594 | validation: 1.206614702061828]
	TIME [epoch: 9.72 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1523512461181045		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 1.1523512461181045 | validation: 1.2876606385725093]
	TIME [epoch: 9.71 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1476807880566724		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 1.1476807880566724 | validation: 0.9050293598215311]
	TIME [epoch: 9.71 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.235150118165827		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 1.235150118165827 | validation: 2.427645023476567]
	TIME [epoch: 9.72 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4873964782388		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 1.4873964782388 | validation: 1.295613689887238]
	TIME [epoch: 9.73 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2643565618908719		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 1.2643565618908719 | validation: 1.2297772967483658]
	TIME [epoch: 9.71 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0039486244713098		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 1.0039486244713098 | validation: 1.2351081135672153]
	TIME [epoch: 9.71 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.024609118943768		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 1.024609118943768 | validation: 1.0375182528214293]
	TIME [epoch: 9.73 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9573933066175604		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 0.9573933066175604 | validation: 0.9397766688750782]
	TIME [epoch: 9.71 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.974542826136464		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 0.974542826136464 | validation: 0.8023289902812418]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_402.pth
	Model improved!!!
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.946621428208841		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 0.946621428208841 | validation: 1.5954900785297588]
	TIME [epoch: 10 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1532446650120978		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 1.1532446650120978 | validation: 1.684688414888675]
	TIME [epoch: 9.74 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0265671032440422		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 1.0265671032440422 | validation: 1.2865022822204888]
	TIME [epoch: 9.71 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0692753563685184		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 1.0692753563685184 | validation: 1.1767564324015272]
	TIME [epoch: 9.72 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9692054489070328		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 0.9692054489070328 | validation: 1.2049017855010151]
	TIME [epoch: 9.72 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9816721073548755		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 0.9816721073548755 | validation: 0.8991547589496577]
	TIME [epoch: 9.73 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9817091752246834		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 0.9817091752246834 | validation: 1.093438036025522]
	TIME [epoch: 9.71 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9593447436076403		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 0.9593447436076403 | validation: 1.0416550246373957]
	TIME [epoch: 9.71 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1317438380024714		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 1.1317438380024714 | validation: 0.8352136961714098]
	TIME [epoch: 9.73 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9603254884450136		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 0.9603254884450136 | validation: 0.7850534512469737]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_412.pth
	Model improved!!!
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2719483994433065		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 1.2719483994433065 | validation: 1.3521628867055677]
	TIME [epoch: 9.72 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2302949178895901		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 1.2302949178895901 | validation: 0.8648373364541633]
	TIME [epoch: 9.71 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0284493042810814		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 1.0284493042810814 | validation: 0.8951760756211212]
	TIME [epoch: 9.74 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9644642093891266		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 0.9644642093891266 | validation: 1.1310653329494589]
	TIME [epoch: 9.72 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9565325486393371		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 0.9565325486393371 | validation: 0.9692328657329827]
	TIME [epoch: 9.71 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9200503490760473		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 0.9200503490760473 | validation: 0.8542299291824793]
	TIME [epoch: 9.72 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1986020285708954		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 1.1986020285708954 | validation: 1.7089861657241856]
	TIME [epoch: 9.74 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0889199936791731		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 1.0889199936791731 | validation: 0.8829680753107135]
	TIME [epoch: 9.71 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9165597457977526		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 0.9165597457977526 | validation: 1.0071443377500753]
	TIME [epoch: 9.72 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1111984802820674		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 1.1111984802820674 | validation: 1.8064603240464396]
	TIME [epoch: 9.73 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1351781310064186		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 1.1351781310064186 | validation: 1.2980245881141084]
	TIME [epoch: 9.72 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0293822591685307		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 1.0293822591685307 | validation: 0.7663867558566858]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_424.pth
	Model improved!!!
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1998776629787478		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 1.1998776629787478 | validation: 1.0020348429611416]
	TIME [epoch: 9.72 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3665088694138994		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 1.3665088694138994 | validation: 1.4580437665146257]
	TIME [epoch: 9.74 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1061609048901802		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 1.1061609048901802 | validation: 1.0609465984539466]
	TIME [epoch: 9.72 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9535547672721523		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 0.9535547672721523 | validation: 1.0938670925488188]
	TIME [epoch: 9.72 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.154543873534828		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 1.154543873534828 | validation: 1.5478311625430143]
	TIME [epoch: 9.71 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0354851627397879		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 1.0354851627397879 | validation: 0.7602148397433409]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_430.pth
	Model improved!!!
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8652155129917775		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 0.8652155129917775 | validation: 0.9163238002679961]
	TIME [epoch: 9.72 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.883805801140525		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 0.883805801140525 | validation: 1.1766251177468414]
	TIME [epoch: 9.72 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9600027149943255		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 0.9600027149943255 | validation: 0.940587568437601]
	TIME [epoch: 9.72 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1289077721717937		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 1.1289077721717937 | validation: 0.9095375757716165]
	TIME [epoch: 9.75 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9560197203995408		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 0.9560197203995408 | validation: 0.6678448033705584]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_435.pth
	Model improved!!!
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0499970881544627		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 1.0499970881544627 | validation: 0.7519282857545886]
	TIME [epoch: 9.72 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1554453370493245		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 1.1554453370493245 | validation: 0.7893250772190078]
	TIME [epoch: 9.73 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0327186278822071		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 1.0327186278822071 | validation: 0.9487912517802013]
	TIME [epoch: 9.73 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2912390107947986		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 1.2912390107947986 | validation: 2.0315708074410934]
	TIME [epoch: 9.71 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1712728890133366		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 1.1712728890133366 | validation: 2.709016102440474]
	TIME [epoch: 9.71 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5669055950494903		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 1.5669055950494903 | validation: 1.0573260989109177]
	TIME [epoch: 9.74 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9750760471147816		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 0.9750760471147816 | validation: 0.9964375285737067]
	TIME [epoch: 9.72 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0391650408386712		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 1.0391650408386712 | validation: 1.0165826617436784]
	TIME [epoch: 9.71 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.990461284290663		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 0.990461284290663 | validation: 1.0348559874194874]
	TIME [epoch: 9.72 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9670085333892235		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 0.9670085333892235 | validation: 0.9968011971857]
	TIME [epoch: 9.74 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8380840309591795		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 0.8380840309591795 | validation: 1.9415215601984641]
	TIME [epoch: 9.72 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0656535283762592		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 1.0656535283762592 | validation: 3.1308240849799587]
	TIME [epoch: 9.71 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9011290302954968		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 1.9011290302954968 | validation: 1.2516247303461387]
	TIME [epoch: 9.73 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0456844035922046		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 1.0456844035922046 | validation: 0.7870362496193534]
	TIME [epoch: 9.72 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7669107463097593		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 0.7669107463097593 | validation: 3.2952644698270777]
	TIME [epoch: 9.72 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5116042980650262		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 1.5116042980650262 | validation: 1.3091336282524875]
	TIME [epoch: 9.71 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9743561498314097		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 0.9743561498314097 | validation: 0.8889024441452302]
	TIME [epoch: 9.73 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9556541900244447		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 0.9556541900244447 | validation: 1.0529066373871014]
	TIME [epoch: 9.71 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5542072593983778		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 1.5542072593983778 | validation: 1.6603030626228634]
	TIME [epoch: 9.72 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1842008019905648		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 1.1842008019905648 | validation: 0.9718116328666133]
	TIME [epoch: 9.71 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8806734112055377		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 0.8806734112055377 | validation: 0.8268977219903727]
	TIME [epoch: 9.74 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9468856237773848		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 1.9468856237773848 | validation: 1.2667119722291642]
	TIME [epoch: 9.71 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0975095793055127		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 1.0975095793055127 | validation: 1.5336308894465647]
	TIME [epoch: 9.72 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1710053250872634		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 1.1710053250872634 | validation: 2.847427097941411]
	TIME [epoch: 9.71 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1440855288389673		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 1.1440855288389673 | validation: 2.3579240371672148]
	TIME [epoch: 9.73 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3953972232058387		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 1.3953972232058387 | validation: 1.5082964262180911]
	TIME [epoch: 9.72 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9163127689387607		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 1.9163127689387607 | validation: 2.397535321177463]
	TIME [epoch: 9.71 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2943070577709368		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 1.2943070577709368 | validation: 0.8348526239733575]
	TIME [epoch: 9.73 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.292167528277304		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 1.292167528277304 | validation: 3.05975070403577]
	TIME [epoch: 9.72 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5349289216427118		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 1.5349289216427118 | validation: 1.201997327316529]
	TIME [epoch: 9.71 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4285047727590623		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 1.4285047727590623 | validation: 1.1431425046675265]
	TIME [epoch: 9.71 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1009787195849032		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 1.1009787195849032 | validation: 1.0440590034724513]
	TIME [epoch: 9.74 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9657211233808635		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 0.9657211233808635 | validation: 3.395748067476566]
	TIME [epoch: 9.71 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9573259202437463		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 1.9573259202437463 | validation: 2.1964019729232684]
	TIME [epoch: 9.72 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3103962474741184		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 1.3103962474741184 | validation: 1.0126706511613037]
	TIME [epoch: 9.72 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2532963991429553		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 1.2532963991429553 | validation: 1.2833618294768194]
	TIME [epoch: 9.74 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1628279314105356		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 1.1628279314105356 | validation: 1.0537572964013844]
	TIME [epoch: 9.71 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9649078661834792		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 0.9649078661834792 | validation: 0.8701112344072006]
	TIME [epoch: 9.71 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6462913651575768		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 1.6462913651575768 | validation: 4.566239344158191]
	TIME [epoch: 9.73 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3545169888585007		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 2.3545169888585007 | validation: 2.7067033495837602]
	TIME [epoch: 9.73 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.192586557423081		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 1.192586557423081 | validation: 0.7910664753579337]
	TIME [epoch: 9.72 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1359542893733883		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 1.1359542893733883 | validation: 0.826767248342849]
	TIME [epoch: 9.72 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5914602059125074		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 1.5914602059125074 | validation: 1.236247389101955]
	TIME [epoch: 9.73 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9776019160709181		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 0.9776019160709181 | validation: 3.0895181660800692]
	TIME [epoch: 9.72 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5978916812712154		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 1.5978916812712154 | validation: 0.9808501851013836]
	TIME [epoch: 9.71 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0703169994137756		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 1.0703169994137756 | validation: 1.14524168138606]
	TIME [epoch: 9.72 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1958837421790374		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 1.1958837421790374 | validation: 1.1256781479995113]
	TIME [epoch: 9.74 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0804265768656198		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 1.0804265768656198 | validation: 3.5234840705452464]
	TIME [epoch: 9.71 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1914071762887857		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 2.1914071762887857 | validation: 1.6427775237336835]
	TIME [epoch: 9.71 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3485311811874297		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 1.3485311811874297 | validation: 1.3678906354318303]
	TIME [epoch: 9.71 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4574381683945827		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 1.4574381683945827 | validation: 0.9816433377117949]
	TIME [epoch: 9.73 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.601335468885867		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 1.601335468885867 | validation: 1.1647295516002023]
	TIME [epoch: 9.71 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2556595763727554		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 1.2556595763727554 | validation: 1.4297810173709014]
	TIME [epoch: 9.71 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7091660312694092		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 1.7091660312694092 | validation: 1.8175328095828855]
	TIME [epoch: 9.72 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1412229201574027		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 1.1412229201574027 | validation: 1.061659269890508]
	TIME [epoch: 9.71 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.135663380132288		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 2.135663380132288 | validation: 1.129937231088457]
	TIME [epoch: 9.7 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9118329012453309		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 0.9118329012453309 | validation: 1.0502344966349602]
	TIME [epoch: 9.7 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9706233967219242		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 0.9706233967219242 | validation: 0.9414250553411125]
	TIME [epoch: 9.72 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1781278037849277		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 1.1781278037849277 | validation: 0.7842018470167428]
	TIME [epoch: 9.7 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.090067434581294		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 1.090067434581294 | validation: 3.589455036627804]
	TIME [epoch: 9.7 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.389069602328948		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 2.389069602328948 | validation: 1.342441068811364]
	TIME [epoch: 9.71 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4496839463274873		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 1.4496839463274873 | validation: 1.059171589359562]
	TIME [epoch: 9.73 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2635024091405591		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 1.2635024091405591 | validation: 0.8905966352405013]
	TIME [epoch: 9.7 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9905269953904545		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 0.9905269953904545 | validation: 1.089530853155605]
	TIME [epoch: 9.71 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2933937086384844		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 1.2933937086384844 | validation: 3.5533252244667053]
	TIME [epoch: 9.72 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5300939254652668		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 1.5300939254652668 | validation: 1.8438710742174298]
	TIME [epoch: 9.72 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.393756037995249		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 1.393756037995249 | validation: 1.0323667620288903]
	TIME [epoch: 9.71 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9565592094383357		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 0.9565592094383357 | validation: 1.1406765139320296]
	TIME [epoch: 9.7 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.043979713842029		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 1.043979713842029 | validation: 2.484818409972638]
	TIME [epoch: 9.73 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2358742858440677		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 1.2358742858440677 | validation: 0.9284609601819662]
	TIME [epoch: 9.7 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0545230217765802		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 1.0545230217765802 | validation: 0.9151794282845365]
	TIME [epoch: 9.7 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9257159309401836		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 0.9257159309401836 | validation: 1.0217678659293052]
	TIME [epoch: 9.7 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2037348685437028		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 1.2037348685437028 | validation: 1.114583994935764]
	TIME [epoch: 9.72 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4236590430951979		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 1.4236590430951979 | validation: 1.4371141497316666]
	TIME [epoch: 9.71 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1167039314649199		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 1.1167039314649199 | validation: 0.9882958924949037]
	TIME [epoch: 9.7 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.160940415732074		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 1.160940415732074 | validation: 0.9135172702070792]
	TIME [epoch: 9.71 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2367197315458005		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 1.2367197315458005 | validation: 2.077452888671356]
	TIME [epoch: 9.72 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4659894493930026		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 1.4659894493930026 | validation: 1.2485306542222847]
	TIME [epoch: 9.71 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2064189968621315		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 1.2064189968621315 | validation: 0.9699616065695537]
	TIME [epoch: 9.7 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.501632509641989		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 1.501632509641989 | validation: 0.9892360238176987]
	TIME [epoch: 9.72 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1241408592491404		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 1.1241408592491404 | validation: 0.8388482314275174]
	TIME [epoch: 9.71 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2577994106310688		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 1.2577994106310688 | validation: 3.404093966415775]
	TIME [epoch: 9.7 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3569844700274105		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 2.3569844700274105 | validation: 3.736222033484513]
	TIME [epoch: 9.7 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9164649999989432		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 1.9164649999989432 | validation: 3.7433712498246736]
	TIME [epoch: 9.72 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.326446255005817		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 3.326446255005817 | validation: 1.738956645652632]
	TIME [epoch: 9.7 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1921071355259945		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 1.1921071355259945 | validation: 0.8910293222764014]
	TIME [epoch: 9.7 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7266536806721355		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 1.7266536806721355 | validation: 3.0785054616170955]
	TIME [epoch: 9.7 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5607733070978527		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 1.5607733070978527 | validation: 1.3783945247625147]
	TIME [epoch: 9.73 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9891419440534953		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 0.9891419440534953 | validation: 1.1294740061441013]
	TIME [epoch: 9.71 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.728633737265321		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 1.728633737265321 | validation: 0.987777931995218]
	TIME [epoch: 9.71 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1828505209030542		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 1.1828505209030542 | validation: 0.9211153423385909]
	TIME [epoch: 9.72 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4515839944456868		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 1.4515839944456868 | validation: 1.364719217150758]
	TIME [epoch: 9.72 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2052661436248766		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 1.2052661436248766 | validation: 1.0120534821283844]
	TIME [epoch: 9.71 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4569151438335435		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 1.4569151438335435 | validation: 2.348841952943346]
	TIME [epoch: 9.7 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.234534448667548		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 1.234534448667548 | validation: 1.3413601013071073]
	TIME [epoch: 9.74 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0651009999863459		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 1.0651009999863459 | validation: 0.9504955528668524]
	TIME [epoch: 9.72 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9066469267338585		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 0.9066469267338585 | validation: 0.7697423146169153]
	TIME [epoch: 9.71 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.78433019098305		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 1.78433019098305 | validation: 1.0259553972046942]
	TIME [epoch: 9.73 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9754549065472687		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 0.9754549065472687 | validation: 1.1709378660524936]
	TIME [epoch: 9.75 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9714066717791244		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 0.9714066717791244 | validation: 1.3642330133291731]
	TIME [epoch: 9.73 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6752692284722825		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 1.6752692284722825 | validation: 0.932040088797358]
	TIME [epoch: 9.73 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0033602966418798		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 1.0033602966418798 | validation: 1.0536061671162162]
	TIME [epoch: 9.74 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.052216322257411		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 1.052216322257411 | validation: 0.8530043231362012]
	TIME [epoch: 9.74 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9369264668463786		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 1.9369264668463786 | validation: 1.0241243483911322]
	TIME [epoch: 9.73 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9212717759165692		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 0.9212717759165692 | validation: 1.447118251825135]
	TIME [epoch: 9.72 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1092808550368005		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 1.1092808550368005 | validation: 0.9705643497762715]
	TIME [epoch: 9.74 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1139289862920625		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 1.1139289862920625 | validation: 0.8673223217318841]
	TIME [epoch: 9.73 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9711940905373566		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 0.9711940905373566 | validation: 3.8308015346424]
	TIME [epoch: 9.72 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.417354201077866		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 2.417354201077866 | validation: 0.9990890898290314]
	TIME [epoch: 9.72 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3241957431783284		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 1.3241957431783284 | validation: 3.0153689987564394]
	TIME [epoch: 9.74 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.619850579508271		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 1.619850579508271 | validation: 1.4309002006445197]
	TIME [epoch: 9.72 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2899451063633465		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 1.2899451063633465 | validation: 0.9304829976452087]
	TIME [epoch: 9.72 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9804441153640763		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.9804441153640763 | validation: 1.2289256098575334]
	TIME [epoch: 9.71 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2544883920438434		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 1.2544883920438434 | validation: 1.7177419059536954]
	TIME [epoch: 9.74 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0373316723272021		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 1.0373316723272021 | validation: 1.0570989165189542]
	TIME [epoch: 9.72 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.18034720660657		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 1.18034720660657 | validation: 1.044343166191515]
	TIME [epoch: 9.72 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9146339699053009		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.9146339699053009 | validation: 1.035759822453845]
	TIME [epoch: 9.73 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7822121723750617		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 1.7822121723750617 | validation: 1.6812790057040388]
	TIME [epoch: 9.75 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2620947075519235		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 1.2620947075519235 | validation: 1.5272707828180776]
	TIME [epoch: 9.72 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6269093326787263		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 1.6269093326787263 | validation: 3.8235505566718544]
	TIME [epoch: 9.72 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0096120761062566		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 3.0096120761062566 | validation: 0.8768236527051605]
	TIME [epoch: 9.74 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9811421618277905		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 0.9811421618277905 | validation: 1.1435032070561864]
	TIME [epoch: 9.72 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0572366483532742		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 1.0572366483532742 | validation: 1.4087852563086307]
	TIME [epoch: 9.72 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.079465048018536		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 2.079465048018536 | validation: 1.1447146304779172]
	TIME [epoch: 9.72 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0107074534405898		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 1.0107074534405898 | validation: 1.0971826411311285]
	TIME [epoch: 9.75 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2042126672601507		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 1.2042126672601507 | validation: 1.055566887061309]
	TIME [epoch: 9.73 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0284225598816916		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 1.0284225598816916 | validation: 0.8615338458636452]
	TIME [epoch: 9.71 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.152734487872227		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 2.152734487872227 | validation: 1.5623802825963153]
	TIME [epoch: 9.73 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2413863031541368		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 1.2413863031541368 | validation: 1.1331644988821126]
	TIME [epoch: 9.74 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9588964983549069		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.9588964983549069 | validation: 1.263445897553794]
	TIME [epoch: 9.73 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1484274232180858		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 1.1484274232180858 | validation: 0.9565620425730037]
	TIME [epoch: 9.72 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.893757868841518		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.893757868841518 | validation: 3.108758577799572]
	TIME [epoch: 9.75 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.698728623635052		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 1.698728623635052 | validation: 1.1829706907120643]
	TIME [epoch: 9.73 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9484632814998676		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.9484632814998676 | validation: 0.9121972431545889]
	TIME [epoch: 9.73 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7030843446823525		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 1.7030843446823525 | validation: 3.980599877930083]
	TIME [epoch: 9.72 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3245239164486047		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 2.3245239164486047 | validation: 1.7853748336586597]
	TIME [epoch: 9.74 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0756173859742542		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 1.0756173859742542 | validation: 1.0488797899210263]
	TIME [epoch: 9.72 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9776875057151833		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 0.9776875057151833 | validation: 1.1302618319118949]
	TIME [epoch: 9.71 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9578883190635166		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.9578883190635166 | validation: 3.066034910763631]
	TIME [epoch: 9.72 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3533286529848043		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 1.3533286529848043 | validation: 0.845211652472976]
	TIME [epoch: 9.74 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9976238123075605		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.9976238123075605 | validation: 0.9201631353053961]
	TIME [epoch: 9.72 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3597876081891336		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 1.3597876081891336 | validation: 3.51201120414897]
	TIME [epoch: 9.72 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7912873648650862		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 1.7912873648650862 | validation: 0.80485662702176]
	TIME [epoch: 9.72 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9100877774529923		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 0.9100877774529923 | validation: 0.9921093121387123]
	TIME [epoch: 9.75 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9629333590107197		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.9629333590107197 | validation: 2.5430419228022547]
	TIME [epoch: 9.72 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6462513178980829		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 1.6462513178980829 | validation: 2.152108324775483]
	TIME [epoch: 9.72 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0966001806831642		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 1.0966001806831642 | validation: 0.8208050088584861]
	TIME [epoch: 9.74 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9432113404180905		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.9432113404180905 | validation: 0.9366236745826834]
	TIME [epoch: 9.72 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.941089602448557		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 0.941089602448557 | validation: 1.211411537335858]
	TIME [epoch: 9.71 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2591784332955416		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 1.2591784332955416 | validation: 1.024545675343355]
	TIME [epoch: 9.71 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9397825152291617		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.9397825152291617 | validation: 0.8002998487200473]
	TIME [epoch: 9.74 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7598774324325		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 1.7598774324325 | validation: 1.4107697595913617]
	TIME [epoch: 9.72 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9120184738021436		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 0.9120184738021436 | validation: 0.864632458207804]
	TIME [epoch: 9.71 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8353102484739509		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.8353102484739509 | validation: 0.7674078566478342]
	TIME [epoch: 9.72 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8802573598996114		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.8802573598996114 | validation: 0.8607074604400725]
	TIME [epoch: 9.73 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9111511155951051		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.9111511155951051 | validation: 1.1959176353452465]
	TIME [epoch: 9.72 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0511191224406815		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 1.0511191224406815 | validation: 0.9240467874190657]
	TIME [epoch: 9.72 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9400305675747914		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.9400305675747914 | validation: 0.9731530053621075]
	TIME [epoch: 9.73 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8943833210640099		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.8943833210640099 | validation: 0.8399204911986133]
	TIME [epoch: 9.72 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2116946004610685		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 1.2116946004610685 | validation: 1.2819354219701022]
	TIME [epoch: 9.71 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.039993228239449		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 1.039993228239449 | validation: 0.9459850783423128]
	TIME [epoch: 9.72 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9463073194756882		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.9463073194756882 | validation: 0.7349191581296575]
	TIME [epoch: 9.74 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9051915002148633		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.9051915002148633 | validation: 1.0310449092853138]
	TIME [epoch: 9.72 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9528795117253923		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.9528795117253923 | validation: 0.8717663768462248]
	TIME [epoch: 9.72 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9467468303791062		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.9467468303791062 | validation: 0.8741684042645372]
	TIME [epoch: 9.72 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8362366178316787		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.8362366178316787 | validation: 0.8207930015593352]
	TIME [epoch: 9.74 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8258129861781864		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.8258129861781864 | validation: 0.7812116164789512]
	TIME [epoch: 9.71 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7779901677851104		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 0.7779901677851104 | validation: 0.675619891820798]
	TIME [epoch: 9.71 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8819023720771166		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 0.8819023720771166 | validation: 0.8187725566737468]
	TIME [epoch: 9.72 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7374935060543403		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.7374935060543403 | validation: 0.8119940146642225]
	TIME [epoch: 9.73 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7919422950417101		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 0.7919422950417101 | validation: 1.2524163413023244]
	TIME [epoch: 9.71 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8553378760083902		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.8553378760083902 | validation: 0.6942141510414337]
	TIME [epoch: 9.72 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7321747774172893		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.7321747774172893 | validation: 0.7266055905759776]
	TIME [epoch: 9.73 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7344488184898024		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.7344488184898024 | validation: 0.9389961319706935]
	TIME [epoch: 9.71 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7718779860033722		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.7718779860033722 | validation: 0.8263133084402199]
	TIME [epoch: 9.71 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7103445920132503		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.7103445920132503 | validation: 0.6252693893850348]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_611.pth
	Model improved!!!
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.841072030198762		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.841072030198762 | validation: 0.7188080287455162]
	TIME [epoch: 9.73 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8487773451404823		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.8487773451404823 | validation: 0.685811133649514]
	TIME [epoch: 9.7 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6966486950402572		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.6966486950402572 | validation: 0.9282194093982239]
	TIME [epoch: 9.71 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6849740048081421		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.6849740048081421 | validation: 1.4747154450630484]
	TIME [epoch: 9.71 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0772257592846437		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 1.0772257592846437 | validation: 1.476790308478645]
	TIME [epoch: 9.73 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9457535096918829		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.9457535096918829 | validation: 0.7302589722472876]
	TIME [epoch: 9.71 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7903517208240048		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.7903517208240048 | validation: 0.9423937282991431]
	TIME [epoch: 9.71 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8290349171423067		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.8290349171423067 | validation: 0.9576527921649464]
	TIME [epoch: 9.72 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.030790692047408		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 1.030790692047408 | validation: 1.0217398447971828]
	TIME [epoch: 9.71 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8625916224738349		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.8625916224738349 | validation: 1.0068978214337279]
	TIME [epoch: 9.71 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8580555710345461		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.8580555710345461 | validation: 0.6494461123761769]
	TIME [epoch: 9.71 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6993339569336422		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 0.6993339569336422 | validation: 0.8010609490519868]
	TIME [epoch: 9.72 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9551223397982815		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.9551223397982815 | validation: 0.7995211896884673]
	TIME [epoch: 9.7 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.765101493598874		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.765101493598874 | validation: 0.7211878695814073]
	TIME [epoch: 9.7 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7449826941927289		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.7449826941927289 | validation: 0.7029972229414121]
	TIME [epoch: 9.7 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6653710419560056		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 0.6653710419560056 | validation: 0.8397195427661233]
	TIME [epoch: 9.73 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7450068506347481		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.7450068506347481 | validation: 0.6506124356956232]
	TIME [epoch: 9.71 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8041016029056423		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.8041016029056423 | validation: 0.9310156068299306]
	TIME [epoch: 9.7 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7897316233622853		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.7897316233622853 | validation: 0.7517557155251351]
	TIME [epoch: 9.71 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.711854484623682		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.711854484623682 | validation: 0.6124864724849607]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_631.pth
	Model improved!!!
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.680973614461785		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.680973614461785 | validation: 0.7319952089840029]
	TIME [epoch: 9.71 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7153814734023983		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.7153814734023983 | validation: 1.2589473088093524]
	TIME [epoch: 9.71 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8554962378464636		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.8554962378464636 | validation: 0.6137012424045755]
	TIME [epoch: 9.73 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7094612977708283		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.7094612977708283 | validation: 0.6311051331376655]
	TIME [epoch: 9.71 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7158260494292108		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.7158260494292108 | validation: 0.7524658902326369]
	TIME [epoch: 9.7 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6461566778064823		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.6461566778064823 | validation: 0.7205277158452364]
	TIME [epoch: 9.7 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.76576237677623		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.76576237677623 | validation: 0.9542390891923179]
	TIME [epoch: 9.73 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6458094649096282		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.6458094649096282 | validation: 0.6930927768782854]
	TIME [epoch: 9.71 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6932127593743918		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.6932127593743918 | validation: 0.6746808276769329]
	TIME [epoch: 9.7 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6916100028878802		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.6916100028878802 | validation: 0.6447389103474103]
	TIME [epoch: 9.71 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6488419007477867		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.6488419007477867 | validation: 0.627961217761362]
	TIME [epoch: 9.73 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6965979209947818		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.6965979209947818 | validation: 0.6087427755172083]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_643.pth
	Model improved!!!
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7631920020733016		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.7631920020733016 | validation: 0.7333955616019202]
	TIME [epoch: 9.72 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6435716161748263		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.6435716161748263 | validation: 0.8995495058677639]
	TIME [epoch: 9.73 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7409972908515258		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.7409972908515258 | validation: 0.8170302706622922]
	TIME [epoch: 9.71 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7151610401207346		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.7151610401207346 | validation: 0.7073522260209161]
	TIME [epoch: 9.7 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8843769652343303		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.8843769652343303 | validation: 0.7663692757492152]
	TIME [epoch: 9.71 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.70360725590699		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.70360725590699 | validation: 0.8879642811818954]
	TIME [epoch: 9.73 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7423542339328422		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.7423542339328422 | validation: 0.6263811964405529]
	TIME [epoch: 9.71 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5715728713402086		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.5715728713402086 | validation: 0.8492132990495489]
	TIME [epoch: 9.71 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.709395687609508		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.709395687609508 | validation: 0.8163074028199105]
	TIME [epoch: 9.71 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7944498313187613		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.7944498313187613 | validation: 0.6379305712789294]
	TIME [epoch: 9.73 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7522770229669198		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.7522770229669198 | validation: 0.6617389975335837]
	TIME [epoch: 9.71 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7547745968236186		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.7547745968236186 | validation: 0.6533424202519518]
	TIME [epoch: 9.71 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6164059370350711		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.6164059370350711 | validation: 0.5947818270982648]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_656.pth
	Model improved!!!
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5722039285541438		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.5722039285541438 | validation: 0.7261569150942109]
	TIME [epoch: 9.72 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8030481449604137		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.8030481449604137 | validation: 0.7296413428479247]
	TIME [epoch: 9.7 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8773481110420942		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.8773481110420942 | validation: 0.706859915101346]
	TIME [epoch: 9.69 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6658756748046865		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.6658756748046865 | validation: 0.6469302095810319]
	TIME [epoch: 9.72 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7056589512458865		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.7056589512458865 | validation: 0.6422864426864056]
	TIME [epoch: 9.7 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6811437463642681		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.6811437463642681 | validation: 0.7425258710922564]
	TIME [epoch: 9.7 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6873011304742793		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.6873011304742793 | validation: 0.5846096709152285]
	TIME [epoch: 9.69 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_663.pth
	Model improved!!!
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6925887489068873		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.6925887489068873 | validation: 0.9531122537319945]
	TIME [epoch: 9.74 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7326383570444504		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.7326383570444504 | validation: 0.5870271600630319]
	TIME [epoch: 9.71 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6438620712535202		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.6438620712535202 | validation: 0.6222053362173232]
	TIME [epoch: 9.7 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6587910361612159		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.6587910361612159 | validation: 0.5749475296626275]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_667.pth
	Model improved!!!
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6474330479488748		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.6474330479488748 | validation: 0.6269559998820533]
	TIME [epoch: 9.72 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6439470265130709		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.6439470265130709 | validation: 0.5636211378188462]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_669.pth
	Model improved!!!
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6021483724184616		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.6021483724184616 | validation: 0.6635029968631468]
	TIME [epoch: 9.71 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7096658963651239		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.7096658963651239 | validation: 0.7016273330871201]
	TIME [epoch: 9.73 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6563046379102595		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.6563046379102595 | validation: 0.5501793774149725]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_672.pth
	Model improved!!!
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5970732433652496		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.5970732433652496 | validation: 0.6143224604481122]
	TIME [epoch: 9.71 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5511725154712488		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.5511725154712488 | validation: 0.5624339175293978]
	TIME [epoch: 9.7 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6711666746581822		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.6711666746581822 | validation: 0.5611069655567703]
	TIME [epoch: 9.71 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7421360893268114		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.7421360893268114 | validation: 0.7751238293335254]
	TIME [epoch: 9.7 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6791528436470005		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.6791528436470005 | validation: 0.5869971085550196]
	TIME [epoch: 9.69 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6631438742559661		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.6631438742559661 | validation: 0.6755848848167986]
	TIME [epoch: 9.71 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7462386859880121		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.7462386859880121 | validation: 0.6352464730476877]
	TIME [epoch: 9.71 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6703640212963722		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.6703640212963722 | validation: 0.5843156792233577]
	TIME [epoch: 9.7 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5623610133257438		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.5623610133257438 | validation: 0.522929361723392]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_681.pth
	Model improved!!!
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6242147620250164		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.6242147620250164 | validation: 0.6706144798998821]
	TIME [epoch: 9.73 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5719806529769645		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.5719806529769645 | validation: 0.6626878055841234]
	TIME [epoch: 9.7 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7290667355704825		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.7290667355704825 | validation: 0.5873459666643277]
	TIME [epoch: 9.7 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6128877772072451		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.6128877772072451 | validation: 0.5390746833313331]
	TIME [epoch: 9.71 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6053030667135278		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.6053030667135278 | validation: 0.5838825039463117]
	TIME [epoch: 9.73 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5956959619873125		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 0.5956959619873125 | validation: 0.9332189724467489]
	TIME [epoch: 9.71 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7323484478172986		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.7323484478172986 | validation: 0.5553512858263756]
	TIME [epoch: 9.7 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5878779741790942		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.5878779741790942 | validation: 0.5994028971930202]
	TIME [epoch: 9.71 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6027594440866373		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.6027594440866373 | validation: 0.5890881731826764]
	TIME [epoch: 9.73 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.617027727475647		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.617027727475647 | validation: 0.5871137120768751]
	TIME [epoch: 9.71 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.569685291477541		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.569685291477541 | validation: 0.774281816823048]
	TIME [epoch: 9.7 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6052328483195957		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.6052328483195957 | validation: 2.2025804489289875]
	TIME [epoch: 9.72 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0154408566259958		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 1.0154408566259958 | validation: 0.5420894777035804]
	TIME [epoch: 9.71 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6738845601930807		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.6738845601930807 | validation: 0.7959140822799837]
	TIME [epoch: 9.71 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6396213899411096		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.6396213899411096 | validation: 0.6855858926588039]
	TIME [epoch: 9.71 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6544716760789656		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.6544716760789656 | validation: 0.5442760803291605]
	TIME [epoch: 9.73 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5739155251865932		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.5739155251865932 | validation: 0.6001839379258056]
	TIME [epoch: 9.72 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6316912451888104		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.6316912451888104 | validation: 0.6408336229010272]
	TIME [epoch: 9.71 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6072209590918313		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.6072209590918313 | validation: 0.6296303893873477]
	TIME [epoch: 9.72 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6034131662366098		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.6034131662366098 | validation: 0.6075906051888439]
	TIME [epoch: 9.73 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6194603566603714		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.6194603566603714 | validation: 0.5780936703165336]
	TIME [epoch: 9.71 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5751845510358728		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.5751845510358728 | validation: 0.6913920115011599]
	TIME [epoch: 9.71 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5917138960807475		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.5917138960807475 | validation: 0.5794475863681435]
	TIME [epoch: 9.72 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6024872716367587		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.6024872716367587 | validation: 0.6547876815542606]
	TIME [epoch: 9.73 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5918313951576416		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.5918313951576416 | validation: 0.6299210011150157]
	TIME [epoch: 9.71 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5814116854994065		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.5814116854994065 | validation: 1.0942471443922026]
	TIME [epoch: 9.71 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6594716001497845		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.6594716001497845 | validation: 0.5890523340828024]
	TIME [epoch: 9.72 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6173267453348116		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.6173267453348116 | validation: 0.5643265781401869]
	TIME [epoch: 9.71 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7145429245773217		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.7145429245773217 | validation: 0.8794512120168819]
	TIME [epoch: 9.7 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7024370377257251		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.7024370377257251 | validation: 0.5875387170413445]
	TIME [epoch: 9.71 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6348403419120643		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.6348403419120643 | validation: 0.6521189488377386]
	TIME [epoch: 9.73 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.636241865032843		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.636241865032843 | validation: 0.8000426850969007]
	TIME [epoch: 9.71 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.661975174431222		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.661975174431222 | validation: 0.5351267955589757]
	TIME [epoch: 9.71 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.586350265498082		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.586350265498082 | validation: 0.6705151742621476]
	TIME [epoch: 9.71 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6614417914016835		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.6614417914016835 | validation: 0.6526536931435953]
	TIME [epoch: 9.73 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5821512803507056		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.5821512803507056 | validation: 0.5537411852790671]
	TIME [epoch: 9.71 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5475869914527467		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.5475869914527467 | validation: 0.6966372775263362]
	TIME [epoch: 9.71 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6177405684397501		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.6177405684397501 | validation: 0.7334164306676851]
	TIME [epoch: 9.72 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6309636258606172		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.6309636258606172 | validation: 0.6369837123244793]
	TIME [epoch: 9.72 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8295022106209325		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.8295022106209325 | validation: 0.860909568261759]
	TIME [epoch: 9.71 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6777181961915898		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.6777181961915898 | validation: 0.7114717392429033]
	TIME [epoch: 9.7 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6356451601371023		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.6356451601371023 | validation: 0.8474459542553103]
	TIME [epoch: 9.72 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6897572410095171		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.6897572410095171 | validation: 0.5454875871344556]
	TIME [epoch: 9.71 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.55890400829338		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.55890400829338 | validation: 0.660198601914758]
	TIME [epoch: 9.71 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5840805383903166		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.5840805383903166 | validation: 0.6416117932257549]
	TIME [epoch: 9.71 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5609160095397894		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.5609160095397894 | validation: 0.5983101497435455]
	TIME [epoch: 9.73 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196144189069177		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.5196144189069177 | validation: 0.7647552136931393]
	TIME [epoch: 9.7 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6042139321927384		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.6042139321927384 | validation: 0.5293011838562799]
	TIME [epoch: 9.7 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5348898098617922		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.5348898098617922 | validation: 0.5820211574594367]
	TIME [epoch: 9.71 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5945735821494119		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.5945735821494119 | validation: 0.5361786114960496]
	TIME [epoch: 9.72 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6893241238922052		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.6893241238922052 | validation: 0.8080673724834424]
	TIME [epoch: 9.7 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.625070598619148		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.625070598619148 | validation: 0.5872364070455264]
	TIME [epoch: 9.7 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5655790458690061		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.5655790458690061 | validation: 0.5815922114697533]
	TIME [epoch: 9.71 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5695752296351657		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.5695752296351657 | validation: 1.000372465530814]
	TIME [epoch: 9.71 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7247214756356506		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.7247214756356506 | validation: 0.5050366839301141]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_736.pth
	Model improved!!!
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5036887349057747		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.5036887349057747 | validation: 0.6044354266636901]
	TIME [epoch: 9.71 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6711785124643411		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.6711785124643411 | validation: 0.9050702835736787]
	TIME [epoch: 9.73 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6294098749893573		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.6294098749893573 | validation: 0.9497595588364146]
	TIME [epoch: 9.7 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.64960895144063		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.64960895144063 | validation: 0.5721781892931574]
	TIME [epoch: 9.71 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6003861217215775		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.6003861217215775 | validation: 0.5213503519752223]
	TIME [epoch: 9.7 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.593317104271837		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.593317104271837 | validation: 0.5875611450761186]
	TIME [epoch: 9.74 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5856467924716792		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.5856467924716792 | validation: 0.6159052691806415]
	TIME [epoch: 9.71 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6538793168578895		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.6538793168578895 | validation: 0.722754283947463]
	TIME [epoch: 9.71 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5821341755340431		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.5821341755340431 | validation: 1.2119211704685964]
	TIME [epoch: 9.71 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6860416417080089		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.6860416417080089 | validation: 1.4358520939565143]
	TIME [epoch: 9.72 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8355438179143846		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.8355438179143846 | validation: 0.6384345068628094]
	TIME [epoch: 9.71 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227432433536998		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.5227432433536998 | validation: 1.422356123102658]
	TIME [epoch: 9.71 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7748100114652633		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.7748100114652633 | validation: 0.5407046559360681]
	TIME [epoch: 9.72 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5456234985196773		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.5456234985196773 | validation: 0.6289825123681206]
	TIME [epoch: 9.71 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5458256831101282		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.5458256831101282 | validation: 0.5717649662394897]
	TIME [epoch: 9.71 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5903464709592008		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.5903464709592008 | validation: 0.6318779988037088]
	TIME [epoch: 9.71 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5960162056633919		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.5960162056633919 | validation: 0.5140286402387381]
	TIME [epoch: 9.73 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5522073388115417		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.5522073388115417 | validation: 1.466380279941648]
	TIME [epoch: 9.71 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7849962963107344		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.7849962963107344 | validation: 0.5796110062383113]
	TIME [epoch: 9.7 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7566145358113922		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.7566145358113922 | validation: 0.5991371185300531]
	TIME [epoch: 9.72 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6290057514552095		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.6290057514552095 | validation: 0.540884458088035]
	TIME [epoch: 9.73 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4963554875946844		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.4963554875946844 | validation: 0.6345258252345471]
	TIME [epoch: 9.72 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6104526012219685		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.6104526012219685 | validation: 0.5559167126060414]
	TIME [epoch: 9.72 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5353190493886758		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.5353190493886758 | validation: 0.5568707440965054]
	TIME [epoch: 9.73 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5560261057132273		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.5560261057132273 | validation: 0.5417345197981357]
	TIME [epoch: 9.73 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6233421044856321		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.6233421044856321 | validation: 0.576143193296435]
	TIME [epoch: 9.72 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5344225918867859		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.5344225918867859 | validation: 0.5549992479454131]
	TIME [epoch: 9.73 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5838725292062459		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.5838725292062459 | validation: 0.6597587008667908]
	TIME [epoch: 9.74 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5497343969138767		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.5497343969138767 | validation: 0.5841791197979103]
	TIME [epoch: 9.71 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5570714924220537		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.5570714924220537 | validation: 0.57147943019741]
	TIME [epoch: 9.71 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5365881654453164		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.5365881654453164 | validation: 0.510809636821008]
	TIME [epoch: 9.72 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5638821567365963		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.5638821567365963 | validation: 0.9352093600824581]
	TIME [epoch: 9.77 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6098524946567673		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.6098524946567673 | validation: 0.6666323564068047]
	TIME [epoch: 9.7 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5547575037420167		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.5547575037420167 | validation: 0.5626121707115881]
	TIME [epoch: 9.7 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6783011750337578		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.6783011750337578 | validation: 0.6786510079744915]
	TIME [epoch: 9.71 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.55371680830727		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.55371680830727 | validation: 0.566607271583164]
	TIME [epoch: 9.73 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8275364604746865		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.8275364604746865 | validation: 0.5078287523070093]
	TIME [epoch: 9.71 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.649242642305026		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.649242642305026 | validation: 0.5566420041899689]
	TIME [epoch: 9.7 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6016280920761893		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.6016280920761893 | validation: 0.5312399312977018]
	TIME [epoch: 9.72 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.661677688220598		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.661677688220598 | validation: 0.6127010223662751]
	TIME [epoch: 9.7 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5566877088134209		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.5566877088134209 | validation: 0.5231493247439535]
	TIME [epoch: 9.71 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5154061750405112		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.5154061750405112 | validation: 0.49960880314443606]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_778.pth
	Model improved!!!
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5394911079934603		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.5394911079934603 | validation: 0.5466734621503063]
	TIME [epoch: 9.73 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5583767653790612		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.5583767653790612 | validation: 0.475019013433008]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_780.pth
	Model improved!!!
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4899217872726556		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.4899217872726556 | validation: 0.5009176094171053]
	TIME [epoch: 9.71 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5009360873146574		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.5009360873146574 | validation: 0.5340066995581303]
	TIME [epoch: 9.7 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5361966196487042		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.5361966196487042 | validation: 0.6163974533281377]
	TIME [epoch: 9.74 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5622967277807739		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.5622967277807739 | validation: 0.575805470675447]
	TIME [epoch: 9.7 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5371268648107607		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.5371268648107607 | validation: 0.7201763214738313]
	TIME [epoch: 9.7 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6208149731052229		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.6208149731052229 | validation: 0.5617571349838856]
	TIME [epoch: 9.72 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.508529867773923		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.508529867773923 | validation: 0.5698202455198904]
	TIME [epoch: 9.71 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5649033075456883		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.5649033075456883 | validation: 0.5918323037300937]
	TIME [epoch: 9.71 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5514665963925045		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.5514665963925045 | validation: 0.5164302706094392]
	TIME [epoch: 9.7 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5213769127749857		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.5213769127749857 | validation: 0.6731297110199419]
	TIME [epoch: 9.73 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5345371428573962		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.5345371428573962 | validation: 1.0148775504685594]
	TIME [epoch: 9.7 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.581369557500345		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.581369557500345 | validation: 0.4537844471764616]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_792.pth
	Model improved!!!
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5217077005661789		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.5217077005661789 | validation: 0.5627938994774248]
	TIME [epoch: 9.71 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5094629202103199		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.5094629202103199 | validation: 0.5437877689159397]
	TIME [epoch: 9.73 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5047559935859434		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.5047559935859434 | validation: 0.5914955390773339]
	TIME [epoch: 9.7 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6661229577258941		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.6661229577258941 | validation: 0.8659288143361944]
	TIME [epoch: 9.7 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6081415352173128		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.6081415352173128 | validation: 0.5418924788372783]
	TIME [epoch: 9.71 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5311600983102198		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.5311600983102198 | validation: 0.5194459162316872]
	TIME [epoch: 9.71 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6943885364924769		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.6943885364924769 | validation: 0.9785680791794835]
	TIME [epoch: 9.7 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8831012954240643		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.8831012954240643 | validation: 0.6667188064858364]
	TIME [epoch: 9.7 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8236200987028989		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.8236200987028989 | validation: 0.5600346447627585]
	TIME [epoch: 9.71 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5091639514096582		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.5091639514096582 | validation: 0.697541125926563]
	TIME [epoch: 9.7 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6236532115682556		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.6236532115682556 | validation: 0.5883343316843086]
	TIME [epoch: 9.69 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5250355115877522		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.5250355115877522 | validation: 0.49075145961561134]
	TIME [epoch: 9.69 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5037374425988312		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.5037374425988312 | validation: 0.5608478724260251]
	TIME [epoch: 9.71 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.619818788930113		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.619818788930113 | validation: 0.5981995539057159]
	TIME [epoch: 9.69 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6406881562603043		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.6406881562603043 | validation: 0.6700814130384957]
	TIME [epoch: 9.69 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5762258273838952		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.5762258273838952 | validation: 0.5117703812712554]
	TIME [epoch: 9.7 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5220217948355911		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.5220217948355911 | validation: 0.6432244184285362]
	TIME [epoch: 9.71 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5727943647282296		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.5727943647282296 | validation: 0.5099139402898446]
	TIME [epoch: 9.7 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5063488320314485		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.5063488320314485 | validation: 0.48839875812213673]
	TIME [epoch: 9.69 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5163825129595881		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.5163825129595881 | validation: 0.5047818280939523]
	TIME [epoch: 9.72 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8596599609815838		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.8596599609815838 | validation: 0.6405796714266595]
	TIME [epoch: 9.7 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6284345636560491		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.6284345636560491 | validation: 0.587197259453221]
	TIME [epoch: 9.69 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5205893982489123		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.5205893982489123 | validation: 0.5431436228984776]
	TIME [epoch: 9.7 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5241772141003923		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.5241772141003923 | validation: 0.57607719868899]
	TIME [epoch: 9.71 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5537271884524608		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.5537271884524608 | validation: 0.49253963933414163]
	TIME [epoch: 9.7 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5270769937070072		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.5270769937070072 | validation: 0.5084492078913979]
	TIME [epoch: 9.69 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6762612472744883		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.6762612472744883 | validation: 0.560791310985597]
	TIME [epoch: 9.69 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5462276364143117		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.5462276364143117 | validation: 0.6080252405432027]
	TIME [epoch: 9.72 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280020304394141		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.5280020304394141 | validation: 0.5263215210889484]
	TIME [epoch: 9.7 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.81568941209495		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.81568941209495 | validation: 0.6323632427263727]
	TIME [epoch: 9.69 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6302303875905075		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.6302303875905075 | validation: 1.0119878987653956]
	TIME [epoch: 9.7 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6237931884686623		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.6237931884686623 | validation: 0.4902172197324407]
	TIME [epoch: 9.71 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5094345618181242		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.5094345618181242 | validation: 1.1239379105650966]
	TIME [epoch: 9.69 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6586042672146555		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.6586042672146555 | validation: 0.4774092076100086]
	TIME [epoch: 9.69 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5022662232934861		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.5022662232934861 | validation: 0.5571034375138583]
	TIME [epoch: 9.71 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5261399918967012		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.5261399918967012 | validation: 0.5971426687501125]
	TIME [epoch: 9.7 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5060647386612538		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.5060647386612538 | validation: 0.9736722549106307]
	TIME [epoch: 9.69 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.63829442277916		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.63829442277916 | validation: 0.4841491429163957]
	TIME [epoch: 9.7 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49119401982447153		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.49119401982447153 | validation: 0.5089790759777263]
	TIME [epoch: 9.72 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.611390440871624		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.611390440871624 | validation: 0.4951951277533083]
	TIME [epoch: 9.69 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6215492738332822		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.6215492738332822 | validation: 0.6405974119463573]
	TIME [epoch: 9.69 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5201583063383011		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.5201583063383011 | validation: 0.5448727543378861]
	TIME [epoch: 9.7 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5278551717877904		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.5278551717877904 | validation: 0.481561329645926]
	TIME [epoch: 9.77 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47863017523811635		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.47863017523811635 | validation: 0.49691977862843517]
	TIME [epoch: 9.69 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47931699782277504		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.47931699782277504 | validation: 0.49025499415820073]
	TIME [epoch: 9.69 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5250370678944553		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.5250370678944553 | validation: 0.5417504347757808]
	TIME [epoch: 9.71 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5092697741491761		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.5092697741491761 | validation: 0.6417463623509235]
	TIME [epoch: 9.71 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5705487325710441		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.5705487325710441 | validation: 0.623771399828608]
	TIME [epoch: 9.69 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7820076031823552		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.7820076031823552 | validation: 1.8298681523571196]
	TIME [epoch: 9.69 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7714997205989299		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.7714997205989299 | validation: 0.5216985287394611]
	TIME [epoch: 9.71 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6574041580567898		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.6574041580567898 | validation: 0.5130735162694439]
	TIME [epoch: 9.7 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48624091918582907		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.48624091918582907 | validation: 0.4648338887008696]
	TIME [epoch: 9.7 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5068103577622379		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.5068103577622379 | validation: 0.549545966832401]
	TIME [epoch: 9.7 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6678565439994111		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.6678565439994111 | validation: 1.0850459950425695]
	TIME [epoch: 9.71 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6422206528674994		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.6422206528674994 | validation: 0.5906479427387737]
	TIME [epoch: 9.69 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5373564473331041		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.5373564473331041 | validation: 0.5688891346812569]
	TIME [epoch: 9.69 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4896126141063698		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.4896126141063698 | validation: 0.589993981194427]
	TIME [epoch: 9.7 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5853393449845595		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.5853393449845595 | validation: 0.587891675476904]
	TIME [epoch: 9.71 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5142897864384384		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.5142897864384384 | validation: 0.4708044071916193]
	TIME [epoch: 9.69 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4861456670177951		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.4861456670177951 | validation: 0.43708333943939354]
	TIME [epoch: 9.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_852.pth
	Model improved!!!
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.558933282866534		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.558933282866534 | validation: 0.6194676371445929]
	TIME [epoch: 9.71 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5304074293646369		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.5304074293646369 | validation: 0.5038425385927384]
	TIME [epoch: 9.7 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5198866032997582		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.5198866032997582 | validation: 0.5467916596954198]
	TIME [epoch: 9.69 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5131545926927907		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.5131545926927907 | validation: 0.493464298046052]
	TIME [epoch: 9.7 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5402258415381339		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.5402258415381339 | validation: 0.5399064826216855]
	TIME [epoch: 9.71 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4960819443174754		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.4960819443174754 | validation: 0.5054958887900739]
	TIME [epoch: 9.7 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5644398593325348		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.5644398593325348 | validation: 0.6480561189235587]
	TIME [epoch: 9.7 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6920336300370803		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.6920336300370803 | validation: 0.6808423320807026]
	TIME [epoch: 9.7 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5263157887605089		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.5263157887605089 | validation: 0.5041109922911947]
	TIME [epoch: 9.72 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5389982837937851		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.5389982837937851 | validation: 0.6517589442684826]
	TIME [epoch: 9.7 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5314000462142172		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.5314000462142172 | validation: 0.48645624394463954]
	TIME [epoch: 9.7 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5251653175481781		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.5251653175481781 | validation: 0.5218295515802851]
	TIME [epoch: 9.71 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5427518437146305		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.5427518437146305 | validation: 0.5214702397915878]
	TIME [epoch: 9.71 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4879471307818184		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.4879471307818184 | validation: 0.49022627867266844]
	TIME [epoch: 9.69 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5274629501824409		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.5274629501824409 | validation: 0.6629971550677166]
	TIME [epoch: 9.7 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6117186877978483		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.6117186877978483 | validation: 0.6088600996417349]
	TIME [epoch: 9.71 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49412241617427977		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.49412241617427977 | validation: 0.4839726580750591]
	TIME [epoch: 9.71 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5373108619463671		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.5373108619463671 | validation: 0.6193912401360436]
	TIME [epoch: 9.69 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5418021370190528		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.5418021370190528 | validation: 0.502617303328009]
	TIME [epoch: 9.7 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5057586548255365		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.5057586548255365 | validation: 0.5383009417200162]
	TIME [epoch: 9.72 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49516663622204726		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.49516663622204726 | validation: 0.5091704167633738]
	TIME [epoch: 9.7 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5436767676336893		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.5436767676336893 | validation: 0.6559564417720185]
	TIME [epoch: 9.7 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.547087953551212		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.547087953551212 | validation: 0.49869672058907427]
	TIME [epoch: 9.7 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4797113835555565		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.4797113835555565 | validation: 0.7119416019581027]
	TIME [epoch: 9.71 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6397992308905496		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.6397992308905496 | validation: 0.5792322660161559]
	TIME [epoch: 9.71 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4762591962562948		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.4762591962562948 | validation: 0.5905782514531663]
	TIME [epoch: 9.7 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47155751182471867		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.47155751182471867 | validation: 0.503388993233484]
	TIME [epoch: 9.71 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5345920239027346		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.5345920239027346 | validation: 0.531868641550301]
	TIME [epoch: 9.7 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4854152230915133		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.4854152230915133 | validation: 0.4774504711114804]
	TIME [epoch: 9.7 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47291920795936926		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.47291920795936926 | validation: 0.5789858773941512]
	TIME [epoch: 9.7 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48221614264507595		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.48221614264507595 | validation: 0.5305026453520699]
	TIME [epoch: 9.71 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5715589214715957		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.5715589214715957 | validation: 0.5862942298828897]
	TIME [epoch: 9.71 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.522547216473552		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.522547216473552 | validation: 0.5192247955303212]
	TIME [epoch: 9.7 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49868789756630233		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.49868789756630233 | validation: 1.3446392981221351]
	TIME [epoch: 9.71 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7654078383683414		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.7654078383683414 | validation: 0.5713003722951182]
	TIME [epoch: 9.71 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49767396491275057		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.49767396491275057 | validation: 0.5719910053245784]
	TIME [epoch: 9.71 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47449432274768694		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.47449432274768694 | validation: 0.607503199153244]
	TIME [epoch: 9.69 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4772724247511939		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.4772724247511939 | validation: 0.4453483338617403]
	TIME [epoch: 9.71 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5243025214732346		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.5243025214732346 | validation: 0.4853258455412893]
	TIME [epoch: 9.72 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4586816080315611		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.4586816080315611 | validation: 0.5314768650625097]
	TIME [epoch: 9.7 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5198325195908058		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.5198325195908058 | validation: 0.5085931911521969]
	TIME [epoch: 9.7 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4730172424223695		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.4730172424223695 | validation: 0.5120530500860264]
	TIME [epoch: 9.71 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.546529936022927		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.546529936022927 | validation: 0.7477017627815699]
	TIME [epoch: 9.71 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6416976585862104		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.6416976585862104 | validation: 0.5166580205185125]
	TIME [epoch: 9.71 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.501572645297087		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.501572645297087 | validation: 0.5236623666146611]
	TIME [epoch: 9.71 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6139225309327769		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.6139225309327769 | validation: 0.6550998206732827]
	TIME [epoch: 9.72 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.681615259184109		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.681615259184109 | validation: 0.6437632759290728]
	TIME [epoch: 9.69 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5361442088986633		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.5361442088986633 | validation: 0.5427253680529597]
	TIME [epoch: 9.7 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.57247859677506		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.57247859677506 | validation: 0.4926357480640695]
	TIME [epoch: 9.7 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47338007706862123		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.47338007706862123 | validation: 0.5346658761525472]
	TIME [epoch: 9.72 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5017830697893157		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.5017830697893157 | validation: 0.4987422564322209]
	TIME [epoch: 9.69 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6127136537810484		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.6127136537810484 | validation: 0.5040138243493832]
	TIME [epoch: 9.71 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.520229847455094		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.520229847455094 | validation: 0.6084020141877929]
	TIME [epoch: 9.73 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6159019503441228		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.6159019503441228 | validation: 1.1583300937614691]
	TIME [epoch: 9.71 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9911170501521301		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.9911170501521301 | validation: 0.8568677388096626]
	TIME [epoch: 9.71 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6334967314206214		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.6334967314206214 | validation: 0.5887814354551208]
	TIME [epoch: 9.71 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5455650757048589		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.5455650757048589 | validation: 0.5094684109952589]
	TIME [epoch: 9.71 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6635235830721335		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.6635235830721335 | validation: 0.6036054432339596]
	TIME [epoch: 9.7 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5330797891724034		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.5330797891724034 | validation: 0.6648958572656497]
	TIME [epoch: 9.69 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5233436756525027		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.5233436756525027 | validation: 0.4829465468558831]
	TIME [epoch: 9.69 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5045689405182106		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.5045689405182106 | validation: 0.5334029942441108]
	TIME [epoch: 9.71 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5359703769014137		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.5359703769014137 | validation: 0.5698247895137568]
	TIME [epoch: 9.71 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5152633297371937		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.5152633297371937 | validation: 0.5058425710607662]
	TIME [epoch: 9.71 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5102102385599521		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.5102102385599521 | validation: 0.5050628842736128]
	TIME [epoch: 9.7 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4952443228852667		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.4952443228852667 | validation: 0.43639621019732533]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_917.pth
	Model improved!!!
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5718363324901978		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.5718363324901978 | validation: 0.49316801086647616]
	TIME [epoch: 9.72 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46353933947753206		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.46353933947753206 | validation: 0.47055460869836196]
	TIME [epoch: 9.72 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6117744024147125		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.6117744024147125 | validation: 0.750117862996908]
	TIME [epoch: 9.73 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.521344501292643		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.521344501292643 | validation: 0.4693306485888945]
	TIME [epoch: 9.72 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47420518339174833		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.47420518339174833 | validation: 0.5459086494772102]
	TIME [epoch: 9.72 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45719977766664127		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.45719977766664127 | validation: 0.433099312862702]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_923.pth
	Model improved!!!
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48658266600742894		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.48658266600742894 | validation: 0.49729479429083023]
	TIME [epoch: 9.73 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45316770671994633		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.45316770671994633 | validation: 0.4346235572034366]
	TIME [epoch: 9.71 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4809380142350583		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.4809380142350583 | validation: 0.5013020248384076]
	TIME [epoch: 9.71 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5228402276493167		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.5228402276493167 | validation: 0.5200290496325318]
	TIME [epoch: 9.72 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4611273334331581		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.4611273334331581 | validation: 0.45250078005061045]
	TIME [epoch: 9.72 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46152674290404		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.46152674290404 | validation: 0.446938339222448]
	TIME [epoch: 9.71 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4606419477418549		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.4606419477418549 | validation: 0.5976026687726976]
	TIME [epoch: 9.71 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5150182760737806		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.5150182760737806 | validation: 0.457208395253127]
	TIME [epoch: 9.72 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46577482696811945		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.46577482696811945 | validation: 0.4692935482970803]
	TIME [epoch: 9.71 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45913593394746044		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.45913593394746044 | validation: 0.45713126278493504]
	TIME [epoch: 9.71 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4736426587317123		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.4736426587317123 | validation: 0.4714889121488554]
	TIME [epoch: 9.71 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.48138498784687345		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.48138498784687345 | validation: 0.45364449120729433]
	TIME [epoch: 9.73 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5487644005352527		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.5487644005352527 | validation: 0.5087964919323167]
	TIME [epoch: 9.71 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4804674654252959		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.4804674654252959 | validation: 0.46488538080324254]
	TIME [epoch: 9.74 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44462587924317454		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.44462587924317454 | validation: 0.4550857585502632]
	TIME [epoch: 9.72 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4538918716277937		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.4538918716277937 | validation: 0.4347720412691917]
	TIME [epoch: 9.73 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43539168410075424		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.43539168410075424 | validation: 0.47358964250993957]
	TIME [epoch: 9.71 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4458310029473599		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.4458310029473599 | validation: 0.45086579375130326]
	TIME [epoch: 9.7 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45304573397669845		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.45304573397669845 | validation: 0.4657431338379196]
	TIME [epoch: 9.72 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5232594498427288		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.5232594498427288 | validation: 0.5225909024556199]
	TIME [epoch: 9.71 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5182613985245592		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.5182613985245592 | validation: 0.4561325822459426]
	TIME [epoch: 9.72 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44937264960283974		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.44937264960283974 | validation: 0.5001687340361695]
	TIME [epoch: 9.71 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4873025049846099		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.4873025049846099 | validation: 0.5279372428360698]
	TIME [epoch: 9.72 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5011188198962266		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.5011188198962266 | validation: 0.57205131541403]
	TIME [epoch: 9.72 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4737099410437565		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.4737099410437565 | validation: 0.47509927626358817]
	TIME [epoch: 9.71 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45306796238007757		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.45306796238007757 | validation: 0.48476793247347594]
	TIME [epoch: 9.7 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4670267772331364		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.4670267772331364 | validation: 0.4749404103105971]
	TIME [epoch: 9.73 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4689488775437673		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.4689488775437673 | validation: 0.4666150844263815]
	TIME [epoch: 9.71 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45828218455472125		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.45828218455472125 | validation: 0.47160016593642257]
	TIME [epoch: 9.71 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44178934718102925		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.44178934718102925 | validation: 0.5041939188827671]
	TIME [epoch: 9.71 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44566005509652673		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.44566005509652673 | validation: 0.454796433688325]
	TIME [epoch: 9.72 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4631445197749094		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.4631445197749094 | validation: 0.48622372836870614]
	TIME [epoch: 9.71 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4674541575504135		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.4674541575504135 | validation: 0.48759914487139017]
	TIME [epoch: 9.71 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4643261697923884		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.4643261697923884 | validation: 0.5016705106360808]
	TIME [epoch: 9.73 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4838521322163308		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.4838521322163308 | validation: 0.5000627143858334]
	TIME [epoch: 9.71 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4471103523316583		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.4471103523316583 | validation: 0.4445847184866328]
	TIME [epoch: 9.71 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49101665594390187		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.49101665594390187 | validation: 0.4729337384227546]
	TIME [epoch: 9.7 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4394772742716885		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.4394772742716885 | validation: 0.4824636091725447]
	TIME [epoch: 9.73 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4610526162885037		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.4610526162885037 | validation: 0.45194956813813897]
	TIME [epoch: 9.7 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4653276543869782		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.4653276543869782 | validation: 0.46581500730648]
	TIME [epoch: 9.71 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47813276005391625		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.47813276005391625 | validation: 0.519252919374367]
	TIME [epoch: 9.71 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4555716591269274		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.4555716591269274 | validation: 0.6163731381835463]
	TIME [epoch: 9.74 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5006633053367306		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.5006633053367306 | validation: 0.4436948240904232]
	TIME [epoch: 9.69 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4837022694567981		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.4837022694567981 | validation: 0.6536422783938772]
	TIME [epoch: 9.71 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49149920293852734		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.49149920293852734 | validation: 0.4511847511959782]
	TIME [epoch: 9.7 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4697216716049818		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.4697216716049818 | validation: 0.4408704536814402]
	TIME [epoch: 9.71 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.43455609968620357		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.43455609968620357 | validation: 0.43823066541709893]
	TIME [epoch: 9.7 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4408595799776768		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.4408595799776768 | validation: 0.4659243054692123]
	TIME [epoch: 9.71 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.44116670762538834		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.44116670762538834 | validation: 0.4847300882280313]
	TIME [epoch: 9.72 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4520427000000529		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.4520427000000529 | validation: 0.4849853691546494]
	TIME [epoch: 9.71 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4644943517467025		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.4644943517467025 | validation: 0.48670330759164737]
	TIME [epoch: 9.7 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4811495469145702		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.4811495469145702 | validation: 0.4929263420731863]
	TIME [epoch: 9.71 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46687332164532014		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.46687332164532014 | validation: 0.41842470004658794]
	TIME [epoch: 9.71 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240217_140924/states/model_tr_study6_976.pth
	Model improved!!!
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4570495730711538		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.4570495730711538 | validation: 0.49515867975567623]
	TIME [epoch: 9.71 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4638019807709428		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.4638019807709428 | validation: 0.43834642550769815]
	TIME [epoch: 9.7 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4624953750059747		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.4624953750059747 | validation: 0.5333355250189744]
	TIME [epoch: 9.72 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47574437883073434		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.47574437883073434 | validation: 0.44043217615927704]
	TIME [epoch: 9.72 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.455023955647954		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.455023955647954 | validation: 0.5357464707870909]
	TIME [epoch: 9.71 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.49958218302391144		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.49958218302391144 | validation: 0.44910338560491186]
	TIME [epoch: 9.7 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4743427307517797		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.4743427307517797 | validation: 0.46344350504344806]
	TIME [epoch: 9.71 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.604666015971248		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.604666015971248 | validation: 0.5397098628619907]
	TIME [epoch: 9.71 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4822417209901884		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.4822417209901884 | validation: 0.5502028291940478]
	TIME [epoch: 9.7 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.503836039097098		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.503836039097098 | validation: 0.5810634272572951]
	TIME [epoch: 9.69 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4708385357221987		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.4708385357221987 | validation: 0.4479310319762616]
	TIME [epoch: 9.72 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.443550290022499		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.443550290022499 | validation: 0.4927363640013496]
	TIME [epoch: 9.71 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46161587576279073		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.46161587576279073 | validation: 0.4875803785885493]
	TIME [epoch: 9.7 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.46045099250180055		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.46045099250180055 | validation: 0.5252351653765991]
	TIME [epoch: 9.71 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5047136991974495		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.5047136991974495 | validation: 0.5547654196346943]
	TIME [epoch: 9.73 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.482581656388496		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.482581656388496 | validation: 0.4677183692044446]
	TIME [epoch: 9.71 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.45201488437904513		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.45201488437904513 | validation: 0.6740541301741655]
	TIME [epoch: 9.7 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5948498926633214		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.5948498926633214 | validation: 0.4830751069108177]
	TIME [epoch: 9.7 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.47201031226952483		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.47201031226952483 | validation: 0.48732498396670426]
	TIME [epoch: 9.71 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4647205132568694		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.4647205132568694 | validation: 0.5089629286012956]
	TIME [epoch: 9.7 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4805749209440119		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.4805749209440119 | validation: 0.5752037829211766]
	TIME [epoch: 9.69 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.5441529386362218		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.5441529386362218 | validation: 0.48748130129082184]
	TIME [epoch: 9.72 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4610466204130409		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.4610466204130409 | validation: 0.5104834145204339]
	TIME [epoch: 9.7 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.4614243364007315		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.4614243364007315 | validation: 0.47368872760744374]
	TIME [epoch: 9.69 sec]
Finished training in 9831.181 seconds.
