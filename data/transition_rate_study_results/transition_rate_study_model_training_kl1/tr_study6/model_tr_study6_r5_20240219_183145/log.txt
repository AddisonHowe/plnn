Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r5', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2665695009

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.91823241093436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.91823241093436 | validation: 8.54912210794789]
	TIME [epoch: 54.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.189878078195145		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.189878078195145 | validation: 7.537368143912329]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.787146087608501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.787146087608501 | validation: 6.693606288235069]
	TIME [epoch: 9.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.231463527767167		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.231463527767167 | validation: 5.98934588153827]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.4090815458673465		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4090815458673465 | validation: 4.631804645536972]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.053425892460637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.053425892460637 | validation: 5.347303610026565]
	TIME [epoch: 9.8 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.692100062665396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.692100062665396 | validation: 4.74872205609935]
	TIME [epoch: 9.82 sec]
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.049448306248411		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.049448306248411 | validation: 4.970071445052061]
	TIME [epoch: 9.8 sec]
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.092941210665564		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.092941210665564 | validation: 4.471139142610041]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.706967183457477		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.706967183457477 | validation: 3.822414849097916]
	TIME [epoch: 9.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.265148534783664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.265148534783664 | validation: 3.322952607983673]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.049372561606522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.049372561606522 | validation: 3.060730319925641]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.841170328602303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.841170328602303 | validation: 4.231193794820424]
	TIME [epoch: 9.82 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9619354681135577		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9619354681135577 | validation: 3.1696881337990463]
	TIME [epoch: 9.8 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5565806782261076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5565806782261076 | validation: 2.652696258638195]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3094646952731397		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3094646952731397 | validation: 2.75382706007659]
	TIME [epoch: 9.82 sec]
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.294251617132182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.294251617132182 | validation: 2.539539065235677]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3479166629338613		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3479166629338613 | validation: 2.9497704846059714]
	TIME [epoch: 9.81 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4669348523965104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4669348523965104 | validation: 2.6099759032609926]
	TIME [epoch: 9.81 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2254794074254027		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2254794074254027 | validation: 2.7434937429386377]
	TIME [epoch: 9.81 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2301807126393007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2301807126393007 | validation: 2.4787525089801004]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.211988853023255		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.211988853023255 | validation: 2.6069976223637936]
	TIME [epoch: 9.81 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.427055291657459		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.427055291657459 | validation: 2.68991912026888]
	TIME [epoch: 9.82 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2294724968372455		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2294724968372455 | validation: 2.4252101226472758]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.248926656429756		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.248926656429756 | validation: 2.478863951868299]
	TIME [epoch: 9.79 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2148447755260583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2148447755260583 | validation: 2.6372142152351454]
	TIME [epoch: 9.83 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1730296380156364		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1730296380156364 | validation: 2.5102715170793704]
	TIME [epoch: 9.81 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2183244616454956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2183244616454956 | validation: 2.4008825594046272]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2048195992804964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2048195992804964 | validation: 2.744694266980176]
	TIME [epoch: 9.83 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.241776095078835		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.241776095078835 | validation: 2.562267216623312]
	TIME [epoch: 9.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1748982783964683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1748982783964683 | validation: 2.5283880952744693]
	TIME [epoch: 9.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.290330822133433		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.290330822133433 | validation: 2.6386052969045677]
	TIME [epoch: 9.8 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.163010644279378		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.163010644279378 | validation: 2.4676439409554023]
	TIME [epoch: 9.84 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2457202279257302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2457202279257302 | validation: 2.48333791377161]
	TIME [epoch: 9.8 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2164715643850856		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2164715643850856 | validation: 2.5857576452496263]
	TIME [epoch: 9.8 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2181144826544665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2181144826544665 | validation: 2.5024921081544202]
	TIME [epoch: 9.82 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.215009445839358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.215009445839358 | validation: 2.5412798155707885]
	TIME [epoch: 9.81 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.154481281509838		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.154481281509838 | validation: 2.4295931721023662]
	TIME [epoch: 9.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1341687957574424		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1341687957574424 | validation: 2.519843715731761]
	TIME [epoch: 9.81 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1798823571370276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1798823571370276 | validation: 2.491352221802345]
	TIME [epoch: 9.83 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.206753400627946		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.206753400627946 | validation: 2.445067991798837]
	TIME [epoch: 9.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1183828701189076		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1183828701189076 | validation: 2.4459851366434866]
	TIME [epoch: 9.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.152083776298882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.152083776298882 | validation: 5.518055377869555]
	TIME [epoch: 9.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.51575547254933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.51575547254933 | validation: 6.148144587372224]
	TIME [epoch: 9.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9916365282423043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9916365282423043 | validation: 4.225659903341926]
	TIME [epoch: 9.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.402743293436964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.402743293436964 | validation: 3.4188350373217076]
	TIME [epoch: 9.81 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2707795241093485		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2707795241093485 | validation: 2.4990830173583634]
	TIME [epoch: 9.82 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9470083394463658		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9470083394463658 | validation: 1.362430862880034]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_48.pth
	Model improved!!!
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.536788798177478		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.536788798177478 | validation: 1.8677519551426047]
	TIME [epoch: 9.8 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8506046370596105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.8506046370596105 | validation: 1.5851926632644575]
	TIME [epoch: 9.82 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9571332972854616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9571332972854616 | validation: 2.920050794179318]
	TIME [epoch: 9.8 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.347273924316825		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.347273924316825 | validation: 2.6306418819180384]
	TIME [epoch: 9.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2821461933012728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2821461933012728 | validation: 2.5728971151388103]
	TIME [epoch: 9.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2243877831960126		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2243877831960126 | validation: 2.5236440838386374]
	TIME [epoch: 9.83 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.175425930861066		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.175425930861066 | validation: 2.4557320730924492]
	TIME [epoch: 9.78 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1753505602470757		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1753505602470757 | validation: 2.45865146588527]
	TIME [epoch: 9.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.189662384006863		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.189662384006863 | validation: 2.3982738521031353]
	TIME [epoch: 9.81 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1155680286912		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1155680286912 | validation: 2.3658633558155184]
	TIME [epoch: 9.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1128190890580725		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1128190890580725 | validation: 2.3892249927056177]
	TIME [epoch: 9.78 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1040541052754405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1040541052754405 | validation: 3.31116980360364]
	TIME [epoch: 9.78 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.286668522173077		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.286668522173077 | validation: 5.559945129313085]
	TIME [epoch: 9.81 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.3808164552931945		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.3808164552931945 | validation: 5.284643435842741]
	TIME [epoch: 9.78 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.095176673042801		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.095176673042801 | validation: 4.442818859779964]
	TIME [epoch: 9.79 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.667160305458808		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.667160305458808 | validation: 5.482235037985722]
	TIME [epoch: 9.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.01941550414683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.01941550414683 | validation: 4.265064890288074]
	TIME [epoch: 9.82 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.704244956972028		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.704244956972028 | validation: 6.197127201839102]
	TIME [epoch: 9.79 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.968081310448708		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.968081310448708 | validation: 5.819697537413674]
	TIME [epoch: 9.79 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.920064644770609		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.920064644770609 | validation: 3.567961737955629]
	TIME [epoch: 9.81 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5324443436514796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5324443436514796 | validation: 2.463830724770423]
	TIME [epoch: 9.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0970898798534643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0970898798534643 | validation: 3.6931413251007617]
	TIME [epoch: 9.79 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.059238436682579		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.059238436682579 | validation: 2.14081869883018]
	TIME [epoch: 9.78 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.414077679392653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.414077679392653 | validation: 5.5931499028291345]
	TIME [epoch: 9.81 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.643761541217332		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.643761541217332 | validation: 2.832819881622819]
	TIME [epoch: 9.79 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.589621528804505		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.589621528804505 | validation: 1.9722867197745573]
	TIME [epoch: 9.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.084417342450995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.084417342450995 | validation: 1.6860740201538278]
	TIME [epoch: 9.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9732892598445333		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9732892598445333 | validation: 1.962232971765764]
	TIME [epoch: 9.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.30463181200274		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.30463181200274 | validation: 1.6292990665879428]
	TIME [epoch: 9.79 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7328605066102907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.7328605066102907 | validation: 2.2985444475513104]
	TIME [epoch: 9.79 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9053381136916905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.9053381136916905 | validation: 1.5358982071516158]
	TIME [epoch: 9.81 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.511872582063053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.511872582063053 | validation: 2.2671815734561385]
	TIME [epoch: 9.78 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2235784787580344		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2235784787580344 | validation: 1.276994248274865]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_81.pth
	Model improved!!!
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.293415276311369		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.293415276311369 | validation: 0.9166801196870761]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9991711133298791		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9991711133298791 | validation: 0.9731356324575012]
	TIME [epoch: 9.81 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9737362100045122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9737362100045122 | validation: 0.9810845913383424]
	TIME [epoch: 9.81 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0019451765106244		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0019451765106244 | validation: 1.136242226655879]
	TIME [epoch: 9.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3295223392717719		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3295223392717719 | validation: 1.4766946652003645]
	TIME [epoch: 9.82 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9521917224982721		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9521917224982721 | validation: 1.041568043367173]
	TIME [epoch: 9.8 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0433633005044052		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0433633005044052 | validation: 0.8534891790757513]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7806661369632212		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.7806661369632212 | validation: 0.8430918637479268]
	TIME [epoch: 9.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9602804509716675		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.9602804509716675 | validation: 2.0401029746910333]
	TIME [epoch: 9.81 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4682959112154599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4682959112154599 | validation: 1.310306157459284]
	TIME [epoch: 9.8 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4666939145343716		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4666939145343716 | validation: 1.2994048287235764]
	TIME [epoch: 9.81 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.999016629902162		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.999016629902162 | validation: 0.8918201976102651]
	TIME [epoch: 9.82 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4248354032246684		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4248354032246684 | validation: 2.881349962942728]
	TIME [epoch: 9.81 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4278969400472823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4278969400472823 | validation: 2.705518619430685]
	TIME [epoch: 9.8 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1329833907846516		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1329833907846516 | validation: 1.6252101440366722]
	TIME [epoch: 9.81 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.187970058297751		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.187970058297751 | validation: 0.6189454554565597]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.764898327977713		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.764898327977713 | validation: 0.8096962603063388]
	TIME [epoch: 9.87 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.945330003036932		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.945330003036932 | validation: 2.464933447980719]
	TIME [epoch: 9.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2028175066630036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2028175066630036 | validation: 2.4801981414456273]
	TIME [epoch: 9.83 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.157995315892148		[learning rate: 0.0099806]
	Learning Rate: 0.00998063
	LOSS [training: 3.157995315892148 | validation: 2.659251941301183]
	TIME [epoch: 9.81 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4414987655284555		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 3.4414987655284555 | validation: 2.672623748830513]
	TIME [epoch: 9.81 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9205307831154896		[learning rate: 0.0099324]
	Learning Rate: 0.00993236
	LOSS [training: 2.9205307831154896 | validation: 1.0219714567151537]
	TIME [epoch: 9.82 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.201086731138123		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 2.201086731138123 | validation: 3.000451135631755]
	TIME [epoch: 9.81 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.946097604893584		[learning rate: 0.0098843]
	Learning Rate: 0.00988433
	LOSS [training: 2.946097604893584 | validation: 1.8670305078843887]
	TIME [epoch: 9.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8380350471628093		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 2.8380350471628093 | validation: 2.7085256009410172]
	TIME [epoch: 9.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9977544596229704		[learning rate: 0.0098365]
	Learning Rate: 0.00983653
	LOSS [training: 2.9977544596229704 | validation: 2.0713055678995245]
	TIME [epoch: 9.82 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7928482943091992		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 1.7928482943091992 | validation: 1.7076325345530483]
	TIME [epoch: 9.81 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2667471648304		[learning rate: 0.009789]
	Learning Rate: 0.00978897
	LOSS [training: 1.2667471648304 | validation: 0.9761673243547719]
	TIME [epoch: 9.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1941913354048332		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 1.1941913354048332 | validation: 1.254644494414091]
	TIME [epoch: 9.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9437052577591588		[learning rate: 0.0097416]
	Learning Rate: 0.00974163
	LOSS [training: 0.9437052577591588 | validation: 0.7607311146291889]
	TIME [epoch: 9.83 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7017237937938162		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 0.7017237937938162 | validation: 1.0512093890079763]
	TIME [epoch: 9.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6466022556023834		[learning rate: 0.0096945]
	Learning Rate: 0.00969452
	LOSS [training: 1.6466022556023834 | validation: 2.795499673529207]
	TIME [epoch: 9.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.336993460764508		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 3.336993460764508 | validation: 2.1709465629734037]
	TIME [epoch: 9.82 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2423092450273443		[learning rate: 0.0096476]
	Learning Rate: 0.00964764
	LOSS [training: 2.2423092450273443 | validation: 1.0829864369367044]
	TIME [epoch: 9.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9200387166040601		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 0.9200387166040601 | validation: 0.961494516827811]
	TIME [epoch: 9.79 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3725074603031024		[learning rate: 0.009601]
	Learning Rate: 0.00960098
	LOSS [training: 1.3725074603031024 | validation: 0.7971732774255955]
	TIME [epoch: 9.79 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0242210098755558		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 1.0242210098755558 | validation: 1.0691176192534126]
	TIME [epoch: 9.82 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9462706855226435		[learning rate: 0.0095546]
	Learning Rate: 0.00955456
	LOSS [training: 0.9462706855226435 | validation: 0.5803031007701516]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2514901648831582		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 1.2514901648831582 | validation: 0.7718118790576136]
	TIME [epoch: 9.79 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5984220407238392		[learning rate: 0.0095084]
	Learning Rate: 0.00950835
	LOSS [training: 1.5984220407238392 | validation: 1.0746738945023608]
	TIME [epoch: 9.81 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1284334917280465		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 1.1284334917280465 | validation: 0.8373960142021527]
	TIME [epoch: 9.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8760030304126338		[learning rate: 0.0094624]
	Learning Rate: 0.00946237
	LOSS [training: 0.8760030304126338 | validation: 0.8732371985924705]
	TIME [epoch: 9.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7697495288179182		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 0.7697495288179182 | validation: 0.909772507369979]
	TIME [epoch: 9.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6213877460564072		[learning rate: 0.0094166]
	Learning Rate: 0.00941661
	LOSS [training: 0.6213877460564072 | validation: 0.7387210720171978]
	TIME [epoch: 9.82 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8147603821858915		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 0.8147603821858915 | validation: 0.8849199889823983]
	TIME [epoch: 9.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1820488193940464		[learning rate: 0.0093711]
	Learning Rate: 0.00937108
	LOSS [training: 1.1820488193940464 | validation: 2.4054129638447006]
	TIME [epoch: 9.79 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8713587390905935		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.8713587390905935 | validation: 1.4071366293221794]
	TIME [epoch: 9.82 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6244604841322556		[learning rate: 0.0093258]
	Learning Rate: 0.00932576
	LOSS [training: 1.6244604841322556 | validation: 2.4296659429137812]
	TIME [epoch: 9.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0919291564738987		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 3.0919291564738987 | validation: 2.4425894566039763]
	TIME [epoch: 9.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.124373959189526		[learning rate: 0.0092807]
	Learning Rate: 0.00928066
	LOSS [training: 3.124373959189526 | validation: 2.3755433357947777]
	TIME [epoch: 9.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.027340177966377		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 3.027340177966377 | validation: 2.1645418434370836]
	TIME [epoch: 9.82 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.170582181200709		[learning rate: 0.0092358]
	Learning Rate: 0.00923578
	LOSS [training: 2.170582181200709 | validation: 0.8654883998075821]
	TIME [epoch: 9.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.31027857263393		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 1.31027857263393 | validation: 1.3541462905390744]
	TIME [epoch: 9.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2137208575188285		[learning rate: 0.0091911]
	Learning Rate: 0.00919112
	LOSS [training: 1.2137208575188285 | validation: 1.0339378952034979]
	TIME [epoch: 9.81 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0890868138360472		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.0890868138360472 | validation: 0.7118841330392714]
	TIME [epoch: 9.81 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8771864918766832		[learning rate: 0.0091467]
	Learning Rate: 0.00914667
	LOSS [training: 0.8771864918766832 | validation: 0.8600533358212173]
	TIME [epoch: 9.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8465175865475709		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 0.8465175865475709 | validation: 0.7284612447499982]
	TIME [epoch: 9.79 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9245791917107088		[learning rate: 0.0091024]
	Learning Rate: 0.00910244
	LOSS [training: 0.9245791917107088 | validation: 0.8069312956219225]
	TIME [epoch: 9.82 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.995725618230539		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 0.995725618230539 | validation: 0.7894011359657864]
	TIME [epoch: 9.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0143529989543971		[learning rate: 0.0090584]
	Learning Rate: 0.00905842
	LOSS [training: 1.0143529989543971 | validation: 1.0887704641731366]
	TIME [epoch: 9.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.057270197447842		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.057270197447842 | validation: 1.6452406364601748]
	TIME [epoch: 9.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0076247893222963		[learning rate: 0.0090146]
	Learning Rate: 0.00901462
	LOSS [training: 3.0076247893222963 | validation: 2.40626790855479]
	TIME [epoch: 9.83 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.10124763373611		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 3.10124763373611 | validation: 2.342206083873422]
	TIME [epoch: 9.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0469242192042856		[learning rate: 0.008971]
	Learning Rate: 0.00897103
	LOSS [training: 3.0469242192042856 | validation: 2.2941814269507814]
	TIME [epoch: 9.79 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.001651953900876		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 3.001651953900876 | validation: 2.366664306067875]
	TIME [epoch: 9.82 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1262678955791903		[learning rate: 0.0089276]
	Learning Rate: 0.00892764
	LOSS [training: 3.1262678955791903 | validation: 2.2868806989672352]
	TIME [epoch: 9.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.88721954305143		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 2.88721954305143 | validation: 2.3493202033272884]
	TIME [epoch: 9.8 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.002271297217522		[learning rate: 0.0088845]
	Learning Rate: 0.00888447
	LOSS [training: 3.002271297217522 | validation: 2.3254207437862955]
	TIME [epoch: 9.8 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.89240471367019		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 2.89240471367019 | validation: 2.1721197571331947]
	TIME [epoch: 9.81 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.837123094128432		[learning rate: 0.0088415]
	Learning Rate: 0.00884151
	LOSS [training: 2.837123094128432 | validation: 2.9147166294167977]
	TIME [epoch: 9.79 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9785851948120348		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 2.9785851948120348 | validation: 1.3399245240666529]
	TIME [epoch: 9.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.184018193490108		[learning rate: 0.0087988]
	Learning Rate: 0.00879875
	LOSS [training: 1.184018193490108 | validation: 2.4373551777894478]
	TIME [epoch: 9.82 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0341087805362252		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 3.0341087805362252 | validation: 2.2573848058737402]
	TIME [epoch: 9.8 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8826447917979423		[learning rate: 0.0087562]
	Learning Rate: 0.0087562
	LOSS [training: 2.8826447917979423 | validation: 1.7910992510495727]
	TIME [epoch: 9.79 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7727460362224043		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 2.7727460362224043 | validation: 1.9065589240386527]
	TIME [epoch: 9.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6510099458164		[learning rate: 0.0087139]
	Learning Rate: 0.00871386
	LOSS [training: 1.6510099458164 | validation: 0.857091462987669]
	TIME [epoch: 9.81 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8631724649208735		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 0.8631724649208735 | validation: 0.5921294693959962]
	TIME [epoch: 9.8 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7882199572128565		[learning rate: 0.0086717]
	Learning Rate: 0.00867172
	LOSS [training: 0.7882199572128565 | validation: 0.5874514126831645]
	TIME [epoch: 9.81 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0085686152453044		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 1.0085686152453044 | validation: 1.1071257148727758]
	TIME [epoch: 9.82 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0339248463890405		[learning rate: 0.0086298]
	Learning Rate: 0.00862979
	LOSS [training: 2.0339248463890405 | validation: 2.039306247542914]
	TIME [epoch: 9.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.612388077960963		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 2.612388077960963 | validation: 2.249922122994561]
	TIME [epoch: 9.79 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8267733017756953		[learning rate: 0.0085881]
	Learning Rate: 0.00858805
	LOSS [training: 2.8267733017756953 | validation: 2.4395232874980604]
	TIME [epoch: 9.8 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6878666390628876		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 2.6878666390628876 | validation: 1.9287185682049193]
	TIME [epoch: 9.82 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.156044078239893		[learning rate: 0.0085465]
	Learning Rate: 0.00854652
	LOSS [training: 2.156044078239893 | validation: 0.7916744742895901]
	TIME [epoch: 9.79 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3578893768489089		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 1.3578893768489089 | validation: 1.237904171954978]
	TIME [epoch: 9.8 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1456177536106869		[learning rate: 0.0085052]
	Learning Rate: 0.00850519
	LOSS [training: 1.1456177536106869 | validation: 0.8799184306320987]
	TIME [epoch: 9.81 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9427675829111581		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 0.9427675829111581 | validation: 1.0184277207495998]
	TIME [epoch: 9.82 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9488243267178731		[learning rate: 0.0084641]
	Learning Rate: 0.00846406
	LOSS [training: 0.9488243267178731 | validation: 0.6091801072498257]
	TIME [epoch: 9.81 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.796340061025383		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.796340061025383 | validation: 1.1815772603075916]
	TIME [epoch: 9.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0725118942252514		[learning rate: 0.0084231]
	Learning Rate: 0.00842313
	LOSS [training: 1.0725118942252514 | validation: 0.8161835543851492]
	TIME [epoch: 9.83 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8210034003120672		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.8210034003120672 | validation: 0.801158500390959]
	TIME [epoch: 9.8 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7328554562816708		[learning rate: 0.0083824]
	Learning Rate: 0.0083824
	LOSS [training: 0.7328554562816708 | validation: 0.6521726059556968]
	TIME [epoch: 9.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3748301290031262		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 1.3748301290031262 | validation: 1.023759662227836]
	TIME [epoch: 9.79 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5267583146547286		[learning rate: 0.0083419]
	Learning Rate: 0.00834186
	LOSS [training: 1.5267583146547286 | validation: 0.8504306981874787]
	TIME [epoch: 9.82 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.284346039399164		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.284346039399164 | validation: 1.8388049744276882]
	TIME [epoch: 9.81 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7197047531683562		[learning rate: 0.0083015]
	Learning Rate: 0.00830153
	LOSS [training: 1.7197047531683562 | validation: 1.144805313470969]
	TIME [epoch: 9.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.049531699750792		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.049531699750792 | validation: 0.896684912049619]
	TIME [epoch: 9.81 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9944511336263494		[learning rate: 0.0082614]
	Learning Rate: 0.00826138
	LOSS [training: 0.9944511336263494 | validation: 0.6205534182136114]
	TIME [epoch: 9.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7168646871115001		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.7168646871115001 | validation: 0.6208927085500686]
	TIME [epoch: 9.81 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8802519644511287		[learning rate: 0.0082214]
	Learning Rate: 0.00822143
	LOSS [training: 0.8802519644511287 | validation: 1.3178992238524379]
	TIME [epoch: 9.8 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2448437996985735		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 1.2448437996985735 | validation: 0.5580110475881528]
	TIME [epoch: 9.83 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_182.pth
	Model improved!!!
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8781996924706028		[learning rate: 0.0081817]
	Learning Rate: 0.00818167
	LOSS [training: 0.8781996924706028 | validation: 0.7572501624042246]
	TIME [epoch: 9.79 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8783039640011413		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.8783039640011413 | validation: 0.8172383742895786]
	TIME [epoch: 9.79 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9310665764500389		[learning rate: 0.0081421]
	Learning Rate: 0.00814211
	LOSS [training: 0.9310665764500389 | validation: 1.1428650454551716]
	TIME [epoch: 9.81 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9182764989000887		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 0.9182764989000887 | validation: 0.7687730751109626]
	TIME [epoch: 9.79 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8625946604525236		[learning rate: 0.0081027]
	Learning Rate: 0.00810273
	LOSS [training: 0.8625946604525236 | validation: 0.8575142184421901]
	TIME [epoch: 9.79 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9816287236092605		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 0.9816287236092605 | validation: 0.8781211433061762]
	TIME [epoch: 9.79 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0926006146439073		[learning rate: 0.0080636]
	Learning Rate: 0.00806355
	LOSS [training: 1.0926006146439073 | validation: 1.539957784229579]
	TIME [epoch: 9.82 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8317085555691358		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 0.8317085555691358 | validation: 0.6951779178466965]
	TIME [epoch: 9.79 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7663189344463027		[learning rate: 0.0080246]
	Learning Rate: 0.00802456
	LOSS [training: 0.7663189344463027 | validation: 0.9073673918770052]
	TIME [epoch: 9.79 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9020307184836905		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 0.9020307184836905 | validation: 0.7397165750965218]
	TIME [epoch: 9.81 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5498390172635199		[learning rate: 0.0079858]
	Learning Rate: 0.00798575
	LOSS [training: 0.5498390172635199 | validation: 0.5352719507038465]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5160735512088281		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.5160735512088281 | validation: 0.5681424333258924]
	TIME [epoch: 9.79 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5366854115880791		[learning rate: 0.0079471]
	Learning Rate: 0.00794713
	LOSS [training: 0.5366854115880791 | validation: 0.5216925444952272]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0409647927511927		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 1.0409647927511927 | validation: 2.7271686854297035]
	TIME [epoch: 9.81 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7545332339367967		[learning rate: 0.0079087]
	Learning Rate: 0.0079087
	LOSS [training: 1.7545332339367967 | validation: 0.8606814733030567]
	TIME [epoch: 9.79 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7335739080016708		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 0.7335739080016708 | validation: 0.6302965188560838]
	TIME [epoch: 9.79 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7108376040433121		[learning rate: 0.0078705]
	Learning Rate: 0.00787046
	LOSS [training: 0.7108376040433121 | validation: 0.6792374530175941]
	TIME [epoch: 9.81 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5318140700623721		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 1.5318140700623721 | validation: 1.6579036310559314]
	TIME [epoch: 9.79 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6938267851552022		[learning rate: 0.0078324]
	Learning Rate: 0.0078324
	LOSS [training: 1.6938267851552022 | validation: 0.8027614402958085]
	TIME [epoch: 9.78 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8423585483414506		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 0.8423585483414506 | validation: 0.5842055046839362]
	TIME [epoch: 9.79 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.022763485453785		[learning rate: 0.0077945]
	Learning Rate: 0.00779452
	LOSS [training: 1.022763485453785 | validation: 1.120923535119371]
	TIME [epoch: 9.81 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4633494926073758		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 1.4633494926073758 | validation: 1.5720798917504457]
	TIME [epoch: 9.78 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3550366222903125		[learning rate: 0.0077568]
	Learning Rate: 0.00775683
	LOSS [training: 1.3550366222903125 | validation: 2.1428145017835027]
	TIME [epoch: 9.79 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.55393194635569		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.55393194635569 | validation: 0.7690196168899877]
	TIME [epoch: 9.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8010641957364198		[learning rate: 0.0077193]
	Learning Rate: 0.00771932
	LOSS [training: 0.8010641957364198 | validation: 0.7085297724380923]
	TIME [epoch: 9.8 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7727986783533269		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.7727986783533269 | validation: 0.6393463826200546]
	TIME [epoch: 9.79 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7710567321332988		[learning rate: 0.007682]
	Learning Rate: 0.00768199
	LOSS [training: 0.7710567321332988 | validation: 0.7330136446482644]
	TIME [epoch: 9.78 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0739530585999353		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 1.0739530585999353 | validation: 1.333690261533335]
	TIME [epoch: 9.81 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1406067789403367		[learning rate: 0.0076448]
	Learning Rate: 0.00764484
	LOSS [training: 1.1406067789403367 | validation: 0.6754533799661455]
	TIME [epoch: 9.79 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8106423679767543		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.8106423679767543 | validation: 0.5290508516646836]
	TIME [epoch: 9.79 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5800089837939278		[learning rate: 0.0076079]
	Learning Rate: 0.00760787
	LOSS [training: 0.5800089837939278 | validation: 0.5821762939391035]
	TIME [epoch: 9.8 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7170356218307925		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 0.7170356218307925 | validation: 0.5408752346479]
	TIME [epoch: 9.81 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7624724574933861		[learning rate: 0.0075711]
	Learning Rate: 0.00757108
	LOSS [training: 0.7624724574933861 | validation: 0.6436228944927678]
	TIME [epoch: 9.79 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5867915337599637		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 0.5867915337599637 | validation: 0.4784863621814985]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_216.pth
	Model improved!!!
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5474956817007286		[learning rate: 0.0075345]
	Learning Rate: 0.00753447
	LOSS [training: 0.5474956817007286 | validation: 0.6375557740226574]
	TIME [epoch: 9.83 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7529842445448647		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.7529842445448647 | validation: 0.5762332193117916]
	TIME [epoch: 9.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.671572684600084		[learning rate: 0.007498]
	Learning Rate: 0.00749803
	LOSS [training: 0.671572684600084 | validation: 0.6057336489666135]
	TIME [epoch: 9.79 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5964597861745187		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.5964597861745187 | validation: 0.7454615146652092]
	TIME [epoch: 9.78 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7084232231874324		[learning rate: 0.0074618]
	Learning Rate: 0.00746177
	LOSS [training: 0.7084232231874324 | validation: 0.6705650502960623]
	TIME [epoch: 9.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.620533613291931		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.620533613291931 | validation: 0.5712021805260808]
	TIME [epoch: 9.79 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7704877164078306		[learning rate: 0.0074257]
	Learning Rate: 0.00742569
	LOSS [training: 0.7704877164078306 | validation: 0.7792703415920151]
	TIME [epoch: 9.79 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7856250130551068		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.7856250130551068 | validation: 0.6342518324375818]
	TIME [epoch: 9.81 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5628765400552284		[learning rate: 0.0073898]
	Learning Rate: 0.00738978
	LOSS [training: 0.5628765400552284 | validation: 0.7570656768453747]
	TIME [epoch: 9.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.611704559468439		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.611704559468439 | validation: 1.0156227968370244]
	TIME [epoch: 9.78 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6344117728351755		[learning rate: 0.007354]
	Learning Rate: 0.00735405
	LOSS [training: 0.6344117728351755 | validation: 0.6628398152050952]
	TIME [epoch: 9.79 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6708730012706434		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.6708730012706434 | validation: 0.6377909417043922]
	TIME [epoch: 9.82 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.667461517773203		[learning rate: 0.0073185]
	Learning Rate: 0.00731848
	LOSS [training: 0.667461517773203 | validation: 0.6341699306573362]
	TIME [epoch: 9.78 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3990929798566216		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 1.3990929798566216 | validation: 0.6436764296458718]
	TIME [epoch: 9.79 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.702548813582128		[learning rate: 0.0072831]
	Learning Rate: 0.00728309
	LOSS [training: 0.702548813582128 | validation: 0.7077741227969853]
	TIME [epoch: 9.79 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5562882325932553		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.5562882325932553 | validation: 0.5946971989876572]
	TIME [epoch: 9.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5446330701270702		[learning rate: 0.0072479]
	Learning Rate: 0.00724787
	LOSS [training: 0.5446330701270702 | validation: 0.5919341751039862]
	TIME [epoch: 9.79 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0185132567030277		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 1.0185132567030277 | validation: 2.9060601755735154]
	TIME [epoch: 9.77 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0393353365228426		[learning rate: 0.0072128]
	Learning Rate: 0.00721282
	LOSS [training: 1.0393353365228426 | validation: 0.625659405076771]
	TIME [epoch: 9.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6099231996744932		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 0.6099231996744932 | validation: 0.6765536552847765]
	TIME [epoch: 9.78 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5384085765795396		[learning rate: 0.0071779]
	Learning Rate: 0.00717794
	LOSS [training: 0.5384085765795396 | validation: 0.5609427256948604]
	TIME [epoch: 9.78 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5449277224521631		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.5449277224521631 | validation: 0.6390973045199406]
	TIME [epoch: 9.79 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6047332988583205		[learning rate: 0.0071432]
	Learning Rate: 0.00714323
	LOSS [training: 0.6047332988583205 | validation: 0.6012550756661256]
	TIME [epoch: 9.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5230527231078476		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 0.5230527231078476 | validation: 0.6072848050914051]
	TIME [epoch: 9.79 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5228424473205564		[learning rate: 0.0071087]
	Learning Rate: 0.00710869
	LOSS [training: 0.5228424473205564 | validation: 0.6506084911305281]
	TIME [epoch: 9.79 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5749868270964582		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.5749868270964582 | validation: 0.6902872372790292]
	TIME [epoch: 9.83 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6186383794827147		[learning rate: 0.0070743]
	Learning Rate: 0.00707431
	LOSS [training: 0.6186383794827147 | validation: 0.5879991439279183]
	TIME [epoch: 9.78 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6362528891398058		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.6362528891398058 | validation: 0.5988833519721596]
	TIME [epoch: 9.79 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5996907827994485		[learning rate: 0.0070401]
	Learning Rate: 0.0070401
	LOSS [training: 0.5996907827994485 | validation: 0.5997478892761265]
	TIME [epoch: 9.79 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6151239116143972		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.6151239116143972 | validation: 0.7719068942945289]
	TIME [epoch: 9.82 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6627068188080587		[learning rate: 0.0070061]
	Learning Rate: 0.00700606
	LOSS [training: 0.6627068188080587 | validation: 1.2562709068660323]
	TIME [epoch: 9.79 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8270294396004708		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.8270294396004708 | validation: 2.2358303401897666]
	TIME [epoch: 9.79 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8511497656772016		[learning rate: 0.0069722]
	Learning Rate: 0.00697218
	LOSS [training: 1.8511497656772016 | validation: 2.714079941261034]
	TIME [epoch: 9.8 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6739142031826968		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.6739142031826968 | validation: 0.6788733895486986]
	TIME [epoch: 9.78 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6509684725910916		[learning rate: 0.0069385]
	Learning Rate: 0.00693846
	LOSS [training: 0.6509684725910916 | validation: 0.7799256618724784]
	TIME [epoch: 9.77 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7637203687527397		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.7637203687527397 | validation: 0.7411000257175008]
	TIME [epoch: 9.78 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6270241548943485		[learning rate: 0.0069049]
	Learning Rate: 0.00690491
	LOSS [training: 0.6270241548943485 | validation: 0.7821716071742317]
	TIME [epoch: 9.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6197651805156882		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.6197651805156882 | validation: 0.6776209690269434]
	TIME [epoch: 9.76 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5778533845921784		[learning rate: 0.0068715]
	Learning Rate: 0.00687152
	LOSS [training: 0.5778533845921784 | validation: 0.6392491832128778]
	TIME [epoch: 9.78 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6309189430839063		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.6309189430839063 | validation: 0.6889197583026153]
	TIME [epoch: 9.81 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6687455722088432		[learning rate: 0.0068383]
	Learning Rate: 0.00683829
	LOSS [training: 0.6687455722088432 | validation: 0.7254957808646121]
	TIME [epoch: 9.79 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7433399934495007		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.7433399934495007 | validation: 0.8361972950071852]
	TIME [epoch: 9.78 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.71977320944161		[learning rate: 0.0068052]
	Learning Rate: 0.00680522
	LOSS [training: 0.71977320944161 | validation: 0.8680878491534927]
	TIME [epoch: 9.79 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6141114392874543		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.6141114392874543 | validation: 0.4054227196183126]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_260.pth
	Model improved!!!
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4557857118548615		[learning rate: 0.0067723]
	Learning Rate: 0.00677231
	LOSS [training: 0.4557857118548615 | validation: 0.5474012290010016]
	TIME [epoch: 9.78 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5375457680344693		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.5375457680344693 | validation: 0.8267400064931953]
	TIME [epoch: 9.79 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7724526982762179		[learning rate: 0.0067396]
	Learning Rate: 0.00673956
	LOSS [training: 0.7724526982762179 | validation: 0.6935001622367963]
	TIME [epoch: 9.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5453100941727403		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.5453100941727403 | validation: 0.631567811574309]
	TIME [epoch: 9.8 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5167206252072786		[learning rate: 0.006707]
	Learning Rate: 0.00670697
	LOSS [training: 0.5167206252072786 | validation: 0.7131986529532526]
	TIME [epoch: 9.78 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7483549842534027		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.7483549842534027 | validation: 0.6946197212319372]
	TIME [epoch: 9.79 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6294413733479255		[learning rate: 0.0066745]
	Learning Rate: 0.00667454
	LOSS [training: 0.6294413733479255 | validation: 0.7285109193132364]
	TIME [epoch: 9.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.615240154490414		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.615240154490414 | validation: 0.6312940334708907]
	TIME [epoch: 9.79 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6507145200990088		[learning rate: 0.0066423]
	Learning Rate: 0.00664226
	LOSS [training: 0.6507145200990088 | validation: 0.8329969781901656]
	TIME [epoch: 9.79 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7088369179200553		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.7088369179200553 | validation: 2.098736225451838]
	TIME [epoch: 9.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.907535421790248		[learning rate: 0.0066101]
	Learning Rate: 0.00661014
	LOSS [training: 0.907535421790248 | validation: 0.6173549482371893]
	TIME [epoch: 9.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6173397926719096		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.6173397926719096 | validation: 0.7744494391132918]
	TIME [epoch: 9.79 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5517344026904213		[learning rate: 0.0065782]
	Learning Rate: 0.00657817
	LOSS [training: 0.5517344026904213 | validation: 0.44948339424348616]
	TIME [epoch: 9.79 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4281021876630752		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.4281021876630752 | validation: 0.49737509432510946]
	TIME [epoch: 9.81 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9852928160432117		[learning rate: 0.0065464]
	Learning Rate: 0.00654636
	LOSS [training: 0.9852928160432117 | validation: 0.9463148216118253]
	TIME [epoch: 9.79 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.275982634579957		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 1.275982634579957 | validation: 0.6611874059138488]
	TIME [epoch: 9.79 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8614528951909322		[learning rate: 0.0065147]
	Learning Rate: 0.0065147
	LOSS [training: 0.8614528951909322 | validation: 0.488092227077707]
	TIME [epoch: 9.79 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5565393224020847		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.5565393224020847 | validation: 0.541311989029192]
	TIME [epoch: 9.81 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6052410859249686		[learning rate: 0.0064832]
	Learning Rate: 0.0064832
	LOSS [training: 0.6052410859249686 | validation: 0.6076172344193245]
	TIME [epoch: 9.79 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5547408955136818		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.5547408955136818 | validation: 0.6604666992171389]
	TIME [epoch: 9.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4497960481276779		[learning rate: 0.0064518]
	Learning Rate: 0.00645185
	LOSS [training: 0.4497960481276779 | validation: 0.5649666441293614]
	TIME [epoch: 9.81 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5973464793262837		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.5973464793262837 | validation: 0.422742491075973]
	TIME [epoch: 9.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.507391943152879		[learning rate: 0.0064206]
	Learning Rate: 0.00642065
	LOSS [training: 0.507391943152879 | validation: 0.5572928969323024]
	TIME [epoch: 9.78 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47014429232172406		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.47014429232172406 | validation: 0.4862941787334247]
	TIME [epoch: 9.79 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4832710840693438		[learning rate: 0.0063896]
	Learning Rate: 0.0063896
	LOSS [training: 0.4832710840693438 | validation: 0.4119026541653362]
	TIME [epoch: 9.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5101082713277371		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.5101082713277371 | validation: 0.4143449571751866]
	TIME [epoch: 9.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5263331291293107		[learning rate: 0.0063587]
	Learning Rate: 0.0063587
	LOSS [training: 0.5263331291293107 | validation: 0.8071723559527746]
	TIME [epoch: 9.79 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5975342442176013		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.5975342442176013 | validation: 0.38486358699590995]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_288.pth
	Model improved!!!
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5436978680389737		[learning rate: 0.006328]
	Learning Rate: 0.00632795
	LOSS [training: 0.5436978680389737 | validation: 1.5167414061151057]
	TIME [epoch: 9.79 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0201677675575558		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 1.0201677675575558 | validation: 0.7926779869587496]
	TIME [epoch: 9.78 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6313770495850386		[learning rate: 0.0062974]
	Learning Rate: 0.00629735
	LOSS [training: 0.6313770495850386 | validation: 0.7272538240347746]
	TIME [epoch: 9.79 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5448129830212995		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.5448129830212995 | validation: 0.5058284441758673]
	TIME [epoch: 9.82 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219500897982947		[learning rate: 0.0062669]
	Learning Rate: 0.0062669
	LOSS [training: 0.5219500897982947 | validation: 0.6033662652187904]
	TIME [epoch: 9.79 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49656109620492045		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.49656109620492045 | validation: 0.5659689883772536]
	TIME [epoch: 9.79 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6882887145013803		[learning rate: 0.0062366]
	Learning Rate: 0.00623659
	LOSS [training: 0.6882887145013803 | validation: 0.7940206779409427]
	TIME [epoch: 9.81 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7670002352058809		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.7670002352058809 | validation: 0.5357205957127786]
	TIME [epoch: 9.81 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.557084518038804		[learning rate: 0.0062064]
	Learning Rate: 0.00620643
	LOSS [training: 0.557084518038804 | validation: 0.6977921230865997]
	TIME [epoch: 9.8 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.816521168436763		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.816521168436763 | validation: 0.5828955285870621]
	TIME [epoch: 9.79 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7535142429347299		[learning rate: 0.0061764]
	Learning Rate: 0.00617642
	LOSS [training: 0.7535142429347299 | validation: 0.44793687169196345]
	TIME [epoch: 9.82 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5106299583369706		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.5106299583369706 | validation: 0.7340782030106593]
	TIME [epoch: 9.8 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7004141362830004		[learning rate: 0.0061466]
	Learning Rate: 0.00614655
	LOSS [training: 0.7004141362830004 | validation: 0.6353901604851243]
	TIME [epoch: 9.79 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.855790050134815		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.855790050134815 | validation: 0.7580375234532007]
	TIME [epoch: 9.81 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.665849692226462		[learning rate: 0.0061168]
	Learning Rate: 0.00611683
	LOSS [training: 0.665849692226462 | validation: 0.6061116008858113]
	TIME [epoch: 9.81 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7652449280819276		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.7652449280819276 | validation: 0.6612419663106728]
	TIME [epoch: 9.79 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7132876347459676		[learning rate: 0.0060872]
	Learning Rate: 0.00608725
	LOSS [training: 0.7132876347459676 | validation: 0.5972066593477621]
	TIME [epoch: 9.79 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5858567725769017		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.5858567725769017 | validation: 0.45669503448036486]
	TIME [epoch: 9.82 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6493995346789356		[learning rate: 0.0060578]
	Learning Rate: 0.00605781
	LOSS [training: 0.6493995346789356 | validation: 0.5497367545455132]
	TIME [epoch: 9.79 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5409179886103084		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.5409179886103084 | validation: 0.7493784424274942]
	TIME [epoch: 9.79 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8068328407492078		[learning rate: 0.0060285]
	Learning Rate: 0.00602852
	LOSS [training: 0.8068328407492078 | validation: 1.084086476492681]
	TIME [epoch: 9.79 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0775145808998883		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 1.0775145808998883 | validation: 1.5831383685056775]
	TIME [epoch: 9.8 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3131059059362007		[learning rate: 0.0059994]
	Learning Rate: 0.00599936
	LOSS [training: 1.3131059059362007 | validation: 0.804439129207355]
	TIME [epoch: 9.79 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3973581926742535		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 1.3973581926742535 | validation: 1.632244171781282]
	TIME [epoch: 9.78 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2649825496651055		[learning rate: 0.0059704]
	Learning Rate: 0.00597035
	LOSS [training: 1.2649825496651055 | validation: 0.9487562410116701]
	TIME [epoch: 9.81 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.39258593382116		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 1.39258593382116 | validation: 0.9608633301396018]
	TIME [epoch: 9.8 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7966182744231585		[learning rate: 0.0059415]
	Learning Rate: 0.00594148
	LOSS [training: 0.7966182744231585 | validation: 0.6515786727110556]
	TIME [epoch: 9.79 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8528853402555828		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.8528853402555828 | validation: 0.7190744474176554]
	TIME [epoch: 9.79 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5492365190917681		[learning rate: 0.0059127]
	Learning Rate: 0.00591275
	LOSS [training: 0.5492365190917681 | validation: 0.46385212136505516]
	TIME [epoch: 9.81 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4326531614204903		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.4326531614204903 | validation: 0.5009233854702231]
	TIME [epoch: 9.79 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5999748644373873		[learning rate: 0.0058842]
	Learning Rate: 0.00588416
	LOSS [training: 0.5999748644373873 | validation: 0.5617403445407335]
	TIME [epoch: 9.79 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49362552371800367		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.49362552371800367 | validation: 0.5908922995038788]
	TIME [epoch: 9.81 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5520815982059858		[learning rate: 0.0058557]
	Learning Rate: 0.0058557
	LOSS [training: 0.5520815982059858 | validation: 0.4275183550526954]
	TIME [epoch: 9.79 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46355441429733224		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.46355441429733224 | validation: 0.5058429262763431]
	TIME [epoch: 9.79 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48025782445582266		[learning rate: 0.0058274]
	Learning Rate: 0.00582738
	LOSS [training: 0.48025782445582266 | validation: 0.37941477191662487]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_323.pth
	Model improved!!!
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182313292846455		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.4182313292846455 | validation: 0.35508601491935976]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36234741464592546		[learning rate: 0.0057992]
	Learning Rate: 0.0057992
	LOSS [training: 0.36234741464592546 | validation: 0.7012419232715462]
	TIME [epoch: 9.79 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5319219437694809		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.5319219437694809 | validation: 0.5365062335214202]
	TIME [epoch: 9.79 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4171412588971536		[learning rate: 0.0057712]
	Learning Rate: 0.00577116
	LOSS [training: 0.4171412588971536 | validation: 0.38039524367844985]
	TIME [epoch: 9.82 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4220820115391783		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.4220820115391783 | validation: 0.6680299965862261]
	TIME [epoch: 9.78 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4616318230544736		[learning rate: 0.0057433]
	Learning Rate: 0.00574325
	LOSS [training: 0.4616318230544736 | validation: 0.6963387340040439]
	TIME [epoch: 9.79 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4804575131580303		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.4804575131580303 | validation: 0.6556202114344288]
	TIME [epoch: 9.79 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5456124351078021		[learning rate: 0.0057155]
	Learning Rate: 0.00571548
	LOSS [training: 0.5456124351078021 | validation: 0.48969497197941636]
	TIME [epoch: 9.82 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5095659484325108		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.5095659484325108 | validation: 0.573389044945051]
	TIME [epoch: 9.79 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5774925678240334		[learning rate: 0.0056878]
	Learning Rate: 0.00568784
	LOSS [training: 0.5774925678240334 | validation: 0.5144607977478379]
	TIME [epoch: 9.78 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.395343943942564		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.395343943942564 | validation: 0.4492209849411461]
	TIME [epoch: 9.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4294950281544513		[learning rate: 0.0056603]
	Learning Rate: 0.00566033
	LOSS [training: 0.4294950281544513 | validation: 0.4162167612275077]
	TIME [epoch: 9.8 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5024931083409042		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.5024931083409042 | validation: 0.8436592393352527]
	TIME [epoch: 9.79 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6600548736479893		[learning rate: 0.005633]
	Learning Rate: 0.00563296
	LOSS [training: 0.6600548736479893 | validation: 0.5883273111345428]
	TIME [epoch: 9.79 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5173745574454904		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.5173745574454904 | validation: 0.5110976800753597]
	TIME [epoch: 9.81 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5962232294398098		[learning rate: 0.0056057]
	Learning Rate: 0.00560572
	LOSS [training: 0.5962232294398098 | validation: 0.5184159901880249]
	TIME [epoch: 9.79 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4286043932493489		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.4286043932493489 | validation: 0.4609190465224783]
	TIME [epoch: 9.78 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4696508245712111		[learning rate: 0.0055786]
	Learning Rate: 0.00557861
	LOSS [training: 0.4696508245712111 | validation: 0.4620871258093348]
	TIME [epoch: 9.8 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5065831695270951		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.5065831695270951 | validation: 0.4647937470145761]
	TIME [epoch: 9.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49792538314956014		[learning rate: 0.0055516]
	Learning Rate: 0.00555164
	LOSS [training: 0.49792538314956014 | validation: 0.4335860782625281]
	TIME [epoch: 9.79 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4405910571241036		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.4405910571241036 | validation: 0.5649239875098936]
	TIME [epoch: 9.8 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4878488537062745		[learning rate: 0.0055248]
	Learning Rate: 0.00552479
	LOSS [training: 0.4878488537062745 | validation: 0.5208323591241271]
	TIME [epoch: 9.81 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43619563643082887		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.43619563643082887 | validation: 0.5117068653097613]
	TIME [epoch: 9.79 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5350677647050184		[learning rate: 0.0054981]
	Learning Rate: 0.00549807
	LOSS [training: 0.5350677647050184 | validation: 0.5113142767511849]
	TIME [epoch: 9.78 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5157088014633342		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.5157088014633342 | validation: 0.6410441799138822]
	TIME [epoch: 9.79 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5533179842915874		[learning rate: 0.0054715]
	Learning Rate: 0.00547149
	LOSS [training: 0.5533179842915874 | validation: 0.6491801963942949]
	TIME [epoch: 9.8 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5758223499061426		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.5758223499061426 | validation: 0.5864138751274843]
	TIME [epoch: 9.78 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6108202840198207		[learning rate: 0.005445]
	Learning Rate: 0.00544503
	LOSS [training: 0.6108202840198207 | validation: 0.5893260916488057]
	TIME [epoch: 9.79 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6396262040043521		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.6396262040043521 | validation: 0.6896514328004062]
	TIME [epoch: 9.8 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5897527835517408		[learning rate: 0.0054187]
	Learning Rate: 0.0054187
	LOSS [training: 0.5897527835517408 | validation: 0.4692309120329994]
	TIME [epoch: 9.79 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.53643932754732		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.53643932754732 | validation: 0.5323025978986747]
	TIME [epoch: 9.78 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49404460094823766		[learning rate: 0.0053925]
	Learning Rate: 0.00539249
	LOSS [training: 0.49404460094823766 | validation: 0.41532505421771765]
	TIME [epoch: 9.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49333861811612517		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.49333861811612517 | validation: 0.4738328219254567]
	TIME [epoch: 9.8 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4849379776478062		[learning rate: 0.0053664]
	Learning Rate: 0.00536641
	LOSS [training: 0.4849379776478062 | validation: 0.4396229206999763]
	TIME [epoch: 9.79 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39034670820256034		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.39034670820256034 | validation: 0.4743044977200198]
	TIME [epoch: 9.79 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3915772958664169		[learning rate: 0.0053405]
	Learning Rate: 0.00534046
	LOSS [training: 0.3915772958664169 | validation: 0.5139816559290027]
	TIME [epoch: 9.79 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46730772959536315		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.46730772959536315 | validation: 0.6141032552749773]
	TIME [epoch: 9.78 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5061432839382739		[learning rate: 0.0053146]
	Learning Rate: 0.00531464
	LOSS [training: 0.5061432839382739 | validation: 0.6131348601420762]
	TIME [epoch: 9.79 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4953984419598475		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.4953984419598475 | validation: 0.6801406554640123]
	TIME [epoch: 9.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5256977898460564		[learning rate: 0.0052889]
	Learning Rate: 0.00528894
	LOSS [training: 0.5256977898460564 | validation: 0.4875526884133786]
	TIME [epoch: 9.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4342458588067835		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.4342458588067835 | validation: 0.5988957643598676]
	TIME [epoch: 9.79 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43623097980978176		[learning rate: 0.0052634]
	Learning Rate: 0.00526336
	LOSS [training: 0.43623097980978176 | validation: 0.4697145729094955]
	TIME [epoch: 9.8 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40712448431307646		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.40712448431307646 | validation: 0.396740776420335]
	TIME [epoch: 9.79 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3591428513551218		[learning rate: 0.0052379]
	Learning Rate: 0.00523791
	LOSS [training: 0.3591428513551218 | validation: 0.3107572645954696]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_367.pth
	Model improved!!!
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43389447172833523		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.43389447172833523 | validation: 0.42140199094784253]
	TIME [epoch: 9.78 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5285641366074074		[learning rate: 0.0052126]
	Learning Rate: 0.00521258
	LOSS [training: 0.5285641366074074 | validation: 0.49704747311099345]
	TIME [epoch: 9.79 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8019548190872943		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.8019548190872943 | validation: 0.6470963005680281]
	TIME [epoch: 9.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8698747096591234		[learning rate: 0.0051874]
	Learning Rate: 0.00518737
	LOSS [training: 0.8698747096591234 | validation: 0.4795213815936095]
	TIME [epoch: 9.78 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4981530887113747		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.4981530887113747 | validation: 0.7708717668305478]
	TIME [epoch: 9.78 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5841839322683975		[learning rate: 0.0051623]
	Learning Rate: 0.00516229
	LOSS [training: 0.5841839322683975 | validation: 0.5346046184453913]
	TIME [epoch: 9.79 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46841476558568085		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.46841476558568085 | validation: 0.5605380986203535]
	TIME [epoch: 9.81 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.419000944111423		[learning rate: 0.0051373]
	Learning Rate: 0.00513732
	LOSS [training: 1.419000944111423 | validation: 2.0632426061862805]
	TIME [epoch: 9.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4439502554465744		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 1.4439502554465744 | validation: 0.6539265098133357]
	TIME [epoch: 9.78 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7860776633677041		[learning rate: 0.0051125]
	Learning Rate: 0.00511248
	LOSS [training: 0.7860776633677041 | validation: 0.5179958680878756]
	TIME [epoch: 9.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5317128355326257		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.5317128355326257 | validation: 0.48443256375840493]
	TIME [epoch: 9.79 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5440540062950493		[learning rate: 0.0050878]
	Learning Rate: 0.00508776
	LOSS [training: 0.5440540062950493 | validation: 0.7413965404430966]
	TIME [epoch: 9.79 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6202699263072481		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.6202699263072481 | validation: 0.4874308956999099]
	TIME [epoch: 9.79 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4755301901560752		[learning rate: 0.0050632]
	Learning Rate: 0.00506315
	LOSS [training: 0.4755301901560752 | validation: 0.5924216539064011]
	TIME [epoch: 9.81 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227309809913726		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.5227309809913726 | validation: 0.4841210922513087]
	TIME [epoch: 9.79 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5202180059495076		[learning rate: 0.0050387]
	Learning Rate: 0.00503867
	LOSS [training: 0.5202180059495076 | validation: 0.4529234559315756]
	TIME [epoch: 9.79 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43448885572699664		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.43448885572699664 | validation: 0.41824887350356393]
	TIME [epoch: 9.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6106890993208056		[learning rate: 0.0050143]
	Learning Rate: 0.0050143
	LOSS [training: 0.6106890993208056 | validation: 0.6158176937075911]
	TIME [epoch: 9.79 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5691362969370463		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.5691362969370463 | validation: 0.6886009229668318]
	TIME [epoch: 9.79 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5605646102830685		[learning rate: 0.0049901]
	Learning Rate: 0.00499005
	LOSS [training: 0.5605646102830685 | validation: 0.616767584424933]
	TIME [epoch: 9.78 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5751412248595948		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.5751412248595948 | validation: 0.4574113028618859]
	TIME [epoch: 9.82 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5962652295965659		[learning rate: 0.0049659]
	Learning Rate: 0.00496592
	LOSS [training: 0.5962652295965659 | validation: 0.6164390041067273]
	TIME [epoch: 9.79 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9985550938352337		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.9985550938352337 | validation: 0.6038706237576965]
	TIME [epoch: 9.79 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7173796550155553		[learning rate: 0.0049419]
	Learning Rate: 0.00494191
	LOSS [training: 0.7173796550155553 | validation: 0.5008508588521068]
	TIME [epoch: 9.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5669238358014923		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.5669238358014923 | validation: 0.5546526548718009]
	TIME [epoch: 9.79 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5082699298868555		[learning rate: 0.004918]
	Learning Rate: 0.00491801
	LOSS [training: 0.5082699298868555 | validation: 0.44190063671865004]
	TIME [epoch: 9.8 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47317381094650013		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.47317381094650013 | validation: 0.5676512980603431]
	TIME [epoch: 9.78 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5937119743942064		[learning rate: 0.0048942]
	Learning Rate: 0.00489423
	LOSS [training: 0.5937119743942064 | validation: 0.5548567841269739]
	TIME [epoch: 9.81 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5323659524827058		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.5323659524827058 | validation: 0.4902840618829273]
	TIME [epoch: 9.78 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5130516086965962		[learning rate: 0.0048706]
	Learning Rate: 0.00487056
	LOSS [training: 0.5130516086965962 | validation: 0.44712701303849883]
	TIME [epoch: 9.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4228436613651749		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.4228436613651749 | validation: 0.4161138146441553]
	TIME [epoch: 9.8 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49297838780231185		[learning rate: 0.004847]
	Learning Rate: 0.00484701
	LOSS [training: 0.49297838780231185 | validation: 0.4517412229256611]
	TIME [epoch: 9.79 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8182052905035239		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.8182052905035239 | validation: 0.506007895960776]
	TIME [epoch: 9.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48310686140595366		[learning rate: 0.0048236]
	Learning Rate: 0.00482357
	LOSS [training: 0.48310686140595366 | validation: 0.4167192710292945]
	TIME [epoch: 9.79 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5269006112134191		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.5269006112134191 | validation: 0.4753081656379707]
	TIME [epoch: 9.82 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6663873348525661		[learning rate: 0.0048002]
	Learning Rate: 0.00480024
	LOSS [training: 0.6663873348525661 | validation: 0.9369088031779143]
	TIME [epoch: 9.79 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9165605640002876		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.9165605640002876 | validation: 0.4908239338621439]
	TIME [epoch: 9.79 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.510059640979158		[learning rate: 0.004777]
	Learning Rate: 0.00477703
	LOSS [training: 0.510059640979158 | validation: 0.4907686764752583]
	TIME [epoch: 9.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4619875728302995		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.4619875728302995 | validation: 0.5188785925607404]
	TIME [epoch: 9.82 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4792813044342715		[learning rate: 0.0047539]
	Learning Rate: 0.00475393
	LOSS [training: 0.4792813044342715 | validation: 0.4123357720932053]
	TIME [epoch: 9.79 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4868457627107349		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.4868457627107349 | validation: 0.4520335672483266]
	TIME [epoch: 9.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41930683676649777		[learning rate: 0.0047309]
	Learning Rate: 0.00473094
	LOSS [training: 0.41930683676649777 | validation: 0.5480533784714355]
	TIME [epoch: 9.82 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8202307467711479		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.8202307467711479 | validation: 0.5455786546415943]
	TIME [epoch: 9.79 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8619873824103632		[learning rate: 0.0047081]
	Learning Rate: 0.00470806
	LOSS [training: 0.8619873824103632 | validation: 0.7869456019664574]
	TIME [epoch: 9.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8578637561458148		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.8578637561458148 | validation: 0.46221626356750817]
	TIME [epoch: 9.79 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5575993356311827		[learning rate: 0.0046853]
	Learning Rate: 0.00468529
	LOSS [training: 0.5575993356311827 | validation: 0.45034749039343025]
	TIME [epoch: 9.82 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6436739669733242		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.6436739669733242 | validation: 0.7051430911506964]
	TIME [epoch: 9.8 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7192345700562156		[learning rate: 0.0046626]
	Learning Rate: 0.00466264
	LOSS [training: 0.7192345700562156 | validation: 0.6073319088835362]
	TIME [epoch: 9.79 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8135817779642848		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.8135817779642848 | validation: 0.6788581955946452]
	TIME [epoch: 9.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.699310280753211		[learning rate: 0.0046401]
	Learning Rate: 0.00464009
	LOSS [training: 0.699310280753211 | validation: 0.4412757359959028]
	TIME [epoch: 9.79 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5894478889546991		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.5894478889546991 | validation: 0.7240339956929666]
	TIME [epoch: 9.79 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8318730757889801		[learning rate: 0.0046177]
	Learning Rate: 0.00461765
	LOSS [training: 0.8318730757889801 | validation: 0.5751116725824481]
	TIME [epoch: 9.8 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5728045244172415		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.5728045244172415 | validation: 0.47752402705066554]
	TIME [epoch: 9.82 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4956464623210019		[learning rate: 0.0045953]
	Learning Rate: 0.00459532
	LOSS [training: 0.4956464623210019 | validation: 0.40609002924372734]
	TIME [epoch: 9.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5227569007843429		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.5227569007843429 | validation: 0.6827437886799413]
	TIME [epoch: 9.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.025716118521719		[learning rate: 0.0045731]
	Learning Rate: 0.0045731
	LOSS [training: 1.025716118521719 | validation: 0.7314059142110426]
	TIME [epoch: 9.81 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5876166504033826		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.5876166504033826 | validation: 0.38079713732263365]
	TIME [epoch: 9.8 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45193125477135165		[learning rate: 0.004551]
	Learning Rate: 0.00455098
	LOSS [training: 0.45193125477135165 | validation: 0.5165505914343453]
	TIME [epoch: 9.79 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.639348106145586		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.639348106145586 | validation: 0.507942251864337]
	TIME [epoch: 9.8 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5702671278072831		[learning rate: 0.004529]
	Learning Rate: 0.00452898
	LOSS [training: 0.5702671278072831 | validation: 0.37278235063546405]
	TIME [epoch: 9.82 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.458583952746119		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.458583952746119 | validation: 0.3961320566627917]
	TIME [epoch: 9.79 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4274250557858922		[learning rate: 0.0045071]
	Learning Rate: 0.00450707
	LOSS [training: 0.4274250557858922 | validation: 0.33155289975864544]
	TIME [epoch: 9.79 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31924009042821533		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.31924009042821533 | validation: 0.255988348476481]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_430.pth
	Model improved!!!
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29010358904942574		[learning rate: 0.0044853]
	Learning Rate: 0.00448528
	LOSS [training: 0.29010358904942574 | validation: 0.25744984426464207]
	TIME [epoch: 9.79 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35839829383263055		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.35839829383263055 | validation: 0.3572700054874878]
	TIME [epoch: 9.79 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33260579178956756		[learning rate: 0.0044636]
	Learning Rate: 0.00446359
	LOSS [training: 0.33260579178956756 | validation: 0.4534836182147384]
	TIME [epoch: 9.79 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34316584953114		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.34316584953114 | validation: 0.30570317757595766]
	TIME [epoch: 9.81 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2938323676472568		[learning rate: 0.004442]
	Learning Rate: 0.004442
	LOSS [training: 0.2938323676472568 | validation: 0.3871724164415016]
	TIME [epoch: 9.79 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39410368677185437		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.39410368677185437 | validation: 0.3116482428413619]
	TIME [epoch: 9.79 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3440061975823373		[learning rate: 0.0044205]
	Learning Rate: 0.00442052
	LOSS [training: 0.3440061975823373 | validation: 0.3805429777742493]
	TIME [epoch: 9.79 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3500984098112039		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.3500984098112039 | validation: 0.4522386908579627]
	TIME [epoch: 9.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40299434102380377		[learning rate: 0.0043991]
	Learning Rate: 0.00439915
	LOSS [training: 0.40299434102380377 | validation: 0.3803114084418918]
	TIME [epoch: 9.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38592966649367316		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.38592966649367316 | validation: 0.6321733392109848]
	TIME [epoch: 9.79 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5436797553345872		[learning rate: 0.0043779]
	Learning Rate: 0.00437787
	LOSS [training: 0.5436797553345872 | validation: 0.7676596288347155]
	TIME [epoch: 9.8 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6897388204406113		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.6897388204406113 | validation: 0.684980048728172]
	TIME [epoch: 9.78 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5186902467904344		[learning rate: 0.0043567]
	Learning Rate: 0.0043567
	LOSS [training: 0.5186902467904344 | validation: 0.8205581900337886]
	TIME [epoch: 9.79 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6363276484430471		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.6363276484430471 | validation: 0.5294226444363599]
	TIME [epoch: 9.79 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5226461245357078		[learning rate: 0.0043356]
	Learning Rate: 0.00433563
	LOSS [training: 0.5226461245357078 | validation: 0.5883258027235617]
	TIME [epoch: 9.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3843726716387791		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.3843726716387791 | validation: 0.2963166050685716]
	TIME [epoch: 9.78 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2643157632911047		[learning rate: 0.0043147]
	Learning Rate: 0.00431467
	LOSS [training: 0.2643157632911047 | validation: 0.29878800066365246]
	TIME [epoch: 9.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3653110862147436		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.3653110862147436 | validation: 0.5205510446102051]
	TIME [epoch: 9.8 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5499682874737216		[learning rate: 0.0042938]
	Learning Rate: 0.0042938
	LOSS [training: 0.5499682874737216 | validation: 0.6347667701803603]
	TIME [epoch: 9.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6479597858472693		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.6479597858472693 | validation: 0.4983134103592273]
	TIME [epoch: 9.79 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48906571764446005		[learning rate: 0.004273]
	Learning Rate: 0.00427304
	LOSS [training: 0.48906571764446005 | validation: 0.5345148683377889]
	TIME [epoch: 9.79 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48743942979200805		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.48743942979200805 | validation: 0.4763513026242116]
	TIME [epoch: 9.82 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9609186373388472		[learning rate: 0.0042524]
	Learning Rate: 0.00425238
	LOSS [training: 0.9609186373388472 | validation: 0.6507538118750672]
	TIME [epoch: 9.79 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7064560617220049		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.7064560617220049 | validation: 0.5224483497553128]
	TIME [epoch: 9.79 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4263555453041694		[learning rate: 0.0042318]
	Learning Rate: 0.00423181
	LOSS [training: 0.4263555453041694 | validation: 0.521519380417341]
	TIME [epoch: 9.82 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6201046932868373		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.6201046932868373 | validation: 0.5212129969377166]
	TIME [epoch: 9.8 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5163219591533961		[learning rate: 0.0042113]
	Learning Rate: 0.00421135
	LOSS [training: 0.5163219591533961 | validation: 0.49829581114117943]
	TIME [epoch: 9.78 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48668351194702125		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.48668351194702125 | validation: 0.5208197825767178]
	TIME [epoch: 9.78 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5182015265417091		[learning rate: 0.004191]
	Learning Rate: 0.00419098
	LOSS [training: 0.5182015265417091 | validation: 0.42681192110863225]
	TIME [epoch: 9.8 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6881640768219429		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.6881640768219429 | validation: 0.5685189442299685]
	TIME [epoch: 9.77 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6156070710760455		[learning rate: 0.0041707]
	Learning Rate: 0.00417071
	LOSS [training: 0.6156070710760455 | validation: 0.38788760355300517]
	TIME [epoch: 9.78 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9843049718324991		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.9843049718324991 | validation: 0.9237014857401887]
	TIME [epoch: 9.79 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8969004537930134		[learning rate: 0.0041505]
	Learning Rate: 0.00415055
	LOSS [training: 0.8969004537930134 | validation: 0.6234230979957778]
	TIME [epoch: 9.8 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6109821698340782		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.6109821698340782 | validation: 0.5253084834972324]
	TIME [epoch: 9.79 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6731126538585593		[learning rate: 0.0041305]
	Learning Rate: 0.00413047
	LOSS [training: 0.6731126538585593 | validation: 0.6373734242484084]
	TIME [epoch: 9.79 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1879221732608045		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 1.1879221732608045 | validation: 0.6566861760339683]
	TIME [epoch: 9.81 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9404143908110468		[learning rate: 0.0041105]
	Learning Rate: 0.0041105
	LOSS [training: 0.9404143908110468 | validation: 0.796348353093521]
	TIME [epoch: 9.78 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0412139561037164		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 1.0412139561037164 | validation: 0.9981826289581531]
	TIME [epoch: 9.78 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0253951884867059		[learning rate: 0.0040906]
	Learning Rate: 0.00409062
	LOSS [training: 1.0253951884867059 | validation: 0.8885827238752182]
	TIME [epoch: 9.79 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8748607616227438		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.8748607616227438 | validation: 0.5584784769270957]
	TIME [epoch: 9.8 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0751049233067806		[learning rate: 0.0040708]
	Learning Rate: 0.00407084
	LOSS [training: 1.0751049233067806 | validation: 1.297011455507834]
	TIME [epoch: 9.79 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4026733131546265		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 1.4026733131546265 | validation: 0.89191683949502]
	TIME [epoch: 9.78 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.916720194190008		[learning rate: 0.0040512]
	Learning Rate: 0.00405116
	LOSS [training: 0.916720194190008 | validation: 0.5361831535020872]
	TIME [epoch: 9.81 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6350350855522102		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.6350350855522102 | validation: 0.5020770780895345]
	TIME [epoch: 9.78 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5925846175053258		[learning rate: 0.0040316]
	Learning Rate: 0.00403157
	LOSS [training: 0.5925846175053258 | validation: 0.7220385840440876]
	TIME [epoch: 9.78 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8196718083735817		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.8196718083735817 | validation: 0.5494606592473565]
	TIME [epoch: 9.78 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4999911888732111		[learning rate: 0.0040121]
	Learning Rate: 0.00401207
	LOSS [training: 0.4999911888732111 | validation: 0.3680000912054975]
	TIME [epoch: 9.81 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38200016318565405		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.38200016318565405 | validation: 0.3772034947416073]
	TIME [epoch: 9.79 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5744450283982323		[learning rate: 0.0039927]
	Learning Rate: 0.00399267
	LOSS [training: 0.5744450283982323 | validation: 0.4997443409436816]
	TIME [epoch: 9.79 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5690900144811283		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.5690900144811283 | validation: 0.4204688047356902]
	TIME [epoch: 9.8 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5598538753998795		[learning rate: 0.0039734]
	Learning Rate: 0.00397336
	LOSS [training: 0.5598538753998795 | validation: 0.4491874135996588]
	TIME [epoch: 9.78 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7464674579816643		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.7464674579816643 | validation: 0.5602094666199183]
	TIME [epoch: 9.78 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5984024672177458		[learning rate: 0.0039541]
	Learning Rate: 0.00395415
	LOSS [training: 0.5984024672177458 | validation: 0.4570563977333106]
	TIME [epoch: 9.78 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46743870946760024		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.46743870946760024 | validation: 0.29739266736271475]
	TIME [epoch: 9.8 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3953879322011051		[learning rate: 0.003935]
	Learning Rate: 0.00393502
	LOSS [training: 0.3953879322011051 | validation: 0.37669700636933073]
	TIME [epoch: 9.78 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182972975389311		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.4182972975389311 | validation: 0.2906347633940099]
	TIME [epoch: 9.79 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3160414084191906		[learning rate: 0.003916]
	Learning Rate: 0.00391599
	LOSS [training: 0.3160414084191906 | validation: 0.38478429071925996]
	TIME [epoch: 9.79 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.363787932864028		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.363787932864028 | validation: 0.27017304373598483]
	TIME [epoch: 9.8 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27803775236545347		[learning rate: 0.0038971]
	Learning Rate: 0.00389706
	LOSS [training: 0.27803775236545347 | validation: 0.328938954379894]
	TIME [epoch: 9.78 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36763696120722855		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.36763696120722855 | validation: 0.5121937618077422]
	TIME [epoch: 9.78 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5151726562567939		[learning rate: 0.0038782]
	Learning Rate: 0.00387821
	LOSS [training: 0.5151726562567939 | validation: 0.7576328648492838]
	TIME [epoch: 9.81 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2664567225348813		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 1.2664567225348813 | validation: 0.875236852074272]
	TIME [epoch: 9.78 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2781427415740658		[learning rate: 0.0038595]
	Learning Rate: 0.00385946
	LOSS [training: 1.2781427415740658 | validation: 0.791883420756648]
	TIME [epoch: 9.78 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8694996884127468		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.8694996884127468 | validation: 0.40856118647471107]
	TIME [epoch: 9.78 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5078401913315731		[learning rate: 0.0038408]
	Learning Rate: 0.00384079
	LOSS [training: 0.5078401913315731 | validation: 0.41335105648811266]
	TIME [epoch: 9.8 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3961843894760972		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.3961843894760972 | validation: 0.36945029192664064]
	TIME [epoch: 9.79 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3906576314226581		[learning rate: 0.0038222]
	Learning Rate: 0.00382222
	LOSS [training: 0.3906576314226581 | validation: 0.4015478478055517]
	TIME [epoch: 9.79 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4533228925031597		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.4533228925031597 | validation: 0.37340970103377935]
	TIME [epoch: 9.8 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4245435529715552		[learning rate: 0.0038037]
	Learning Rate: 0.00380374
	LOSS [training: 0.4245435529715552 | validation: 0.33388702338178866]
	TIME [epoch: 9.78 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39614406058050255		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.39614406058050255 | validation: 0.4144905343206604]
	TIME [epoch: 9.79 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4329448123719608		[learning rate: 0.0037853]
	Learning Rate: 0.00378534
	LOSS [training: 0.4329448123719608 | validation: 0.31627824954536804]
	TIME [epoch: 9.79 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3179712294672262		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.3179712294672262 | validation: 0.401514569942573]
	TIME [epoch: 9.8 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31995158872876295		[learning rate: 0.003767]
	Learning Rate: 0.00376704
	LOSS [training: 0.31995158872876295 | validation: 0.2863308150169654]
	TIME [epoch: 9.78 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2863145240080856		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.2863145240080856 | validation: 0.32816557700761173]
	TIME [epoch: 9.79 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32590320382771415		[learning rate: 0.0037488]
	Learning Rate: 0.00374882
	LOSS [training: 0.32590320382771415 | validation: 0.2869904635649233]
	TIME [epoch: 9.81 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2696112809940314		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.2696112809940314 | validation: 0.393228652600168]
	TIME [epoch: 9.79 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3409817745375404		[learning rate: 0.0037307]
	Learning Rate: 0.00373069
	LOSS [training: 0.3409817745375404 | validation: 0.294814770545414]
	TIME [epoch: 9.78 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38159657892456905		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.38159657892456905 | validation: 0.27672230021556465]
	TIME [epoch: 9.79 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3904216570929053		[learning rate: 0.0037127]
	Learning Rate: 0.00371265
	LOSS [training: 0.3904216570929053 | validation: 0.3123228678979486]
	TIME [epoch: 9.81 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33017914808497384		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.33017914808497384 | validation: 0.2909130811407756]
	TIME [epoch: 9.78 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2917039152012514		[learning rate: 0.0036947]
	Learning Rate: 0.0036947
	LOSS [training: 0.2917039152012514 | validation: 0.3098761720226318]
	TIME [epoch: 9.79 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3587746167554375		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.3587746167554375 | validation: 0.2893162160861582]
	TIME [epoch: 9.81 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34889858851379263		[learning rate: 0.0036768]
	Learning Rate: 0.00367683
	LOSS [training: 0.34889858851379263 | validation: 0.4064883140263515]
	TIME [epoch: 9.79 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5003165682955412		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.5003165682955412 | validation: 0.3219779049212862]
	TIME [epoch: 9.79 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5342902097806344		[learning rate: 0.0036591]
	Learning Rate: 0.00365905
	LOSS [training: 0.5342902097806344 | validation: 0.48145032211181354]
	TIME [epoch: 9.79 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.566534613240562		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.566534613240562 | validation: 0.4661712424366421]
	TIME [epoch: 9.8 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45185344367103963		[learning rate: 0.0036414]
	Learning Rate: 0.00364136
	LOSS [training: 0.45185344367103963 | validation: 0.3088945351039212]
	TIME [epoch: 9.77 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37415829453240473		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.37415829453240473 | validation: 0.49540611591437467]
	TIME [epoch: 9.78 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5425268960654157		[learning rate: 0.0036237]
	Learning Rate: 0.00362375
	LOSS [training: 0.5425268960654157 | validation: 0.39158035319885337]
	TIME [epoch: 9.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37944049271021907		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.37944049271021907 | validation: 0.5068952012012905]
	TIME [epoch: 9.81 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.781082969875575		[learning rate: 0.0036062]
	Learning Rate: 0.00360622
	LOSS [training: 0.781082969875575 | validation: 0.3826775998376769]
	TIME [epoch: 9.78 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4590499263487161		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.4590499263487161 | validation: 0.3582287863720937]
	TIME [epoch: 9.78 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5407726887939132		[learning rate: 0.0035888]
	Learning Rate: 0.00358878
	LOSS [training: 0.5407726887939132 | validation: 0.7062277081989521]
	TIME [epoch: 9.82 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0075197019010018		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 1.0075197019010018 | validation: 0.8252725417012436]
	TIME [epoch: 9.8 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.110907492239629		[learning rate: 0.0035714]
	Learning Rate: 0.00357143
	LOSS [training: 1.110907492239629 | validation: 0.6126969306537875]
	TIME [epoch: 9.79 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.521794905914541		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.521794905914541 | validation: 0.5177911977950264]
	TIME [epoch: 9.79 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3808833277059979		[learning rate: 0.0035542]
	Learning Rate: 0.00355416
	LOSS [training: 0.3808833277059979 | validation: 0.31148715573212293]
	TIME [epoch: 9.81 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5056051522141158		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.5056051522141158 | validation: 0.5385665629090086]
	TIME [epoch: 9.79 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.515095255078911		[learning rate: 0.003537]
	Learning Rate: 0.00353697
	LOSS [training: 0.515095255078911 | validation: 0.3542011219570347]
	TIME [epoch: 9.79 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39066298451153425		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.39066298451153425 | validation: 0.3048714221840148]
	TIME [epoch: 9.8 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43369884909037887		[learning rate: 0.0035199]
	Learning Rate: 0.00351987
	LOSS [training: 0.43369884909037887 | validation: 0.36784423704622965]
	TIME [epoch: 9.78 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3686841269091545		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.3686841269091545 | validation: 0.36525813400335]
	TIME [epoch: 9.77 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4625352110931294		[learning rate: 0.0035028]
	Learning Rate: 0.00350285
	LOSS [training: 0.4625352110931294 | validation: 0.451062474639848]
	TIME [epoch: 9.79 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36373754278126913		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.36373754278126913 | validation: 0.4040951977189227]
	TIME [epoch: 9.8 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3648501680056222		[learning rate: 0.0034859]
	Learning Rate: 0.00348591
	LOSS [training: 0.3648501680056222 | validation: 0.307262845279142]
	TIME [epoch: 9.78 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32228101419054256		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.32228101419054256 | validation: 0.33872750339104657]
	TIME [epoch: 9.79 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3390996190847921		[learning rate: 0.003469]
	Learning Rate: 0.00346905
	LOSS [training: 0.3390996190847921 | validation: 0.38208489702085474]
	TIME [epoch: 9.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3465500172770567		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.3465500172770567 | validation: 0.3625763660536036]
	TIME [epoch: 9.79 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37447599169799606		[learning rate: 0.0034523]
	Learning Rate: 0.00345227
	LOSS [training: 0.37447599169799606 | validation: 0.338146460554049]
	TIME [epoch: 9.79 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3436307225952323		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.3436307225952323 | validation: 0.5658024977668086]
	TIME [epoch: 9.8 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40637035433637736		[learning rate: 0.0034356]
	Learning Rate: 0.00343558
	LOSS [training: 0.40637035433637736 | validation: 0.41048805888278467]
	TIME [epoch: 9.81 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5214902134080032		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.5214902134080032 | validation: 0.5141750553938954]
	TIME [epoch: 9.8 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46289282518399083		[learning rate: 0.003419]
	Learning Rate: 0.00341897
	LOSS [training: 0.46289282518399083 | validation: 0.3379616273201275]
	TIME [epoch: 9.77 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3928168575864046		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.3928168575864046 | validation: 0.3340664152182085]
	TIME [epoch: 9.8 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3477113313202319		[learning rate: 0.0034024]
	Learning Rate: 0.00340243
	LOSS [training: 0.3477113313202319 | validation: 0.2892184261027891]
	TIME [epoch: 9.8 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3080072751410897		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.3080072751410897 | validation: 0.29086242218210623]
	TIME [epoch: 9.78 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2950260674888674		[learning rate: 0.003386]
	Learning Rate: 0.00338598
	LOSS [training: 0.2950260674888674 | validation: 0.3065231201263292]
	TIME [epoch: 9.78 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30352587664274605		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.30352587664274605 | validation: 0.2803803549920212]
	TIME [epoch: 9.81 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.361772196722798		[learning rate: 0.0033696]
	Learning Rate: 0.0033696
	LOSS [training: 0.361772196722798 | validation: 0.3069101999780675]
	TIME [epoch: 9.78 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41880820028327664		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.41880820028327664 | validation: 0.3585469711966563]
	TIME [epoch: 9.79 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4203311759875025		[learning rate: 0.0033533]
	Learning Rate: 0.00335331
	LOSS [training: 0.4203311759875025 | validation: 0.5072663188944198]
	TIME [epoch: 9.79 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6269903083316134		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.6269903083316134 | validation: 0.5065260643334994]
	TIME [epoch: 9.79 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38887969382159954		[learning rate: 0.0033371]
	Learning Rate: 0.00333709
	LOSS [training: 0.38887969382159954 | validation: 0.5485834384107454]
	TIME [epoch: 9.78 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5214800784214335		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.5214800784214335 | validation: 0.41645206647326105]
	TIME [epoch: 9.79 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3608099884629469		[learning rate: 0.003321]
	Learning Rate: 0.00332096
	LOSS [training: 0.3608099884629469 | validation: 0.37692409674166455]
	TIME [epoch: 9.81 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4025902547672421		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.4025902547672421 | validation: 0.38444155892070375]
	TIME [epoch: 9.79 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3226130416547857		[learning rate: 0.0033049]
	Learning Rate: 0.0033049
	LOSS [training: 0.3226130416547857 | validation: 0.3348137689567025]
	TIME [epoch: 9.79 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47565328708253424		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.47565328708253424 | validation: 0.43272932220127075]
	TIME [epoch: 9.79 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3736468146570469		[learning rate: 0.0032889]
	Learning Rate: 0.00328891
	LOSS [training: 0.3736468146570469 | validation: 0.3233791477444333]
	TIME [epoch: 9.8 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2850462895113811		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.2850462895113811 | validation: 0.2693154075241686]
	TIME [epoch: 9.78 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.398599765316038		[learning rate: 0.003273]
	Learning Rate: 0.00327301
	LOSS [training: 0.398599765316038 | validation: 0.33731383287961836]
	TIME [epoch: 9.78 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35197996162016987		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.35197996162016987 | validation: 0.3791667840366475]
	TIME [epoch: 9.8 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3032213564159781		[learning rate: 0.0032572]
	Learning Rate: 0.00325718
	LOSS [training: 0.3032213564159781 | validation: 0.23501776841829058]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_563.pth
	Model improved!!!
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25254273740590455		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.25254273740590455 | validation: 0.2835953084955664]
	TIME [epoch: 9.78 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2892833528905866		[learning rate: 0.0032414]
	Learning Rate: 0.00324143
	LOSS [training: 0.2892833528905866 | validation: 0.47753656423997165]
	TIME [epoch: 9.8 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46371825375166525		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.46371825375166525 | validation: 0.49651222357040753]
	TIME [epoch: 9.8 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36040713297998844		[learning rate: 0.0032258]
	Learning Rate: 0.00322576
	LOSS [training: 0.36040713297998844 | validation: 0.36229074812609235]
	TIME [epoch: 9.78 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2738827312892654		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.2738827312892654 | validation: 0.3271469923169819]
	TIME [epoch: 9.79 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31112009488012127		[learning rate: 0.0032102]
	Learning Rate: 0.00321016
	LOSS [training: 0.31112009488012127 | validation: 0.3439696954436905]
	TIME [epoch: 9.81 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3506733419575013		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.3506733419575013 | validation: 0.3364735193189717]
	TIME [epoch: 9.79 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44597233483480814		[learning rate: 0.0031946]
	Learning Rate: 0.00319463
	LOSS [training: 0.44597233483480814 | validation: 0.4099654570498039]
	TIME [epoch: 9.79 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37985527029673527		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.37985527029673527 | validation: 0.3911944892124264]
	TIME [epoch: 9.79 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32963061852137315		[learning rate: 0.0031792]
	Learning Rate: 0.00317918
	LOSS [training: 0.32963061852137315 | validation: 0.316372691266388]
	TIME [epoch: 9.8 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30456596030713295		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.30456596030713295 | validation: 0.4173501336961472]
	TIME [epoch: 9.78 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3720948751529406		[learning rate: 0.0031638]
	Learning Rate: 0.00316381
	LOSS [training: 0.3720948751529406 | validation: 0.3506734050236193]
	TIME [epoch: 9.78 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2703770376686789		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.2703770376686789 | validation: 0.25509834691345334]
	TIME [epoch: 9.8 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37759195973225224		[learning rate: 0.0031485]
	Learning Rate: 0.00314851
	LOSS [training: 0.37759195973225224 | validation: 0.36643445889972226]
	TIME [epoch: 9.79 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4240923706093895		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.4240923706093895 | validation: 0.35777145541712146]
	TIME [epoch: 9.79 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4318800021477117		[learning rate: 0.0031333]
	Learning Rate: 0.00313329
	LOSS [training: 0.4318800021477117 | validation: 0.3075224291417727]
	TIME [epoch: 9.78 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4703342432929494		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.4703342432929494 | validation: 0.35111288651954625]
	TIME [epoch: 9.81 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3909376105130618		[learning rate: 0.0031181]
	Learning Rate: 0.00311813
	LOSS [training: 0.3909376105130618 | validation: 0.3661983195311494]
	TIME [epoch: 9.79 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3225471336945175		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.3225471336945175 | validation: 0.24298708641991526]
	TIME [epoch: 9.79 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30036595842953484		[learning rate: 0.0031031]
	Learning Rate: 0.00310305
	LOSS [training: 0.30036595842953484 | validation: 0.31164459694832003]
	TIME [epoch: 9.79 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3350306359429677		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.3350306359429677 | validation: 0.4316564503928851]
	TIME [epoch: 9.8 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.512085984208446		[learning rate: 0.003088]
	Learning Rate: 0.00308805
	LOSS [training: 0.512085984208446 | validation: 0.4092569384716853]
	TIME [epoch: 9.79 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6139499618325528		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.6139499618325528 | validation: 0.4772004442748255]
	TIME [epoch: 9.8 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4382826029389043		[learning rate: 0.0030731]
	Learning Rate: 0.00307312
	LOSS [training: 0.4382826029389043 | validation: 0.44254058531036095]
	TIME [epoch: 9.8 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4693328750625766		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.4693328750625766 | validation: 0.5362406912052338]
	TIME [epoch: 9.79 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49638363952681386		[learning rate: 0.0030583]
	Learning Rate: 0.00305825
	LOSS [training: 0.49638363952681386 | validation: 0.44043130774302525]
	TIME [epoch: 9.78 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4682241863266328		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.4682241863266328 | validation: 0.7888768247270679]
	TIME [epoch: 9.79 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6120168560891792		[learning rate: 0.0030435]
	Learning Rate: 0.00304347
	LOSS [training: 0.6120168560891792 | validation: 0.569303236104956]
	TIME [epoch: 9.8 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4908925653602433		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.4908925653602433 | validation: 0.3516788927891271]
	TIME [epoch: 9.79 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38840703605012317		[learning rate: 0.0030287]
	Learning Rate: 0.00302875
	LOSS [training: 0.38840703605012317 | validation: 0.32871723853070545]
	TIME [epoch: 9.8 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4435202952660062		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.4435202952660062 | validation: 0.643042385284555]
	TIME [epoch: 9.81 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.727366225075435		[learning rate: 0.0030141]
	Learning Rate: 0.0030141
	LOSS [training: 0.727366225075435 | validation: 0.6680957641297002]
	TIME [epoch: 9.79 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6199444001297963		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.6199444001297963 | validation: 0.47799365658633536]
	TIME [epoch: 9.8 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45189509265570854		[learning rate: 0.0029995]
	Learning Rate: 0.00299953
	LOSS [training: 0.45189509265570854 | validation: 0.334977200452092]
	TIME [epoch: 9.79 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.316768992487539		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.316768992487539 | validation: 0.30234282570404764]
	TIME [epoch: 9.81 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.429585044142711		[learning rate: 0.002985]
	Learning Rate: 0.00298502
	LOSS [training: 0.429585044142711 | validation: 0.6722646372717098]
	TIME [epoch: 9.79 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4580309435001534		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.4580309435001534 | validation: 0.40806861308094455]
	TIME [epoch: 9.79 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36842586127031807		[learning rate: 0.0029706]
	Learning Rate: 0.00297059
	LOSS [training: 0.36842586127031807 | validation: 0.32742783096282085]
	TIME [epoch: 9.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31059949779912016		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.31059949779912016 | validation: 0.32333640054051205]
	TIME [epoch: 9.8 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3082859918311501		[learning rate: 0.0029562]
	Learning Rate: 0.00295622
	LOSS [training: 0.3082859918311501 | validation: 0.322232860229981]
	TIME [epoch: 9.79 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32277326800082984		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.32277326800082984 | validation: 0.37301440729061724]
	TIME [epoch: 9.79 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32339164963689615		[learning rate: 0.0029419]
	Learning Rate: 0.00294192
	LOSS [training: 0.32339164963689615 | validation: 0.3629362693807988]
	TIME [epoch: 9.81 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3192550530821025		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.3192550530821025 | validation: 0.2752732193928493]
	TIME [epoch: 9.8 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2819028231655724		[learning rate: 0.0029277]
	Learning Rate: 0.0029277
	LOSS [training: 0.2819028231655724 | validation: 0.3177340206574724]
	TIME [epoch: 9.8 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28943038763780904		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.28943038763780904 | validation: 0.2655157730837114]
	TIME [epoch: 9.78 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34187464865476347		[learning rate: 0.0029135]
	Learning Rate: 0.00291354
	LOSS [training: 0.34187464865476347 | validation: 0.37208214486922253]
	TIME [epoch: 9.8 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2832525839559407		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.2832525839559407 | validation: 0.27343608446718454]
	TIME [epoch: 9.78 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2570917922750322		[learning rate: 0.0028995]
	Learning Rate: 0.00289945
	LOSS [training: 0.2570917922750322 | validation: 0.2895980310887024]
	TIME [epoch: 9.79 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47196114864317884		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.47196114864317884 | validation: 0.42806419676276686]
	TIME [epoch: 9.82 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40737589074235314		[learning rate: 0.0028854]
	Learning Rate: 0.00288543
	LOSS [training: 0.40737589074235314 | validation: 0.3803442787623501]
	TIME [epoch: 9.8 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42188082890623857		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.42188082890623857 | validation: 0.4689174380670517]
	TIME [epoch: 9.79 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4307279226169345		[learning rate: 0.0028715]
	Learning Rate: 0.00287148
	LOSS [training: 0.4307279226169345 | validation: 0.4454876520150583]
	TIME [epoch: 9.79 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34713208643514215		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.34713208643514215 | validation: 0.2759034646154066]
	TIME [epoch: 9.8 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2953024460705126		[learning rate: 0.0028576]
	Learning Rate: 0.00285759
	LOSS [training: 0.2953024460705126 | validation: 0.3430103112343012]
	TIME [epoch: 9.79 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4219044972269895		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.4219044972269895 | validation: 0.308220799811727]
	TIME [epoch: 9.79 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35091786414814224		[learning rate: 0.0028438]
	Learning Rate: 0.00284377
	LOSS [training: 0.35091786414814224 | validation: 0.4106453620353678]
	TIME [epoch: 9.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5116366866876574		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.5116366866876574 | validation: 0.4118122171624441]
	TIME [epoch: 9.78 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43178786908037187		[learning rate: 0.00283]
	Learning Rate: 0.00283002
	LOSS [training: 0.43178786908037187 | validation: 0.3550389002971198]
	TIME [epoch: 9.79 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43445687877257233		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.43445687877257233 | validation: 0.3777705509951399]
	TIME [epoch: 9.79 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39986362181631974		[learning rate: 0.0028163]
	Learning Rate: 0.00281633
	LOSS [training: 0.39986362181631974 | validation: 0.3465530664343319]
	TIME [epoch: 9.8 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44793818227672055		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.44793818227672055 | validation: 0.48758256084651025]
	TIME [epoch: 9.79 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.513865187654892		[learning rate: 0.0028027]
	Learning Rate: 0.00280272
	LOSS [training: 0.513865187654892 | validation: 0.4376009443261545]
	TIME [epoch: 9.79 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4050925022038716		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.4050925022038716 | validation: 0.3524651395580402]
	TIME [epoch: 9.81 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3946420242683798		[learning rate: 0.0027892]
	Learning Rate: 0.00278916
	LOSS [training: 0.3946420242683798 | validation: 0.3837248196197133]
	TIME [epoch: 9.79 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4270270903870217		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.4270270903870217 | validation: 0.3806268453729161]
	TIME [epoch: 9.78 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42998000314645746		[learning rate: 0.0027757]
	Learning Rate: 0.00277567
	LOSS [training: 0.42998000314645746 | validation: 0.3344523699826026]
	TIME [epoch: 9.78 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38175840040250725		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.38175840040250725 | validation: 0.4719960535061117]
	TIME [epoch: 9.81 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.597186226725651		[learning rate: 0.0027623]
	Learning Rate: 0.00276225
	LOSS [training: 0.597186226725651 | validation: 0.49634696396219113]
	TIME [epoch: 9.79 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5620014934700842		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.5620014934700842 | validation: 0.51619450303858]
	TIME [epoch: 9.79 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4102325221212316		[learning rate: 0.0027489]
	Learning Rate: 0.00274889
	LOSS [training: 0.4102325221212316 | validation: 0.3828669248158569]
	TIME [epoch: 9.8 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3345518110394273		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.3345518110394273 | validation: 0.3381078973445395]
	TIME [epoch: 9.8 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3144673326569166		[learning rate: 0.0027356]
	Learning Rate: 0.0027356
	LOSS [training: 0.3144673326569166 | validation: 0.2984576185676755]
	TIME [epoch: 9.79 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32660336295285874		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.32660336295285874 | validation: 0.34484798345883133]
	TIME [epoch: 9.78 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40559197217306336		[learning rate: 0.0027224]
	Learning Rate: 0.00272237
	LOSS [training: 0.40559197217306336 | validation: 0.4571432397300748]
	TIME [epoch: 9.81 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.544144421567756		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.544144421567756 | validation: 0.5620530188932904]
	TIME [epoch: 9.79 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4363128851078252		[learning rate: 0.0027092]
	Learning Rate: 0.00270921
	LOSS [training: 0.4363128851078252 | validation: 0.363112678534597]
	TIME [epoch: 9.79 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3879382918558083		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.3879382918558083 | validation: 0.43565543995023837]
	TIME [epoch: 9.8 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37688423737207144		[learning rate: 0.0026961]
	Learning Rate: 0.00269611
	LOSS [training: 0.37688423737207144 | validation: 0.31502825752021324]
	TIME [epoch: 9.8 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3213911085501601		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.3213911085501601 | validation: 0.3329174500671876]
	TIME [epoch: 9.79 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31757561934164324		[learning rate: 0.0026831]
	Learning Rate: 0.00268307
	LOSS [training: 0.31757561934164324 | validation: 0.25942128899309197]
	TIME [epoch: 9.79 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29703246596166916		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.29703246596166916 | validation: 0.4201950245081232]
	TIME [epoch: 9.8 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3566026272338719		[learning rate: 0.0026701]
	Learning Rate: 0.00267009
	LOSS [training: 0.3566026272338719 | validation: 0.27627571736248974]
	TIME [epoch: 9.79 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3071639140596365		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.3071639140596365 | validation: 0.26879634946521863]
	TIME [epoch: 9.78 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2803088557668246		[learning rate: 0.0026572]
	Learning Rate: 0.00265718
	LOSS [training: 0.2803088557668246 | validation: 0.28250511862506933]
	TIME [epoch: 9.78 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33574912319976913		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.33574912319976913 | validation: 0.4762161683925743]
	TIME [epoch: 9.81 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3521556589203273		[learning rate: 0.0026443]
	Learning Rate: 0.00264433
	LOSS [training: 0.3521556589203273 | validation: 0.23779770884010645]
	TIME [epoch: 9.8 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29969888697894		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.29969888697894 | validation: 0.34489052629540673]
	TIME [epoch: 9.79 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34191142848695194		[learning rate: 0.0026315]
	Learning Rate: 0.00263154
	LOSS [training: 0.34191142848695194 | validation: 0.26323594549405477]
	TIME [epoch: 9.8 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3334080020281362		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.3334080020281362 | validation: 0.3122059558346216]
	TIME [epoch: 9.78 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31212758130372337		[learning rate: 0.0026188]
	Learning Rate: 0.00261882
	LOSS [training: 0.31212758130372337 | validation: 0.3869920800301887]
	TIME [epoch: 9.78 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31011898373409474		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.31011898373409474 | validation: 0.27820493685357056]
	TIME [epoch: 9.78 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2435688180348316		[learning rate: 0.0026062]
	Learning Rate: 0.00260615
	LOSS [training: 0.2435688180348316 | validation: 0.25378082735560215]
	TIME [epoch: 9.81 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24306084623929153		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.24306084623929153 | validation: 0.27051016576654563]
	TIME [epoch: 9.78 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3009131686926659		[learning rate: 0.0025936]
	Learning Rate: 0.00259355
	LOSS [training: 0.3009131686926659 | validation: 0.340374898252592]
	TIME [epoch: 9.78 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4007814565871203		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.4007814565871203 | validation: 0.3806218494785349]
	TIME [epoch: 9.81 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3901807134020347		[learning rate: 0.002581]
	Learning Rate: 0.00258101
	LOSS [training: 0.3901807134020347 | validation: 0.30867134650165534]
	TIME [epoch: 9.8 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2959703837422448		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.2959703837422448 | validation: 0.28880266943541516]
	TIME [epoch: 9.78 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34075132881780407		[learning rate: 0.0025685]
	Learning Rate: 0.00256853
	LOSS [training: 0.34075132881780407 | validation: 0.3324480095952447]
	TIME [epoch: 9.79 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36586834498021575		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.36586834498021575 | validation: 0.367508257450898]
	TIME [epoch: 9.81 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3020650026442343		[learning rate: 0.0025561]
	Learning Rate: 0.00255611
	LOSS [training: 0.3020650026442343 | validation: 0.33489103387737373]
	TIME [epoch: 9.79 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3152994222360034		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.3152994222360034 | validation: 0.33849373861636695]
	TIME [epoch: 9.78 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3312902435041537		[learning rate: 0.0025437]
	Learning Rate: 0.00254375
	LOSS [training: 0.3312902435041537 | validation: 0.35652395324092856]
	TIME [epoch: 9.79 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30899268253762946		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.30899268253762946 | validation: 0.4067040507721727]
	TIME [epoch: 9.79 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4031928598243469		[learning rate: 0.0025314]
	Learning Rate: 0.00253144
	LOSS [training: 0.4031928598243469 | validation: 0.36592281741925187]
	TIME [epoch: 9.8 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49819383491377367		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.49819383491377367 | validation: 0.5455581412019115]
	TIME [epoch: 9.79 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5041595570316624		[learning rate: 0.0025192]
	Learning Rate: 0.0025192
	LOSS [training: 0.5041595570316624 | validation: 0.3840805013343889]
	TIME [epoch: 9.8 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3502466984289722		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.3502466984289722 | validation: 0.3172408475809306]
	TIME [epoch: 9.78 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3218959392156708		[learning rate: 0.002507]
	Learning Rate: 0.00250702
	LOSS [training: 0.3218959392156708 | validation: 0.3318889932830328]
	TIME [epoch: 9.77 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3198220161454093		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.3198220161454093 | validation: 0.398753171742481]
	TIME [epoch: 9.81 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3419917522655154		[learning rate: 0.0024949]
	Learning Rate: 0.0024949
	LOSS [training: 0.3419917522655154 | validation: 0.25833947856230555]
	TIME [epoch: 9.79 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30877980647443226		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.30877980647443226 | validation: 0.37199022902430107]
	TIME [epoch: 9.78 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28137413356638397		[learning rate: 0.0024828]
	Learning Rate: 0.00248283
	LOSS [training: 0.28137413356638397 | validation: 0.2467356190622283]
	TIME [epoch: 9.78 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27072735162786693		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.27072735162786693 | validation: 0.30167670670612645]
	TIME [epoch: 9.8 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3577313844341542		[learning rate: 0.0024708]
	Learning Rate: 0.00247083
	LOSS [training: 0.3577313844341542 | validation: 0.3851628272130633]
	TIME [epoch: 9.78 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39701493258150033		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.39701493258150033 | validation: 0.3671084674833184]
	TIME [epoch: 9.78 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3592976066595079		[learning rate: 0.0024589]
	Learning Rate: 0.00245888
	LOSS [training: 0.3592976066595079 | validation: 0.27819076094463624]
	TIME [epoch: 9.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2774559249769687		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.2774559249769687 | validation: 0.26121237670203845]
	TIME [epoch: 9.8 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2700355355933385		[learning rate: 0.002447]
	Learning Rate: 0.00244699
	LOSS [training: 0.2700355355933385 | validation: 0.273284679760704]
	TIME [epoch: 9.79 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26428339019444463		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.26428339019444463 | validation: 0.2866962954934219]
	TIME [epoch: 9.8 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3274987198913507		[learning rate: 0.0024352]
	Learning Rate: 0.00243515
	LOSS [training: 0.3274987198913507 | validation: 0.3680494510184599]
	TIME [epoch: 9.82 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3046746113408224		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.3046746113408224 | validation: 0.29161247853861866]
	TIME [epoch: 9.79 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.277483740254408		[learning rate: 0.0024234]
	Learning Rate: 0.00242338
	LOSS [training: 0.277483740254408 | validation: 0.30976868596137985]
	TIME [epoch: 9.8 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2959656143395333		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.2959656143395333 | validation: 0.2648674321791535]
	TIME [epoch: 9.8 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26812878615994273		[learning rate: 0.0024117]
	Learning Rate: 0.00241166
	LOSS [training: 0.26812878615994273 | validation: 0.3210089978970998]
	TIME [epoch: 9.81 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28495672299532		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.28495672299532 | validation: 0.3119250885437074]
	TIME [epoch: 9.78 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2817068234348502		[learning rate: 0.0024]
	Learning Rate: 0.0024
	LOSS [training: 0.2817068234348502 | validation: 0.30265727858701486]
	TIME [epoch: 9.79 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27526554748444515		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.27526554748444515 | validation: 0.31400894334943585]
	TIME [epoch: 9.81 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39291918577035745		[learning rate: 0.0023884]
	Learning Rate: 0.00238839
	LOSS [training: 0.39291918577035745 | validation: 0.2986220136362702]
	TIME [epoch: 9.79 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31192492241346953		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.31192492241346953 | validation: 0.35372399405195554]
	TIME [epoch: 9.78 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2808234670396345		[learning rate: 0.0023768]
	Learning Rate: 0.00237684
	LOSS [training: 0.2808234670396345 | validation: 0.2994618808016828]
	TIME [epoch: 9.78 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2994380808392782		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.2994380808392782 | validation: 0.3699199934316668]
	TIME [epoch: 9.81 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29049383527006883		[learning rate: 0.0023653]
	Learning Rate: 0.00236535
	LOSS [training: 0.29049383527006883 | validation: 0.29145925653968524]
	TIME [epoch: 9.79 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26717085997001727		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.26717085997001727 | validation: 0.31677093770976666]
	TIME [epoch: 9.8 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2593122872229693		[learning rate: 0.0023539]
	Learning Rate: 0.00235391
	LOSS [training: 0.2593122872229693 | validation: 0.46542158735550104]
	TIME [epoch: 9.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.398789380616542		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.398789380616542 | validation: 0.3190300170337808]
	TIME [epoch: 9.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31218584086851536		[learning rate: 0.0023425]
	Learning Rate: 0.00234252
	LOSS [training: 0.31218584086851536 | validation: 0.2535065153381878]
	TIME [epoch: 9.79 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3178097660721056		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.3178097660721056 | validation: 0.5955448962536369]
	TIME [epoch: 9.78 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8027760391595258		[learning rate: 0.0023312]
	Learning Rate: 0.0023312
	LOSS [training: 0.8027760391595258 | validation: 0.5854176247641337]
	TIME [epoch: 9.81 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6205981239417518		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.6205981239417518 | validation: 0.4954588337529509]
	TIME [epoch: 9.79 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6357892667844817		[learning rate: 0.0023199]
	Learning Rate: 0.00231992
	LOSS [training: 0.6357892667844817 | validation: 0.40339781831006544]
	TIME [epoch: 9.79 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39881424601934967		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.39881424601934967 | validation: 0.35499663763622247]
	TIME [epoch: 9.8 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34273401231444306		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.34273401231444306 | validation: 0.33280747529348803]
	TIME [epoch: 9.8 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27270214695320416		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.27270214695320416 | validation: 0.2828164269574046]
	TIME [epoch: 9.79 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26610410175297394		[learning rate: 0.0022975]
	Learning Rate: 0.00229754
	LOSS [training: 0.26610410175297394 | validation: 0.32110261329433115]
	TIME [epoch: 9.8 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.278773304029737		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.278773304029737 | validation: 0.32296989047006686]
	TIME [epoch: 9.81 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2593643711729343		[learning rate: 0.0022864]
	Learning Rate: 0.00228643
	LOSS [training: 0.2593643711729343 | validation: 0.30785667752939005]
	TIME [epoch: 9.79 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2882207141335837		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.2882207141335837 | validation: 0.366713413656755]
	TIME [epoch: 9.8 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27216666400812567		[learning rate: 0.0022754]
	Learning Rate: 0.00227537
	LOSS [training: 0.27216666400812567 | validation: 0.2481050811028289]
	TIME [epoch: 9.8 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25260878342755716		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.25260878342755716 | validation: 0.2867244821417388]
	TIME [epoch: 9.82 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25599442491088986		[learning rate: 0.0022644]
	Learning Rate: 0.00226437
	LOSS [training: 0.25599442491088986 | validation: 0.2887907587280108]
	TIME [epoch: 9.8 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2673689236875245		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.2673689236875245 | validation: 0.34983426840988224]
	TIME [epoch: 9.8 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38339520482595707		[learning rate: 0.0022534]
	Learning Rate: 0.00225342
	LOSS [training: 0.38339520482595707 | validation: 0.4748220059538419]
	TIME [epoch: 9.81 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30914949660496993		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.30914949660496993 | validation: 0.3072599622561187]
	TIME [epoch: 9.79 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22488179960913168		[learning rate: 0.0022425]
	Learning Rate: 0.00224252
	LOSS [training: 0.22488179960913168 | validation: 0.2606941592839188]
	TIME [epoch: 9.79 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2518169506389938		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.2518169506389938 | validation: 0.309272668455023]
	TIME [epoch: 9.79 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2429764246451871		[learning rate: 0.0022317]
	Learning Rate: 0.00223168
	LOSS [training: 0.2429764246451871 | validation: 0.30515825250330336]
	TIME [epoch: 9.82 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2465849524352975		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.2465849524352975 | validation: 0.2886771911475124]
	TIME [epoch: 9.81 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22955427241044477		[learning rate: 0.0022209]
	Learning Rate: 0.00222089
	LOSS [training: 0.22955427241044477 | validation: 0.34121048401071236]
	TIME [epoch: 9.81 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29651488020510797		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.29651488020510797 | validation: 0.27412094506093543]
	TIME [epoch: 9.81 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28496722791604484		[learning rate: 0.0022101]
	Learning Rate: 0.00221015
	LOSS [training: 0.28496722791604484 | validation: 0.37690629887588134]
	TIME [epoch: 9.81 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3353444732462959		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.3353444732462959 | validation: 0.30682246017722437]
	TIME [epoch: 9.79 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.294895070756964		[learning rate: 0.0021995]
	Learning Rate: 0.00219946
	LOSS [training: 0.294895070756964 | validation: 0.30664767896627726]
	TIME [epoch: 9.79 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44968357048413693		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.44968357048413693 | validation: 0.5467941783085758]
	TIME [epoch: 9.82 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6945729951772346		[learning rate: 0.0021888]
	Learning Rate: 0.00218882
	LOSS [training: 0.6945729951772346 | validation: 0.5126834744552687]
	TIME [epoch: 9.79 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5589259481442994		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.5589259481442994 | validation: 0.3702045626875079]
	TIME [epoch: 9.79 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36438485805378135		[learning rate: 0.0021782]
	Learning Rate: 0.00217824
	LOSS [training: 0.36438485805378135 | validation: 0.311557736288488]
	TIME [epoch: 9.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29914935342977256		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.29914935342977256 | validation: 0.37773023960909086]
	TIME [epoch: 9.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39561726328448354		[learning rate: 0.0021677]
	Learning Rate: 0.0021677
	LOSS [training: 0.39561726328448354 | validation: 0.31673489673971833]
	TIME [epoch: 9.8 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3347031087847473		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.3347031087847473 | validation: 0.2371762262130377]
	TIME [epoch: 9.79 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2276590560443465		[learning rate: 0.0021572]
	Learning Rate: 0.00215722
	LOSS [training: 0.2276590560443465 | validation: 0.2719069852674756]
	TIME [epoch: 9.81 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2474261904598301		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.2474261904598301 | validation: 0.241236499416822]
	TIME [epoch: 9.79 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26532611297352127		[learning rate: 0.0021468]
	Learning Rate: 0.00214679
	LOSS [training: 0.26532611297352127 | validation: 0.2740318596090135]
	TIME [epoch: 9.79 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29544017473813666		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.29544017473813666 | validation: 0.2983157250106994]
	TIME [epoch: 9.8 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3159733618545887		[learning rate: 0.0021364]
	Learning Rate: 0.00213641
	LOSS [training: 0.3159733618545887 | validation: 0.2650351620581951]
	TIME [epoch: 9.81 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29131157392925805		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.29131157392925805 | validation: 0.2552585213343498]
	TIME [epoch: 9.79 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3281770425665316		[learning rate: 0.0021261]
	Learning Rate: 0.00212608
	LOSS [training: 0.3281770425665316 | validation: 0.3155119220208371]
	TIME [epoch: 9.79 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31300245808018595		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.31300245808018595 | validation: 0.26942142664594276]
	TIME [epoch: 9.81 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3050173182014729		[learning rate: 0.0021158]
	Learning Rate: 0.0021158
	LOSS [training: 0.3050173182014729 | validation: 0.2971864798578189]
	TIME [epoch: 9.79 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2841941569915031		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.2841941569915031 | validation: 0.279264939390303]
	TIME [epoch: 9.8 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2555545968696803		[learning rate: 0.0021056]
	Learning Rate: 0.00210556
	LOSS [training: 0.2555545968696803 | validation: 0.24855048119933018]
	TIME [epoch: 9.8 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28907074917749787		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.28907074917749787 | validation: 0.3038205881322121]
	TIME [epoch: 9.8 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29781336757070886		[learning rate: 0.0020954]
	Learning Rate: 0.00209538
	LOSS [training: 0.29781336757070886 | validation: 0.3217788971644774]
	TIME [epoch: 9.79 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2654717163677979		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.2654717163677979 | validation: 0.2519655111146842]
	TIME [epoch: 9.8 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26754252782078225		[learning rate: 0.0020852]
	Learning Rate: 0.00208525
	LOSS [training: 0.26754252782078225 | validation: 0.3144002553225986]
	TIME [epoch: 9.81 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25135612455747347		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.25135612455747347 | validation: 0.28117541991893663]
	TIME [epoch: 9.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2689460339240888		[learning rate: 0.0020752]
	Learning Rate: 0.00207517
	LOSS [training: 0.2689460339240888 | validation: 0.36439899393460873]
	TIME [epoch: 9.79 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26877851810714065		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.26877851810714065 | validation: 0.280836928513295]
	TIME [epoch: 9.8 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.250857067968572		[learning rate: 0.0020651]
	Learning Rate: 0.00206513
	LOSS [training: 0.250857067968572 | validation: 0.25247402594592167]
	TIME [epoch: 9.82 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2998533521068206		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.2998533521068206 | validation: 0.33319197246770516]
	TIME [epoch: 9.79 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37932709112094126		[learning rate: 0.0020551]
	Learning Rate: 0.00205514
	LOSS [training: 0.37932709112094126 | validation: 0.34897117526084354]
	TIME [epoch: 9.78 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4301500212733746		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.4301500212733746 | validation: 0.40772938401029685]
	TIME [epoch: 9.82 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38566649370283573		[learning rate: 0.0020452]
	Learning Rate: 0.0020452
	LOSS [training: 0.38566649370283573 | validation: 0.3037601518644956]
	TIME [epoch: 9.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3278755055815056		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.3278755055815056 | validation: 0.2866402236378626]
	TIME [epoch: 9.8 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2961282408021719		[learning rate: 0.0020353]
	Learning Rate: 0.00203531
	LOSS [training: 0.2961282408021719 | validation: 0.26445286061788054]
	TIME [epoch: 9.8 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25986847271487223		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.25986847271487223 | validation: 0.27804716360033527]
	TIME [epoch: 9.82 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25257262142210524		[learning rate: 0.0020255]
	Learning Rate: 0.00202547
	LOSS [training: 0.25257262142210524 | validation: 0.2763420031818484]
	TIME [epoch: 9.8 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2709241364557266		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.2709241364557266 | validation: 0.3265529304863769]
	TIME [epoch: 9.79 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32839634064631706		[learning rate: 0.0020157]
	Learning Rate: 0.00201568
	LOSS [training: 0.32839634064631706 | validation: 0.3078437809349428]
	TIME [epoch: 9.8 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3443879022727694		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.3443879022727694 | validation: 0.2951545739388131]
	TIME [epoch: 9.81 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27856224093969695		[learning rate: 0.0020059]
	Learning Rate: 0.00200593
	LOSS [training: 0.27856224093969695 | validation: 0.2587341738840538]
	TIME [epoch: 9.79 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25086607171860054		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.25086607171860054 | validation: 0.22891761933561547]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_764.pth
	Model improved!!!
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2702955702546888		[learning rate: 0.0019962]
	Learning Rate: 0.00199623
	LOSS [training: 0.2702955702546888 | validation: 0.2497622724762798]
	TIME [epoch: 9.81 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24144474524274512		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.24144474524274512 | validation: 0.39235819774185987]
	TIME [epoch: 9.79 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3669581029614948		[learning rate: 0.0019866]
	Learning Rate: 0.00198658
	LOSS [training: 0.3669581029614948 | validation: 0.3691427831262568]
	TIME [epoch: 9.79 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3262747148093373		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.3262747148093373 | validation: 0.3065451418170971]
	TIME [epoch: 9.81 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25730493427749895		[learning rate: 0.001977]
	Learning Rate: 0.00197697
	LOSS [training: 0.25730493427749895 | validation: 0.2868742802518573]
	TIME [epoch: 9.8 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2659067762628236		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.2659067762628236 | validation: 0.2769784888301301]
	TIME [epoch: 9.79 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29599958366794116		[learning rate: 0.0019674]
	Learning Rate: 0.00196741
	LOSS [training: 0.29599958366794116 | validation: 0.32572611046977723]
	TIME [epoch: 9.79 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2684112463446187		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.2684112463446187 | validation: 0.25551790899470517]
	TIME [epoch: 9.82 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24216963642189335		[learning rate: 0.0019579]
	Learning Rate: 0.0019579
	LOSS [training: 0.24216963642189335 | validation: 0.2841526801902075]
	TIME [epoch: 9.79 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23994305024534346		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.23994305024534346 | validation: 0.24718211113313754]
	TIME [epoch: 9.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23706034565364648		[learning rate: 0.0019484]
	Learning Rate: 0.00194843
	LOSS [training: 0.23706034565364648 | validation: 0.32728406424203854]
	TIME [epoch: 9.81 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28235810272255557		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.28235810272255557 | validation: 0.3094905925551585]
	TIME [epoch: 9.82 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3312560487338582		[learning rate: 0.001939]
	Learning Rate: 0.00193901
	LOSS [training: 0.3312560487338582 | validation: 0.43285577119778645]
	TIME [epoch: 9.8 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3632412534253014		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.3632412534253014 | validation: 0.38276829656761563]
	TIME [epoch: 9.8 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32355879149265576		[learning rate: 0.0019296]
	Learning Rate: 0.00192963
	LOSS [training: 0.32355879149265576 | validation: 0.3335498516784689]
	TIME [epoch: 9.81 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28193146388513346		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.28193146388513346 | validation: 0.3238006579050358]
	TIME [epoch: 9.81 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29655868904307014		[learning rate: 0.0019203]
	Learning Rate: 0.0019203
	LOSS [training: 0.29655868904307014 | validation: 0.3328765043801982]
	TIME [epoch: 9.79 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3295802574625123		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.3295802574625123 | validation: 0.36348391119190854]
	TIME [epoch: 9.8 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3032464919462802		[learning rate: 0.001911]
	Learning Rate: 0.00191101
	LOSS [training: 0.3032464919462802 | validation: 0.31690811541155334]
	TIME [epoch: 9.8 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3138314687005912		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.3138314687005912 | validation: 0.3884348674364941]
	TIME [epoch: 9.79 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3536216018816961		[learning rate: 0.0019018]
	Learning Rate: 0.00190177
	LOSS [training: 0.3536216018816961 | validation: 0.32457430695468065]
	TIME [epoch: 9.79 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27030651647754456		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.27030651647754456 | validation: 0.31742816088308606]
	TIME [epoch: 9.8 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2343202585581361		[learning rate: 0.0018926]
	Learning Rate: 0.00189257
	LOSS [training: 0.2343202585581361 | validation: 0.26374290319386384]
	TIME [epoch: 9.8 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.266404968730436		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.266404968730436 | validation: 0.3153089591463968]
	TIME [epoch: 9.8 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.308946297492147		[learning rate: 0.0018834]
	Learning Rate: 0.00188342
	LOSS [training: 0.308946297492147 | validation: 0.4423443251273983]
	TIME [epoch: 9.79 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35187043392426026		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.35187043392426026 | validation: 0.28145313054947046]
	TIME [epoch: 9.8 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2410212294465186		[learning rate: 0.0018743]
	Learning Rate: 0.00187431
	LOSS [training: 0.2410212294465186 | validation: 0.2884158624730222]
	TIME [epoch: 9.79 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26343343324092505		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.26343343324092505 | validation: 0.2908942300476728]
	TIME [epoch: 9.8 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2522427963330788		[learning rate: 0.0018652]
	Learning Rate: 0.00186525
	LOSS [training: 0.2522427963330788 | validation: 0.2533190230971597]
	TIME [epoch: 9.81 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21351949021579758		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.21351949021579758 | validation: 0.2884695555657092]
	TIME [epoch: 9.8 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23647690348046138		[learning rate: 0.0018562]
	Learning Rate: 0.00185623
	LOSS [training: 0.23647690348046138 | validation: 0.22940868702532646]
	TIME [epoch: 9.79 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22447511337890683		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.22447511337890683 | validation: 0.2542533948697696]
	TIME [epoch: 9.79 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24892668055992387		[learning rate: 0.0018473]
	Learning Rate: 0.00184725
	LOSS [training: 0.24892668055992387 | validation: 0.2948527842833854]
	TIME [epoch: 9.82 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3485066364231536		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.3485066364231536 | validation: 0.3953113336223883]
	TIME [epoch: 9.8 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39086279424883763		[learning rate: 0.0018383]
	Learning Rate: 0.00183832
	LOSS [training: 0.39086279424883763 | validation: 0.30158870443734975]
	TIME [epoch: 9.8 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30343056797531326		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.30343056797531326 | validation: 0.33933973464645334]
	TIME [epoch: 9.81 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41777484408168436		[learning rate: 0.0018294]
	Learning Rate: 0.00182943
	LOSS [training: 0.41777484408168436 | validation: 0.37586100254804117]
	TIME [epoch: 9.81 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38469344865472443		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.38469344865472443 | validation: 0.2889728078250592]
	TIME [epoch: 9.8 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.300166839836543		[learning rate: 0.0018206]
	Learning Rate: 0.00182058
	LOSS [training: 0.300166839836543 | validation: 0.2679091927133681]
	TIME [epoch: 9.8 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2507861287135171		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.2507861287135171 | validation: 0.26637363812351544]
	TIME [epoch: 9.81 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24788809797637196		[learning rate: 0.0018118]
	Learning Rate: 0.00181178
	LOSS [training: 0.24788809797637196 | validation: 0.2780264312777309]
	TIME [epoch: 9.79 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2915418888376925		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.2915418888376925 | validation: 0.37355530582894503]
	TIME [epoch: 9.8 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36964934218931444		[learning rate: 0.001803]
	Learning Rate: 0.00180302
	LOSS [training: 0.36964934218931444 | validation: 0.33213844746483273]
	TIME [epoch: 9.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2810194230410487		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.2810194230410487 | validation: 0.25243977136060486]
	TIME [epoch: 9.81 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24128599234640488		[learning rate: 0.0017943]
	Learning Rate: 0.0017943
	LOSS [training: 0.24128599234640488 | validation: 0.2797811111115864]
	TIME [epoch: 9.8 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2399681294369384		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.2399681294369384 | validation: 0.27904069764893746]
	TIME [epoch: 9.79 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2228325470005219		[learning rate: 0.0017856]
	Learning Rate: 0.00178562
	LOSS [training: 0.2228325470005219 | validation: 0.2618010264876012]
	TIME [epoch: 9.81 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22159674883416605		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.22159674883416605 | validation: 0.2947823106526077]
	TIME [epoch: 9.8 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21592442082528535		[learning rate: 0.001777]
	Learning Rate: 0.00177699
	LOSS [training: 0.21592442082528535 | validation: 0.22711153314093707]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_813.pth
	Model improved!!!
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19582287282487004		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.19582287282487004 | validation: 0.3087507813326172]
	TIME [epoch: 9.8 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23757277396353027		[learning rate: 0.0017684]
	Learning Rate: 0.00176839
	LOSS [training: 0.23757277396353027 | validation: 0.25494223773537505]
	TIME [epoch: 9.8 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21477074475122698		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.21477074475122698 | validation: 0.2724614706647274]
	TIME [epoch: 10 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27485957382901177		[learning rate: 0.0017598]
	Learning Rate: 0.00175984
	LOSS [training: 0.27485957382901177 | validation: 0.2908555520988789]
	TIME [epoch: 9.8 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24753522669665756		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.24753522669665756 | validation: 0.2734642871712723]
	TIME [epoch: 9.81 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20049159756857785		[learning rate: 0.0017513]
	Learning Rate: 0.00175133
	LOSS [training: 0.20049159756857785 | validation: 0.24549042383279762]
	TIME [epoch: 9.79 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1957175448171498		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.1957175448171498 | validation: 0.24627365800588588]
	TIME [epoch: 9.79 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20259301450427752		[learning rate: 0.0017429]
	Learning Rate: 0.00174286
	LOSS [training: 0.20259301450427752 | validation: 0.25135547467867136]
	TIME [epoch: 9.79 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2071526252817054		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.2071526252817054 | validation: 0.27668430606791267]
	TIME [epoch: 9.81 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21488938699053697		[learning rate: 0.0017344]
	Learning Rate: 0.00173443
	LOSS [training: 0.21488938699053697 | validation: 0.27137794086745]
	TIME [epoch: 9.79 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20050465208504592		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.20050465208504592 | validation: 0.2270424375510536]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_824.pth
	Model improved!!!
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19332950016550346		[learning rate: 0.001726]
	Learning Rate: 0.00172605
	LOSS [training: 0.19332950016550346 | validation: 0.20613601423568775]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21210742004184144		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.21210742004184144 | validation: 0.27952383688199883]
	TIME [epoch: 9.8 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26445585782334186		[learning rate: 0.0017177]
	Learning Rate: 0.0017177
	LOSS [training: 0.26445585782334186 | validation: 0.3145032066144543]
	TIME [epoch: 9.79 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38251999187776964		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.38251999187776964 | validation: 0.2846847275171529]
	TIME [epoch: 9.79 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27469857210421156		[learning rate: 0.0017094]
	Learning Rate: 0.00170939
	LOSS [training: 0.27469857210421156 | validation: 0.2522900870622843]
	TIME [epoch: 9.81 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.261367485596137		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.261367485596137 | validation: 0.32999993134548605]
	TIME [epoch: 9.79 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2425528172098644		[learning rate: 0.0017011]
	Learning Rate: 0.00170113
	LOSS [training: 0.2425528172098644 | validation: 0.23141335035913976]
	TIME [epoch: 9.8 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.196880391024918		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.196880391024918 | validation: 0.25572955517443546]
	TIME [epoch: 9.81 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22722465658776034		[learning rate: 0.0016929]
	Learning Rate: 0.0016929
	LOSS [training: 0.22722465658776034 | validation: 0.24102051852524028]
	TIME [epoch: 9.8 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2232095586900483		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.2232095586900483 | validation: 0.30108999032025074]
	TIME [epoch: 9.79 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22586792070097617		[learning rate: 0.0016847]
	Learning Rate: 0.00168471
	LOSS [training: 0.22586792070097617 | validation: 0.24252007606942733]
	TIME [epoch: 9.79 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18991499221670266		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.18991499221670266 | validation: 0.30413519595827315]
	TIME [epoch: 9.8 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2528497597584453		[learning rate: 0.0016766]
	Learning Rate: 0.00167657
	LOSS [training: 0.2528497597584453 | validation: 0.25787596765783855]
	TIME [epoch: 9.79 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21562966503599093		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.21562966503599093 | validation: 0.2871658581363357]
	TIME [epoch: 9.79 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20532994293585433		[learning rate: 0.0016685]
	Learning Rate: 0.00166846
	LOSS [training: 0.20532994293585433 | validation: 0.30689548859822513]
	TIME [epoch: 9.83 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26396885486232774		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.26396885486232774 | validation: 0.36997672403699833]
	TIME [epoch: 9.8 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2767621507364213		[learning rate: 0.0016604]
	Learning Rate: 0.00166039
	LOSS [training: 0.2767621507364213 | validation: 0.37476230439924657]
	TIME [epoch: 9.8 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3065355920129746		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.3065355920129746 | validation: 0.33509928636912323]
	TIME [epoch: 9.79 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2626437261344756		[learning rate: 0.0016524]
	Learning Rate: 0.00165236
	LOSS [training: 0.2626437261344756 | validation: 0.3453099004388212]
	TIME [epoch: 9.82 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34795356811511285		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.34795356811511285 | validation: 0.409050451940599]
	TIME [epoch: 9.79 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40105612931519496		[learning rate: 0.0016444]
	Learning Rate: 0.00164437
	LOSS [training: 0.40105612931519496 | validation: 0.5900017417729465]
	TIME [epoch: 9.79 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43410517729236836		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.43410517729236836 | validation: 0.5143869959475827]
	TIME [epoch: 9.79 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3820851771835173		[learning rate: 0.0016364]
	Learning Rate: 0.00163642
	LOSS [training: 0.3820851771835173 | validation: 0.33671473200726637]
	TIME [epoch: 9.81 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2972073804036461		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.2972073804036461 | validation: 0.36892794058034]
	TIME [epoch: 9.79 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30477733103821786		[learning rate: 0.0016285]
	Learning Rate: 0.00162851
	LOSS [training: 0.30477733103821786 | validation: 0.31357001526318246]
	TIME [epoch: 9.79 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31053213449630723		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.31053213449630723 | validation: 0.3116860094825831]
	TIME [epoch: 9.81 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2690062283107705		[learning rate: 0.0016206]
	Learning Rate: 0.00162063
	LOSS [training: 0.2690062283107705 | validation: 0.29695189089240936]
	TIME [epoch: 9.8 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31104786242430527		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.31104786242430527 | validation: 0.3150423204674141]
	TIME [epoch: 9.79 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33041761580588236		[learning rate: 0.0016128]
	Learning Rate: 0.00161279
	LOSS [training: 0.33041761580588236 | validation: 0.35031845737597134]
	TIME [epoch: 9.8 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3304524837426119		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.3304524837426119 | validation: 0.423719772638083]
	TIME [epoch: 9.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33820525260132334		[learning rate: 0.001605]
	Learning Rate: 0.001605
	LOSS [training: 0.33820525260132334 | validation: 0.3431592187799604]
	TIME [epoch: 9.79 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30442507494257404		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.30442507494257404 | validation: 0.32562912074179345]
	TIME [epoch: 9.79 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3073530229707364		[learning rate: 0.0015972]
	Learning Rate: 0.00159723
	LOSS [training: 0.3073530229707364 | validation: 0.37961486998530747]
	TIME [epoch: 9.8 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46118031406610493		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.46118031406610493 | validation: 0.4978144115941091]
	TIME [epoch: 9.79 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4451803467033172		[learning rate: 0.0015895]
	Learning Rate: 0.00158951
	LOSS [training: 0.4451803467033172 | validation: 0.5053812981145225]
	TIME [epoch: 9.79 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3929262133561985		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.3929262133561985 | validation: 0.37354606320926736]
	TIME [epoch: 9.79 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3221661925147628		[learning rate: 0.0015818]
	Learning Rate: 0.00158182
	LOSS [training: 0.3221661925147628 | validation: 0.34442869916803726]
	TIME [epoch: 9.8 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31374438160540297		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.31374438160540297 | validation: 0.41068736630680563]
	TIME [epoch: 9.78 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3492867626776567		[learning rate: 0.0015742]
	Learning Rate: 0.00157417
	LOSS [training: 0.3492867626776567 | validation: 0.42031048547151145]
	TIME [epoch: 9.79 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3188716999837407		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.3188716999837407 | validation: 0.30601229328056906]
	TIME [epoch: 9.8 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2736492464897413		[learning rate: 0.0015666]
	Learning Rate: 0.00156656
	LOSS [training: 0.2736492464897413 | validation: 0.31737365826949593]
	TIME [epoch: 9.8 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27409790993588673		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.27409790993588673 | validation: 0.2570602337776941]
	TIME [epoch: 9.78 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24564894065634996		[learning rate: 0.001559]
	Learning Rate: 0.00155899
	LOSS [training: 0.24564894065634996 | validation: 0.31867346755290116]
	TIME [epoch: 9.79 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3108824263103741		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.3108824263103741 | validation: 0.2678579067413474]
	TIME [epoch: 9.81 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22243796419109368		[learning rate: 0.0015514]
	Learning Rate: 0.00155145
	LOSS [training: 0.22243796419109368 | validation: 0.3158175842991486]
	TIME [epoch: 9.79 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2739856260772661		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.2739856260772661 | validation: 0.34123119770232]
	TIME [epoch: 9.79 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2831428778819777		[learning rate: 0.0015439]
	Learning Rate: 0.00154394
	LOSS [training: 0.2831428778819777 | validation: 0.29838436906840426]
	TIME [epoch: 9.8 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24555421366362581		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.24555421366362581 | validation: 0.19674497137519653]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_872.pth
	Model improved!!!
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22936170202863107		[learning rate: 0.0015365]
	Learning Rate: 0.00153648
	LOSS [training: 0.22936170202863107 | validation: 0.23769754652630787]
	TIME [epoch: 9.79 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21514999521157868		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.21514999521157868 | validation: 0.2670553432875277]
	TIME [epoch: 9.79 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23177042468974846		[learning rate: 0.001529]
	Learning Rate: 0.00152905
	LOSS [training: 0.23177042468974846 | validation: 0.22638121131521985]
	TIME [epoch: 9.81 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28153171908939606		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.28153171908939606 | validation: 0.3350546152160194]
	TIME [epoch: 9.79 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.249995235012001		[learning rate: 0.0015217]
	Learning Rate: 0.00152165
	LOSS [training: 0.249995235012001 | validation: 0.21920346769713944]
	TIME [epoch: 9.79 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19837610612589232		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.19837610612589232 | validation: 0.26299528341458006]
	TIME [epoch: 9.8 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24910669715565562		[learning rate: 0.0015143]
	Learning Rate: 0.00151429
	LOSS [training: 0.24910669715565562 | validation: 0.30225796001739336]
	TIME [epoch: 9.8 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20270794471497816		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.20270794471497816 | validation: 0.2448563560501173]
	TIME [epoch: 9.79 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2802197230398965		[learning rate: 0.001507]
	Learning Rate: 0.00150697
	LOSS [training: 0.2802197230398965 | validation: 0.2494611810300701]
	TIME [epoch: 9.79 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28039320568376486		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.28039320568376486 | validation: 0.2387134728699565]
	TIME [epoch: 9.81 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2551367066376279		[learning rate: 0.0014997]
	Learning Rate: 0.00149968
	LOSS [training: 0.2551367066376279 | validation: 0.21366410778549452]
	TIME [epoch: 9.79 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18496688621947432		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.18496688621947432 | validation: 0.2227272823013754]
	TIME [epoch: 9.78 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.184270121564164		[learning rate: 0.0014924]
	Learning Rate: 0.00149243
	LOSS [training: 0.184270121564164 | validation: 0.2459941754390649]
	TIME [epoch: 9.79 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20716800982284247		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.20716800982284247 | validation: 0.22403542122515732]
	TIME [epoch: 9.79 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20399873940511676		[learning rate: 0.0014852]
	Learning Rate: 0.00148522
	LOSS [training: 0.20399873940511676 | validation: 0.2570896324761899]
	TIME [epoch: 9.79 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23537254861735768		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.23537254861735768 | validation: 0.2348163303250723]
	TIME [epoch: 9.79 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2090932214220486		[learning rate: 0.001478]
	Learning Rate: 0.00147803
	LOSS [training: 0.2090932214220486 | validation: 0.2704760438072714]
	TIME [epoch: 9.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23745477744043497		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.23745477744043497 | validation: 0.2748121224359494]
	TIME [epoch: 9.78 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24652952969702824		[learning rate: 0.0014709]
	Learning Rate: 0.00147089
	LOSS [training: 0.24652952969702824 | validation: 0.23142714717953308]
	TIME [epoch: 9.78 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20861385551021452		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.20861385551021452 | validation: 0.23744855312527763]
	TIME [epoch: 9.78 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22990347181630502		[learning rate: 0.0014638]
	Learning Rate: 0.00146377
	LOSS [training: 0.22990347181630502 | validation: 0.2603888158055143]
	TIME [epoch: 9.81 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2716381054581027		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.2716381054581027 | validation: 0.25718403100271964]
	TIME [epoch: 9.78 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27899287843668047		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.27899287843668047 | validation: 0.24310232867281276]
	TIME [epoch: 9.78 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22334301866718578		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.22334301866718578 | validation: 0.21644117836278173]
	TIME [epoch: 9.8 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1975662366276934		[learning rate: 0.0014497]
	Learning Rate: 0.00144965
	LOSS [training: 0.1975662366276934 | validation: 0.22015883457800187]
	TIME [epoch: 9.79 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2061628516506957		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.2061628516506957 | validation: 0.20224866770077404]
	TIME [epoch: 9.78 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20407797894917507		[learning rate: 0.0014426]
	Learning Rate: 0.00144264
	LOSS [training: 0.20407797894917507 | validation: 0.22805025348676]
	TIME [epoch: 9.79 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2119367017072113		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.2119367017072113 | validation: 0.25107272377196216]
	TIME [epoch: 9.81 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22620352323142678		[learning rate: 0.0014357]
	Learning Rate: 0.00143566
	LOSS [training: 0.22620352323142678 | validation: 0.2723616404133343]
	TIME [epoch: 9.78 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20173363458110946		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.20173363458110946 | validation: 0.2272597940010936]
	TIME [epoch: 9.78 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18977912438919253		[learning rate: 0.0014287]
	Learning Rate: 0.00142872
	LOSS [training: 0.18977912438919253 | validation: 0.2761149457363469]
	TIME [epoch: 9.8 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2303387423401318		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.2303387423401318 | validation: 0.2800524184212311]
	TIME [epoch: 9.78 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23765295461968253		[learning rate: 0.0014218]
	Learning Rate: 0.00142181
	LOSS [training: 0.23765295461968253 | validation: 0.2263699705777662]
	TIME [epoch: 9.79 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2041957222320973		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.2041957222320973 | validation: 0.19275217136631853]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_906.pth
	Model improved!!!
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19356604307286523		[learning rate: 0.0014149]
	Learning Rate: 0.00141494
	LOSS [training: 0.19356604307286523 | validation: 0.3525732154153673]
	TIME [epoch: 9.81 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21672699241601734		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.21672699241601734 | validation: 0.2422619705805107]
	TIME [epoch: 9.79 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27443268193976317		[learning rate: 0.0014081]
	Learning Rate: 0.00140809
	LOSS [training: 0.27443268193976317 | validation: 0.2952291365171818]
	TIME [epoch: 9.79 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24616302456163996		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.24616302456163996 | validation: 0.27094832190476953]
	TIME [epoch: 9.79 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2508976465716052		[learning rate: 0.0014013]
	Learning Rate: 0.00140128
	LOSS [training: 0.2508976465716052 | validation: 0.2953301706414508]
	TIME [epoch: 9.79 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23467721600765118		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.23467721600765118 | validation: 0.26534662483650434]
	TIME [epoch: 9.78 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22623361702556877		[learning rate: 0.0013945]
	Learning Rate: 0.00139451
	LOSS [training: 0.22623361702556877 | validation: 0.26634052735788694]
	TIME [epoch: 9.79 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21939966439411665		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.21939966439411665 | validation: 0.31225438965551694]
	TIME [epoch: 9.8 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23080755545609835		[learning rate: 0.0013878]
	Learning Rate: 0.00138776
	LOSS [training: 0.23080755545609835 | validation: 0.27601585234615394]
	TIME [epoch: 9.79 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2034405930172401		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.2034405930172401 | validation: 0.29748362376196946]
	TIME [epoch: 9.78 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24000728295668802		[learning rate: 0.0013811]
	Learning Rate: 0.00138105
	LOSS [training: 0.24000728295668802 | validation: 0.2484285573732715]
	TIME [epoch: 9.79 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23638107739672934		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.23638107739672934 | validation: 0.2710085074785942]
	TIME [epoch: 9.8 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20191756122425214		[learning rate: 0.0013744]
	Learning Rate: 0.00137437
	LOSS [training: 0.20191756122425214 | validation: 0.24461260286887965]
	TIME [epoch: 9.78 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2168413441144752		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.2168413441144752 | validation: 0.27800863081472005]
	TIME [epoch: 9.78 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2154043407388973		[learning rate: 0.0013677]
	Learning Rate: 0.00136773
	LOSS [training: 0.2154043407388973 | validation: 0.211250805581628]
	TIME [epoch: 9.79 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2025844042348397		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.2025844042348397 | validation: 0.23117770170176896]
	TIME [epoch: 9.78 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1952247009996207		[learning rate: 0.0013611]
	Learning Rate: 0.00136111
	LOSS [training: 0.1952247009996207 | validation: 0.2494440686201721]
	TIME [epoch: 9.78 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21816732115296827		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.21816732115296827 | validation: 0.26584902381865533]
	TIME [epoch: 9.78 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21360515802199492		[learning rate: 0.0013545]
	Learning Rate: 0.00135453
	LOSS [training: 0.21360515802199492 | validation: 0.2570515925286901]
	TIME [epoch: 9.79 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23493093399426979		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.23493093399426979 | validation: 0.28133786977109854]
	TIME [epoch: 9.78 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22346870696131466		[learning rate: 0.001348]
	Learning Rate: 0.00134798
	LOSS [training: 0.22346870696131466 | validation: 0.2110996791002979]
	TIME [epoch: 9.78 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1962043110401897		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.1962043110401897 | validation: 0.22053414953190248]
	TIME [epoch: 9.8 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19103275016326454		[learning rate: 0.0013415]
	Learning Rate: 0.00134146
	LOSS [training: 0.19103275016326454 | validation: 0.22617351983280742]
	TIME [epoch: 9.78 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21969785745109288		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.21969785745109288 | validation: 0.24819947858985822]
	TIME [epoch: 9.79 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21819729740623856		[learning rate: 0.001335]
	Learning Rate: 0.00133498
	LOSS [training: 0.21819729740623856 | validation: 0.19881409323107066]
	TIME [epoch: 9.79 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19552618815400571		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.19552618815400571 | validation: 0.39163260660419985]
	TIME [epoch: 9.8 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27774969043939374		[learning rate: 0.0013285]
	Learning Rate: 0.00132852
	LOSS [training: 0.27774969043939374 | validation: 0.22455576631589502]
	TIME [epoch: 9.78 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21724151497663838		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.21724151497663838 | validation: 0.2216237707019837]
	TIME [epoch: 9.78 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17853862432740358		[learning rate: 0.0013221]
	Learning Rate: 0.0013221
	LOSS [training: 0.17853862432740358 | validation: 0.2508637141161584]
	TIME [epoch: 9.79 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24030076642112377		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.24030076642112377 | validation: 0.27270029971466053]
	TIME [epoch: 9.78 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20686608636944032		[learning rate: 0.0013157]
	Learning Rate: 0.0013157
	LOSS [training: 0.20686608636944032 | validation: 0.20432316735885092]
	TIME [epoch: 9.78 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19389838103955462		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.19389838103955462 | validation: 0.19822334348844145]
	TIME [epoch: 9.78 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21634003839825838		[learning rate: 0.0013093]
	Learning Rate: 0.00130934
	LOSS [training: 0.21634003839825838 | validation: 0.2708104476405515]
	TIME [epoch: 9.81 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25134046997039816		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.25134046997039816 | validation: 0.2885459923109027]
	TIME [epoch: 9.78 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23001990163518685		[learning rate: 0.001303]
	Learning Rate: 0.00130301
	LOSS [training: 0.23001990163518685 | validation: 0.22358194817572297]
	TIME [epoch: 9.78 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18418501320293765		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.18418501320293765 | validation: 0.214863026549839]
	TIME [epoch: 9.78 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18184942764383574		[learning rate: 0.0012967]
	Learning Rate: 0.00129671
	LOSS [training: 0.18184942764383574 | validation: 0.23234515471907569]
	TIME [epoch: 9.8 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21722374120013024		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.21722374120013024 | validation: 0.28343669654668463]
	TIME [epoch: 9.79 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22199934594310244		[learning rate: 0.0012904]
	Learning Rate: 0.00129044
	LOSS [training: 0.22199934594310244 | validation: 0.2112290227146645]
	TIME [epoch: 9.78 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17148119570158557		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.17148119570158557 | validation: 0.22002079938966962]
	TIME [epoch: 9.79 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17783413145111865		[learning rate: 0.0012842]
	Learning Rate: 0.0012842
	LOSS [training: 0.17783413145111865 | validation: 0.22180651117062128]
	TIME [epoch: 9.78 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17691241587594364		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.17691241587594364 | validation: 0.24878179582472743]
	TIME [epoch: 9.78 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19483965869141345		[learning rate: 0.001278]
	Learning Rate: 0.00127799
	LOSS [training: 0.19483965869141345 | validation: 0.25419038788133536]
	TIME [epoch: 9.79 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23755451647824183		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.23755451647824183 | validation: 0.2640043235858661]
	TIME [epoch: 9.8 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2750062687584144		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.2750062687584144 | validation: 0.3028190269863662]
	TIME [epoch: 9.79 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32345675635655036		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.32345675635655036 | validation: 0.2984625151190166]
	TIME [epoch: 9.78 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34633377475096483		[learning rate: 0.0012657]
	Learning Rate: 0.00126566
	LOSS [training: 0.34633377475096483 | validation: 0.27569669504973904]
	TIME [epoch: 9.81 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3259607280433189		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.3259607280433189 | validation: 0.2803392866090223]
	TIME [epoch: 9.78 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.278490271612261		[learning rate: 0.0012595]
	Learning Rate: 0.00125954
	LOSS [training: 0.278490271612261 | validation: 0.22119314308997517]
	TIME [epoch: 9.78 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21616427032511173		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.21616427032511173 | validation: 0.18927480309725359]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_956.pth
	Model improved!!!
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2161768521086616		[learning rate: 0.0012534]
	Learning Rate: 0.00125344
	LOSS [training: 0.2161768521086616 | validation: 0.24386558571062536]
	TIME [epoch: 9.81 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22736526330338772		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.22736526330338772 | validation: 0.22388316510401582]
	TIME [epoch: 9.79 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19817732142901515		[learning rate: 0.0012474]
	Learning Rate: 0.00124738
	LOSS [training: 0.19817732142901515 | validation: 0.2047317115721743]
	TIME [epoch: 9.79 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1982735288044873		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.1982735288044873 | validation: 0.2223297537038562]
	TIME [epoch: 9.8 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19137639785627486		[learning rate: 0.0012414]
	Learning Rate: 0.00124135
	LOSS [training: 0.19137639785627486 | validation: 0.18871022460912865]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_961.pth
	Model improved!!!
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17967403822212052		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.17967403822212052 | validation: 0.21427718612472613]
	TIME [epoch: 9.78 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1854365765357694		[learning rate: 0.0012353]
	Learning Rate: 0.00123535
	LOSS [training: 0.1854365765357694 | validation: 0.20232814808506563]
	TIME [epoch: 9.78 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1849942165111629		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.1849942165111629 | validation: 0.2306315510538547]
	TIME [epoch: 9.8 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1900446077179969		[learning rate: 0.0012294]
	Learning Rate: 0.00122937
	LOSS [training: 0.1900446077179969 | validation: 0.19893837578360843]
	TIME [epoch: 9.78 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17645759775334832		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.17645759775334832 | validation: 0.25661939880593354]
	TIME [epoch: 9.79 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20477981097094977		[learning rate: 0.0012234]
	Learning Rate: 0.00122343
	LOSS [training: 0.20477981097094977 | validation: 0.21185564785759387]
	TIME [epoch: 9.8 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19066084198773775		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.19066084198773775 | validation: 0.20387779806357154]
	TIME [epoch: 9.79 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18682174373451046		[learning rate: 0.0012175]
	Learning Rate: 0.00121751
	LOSS [training: 0.18682174373451046 | validation: 0.19693289181003412]
	TIME [epoch: 9.78 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18088839769587214		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.18088839769587214 | validation: 0.2239531280606314]
	TIME [epoch: 9.77 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2079797218521608		[learning rate: 0.0012116]
	Learning Rate: 0.00121163
	LOSS [training: 0.2079797218521608 | validation: 0.2682786692543258]
	TIME [epoch: 9.8 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32214956921123294		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.32214956921123294 | validation: 0.2732213875940658]
	TIME [epoch: 9.79 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2959135635527885		[learning rate: 0.0012058]
	Learning Rate: 0.00120577
	LOSS [training: 0.2959135635527885 | validation: 0.23399913911788572]
	TIME [epoch: 9.78 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20366373208726962		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.20366373208726962 | validation: 0.20765273356849234]
	TIME [epoch: 9.79 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19634604027556052		[learning rate: 0.0011999]
	Learning Rate: 0.00119994
	LOSS [training: 0.19634604027556052 | validation: 0.2068112593801993]
	TIME [epoch: 9.78 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18711737623022068		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.18711737623022068 | validation: 0.20081533973239465]
	TIME [epoch: 9.79 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1916797783522386		[learning rate: 0.0011941]
	Learning Rate: 0.00119413
	LOSS [training: 0.1916797783522386 | validation: 0.20523926371006795]
	TIME [epoch: 9.77 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20502933190538242		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.20502933190538242 | validation: 0.2025496171405684]
	TIME [epoch: 9.8 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23135608562022228		[learning rate: 0.0011884]
	Learning Rate: 0.00118836
	LOSS [training: 0.23135608562022228 | validation: 0.23399179096140665]
	TIME [epoch: 9.78 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2579187043821835		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.2579187043821835 | validation: 0.2272076655750601]
	TIME [epoch: 9.79 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21472134581323984		[learning rate: 0.0011826]
	Learning Rate: 0.00118261
	LOSS [training: 0.21472134581323984 | validation: 0.25519658388153105]
	TIME [epoch: 9.78 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2677758159424485		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.2677758159424485 | validation: 0.2455443567942112]
	TIME [epoch: 9.8 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25321579416344375		[learning rate: 0.0011769]
	Learning Rate: 0.00117689
	LOSS [training: 0.25321579416344375 | validation: 0.24431712738868563]
	TIME [epoch: 9.78 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21962721165138954		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.21962721165138954 | validation: 0.25127141705150235]
	TIME [epoch: 9.79 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19772019089325482		[learning rate: 0.0011712]
	Learning Rate: 0.0011712
	LOSS [training: 0.19772019089325482 | validation: 0.1780029106008087]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_985.pth
	Model improved!!!
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17272817458304185		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.17272817458304185 | validation: 0.20937323816968334]
	TIME [epoch: 9.79 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16843589723701952		[learning rate: 0.0011655]
	Learning Rate: 0.00116554
	LOSS [training: 0.16843589723701952 | validation: 0.19341292894863302]
	TIME [epoch: 9.78 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20215837152256572		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.20215837152256572 | validation: 0.22619231163855033]
	TIME [epoch: 9.79 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18669110079243117		[learning rate: 0.0011599]
	Learning Rate: 0.0011599
	LOSS [training: 0.18669110079243117 | validation: 0.1760919386524966]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_989.pth
	Model improved!!!
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16014332378640941		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.16014332378640941 | validation: 0.17706118910718502]
	TIME [epoch: 9.78 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16827323078800965		[learning rate: 0.0011543]
	Learning Rate: 0.00115429
	LOSS [training: 0.16827323078800965 | validation: 0.21358496608697106]
	TIME [epoch: 9.77 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1674632963115316		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.1674632963115316 | validation: 0.22930014104058657]
	TIME [epoch: 9.79 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23478388120469845		[learning rate: 0.0011487]
	Learning Rate: 0.00114871
	LOSS [training: 0.23478388120469845 | validation: 0.24791355583119]
	TIME [epoch: 9.78 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23485714183336662		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.23485714183336662 | validation: 0.19526603132836734]
	TIME [epoch: 9.78 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20243859119726704		[learning rate: 0.0011432]
	Learning Rate: 0.00114316
	LOSS [training: 0.20243859119726704 | validation: 0.2273444997284576]
	TIME [epoch: 9.78 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18130294033115196		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.18130294033115196 | validation: 0.19760940152533546]
	TIME [epoch: 9.8 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18195567737497415		[learning rate: 0.0011376]
	Learning Rate: 0.00113763
	LOSS [training: 0.18195567737497415 | validation: 0.18514649288630008]
	TIME [epoch: 9.78 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21419592331584622		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.21419592331584622 | validation: 0.34032609356733884]
	TIME [epoch: 9.78 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2770393863015301		[learning rate: 0.0011321]
	Learning Rate: 0.00113213
	LOSS [training: 0.2770393863015301 | validation: 0.2259535462481319]
	TIME [epoch: 9.79 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26017122259167685		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.26017122259167685 | validation: 0.2104374904213099]
	TIME [epoch: 9.79 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19443714397473483		[learning rate: 0.0011267]
	Learning Rate: 0.00112665
	LOSS [training: 0.19443714397473483 | validation: 0.20407686894072286]
	TIME [epoch: 9.77 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18082359101330653		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.18082359101330653 | validation: 0.22616549432955246]
	TIME [epoch: 9.78 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17641316252229228		[learning rate: 0.0011212]
	Learning Rate: 0.0011212
	LOSS [training: 0.17641316252229228 | validation: 0.19813956981227987]
	TIME [epoch: 9.8 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16504184367624447		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.16504184367624447 | validation: 0.21657660814994636]
	TIME [epoch: 9.78 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17028811022798343		[learning rate: 0.0011158]
	Learning Rate: 0.00111578
	LOSS [training: 0.17028811022798343 | validation: 0.2626894248374725]
	TIME [epoch: 9.79 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2278366499321985		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.2278366499321985 | validation: 0.2707736737355225]
	TIME [epoch: 9.79 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2390888501337109		[learning rate: 0.0011104]
	Learning Rate: 0.00111039
	LOSS [training: 0.2390888501337109 | validation: 0.20796191736015077]
	TIME [epoch: 9.78 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1784250004594365		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.1784250004594365 | validation: 0.23125282256357482]
	TIME [epoch: 9.78 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17632925324856832		[learning rate: 0.001105]
	Learning Rate: 0.00110502
	LOSS [training: 0.17632925324856832 | validation: 0.1784018145470843]
	TIME [epoch: 9.79 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16635138355605833		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.16635138355605833 | validation: 0.1916984181546499]
	TIME [epoch: 9.8 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14695882463800447		[learning rate: 0.0010997]
	Learning Rate: 0.00109967
	LOSS [training: 0.14695882463800447 | validation: 0.18433393350808946]
	TIME [epoch: 9.79 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1407949999439974		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.1407949999439974 | validation: 0.18484608177214065]
	TIME [epoch: 9.78 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20561296218204222		[learning rate: 0.0010944]
	Learning Rate: 0.00109435
	LOSS [training: 0.20561296218204222 | validation: 0.2140391221860858]
	TIME [epoch: 9.79 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18072588689267546		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.18072588689267546 | validation: 0.19476672872050274]
	TIME [epoch: 9.8 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1556066900137453		[learning rate: 0.0010891]
	Learning Rate: 0.00108906
	LOSS [training: 0.1556066900137453 | validation: 0.22950948751565314]
	TIME [epoch: 9.79 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1918058850429311		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.1918058850429311 | validation: 0.22039070169029365]
	TIME [epoch: 9.78 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15292335147931918		[learning rate: 0.0010838]
	Learning Rate: 0.0010838
	LOSS [training: 0.15292335147931918 | validation: 0.1655632555414078]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1017.pth
	Model improved!!!
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16873768815899476		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.16873768815899476 | validation: 0.17141712120034375]
	TIME [epoch: 9.78 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14501440131290216		[learning rate: 0.0010786]
	Learning Rate: 0.00107855
	LOSS [training: 0.14501440131290216 | validation: 0.18980352600551015]
	TIME [epoch: 9.79 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16460938134169387		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.16460938134169387 | validation: 0.18596391246679786]
	TIME [epoch: 9.78 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14643268670649853		[learning rate: 0.0010733]
	Learning Rate: 0.00107334
	LOSS [training: 0.14643268670649853 | validation: 0.2013220012394084]
	TIME [epoch: 9.79 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1394162851714594		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.1394162851714594 | validation: 0.21087926337907786]
	TIME [epoch: 9.78 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16879009588018942		[learning rate: 0.0010681]
	Learning Rate: 0.00106815
	LOSS [training: 0.16879009588018942 | validation: 0.21071362298258722]
	TIME [epoch: 9.79 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16734560026912199		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.16734560026912199 | validation: 0.16869442650051958]
	TIME [epoch: 9.8 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16090253645436664		[learning rate: 0.001063]
	Learning Rate: 0.00106298
	LOSS [training: 0.16090253645436664 | validation: 0.1989983072584829]
	TIME [epoch: 9.79 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17305927120312306		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.17305927120312306 | validation: 0.22602577883856328]
	TIME [epoch: 9.77 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19174460069097216		[learning rate: 0.0010578]
	Learning Rate: 0.00105784
	LOSS [training: 0.19174460069097216 | validation: 0.17738059045906007]
	TIME [epoch: 9.79 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16342582910029696		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.16342582910029696 | validation: 0.2019274171639036]
	TIME [epoch: 9.79 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18978910029068738		[learning rate: 0.0010527]
	Learning Rate: 0.00105273
	LOSS [training: 0.18978910029068738 | validation: 0.24697729353481998]
	TIME [epoch: 9.78 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2563151850968977		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.2563151850968977 | validation: 0.2539442871299292]
	TIME [epoch: 9.78 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29397109045673064		[learning rate: 0.0010476]
	Learning Rate: 0.00104764
	LOSS [training: 0.29397109045673064 | validation: 0.26000771838252873]
	TIME [epoch: 9.8 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2796788139595643		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.2796788139595643 | validation: 0.2743141670829875]
	TIME [epoch: 9.77 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2683977924338175		[learning rate: 0.0010426]
	Learning Rate: 0.00104257
	LOSS [training: 0.2683977924338175 | validation: 0.2247609369605857]
	TIME [epoch: 9.78 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19658264409467582		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.19658264409467582 | validation: 0.1851243583878736]
	TIME [epoch: 9.77 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15469769424415464		[learning rate: 0.0010375]
	Learning Rate: 0.00103753
	LOSS [training: 0.15469769424415464 | validation: 0.1896260398176515]
	TIME [epoch: 9.8 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17135925646524472		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.17135925646524472 | validation: 0.19522486737695313]
	TIME [epoch: 9.77 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16135051303305678		[learning rate: 0.0010325]
	Learning Rate: 0.00103251
	LOSS [training: 0.16135051303305678 | validation: 0.2025933960894217]
	TIME [epoch: 9.77 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2033242569037738		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.2033242569037738 | validation: 0.2327416628685746]
	TIME [epoch: 9.79 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24653169980095518		[learning rate: 0.0010275]
	Learning Rate: 0.00102752
	LOSS [training: 0.24653169980095518 | validation: 0.2605854248661164]
	TIME [epoch: 9.79 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24229056672455376		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.24229056672455376 | validation: 0.2308759696140248]
	TIME [epoch: 9.78 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22375579391144126		[learning rate: 0.0010225]
	Learning Rate: 0.00102255
	LOSS [training: 0.22375579391144126 | validation: 0.22618132956426817]
	TIME [epoch: 9.78 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17240632789362267		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.17240632789362267 | validation: 0.24192369563371766]
	TIME [epoch: 9.79 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2807117574860395		[learning rate: 0.0010176]
	Learning Rate: 0.0010176
	LOSS [training: 0.2807117574860395 | validation: 0.3140038814797161]
	TIME [epoch: 9.78 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25160883248413074		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.25160883248413074 | validation: 0.28643251029923944]
	TIME [epoch: 9.77 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2742922732537173		[learning rate: 0.0010127]
	Learning Rate: 0.00101268
	LOSS [training: 0.2742922732537173 | validation: 0.3552482352148657]
	TIME [epoch: 9.79 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32351531934018396		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.32351531934018396 | validation: 0.2836899973051547]
	TIME [epoch: 9.78 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24494577460456216		[learning rate: 0.0010078]
	Learning Rate: 0.00100779
	LOSS [training: 0.24494577460456216 | validation: 0.26010449835020116]
	TIME [epoch: 9.78 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21824624905248494		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.21824624905248494 | validation: 0.21800190103458644]
	TIME [epoch: 9.77 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1725419580463389		[learning rate: 0.0010029]
	Learning Rate: 0.00100291
	LOSS [training: 0.1725419580463389 | validation: 0.22833397065154992]
	TIME [epoch: 9.81 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18586320955360905		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.18586320955360905 | validation: 0.23033474999146486]
	TIME [epoch: 9.78 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20593852507916693		[learning rate: 0.00099806]
	Learning Rate: 0.000998063
	LOSS [training: 0.20593852507916693 | validation: 0.2821000343162514]
	TIME [epoch: 9.79 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2849733656722466		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.2849733656722466 | validation: 0.2744318277414909]
	TIME [epoch: 9.78 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28440584812568176		[learning rate: 0.00099324]
	Learning Rate: 0.000993237
	LOSS [training: 0.28440584812568176 | validation: 0.24780084971477995]
	TIME [epoch: 9.8 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2507385619655463		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.2507385619655463 | validation: 0.2441789614255482]
	TIME [epoch: 9.77 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2118693032858384		[learning rate: 0.00098843]
	Learning Rate: 0.000988433
	LOSS [training: 0.2118693032858384 | validation: 0.1929642516305586]
	TIME [epoch: 9.78 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18727346601571976		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.18727346601571976 | validation: 0.15267405073145146]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1056.pth
	Model improved!!!
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1812676231712091		[learning rate: 0.00098365]
	Learning Rate: 0.000983653
	LOSS [training: 0.1812676231712091 | validation: 0.2479170519660255]
	TIME [epoch: 9.78 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20076281869808774		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.20076281869808774 | validation: 0.2557168608217534]
	TIME [epoch: 9.78 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21408465157892312		[learning rate: 0.0009789]
	Learning Rate: 0.000978897
	LOSS [training: 0.21408465157892312 | validation: 0.24818029285366167]
	TIME [epoch: 9.78 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2420314506320346		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.2420314506320346 | validation: 0.230667221171751]
	TIME [epoch: 9.79 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1997823421242138		[learning rate: 0.00097416]
	Learning Rate: 0.000974163
	LOSS [training: 0.1997823421242138 | validation: 0.1913399440171016]
	TIME [epoch: 9.78 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17705402197754697		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.17705402197754697 | validation: 0.20486395951432287]
	TIME [epoch: 9.77 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17978660457825724		[learning rate: 0.00096945]
	Learning Rate: 0.000969452
	LOSS [training: 0.17978660457825724 | validation: 0.2038716893641086]
	TIME [epoch: 9.8 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16605835072263742		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.16605835072263742 | validation: 0.19700218717878742]
	TIME [epoch: 9.77 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16616450049707612		[learning rate: 0.00096476]
	Learning Rate: 0.000964764
	LOSS [training: 0.16616450049707612 | validation: 0.19381649875349477]
	TIME [epoch: 9.78 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18359664724221306		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.18359664724221306 | validation: 0.20285923939284914]
	TIME [epoch: 9.79 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15893635126966466		[learning rate: 0.0009601]
	Learning Rate: 0.000960098
	LOSS [training: 0.15893635126966466 | validation: 0.19556252552830017]
	TIME [epoch: 9.8 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15412422829778308		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.15412422829778308 | validation: 0.185506481748171]
	TIME [epoch: 9.78 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14483844208065091		[learning rate: 0.00095546]
	Learning Rate: 0.000955456
	LOSS [training: 0.14483844208065091 | validation: 0.19547339130215435]
	TIME [epoch: 9.77 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1537287468987096		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.1537287468987096 | validation: 0.20305010527813946]
	TIME [epoch: 9.8 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20910521100404753		[learning rate: 0.00095084]
	Learning Rate: 0.000950835
	LOSS [training: 0.20910521100404753 | validation: 0.234023600001229]
	TIME [epoch: 9.78 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18188017077823887		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.18188017077823887 | validation: 0.1964451628569604]
	TIME [epoch: 9.78 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20049614009282535		[learning rate: 0.00094624]
	Learning Rate: 0.000946237
	LOSS [training: 0.20049614009282535 | validation: 0.21852434993505124]
	TIME [epoch: 9.78 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20803229613069107		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.20803229613069107 | validation: 0.22930937370597698]
	TIME [epoch: 9.8 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21617477795879073		[learning rate: 0.00094166]
	Learning Rate: 0.000941661
	LOSS [training: 0.21617477795879073 | validation: 0.24892806347051794]
	TIME [epoch: 9.78 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20609004620869326		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.20609004620869326 | validation: 0.21276769294125822]
	TIME [epoch: 9.78 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20358858361539234		[learning rate: 0.00093711]
	Learning Rate: 0.000937108
	LOSS [training: 0.20358858361539234 | validation: 0.24242160040172003]
	TIME [epoch: 9.79 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23088265277876033		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.23088265277876033 | validation: 0.28588893077398553]
	TIME [epoch: 9.79 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2123399474303735		[learning rate: 0.00093258]
	Learning Rate: 0.000932576
	LOSS [training: 0.2123399474303735 | validation: 0.23578621046820544]
	TIME [epoch: 9.78 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19200771873260689		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.19200771873260689 | validation: 0.2319335693700699]
	TIME [epoch: 9.78 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19680898435021374		[learning rate: 0.00092807]
	Learning Rate: 0.000928066
	LOSS [training: 0.19680898435021374 | validation: 0.22981276014924532]
	TIME [epoch: 9.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2462739856190869		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.2462739856190869 | validation: 0.26696431435973017]
	TIME [epoch: 9.78 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23205742956190267		[learning rate: 0.00092358]
	Learning Rate: 0.000923578
	LOSS [training: 0.23205742956190267 | validation: 0.210887593915086]
	TIME [epoch: 9.77 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17488416424685552		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.17488416424685552 | validation: 0.21814870607356893]
	TIME [epoch: 9.79 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16680728770864572		[learning rate: 0.00091911]
	Learning Rate: 0.000919112
	LOSS [training: 0.16680728770864572 | validation: 0.19631976348116623]
	TIME [epoch: 9.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15324767057598607		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.15324767057598607 | validation: 0.19081866038732542]
	TIME [epoch: 9.78 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15257057879805752		[learning rate: 0.00091467]
	Learning Rate: 0.000914667
	LOSS [training: 0.15257057879805752 | validation: 0.19953907500369966]
	TIME [epoch: 9.77 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1527871175705615		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.1527871175705615 | validation: 0.20224127479404788]
	TIME [epoch: 9.8 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16120100208660332		[learning rate: 0.00091024]
	Learning Rate: 0.000910244
	LOSS [training: 0.16120100208660332 | validation: 0.19278428399822992]
	TIME [epoch: 9.78 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16413564317943855		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.16413564317943855 | validation: 0.2226288508363607]
	TIME [epoch: 9.78 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16682718729565785		[learning rate: 0.00090584]
	Learning Rate: 0.000905843
	LOSS [training: 0.16682718729565785 | validation: 0.21467329138693145]
	TIME [epoch: 9.78 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15895445399072766		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.15895445399072766 | validation: 0.2131357278448791]
	TIME [epoch: 9.8 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17065953277669937		[learning rate: 0.00090146]
	Learning Rate: 0.000901462
	LOSS [training: 0.17065953277669937 | validation: 0.2134893198001016]
	TIME [epoch: 9.78 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16430266450956635		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.16430266450956635 | validation: 0.2103661006913297]
	TIME [epoch: 9.78 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15826608024862016		[learning rate: 0.0008971]
	Learning Rate: 0.000897103
	LOSS [training: 0.15826608024862016 | validation: 0.21498029257819185]
	TIME [epoch: 9.79 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17582265073069012		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.17582265073069012 | validation: 0.20977696363242881]
	TIME [epoch: 9.79 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1555834579816358		[learning rate: 0.00089276]
	Learning Rate: 0.000892764
	LOSS [training: 0.1555834579816358 | validation: 0.20136194215683922]
	TIME [epoch: 9.78 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15616118583566102		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.15616118583566102 | validation: 0.21194592415971578]
	TIME [epoch: 9.78 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16571677215902106		[learning rate: 0.00088845]
	Learning Rate: 0.000888447
	LOSS [training: 0.16571677215902106 | validation: 0.16506161033339706]
	TIME [epoch: 9.8 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1495218154356291		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.1495218154356291 | validation: 0.1728407890277918]
	TIME [epoch: 9.79 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15032324830259927		[learning rate: 0.00088415]
	Learning Rate: 0.000884151
	LOSS [training: 0.15032324830259927 | validation: 0.2012095468007729]
	TIME [epoch: 9.78 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14530403407315612		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.14530403407315612 | validation: 0.1891857095383633]
	TIME [epoch: 9.79 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15840468611203998		[learning rate: 0.00087988]
	Learning Rate: 0.000879875
	LOSS [training: 0.15840468611203998 | validation: 0.25187392747108156]
	TIME [epoch: 9.78 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18181037270697786		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.18181037270697786 | validation: 0.19109865926319317]
	TIME [epoch: 9.78 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14798023228799922		[learning rate: 0.00087562]
	Learning Rate: 0.00087562
	LOSS [training: 0.14798023228799922 | validation: 0.1906873948368882]
	TIME [epoch: 9.77 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14774337847844446		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.14774337847844446 | validation: 0.22064105026802738]
	TIME [epoch: 9.8 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20625248888943903		[learning rate: 0.00087139]
	Learning Rate: 0.000871386
	LOSS [training: 0.20625248888943903 | validation: 0.2741300359152445]
	TIME [epoch: 9.78 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19538897078504927		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.19538897078504927 | validation: 0.2326771742644401]
	TIME [epoch: 9.79 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20494724604018053		[learning rate: 0.00086717]
	Learning Rate: 0.000867172
	LOSS [training: 0.20494724604018053 | validation: 0.2428268621930009]
	TIME [epoch: 9.79 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1935591793045892		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.1935591793045892 | validation: 0.28411795843506826]
	TIME [epoch: 9.8 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21490927395815787		[learning rate: 0.00086298]
	Learning Rate: 0.000862979
	LOSS [training: 0.21490927395815787 | validation: 0.22083906294324052]
	TIME [epoch: 9.78 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19967629369809586		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.19967629369809586 | validation: 0.22167832631014572]
	TIME [epoch: 9.79 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19017169059396505		[learning rate: 0.00085881]
	Learning Rate: 0.000858805
	LOSS [training: 0.19017169059396505 | validation: 0.18456287781948927]
	TIME [epoch: 9.8 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.166088261578535		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.166088261578535 | validation: 0.19325883083957643]
	TIME [epoch: 9.78 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15574101664855583		[learning rate: 0.00085465]
	Learning Rate: 0.000854652
	LOSS [training: 0.15574101664855583 | validation: 0.20029314427858175]
	TIME [epoch: 9.78 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1571686465983994		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.1571686465983994 | validation: 0.21950052742023446]
	TIME [epoch: 9.79 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.166977797088045		[learning rate: 0.00085052]
	Learning Rate: 0.000850519
	LOSS [training: 0.166977797088045 | validation: 0.20339238157829725]
	TIME [epoch: 9.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1765308321610455		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.1765308321610455 | validation: 0.2293505943777807]
	TIME [epoch: 9.78 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2079475320910471		[learning rate: 0.00084641]
	Learning Rate: 0.000846406
	LOSS [training: 0.2079475320910471 | validation: 0.2567616544684225]
	TIME [epoch: 9.78 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23365287727743875		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.23365287727743875 | validation: 0.3010381077825498]
	TIME [epoch: 9.8 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2773357333898539		[learning rate: 0.00084231]
	Learning Rate: 0.000842313
	LOSS [training: 0.2773357333898539 | validation: 0.2674821509582596]
	TIME [epoch: 9.78 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2868812988771426		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.2868812988771426 | validation: 0.3136894058659872]
	TIME [epoch: 9.78 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2878612703284421		[learning rate: 0.00083824]
	Learning Rate: 0.00083824
	LOSS [training: 0.2878612703284421 | validation: 0.3036988162548318]
	TIME [epoch: 9.78 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2196901459253274		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.2196901459253274 | validation: 0.2622744073862417]
	TIME [epoch: 9.8 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1998465910338854		[learning rate: 0.00083419]
	Learning Rate: 0.000834187
	LOSS [training: 0.1998465910338854 | validation: 0.23301545675284735]
	TIME [epoch: 9.78 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20864497622867847		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.20864497622867847 | validation: 0.27126669509855844]
	TIME [epoch: 9.78 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2087526399319382		[learning rate: 0.00083015]
	Learning Rate: 0.000830152
	LOSS [training: 0.2087526399319382 | validation: 0.24485369306743515]
	TIME [epoch: 9.8 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2129092657292937		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.2129092657292937 | validation: 0.2362060019105757]
	TIME [epoch: 9.79 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19676604746640688		[learning rate: 0.00082614]
	Learning Rate: 0.000826138
	LOSS [training: 0.19676604746640688 | validation: 0.20172604942814265]
	TIME [epoch: 9.77 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17282280907683417		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.17282280907683417 | validation: 0.18605978955608315]
	TIME [epoch: 9.78 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16579081156697675		[learning rate: 0.00082214]
	Learning Rate: 0.000822143
	LOSS [training: 0.16579081156697675 | validation: 0.20696691719845667]
	TIME [epoch: 9.8 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20303356906487888		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.20303356906487888 | validation: 0.24818197510912682]
	TIME [epoch: 9.79 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2263695164111768		[learning rate: 0.00081817]
	Learning Rate: 0.000818167
	LOSS [training: 0.2263695164111768 | validation: 0.2359247212985388]
	TIME [epoch: 9.78 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23141856712452952		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.23141856712452952 | validation: 0.23588999487834322]
	TIME [epoch: 9.8 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17589447038798484		[learning rate: 0.00081421]
	Learning Rate: 0.000814211
	LOSS [training: 0.17589447038798484 | validation: 0.1577526443180415]
	TIME [epoch: 9.79 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13806593559761154		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.13806593559761154 | validation: 0.17263755447471288]
	TIME [epoch: 9.78 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13694404401134036		[learning rate: 0.00081027]
	Learning Rate: 0.000810273
	LOSS [training: 0.13694404401134036 | validation: 0.17833460669717022]
	TIME [epoch: 9.78 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13498393632050484		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.13498393632050484 | validation: 0.18553985167019016]
	TIME [epoch: 9.81 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13933697731971564		[learning rate: 0.00080636]
	Learning Rate: 0.000806355
	LOSS [training: 0.13933697731971564 | validation: 0.1878230044252591]
	TIME [epoch: 9.78 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13309530336888215		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.13309530336888215 | validation: 0.1720035959472674]
	TIME [epoch: 9.79 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1486402726583635		[learning rate: 0.00080246]
	Learning Rate: 0.000802456
	LOSS [training: 0.1486402726583635 | validation: 0.1742147347200455]
	TIME [epoch: 9.79 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14621954540832213		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.14621954540832213 | validation: 0.18376788400144833]
	TIME [epoch: 9.8 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14243132157084681		[learning rate: 0.00079858]
	Learning Rate: 0.000798575
	LOSS [training: 0.14243132157084681 | validation: 0.17947500990154666]
	TIME [epoch: 9.78 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14237686809106892		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.14237686809106892 | validation: 0.17643003353478962]
	TIME [epoch: 9.79 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15443204677689085		[learning rate: 0.00079471]
	Learning Rate: 0.000794713
	LOSS [training: 0.15443204677689085 | validation: 0.20494223894805083]
	TIME [epoch: 9.8 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2102218821823158		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.2102218821823158 | validation: 0.2082667822139108]
	TIME [epoch: 9.78 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16102285145497414		[learning rate: 0.00079087]
	Learning Rate: 0.00079087
	LOSS [training: 0.16102285145497414 | validation: 0.18164154248561354]
	TIME [epoch: 9.78 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1530140609777779		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.1530140609777779 | validation: 0.21105440269707287]
	TIME [epoch: 9.79 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.156547673159239		[learning rate: 0.00078705]
	Learning Rate: 0.000787046
	LOSS [training: 0.156547673159239 | validation: 0.21525203197227108]
	TIME [epoch: 9.81 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16283967734048338		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.16283967734048338 | validation: 0.2081413723009518]
	TIME [epoch: 9.79 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14817259975475397		[learning rate: 0.00078324]
	Learning Rate: 0.00078324
	LOSS [training: 0.14817259975475397 | validation: 0.19685684123408956]
	TIME [epoch: 9.79 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14851111038244075		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.14851111038244075 | validation: 0.19126261348033488]
	TIME [epoch: 9.8 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17499257618476277		[learning rate: 0.00077945]
	Learning Rate: 0.000779452
	LOSS [training: 0.17499257618476277 | validation: 0.26262909137053675]
	TIME [epoch: 9.79 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1792155338312244		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.1792155338312244 | validation: 0.2136858552471636]
	TIME [epoch: 9.78 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17958399672928707		[learning rate: 0.00077568]
	Learning Rate: 0.000775683
	LOSS [training: 0.17958399672928707 | validation: 0.25840621601618535]
	TIME [epoch: 9.78 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18132593147234558		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.18132593147234558 | validation: 0.20856800544430598]
	TIME [epoch: 9.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18814997047860316		[learning rate: 0.00077193]
	Learning Rate: 0.000771932
	LOSS [training: 0.18814997047860316 | validation: 0.21582090976243273]
	TIME [epoch: 9.78 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18541923535125074		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.18541923535125074 | validation: 0.18915353251758718]
	TIME [epoch: 9.78 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16759418650509983		[learning rate: 0.0007682]
	Learning Rate: 0.000768199
	LOSS [training: 0.16759418650509983 | validation: 0.19997736661412305]
	TIME [epoch: 9.79 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13655236253599812		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.13655236253599812 | validation: 0.1613484743927181]
	TIME [epoch: 9.79 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14509291643220615		[learning rate: 0.00076448]
	Learning Rate: 0.000764484
	LOSS [training: 0.14509291643220615 | validation: 0.20478110655438425]
	TIME [epoch: 9.78 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14219082217587703		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.14219082217587703 | validation: 0.15051994533345267]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1162.pth
	Model improved!!!
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1466560966551047		[learning rate: 0.00076079]
	Learning Rate: 0.000760787
	LOSS [training: 0.1466560966551047 | validation: 0.1678081050240686]
	TIME [epoch: 9.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13689618554859448		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.13689618554859448 | validation: 0.1915533208949713]
	TIME [epoch: 9.78 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1322127027260755		[learning rate: 0.00075711]
	Learning Rate: 0.000757108
	LOSS [training: 0.1322127027260755 | validation: 0.16687799417499768]
	TIME [epoch: 9.77 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13071013378660912		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.13071013378660912 | validation: 0.1924847177069711]
	TIME [epoch: 9.79 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15098874619315422		[learning rate: 0.00075345]
	Learning Rate: 0.000753447
	LOSS [training: 0.15098874619315422 | validation: 0.18943900358307914]
	TIME [epoch: 9.78 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1492906831947064		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.1492906831947064 | validation: 0.19081469749775157]
	TIME [epoch: 9.78 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15431582516345763		[learning rate: 0.0007498]
	Learning Rate: 0.000749803
	LOSS [training: 0.15431582516345763 | validation: 0.17256064929673615]
	TIME [epoch: 9.78 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16337580727497583		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.16337580727497583 | validation: 0.2098003149556184]
	TIME [epoch: 9.8 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15959478900926333		[learning rate: 0.00074618]
	Learning Rate: 0.000746177
	LOSS [training: 0.15959478900926333 | validation: 0.18749292187342229]
	TIME [epoch: 9.77 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16535960951953613		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.16535960951953613 | validation: 0.20056192265880995]
	TIME [epoch: 9.77 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16753085088722122		[learning rate: 0.00074257]
	Learning Rate: 0.000742569
	LOSS [training: 0.16753085088722122 | validation: 0.17588483277747874]
	TIME [epoch: 9.78 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1616030549101119		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.1616030549101119 | validation: 0.20663027937756354]
	TIME [epoch: 9.78 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16058262430193038		[learning rate: 0.00073898]
	Learning Rate: 0.000738978
	LOSS [training: 0.16058262430193038 | validation: 0.17218836636133505]
	TIME [epoch: 9.77 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16163066278484547		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.16163066278484547 | validation: 0.21736575461460242]
	TIME [epoch: 9.78 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16846528722798113		[learning rate: 0.0007354]
	Learning Rate: 0.000735405
	LOSS [training: 0.16846528722798113 | validation: 0.21373529437495464]
	TIME [epoch: 9.8 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19633247248582186		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.19633247248582186 | validation: 0.24471363776067065]
	TIME [epoch: 9.77 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1846768900787816		[learning rate: 0.00073185]
	Learning Rate: 0.000731848
	LOSS [training: 0.1846768900787816 | validation: 0.19046237429052856]
	TIME [epoch: 9.78 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1767641079059779		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.1767641079059779 | validation: 0.17967399801812334]
	TIME [epoch: 9.77 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15314245564175671		[learning rate: 0.00072831]
	Learning Rate: 0.000728309
	LOSS [training: 0.15314245564175671 | validation: 0.1837978805976477]
	TIME [epoch: 9.79 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15048316433361167		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.15048316433361167 | validation: 0.18385952192855423]
	TIME [epoch: 9.78 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17584917505092634		[learning rate: 0.00072479]
	Learning Rate: 0.000724787
	LOSS [training: 0.17584917505092634 | validation: 0.20386134851777635]
	TIME [epoch: 9.77 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17111819267750344		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.17111819267750344 | validation: 0.18333514313432508]
	TIME [epoch: 9.8 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16767343200594859		[learning rate: 0.00072128]
	Learning Rate: 0.000721282
	LOSS [training: 0.16767343200594859 | validation: 0.18627928565937588]
	TIME [epoch: 9.78 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16947156451695164		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.16947156451695164 | validation: 0.20079128325780168]
	TIME [epoch: 9.78 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16346268668815106		[learning rate: 0.00071779]
	Learning Rate: 0.000717794
	LOSS [training: 0.16346268668815106 | validation: 0.17692147977347705]
	TIME [epoch: 9.77 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515378209038138		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.1515378209038138 | validation: 0.19921536496423517]
	TIME [epoch: 9.8 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15072038432731022		[learning rate: 0.00071432]
	Learning Rate: 0.000714323
	LOSS [training: 0.15072038432731022 | validation: 0.19671390506609893]
	TIME [epoch: 9.78 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13551670851253528		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.13551670851253528 | validation: 0.17145294503314568]
	TIME [epoch: 9.78 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1438849340758684		[learning rate: 0.00071087]
	Learning Rate: 0.000710869
	LOSS [training: 0.1438849340758684 | validation: 0.18643237476248695]
	TIME [epoch: 9.79 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1427032757811168		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.1427032757811168 | validation: 0.17041133903917552]
	TIME [epoch: 9.78 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13435183393742273		[learning rate: 0.00070743]
	Learning Rate: 0.000707431
	LOSS [training: 0.13435183393742273 | validation: 0.18467289136822287]
	TIME [epoch: 9.77 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13630576849007556		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.13630576849007556 | validation: 0.18489892611958092]
	TIME [epoch: 9.77 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13498427837744412		[learning rate: 0.00070401]
	Learning Rate: 0.00070401
	LOSS [training: 0.13498427837744412 | validation: 0.19571645249830347]
	TIME [epoch: 9.81 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14173206662136215		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.14173206662136215 | validation: 0.19985738150719534]
	TIME [epoch: 9.77 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13798126872017386		[learning rate: 0.00070061]
	Learning Rate: 0.000700606
	LOSS [training: 0.13798126872017386 | validation: 0.168966066269264]
	TIME [epoch: 9.78 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1624608233267414		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.1624608233267414 | validation: 0.1898591261835565]
	TIME [epoch: 9.79 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14417436714753726		[learning rate: 0.00069722]
	Learning Rate: 0.000697218
	LOSS [training: 0.14417436714753726 | validation: 0.20379046327042452]
	TIME [epoch: 9.78 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16830171359683416		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.16830171359683416 | validation: 0.16245374639382135]
	TIME [epoch: 9.77 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12844603719666758		[learning rate: 0.00069385]
	Learning Rate: 0.000693846
	LOSS [training: 0.12844603719666758 | validation: 0.16993715335106319]
	TIME [epoch: 9.78 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13836106608793178		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.13836106608793178 | validation: 0.18812538925637495]
	TIME [epoch: 9.8 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13782860051944218		[learning rate: 0.00069049]
	Learning Rate: 0.000690491
	LOSS [training: 0.13782860051944218 | validation: 0.1734058103799525]
	TIME [epoch: 9.77 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1578416961154407		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.1578416961154407 | validation: 0.19699842724449987]
	TIME [epoch: 9.79 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14113311394056133		[learning rate: 0.00068715]
	Learning Rate: 0.000687152
	LOSS [training: 0.14113311394056133 | validation: 0.1668733148391895]
	TIME [epoch: 9.79 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1484439141565273		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.1484439141565273 | validation: 0.19283653543460497]
	TIME [epoch: 9.79 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1363266324040954		[learning rate: 0.00068383]
	Learning Rate: 0.000683829
	LOSS [training: 0.1363266324040954 | validation: 0.19420394310653868]
	TIME [epoch: 9.77 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1370458917854108		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.1370458917854108 | validation: 0.19301389157001533]
	TIME [epoch: 9.78 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13000588840055735		[learning rate: 0.00068052]
	Learning Rate: 0.000680522
	LOSS [training: 0.13000588840055735 | validation: 0.1744998564965678]
	TIME [epoch: 9.81 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12730114476542703		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.12730114476542703 | validation: 0.17307035254290243]
	TIME [epoch: 9.77 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13671821520894775		[learning rate: 0.00067723]
	Learning Rate: 0.000677231
	LOSS [training: 0.13671821520894775 | validation: 0.18568305161772183]
	TIME [epoch: 9.78 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13200058788884544		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.13200058788884544 | validation: 0.17521690877461182]
	TIME [epoch: 9.78 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14482216805742748		[learning rate: 0.00067396]
	Learning Rate: 0.000673956
	LOSS [training: 0.14482216805742748 | validation: 0.2048162499015072]
	TIME [epoch: 9.8 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12993324262647843		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.12993324262647843 | validation: 0.18850133888242454]
	TIME [epoch: 9.77 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13588188910247825		[learning rate: 0.0006707]
	Learning Rate: 0.000670697
	LOSS [training: 0.13588188910247825 | validation: 0.18827056844943102]
	TIME [epoch: 9.77 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.165549348834482		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.165549348834482 | validation: 0.19828204697915383]
	TIME [epoch: 9.8 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13734450425483047		[learning rate: 0.00066745]
	Learning Rate: 0.000667454
	LOSS [training: 0.13734450425483047 | validation: 0.16725253807780704]
	TIME [epoch: 9.79 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14030908040656512		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.14030908040656512 | validation: 0.1950254763490011]
	TIME [epoch: 9.79 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1384285316821905		[learning rate: 0.00066423]
	Learning Rate: 0.000664226
	LOSS [training: 0.1384285316821905 | validation: 0.15943835766034328]
	TIME [epoch: 9.79 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13197890478027038		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.13197890478027038 | validation: 0.15131421467247255]
	TIME [epoch: 9.82 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12350819787348748		[learning rate: 0.00066101]
	Learning Rate: 0.000661014
	LOSS [training: 0.12350819787348748 | validation: 0.17318831359642992]
	TIME [epoch: 9.78 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1270624211085841		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.1270624211085841 | validation: 0.21096696770766252]
	TIME [epoch: 9.79 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1391722500593792		[learning rate: 0.00065782]
	Learning Rate: 0.000657817
	LOSS [training: 0.1391722500593792 | validation: 0.20744141380314965]
	TIME [epoch: 9.8 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1266835738917328		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.1266835738917328 | validation: 0.1935088475296418]
	TIME [epoch: 9.78 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1360238140986306		[learning rate: 0.00065464]
	Learning Rate: 0.000654636
	LOSS [training: 0.1360238140986306 | validation: 0.20483951407551806]
	TIME [epoch: 9.78 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14992200082864587		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.14992200082864587 | validation: 0.1774557311905584]
	TIME [epoch: 9.78 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13160883794089198		[learning rate: 0.00065147]
	Learning Rate: 0.000651471
	LOSS [training: 0.13160883794089198 | validation: 0.1789934174957244]
	TIME [epoch: 9.8 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1438509133561814		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.1438509133561814 | validation: 0.18447153326040894]
	TIME [epoch: 9.78 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1254452501530413		[learning rate: 0.00064832]
	Learning Rate: 0.00064832
	LOSS [training: 0.1254452501530413 | validation: 0.15949633550755513]
	TIME [epoch: 9.78 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15284541670694152		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.15284541670694152 | validation: 0.18945544537345274]
	TIME [epoch: 9.79 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1577192665413151		[learning rate: 0.00064519]
	Learning Rate: 0.000645185
	LOSS [training: 0.1577192665413151 | validation: 0.21603063258840657]
	TIME [epoch: 9.79 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14526572530268556		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.14526572530268556 | validation: 0.19476712428575155]
	TIME [epoch: 9.79 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1398098951163548		[learning rate: 0.00064206]
	Learning Rate: 0.000642065
	LOSS [training: 0.1398098951163548 | validation: 0.19321545568733137]
	TIME [epoch: 9.78 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15730568533082198		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.15730568533082198 | validation: 0.21669515744250717]
	TIME [epoch: 9.81 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14628152607473882		[learning rate: 0.00063896]
	Learning Rate: 0.00063896
	LOSS [training: 0.14628152607473882 | validation: 0.19556055388785482]
	TIME [epoch: 9.78 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16355314800695628		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.16355314800695628 | validation: 0.21038546103558894]
	TIME [epoch: 9.79 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1516245249386892		[learning rate: 0.00063587]
	Learning Rate: 0.00063587
	LOSS [training: 0.1516245249386892 | validation: 0.18304329409191425]
	TIME [epoch: 9.78 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14530579376160313		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.14530579376160313 | validation: 0.1658924861466017]
	TIME [epoch: 9.79 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13019894619237915		[learning rate: 0.0006328]
	Learning Rate: 0.000632795
	LOSS [training: 0.13019894619237915 | validation: 0.17512555630295196]
	TIME [epoch: 9.77 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1512317008308733		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.1512317008308733 | validation: 0.19651373097031768]
	TIME [epoch: 9.78 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1559585102848191		[learning rate: 0.00062974]
	Learning Rate: 0.000629735
	LOSS [training: 0.1559585102848191 | validation: 0.20744566180224552]
	TIME [epoch: 9.8 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1841332536055439		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.1841332536055439 | validation: 0.2421950670221905]
	TIME [epoch: 9.78 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16196637424700583		[learning rate: 0.00062669]
	Learning Rate: 0.00062669
	LOSS [training: 0.16196637424700583 | validation: 0.16709521516244405]
	TIME [epoch: 9.77 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12559996917379174		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.12559996917379174 | validation: 0.17165625033582793]
	TIME [epoch: 9.77 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.128817731705161		[learning rate: 0.00062366]
	Learning Rate: 0.000623659
	LOSS [training: 0.128817731705161 | validation: 0.16801566766309978]
	TIME [epoch: 9.79 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11907540619923593		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.11907540619923593 | validation: 0.15760566937956833]
	TIME [epoch: 9.77 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12820799154108026		[learning rate: 0.00062064]
	Learning Rate: 0.000620643
	LOSS [training: 0.12820799154108026 | validation: 0.20609938387778737]
	TIME [epoch: 9.78 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14306826697409755		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.14306826697409755 | validation: 0.17154110261200128]
	TIME [epoch: 9.79 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14346238175336204		[learning rate: 0.00061764]
	Learning Rate: 0.000617642
	LOSS [training: 0.14346238175336204 | validation: 0.17174867194286322]
	TIME [epoch: 9.78 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14125773826257873		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.14125773826257873 | validation: 0.1784576756981137]
	TIME [epoch: 9.77 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14447921020742083		[learning rate: 0.00061466]
	Learning Rate: 0.000614655
	LOSS [training: 0.14447921020742083 | validation: 0.19668550300158083]
	TIME [epoch: 9.78 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13862429332813656		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.13862429332813656 | validation: 0.168648786726459]
	TIME [epoch: 9.79 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342542459868679		[learning rate: 0.00061168]
	Learning Rate: 0.000611683
	LOSS [training: 0.1342542459868679 | validation: 0.1942568101340883]
	TIME [epoch: 9.77 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13693598089470083		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.13693598089470083 | validation: 0.1741837256378077]
	TIME [epoch: 9.77 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12573459698839673		[learning rate: 0.00060872]
	Learning Rate: 0.000608725
	LOSS [training: 0.12573459698839673 | validation: 0.18778578751801167]
	TIME [epoch: 9.8 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13568642975237472		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.13568642975237472 | validation: 0.20282179764727915]
	TIME [epoch: 9.77 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16947691094718806		[learning rate: 0.00060578]
	Learning Rate: 0.000605781
	LOSS [training: 0.16947691094718806 | validation: 0.20136941034937003]
	TIME [epoch: 9.78 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1426131204396322		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.1426131204396322 | validation: 0.1896270380008704]
	TIME [epoch: 9.78 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13726096389814585		[learning rate: 0.00060285]
	Learning Rate: 0.000602852
	LOSS [training: 0.13726096389814585 | validation: 0.176186702161423]
	TIME [epoch: 9.78 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13957527510374995		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.13957527510374995 | validation: 0.19118729406778912]
	TIME [epoch: 9.78 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1607822295478441		[learning rate: 0.00059994]
	Learning Rate: 0.000599936
	LOSS [training: 0.1607822295478441 | validation: 0.2076314919501536]
	TIME [epoch: 9.78 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19228557536820662		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.19228557536820662 | validation: 0.27663618771679843]
	TIME [epoch: 9.8 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25327225056403563		[learning rate: 0.00059704]
	Learning Rate: 0.000597035
	LOSS [training: 0.25327225056403563 | validation: 0.2586410031152359]
	TIME [epoch: 9.77 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21534498980855488		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.21534498980855488 | validation: 0.20600389038232172]
	TIME [epoch: 9.77 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18631708889690826		[learning rate: 0.00059415]
	Learning Rate: 0.000594148
	LOSS [training: 0.18631708889690826 | validation: 0.24247343043787556]
	TIME [epoch: 9.8 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20459841363151093		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.20459841363151093 | validation: 0.2527166326069385]
	TIME [epoch: 9.77 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18451864771269366		[learning rate: 0.00059128]
	Learning Rate: 0.000591275
	LOSS [training: 0.18451864771269366 | validation: 0.23710173682134233]
	TIME [epoch: 9.78 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18239886889397397		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.18239886889397397 | validation: 0.2552198140869158]
	TIME [epoch: 9.77 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20460181232727984		[learning rate: 0.00058842]
	Learning Rate: 0.000588416
	LOSS [training: 0.20460181232727984 | validation: 0.30366941226175675]
	TIME [epoch: 9.8 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23175554965622364		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.23175554965622364 | validation: 0.2511508745188446]
	TIME [epoch: 9.77 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18216325077790452		[learning rate: 0.00058557]
	Learning Rate: 0.00058557
	LOSS [training: 0.18216325077790452 | validation: 0.24249749380737115]
	TIME [epoch: 9.78 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18476479468782156		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.18476479468782156 | validation: 0.24993856903350023]
	TIME [epoch: 9.79 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19608142729632252		[learning rate: 0.00058274]
	Learning Rate: 0.000582738
	LOSS [training: 0.19608142729632252 | validation: 0.2365369986332211]
	TIME [epoch: 9.77 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.167455804503516		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.167455804503516 | validation: 0.2167396501211132]
	TIME [epoch: 9.77 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15926539979120366		[learning rate: 0.00057992]
	Learning Rate: 0.00057992
	LOSS [training: 0.15926539979120366 | validation: 0.21471799587943455]
	TIME [epoch: 9.78 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15673272540074326		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.15673272540074326 | validation: 0.1825309786374981]
	TIME [epoch: 9.78 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14157604397327045		[learning rate: 0.00057712]
	Learning Rate: 0.000577116
	LOSS [training: 0.14157604397327045 | validation: 0.1652144150850058]
	TIME [epoch: 9.78 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15192307972617808		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.15192307972617808 | validation: 0.21728663263142917]
	TIME [epoch: 9.77 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1822349816871725		[learning rate: 0.00057433]
	Learning Rate: 0.000574325
	LOSS [training: 0.1822349816871725 | validation: 0.20288145892849674]
	TIME [epoch: 9.8 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14483131741333005		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.14483131741333005 | validation: 0.22167265042956352]
	TIME [epoch: 9.78 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14863656660033983		[learning rate: 0.00057155]
	Learning Rate: 0.000571548
	LOSS [training: 0.14863656660033983 | validation: 0.1956530123249199]
	TIME [epoch: 9.78 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15419751270414225		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.15419751270414225 | validation: 0.15728827981614601]
	TIME [epoch: 9.79 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1350515631859473		[learning rate: 0.00056878]
	Learning Rate: 0.000568784
	LOSS [training: 0.1350515631859473 | validation: 0.1835185563854066]
	TIME [epoch: 9.79 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13334210349222192		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.13334210349222192 | validation: 0.20464162612403236]
	TIME [epoch: 9.77 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15534831277570993		[learning rate: 0.00056603]
	Learning Rate: 0.000566033
	LOSS [training: 0.15534831277570993 | validation: 0.21223447207516621]
	TIME [epoch: 9.78 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14954599157618242		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.14954599157618242 | validation: 0.19665128488508402]
	TIME [epoch: 9.78 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14322597168563195		[learning rate: 0.0005633]
	Learning Rate: 0.000563296
	LOSS [training: 0.14322597168563195 | validation: 0.22643161901741907]
	TIME [epoch: 9.78 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1544359927644008		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.1544359927644008 | validation: 0.22240044065205142]
	TIME [epoch: 9.77 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15858880042386053		[learning rate: 0.00056057]
	Learning Rate: 0.000560572
	LOSS [training: 0.15858880042386053 | validation: 0.18128231987171975]
	TIME [epoch: 9.81 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15784530911611303		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.15784530911611303 | validation: 0.15811643217620763]
	TIME [epoch: 9.78 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13349260873095697		[learning rate: 0.00055786]
	Learning Rate: 0.000557861
	LOSS [training: 0.13349260873095697 | validation: 0.17023879652464807]
	TIME [epoch: 9.78 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16975762589721982		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.16975762589721982 | validation: 0.2361933185358344]
	TIME [epoch: 9.79 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22112153536987914		[learning rate: 0.00055516]
	Learning Rate: 0.000555164
	LOSS [training: 0.22112153536987914 | validation: 0.22325308146498868]
	TIME [epoch: 9.79 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2018220029087324		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.2018220029087324 | validation: 0.23099850719911152]
	TIME [epoch: 9.77 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19330225631399164		[learning rate: 0.00055248]
	Learning Rate: 0.000552479
	LOSS [training: 0.19330225631399164 | validation: 0.22136672383282366]
	TIME [epoch: 9.79 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16349620250239666		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.16349620250239666 | validation: 0.16853082251097057]
	TIME [epoch: 9.79 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16067325450573414		[learning rate: 0.00054981]
	Learning Rate: 0.000549807
	LOSS [training: 0.16067325450573414 | validation: 0.21780655411463115]
	TIME [epoch: 9.78 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1619132288192025		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.1619132288192025 | validation: 0.1529939657923781]
	TIME [epoch: 9.78 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15951783007607373		[learning rate: 0.00054715]
	Learning Rate: 0.000547149
	LOSS [training: 0.15951783007607373 | validation: 0.23972123522469646]
	TIME [epoch: 9.8 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15164927524460053		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.15164927524460053 | validation: 0.17950372776395518]
	TIME [epoch: 9.78 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.134861777466299		[learning rate: 0.0005445]
	Learning Rate: 0.000544503
	LOSS [training: 0.134861777466299 | validation: 0.16374613354281764]
	TIME [epoch: 9.78 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1452549854133058		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.1452549854133058 | validation: 0.20061338720965352]
	TIME [epoch: 9.79 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14735005298473966		[learning rate: 0.00054187]
	Learning Rate: 0.000541869
	LOSS [training: 0.14735005298473966 | validation: 0.16147691732986708]
	TIME [epoch: 9.79 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1401309372667182		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.1401309372667182 | validation: 0.17866184983823089]
	TIME [epoch: 9.77 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13571712089980886		[learning rate: 0.00053925]
	Learning Rate: 0.000539249
	LOSS [training: 0.13571712089980886 | validation: 0.16507352447061746]
	TIME [epoch: 9.79 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12284352250845128		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.12284352250845128 | validation: 0.17765972803223265]
	TIME [epoch: 9.8 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12390108630392563		[learning rate: 0.00053664]
	Learning Rate: 0.000536641
	LOSS [training: 0.12390108630392563 | validation: 0.16561384797758813]
	TIME [epoch: 9.79 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12567325549910383		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.12567325549910383 | validation: 0.15291492055171602]
	TIME [epoch: 9.77 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13275439357942212		[learning rate: 0.00053405]
	Learning Rate: 0.000534046
	LOSS [training: 0.13275439357942212 | validation: 0.16192252068352234]
	TIME [epoch: 9.8 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13077141614618637		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.13077141614618637 | validation: 0.15830584159220704]
	TIME [epoch: 9.78 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1326846418395182		[learning rate: 0.00053146]
	Learning Rate: 0.000531464
	LOSS [training: 0.1326846418395182 | validation: 0.15793415651592546]
	TIME [epoch: 9.78 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1442604321197608		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.1442604321197608 | validation: 0.1718850873630614]
	TIME [epoch: 9.78 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13742216649845368		[learning rate: 0.00052889]
	Learning Rate: 0.000528894
	LOSS [training: 0.13742216649845368 | validation: 0.16960068927144317]
	TIME [epoch: 9.79 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13901950509838107		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.13901950509838107 | validation: 0.15128476763371235]
	TIME [epoch: 9.77 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12292237169417977		[learning rate: 0.00052634]
	Learning Rate: 0.000526336
	LOSS [training: 0.12292237169417977 | validation: 0.1544477198439032]
	TIME [epoch: 9.78 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11934757423949667		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.11934757423949667 | validation: 0.16825888787612356]
	TIME [epoch: 9.81 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15585105301661792		[learning rate: 0.00052379]
	Learning Rate: 0.000523791
	LOSS [training: 0.15585105301661792 | validation: 0.17849519906823516]
	TIME [epoch: 9.78 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1670458750021668		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.1670458750021668 | validation: 0.22406595382544756]
	TIME [epoch: 9.78 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1487093357387492		[learning rate: 0.00052126]
	Learning Rate: 0.000521258
	LOSS [training: 0.1487093357387492 | validation: 0.16371696535001476]
	TIME [epoch: 9.8 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13275779017329256		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.13275779017329256 | validation: 0.14881414588979153]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1320.pth
	Model improved!!!
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13199560534518578		[learning rate: 0.00051874]
	Learning Rate: 0.000518737
	LOSS [training: 0.13199560534518578 | validation: 0.1601993080443717]
	TIME [epoch: 9.77 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1268804982979307		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.1268804982979307 | validation: 0.1554648659147151]
	TIME [epoch: 9.78 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12471218093769221		[learning rate: 0.00051623]
	Learning Rate: 0.000516229
	LOSS [training: 0.12471218093769221 | validation: 0.17766927258384932]
	TIME [epoch: 9.79 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1461646387507217		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.1461646387507217 | validation: 0.18053778470488738]
	TIME [epoch: 9.77 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12929231255301488		[learning rate: 0.00051373]
	Learning Rate: 0.000513732
	LOSS [training: 0.12929231255301488 | validation: 0.19969327851071605]
	TIME [epoch: 9.78 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1515256760776347		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.1515256760776347 | validation: 0.19888794968146034]
	TIME [epoch: 9.8 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14831315243380766		[learning rate: 0.00051125]
	Learning Rate: 0.000511248
	LOSS [training: 0.14831315243380766 | validation: 0.18726743155793085]
	TIME [epoch: 9.78 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1656957439418863		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.1656957439418863 | validation: 0.20958659842451]
	TIME [epoch: 9.79 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20175247670683757		[learning rate: 0.00050878]
	Learning Rate: 0.000508776
	LOSS [training: 0.20175247670683757 | validation: 0.21655129408907026]
	TIME [epoch: 9.8 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21911106371290429		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.21911106371290429 | validation: 0.1980792729174045]
	TIME [epoch: 9.79 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19007398083203803		[learning rate: 0.00050632]
	Learning Rate: 0.000506315
	LOSS [training: 0.19007398083203803 | validation: 0.21447846051431518]
	TIME [epoch: 9.79 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21202476964477665		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.21202476964477665 | validation: 0.23977928025005205]
	TIME [epoch: 9.79 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23178383759954743		[learning rate: 0.00050387]
	Learning Rate: 0.000503867
	LOSS [training: 0.23178383759954743 | validation: 0.22702571683660652]
	TIME [epoch: 9.81 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1819769845740361		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.1819769845740361 | validation: 0.19426529182161767]
	TIME [epoch: 9.78 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17407100215709748		[learning rate: 0.00050143]
	Learning Rate: 0.00050143
	LOSS [training: 0.17407100215709748 | validation: 0.1725033021251227]
	TIME [epoch: 9.78 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16804720993760286		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.16804720993760286 | validation: 0.18896041060654173]
	TIME [epoch: 9.79 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15000509170551335		[learning rate: 0.00049901]
	Learning Rate: 0.000499005
	LOSS [training: 0.15000509170551335 | validation: 0.18288086964401026]
	TIME [epoch: 9.78 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16097739623649568		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.16097739623649568 | validation: 0.17147143107180274]
	TIME [epoch: 9.79 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13552100196875821		[learning rate: 0.00049659]
	Learning Rate: 0.000496592
	LOSS [training: 0.13552100196875821 | validation: 0.1592297796795708]
	TIME [epoch: 9.79 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13008686863488844		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.13008686863488844 | validation: 0.18212163696175224]
	TIME [epoch: 9.82 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13621583787398817		[learning rate: 0.00049419]
	Learning Rate: 0.000494191
	LOSS [training: 0.13621583787398817 | validation: 0.18750225708390988]
	TIME [epoch: 9.79 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15284206366732625		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.15284206366732625 | validation: 0.19318928029411175]
	TIME [epoch: 9.79 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15086872811806618		[learning rate: 0.0004918]
	Learning Rate: 0.000491801
	LOSS [training: 0.15086872811806618 | validation: 0.1902834664682068]
	TIME [epoch: 9.8 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1369113279366468		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.1369113279366468 | validation: 0.1791018273266569]
	TIME [epoch: 9.78 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14734565481814413		[learning rate: 0.00048942]
	Learning Rate: 0.000489423
	LOSS [training: 0.14734565481814413 | validation: 0.1980558945736019]
	TIME [epoch: 9.79 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13049702139127115		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.13049702139127115 | validation: 0.1455553871922053]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1346.pth
	Model improved!!!
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1293324067658503		[learning rate: 0.00048706]
	Learning Rate: 0.000487056
	LOSS [training: 0.1293324067658503 | validation: 0.1702587945566382]
	TIME [epoch: 9.81 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1327944368025123		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.1327944368025123 | validation: 0.1640273599256184]
	TIME [epoch: 9.8 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14786538748899775		[learning rate: 0.0004847]
	Learning Rate: 0.000484701
	LOSS [training: 0.14786538748899775 | validation: 0.17867588891900776]
	TIME [epoch: 9.78 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16239327096550044		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.16239327096550044 | validation: 0.1803930326805635]
	TIME [epoch: 9.81 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.156336151603209		[learning rate: 0.00048236]
	Learning Rate: 0.000482357
	LOSS [training: 0.156336151603209 | validation: 0.17656134482189956]
	TIME [epoch: 9.8 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14717725056814052		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.14717725056814052 | validation: 0.18487384222632702]
	TIME [epoch: 9.79 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13710757575358734		[learning rate: 0.00048002]
	Learning Rate: 0.000480024
	LOSS [training: 0.13710757575358734 | validation: 0.17471808642552136]
	TIME [epoch: 9.8 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1244986307228196		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.1244986307228196 | validation: 0.1803435115434666]
	TIME [epoch: 9.79 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13728328737195375		[learning rate: 0.0004777]
	Learning Rate: 0.000477703
	LOSS [training: 0.13728328737195375 | validation: 0.2098813932703672]
	TIME [epoch: 9.79 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14061377548506265		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.14061377548506265 | validation: 0.17450654369249496]
	TIME [epoch: 9.8 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12009936457932321		[learning rate: 0.00047539]
	Learning Rate: 0.000475393
	LOSS [training: 0.12009936457932321 | validation: 0.16306760013094151]
	TIME [epoch: 9.8 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12460083926580472		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.12460083926580472 | validation: 0.1798788305358356]
	TIME [epoch: 9.77 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12057560505089557		[learning rate: 0.00047309]
	Learning Rate: 0.000473094
	LOSS [training: 0.12057560505089557 | validation: 0.15922628787619644]
	TIME [epoch: 9.79 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11955131334232547		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.11955131334232547 | validation: 0.171320929084666]
	TIME [epoch: 9.8 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12622508505150512		[learning rate: 0.00047081]
	Learning Rate: 0.000470806
	LOSS [training: 0.12622508505150512 | validation: 0.15354428591321584]
	TIME [epoch: 9.79 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12503377848344321		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.12503377848344321 | validation: 0.14370427731600277]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1362.pth
	Model improved!!!
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1133089510026419		[learning rate: 0.00046853]
	Learning Rate: 0.000468529
	LOSS [training: 0.1133089510026419 | validation: 0.15171049522143817]
	TIME [epoch: 9.81 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11597133243258735		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.11597133243258735 | validation: 0.16582324292767137]
	TIME [epoch: 9.78 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11893824168612648		[learning rate: 0.00046626]
	Learning Rate: 0.000466264
	LOSS [training: 0.11893824168612648 | validation: 0.1478438735367532]
	TIME [epoch: 9.78 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11283337227437633		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.11283337227437633 | validation: 0.1460394308014811]
	TIME [epoch: 9.79 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11071143947150053		[learning rate: 0.00046401]
	Learning Rate: 0.000464009
	LOSS [training: 0.11071143947150053 | validation: 0.16307375562448315]
	TIME [epoch: 9.79 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1067689764334677		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.1067689764334677 | validation: 0.169413089100755]
	TIME [epoch: 9.79 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10818335766112522		[learning rate: 0.00046177]
	Learning Rate: 0.000461765
	LOSS [training: 0.10818335766112522 | validation: 0.13416230855853908]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1369.pth
	Model improved!!!
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10713630696184251		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.10713630696184251 | validation: 0.15213343269528853]
	TIME [epoch: 9.82 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11081967378730544		[learning rate: 0.00045953]
	Learning Rate: 0.000459532
	LOSS [training: 0.11081967378730544 | validation: 0.15954873559619556]
	TIME [epoch: 9.78 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11470859069635886		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.11470859069635886 | validation: 0.12391164299964047]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1372.pth
	Model improved!!!
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10294106601579997		[learning rate: 0.00045731]
	Learning Rate: 0.00045731
	LOSS [training: 0.10294106601579997 | validation: 0.1580668491481123]
	TIME [epoch: 9.81 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10718367873248495		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.10718367873248495 | validation: 0.16088369554088452]
	TIME [epoch: 9.77 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11076417012670223		[learning rate: 0.0004551]
	Learning Rate: 0.000455098
	LOSS [training: 0.11076417012670223 | validation: 0.135214731420571]
	TIME [epoch: 9.79 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11387055540737916		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.11387055540737916 | validation: 0.15117664198203812]
	TIME [epoch: 9.79 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11536091068568055		[learning rate: 0.0004529]
	Learning Rate: 0.000452898
	LOSS [training: 0.11536091068568055 | validation: 0.18859243927455344]
	TIME [epoch: 9.8 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12396524068499426		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.12396524068499426 | validation: 0.15103975677237266]
	TIME [epoch: 9.79 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11961836939732295		[learning rate: 0.00045071]
	Learning Rate: 0.000450708
	LOSS [training: 0.11961836939732295 | validation: 0.16505405500134523]
	TIME [epoch: 9.79 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.125565808820985		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.125565808820985 | validation: 0.1546264169133624]
	TIME [epoch: 9.81 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1184082623854769		[learning rate: 0.00044853]
	Learning Rate: 0.000448528
	LOSS [training: 0.1184082623854769 | validation: 0.1669226778852908]
	TIME [epoch: 9.79 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12461268830066767		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.12461268830066767 | validation: 0.15537185855056945]
	TIME [epoch: 9.79 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11789715511232371		[learning rate: 0.00044636]
	Learning Rate: 0.000446359
	LOSS [training: 0.11789715511232371 | validation: 0.16608366498147034]
	TIME [epoch: 9.8 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11230522685002083		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.11230522685002083 | validation: 0.1491583134770029]
	TIME [epoch: 9.77 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12129239746014298		[learning rate: 0.0004442]
	Learning Rate: 0.0004442
	LOSS [training: 0.12129239746014298 | validation: 0.1694482479698078]
	TIME [epoch: 9.78 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12676492168107992		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.12676492168107992 | validation: 0.15825004669417456]
	TIME [epoch: 9.79 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13562609670529152		[learning rate: 0.00044205]
	Learning Rate: 0.000442052
	LOSS [training: 0.13562609670529152 | validation: 0.18634491348977178]
	TIME [epoch: 9.81 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12437271550870588		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.12437271550870588 | validation: 0.13048900431629026]
	TIME [epoch: 9.78 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11751532727415141		[learning rate: 0.00043991]
	Learning Rate: 0.000439915
	LOSS [training: 0.11751532727415141 | validation: 0.17810537981471675]
	TIME [epoch: 9.78 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12888368374051556		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.12888368374051556 | validation: 0.17852325955764062]
	TIME [epoch: 9.79 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12654357598918473		[learning rate: 0.00043779]
	Learning Rate: 0.000437787
	LOSS [training: 0.12654357598918473 | validation: 0.15083811836340122]
	TIME [epoch: 9.77 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12515061357186663		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.12515061357186663 | validation: 0.14808802353952213]
	TIME [epoch: 9.78 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11656943032819331		[learning rate: 0.00043567]
	Learning Rate: 0.00043567
	LOSS [training: 0.11656943032819331 | validation: 0.16363149252662626]
	TIME [epoch: 9.78 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11990558700828365		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.11990558700828365 | validation: 0.14790978880704944]
	TIME [epoch: 9.78 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12360091851570174		[learning rate: 0.00043356]
	Learning Rate: 0.000433563
	LOSS [training: 0.12360091851570174 | validation: 0.14541406852885336]
	TIME [epoch: 9.79 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12637540862139		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.12637540862139 | validation: 0.18518494224751944]
	TIME [epoch: 9.77 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13932321513683765		[learning rate: 0.00043147]
	Learning Rate: 0.000431467
	LOSS [training: 0.13932321513683765 | validation: 0.1819152821433803]
	TIME [epoch: 9.81 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12270235290352305		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.12270235290352305 | validation: 0.18149663668654265]
	TIME [epoch: 9.79 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12346922937176326		[learning rate: 0.00042938]
	Learning Rate: 0.00042938
	LOSS [training: 0.12346922937176326 | validation: 0.18821080654499622]
	TIME [epoch: 9.79 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12693977169729917		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.12693977169729917 | validation: 0.19031999968009022]
	TIME [epoch: 9.8 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13809444829417006		[learning rate: 0.0004273]
	Learning Rate: 0.000427304
	LOSS [training: 0.13809444829417006 | validation: 0.15916195339816766]
	TIME [epoch: 9.78 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12265008419473626		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.12265008419473626 | validation: 0.15717300253190955]
	TIME [epoch: 9.78 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1158676549443092		[learning rate: 0.00042524]
	Learning Rate: 0.000425238
	LOSS [training: 0.1158676549443092 | validation: 0.13111819602278377]
	TIME [epoch: 9.78 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10758706710069461		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.10758706710069461 | validation: 0.15326260325008356]
	TIME [epoch: 9.79 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10674234378993837		[learning rate: 0.00042318]
	Learning Rate: 0.000423181
	LOSS [training: 0.10674234378993837 | validation: 0.15332827963998774]
	TIME [epoch: 9.79 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1170212992286713		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.1170212992286713 | validation: 0.17921061742797484]
	TIME [epoch: 9.78 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10703087762655175		[learning rate: 0.00042113]
	Learning Rate: 0.000421135
	LOSS [training: 0.10703087762655175 | validation: 0.13148048873983037]
	TIME [epoch: 9.81 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10205134559916336		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.10205134559916336 | validation: 0.15886155514861064]
	TIME [epoch: 9.78 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1081912474857482		[learning rate: 0.0004191]
	Learning Rate: 0.000419098
	LOSS [training: 0.1081912474857482 | validation: 0.12484163244171413]
	TIME [epoch: 9.78 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11435197967756676		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.11435197967756676 | validation: 0.154217992935088]
	TIME [epoch: 9.8 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1047992328398688		[learning rate: 0.00041707]
	Learning Rate: 0.000417072
	LOSS [training: 0.1047992328398688 | validation: 0.13832321933365918]
	TIME [epoch: 9.78 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10851485755247951		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.10851485755247951 | validation: 0.1493930945995525]
	TIME [epoch: 9.78 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10616256024478357		[learning rate: 0.00041505]
	Learning Rate: 0.000415055
	LOSS [training: 0.10616256024478357 | validation: 0.15708709343446445]
	TIME [epoch: 9.79 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11319054799905151		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.11319054799905151 | validation: 0.1666257963290411]
	TIME [epoch: 9.79 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11260656159677059		[learning rate: 0.00041305]
	Learning Rate: 0.000413048
	LOSS [training: 0.11260656159677059 | validation: 0.1492092917308531]
	TIME [epoch: 9.78 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10675232510640391		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.10675232510640391 | validation: 0.1517691898535463]
	TIME [epoch: 9.78 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11256298816126682		[learning rate: 0.00041105]
	Learning Rate: 0.00041105
	LOSS [training: 0.11256298816126682 | validation: 0.170695188959957]
	TIME [epoch: 9.81 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11700145878686277		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.11700145878686277 | validation: 0.14478317061666052]
	TIME [epoch: 9.78 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11983498367956533		[learning rate: 0.00040906]
	Learning Rate: 0.000409062
	LOSS [training: 0.11983498367956533 | validation: 0.1456481809515225]
	TIME [epoch: 9.79 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11033752847071938		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.11033752847071938 | validation: 0.1580691092829615]
	TIME [epoch: 9.78 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12009720830025428		[learning rate: 0.00040708]
	Learning Rate: 0.000407084
	LOSS [training: 0.12009720830025428 | validation: 0.1680784122462656]
	TIME [epoch: 9.8 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13977591534112777		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.13977591534112777 | validation: 0.18742042512381552]
	TIME [epoch: 9.78 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1611329118117416		[learning rate: 0.00040512]
	Learning Rate: 0.000405116
	LOSS [training: 0.1611329118117416 | validation: 0.16274081672829885]
	TIME [epoch: 9.79 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1475684782973		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.1475684782973 | validation: 0.17230699780408898]
	TIME [epoch: 9.8 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12956093534928423		[learning rate: 0.00040316]
	Learning Rate: 0.000403157
	LOSS [training: 0.12956093534928423 | validation: 0.17644542462369722]
	TIME [epoch: 9.79 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12018878480568969		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.12018878480568969 | validation: 0.12987711810626443]
	TIME [epoch: 9.79 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10881926611616688		[learning rate: 0.00040121]
	Learning Rate: 0.000401207
	LOSS [training: 0.10881926611616688 | validation: 0.14077402905244119]
	TIME [epoch: 9.79 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10490274787887381		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.10490274787887381 | validation: 0.14198282101626764]
	TIME [epoch: 9.78 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11278725165170174		[learning rate: 0.00039927]
	Learning Rate: 0.000399267
	LOSS [training: 0.11278725165170174 | validation: 0.1752649323913621]
	TIME [epoch: 9.79 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11231245067028092		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.11231245067028092 | validation: 0.17848398951699154]
	TIME [epoch: 9.79 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1047720720321715		[learning rate: 0.00039734]
	Learning Rate: 0.000397336
	LOSS [training: 0.1047720720321715 | validation: 0.1597589940120509]
	TIME [epoch: 9.81 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10758613493966966		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.10758613493966966 | validation: 0.17078437164034]
	TIME [epoch: 9.79 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11157696260709934		[learning rate: 0.00039541]
	Learning Rate: 0.000395415
	LOSS [training: 0.11157696260709934 | validation: 0.16350686230371403]
	TIME [epoch: 9.78 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10752653152450602		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.10752653152450602 | validation: 0.1471114136463633]
	TIME [epoch: 9.81 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11194274732110891		[learning rate: 0.0003935]
	Learning Rate: 0.000393502
	LOSS [training: 0.11194274732110891 | validation: 0.13385071466605572]
	TIME [epoch: 9.78 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11750566658601311		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.11750566658601311 | validation: 0.15885287743610432]
	TIME [epoch: 9.78 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11838920617158184		[learning rate: 0.0003916]
	Learning Rate: 0.000391599
	LOSS [training: 0.11838920617158184 | validation: 0.14697663799085794]
	TIME [epoch: 9.79 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10615415532598209		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.10615415532598209 | validation: 0.15418714621633686]
	TIME [epoch: 9.79 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10125311143063012		[learning rate: 0.00038971]
	Learning Rate: 0.000389706
	LOSS [training: 0.10125311143063012 | validation: 0.1663500175772248]
	TIME [epoch: 9.78 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10594161517419794		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.10594161517419794 | validation: 0.1355255209989718]
	TIME [epoch: 9.78 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10599747571373715		[learning rate: 0.00038782]
	Learning Rate: 0.000387821
	LOSS [training: 0.10599747571373715 | validation: 0.14699744840106221]
	TIME [epoch: 9.81 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10688874584320367		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.10688874584320367 | validation: 0.13077750482565204]
	TIME [epoch: 9.79 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10761430537845493		[learning rate: 0.00038595]
	Learning Rate: 0.000385946
	LOSS [training: 0.10761430537845493 | validation: 0.15251628046973995]
	TIME [epoch: 9.79 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11631727494786492		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.11631727494786492 | validation: 0.13077876928732926]
	TIME [epoch: 9.8 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10853960178276552		[learning rate: 0.00038408]
	Learning Rate: 0.000384079
	LOSS [training: 0.10853960178276552 | validation: 0.1272690448126632]
	TIME [epoch: 9.78 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10412107143326728		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.10412107143326728 | validation: 0.14267729884383434]
	TIME [epoch: 9.79 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09744865484264112		[learning rate: 0.00038222]
	Learning Rate: 0.000382222
	LOSS [training: 0.09744865484264112 | validation: 0.1466922962930512]
	TIME [epoch: 9.79 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09775418970087729		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.09775418970087729 | validation: 0.16224238798214052]
	TIME [epoch: 9.79 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11517863448019598		[learning rate: 0.00038037]
	Learning Rate: 0.000380374
	LOSS [training: 0.11517863448019598 | validation: 0.16758519601046953]
	TIME [epoch: 9.8 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11393699737716292		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.11393699737716292 | validation: 0.15263402400751674]
	TIME [epoch: 9.79 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10479476435818072		[learning rate: 0.00037853]
	Learning Rate: 0.000378534
	LOSS [training: 0.10479476435818072 | validation: 0.14187076672973395]
	TIME [epoch: 9.8 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10623309018011722		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.10623309018011722 | validation: 0.14311245614133727]
	TIME [epoch: 9.78 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10830451408242456		[learning rate: 0.0003767]
	Learning Rate: 0.000376704
	LOSS [training: 0.10830451408242456 | validation: 0.14992663053702807]
	TIME [epoch: 9.79 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10374427924638574		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.10374427924638574 | validation: 0.137625250247383]
	TIME [epoch: 9.8 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10798912432487309		[learning rate: 0.00037488]
	Learning Rate: 0.000374882
	LOSS [training: 0.10798912432487309 | validation: 0.15034953861699457]
	TIME [epoch: 9.79 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1166680078871372		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.1166680078871372 | validation: 0.17874397816870904]
	TIME [epoch: 9.79 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1260341968344		[learning rate: 0.00037307]
	Learning Rate: 0.000373069
	LOSS [training: 0.1260341968344 | validation: 0.1512110864472808]
	TIME [epoch: 9.78 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11251083091378158		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.11251083091378158 | validation: 0.17620478991738175]
	TIME [epoch: 9.81 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12218387381967166		[learning rate: 0.00037127]
	Learning Rate: 0.000371265
	LOSS [training: 0.12218387381967166 | validation: 0.17134613424144232]
	TIME [epoch: 9.78 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10933857466509407		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.10933857466509407 | validation: 0.16264748396380938]
	TIME [epoch: 9.78 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12852170535555638		[learning rate: 0.00036947]
	Learning Rate: 0.00036947
	LOSS [training: 0.12852170535555638 | validation: 0.1827908121213467]
	TIME [epoch: 9.79 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14141533310475846		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.14141533310475846 | validation: 0.18197841855201305]
	TIME [epoch: 9.78 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14635547693671963		[learning rate: 0.00036768]
	Learning Rate: 0.000367683
	LOSS [training: 0.14635547693671963 | validation: 0.14138637872593635]
	TIME [epoch: 9.77 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12756696619840685		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.12756696619840685 | validation: 0.14635570577619667]
	TIME [epoch: 9.81 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12099280198274014		[learning rate: 0.00036591]
	Learning Rate: 0.000365905
	LOSS [training: 0.12099280198274014 | validation: 0.16445484103545085]
	TIME [epoch: 9.8 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11550771375637107		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.11550771375637107 | validation: 0.16831943815512668]
	TIME [epoch: 9.79 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11934814558526571		[learning rate: 0.00036414]
	Learning Rate: 0.000364136
	LOSS [training: 0.11934814558526571 | validation: 0.14270387165128778]
	TIME [epoch: 9.79 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12581445901295707		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.12581445901295707 | validation: 0.1930750063913076]
	TIME [epoch: 9.82 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14529092349300754		[learning rate: 0.00036237]
	Learning Rate: 0.000362375
	LOSS [training: 0.14529092349300754 | validation: 0.19430724636782665]
	TIME [epoch: 9.79 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1642535898004666		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.1642535898004666 | validation: 0.19654867226866557]
	TIME [epoch: 9.79 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1804359314427964		[learning rate: 0.00036062]
	Learning Rate: 0.000360622
	LOSS [training: 0.1804359314427964 | validation: 0.18205642806658978]
	TIME [epoch: 9.8 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16250992618326493		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.16250992618326493 | validation: 0.19226261591142482]
	TIME [epoch: 9.8 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16285885952907445		[learning rate: 0.00035888]
	Learning Rate: 0.000358878
	LOSS [training: 0.16285885952907445 | validation: 0.19498766219792948]
	TIME [epoch: 9.79 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16869108025526758		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.16869108025526758 | validation: 0.19560091273849303]
	TIME [epoch: 9.8 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16861849311542404		[learning rate: 0.00035714]
	Learning Rate: 0.000357143
	LOSS [training: 0.16861849311542404 | validation: 0.23358970181775945]
	TIME [epoch: 9.8 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17863833157905426		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.17863833157905426 | validation: 0.19116540050506076]
	TIME [epoch: 9.79 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15988889065885314		[learning rate: 0.00035542]
	Learning Rate: 0.000355416
	LOSS [training: 0.15988889065885314 | validation: 0.1966138484119346]
	TIME [epoch: 9.78 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13363843613535786		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.13363843613535786 | validation: 0.1580556466994774]
	TIME [epoch: 9.8 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12374824147469816		[learning rate: 0.0003537]
	Learning Rate: 0.000353697
	LOSS [training: 0.12374824147469816 | validation: 0.1566546304440103]
	TIME [epoch: 9.79 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1262150853164045		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.1262150853164045 | validation: 0.1921594694007007]
	TIME [epoch: 9.79 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1315669988169197		[learning rate: 0.00035199]
	Learning Rate: 0.000351987
	LOSS [training: 0.1315669988169197 | validation: 0.18240866161086663]
	TIME [epoch: 9.81 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11679646317525132		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.11679646317525132 | validation: 0.15174396285282263]
	TIME [epoch: 9.8 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11055423788291581		[learning rate: 0.00035028]
	Learning Rate: 0.000350285
	LOSS [training: 0.11055423788291581 | validation: 0.1469369533663694]
	TIME [epoch: 9.79 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11600402248179545		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.11600402248179545 | validation: 0.1688482014909074]
	TIME [epoch: 9.78 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11768808931364946		[learning rate: 0.00034859]
	Learning Rate: 0.000348591
	LOSS [training: 0.11768808931364946 | validation: 0.17636632438940558]
	TIME [epoch: 9.8 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12178649541113817		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.12178649541113817 | validation: 0.16509611405338834]
	TIME [epoch: 9.78 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10942132261225317		[learning rate: 0.0003469]
	Learning Rate: 0.000346905
	LOSS [training: 0.10942132261225317 | validation: 0.15190964879781976]
	TIME [epoch: 9.79 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10995745597332143		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.10995745597332143 | validation: 0.16326968540450978]
	TIME [epoch: 9.8 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10924234389066405		[learning rate: 0.00034523]
	Learning Rate: 0.000345227
	LOSS [training: 0.10924234389066405 | validation: 0.14810607402133427]
	TIME [epoch: 9.8 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11347364141878313		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.11347364141878313 | validation: 0.14686692670725132]
	TIME [epoch: 9.8 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11636357018266119		[learning rate: 0.00034356]
	Learning Rate: 0.000343558
	LOSS [training: 0.11636357018266119 | validation: 0.16753963468820793]
	TIME [epoch: 9.8 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10615219692614733		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.10615219692614733 | validation: 0.14681468365209888]
	TIME [epoch: 9.79 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10342235769513997		[learning rate: 0.0003419]
	Learning Rate: 0.000341897
	LOSS [training: 0.10342235769513997 | validation: 0.15193264700812126]
	TIME [epoch: 9.8 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10577693871410929		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.10577693871410929 | validation: 0.17599750964687874]
	TIME [epoch: 9.78 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11126601045126927		[learning rate: 0.00034024]
	Learning Rate: 0.000340243
	LOSS [training: 0.11126601045126927 | validation: 0.14321017493333307]
	TIME [epoch: 9.82 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10966507178216996		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.10966507178216996 | validation: 0.1715116500012578]
	TIME [epoch: 9.8 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12342316362859251		[learning rate: 0.0003386]
	Learning Rate: 0.000338598
	LOSS [training: 0.12342316362859251 | validation: 0.18608374006151415]
	TIME [epoch: 9.8 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13447921243955285		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.13447921243955285 | validation: 0.17028939110308244]
	TIME [epoch: 9.79 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12031248026221826		[learning rate: 0.00033696]
	Learning Rate: 0.00033696
	LOSS [training: 0.12031248026221826 | validation: 0.16640080130223894]
	TIME [epoch: 9.8 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11200443305638239		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.11200443305638239 | validation: 0.14608068763934154]
	TIME [epoch: 9.79 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10358637786499521		[learning rate: 0.00033533]
	Learning Rate: 0.000335331
	LOSS [training: 0.10358637786499521 | validation: 0.14996963764455623]
	TIME [epoch: 9.8 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10729261210767309		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.10729261210767309 | validation: 0.163683429348321]
	TIME [epoch: 9.82 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10049054292200824		[learning rate: 0.00033371]
	Learning Rate: 0.000333709
	LOSS [training: 0.10049054292200824 | validation: 0.1341659764277862]
	TIME [epoch: 9.78 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1039920930209001		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.1039920930209001 | validation: 0.14442042286603354]
	TIME [epoch: 9.79 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1129580464059041		[learning rate: 0.0003321]
	Learning Rate: 0.000332096
	LOSS [training: 0.1129580464059041 | validation: 0.1483137040293987]
	TIME [epoch: 9.81 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11313017217951268		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.11313017217951268 | validation: 0.15403377452031616]
	TIME [epoch: 9.78 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11653152247918293		[learning rate: 0.00033049]
	Learning Rate: 0.00033049
	LOSS [training: 0.11653152247918293 | validation: 0.15618397737843734]
	TIME [epoch: 9.8 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12263952436672984		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.12263952436672984 | validation: 0.15144485022358226]
	TIME [epoch: 9.81 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09966731010890834		[learning rate: 0.00032889]
	Learning Rate: 0.000328891
	LOSS [training: 0.09966731010890834 | validation: 0.17188138747373116]
	TIME [epoch: 9.79 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10963807163662902		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.10963807163662902 | validation: 0.1583136758438929]
	TIME [epoch: 9.78 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11006143143017562		[learning rate: 0.0003273]
	Learning Rate: 0.000327301
	LOSS [training: 0.11006143143017562 | validation: 0.15009610907743373]
	TIME [epoch: 9.8 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10890636569306553		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.10890636569306553 | validation: 0.15544858221265465]
	TIME [epoch: 9.81 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10623392575193276		[learning rate: 0.00032572]
	Learning Rate: 0.000325718
	LOSS [training: 0.10623392575193276 | validation: 0.1474808358527429]
	TIME [epoch: 9.79 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1164636722897904		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.1164636722897904 | validation: 0.147555946192672]
	TIME [epoch: 9.79 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1060644179798822		[learning rate: 0.00032414]
	Learning Rate: 0.000324143
	LOSS [training: 0.1060644179798822 | validation: 0.18081277852841462]
	TIME [epoch: 9.81 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1254697290586532		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.1254697290586532 | validation: 0.1316261401654238]
	TIME [epoch: 9.78 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10719714790111867		[learning rate: 0.00032258]
	Learning Rate: 0.000322576
	LOSS [training: 0.10719714790111867 | validation: 0.12592232750495716]
	TIME [epoch: 9.79 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10485070911543952		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.10485070911543952 | validation: 0.14378852021708782]
	TIME [epoch: 9.79 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10852380442182219		[learning rate: 0.00032102]
	Learning Rate: 0.000321016
	LOSS [training: 0.10852380442182219 | validation: 0.1705835338126549]
	TIME [epoch: 9.79 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11071599791196714		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.11071599791196714 | validation: 0.1717218059677332]
	TIME [epoch: 9.79 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11026905018687647		[learning rate: 0.00031946]
	Learning Rate: 0.000319463
	LOSS [training: 0.11026905018687647 | validation: 0.16154212869597373]
	TIME [epoch: 9.8 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10907054686533937		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.10907054686533937 | validation: 0.14999931350524606]
	TIME [epoch: 9.8 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10545291660825169		[learning rate: 0.00031792]
	Learning Rate: 0.000317918
	LOSS [training: 0.10545291660825169 | validation: 0.1506328920136094]
	TIME [epoch: 9.79 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1128719036811604		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.1128719036811604 | validation: 0.17269326221245565]
	TIME [epoch: 9.78 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11474713366325526		[learning rate: 0.00031638]
	Learning Rate: 0.000316381
	LOSS [training: 0.11474713366325526 | validation: 0.1774180530577077]
	TIME [epoch: 9.8 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11584424074932613		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.11584424074932613 | validation: 0.18130266977914558]
	TIME [epoch: 9.78 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11877499743009341		[learning rate: 0.00031485]
	Learning Rate: 0.000314851
	LOSS [training: 0.11877499743009341 | validation: 0.1724675498659695]
	TIME [epoch: 9.78 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11463515184739734		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.11463515184739734 | validation: 0.1360786592727511]
	TIME [epoch: 9.78 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11367127194649393		[learning rate: 0.00031333]
	Learning Rate: 0.000313329
	LOSS [training: 0.11367127194649393 | validation: 0.149605004367688]
	TIME [epoch: 9.81 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11484881863667055		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.11484881863667055 | validation: 0.15912824068406092]
	TIME [epoch: 9.79 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1128616579994474		[learning rate: 0.00031181]
	Learning Rate: 0.000311813
	LOSS [training: 0.1128616579994474 | validation: 0.14592772748507782]
	TIME [epoch: 9.79 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11536609779149083		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.11536609779149083 | validation: 0.15433219037557336]
	TIME [epoch: 9.81 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10864986714625384		[learning rate: 0.00031031]
	Learning Rate: 0.000310305
	LOSS [training: 0.10864986714625384 | validation: 0.13793830903051033]
	TIME [epoch: 9.78 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.107362861436426		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.107362861436426 | validation: 0.1564046964974708]
	TIME [epoch: 9.79 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10585518145176598		[learning rate: 0.0003088]
	Learning Rate: 0.000308805
	LOSS [training: 0.10585518145176598 | validation: 0.15142464704986405]
	TIME [epoch: 9.81 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11041943035485322		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.11041943035485322 | validation: 0.15582504606467115]
	TIME [epoch: 9.78 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11125349218783416		[learning rate: 0.00030731]
	Learning Rate: 0.000307312
	LOSS [training: 0.11125349218783416 | validation: 0.15485318651017818]
	TIME [epoch: 9.78 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11596835586301513		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.11596835586301513 | validation: 0.17025571322092833]
	TIME [epoch: 9.79 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1247564197685079		[learning rate: 0.00030583]
	Learning Rate: 0.000305826
	LOSS [training: 0.1247564197685079 | validation: 0.16137101155172512]
	TIME [epoch: 9.8 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12226538394687517		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.12226538394687517 | validation: 0.1717062796722043]
	TIME [epoch: 9.79 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1332776388196124		[learning rate: 0.00030435]
	Learning Rate: 0.000304347
	LOSS [training: 0.1332776388196124 | validation: 0.18467205493115643]
	TIME [epoch: 9.79 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13793205311351392		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.13793205311351392 | validation: 0.18691352232607406]
	TIME [epoch: 9.81 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13139082290281406		[learning rate: 0.00030287]
	Learning Rate: 0.000302875
	LOSS [training: 0.13139082290281406 | validation: 0.19864470674764526]
	TIME [epoch: 9.8 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15016154113870228		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.15016154113870228 | validation: 0.17884550785756972]
	TIME [epoch: 9.78 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15961483883705635		[learning rate: 0.00030141]
	Learning Rate: 0.00030141
	LOSS [training: 0.15961483883705635 | validation: 0.2208688000334923]
	TIME [epoch: 9.8 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16207667397938158		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.16207667397938158 | validation: 0.19943093059765032]
	TIME [epoch: 9.8 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15198802453435606		[learning rate: 0.00029995]
	Learning Rate: 0.000299953
	LOSS [training: 0.15198802453435606 | validation: 0.18044821332898317]
	TIME [epoch: 9.78 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14037157190495636		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.14037157190495636 | validation: 0.18965626699165947]
	TIME [epoch: 9.79 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14031329874967569		[learning rate: 0.0002985]
	Learning Rate: 0.000298502
	LOSS [training: 0.14031329874967569 | validation: 0.19117268805468443]
	TIME [epoch: 9.8 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12490682822174903		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.12490682822174903 | validation: 0.16395593244185735]
	TIME [epoch: 9.78 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12131733287446322		[learning rate: 0.00029706]
	Learning Rate: 0.000297059
	LOSS [training: 0.12131733287446322 | validation: 0.1780088616930577]
	TIME [epoch: 9.8 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12403420900819084		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.12403420900819084 | validation: 0.1675745235014459]
	TIME [epoch: 9.8 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11736811648106031		[learning rate: 0.00029562]
	Learning Rate: 0.000295622
	LOSS [training: 0.11736811648106031 | validation: 0.17567752053445912]
	TIME [epoch: 9.8 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11770807466284099		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.11770807466284099 | validation: 0.14696215278090646]
	TIME [epoch: 9.79 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11836662408173881		[learning rate: 0.00029419]
	Learning Rate: 0.000294193
	LOSS [training: 0.11836662408173881 | validation: 0.1563304877167347]
	TIME [epoch: 9.79 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11034810425517202		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.11034810425517202 | validation: 0.16426186204930993]
	TIME [epoch: 9.8 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11212426366500235		[learning rate: 0.00029277]
	Learning Rate: 0.00029277
	LOSS [training: 0.11212426366500235 | validation: 0.15884285327852884]
	TIME [epoch: 9.8 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11789075023470941		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.11789075023470941 | validation: 0.19186752717684577]
	TIME [epoch: 9.79 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12025273240349084		[learning rate: 0.00029135]
	Learning Rate: 0.000291354
	LOSS [training: 0.12025273240349084 | validation: 0.13269052922451585]
	TIME [epoch: 9.8 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12161400463878905		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.12161400463878905 | validation: 0.17167373736288022]
	TIME [epoch: 9.79 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10703623993881403		[learning rate: 0.00028995]
	Learning Rate: 0.000289945
	LOSS [training: 0.10703623993881403 | validation: 0.16121658389313837]
	TIME [epoch: 9.79 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1188917151154989		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.1188917151154989 | validation: 0.1630940251394263]
	TIME [epoch: 9.81 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11295664841783418		[learning rate: 0.00028854]
	Learning Rate: 0.000288543
	LOSS [training: 0.11295664841783418 | validation: 0.16371066870036863]
	TIME [epoch: 9.78 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11060707422826943		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.11060707422826943 | validation: 0.1698368424548174]
	TIME [epoch: 9.8 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11389575297017007		[learning rate: 0.00028715]
	Learning Rate: 0.000287148
	LOSS [training: 0.11389575297017007 | validation: 0.169775529365336]
	TIME [epoch: 9.79 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11962538589425882		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.11962538589425882 | validation: 0.17038195668518874]
	TIME [epoch: 9.8 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11153741654673285		[learning rate: 0.00028576]
	Learning Rate: 0.000285759
	LOSS [training: 0.11153741654673285 | validation: 0.14432319906133054]
	TIME [epoch: 9.79 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12452044036750456		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.12452044036750456 | validation: 0.17843016384853286]
	TIME [epoch: 9.8 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1236271143691176		[learning rate: 0.00028438]
	Learning Rate: 0.000284377
	LOSS [training: 0.1236271143691176 | validation: 0.1642166834682881]
	TIME [epoch: 9.81 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12627713341148178		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.12627713341148178 | validation: 0.15329364695155864]
	TIME [epoch: 9.79 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11691960113446127		[learning rate: 0.000283]
	Learning Rate: 0.000283002
	LOSS [training: 0.11691960113446127 | validation: 0.17303224969655298]
	TIME [epoch: 9.78 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11490756905056214		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.11490756905056214 | validation: 0.14941643812326916]
	TIME [epoch: 9.8 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11290553541242095		[learning rate: 0.00028163]
	Learning Rate: 0.000281633
	LOSS [training: 0.11290553541242095 | validation: 0.14047787417103447]
	TIME [epoch: 9.8 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11091636602907651		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.11091636602907651 | validation: 0.17015240553395647]
	TIME [epoch: 9.79 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10573544831478025		[learning rate: 0.00028027]
	Learning Rate: 0.000280272
	LOSS [training: 0.10573544831478025 | validation: 0.16754132599552954]
	TIME [epoch: 9.79 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10982494606243923		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.10982494606243923 | validation: 0.14902680478292601]
	TIME [epoch: 9.81 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10650655531205526		[learning rate: 0.00027892]
	Learning Rate: 0.000278916
	LOSS [training: 0.10650655531205526 | validation: 0.14884590420051072]
	TIME [epoch: 9.78 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11289259093794732		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.11289259093794732 | validation: 0.16412423865627787]
	TIME [epoch: 9.79 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11202382113887362		[learning rate: 0.00027757]
	Learning Rate: 0.000277567
	LOSS [training: 0.11202382113887362 | validation: 0.16432042766843538]
	TIME [epoch: 9.8 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11205748262497765		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.11205748262497765 | validation: 0.16389561911674425]
	TIME [epoch: 9.8 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09983596132300603		[learning rate: 0.00027623]
	Learning Rate: 0.000276225
	LOSS [training: 0.09983596132300603 | validation: 0.15916437798337735]
	TIME [epoch: 9.78 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11421635787463905		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.11421635787463905 | validation: 0.1608115603280988]
	TIME [epoch: 9.79 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10868858910688006		[learning rate: 0.00027489]
	Learning Rate: 0.000274889
	LOSS [training: 0.10868858910688006 | validation: 0.14318326878801846]
	TIME [epoch: 9.8 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10821899562063644		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.10821899562063644 | validation: 0.15054808432680208]
	TIME [epoch: 9.8 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11037070653513567		[learning rate: 0.00027356]
	Learning Rate: 0.00027356
	LOSS [training: 0.11037070653513567 | validation: 0.15464677088810283]
	TIME [epoch: 9.78 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10712743250033403		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.10712743250033403 | validation: 0.13989112687522848]
	TIME [epoch: 9.81 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1124381338228801		[learning rate: 0.00027224]
	Learning Rate: 0.000272237
	LOSS [training: 0.1124381338228801 | validation: 0.1633113886360669]
	TIME [epoch: 9.79 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.119055757807548		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.119055757807548 | validation: 0.20240925695181106]
	TIME [epoch: 9.79 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13225037907605608		[learning rate: 0.00027092]
	Learning Rate: 0.000270921
	LOSS [training: 0.13225037907605608 | validation: 0.1895708973524271]
	TIME [epoch: 9.8 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10918643754912852		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.10918643754912852 | validation: 0.16122838875341192]
	TIME [epoch: 9.79 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10124492275709782		[learning rate: 0.00026961]
	Learning Rate: 0.000269611
	LOSS [training: 0.10124492275709782 | validation: 0.14241089765612702]
	TIME [epoch: 9.79 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11487323867262264		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.11487323867262264 | validation: 0.13144290399261338]
	TIME [epoch: 9.8 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10746986718686755		[learning rate: 0.00026831]
	Learning Rate: 0.000268307
	LOSS [training: 0.10746986718686755 | validation: 0.13405407080460788]
	TIME [epoch: 9.81 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11444720780699909		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.11444720780699909 | validation: 0.14814874997145575]
	TIME [epoch: 9.79 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10409633372505418		[learning rate: 0.00026701]
	Learning Rate: 0.000267009
	LOSS [training: 0.10409633372505418 | validation: 0.1407982233092296]
	TIME [epoch: 9.8 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12020088466688543		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.12020088466688543 | validation: 0.16798858908540454]
	TIME [epoch: 9.81 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11112209743849695		[learning rate: 0.00026572]
	Learning Rate: 0.000265718
	LOSS [training: 0.11112209743849695 | validation: 0.13616832688697492]
	TIME [epoch: 9.79 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09857096100905541		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.09857096100905541 | validation: 0.13388589190273997]
	TIME [epoch: 9.79 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10666219161735949		[learning rate: 0.00026443]
	Learning Rate: 0.000264433
	LOSS [training: 0.10666219161735949 | validation: 0.16182482089736172]
	TIME [epoch: 9.79 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10372988817152154		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.10372988817152154 | validation: 0.15509966765543634]
	TIME [epoch: 9.8 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11087662977995605		[learning rate: 0.00026315]
	Learning Rate: 0.000263154
	LOSS [training: 0.11087662977995605 | validation: 0.16551132178471661]
	TIME [epoch: 9.78 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12377477833175096		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.12377477833175096 | validation: 0.1679600314275628]
	TIME [epoch: 9.79 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11170779429259303		[learning rate: 0.00026188]
	Learning Rate: 0.000261882
	LOSS [training: 0.11170779429259303 | validation: 0.1403889434433167]
	TIME [epoch: 9.8 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10935213563132293		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.10935213563132293 | validation: 0.1614754870082002]
	TIME [epoch: 9.78 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11252226200441617		[learning rate: 0.00026062]
	Learning Rate: 0.000260615
	LOSS [training: 0.11252226200441617 | validation: 0.15944367864563952]
	TIME [epoch: 9.79 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11423008136010371		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.11423008136010371 | validation: 0.1356565958268264]
	TIME [epoch: 9.81 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10039192308066784		[learning rate: 0.00025936]
	Learning Rate: 0.000259355
	LOSS [training: 0.10039192308066784 | validation: 0.1342804670386051]
	TIME [epoch: 9.8 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1025160052973734		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.1025160052973734 | validation: 0.14845306207341086]
	TIME [epoch: 9.78 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10817246636236821		[learning rate: 0.0002581]
	Learning Rate: 0.000258101
	LOSS [training: 0.10817246636236821 | validation: 0.16422616682826374]
	TIME [epoch: 9.79 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10608954751301258		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.10608954751301258 | validation: 0.13835485551644106]
	TIME [epoch: 9.81 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10587595017720264		[learning rate: 0.00025685]
	Learning Rate: 0.000256853
	LOSS [training: 0.10587595017720264 | validation: 0.15940253277345826]
	TIME [epoch: 9.79 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10310401155604894		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.10310401155604894 | validation: 0.15043868204162972]
	TIME [epoch: 9.79 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11494688178405202		[learning rate: 0.00025561]
	Learning Rate: 0.000255611
	LOSS [training: 0.11494688178405202 | validation: 0.14929473976385393]
	TIME [epoch: 9.81 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1261752845991469		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.1261752845991469 | validation: 0.17150172544962888]
	TIME [epoch: 9.79 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10953711320057949		[learning rate: 0.00025437]
	Learning Rate: 0.000254375
	LOSS [training: 0.10953711320057949 | validation: 0.1573341169148748]
	TIME [epoch: 9.79 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10923826961279282		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.10923826961279282 | validation: 0.1606362500693448]
	TIME [epoch: 9.81 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10519770081958886		[learning rate: 0.00025314]
	Learning Rate: 0.000253144
	LOSS [training: 0.10519770081958886 | validation: 0.1295825937243769]
	TIME [epoch: 9.81 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10388862088716908		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.10388862088716908 | validation: 0.15652216200925614]
	TIME [epoch: 9.79 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09941831274172885		[learning rate: 0.00025192]
	Learning Rate: 0.00025192
	LOSS [training: 0.09941831274172885 | validation: 0.15010926258202795]
	TIME [epoch: 9.79 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10921070377260025		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.10921070377260025 | validation: 0.13769421105675606]
	TIME [epoch: 9.8 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10768600014679833		[learning rate: 0.0002507]
	Learning Rate: 0.000250702
	LOSS [training: 0.10768600014679833 | validation: 0.15163134299436895]
	TIME [epoch: 9.79 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10718091987352149		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.10718091987352149 | validation: 0.1558547234867439]
	TIME [epoch: 9.79 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11250372409233991		[learning rate: 0.00024949]
	Learning Rate: 0.00024949
	LOSS [training: 0.11250372409233991 | validation: 0.16087149088141778]
	TIME [epoch: 9.82 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1136166128110889		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.1136166128110889 | validation: 0.1471747620710574]
	TIME [epoch: 9.8 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10113706226420868		[learning rate: 0.00024828]
	Learning Rate: 0.000248283
	LOSS [training: 0.10113706226420868 | validation: 0.1527952405031237]
	TIME [epoch: 9.8 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11251461209159871		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.11251461209159871 | validation: 0.1583118056311085]
	TIME [epoch: 9.8 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10486107554643018		[learning rate: 0.00024708]
	Learning Rate: 0.000247083
	LOSS [training: 0.10486107554643018 | validation: 0.15542288361568118]
	TIME [epoch: 9.79 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1028383259448072		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.1028383259448072 | validation: 0.16684998925985625]
	TIME [epoch: 9.79 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11212334507852173		[learning rate: 0.00024589]
	Learning Rate: 0.000245888
	LOSS [training: 0.11212334507852173 | validation: 0.12414141886848079]
	TIME [epoch: 9.8 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10925731399318903		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.10925731399318903 | validation: 0.1702974518495011]
	TIME [epoch: 9.8 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10840672685515351		[learning rate: 0.0002447]
	Learning Rate: 0.000244699
	LOSS [training: 0.10840672685515351 | validation: 0.16739596212164315]
	TIME [epoch: 9.8 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10398137462075929		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.10398137462075929 | validation: 0.1495409306022272]
	TIME [epoch: 9.78 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1074040224704107		[learning rate: 0.00024352]
	Learning Rate: 0.000243515
	LOSS [training: 0.1074040224704107 | validation: 0.16630236672453474]
	TIME [epoch: 9.81 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10509169261119744		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.10509169261119744 | validation: 0.14492617640661376]
	TIME [epoch: 9.8 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10400183388115562		[learning rate: 0.00024234]
	Learning Rate: 0.000242338
	LOSS [training: 0.10400183388115562 | validation: 0.12833683323729606]
	TIME [epoch: 9.8 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10994107192556028		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.10994107192556028 | validation: 0.14021554368605701]
	TIME [epoch: 9.79 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11277096608510966		[learning rate: 0.00024117]
	Learning Rate: 0.000241166
	LOSS [training: 0.11277096608510966 | validation: 0.16444554194000552]
	TIME [epoch: 9.81 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11759240848868939		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.11759240848868939 | validation: 0.1733135449798983]
	TIME [epoch: 9.79 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11722774622632734		[learning rate: 0.00024]
	Learning Rate: 0.00024
	LOSS [training: 0.11722774622632734 | validation: 0.15314312790544266]
	TIME [epoch: 9.79 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1047025630980547		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.1047025630980547 | validation: 0.13411448583831923]
	TIME [epoch: 9.8 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10494182730298088		[learning rate: 0.00023884]
	Learning Rate: 0.000238839
	LOSS [training: 0.10494182730298088 | validation: 0.1259293732528182]
	TIME [epoch: 9.8 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10503274725554265		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.10503274725554265 | validation: 0.15243376760426547]
	TIME [epoch: 9.8 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10664166528072298		[learning rate: 0.00023768]
	Learning Rate: 0.000237684
	LOSS [training: 0.10664166528072298 | validation: 0.12923875317619307]
	TIME [epoch: 9.81 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09765209865602391		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.09765209865602391 | validation: 0.14917374418117152]
	TIME [epoch: 9.81 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09777445935958343		[learning rate: 0.00023653]
	Learning Rate: 0.000236535
	LOSS [training: 0.09777445935958343 | validation: 0.14195140215842783]
	TIME [epoch: 9.8 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1024923062217495		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.1024923062217495 | validation: 0.15343938404621726]
	TIME [epoch: 9.79 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10846910575875549		[learning rate: 0.00023539]
	Learning Rate: 0.000235391
	LOSS [training: 0.10846910575875549 | validation: 0.15458279179141063]
	TIME [epoch: 9.8 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09424029692750836		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.09424029692750836 | validation: 0.1554070055436822]
	TIME [epoch: 9.79 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09974105035190599		[learning rate: 0.00023425]
	Learning Rate: 0.000234252
	LOSS [training: 0.09974105035190599 | validation: 0.12373703069928169]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1649.pth
	Model improved!!!
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11188436764986547		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.11188436764986547 | validation: 0.15345150787595258]
	TIME [epoch: 9.81 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11619685985147128		[learning rate: 0.00023312]
	Learning Rate: 0.00023312
	LOSS [training: 0.11619685985147128 | validation: 0.14665159187119658]
	TIME [epoch: 9.79 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10766134733107127		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.10766134733107127 | validation: 0.15358498400562517]
	TIME [epoch: 9.77 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11414977852879102		[learning rate: 0.00023199]
	Learning Rate: 0.000231992
	LOSS [training: 0.11414977852879102 | validation: 0.161184992084067]
	TIME [epoch: 9.78 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10325685684208967		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.10325685684208967 | validation: 0.1239415306019923]
	TIME [epoch: 9.79 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09558996394118048		[learning rate: 0.00023087]
	Learning Rate: 0.00023087
	LOSS [training: 0.09558996394118048 | validation: 0.1481195046160764]
	TIME [epoch: 9.78 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09986963703530008		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.09986963703530008 | validation: 0.14163704745472044]
	TIME [epoch: 9.79 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10662627337348307		[learning rate: 0.00022975]
	Learning Rate: 0.000229754
	LOSS [training: 0.10662627337348307 | validation: 0.17417462551886018]
	TIME [epoch: 9.81 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10707054496989417		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.10707054496989417 | validation: 0.1516712000097424]
	TIME [epoch: 9.78 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11632942041273761		[learning rate: 0.00022864]
	Learning Rate: 0.000228643
	LOSS [training: 0.11632942041273761 | validation: 0.13495783059303212]
	TIME [epoch: 9.78 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11310130591091963		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.11310130591091963 | validation: 0.1487893608590284]
	TIME [epoch: 9.8 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10513725410523889		[learning rate: 0.00022754]
	Learning Rate: 0.000227537
	LOSS [training: 0.10513725410523889 | validation: 0.1582755689095535]
	TIME [epoch: 9.8 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10166370930041384		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.10166370930041384 | validation: 0.1679085652863231]
	TIME [epoch: 9.78 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0986721257751505		[learning rate: 0.00022644]
	Learning Rate: 0.000226437
	LOSS [training: 0.0986721257751505 | validation: 0.15782686784881558]
	TIME [epoch: 9.79 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1039923296626987		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.1039923296626987 | validation: 0.15774535738512677]
	TIME [epoch: 9.8 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10993097098420705		[learning rate: 0.00022534]
	Learning Rate: 0.000225342
	LOSS [training: 0.10993097098420705 | validation: 0.15589603817780373]
	TIME [epoch: 9.79 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10514743489169179		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.10514743489169179 | validation: 0.15981757851672246]
	TIME [epoch: 9.78 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11063511883310861		[learning rate: 0.00022425]
	Learning Rate: 0.000224252
	LOSS [training: 0.11063511883310861 | validation: 0.12728329433468719]
	TIME [epoch: 9.8 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11575920156683539		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.11575920156683539 | validation: 0.14724853099149213]
	TIME [epoch: 9.79 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11700219638911682		[learning rate: 0.00022317]
	Learning Rate: 0.000223168
	LOSS [training: 0.11700219638911682 | validation: 0.13518658123998617]
	TIME [epoch: 9.77 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12050202802387718		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.12050202802387718 | validation: 0.13680524690304144]
	TIME [epoch: 9.8 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11465945075899378		[learning rate: 0.00022209]
	Learning Rate: 0.000222089
	LOSS [training: 0.11465945075899378 | validation: 0.13107564268175367]
	TIME [epoch: 9.78 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11084961009023556		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.11084961009023556 | validation: 0.14606036433815958]
	TIME [epoch: 9.77 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1072587963963908		[learning rate: 0.00022101]
	Learning Rate: 0.000221015
	LOSS [training: 0.1072587963963908 | validation: 0.12556787039979742]
	TIME [epoch: 9.78 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10946058779802259		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.10946058779802259 | validation: 0.14403707253232775]
	TIME [epoch: 9.79 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11142884148635197		[learning rate: 0.00021995]
	Learning Rate: 0.000219946
	LOSS [training: 0.11142884148635197 | validation: 0.15278308981159086]
	TIME [epoch: 9.78 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12248924999862665		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.12248924999862665 | validation: 0.15678781753202614]
	TIME [epoch: 9.79 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1268685411863077		[learning rate: 0.00021888]
	Learning Rate: 0.000218882
	LOSS [training: 0.1268685411863077 | validation: 0.135322741575888]
	TIME [epoch: 9.8 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12167934623339056		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.12167934623339056 | validation: 0.15271029298152253]
	TIME [epoch: 9.77 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12311465382494938		[learning rate: 0.00021782]
	Learning Rate: 0.000217824
	LOSS [training: 0.12311465382494938 | validation: 0.16883485087175168]
	TIME [epoch: 9.77 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13541645458129148		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.13541645458129148 | validation: 0.1769504522352547]
	TIME [epoch: 9.79 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15267141061844688		[learning rate: 0.00021677]
	Learning Rate: 0.00021677
	LOSS [training: 0.15267141061844688 | validation: 0.16647695528063408]
	TIME [epoch: 9.78 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15380131244706097		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.15380131244706097 | validation: 0.15219080680273636]
	TIME [epoch: 9.79 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13518795777793208		[learning rate: 0.00021572]
	Learning Rate: 0.000215722
	LOSS [training: 0.13518795777793208 | validation: 0.16640112609379146]
	TIME [epoch: 9.77 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1200574373082071		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.1200574373082071 | validation: 0.131137882831739]
	TIME [epoch: 9.79 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11683335272572407		[learning rate: 0.00021468]
	Learning Rate: 0.000214679
	LOSS [training: 0.11683335272572407 | validation: 0.16378253241944962]
	TIME [epoch: 9.77 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1253832504136438		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.1253832504136438 | validation: 0.16266764876745335]
	TIME [epoch: 9.78 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11809454427871549		[learning rate: 0.00021364]
	Learning Rate: 0.000213641
	LOSS [training: 0.11809454427871549 | validation: 0.1741072381740185]
	TIME [epoch: 9.8 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11885028911733002		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.11885028911733002 | validation: 0.1552567534796225]
	TIME [epoch: 9.78 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11256712047022588		[learning rate: 0.00021261]
	Learning Rate: 0.000212608
	LOSS [training: 0.11256712047022588 | validation: 0.15807168953561834]
	TIME [epoch: 9.78 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1076782205481031		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.1076782205481031 | validation: 0.13524313687824083]
	TIME [epoch: 9.79 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10805102088238897		[learning rate: 0.00021158]
	Learning Rate: 0.00021158
	LOSS [training: 0.10805102088238897 | validation: 0.15462387584708534]
	TIME [epoch: 9.79 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11087232885320072		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.11087232885320072 | validation: 0.14698548317370275]
	TIME [epoch: 9.77 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10958278698836185		[learning rate: 0.00021056]
	Learning Rate: 0.000210556
	LOSS [training: 0.10958278698836185 | validation: 0.15953188122832423]
	TIME [epoch: 9.77 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10694634049651194		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.10694634049651194 | validation: 0.13738558759402883]
	TIME [epoch: 9.79 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11126457171852606		[learning rate: 0.00020954]
	Learning Rate: 0.000209538
	LOSS [training: 0.11126457171852606 | validation: 0.1548258995893397]
	TIME [epoch: 9.78 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10483356305025737		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.10483356305025737 | validation: 0.13517062809555375]
	TIME [epoch: 9.78 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10709253551377773		[learning rate: 0.00020852]
	Learning Rate: 0.000208525
	LOSS [training: 0.10709253551377773 | validation: 0.1445787494273814]
	TIME [epoch: 9.78 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11782718778064434		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.11782718778064434 | validation: 0.15391806191022908]
	TIME [epoch: 9.78 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12112325271974607		[learning rate: 0.00020752]
	Learning Rate: 0.000207516
	LOSS [training: 0.12112325271974607 | validation: 0.14225340919793594]
	TIME [epoch: 9.77 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12231710558698139		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.12231710558698139 | validation: 0.12857193231691164]
	TIME [epoch: 9.77 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11550479395021532		[learning rate: 0.00020651]
	Learning Rate: 0.000206513
	LOSS [training: 0.11550479395021532 | validation: 0.12944150024387996]
	TIME [epoch: 9.78 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10589373477915882		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.10589373477915882 | validation: 0.1707975443621907]
	TIME [epoch: 9.79 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11180270749093509		[learning rate: 0.00020551]
	Learning Rate: 0.000205514
	LOSS [training: 0.11180270749093509 | validation: 0.166659495653336]
	TIME [epoch: 9.77 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11112983886410484		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.11112983886410484 | validation: 0.15507814253427393]
	TIME [epoch: 9.8 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11089056522291788		[learning rate: 0.00020452]
	Learning Rate: 0.000204521
	LOSS [training: 0.11089056522291788 | validation: 0.17333590067842367]
	TIME [epoch: 9.76 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11016403296821715		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.11016403296821715 | validation: 0.1442108280667483]
	TIME [epoch: 9.78 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10689115923567702		[learning rate: 0.00020353]
	Learning Rate: 0.000203531
	LOSS [training: 0.10689115923567702 | validation: 0.16031064584912927]
	TIME [epoch: 9.78 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1090930094295939		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.1090930094295939 | validation: 0.15122985320643717]
	TIME [epoch: 9.78 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10124839389939946		[learning rate: 0.00020255]
	Learning Rate: 0.000202547
	LOSS [training: 0.10124839389939946 | validation: 0.15618689797703003]
	TIME [epoch: 9.77 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10445582935321404		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.10445582935321404 | validation: 0.1277143447509507]
	TIME [epoch: 9.78 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0987789322964923		[learning rate: 0.00020157]
	Learning Rate: 0.000201568
	LOSS [training: 0.0987789322964923 | validation: 0.12911248677484247]
	TIME [epoch: 9.79 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10553484717054681		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.10553484717054681 | validation: 0.13158203953353087]
	TIME [epoch: 9.78 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10945127032699786		[learning rate: 0.00020059]
	Learning Rate: 0.000200593
	LOSS [training: 0.10945127032699786 | validation: 0.16769896827288705]
	TIME [epoch: 9.78 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10685024212380782		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.10685024212380782 | validation: 0.1578722600828301]
	TIME [epoch: 9.8 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10860524155840723		[learning rate: 0.00019962]
	Learning Rate: 0.000199623
	LOSS [training: 0.10860524155840723 | validation: 0.17892425322609093]
	TIME [epoch: 9.79 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11674668315132933		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.11674668315132933 | validation: 0.13488076648247288]
	TIME [epoch: 9.78 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10940989523410671		[learning rate: 0.00019866]
	Learning Rate: 0.000198658
	LOSS [training: 0.10940989523410671 | validation: 0.17096929320442555]
	TIME [epoch: 10 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10558700786243787		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.10558700786243787 | validation: 0.158764862327416]
	TIME [epoch: 9.81 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10615109639146796		[learning rate: 0.0001977]
	Learning Rate: 0.000197697
	LOSS [training: 0.10615109639146796 | validation: 0.15926319938477743]
	TIME [epoch: 9.79 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10181970013075155		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.10181970013075155 | validation: 0.170426039281456]
	TIME [epoch: 9.8 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10539239013574515		[learning rate: 0.00019674]
	Learning Rate: 0.000196741
	LOSS [training: 0.10539239013574515 | validation: 0.17308385651131686]
	TIME [epoch: 9.81 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11477497942399868		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.11477497942399868 | validation: 0.17614564038472635]
	TIME [epoch: 9.79 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11687027380557446		[learning rate: 0.00019579]
	Learning Rate: 0.00019579
	LOSS [training: 0.11687027380557446 | validation: 0.15206945548757692]
	TIME [epoch: 9.79 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1276402650514906		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.1276402650514906 | validation: 0.19591928230037392]
	TIME [epoch: 9.8 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11309074876444133		[learning rate: 0.00019484]
	Learning Rate: 0.000194843
	LOSS [training: 0.11309074876444133 | validation: 0.1750350364394923]
	TIME [epoch: 9.79 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10618468427364762		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.10618468427364762 | validation: 0.16214370019338703]
	TIME [epoch: 9.79 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10653378572218572		[learning rate: 0.0001939]
	Learning Rate: 0.000193901
	LOSS [training: 0.10653378572218572 | validation: 0.1558642926696706]
	TIME [epoch: 9.79 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10090450805898436		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.10090450805898436 | validation: 0.15189161751719668]
	TIME [epoch: 9.81 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10417214780058515		[learning rate: 0.00019296]
	Learning Rate: 0.000192963
	LOSS [training: 0.10417214780058515 | validation: 0.16433110888713912]
	TIME [epoch: 9.79 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0977363509736638		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.0977363509736638 | validation: 0.16959552150965962]
	TIME [epoch: 9.8 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10551686678015364		[learning rate: 0.00019203]
	Learning Rate: 0.00019203
	LOSS [training: 0.10551686678015364 | validation: 0.15169570649198313]
	TIME [epoch: 9.8 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10408093403353717		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.10408093403353717 | validation: 0.13280611633612288]
	TIME [epoch: 9.79 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10584396503904495		[learning rate: 0.0001911]
	Learning Rate: 0.000191101
	LOSS [training: 0.10584396503904495 | validation: 0.15405135646712587]
	TIME [epoch: 9.78 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1081871024335338		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.1081871024335338 | validation: 0.15967338740330636]
	TIME [epoch: 9.8 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1103580682371138		[learning rate: 0.00019018]
	Learning Rate: 0.000190177
	LOSS [training: 0.1103580682371138 | validation: 0.16021475536008736]
	TIME [epoch: 9.8 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10858257993611113		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.10858257993611113 | validation: 0.12813249899034262]
	TIME [epoch: 9.79 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10493234706960641		[learning rate: 0.00018926]
	Learning Rate: 0.000189257
	LOSS [training: 0.10493234706960641 | validation: 0.15694334039661406]
	TIME [epoch: 9.79 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10549823266591922		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.10549823266591922 | validation: 0.12061863452617705]
	TIME [epoch: 9.81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1738.pth
	Model improved!!!
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10209530987882647		[learning rate: 0.00018834]
	Learning Rate: 0.000188342
	LOSS [training: 0.10209530987882647 | validation: 0.12463644600307201]
	TIME [epoch: 9.78 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10244163070842205		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.10244163070842205 | validation: 0.1477043388977717]
	TIME [epoch: 9.78 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10313314433564824		[learning rate: 0.00018743]
	Learning Rate: 0.000187431
	LOSS [training: 0.10313314433564824 | validation: 0.16543853325430902]
	TIME [epoch: 9.8 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1033823773888023		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.1033823773888023 | validation: 0.15381240342848818]
	TIME [epoch: 9.78 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0941625742218348		[learning rate: 0.00018652]
	Learning Rate: 0.000186525
	LOSS [training: 0.0941625742218348 | validation: 0.14892003407434506]
	TIME [epoch: 9.78 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10017803108583734		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.10017803108583734 | validation: 0.14727123927218835]
	TIME [epoch: 9.78 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10067647837993872		[learning rate: 0.00018562]
	Learning Rate: 0.000185623
	LOSS [training: 0.10067647837993872 | validation: 0.13625550255427382]
	TIME [epoch: 9.79 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10090893611544745		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.10090893611544745 | validation: 0.13305163037418732]
	TIME [epoch: 9.78 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10342936885891632		[learning rate: 0.00018473]
	Learning Rate: 0.000184725
	LOSS [training: 0.10342936885891632 | validation: 0.13514887165885836]
	TIME [epoch: 9.78 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10877766351723832		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.10877766351723832 | validation: 0.11868758281711574]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1748.pth
	Model improved!!!
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1040989090188315		[learning rate: 0.00018383]
	Learning Rate: 0.000183832
	LOSS [training: 0.1040989090188315 | validation: 0.1530090145479878]
	TIME [epoch: 9.79 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10286027565392974		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.10286027565392974 | validation: 0.1685540005900672]
	TIME [epoch: 9.79 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09593227712488092		[learning rate: 0.00018294]
	Learning Rate: 0.000182943
	LOSS [training: 0.09593227712488092 | validation: 0.1172954005949348]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1751.pth
	Model improved!!!
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0964225193877942		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.0964225193877942 | validation: 0.15995030104759006]
	TIME [epoch: 9.78 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10336184395530265		[learning rate: 0.00018206]
	Learning Rate: 0.000182058
	LOSS [training: 0.10336184395530265 | validation: 0.1396090410961141]
	TIME [epoch: 9.78 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10245647493246765		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.10245647493246765 | validation: 0.14583732883498746]
	TIME [epoch: 9.78 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10765728341504341		[learning rate: 0.00018118]
	Learning Rate: 0.000181178
	LOSS [training: 0.10765728341504341 | validation: 0.12181013544667314]
	TIME [epoch: 9.8 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09641349844128735		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.09641349844128735 | validation: 0.12840005377334893]
	TIME [epoch: 9.78 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09618482411483412		[learning rate: 0.0001803]
	Learning Rate: 0.000180302
	LOSS [training: 0.09618482411483412 | validation: 0.12757286643515006]
	TIME [epoch: 9.78 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09821958971474695		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.09821958971474695 | validation: 0.1512338002273495]
	TIME [epoch: 9.8 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10144775492575453		[learning rate: 0.00017943]
	Learning Rate: 0.00017943
	LOSS [training: 0.10144775492575453 | validation: 0.15366267612750023]
	TIME [epoch: 9.77 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10103252468488655		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.10103252468488655 | validation: 0.12141383178531441]
	TIME [epoch: 9.77 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.104094153085774		[learning rate: 0.00017856]
	Learning Rate: 0.000178562
	LOSS [training: 0.104094153085774 | validation: 0.1348599774129038]
	TIME [epoch: 9.79 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10121311947852467		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.10121311947852467 | validation: 0.14113126948782534]
	TIME [epoch: 9.78 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09723137607745551		[learning rate: 0.0001777]
	Learning Rate: 0.000177699
	LOSS [training: 0.09723137607745551 | validation: 0.14907718764844216]
	TIME [epoch: 9.77 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09623499880196953		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.09623499880196953 | validation: 0.1608059137406632]
	TIME [epoch: 9.78 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10926048197960725		[learning rate: 0.00017684]
	Learning Rate: 0.000176839
	LOSS [training: 0.10926048197960725 | validation: 0.1620954974881581]
	TIME [epoch: 9.79 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10651176324659384		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.10651176324659384 | validation: 0.12652762926340524]
	TIME [epoch: 9.78 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10050577363691235		[learning rate: 0.00017598]
	Learning Rate: 0.000175984
	LOSS [training: 0.10050577363691235 | validation: 0.1641948734985462]
	TIME [epoch: 9.78 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10866169903759722		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.10866169903759722 | validation: 0.15827509274919377]
	TIME [epoch: 9.8 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10758203314559231		[learning rate: 0.00017513]
	Learning Rate: 0.000175133
	LOSS [training: 0.10758203314559231 | validation: 0.1263290188801766]
	TIME [epoch: 9.78 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1025764182502461		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.1025764182502461 | validation: 0.13922943538178212]
	TIME [epoch: 9.78 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10205777737913121		[learning rate: 0.00017429]
	Learning Rate: 0.000174286
	LOSS [training: 0.10205777737913121 | validation: 0.13551256332057027]
	TIME [epoch: 9.78 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09884178037679607		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.09884178037679607 | validation: 0.15285612000523943]
	TIME [epoch: 9.79 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09732609091514437		[learning rate: 0.00017344]
	Learning Rate: 0.000173443
	LOSS [training: 0.09732609091514437 | validation: 0.1495330491402923]
	TIME [epoch: 9.78 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09870555179198114		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.09870555179198114 | validation: 0.14533208913410658]
	TIME [epoch: 9.77 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1048535318143472		[learning rate: 0.0001726]
	Learning Rate: 0.000172605
	LOSS [training: 0.1048535318143472 | validation: 0.15428090819279003]
	TIME [epoch: 9.79 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10375859547485096		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.10375859547485096 | validation: 0.13717810812820866]
	TIME [epoch: 9.78 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09771414327942239		[learning rate: 0.00017177]
	Learning Rate: 0.00017177
	LOSS [training: 0.09771414327942239 | validation: 0.1536874438523721]
	TIME [epoch: 9.77 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10344632200551125		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.10344632200551125 | validation: 0.1613420591360792]
	TIME [epoch: 9.79 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10871570281975566		[learning rate: 0.00017094]
	Learning Rate: 0.000170939
	LOSS [training: 0.10871570281975566 | validation: 0.15914608221976326]
	TIME [epoch: 9.78 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10145179288588824		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.10145179288588824 | validation: 0.1518649526126047]
	TIME [epoch: 9.77 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10682587918545598		[learning rate: 0.00017011]
	Learning Rate: 0.000170113
	LOSS [training: 0.10682587918545598 | validation: 0.15735566472898302]
	TIME [epoch: 9.78 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10236109035921662		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.10236109035921662 | validation: 0.13710396959482288]
	TIME [epoch: 9.79 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10279863929671565		[learning rate: 0.00016929]
	Learning Rate: 0.00016929
	LOSS [training: 0.10279863929671565 | validation: 0.15469535321393454]
	TIME [epoch: 9.78 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10277766853273507		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.10277766853273507 | validation: 0.14220227975441377]
	TIME [epoch: 9.79 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09549130098224676		[learning rate: 0.00016847]
	Learning Rate: 0.000168471
	LOSS [training: 0.09549130098224676 | validation: 0.13046760243563837]
	TIME [epoch: 9.8 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1048303363502308		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.1048303363502308 | validation: 0.13658188215294695]
	TIME [epoch: 9.78 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10262323358530356		[learning rate: 0.00016766]
	Learning Rate: 0.000167657
	LOSS [training: 0.10262323358530356 | validation: 0.14337848352492386]
	TIME [epoch: 9.78 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09600273583637306		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.09600273583637306 | validation: 0.15319652470452408]
	TIME [epoch: 9.79 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10409034497841371		[learning rate: 0.00016685]
	Learning Rate: 0.000166846
	LOSS [training: 0.10409034497841371 | validation: 0.15647495191948102]
	TIME [epoch: 9.78 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10475967206041437		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.10475967206041437 | validation: 0.1541838386565388]
	TIME [epoch: 9.78 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09725832169267835		[learning rate: 0.00016604]
	Learning Rate: 0.000166039
	LOSS [training: 0.09725832169267835 | validation: 0.14098816404840256]
	TIME [epoch: 9.78 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0994160370498331		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.0994160370498331 | validation: 0.1342279825610912]
	TIME [epoch: 9.8 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10617930863805743		[learning rate: 0.00016524]
	Learning Rate: 0.000165236
	LOSS [training: 0.10617930863805743 | validation: 0.12393143947861841]
	TIME [epoch: 9.78 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09848392762270011		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.09848392762270011 | validation: 0.13408155178025236]
	TIME [epoch: 9.78 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10971711466375092		[learning rate: 0.00016444]
	Learning Rate: 0.000164437
	LOSS [training: 0.10971711466375092 | validation: 0.1566023329418673]
	TIME [epoch: 9.8 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10379913492101778		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.10379913492101778 | validation: 0.13770617555660158]
	TIME [epoch: 9.77 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09940366772265005		[learning rate: 0.00016364]
	Learning Rate: 0.000163642
	LOSS [training: 0.09940366772265005 | validation: 0.14016738186574287]
	TIME [epoch: 9.78 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09991896179598661		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.09991896179598661 | validation: 0.1522334092924289]
	TIME [epoch: 9.78 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10429151048110727		[learning rate: 0.00016285]
	Learning Rate: 0.000162851
	LOSS [training: 0.10429151048110727 | validation: 0.15389328464253801]
	TIME [epoch: 9.79 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10707562935573522		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.10707562935573522 | validation: 0.17252357959838654]
	TIME [epoch: 9.78 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10639812385943655		[learning rate: 0.00016206]
	Learning Rate: 0.000162063
	LOSS [training: 0.10639812385943655 | validation: 0.15910715724891003]
	TIME [epoch: 9.78 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1090027221594952		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.1090027221594952 | validation: 0.15121249163956557]
	TIME [epoch: 9.8 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10592851117079286		[learning rate: 0.00016128]
	Learning Rate: 0.000161279
	LOSS [training: 0.10592851117079286 | validation: 0.15904636812892553]
	TIME [epoch: 9.78 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10320414641356686		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.10320414641356686 | validation: 0.15104666298565764]
	TIME [epoch: 9.78 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10643137163604659		[learning rate: 0.0001605]
	Learning Rate: 0.000160499
	LOSS [training: 0.10643137163604659 | validation: 0.16481709334074288]
	TIME [epoch: 9.8 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1071261767465594		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.1071261767465594 | validation: 0.1552683525415583]
	TIME [epoch: 9.78 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09752234500259352		[learning rate: 0.00015972]
	Learning Rate: 0.000159723
	LOSS [training: 0.09752234500259352 | validation: 0.13412037129374818]
	TIME [epoch: 9.78 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10328720786032282		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.10328720786032282 | validation: 0.1433850693803637]
	TIME [epoch: 9.78 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09855723891280584		[learning rate: 0.00015895]
	Learning Rate: 0.000158951
	LOSS [training: 0.09855723891280584 | validation: 0.13480929321121507]
	TIME [epoch: 9.79 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09767722441244456		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.09767722441244456 | validation: 0.14880431356027546]
	TIME [epoch: 9.78 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1012167403252862		[learning rate: 0.00015818]
	Learning Rate: 0.000158182
	LOSS [training: 0.1012167403252862 | validation: 0.1307708197633904]
	TIME [epoch: 9.78 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10058931185037887		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.10058931185037887 | validation: 0.14087622977896957]
	TIME [epoch: 9.8 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10843940858229387		[learning rate: 0.00015742]
	Learning Rate: 0.000157417
	LOSS [training: 0.10843940858229387 | validation: 0.15912117374737317]
	TIME [epoch: 9.79 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09747131837986141		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.09747131837986141 | validation: 0.1468597302282722]
	TIME [epoch: 9.78 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09607231409165479		[learning rate: 0.00015666]
	Learning Rate: 0.000156656
	LOSS [training: 0.09607231409165479 | validation: 0.14343422897320693]
	TIME [epoch: 9.8 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09820174431956277		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.09820174431956277 | validation: 0.16842451203401113]
	TIME [epoch: 9.78 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10057763279192715		[learning rate: 0.0001559]
	Learning Rate: 0.000155899
	LOSS [training: 0.10057763279192715 | validation: 0.14148384327653638]
	TIME [epoch: 9.78 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10228377864516203		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.10228377864516203 | validation: 0.15338624813917176]
	TIME [epoch: 9.78 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0968973972306025		[learning rate: 0.00015514]
	Learning Rate: 0.000155145
	LOSS [training: 0.0968973972306025 | validation: 0.14473104734475853]
	TIME [epoch: 9.8 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09404684455700008		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.09404684455700008 | validation: 0.14200335636679778]
	TIME [epoch: 9.78 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09354676663813918		[learning rate: 0.00015439]
	Learning Rate: 0.000154394
	LOSS [training: 0.09354676663813918 | validation: 0.1285816260215433]
	TIME [epoch: 9.78 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10687611962185337		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.10687611962185337 | validation: 0.14766377862381233]
	TIME [epoch: 9.79 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09472784974165295		[learning rate: 0.00015365]
	Learning Rate: 0.000153648
	LOSS [training: 0.09472784974165295 | validation: 0.11945368103804124]
	TIME [epoch: 9.78 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10101805354681807		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.10101805354681807 | validation: 0.12951213497508726]
	TIME [epoch: 9.78 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09676280209257723		[learning rate: 0.0001529]
	Learning Rate: 0.000152905
	LOSS [training: 0.09676280209257723 | validation: 0.14737628417840612]
	TIME [epoch: 9.79 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09999676949971989		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.09999676949971989 | validation: 0.13798752324592622]
	TIME [epoch: 9.79 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10057797317600588		[learning rate: 0.00015217]
	Learning Rate: 0.000152165
	LOSS [training: 0.10057797317600588 | validation: 0.12409845248886335]
	TIME [epoch: 9.78 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10229448330427074		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.10229448330427074 | validation: 0.14538520436743974]
	TIME [epoch: 9.78 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09868611108089004		[learning rate: 0.00015143]
	Learning Rate: 0.00015143
	LOSS [training: 0.09868611108089004 | validation: 0.14773946296468]
	TIME [epoch: 9.8 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09660903076738538		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.09660903076738538 | validation: 0.15467732756794714]
	TIME [epoch: 9.78 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09677561259063876		[learning rate: 0.0001507]
	Learning Rate: 0.000150697
	LOSS [training: 0.09677561259063876 | validation: 0.14891350023785516]
	TIME [epoch: 9.77 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10349659233770694		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.10349659233770694 | validation: 0.15903634049728413]
	TIME [epoch: 9.79 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10007965223865281		[learning rate: 0.00014997]
	Learning Rate: 0.000149968
	LOSS [training: 0.10007965223865281 | validation: 0.11949984232219395]
	TIME [epoch: 9.78 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09618798777097301		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.09618798777097301 | validation: 0.14455679633708676]
	TIME [epoch: 9.77 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09686022932988761		[learning rate: 0.00014924]
	Learning Rate: 0.000149243
	LOSS [training: 0.09686022932988761 | validation: 0.15725804050033168]
	TIME [epoch: 9.78 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09839067595008098		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.09839067595008098 | validation: 0.13808455490095364]
	TIME [epoch: 9.79 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09321709594527314		[learning rate: 0.00014852]
	Learning Rate: 0.000148522
	LOSS [training: 0.09321709594527314 | validation: 0.13580569970446407]
	TIME [epoch: 9.77 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09299663805091088		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.09299663805091088 | validation: 0.1380613483921751]
	TIME [epoch: 9.77 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09889980812725416		[learning rate: 0.0001478]
	Learning Rate: 0.000147803
	LOSS [training: 0.09889980812725416 | validation: 0.12546547000801955]
	TIME [epoch: 9.79 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.099777433932002		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.099777433932002 | validation: 0.13276279852614678]
	TIME [epoch: 9.78 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10190047104012948		[learning rate: 0.00014709]
	Learning Rate: 0.000147089
	LOSS [training: 0.10190047104012948 | validation: 0.15456989507699012]
	TIME [epoch: 9.78 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10532932542174508		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.10532932542174508 | validation: 0.1273089961333499]
	TIME [epoch: 9.79 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09811954256593441		[learning rate: 0.00014638]
	Learning Rate: 0.000146377
	LOSS [training: 0.09811954256593441 | validation: 0.11989571890532569]
	TIME [epoch: 9.78 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09668457185829663		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.09668457185829663 | validation: 0.14465108564114046]
	TIME [epoch: 9.78 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09921748110477953		[learning rate: 0.00014567]
	Learning Rate: 0.000145669
	LOSS [training: 0.09921748110477953 | validation: 0.11807458069073032]
	TIME [epoch: 9.78 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09936607468741009		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.09936607468741009 | validation: 0.1477545544317686]
	TIME [epoch: 9.8 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09145629481022678		[learning rate: 0.00014497]
	Learning Rate: 0.000144965
	LOSS [training: 0.09145629481022678 | validation: 0.15056434738679614]
	TIME [epoch: 9.78 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09505559356682099		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.09505559356682099 | validation: 0.14627755121106087]
	TIME [epoch: 9.78 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09268882610103078		[learning rate: 0.00014426]
	Learning Rate: 0.000144264
	LOSS [training: 0.09268882610103078 | validation: 0.12556423543283285]
	TIME [epoch: 9.8 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09587468620859582		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.09587468620859582 | validation: 0.15558530240284882]
	TIME [epoch: 9.79 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09479723894320455		[learning rate: 0.00014357]
	Learning Rate: 0.000143566
	LOSS [training: 0.09479723894320455 | validation: 0.13820270430143386]
	TIME [epoch: 9.78 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10108573640361929		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.10108573640361929 | validation: 0.15794490771628503]
	TIME [epoch: 9.78 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10776019128067627		[learning rate: 0.00014287]
	Learning Rate: 0.000142872
	LOSS [training: 0.10776019128067627 | validation: 0.13062683443703252]
	TIME [epoch: 9.8 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10453566869772093		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.10453566869772093 | validation: 0.1393205972843691]
	TIME [epoch: 9.77 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10771417649484369		[learning rate: 0.00014218]
	Learning Rate: 0.000142181
	LOSS [training: 0.10771417649484369 | validation: 0.14501910310940097]
	TIME [epoch: 9.78 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09734144654640563		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.09734144654640563 | validation: 0.1349759947761386]
	TIME [epoch: 9.79 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0981937016998258		[learning rate: 0.00014149]
	Learning Rate: 0.000141494
	LOSS [training: 0.0981937016998258 | validation: 0.12168576605962596]
	TIME [epoch: 9.77 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10162739481683011		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.10162739481683011 | validation: 0.1421323575185628]
	TIME [epoch: 9.77 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10536647019023429		[learning rate: 0.00014081]
	Learning Rate: 0.000140809
	LOSS [training: 0.10536647019023429 | validation: 0.14745673317619573]
	TIME [epoch: 9.79 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10023386531781972		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.10023386531781972 | validation: 0.14991676825156325]
	TIME [epoch: 9.78 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10416465345889254		[learning rate: 0.00014013]
	Learning Rate: 0.000140128
	LOSS [training: 0.10416465345889254 | validation: 0.133222000112973]
	TIME [epoch: 9.78 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10344526525325573		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.10344526525325573 | validation: 0.1545641223243791]
	TIME [epoch: 9.77 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10031706690892148		[learning rate: 0.00013945]
	Learning Rate: 0.000139451
	LOSS [training: 0.10031706690892148 | validation: 0.1347979874682499]
	TIME [epoch: 9.79 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10235056006914871		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.10235056006914871 | validation: 0.1668501597445507]
	TIME [epoch: 9.77 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09700524430109303		[learning rate: 0.00013878]
	Learning Rate: 0.000138776
	LOSS [training: 0.09700524430109303 | validation: 0.15053017344786457]
	TIME [epoch: 9.77 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10173502002260956		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.10173502002260956 | validation: 0.16262848669225854]
	TIME [epoch: 9.8 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10045037516755453		[learning rate: 0.00013811]
	Learning Rate: 0.000138105
	LOSS [training: 0.10045037516755453 | validation: 0.13244954048826243]
	TIME [epoch: 9.77 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09978006340347505		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.09978006340347505 | validation: 0.14450603417094945]
	TIME [epoch: 9.78 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10022140595338314		[learning rate: 0.00013744]
	Learning Rate: 0.000137437
	LOSS [training: 0.10022140595338314 | validation: 0.1503651283346307]
	TIME [epoch: 9.78 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10924700777967122		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.10924700777967122 | validation: 0.14533331907530603]
	TIME [epoch: 9.78 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10058824364186411		[learning rate: 0.00013677]
	Learning Rate: 0.000136773
	LOSS [training: 0.10058824364186411 | validation: 0.1412138252081424]
	TIME [epoch: 9.77 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0982869818721867		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.0982869818721867 | validation: 0.1512199863286017]
	TIME [epoch: 9.77 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10289770445796782		[learning rate: 0.00013611]
	Learning Rate: 0.000136111
	LOSS [training: 0.10289770445796782 | validation: 0.1356564578379579]
	TIME [epoch: 9.8 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09543568001136504		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.09543568001136504 | validation: 0.14336551439750855]
	TIME [epoch: 9.77 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0979724551940406		[learning rate: 0.00013545]
	Learning Rate: 0.000135453
	LOSS [training: 0.0979724551940406 | validation: 0.13736931287766335]
	TIME [epoch: 9.78 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09959437691533982		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.09959437691533982 | validation: 0.1521694163251672]
	TIME [epoch: 9.79 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10277225528030823		[learning rate: 0.0001348]
	Learning Rate: 0.000134798
	LOSS [training: 0.10277225528030823 | validation: 0.1256015544690917]
	TIME [epoch: 9.78 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09864152645868003		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.09864152645868003 | validation: 0.15126425472760482]
	TIME [epoch: 9.78 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10131035243723319		[learning rate: 0.00013415]
	Learning Rate: 0.000134146
	LOSS [training: 0.10131035243723319 | validation: 0.1469750615282408]
	TIME [epoch: 9.79 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09957186402061893		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.09957186402061893 | validation: 0.14453044054145292]
	TIME [epoch: 9.79 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10148949406627872		[learning rate: 0.0001335]
	Learning Rate: 0.000133498
	LOSS [training: 0.10148949406627872 | validation: 0.14678850196957782]
	TIME [epoch: 9.78 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.099413967111492		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.099413967111492 | validation: 0.1473005883017319]
	TIME [epoch: 9.77 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1004446455886431		[learning rate: 0.00013285]
	Learning Rate: 0.000132852
	LOSS [training: 0.1004446455886431 | validation: 0.14742332480026626]
	TIME [epoch: 9.79 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10268833699237648		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.10268833699237648 | validation: 0.1676777328762007]
	TIME [epoch: 9.78 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09955069155456434		[learning rate: 0.00013221]
	Learning Rate: 0.00013221
	LOSS [training: 0.09955069155456434 | validation: 0.137080060226052]
	TIME [epoch: 9.78 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09500837453685108		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.09500837453685108 | validation: 0.13437124188871033]
	TIME [epoch: 9.79 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1038622282005649		[learning rate: 0.00013157]
	Learning Rate: 0.00013157
	LOSS [training: 0.1038622282005649 | validation: 0.15763379777166545]
	TIME [epoch: 9.78 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09745217824297267		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.09745217824297267 | validation: 0.14937948779729077]
	TIME [epoch: 9.77 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10109846752178117		[learning rate: 0.00013093]
	Learning Rate: 0.000130934
	LOSS [training: 0.10109846752178117 | validation: 0.12550438684197743]
	TIME [epoch: 9.77 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09740335894196163		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.09740335894196163 | validation: 0.13575639294579633]
	TIME [epoch: 9.79 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10096578057639811		[learning rate: 0.0001303]
	Learning Rate: 0.000130301
	LOSS [training: 0.10096578057639811 | validation: 0.15194291225554987]
	TIME [epoch: 9.78 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10289612760083008		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.10289612760083008 | validation: 0.12552027118711426]
	TIME [epoch: 9.77 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10700611306236038		[learning rate: 0.00012967]
	Learning Rate: 0.000129671
	LOSS [training: 0.10700611306236038 | validation: 0.13526683912112483]
	TIME [epoch: 9.79 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09826440347756786		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.09826440347756786 | validation: 0.16196691630974144]
	TIME [epoch: 9.77 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1027044671124863		[learning rate: 0.00012904]
	Learning Rate: 0.000129044
	LOSS [training: 0.1027044671124863 | validation: 0.1516641379277751]
	TIME [epoch: 9.78 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09715320943532543		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.09715320943532543 | validation: 0.13555617308973045]
	TIME [epoch: 9.78 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09882056579306969		[learning rate: 0.00012842]
	Learning Rate: 0.00012842
	LOSS [training: 0.09882056579306969 | validation: 0.1246616094219225]
	TIME [epoch: 9.78 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10238253430770061		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.10238253430770061 | validation: 0.1476050979110706]
	TIME [epoch: 9.77 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09706820315076856		[learning rate: 0.0001278]
	Learning Rate: 0.000127799
	LOSS [training: 0.09706820315076856 | validation: 0.14309661748550506]
	TIME [epoch: 9.77 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10527313335760832		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.10527313335760832 | validation: 0.1590275840704462]
	TIME [epoch: 9.8 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10388491743630199		[learning rate: 0.00012718]
	Learning Rate: 0.000127181
	LOSS [training: 0.10388491743630199 | validation: 0.14706167656068428]
	TIME [epoch: 9.79 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10587215222619253		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.10587215222619253 | validation: 0.13376281984309418]
	TIME [epoch: 9.78 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09932935462629451		[learning rate: 0.00012657]
	Learning Rate: 0.000126566
	LOSS [training: 0.09932935462629451 | validation: 0.14245531977459278]
	TIME [epoch: 9.78 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09849220310246869		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.09849220310246869 | validation: 0.1513525841380795]
	TIME [epoch: 9.78 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10173495060839825		[learning rate: 0.00012595]
	Learning Rate: 0.000125954
	LOSS [training: 0.10173495060839825 | validation: 0.1427653388576187]
	TIME [epoch: 9.77 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10047788459871443		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.10047788459871443 | validation: 0.1587015808280788]
	TIME [epoch: 9.77 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09746048266019396		[learning rate: 0.00012534]
	Learning Rate: 0.000125345
	LOSS [training: 0.09746048266019396 | validation: 0.15618882908139775]
	TIME [epoch: 9.79 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10073564636220489		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.10073564636220489 | validation: 0.1600406244884735]
	TIME [epoch: 9.77 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10746981248218064		[learning rate: 0.00012474]
	Learning Rate: 0.000124738
	LOSS [training: 0.10746981248218064 | validation: 0.13815830664570503]
	TIME [epoch: 9.77 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09646738279366492		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.09646738279366492 | validation: 0.14513322761910868]
	TIME [epoch: 9.79 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10689564363075314		[learning rate: 0.00012414]
	Learning Rate: 0.000124135
	LOSS [training: 0.10689564363075314 | validation: 0.12541132694066534]
	TIME [epoch: 9.77 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10568121092084035		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.10568121092084035 | validation: 0.16223374114166667]
	TIME [epoch: 9.78 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11106588832615605		[learning rate: 0.00012353]
	Learning Rate: 0.000123535
	LOSS [training: 0.11106588832615605 | validation: 0.12265950570966283]
	TIME [epoch: 9.79 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10292596814520542		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.10292596814520542 | validation: 0.156202201810455]
	TIME [epoch: 9.78 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1053806695782498		[learning rate: 0.00012294]
	Learning Rate: 0.000122937
	LOSS [training: 0.1053806695782498 | validation: 0.14514240891912125]
	TIME [epoch: 9.77 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10322656196983548		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.10322656196983548 | validation: 0.14385696436959913]
	TIME [epoch: 9.77 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09719138001547387		[learning rate: 0.00012234]
	Learning Rate: 0.000122343
	LOSS [training: 0.09719138001547387 | validation: 0.13113852425794642]
	TIME [epoch: 9.79 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.092413531596837		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.092413531596837 | validation: 0.1519197934846541]
	TIME [epoch: 9.77 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09970476886382926		[learning rate: 0.00012175]
	Learning Rate: 0.000121751
	LOSS [training: 0.09970476886382926 | validation: 0.15081326308767026]
	TIME [epoch: 9.78 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09908620302653534		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.09908620302653534 | validation: 0.13316174656082197]
	TIME [epoch: 9.8 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0993051064885874		[learning rate: 0.00012116]
	Learning Rate: 0.000121163
	LOSS [training: 0.0993051064885874 | validation: 0.13246907257521312]
	TIME [epoch: 9.78 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10119237378777399		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.10119237378777399 | validation: 0.14738822394389256]
	TIME [epoch: 9.77 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10143478920845914		[learning rate: 0.00012058]
	Learning Rate: 0.000120577
	LOSS [training: 0.10143478920845914 | validation: 0.12941420795204334]
	TIME [epoch: 9.78 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09336359616672028		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.09336359616672028 | validation: 0.13148536219414936]
	TIME [epoch: 9.78 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09605279264405482		[learning rate: 0.00011999]
	Learning Rate: 0.000119994
	LOSS [training: 0.09605279264405482 | validation: 0.1542439160965381]
	TIME [epoch: 9.78 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09198234858744855		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.09198234858744855 | validation: 0.1337487835214369]
	TIME [epoch: 9.78 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09896872425493866		[learning rate: 0.00011941]
	Learning Rate: 0.000119413
	LOSS [training: 0.09896872425493866 | validation: 0.1353601215876448]
	TIME [epoch: 9.79 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09933194936065856		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.09933194936065856 | validation: 0.1643915670664179]
	TIME [epoch: 9.78 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10161670411470436		[learning rate: 0.00011884]
	Learning Rate: 0.000118836
	LOSS [training: 0.10161670411470436 | validation: 0.13926025545984552]
	TIME [epoch: 9.78 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09355764605280237		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.09355764605280237 | validation: 0.14207824518864126]
	TIME [epoch: 9.8 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09773454431631072		[learning rate: 0.00011826]
	Learning Rate: 0.000118261
	LOSS [training: 0.09773454431631072 | validation: 0.14936464912778682]
	TIME [epoch: 9.79 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.097407282909077		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.097407282909077 | validation: 0.1377672375431107]
	TIME [epoch: 9.77 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09267986284200617		[learning rate: 0.00011769]
	Learning Rate: 0.000117689
	LOSS [training: 0.09267986284200617 | validation: 0.13155320909146265]
	TIME [epoch: 9.77 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10507313557537194		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.10507313557537194 | validation: 0.15692332804826617]
	TIME [epoch: 9.8 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09705991051721401		[learning rate: 0.00011712]
	Learning Rate: 0.00011712
	LOSS [training: 0.09705991051721401 | validation: 0.1286947457179453]
	TIME [epoch: 9.78 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10276385004896207		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.10276385004896207 | validation: 0.15012051214340508]
	TIME [epoch: 9.77 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1020682542721995		[learning rate: 0.00011655]
	Learning Rate: 0.000116554
	LOSS [training: 0.1020682542721995 | validation: 0.14493748222847225]
	TIME [epoch: 9.79 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0984636583128623		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.0984636583128623 | validation: 0.12394405314616577]
	TIME [epoch: 9.78 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10156111792038122		[learning rate: 0.00011599]
	Learning Rate: 0.00011599
	LOSS [training: 0.10156111792038122 | validation: 0.12081423364945183]
	TIME [epoch: 9.77 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09793710532581427		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.09793710532581427 | validation: 0.15772608998881216]
	TIME [epoch: 9.8 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10352623457682102		[learning rate: 0.00011543]
	Learning Rate: 0.000115429
	LOSS [training: 0.10352623457682102 | validation: 0.11567689975834332]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240219_183145/states/model_tr_study6_1941.pth
	Model improved!!!
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09599469530766104		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.09599469530766104 | validation: 0.1417139707299019]
	TIME [epoch: 9.79 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10127342292622936		[learning rate: 0.00011487]
	Learning Rate: 0.000114871
	LOSS [training: 0.10127342292622936 | validation: 0.132161481334874]
	TIME [epoch: 9.78 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10446011994625444		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.10446011994625444 | validation: 0.15413633635607007]
	TIME [epoch: 9.8 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10229520127944561		[learning rate: 0.00011432]
	Learning Rate: 0.000114316
	LOSS [training: 0.10229520127944561 | validation: 0.125091843067086]
	TIME [epoch: 9.77 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10783620569749719		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.10783620569749719 | validation: 0.1605492009406104]
	TIME [epoch: 9.78 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10260687656885954		[learning rate: 0.00011376]
	Learning Rate: 0.000113763
	LOSS [training: 0.10260687656885954 | validation: 0.1185906329340294]
	TIME [epoch: 9.81 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0993102570318507		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.0993102570318507 | validation: 0.13853630687602642]
	TIME [epoch: 9.79 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09959964864303862		[learning rate: 0.00011321]
	Learning Rate: 0.000113213
	LOSS [training: 0.09959964864303862 | validation: 0.15147209259176403]
	TIME [epoch: 9.8 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09727893611409608		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.09727893611409608 | validation: 0.15137740845824543]
	TIME [epoch: 9.8 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09699338481874178		[learning rate: 0.00011267]
	Learning Rate: 0.000112665
	LOSS [training: 0.09699338481874178 | validation: 0.13102413272530825]
	TIME [epoch: 9.81 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09509695530875044		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.09509695530875044 | validation: 0.12112452831682437]
	TIME [epoch: 9.79 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09784973264614627		[learning rate: 0.00011212]
	Learning Rate: 0.00011212
	LOSS [training: 0.09784973264614627 | validation: 0.14510344228570768]
	TIME [epoch: 9.8 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09574232646929985		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.09574232646929985 | validation: 0.1464013923770416]
	TIME [epoch: 9.81 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09539447173951086		[learning rate: 0.00011158]
	Learning Rate: 0.000111578
	LOSS [training: 0.09539447173951086 | validation: 0.12817032076958437]
	TIME [epoch: 9.8 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09361699592369557		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.09361699592369557 | validation: 0.11882601911103759]
	TIME [epoch: 9.79 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09723515153462073		[learning rate: 0.00011104]
	Learning Rate: 0.000111039
	LOSS [training: 0.09723515153462073 | validation: 0.14897815097505368]
	TIME [epoch: 9.81 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0959454123324884		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.0959454123324884 | validation: 0.12423986732920529]
	TIME [epoch: 9.79 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09505905576647064		[learning rate: 0.0001105]
	Learning Rate: 0.000110502
	LOSS [training: 0.09505905576647064 | validation: 0.12256567572161096]
	TIME [epoch: 9.78 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09228257017638898		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.09228257017638898 | validation: 0.1352797470284029]
	TIME [epoch: 9.79 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09325939083452575		[learning rate: 0.00010997]
	Learning Rate: 0.000109967
	LOSS [training: 0.09325939083452575 | validation: 0.15691351522869548]
	TIME [epoch: 9.81 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09194656340447513		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.09194656340447513 | validation: 0.1532499061718867]
	TIME [epoch: 9.78 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09495274393708905		[learning rate: 0.00010944]
	Learning Rate: 0.000109435
	LOSS [training: 0.09495274393708905 | validation: 0.13894762711971925]
	TIME [epoch: 9.8 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10104140018636945		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.10104140018636945 | validation: 0.1438933313053675]
	TIME [epoch: 9.82 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09947323574401416		[learning rate: 0.00010891]
	Learning Rate: 0.000108906
	LOSS [training: 0.09947323574401416 | validation: 0.14411863485351453]
	TIME [epoch: 9.78 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09580180292276426		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.09580180292276426 | validation: 0.1228194785417946]
	TIME [epoch: 9.79 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09799195332113593		[learning rate: 0.00010838]
	Learning Rate: 0.00010838
	LOSS [training: 0.09799195332113593 | validation: 0.11683870808707023]
	TIME [epoch: 9.81 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1017126646023562		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.1017126646023562 | validation: 0.1327911859389601]
	TIME [epoch: 9.8 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09408561108347088		[learning rate: 0.00010786]
	Learning Rate: 0.000107855
	LOSS [training: 0.09408561108347088 | validation: 0.15214525420131134]
	TIME [epoch: 9.79 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10058057967054482		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.10058057967054482 | validation: 0.15907167439684325]
	TIME [epoch: 9.8 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10119082240606063		[learning rate: 0.00010733]
	Learning Rate: 0.000107334
	LOSS [training: 0.10119082240606063 | validation: 0.16436222704470177]
	TIME [epoch: 9.81 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0977839459539337		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.0977839459539337 | validation: 0.1357681338836562]
	TIME [epoch: 9.78 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10193617527728338		[learning rate: 0.00010681]
	Learning Rate: 0.000106815
	LOSS [training: 0.10193617527728338 | validation: 0.1409264381456121]
	TIME [epoch: 9.78 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09580987545409196		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.09580987545409196 | validation: 0.11747107465950894]
	TIME [epoch: 9.82 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1015819876185585		[learning rate: 0.0001063]
	Learning Rate: 0.000106298
	LOSS [training: 0.1015819876185585 | validation: 0.13862558960634622]
	TIME [epoch: 9.78 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09459572509211076		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.09459572509211076 | validation: 0.12318981090521679]
	TIME [epoch: 9.78 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09613520909985326		[learning rate: 0.00010578]
	Learning Rate: 0.000105784
	LOSS [training: 0.09613520909985326 | validation: 0.14152651605993188]
	TIME [epoch: 9.8 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09607742363369001		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.09607742363369001 | validation: 0.14248237214664702]
	TIME [epoch: 9.8 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09754758566471866		[learning rate: 0.00010527]
	Learning Rate: 0.000105273
	LOSS [training: 0.09754758566471866 | validation: 0.14598064698967933]
	TIME [epoch: 9.79 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09629085755316855		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.09629085755316855 | validation: 0.1218193882101825]
	TIME [epoch: 9.78 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10220556147172337		[learning rate: 0.00010476]
	Learning Rate: 0.000104764
	LOSS [training: 0.10220556147172337 | validation: 0.1470665871968034]
	TIME [epoch: 9.81 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10003844688442484		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.10003844688442484 | validation: 0.15026858281639852]
	TIME [epoch: 9.79 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09649429139687138		[learning rate: 0.00010426]
	Learning Rate: 0.000104257
	LOSS [training: 0.09649429139687138 | validation: 0.14100135990165533]
	TIME [epoch: 9.78 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0952266490215205		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.0952266490215205 | validation: 0.13977135739243637]
	TIME [epoch: 9.81 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09762584487928672		[learning rate: 0.00010375]
	Learning Rate: 0.000103753
	LOSS [training: 0.09762584487928672 | validation: 0.12302225320437561]
	TIME [epoch: 9.78 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09728822126245867		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.09728822126245867 | validation: 0.1506649134585615]
	TIME [epoch: 9.79 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08990132387824099		[learning rate: 0.00010325]
	Learning Rate: 0.000103251
	LOSS [training: 0.08990132387824099 | validation: 0.1226093112613195]
	TIME [epoch: 9.79 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09782348733314439		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.09782348733314439 | validation: 0.14503126541980393]
	TIME [epoch: 9.8 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1032165922612358		[learning rate: 0.00010275]
	Learning Rate: 0.000102752
	LOSS [training: 0.1032165922612358 | validation: 0.1438466512541628]
	TIME [epoch: 9.79 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0973599613606709		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.0973599613606709 | validation: 0.15963565228749427]
	TIME [epoch: 9.79 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10274575466895215		[learning rate: 0.00010225]
	Learning Rate: 0.000102255
	LOSS [training: 0.10274575466895215 | validation: 0.15327075140748178]
	TIME [epoch: 9.8 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09807427097184698		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.09807427097184698 | validation: 0.11787807869686372]
	TIME [epoch: 9.79 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10047402115396094		[learning rate: 0.00010176]
	Learning Rate: 0.00010176
	LOSS [training: 0.10047402115396094 | validation: 0.13103577662788132]
	TIME [epoch: 9.78 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10041109919105899		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.10041109919105899 | validation: 0.13594378558951892]
	TIME [epoch: 9.79 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09558175408323191		[learning rate: 0.00010127]
	Learning Rate: 0.000101268
	LOSS [training: 0.09558175408323191 | validation: 0.13433688109574568]
	TIME [epoch: 9.78 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1044838987013865		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.1044838987013865 | validation: 0.14669523807185297]
	TIME [epoch: 9.79 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09262092383318773		[learning rate: 0.00010078]
	Learning Rate: 0.000100779
	LOSS [training: 0.09262092383318773 | validation: 0.1619586526080659]
	TIME [epoch: 9.79 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09409254698400045		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.09409254698400045 | validation: 0.12911788897729426]
	TIME [epoch: 9.81 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09756522584600519		[learning rate: 0.00010029]
	Learning Rate: 0.000100291
	LOSS [training: 0.09756522584600519 | validation: 0.11975464933941227]
	TIME [epoch: 9.79 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09565505783967587		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.09565505783967587 | validation: 0.12264279882965969]
	TIME [epoch: 9.79 sec]
Finished training in 19718.086 seconds.
