Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r5', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 403977018

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.479247498377953		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.479247498377953 | validation: 7.487885483637718]
	TIME [epoch: 111 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.791150267600992		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.791150267600992 | validation: 6.129920651285004]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.125382159343933		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.125382159343933 | validation: 5.724604122236294]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.515779998064667		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.515779998064667 | validation: 5.419833986163231]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.498835938234647		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.498835938234647 | validation: 6.05342236007285]
	TIME [epoch: 24.8 sec]
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6824624805136565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.6824624805136565 | validation: 5.086794088490184]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.079964078640558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.079964078640558 | validation: 5.074509946510877]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.939495887153103		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.939495887153103 | validation: 4.69172772220933]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.782822573943138		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.782822573943138 | validation: 5.034650831817875]
	TIME [epoch: 24.8 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.941334559301154		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.941334559301154 | validation: 4.664506540760414]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.481828433143606		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.481828433143606 | validation: 4.451056679133951]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.391916570034703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.391916570034703 | validation: 4.48983391826563]
	TIME [epoch: 24.8 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.159442399076044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.159442399076044 | validation: 4.214684708756874]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9247516821241017		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9247516821241017 | validation: 4.1512297828634805]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.843572388933032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.843572388933032 | validation: 5.558603038998209]
	TIME [epoch: 24.8 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.188250631871584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.188250631871584 | validation: 4.111458197893685]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7416703767513884		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7416703767513884 | validation: 4.188354431769118]
	TIME [epoch: 24.8 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.022841485066966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.022841485066966 | validation: 5.1579194128210935]
	TIME [epoch: 24.8 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.197940899414679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.197940899414679 | validation: 4.220147708867542]
	TIME [epoch: 24.8 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7453256915506588		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7453256915506588 | validation: 3.9108223822368986]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6385399413712105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6385399413712105 | validation: 3.892220173595788]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6018548978412763		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6018548978412763 | validation: 3.6721372143612543]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.480918526163766		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.480918526163766 | validation: 3.626532118301083]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.488297850449281		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.488297850449281 | validation: 3.4160834649649043]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3923370663372348		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3923370663372348 | validation: 3.4499176774099176]
	TIME [epoch: 24.8 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.332271282730987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.332271282730987 | validation: 3.453176649611251]
	TIME [epoch: 24.8 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5580750713512685		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5580750713512685 | validation: 3.327830425975014]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_27.pth
	Model improved!!!
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.174112292879122		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.174112292879122 | validation: 4.070825132993729]
	TIME [epoch: 24.8 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7658904558582096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7658904558582096 | validation: 3.766608334312591]
	TIME [epoch: 24.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4989029872215958		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4989029872215958 | validation: 3.530386093054606]
	TIME [epoch: 24.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6272086880466556		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6272086880466556 | validation: 3.568618296045405]
	TIME [epoch: 24.8 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3189582952680374		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3189582952680374 | validation: 3.367999575689496]
	TIME [epoch: 24.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.393460346148019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.393460346148019 | validation: 3.409887665446248]
	TIME [epoch: 24.7 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.231434289357668		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.231434289357668 | validation: 3.5797252446888286]
	TIME [epoch: 24.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.480347452879104		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.480347452879104 | validation: 3.18759063574473]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6851025991572515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6851025991572515 | validation: 5.197009025029945]
	TIME [epoch: 24.8 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.383589166078551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.383589166078551 | validation: 4.40648387405583]
	TIME [epoch: 24.7 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.3799818007200555		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3799818007200555 | validation: 3.5874650287367524]
	TIME [epoch: 24.7 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.389719748587748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.389719748587748 | validation: 4.701426767066361]
	TIME [epoch: 24.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.365162659964589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.365162659964589 | validation: 4.485580629617541]
	TIME [epoch: 24.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8970782695059087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8970782695059087 | validation: 3.1569523147138696]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_41.pth
	Model improved!!!
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.187389542156728		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.187389542156728 | validation: 3.7912778424145506]
	TIME [epoch: 24.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4737679770203096		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4737679770203096 | validation: 3.4623261432844608]
	TIME [epoch: 24.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.24976672422416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.24976672422416 | validation: 3.5270094301539245]
	TIME [epoch: 24.7 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.480672559924261		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.480672559924261 | validation: 4.620632447579349]
	TIME [epoch: 24.9 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.886376778511342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.886376778511342 | validation: 3.6638592923395574]
	TIME [epoch: 24.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2581394107022876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2581394107022876 | validation: 3.141331044052446]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1570264306396396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1570264306396396 | validation: 3.253417380729411]
	TIME [epoch: 24.8 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1517518726318303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1517518726318303 | validation: 3.133350656032208]
	TIME [epoch: 24.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.003810123877916		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.003810123877916 | validation: 3.0307732901570628]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_50.pth
	Model improved!!!
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.948682989120706		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 2.948682989120706 | validation: 2.951120631221726]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_51.pth
	Model improved!!!
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.102573270163087		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.102573270163087 | validation: 3.2129948858838544]
	TIME [epoch: 24.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9076099455492725		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.9076099455492725 | validation: 3.551055946687811]
	TIME [epoch: 24.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2113158992900495		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.2113158992900495 | validation: 2.9165287767950243]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_54.pth
	Model improved!!!
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0444534411250537		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.0444534411250537 | validation: 2.663708907387402]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_55.pth
	Model improved!!!
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7033022634061536		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 2.7033022634061536 | validation: 2.592768899304573]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_56.pth
	Model improved!!!
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.172398831147798		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 3.172398831147798 | validation: 2.9299766345356804]
	TIME [epoch: 24.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.097622339946625		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 5.097622339946625 | validation: 4.445275852968002]
	TIME [epoch: 24.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8643977725914045		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.8643977725914045 | validation: 3.2850835870676156]
	TIME [epoch: 24.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4702966239313833		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.4702966239313833 | validation: 3.402631695413954]
	TIME [epoch: 24.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.271805801199954		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 3.271805801199954 | validation: 2.859659769194697]
	TIME [epoch: 24.8 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9854460146160786		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.9854460146160786 | validation: 3.2284966962887247]
	TIME [epoch: 24.8 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.244951622905925		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 4.244951622905925 | validation: 4.821685677892208]
	TIME [epoch: 24.8 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.032537205109344		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 4.032537205109344 | validation: 2.9746529450647348]
	TIME [epoch: 24.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.032935196443668		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.032935196443668 | validation: 3.014022938035738]
	TIME [epoch: 24.8 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.961806237871815		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 2.961806237871815 | validation: 2.9091038575558406]
	TIME [epoch: 24.8 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.106362253736808		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 3.106362253736808 | validation: 3.128417421882064]
	TIME [epoch: 24.8 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1718964247926		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.1718964247926 | validation: 3.4711194615395256]
	TIME [epoch: 24.8 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2469703582738427		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 3.2469703582738427 | validation: 3.542027841293416]
	TIME [epoch: 24.8 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.682982554892028		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.682982554892028 | validation: 3.4532612881862748]
	TIME [epoch: 24.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.991772631217031		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 2.991772631217031 | validation: 2.8632297957905837]
	TIME [epoch: 24.8 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.330862130608912		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.330862130608912 | validation: 2.747322460288077]
	TIME [epoch: 24.8 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0129557237646347		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 3.0129557237646347 | validation: 2.513057037489106]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0141192809929667		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.0141192809929667 | validation: 2.64013000022561]
	TIME [epoch: 24.8 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6979711536391227		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 3.6979711536391227 | validation: 3.263268200883918]
	TIME [epoch: 24.8 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3809131313849754		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 3.3809131313849754 | validation: 3.5921755459663047]
	TIME [epoch: 24.8 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.876662432043946		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 2.876662432043946 | validation: 3.21569534338447]
	TIME [epoch: 24.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.666972502963293		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.666972502963293 | validation: 3.8008052516414965]
	TIME [epoch: 24.8 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7770164204349665		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 3.7770164204349665 | validation: 3.917325811745196]
	TIME [epoch: 24.8 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.988618502895584		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 3.988618502895584 | validation: 3.818305900430776]
	TIME [epoch: 24.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5929797101624894		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.5929797101624894 | validation: 3.043480276838151]
	TIME [epoch: 24.8 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8072844872634373		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 2.8072844872634373 | validation: 3.8627868034556445]
	TIME [epoch: 24.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9357139384456437		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 3.9357139384456437 | validation: 3.3309939657811323]
	TIME [epoch: 24.8 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8495604777381507		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 2.8495604777381507 | validation: 2.6935688128528477]
	TIME [epoch: 24.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8582990569631033		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.8582990569631033 | validation: 2.6589796159511594]
	TIME [epoch: 24.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9759335087831413		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 2.9759335087831413 | validation: 2.8900147790088737]
	TIME [epoch: 24.8 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6202248575258613		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 2.6202248575258613 | validation: 2.480257580035105]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_87.pth
	Model improved!!!
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.391528032788016		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 3.391528032788016 | validation: 3.8005489925744893]
	TIME [epoch: 24.8 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2798920665525406		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 3.2798920665525406 | validation: 2.572463705608787]
	TIME [epoch: 24.8 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6241113415471693		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 2.6241113415471693 | validation: 2.4009795172102844]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_90.pth
	Model improved!!!
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4974008219782022		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 2.4974008219782022 | validation: 2.18861953412088]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.321110667943686		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.321110667943686 | validation: 4.056101364312069]
	TIME [epoch: 24.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8717978154582027		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 3.8717978154582027 | validation: 3.214500575889724]
	TIME [epoch: 24.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.114314280238824		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 4.114314280238824 | validation: 4.537766136558089]
	TIME [epoch: 24.8 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7065318040791455		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 3.7065318040791455 | validation: 2.847266052948261]
	TIME [epoch: 24.7 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2664396596140204		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 3.2664396596140204 | validation: 2.772605000099137]
	TIME [epoch: 24.8 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8642713972450404		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.8642713972450404 | validation: 2.7491947615811734]
	TIME [epoch: 24.8 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7299964455118126		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.7299964455118126 | validation: 3.248804240563174]
	TIME [epoch: 24.8 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.182528956014844		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 4.182528956014844 | validation: 3.225817962370828]
	TIME [epoch: 24.8 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9051813028157323		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 3.9051813028157323 | validation: 3.0804041560468187]
	TIME [epoch: 24.8 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9385707521860134		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.9385707521860134 | validation: 4.3324341674570075]
	TIME [epoch: 24.8 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.061067764987002		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 4.061067764987002 | validation: 3.519288296775517]
	TIME [epoch: 24.8 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.252541377560523		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 3.252541377560523 | validation: 2.627113223594868]
	TIME [epoch: 24.8 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.625626544465477		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.625626544465477 | validation: 2.491107135008257]
	TIME [epoch: 24.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4832020910572012		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 3.4832020910572012 | validation: 3.54243304921754]
	TIME [epoch: 24.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1191339129937976		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 3.1191339129937976 | validation: 2.875322438970208]
	TIME [epoch: 24.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6610651616588408		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.6610651616588408 | validation: 2.305874152936011]
	TIME [epoch: 24.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.420148330091126		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 3.420148330091126 | validation: 3.140905077763624]
	TIME [epoch: 24.8 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1833304544843743		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 3.1833304544843743 | validation: 3.7596465298257375]
	TIME [epoch: 24.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6247908443580705		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 3.6247908443580705 | validation: 2.645917698455597]
	TIME [epoch: 24.8 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8149661038586204		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 2.8149661038586204 | validation: 3.9938554232726173]
	TIME [epoch: 24.8 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.843490304291345		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 3.843490304291345 | validation: 2.864603021398326]
	TIME [epoch: 24.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39753019280457		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 3.39753019280457 | validation: 4.459776157551003]
	TIME [epoch: 24.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1000978448815735		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 4.1000978448815735 | validation: 3.7339974032206094]
	TIME [epoch: 24.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.209182629887741		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 4.209182629887741 | validation: 3.021821190762512]
	TIME [epoch: 24.8 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9677278984405953		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.9677278984405953 | validation: 3.3033455962255154]
	TIME [epoch: 24.8 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.279196463074805		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 3.279196463074805 | validation: 2.478810533843731]
	TIME [epoch: 24.8 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.384089262787347		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 2.384089262787347 | validation: 2.1602791488667403]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_118.pth
	Model improved!!!
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2416875800939273		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 2.2416875800939273 | validation: 2.170409708676055]
	TIME [epoch: 24.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.108194018332486		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 2.108194018332486 | validation: 1.89186127875469]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.902428857425381		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 2.902428857425381 | validation: 5.250354861770916]
	TIME [epoch: 24.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.38257428684924		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 4.38257428684924 | validation: 3.1176559898429175]
	TIME [epoch: 24.8 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6884247440651174		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 2.6884247440651174 | validation: 2.1202925554100718]
	TIME [epoch: 24.8 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.043144398973834		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 2.043144398973834 | validation: 2.0377535903620867]
	TIME [epoch: 24.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.200054022848875		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 2.200054022848875 | validation: 1.8459062552865402]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_125.pth
	Model improved!!!
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9559444923208873		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 1.9559444923208873 | validation: 2.635588568820308]
	TIME [epoch: 24.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0684833636516875		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 2.0684833636516875 | validation: 1.781844937220782]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_127.pth
	Model improved!!!
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0105435980606785		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 2.0105435980606785 | validation: 1.9079745957846082]
	TIME [epoch: 24.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7966661620398803		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 1.7966661620398803 | validation: 2.390181007635975]
	TIME [epoch: 24.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8009323840257765		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 1.8009323840257765 | validation: 2.1909124802009545]
	TIME [epoch: 24.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.417253117457439		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 2.417253117457439 | validation: 2.604861122150714]
	TIME [epoch: 24.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1178892993568312		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 2.1178892993568312 | validation: 1.437683031797705]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_132.pth
	Model improved!!!
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4215180823842046		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 2.4215180823842046 | validation: 1.2589684320117736]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.311117557910759		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 1.311117557910759 | validation: 1.8329459750767672]
	TIME [epoch: 24.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4382686624519287		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 1.4382686624519287 | validation: 1.7892141343800854]
	TIME [epoch: 24.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4087551221803762		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 1.4087551221803762 | validation: 1.980520811358511]
	TIME [epoch: 24.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5768261827826		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 1.5768261827826 | validation: 1.0428470598031705]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_137.pth
	Model improved!!!
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0199716823637952		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 1.0199716823637952 | validation: 2.1083816116117684]
	TIME [epoch: 24.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2147233339821875		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 1.2147233339821875 | validation: 4.801007928124235]
	TIME [epoch: 24.7 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9721772113204121		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 1.9721772113204121 | validation: 0.8741453167337011]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_140.pth
	Model improved!!!
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9789436109021246		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 0.9789436109021246 | validation: 1.2554978952704035]
	TIME [epoch: 24.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9415518361505844		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 1.9415518361505844 | validation: 2.1098420853933586]
	TIME [epoch: 24.7 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3529769353290269		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 1.3529769353290269 | validation: 1.1052151437674136]
	TIME [epoch: 24.7 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9739308176706222		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 0.9739308176706222 | validation: 1.303938545792906]
	TIME [epoch: 24.8 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3260658741195144		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 1.3260658741195144 | validation: 0.8688459899350275]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7368329187581717		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 1.7368329187581717 | validation: 1.2360589086926115]
	TIME [epoch: 24.7 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1180705151067554		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 1.1180705151067554 | validation: 0.9058477557326708]
	TIME [epoch: 24.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0151804150359642		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 1.0151804150359642 | validation: 0.8797642163396114]
	TIME [epoch: 24.7 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1355674457681992		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 1.1355674457681992 | validation: 0.9511258829040168]
	TIME [epoch: 24.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.410924462247513		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.410924462247513 | validation: 1.351429772725754]
	TIME [epoch: 24.8 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3312984163479913		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 1.3312984163479913 | validation: 1.10009558714948]
	TIME [epoch: 24.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1385475102241291		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 1.1385475102241291 | validation: 2.2630393128857786]
	TIME [epoch: 24.8 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6663061462722317		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 1.6663061462722317 | validation: 1.125435241284197]
	TIME [epoch: 24.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2743702834710016		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.2743702834710016 | validation: 3.4450577180891724]
	TIME [epoch: 24.7 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5886651117571216		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 3.5886651117571216 | validation: 3.198512851098293]
	TIME [epoch: 24.7 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3497195451341772		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 3.3497195451341772 | validation: 3.8326181489116595]
	TIME [epoch: 24.8 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7236715931694064		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 3.7236715931694064 | validation: 3.557009826326689]
	TIME [epoch: 24.7 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.421950345056291		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 4.421950345056291 | validation: 3.61227070178453]
	TIME [epoch: 24.7 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.511175333913105		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 3.511175333913105 | validation: 3.066500970916688]
	TIME [epoch: 24.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.393487399485098		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 3.393487399485098 | validation: 3.4573234577185747]
	TIME [epoch: 24.7 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4735826619614625		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 3.4735826619614625 | validation: 3.036821231266438]
	TIME [epoch: 24.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.300861159599161		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 3.300861159599161 | validation: 3.014999214268338]
	TIME [epoch: 24.8 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.338482147838083		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 3.338482147838083 | validation: 2.99204601100886]
	TIME [epoch: 24.7 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.269393785116874		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 3.269393785116874 | validation: 2.977990233968689]
	TIME [epoch: 24.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.246235047321992		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.246235047321992 | validation: 2.951099835703617]
	TIME [epoch: 24.8 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2347199829583486		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.2347199829583486 | validation: 2.9217726930931622]
	TIME [epoch: 24.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2378804026902195		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 3.2378804026902195 | validation: 3.3183081916332187]
	TIME [epoch: 24.8 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4749785596438585		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 3.4749785596438585 | validation: 3.154919383079752]
	TIME [epoch: 24.8 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.196775687672186		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 4.196775687672186 | validation: 4.8693721485550325]
	TIME [epoch: 24.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.137156584561019		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 4.137156584561019 | validation: 3.3624039316996632]
	TIME [epoch: 24.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4045314037688046		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 3.4045314037688046 | validation: 2.898995506347146]
	TIME [epoch: 24.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7714120248424274		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 3.7714120248424274 | validation: 5.4824401649552374]
	TIME [epoch: 24.7 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.236906466874102		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 6.236906466874102 | validation: 4.447459230772901]
	TIME [epoch: 24.8 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.471916145286063		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 4.471916145286063 | validation: 3.8457862929781097]
	TIME [epoch: 24.8 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.329963927299742		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 4.329963927299742 | validation: 3.7601403655552565]
	TIME [epoch: 24.7 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.0390799709849015		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 4.0390799709849015 | validation: 4.353512904888389]
	TIME [epoch: 24.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.875864352485678		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 4.875864352485678 | validation: 4.097755173030758]
	TIME [epoch: 24.8 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.1754867842113885		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 4.1754867842113885 | validation: 3.112792543761922]
	TIME [epoch: 24.7 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.39369638356258		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 3.39369638356258 | validation: 3.1141709221363265]
	TIME [epoch: 24.8 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5785636417006432		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 3.5785636417006432 | validation: 3.1933405667853525]
	TIME [epoch: 24.8 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3952308683109345		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 3.3952308683109345 | validation: 3.0463408964265817]
	TIME [epoch: 24.7 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3072838442168484		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 3.3072838442168484 | validation: 2.981013891745813]
	TIME [epoch: 24.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.299155763806658		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 3.299155763806658 | validation: 2.952490681015474]
	TIME [epoch: 24.7 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4516874894280316		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 3.4516874894280316 | validation: 3.2179397980608235]
	TIME [epoch: 24.7 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3454465844301358		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 3.3454465844301358 | validation: 3.1183284451692272]
	TIME [epoch: 24.8 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3130914474554003		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.3130914474554003 | validation: 2.9432522822702256]
	TIME [epoch: 24.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.357575401764719		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 3.357575401764719 | validation: 3.511899696062065]
	TIME [epoch: 24.7 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5543319824793627		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.5543319824793627 | validation: 3.106917532854934]
	TIME [epoch: 24.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3033607239065437		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 3.3033607239065437 | validation: 2.9673625821402356]
	TIME [epoch: 24.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3259634376272618		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 3.3259634376272618 | validation: 3.172133174138654]
	TIME [epoch: 24.7 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4247768941492107		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 3.4247768941492107 | validation: 3.0642946368649637]
	TIME [epoch: 24.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.528103058397979		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 3.528103058397979 | validation: 4.305337386238619]
	TIME [epoch: 24.7 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.122334857279952		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 4.122334857279952 | validation: 4.065870373367012]
	TIME [epoch: 24.7 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8804271622037465		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 3.8804271622037465 | validation: 3.203399236156089]
	TIME [epoch: 24.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5667592755292454		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 3.5667592755292454 | validation: 3.0601480490176556]
	TIME [epoch: 24.7 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.48181772454455		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 3.48181772454455 | validation: 3.139303644261347]
	TIME [epoch: 24.7 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4045743686558714		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 3.4045743686558714 | validation: 3.1324281824718776]
	TIME [epoch: 24.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3466765524688418		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 3.3466765524688418 | validation: 3.0004046863259575]
	TIME [epoch: 24.7 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.667255097307284		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 3.667255097307284 | validation: 3.919803802943324]
	TIME [epoch: 24.7 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6394220485382633		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 3.6394220485382633 | validation: 3.225989493069396]
	TIME [epoch: 24.8 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5750817868426106		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 3.5750817868426106 | validation: 3.359625825276563]
	TIME [epoch: 24.7 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.472466336525238		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 3.472466336525238 | validation: 3.310690773046703]
	TIME [epoch: 24.7 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.582185113660968		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 3.582185113660968 | validation: 3.6011645867035766]
	TIME [epoch: 24.8 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.314780477620387		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 4.314780477620387 | validation: 3.3863797363931463]
	TIME [epoch: 24.7 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.640255527744439		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 3.640255527744439 | validation: 3.197390500932935]
	TIME [epoch: 24.7 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4384019400213903		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 3.4384019400213903 | validation: 3.0767469870645288]
	TIME [epoch: 24.8 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3743109794485235		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 3.3743109794485235 | validation: 3.0272800129301376]
	TIME [epoch: 24.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3108924336188137		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 3.3108924336188137 | validation: 3.050487091929909]
	TIME [epoch: 24.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2973667864726455		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 3.2973667864726455 | validation: 2.9838026774226867]
	TIME [epoch: 24.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3492043398241456		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 3.3492043398241456 | validation: 3.1944246493949144]
	TIME [epoch: 24.7 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4693614791448657		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 3.4693614791448657 | validation: 3.1479998823071735]
	TIME [epoch: 24.8 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.328081961694939		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 3.328081961694939 | validation: 3.080763841822151]
	TIME [epoch: 24.8 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.318888472752179		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 3.318888472752179 | validation: 3.0051012017143113]
	TIME [epoch: 24.7 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2684678140586305		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 3.2684678140586305 | validation: 3.1387849598569906]
	TIME [epoch: 24.7 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2761916768515125		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 3.2761916768515125 | validation: 2.951113489379782]
	TIME [epoch: 24.8 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.215778383336917		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 3.215778383336917 | validation: 2.9495787679619627]
	TIME [epoch: 24.7 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302509481581453		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 3.302509481581453 | validation: 3.3302873164423286]
	TIME [epoch: 24.8 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4407304695610508		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 3.4407304695610508 | validation: 3.091333487720923]
	TIME [epoch: 24.8 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3453080114575378		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 3.3453080114575378 | validation: 2.9995127746039127]
	TIME [epoch: 24.7 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2322489396403515		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 3.2322489396403515 | validation: 2.9938717922598608]
	TIME [epoch: 24.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2467094634474587		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 3.2467094634474587 | validation: 2.9290389191127075]
	TIME [epoch: 24.8 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2235830556412903		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 3.2235830556412903 | validation: 3.0087465848766954]
	TIME [epoch: 24.7 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.23339591066676		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 3.23339591066676 | validation: 2.9815946996483023]
	TIME [epoch: 24.8 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2145457018813164		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 3.2145457018813164 | validation: 3.0313612307869655]
	TIME [epoch: 24.8 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2465675250042363		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 3.2465675250042363 | validation: 2.9548074530728186]
	TIME [epoch: 24.7 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1992302055768684		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 3.1992302055768684 | validation: 2.9986173214539087]
	TIME [epoch: 24.8 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244425198873115		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 3.244425198873115 | validation: 3.122256878521799]
	TIME [epoch: 24.8 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.291657212397743		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 3.291657212397743 | validation: 2.9523994862704606]
	TIME [epoch: 24.7 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239525731161369		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 3.239525731161369 | validation: 3.150435313246268]
	TIME [epoch: 24.8 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.579946788968396		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 3.579946788968396 | validation: 2.988893729859779]
	TIME [epoch: 24.8 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.222849101345397		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 3.222849101345397 | validation: 2.9549729190954372]
	TIME [epoch: 24.7 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1966768884177563		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 3.1966768884177563 | validation: 2.928261982955194]
	TIME [epoch: 24.8 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3029964116266335		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 3.3029964116266335 | validation: 3.3446240638289475]
	TIME [epoch: 24.8 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.696150487627132		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 3.696150487627132 | validation: 3.0613661848475853]
	TIME [epoch: 24.7 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.278155586155926		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 3.278155586155926 | validation: 2.916317387866645]
	TIME [epoch: 24.8 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4846674554884145		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 3.4846674554884145 | validation: 4.826079931821974]
	TIME [epoch: 24.8 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.528720186428012		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 4.528720186428012 | validation: 3.418086433181413]
	TIME [epoch: 24.7 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3963391543972294		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 3.3963391543972294 | validation: 3.0324663581415616]
	TIME [epoch: 24.8 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.311995841607221		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 3.311995841607221 | validation: 2.9931955033062425]
	TIME [epoch: 24.8 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.313515033829832		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 3.313515033829832 | validation: 2.9744851644000527]
	TIME [epoch: 24.7 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2985478617081037		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 3.2985478617081037 | validation: 2.9502585521972398]
	TIME [epoch: 24.8 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2475393206942185		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 3.2475393206942185 | validation: 2.9275540231860364]
	TIME [epoch: 24.8 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.244693545173288		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 3.244693545173288 | validation: 2.9107146257422563]
	TIME [epoch: 24.7 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2153166079319755		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 3.2153166079319755 | validation: 2.9033028765563595]
	TIME [epoch: 24.8 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2227299320079825		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 3.2227299320079825 | validation: 2.9935372957798285]
	TIME [epoch: 24.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.275735718644552		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 3.275735718644552 | validation: 2.9309394712599794]
	TIME [epoch: 24.7 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.306495393127544		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 3.306495393127544 | validation: 3.6170996667112196]
	TIME [epoch: 24.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.941400470359245		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 4.941400470359245 | validation: 5.368100319326287]
	TIME [epoch: 24.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.87106867832687		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 4.87106867832687 | validation: 3.800130970581632]
	TIME [epoch: 24.7 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.652915363806785		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 4.652915363806785 | validation: 4.20210969398691]
	TIME [epoch: 24.8 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.918389441566213		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 3.918389441566213 | validation: 3.2162550774559096]
	TIME [epoch: 24.8 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.507128263749972		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 3.507128263749972 | validation: 3.2510288845801596]
	TIME [epoch: 24.7 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3487587538620267		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 3.3487587538620267 | validation: 3.1085988005332514]
	TIME [epoch: 24.8 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8264292476270327		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 3.8264292476270327 | validation: 3.1191351680491675]
	TIME [epoch: 24.8 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.404808543407105		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 3.404808543407105 | validation: 3.1027179655463786]
	TIME [epoch: 24.7 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4122665613609806		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 3.4122665613609806 | validation: 3.385450638260412]
	TIME [epoch: 24.8 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.581257514502175		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 3.581257514502175 | validation: 3.146372393219578]
	TIME [epoch: 24.7 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4836355825331875		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 3.4836355825331875 | validation: 3.1150482598626787]
	TIME [epoch: 24.8 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5582510407962227		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 3.5582510407962227 | validation: 3.117659949237577]
	TIME [epoch: 24.8 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.433603614476577		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 3.433603614476577 | validation: 3.205891875566901]
	TIME [epoch: 24.7 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.450406896463188		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 3.450406896463188 | validation: 3.0834559111720625]
	TIME [epoch: 24.7 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4747926807451113		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 3.4747926807451113 | validation: 3.0938739885857816]
	TIME [epoch: 24.8 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.441872555761171		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 3.441872555761171 | validation: 3.10802759499363]
	TIME [epoch: 24.7 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4115182885249244		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 3.4115182885249244 | validation: 3.0898483124578675]
	TIME [epoch: 24.7 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.523170329058863		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 3.523170329058863 | validation: 5.401916281082664]
	TIME [epoch: 24.8 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.766329134842295		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 4.766329134842295 | validation: 3.5393757990893566]
	TIME [epoch: 24.8 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3784548438029796		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 3.3784548438029796 | validation: 3.143892508220819]
	TIME [epoch: 24.7 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.988100009345291		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 2.988100009345291 | validation: 3.732654892571842]
	TIME [epoch: 24.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8584386872768777		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 3.8584386872768777 | validation: 3.3004801694080514]
	TIME [epoch: 24.7 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4077756287095156		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 3.4077756287095156 | validation: 3.0427981364643717]
	TIME [epoch: 24.7 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3469048730623165		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 3.3469048730623165 | validation: 3.0548207490062156]
	TIME [epoch: 24.8 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3522516824894493		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 3.3522516824894493 | validation: 3.051550712164561]
	TIME [epoch: 24.7 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8102224863960554		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 3.8102224863960554 | validation: 3.084877071329272]
	TIME [epoch: 24.7 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.436692824271754		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 3.436692824271754 | validation: 3.073476859137394]
	TIME [epoch: 24.8 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4681450329288084		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 3.4681450329288084 | validation: 3.1274640261702995]
	TIME [epoch: 24.7 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.376533135176212		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 3.376533135176212 | validation: 3.0369295021440963]
	TIME [epoch: 24.8 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.317078550320698		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 3.317078550320698 | validation: 3.0773226354301855]
	TIME [epoch: 24.8 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3918597837997946		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 3.3918597837997946 | validation: 3.0134259579797416]
	TIME [epoch: 24.7 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3585293731555144		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 3.3585293731555144 | validation: 3.079633667001545]
	TIME [epoch: 24.8 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3843745167139		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 3.3843745167139 | validation: 3.062051344395617]
	TIME [epoch: 24.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6263046992622723		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 3.6263046992622723 | validation: 3.6292544032113256]
	TIME [epoch: 24.7 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.239949982541124		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 3.239949982541124 | validation: 2.8126102814413723]
	TIME [epoch: 24.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1556013752858885		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 3.1556013752858885 | validation: 3.424871114436081]
	TIME [epoch: 24.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4894216982767574		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 3.4894216982767574 | validation: 3.0947940184301057]
	TIME [epoch: 24.7 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3958886508871653		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 3.3958886508871653 | validation: 3.11331226718869]
	TIME [epoch: 24.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3981383467069888		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 3.3981383467069888 | validation: 3.0895358984183288]
	TIME [epoch: 24.8 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5326939064806266		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 3.5326939064806266 | validation: 3.233243699410757]
	TIME [epoch: 24.7 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.446906874084466		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 3.446906874084466 | validation: 3.083267122529101]
	TIME [epoch: 24.8 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3832978373446023		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 3.3832978373446023 | validation: 3.038824060896615]
	TIME [epoch: 24.8 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5404449726981118		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 3.5404449726981118 | validation: 3.549587167257499]
	TIME [epoch: 24.7 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.493629256977044		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 3.493629256977044 | validation: 2.885770811171027]
	TIME [epoch: 24.7 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.123585870559051		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 3.123585870559051 | validation: 2.799273387094431]
	TIME [epoch: 24.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1897800668899636		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 3.1897800668899636 | validation: 2.659998334485402]
	TIME [epoch: 24.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.562798521818591		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 2.562798521818591 | validation: 1.7671894917039572]
	TIME [epoch: 24.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.454221653974511		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 1.454221653974511 | validation: 0.8800781391230306]
	TIME [epoch: 24.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3174049502567624		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 1.3174049502567624 | validation: 1.2492084655023334]
	TIME [epoch: 24.7 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.055716910200764		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 1.055716910200764 | validation: 0.7967228050334584]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_297.pth
	Model improved!!!
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9868415855133723		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 1.9868415855133723 | validation: 3.17769006995777]
	TIME [epoch: 24.7 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.305141584226372		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 3.305141584226372 | validation: 2.988248095829782]
	TIME [epoch: 24.7 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2117988285087598		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 3.2117988285087598 | validation: 3.0901577229356993]
	TIME [epoch: 24.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3677293986823993		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 3.3677293986823993 | validation: 3.1602274934582524]
	TIME [epoch: 24.7 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5461688815565635		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 3.5461688815565635 | validation: 3.1285753005685195]
	TIME [epoch: 24.7 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.394194401500211		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 3.394194401500211 | validation: 2.619604283423044]
	TIME [epoch: 24.7 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8222346274091548		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 1.8222346274091548 | validation: 0.9428974290598857]
	TIME [epoch: 24.7 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1330376919644154		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 1.1330376919644154 | validation: 0.8048231767057871]
	TIME [epoch: 24.7 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7303074382564474		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 2.7303074382564474 | validation: 2.5476612468818325]
	TIME [epoch: 24.7 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3793318528086695		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 1.3793318528086695 | validation: 0.8695375088911559]
	TIME [epoch: 24.8 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6205986171182198		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 1.6205986171182198 | validation: 2.8001166966762567]
	TIME [epoch: 24.7 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6808726960485578		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 1.6808726960485578 | validation: 0.8079182987934378]
	TIME [epoch: 24.7 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2991126256085603		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 1.2991126256085603 | validation: 1.12207035625717]
	TIME [epoch: 24.7 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9611114531580209		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 0.9611114531580209 | validation: 1.7473998132952062]
	TIME [epoch: 24.7 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2599548743999156		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.2599548743999156 | validation: 1.4000037286839273]
	TIME [epoch: 24.7 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.185641226559725		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 1.185641226559725 | validation: 0.7466508979442208]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_313.pth
	Model improved!!!
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8675915364895467		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.8675915364895467 | validation: 0.8814293646022201]
	TIME [epoch: 24.7 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8697616179411138		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.8697616179411138 | validation: 0.8261863778118863]
	TIME [epoch: 24.7 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0519173737918126		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 1.0519173737918126 | validation: 0.9708896836829612]
	TIME [epoch: 24.7 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4301234844061579		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.4301234844061579 | validation: 1.2347966008306752]
	TIME [epoch: 24.7 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2211664598725829		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 1.2211664598725829 | validation: 0.9823191725527026]
	TIME [epoch: 24.7 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0803492552128389		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 1.0803492552128389 | validation: 0.9650315704354558]
	TIME [epoch: 24.7 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1499617969375517		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 1.1499617969375517 | validation: 0.9501143556676146]
	TIME [epoch: 24.7 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.064365304812699		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 1.064365304812699 | validation: 1.268875228418528]
	TIME [epoch: 24.7 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1222245682879244		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 1.1222245682879244 | validation: 0.9804423765355488]
	TIME [epoch: 24.7 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3087356957637069		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 1.3087356957637069 | validation: 0.9322789918940724]
	TIME [epoch: 24.7 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0325902443234143		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 1.0325902443234143 | validation: 0.9437701701897362]
	TIME [epoch: 24.8 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0355799819919853		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 1.0355799819919853 | validation: 0.925780132834715]
	TIME [epoch: 24.7 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0749184248514019		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 1.0749184248514019 | validation: 0.8878698893784416]
	TIME [epoch: 24.7 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0128104103192777		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 1.0128104103192777 | validation: 0.9996420475106129]
	TIME [epoch: 24.8 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8930282899151685		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 2.8930282899151685 | validation: 3.561140805314037]
	TIME [epoch: 24.7 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7642586734012875		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 1.7642586734012875 | validation: 0.9734842849346796]
	TIME [epoch: 24.7 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0217186273630994		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 1.0217186273630994 | validation: 0.9033367264215858]
	TIME [epoch: 24.7 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9991887266098547		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.9991887266098547 | validation: 0.9402664524723638]
	TIME [epoch: 24.7 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.032352782159087		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 1.032352782159087 | validation: 0.8854119133842971]
	TIME [epoch: 24.7 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9731569246712405		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.9731569246712405 | validation: 0.8676953622506963]
	TIME [epoch: 24.7 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9737688734996246		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.9737688734996246 | validation: 0.8950160697534415]
	TIME [epoch: 24.7 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8883373179264374		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 0.8883373179264374 | validation: 0.7448451120419319]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_335.pth
	Model improved!!!
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.820592548923202		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.820592548923202 | validation: 1.0508069921976169]
	TIME [epoch: 24.7 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2485476442119794		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 1.2485476442119794 | validation: 0.9543537331140604]
	TIME [epoch: 24.7 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9533662829431111		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.9533662829431111 | validation: 0.9061187743138325]
	TIME [epoch: 24.7 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9959703461629735		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 0.9959703461629735 | validation: 0.8884148077294707]
	TIME [epoch: 24.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9759222446435069		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.9759222446435069 | validation: 1.0098055835632282]
	TIME [epoch: 24.7 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0173145726118018		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 1.0173145726118018 | validation: 0.8863236026192951]
	TIME [epoch: 24.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.275389399681238		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 1.275389399681238 | validation: 0.9812087350972248]
	TIME [epoch: 24.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0295423609624084		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 1.0295423609624084 | validation: 0.9590647041786744]
	TIME [epoch: 24.7 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9933706555089514		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 0.9933706555089514 | validation: 0.8841666545186831]
	TIME [epoch: 24.7 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8695658258306818		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.8695658258306818 | validation: 0.7246879611885677]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_345.pth
	Model improved!!!
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7733999052089588		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.7733999052089588 | validation: 1.000532154155447]
	TIME [epoch: 24.7 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3878263434371894		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 1.3878263434371894 | validation: 1.0694234088784573]
	TIME [epoch: 24.7 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0473993051357235		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.0473993051357235 | validation: 0.9269516628961693]
	TIME [epoch: 24.8 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9693835257300577		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 0.9693835257300577 | validation: 0.9240028318743599]
	TIME [epoch: 24.7 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9739390401742769		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.9739390401742769 | validation: 0.9450857111717161]
	TIME [epoch: 24.7 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0155376457145882		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.0155376457145882 | validation: 0.9116154047922084]
	TIME [epoch: 24.8 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.004066031357603		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.004066031357603 | validation: 0.9143893608578063]
	TIME [epoch: 24.7 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9415728396719844		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 0.9415728396719844 | validation: 0.8536654374139524]
	TIME [epoch: 24.7 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9448223034787284		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.9448223034787284 | validation: 0.9448674296994639]
	TIME [epoch: 24.8 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0310560927901338		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.0310560927901338 | validation: 0.7618687364685102]
	TIME [epoch: 24.8 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7136353750566612		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 0.7136353750566612 | validation: 1.0330689378425053]
	TIME [epoch: 24.7 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8304708770224576		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.8304708770224576 | validation: 0.8455574511883965]
	TIME [epoch: 24.8 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6699389434867393		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.6699389434867393 | validation: 0.8319598996993611]
	TIME [epoch: 24.7 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8995553794093998		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.8995553794093998 | validation: 0.7870832834591951]
	TIME [epoch: 24.7 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7506274551542511		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.7506274551542511 | validation: 0.9006845167600182]
	TIME [epoch: 24.8 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.855451398403626		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 0.855451398403626 | validation: 0.7775417253019103]
	TIME [epoch: 24.7 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8366275721391375		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 0.8366275721391375 | validation: 0.8368333121709042]
	TIME [epoch: 24.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8916690303940218		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 0.8916690303940218 | validation: 1.1324732269976563]
	TIME [epoch: 24.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8094032919334029		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 0.8094032919334029 | validation: 0.6564587594158318]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_364.pth
	Model improved!!!
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6127712953986446		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 0.6127712953986446 | validation: 0.7284748892163141]
	TIME [epoch: 24.7 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8628183207864193		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 0.8628183207864193 | validation: 0.7277172916851095]
	TIME [epoch: 24.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6556737694440538		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 0.6556737694440538 | validation: 0.8667117358154239]
	TIME [epoch: 24.7 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7290728853562309		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 0.7290728853562309 | validation: 0.7552949888734424]
	TIME [epoch: 24.7 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6488106367948936		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 0.6488106367948936 | validation: 0.696545308999968]
	TIME [epoch: 24.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7340082314885555		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 0.7340082314885555 | validation: 0.8607332370066993]
	TIME [epoch: 24.7 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.854956722995307		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 0.854956722995307 | validation: 0.8016887876925219]
	TIME [epoch: 24.8 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6857018792251375		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 0.6857018792251375 | validation: 0.9514741368387104]
	TIME [epoch: 24.8 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7070343861363264		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 0.7070343861363264 | validation: 0.7193313070463043]
	TIME [epoch: 24.7 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7014529757376968		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 0.7014529757376968 | validation: 0.7179710285289173]
	TIME [epoch: 24.7 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.755663826582443		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 0.755663826582443 | validation: 0.8910596984664776]
	TIME [epoch: 24.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9925192596899476		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 0.9925192596899476 | validation: 1.50786462358606]
	TIME [epoch: 24.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8296396456056371		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 0.8296396456056371 | validation: 0.7522406479407255]
	TIME [epoch: 24.7 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7459344077489464		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 0.7459344077489464 | validation: 0.8625785625530341]
	TIME [epoch: 24.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9177075396495965		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 0.9177075396495965 | validation: 0.8498975399186123]
	TIME [epoch: 24.7 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7386096457518987		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 0.7386096457518987 | validation: 0.6433532577189037]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_380.pth
	Model improved!!!
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5653262075559264		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 0.5653262075559264 | validation: 0.5875217259785763]
	TIME [epoch: 24.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_381.pth
	Model improved!!!
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.588317057362694		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 0.588317057362694 | validation: 0.6965734588221913]
	TIME [epoch: 24.7 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6521773374312289		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 0.6521773374312289 | validation: 0.7768487937773987]
	TIME [epoch: 24.7 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6316965493315067		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 0.6316965493315067 | validation: 0.6070451132029844]
	TIME [epoch: 24.7 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5854575200390442		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 0.5854575200390442 | validation: 0.6917640497947004]
	TIME [epoch: 24.7 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6931054852261369		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 0.6931054852261369 | validation: 0.6895105690674774]
	TIME [epoch: 24.7 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6470665670562229		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 0.6470665670562229 | validation: 0.6581377196035402]
	TIME [epoch: 24.7 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.464282985974427		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 1.464282985974427 | validation: 1.5318244067531424]
	TIME [epoch: 24.7 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7887861409427244		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 0.7887861409427244 | validation: 0.8070599814724047]
	TIME [epoch: 24.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0617266147628541		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 1.0617266147628541 | validation: 1.6378705786363508]
	TIME [epoch: 24.7 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3740766122351373		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 1.3740766122351373 | validation: 0.711336038063297]
	TIME [epoch: 24.7 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7520819983870735		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 0.7520819983870735 | validation: 0.6310224431546477]
	TIME [epoch: 24.7 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9529225853687252		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 0.9529225853687252 | validation: 0.9547390767142662]
	TIME [epoch: 24.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7980866358673381		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 0.7980866358673381 | validation: 0.8221507990965037]
	TIME [epoch: 24.7 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7758272833186426		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 0.7758272833186426 | validation: 0.806591572525871]
	TIME [epoch: 24.7 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6462775745916035		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 0.6462775745916035 | validation: 0.5910606545826126]
	TIME [epoch: 24.7 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7601250091738708		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 0.7601250091738708 | validation: 0.745641749614114]
	TIME [epoch: 24.7 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6461795570457001		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 0.6461795570457001 | validation: 0.6254367594481306]
	TIME [epoch: 24.7 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7144371498882902		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 0.7144371498882902 | validation: 0.6307546380724459]
	TIME [epoch: 24.7 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6034329752147137		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 0.6034329752147137 | validation: 0.8263470594550492]
	TIME [epoch: 24.7 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7771907239104016		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 0.7771907239104016 | validation: 0.6010587312515923]
	TIME [epoch: 24.7 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5585495225602413		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 0.5585495225602413 | validation: 0.7628086580370349]
	TIME [epoch: 24.7 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7092327314672826		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 0.7092327314672826 | validation: 0.6711979775962172]
	TIME [epoch: 24.7 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.979276400340957		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 1.979276400340957 | validation: 3.2976614998235143]
	TIME [epoch: 24.7 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.553664843707004		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 3.553664843707004 | validation: 2.961539070452796]
	TIME [epoch: 24.7 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4211266020671913		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 3.4211266020671913 | validation: 3.1141587921652776]
	TIME [epoch: 24.7 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.610800457841237		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 3.610800457841237 | validation: 3.22725558347894]
	TIME [epoch: 24.7 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5814510952010647		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 3.5814510952010647 | validation: 3.069054062524131]
	TIME [epoch: 24.7 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.251858362303006		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 3.251858362303006 | validation: 2.8998979208556]
	TIME [epoch: 24.7 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2839259249071304		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 3.2839259249071304 | validation: 3.044080057516993]
	TIME [epoch: 24.7 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.240356439519513		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 3.240356439519513 | validation: 2.929644613888429]
	TIME [epoch: 24.7 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.180302029415966		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 3.180302029415966 | validation: 2.930798129808725]
	TIME [epoch: 24.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1729236704128696		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 3.1729236704128696 | validation: 2.8735783139522]
	TIME [epoch: 24.7 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1650584933411032		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 3.1650584933411032 | validation: 2.893026375789426]
	TIME [epoch: 24.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.201123039819338		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 3.201123039819338 | validation: 3.1454350267484483]
	TIME [epoch: 24.7 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.523257073565604		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 3.523257073565604 | validation: 3.8263284102105413]
	TIME [epoch: 24.7 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.398102288932348		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 4.398102288932348 | validation: 3.7655976239446414]
	TIME [epoch: 24.7 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6982195833767384		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 3.6982195833767384 | validation: 2.9741875398367386]
	TIME [epoch: 24.7 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.231752433871674		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 3.231752433871674 | validation: 2.9723773375259337]
	TIME [epoch: 24.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5818714285962363		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 3.5818714285962363 | validation: 3.5123577360728326]
	TIME [epoch: 24.7 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.476518213436679		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 3.476518213436679 | validation: 2.9081290850468107]
	TIME [epoch: 24.7 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2096624526477		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 3.2096624526477 | validation: 2.951918029903445]
	TIME [epoch: 24.7 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3975068872928023		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 3.3975068872928023 | validation: 3.3029543960029253]
	TIME [epoch: 24.7 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.328311796323378		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 3.328311796323378 | validation: 2.9342813097492946]
	TIME [epoch: 24.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3881375412860835		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 3.3881375412860835 | validation: 3.035842031603149]
	TIME [epoch: 24.7 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3163223258283487		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 3.3163223258283487 | validation: 2.9381868035719707]
	TIME [epoch: 24.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3393576848747157		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 3.3393576848747157 | validation: 3.403816007101743]
	TIME [epoch: 24.7 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.651423438900465		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 3.651423438900465 | validation: 3.089911005710694]
	TIME [epoch: 24.7 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3696487888111157		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 3.3696487888111157 | validation: 3.0588702618390733]
	TIME [epoch: 24.7 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3348214714254287		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 3.3348214714254287 | validation: 3.0091017659796986]
	TIME [epoch: 24.7 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4115219677808435		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 3.4115219677808435 | validation: 3.063085864434986]
	TIME [epoch: 24.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3652394298746837		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 3.3652394298746837 | validation: 3.0302248565469903]
	TIME [epoch: 24.7 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.374044615325261		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 3.374044615325261 | validation: 3.1631524384240812]
	TIME [epoch: 24.7 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.344466462787611		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 3.344466462787611 | validation: 2.99046803952427]
	TIME [epoch: 24.7 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2846156623039446		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 3.2846156623039446 | validation: 2.9616792045576084]
	TIME [epoch: 24.7 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2650851667796426		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 3.2650851667796426 | validation: 3.037200693481848]
	TIME [epoch: 24.7 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.527807008846854		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 3.527807008846854 | validation: 3.2282610946606196]
	TIME [epoch: 24.7 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.468266397727297		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 3.468266397727297 | validation: 3.199354885608426]
	TIME [epoch: 24.7 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5438901092746766		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 3.5438901092746766 | validation: 3.6469040095427436]
	TIME [epoch: 24.7 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7903839256469882		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 3.7903839256469882 | validation: 3.01351384952579]
	TIME [epoch: 24.7 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.425139905848296		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 3.425139905848296 | validation: 3.334831725932224]
	TIME [epoch: 24.7 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4544378700267		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 3.4544378700267 | validation: 3.0221329677505615]
	TIME [epoch: 24.7 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.251617145611121		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 3.251617145611121 | validation: 2.9964731335167314]
	TIME [epoch: 24.7 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3936992093517517		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 3.3936992093517517 | validation: 3.476331707848747]
	TIME [epoch: 24.7 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6069107972487924		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 3.6069107972487924 | validation: 3.1641248690734107]
	TIME [epoch: 24.7 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3662371794683112		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 3.3662371794683112 | validation: 3.0626465346467833]
	TIME [epoch: 24.7 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4500139134643084		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 3.4500139134643084 | validation: 3.035326180371171]
	TIME [epoch: 24.7 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3302203829129295		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 3.3302203829129295 | validation: 2.9968092030796134]
	TIME [epoch: 24.7 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2964487171206		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 3.2964487171206 | validation: 3.038141448253353]
	TIME [epoch: 24.7 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2932101492633494		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 3.2932101492633494 | validation: 2.816667035899312]
	TIME [epoch: 24.7 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7970706146619757		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 2.7970706146619757 | validation: 3.2304528944728985]
	TIME [epoch: 24.7 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8060413122664727		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 1.8060413122664727 | validation: 1.0643223141925382]
	TIME [epoch: 24.7 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0614523769343416		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 1.0614523769343416 | validation: 1.073120339815764]
	TIME [epoch: 24.7 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0025811588320708		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.0025811588320708 | validation: 0.6892005542819581]
	TIME [epoch: 24.7 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7099989651049166		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.7099989651049166 | validation: 0.7403577773314669]
	TIME [epoch: 24.7 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.699323340632235		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.699323340632235 | validation: 0.7835928223731159]
	TIME [epoch: 24.7 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7373986387946333		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.7373986387946333 | validation: 0.5986596263497151]
	TIME [epoch: 24.7 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6243828055406494		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.6243828055406494 | validation: 0.5932532357961602]
	TIME [epoch: 24.7 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7337622566335329		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.7337622566335329 | validation: 0.7849874406463888]
	TIME [epoch: 24.7 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8827598435951192		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.8827598435951192 | validation: 0.7526252096697147]
	TIME [epoch: 24.7 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6817473007293761		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.6817473007293761 | validation: 0.6514676754234634]
	TIME [epoch: 24.7 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.694009042511852		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.694009042511852 | validation: 0.5090621189507504]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_462.pth
	Model improved!!!
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5120785163369437		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.5120785163369437 | validation: 0.5282726042297861]
	TIME [epoch: 24.7 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5227411672660076		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.5227411672660076 | validation: 0.5232553761320021]
	TIME [epoch: 24.7 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2154462868654363		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 1.2154462868654363 | validation: 0.7153389854243782]
	TIME [epoch: 24.7 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7133272594853793		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.7133272594853793 | validation: 0.5795426972832869]
	TIME [epoch: 24.7 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6457235420684586		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.6457235420684586 | validation: 0.711208818213358]
	TIME [epoch: 24.7 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5964042342161955		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.5964042342161955 | validation: 0.6171814179545033]
	TIME [epoch: 24.7 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6477401614199199		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.6477401614199199 | validation: 0.7210326603893725]
	TIME [epoch: 24.7 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6620543108111875		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.6620543108111875 | validation: 0.645210381627644]
	TIME [epoch: 24.7 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6148545320833394		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 0.6148545320833394 | validation: 0.6495498229185341]
	TIME [epoch: 24.7 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5771324992937705		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.5771324992937705 | validation: 0.5603729711530585]
	TIME [epoch: 24.7 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5831707473899286		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.5831707473899286 | validation: 0.9283816177229904]
	TIME [epoch: 24.7 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7351130129401265		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.7351130129401265 | validation: 0.5935179961989856]
	TIME [epoch: 24.7 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5048746732627036		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.5048746732627036 | validation: 0.6681730085144851]
	TIME [epoch: 24.7 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6048203119194023		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.6048203119194023 | validation: 0.571526888994989]
	TIME [epoch: 24.7 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.668880166030305		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 1.668880166030305 | validation: 1.6219394705412242]
	TIME [epoch: 24.7 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1399798497271547		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 1.1399798497271547 | validation: 0.8022847843053424]
	TIME [epoch: 24.7 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6436646199886161		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.6436646199886161 | validation: 0.7353282509491283]
	TIME [epoch: 24.7 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6000834080483032		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.6000834080483032 | validation: 0.5763196577757868]
	TIME [epoch: 24.7 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5814281217286469		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5814281217286469 | validation: 0.639503394282564]
	TIME [epoch: 24.7 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5425778702651961		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.5425778702651961 | validation: 0.5278725500543759]
	TIME [epoch: 24.7 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5332803327735369		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5332803327735369 | validation: 0.6375133556489585]
	TIME [epoch: 24.7 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6314028124183375		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 1.6314028124183375 | validation: 2.2976930343970348]
	TIME [epoch: 24.7 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6626861199893637		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 2.6626861199893637 | validation: 0.9637622084958807]
	TIME [epoch: 24.7 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7258454769448535		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.7258454769448535 | validation: 0.6721190318753173]
	TIME [epoch: 24.7 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5879703804045071		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.5879703804045071 | validation: 0.7055749498518276]
	TIME [epoch: 24.7 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9067840192800086		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.9067840192800086 | validation: 0.7629010401415641]
	TIME [epoch: 24.7 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9570277094126117		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.9570277094126117 | validation: 0.6499511466862058]
	TIME [epoch: 24.7 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5867690837596086		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.5867690837596086 | validation: 0.5666416879644137]
	TIME [epoch: 24.7 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6156790626369144		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.6156790626369144 | validation: 1.2770319283351506]
	TIME [epoch: 24.7 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0821024221488518		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 1.0821024221488518 | validation: 0.7495503527834342]
	TIME [epoch: 24.7 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6761516475428927		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.6761516475428927 | validation: 0.5718496557103794]
	TIME [epoch: 24.7 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6453018049079072		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 0.6453018049079072 | validation: 0.8654220412964619]
	TIME [epoch: 24.7 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8412477532403684		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.8412477532403684 | validation: 0.6470177094399588]
	TIME [epoch: 24.7 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5329863238036346		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.5329863238036346 | validation: 0.49474330681901607]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_496.pth
	Model improved!!!
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6683434887785458		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.6683434887785458 | validation: 0.5959281682357848]
	TIME [epoch: 24.7 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.545731991310728		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.545731991310728 | validation: 0.826904926869192]
	TIME [epoch: 24.7 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9105493133259166		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.9105493133259166 | validation: 1.4869890712723777]
	TIME [epoch: 24.7 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1951938176901304		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 1.1951938176901304 | validation: 0.6098724757269907]
	TIME [epoch: 24.7 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9590603007429592		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.9590603007429592 | validation: 0.8962649503620372]
	TIME [epoch: 24.7 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7580424793074884		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.7580424793074884 | validation: 0.8311494086407999]
	TIME [epoch: 24.7 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7433780275197781		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.7433780275197781 | validation: 0.6616625631707226]
	TIME [epoch: 24.7 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6701574201579101		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.6701574201579101 | validation: 0.6185013267313074]
	TIME [epoch: 24.7 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5669122313360522		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.5669122313360522 | validation: 0.5011146646096016]
	TIME [epoch: 24.7 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3381961635601476		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 1.3381961635601476 | validation: 1.0065664364079492]
	TIME [epoch: 24.7 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7869923133752074		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 0.7869923133752074 | validation: 1.0544053383706653]
	TIME [epoch: 24.7 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9480961018510812		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.9480961018510812 | validation: 1.5824644244678765]
	TIME [epoch: 24.7 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0958908202425377		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 1.0958908202425377 | validation: 0.8499097256008349]
	TIME [epoch: 24.7 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0972373910182378		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 1.0972373910182378 | validation: 0.677549113181742]
	TIME [epoch: 24.7 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5783709206451655		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.5783709206451655 | validation: 0.8582921146081068]
	TIME [epoch: 24.7 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1274627291530146		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 1.1274627291530146 | validation: 0.7103691482958849]
	TIME [epoch: 24.7 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6694069301667962		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.6694069301667962 | validation: 0.7468940228562392]
	TIME [epoch: 24.7 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7177694875877337		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.7177694875877337 | validation: 0.7075971997279842]
	TIME [epoch: 24.7 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7952914905126672		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.7952914905126672 | validation: 0.7335553721032976]
	TIME [epoch: 24.7 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6569947957432075		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.6569947957432075 | validation: 0.5883920889636961]
	TIME [epoch: 24.7 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7111731548168869		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.7111731548168869 | validation: 0.5862066161952955]
	TIME [epoch: 24.7 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.568477475129568		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.568477475129568 | validation: 0.5310275561781574]
	TIME [epoch: 24.8 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5989073960035143		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.5989073960035143 | validation: 1.8375236556522274]
	TIME [epoch: 24.8 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.121761926655699		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 2.121761926655699 | validation: 0.7382696753347199]
	TIME [epoch: 24.8 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.665754103185306		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.665754103185306 | validation: 0.5474809526419125]
	TIME [epoch: 24.7 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8599414502521321		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.8599414502521321 | validation: 1.3278964204586885]
	TIME [epoch: 24.8 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8713516073507436		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.8713516073507436 | validation: 0.7414235728238208]
	TIME [epoch: 24.7 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8766845539872726		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.8766845539872726 | validation: 0.5980809832982431]
	TIME [epoch: 24.7 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5736102195658745		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.5736102195658745 | validation: 0.597872324790582]
	TIME [epoch: 24.7 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6065808766617746		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 0.6065808766617746 | validation: 0.6847589151542465]
	TIME [epoch: 24.7 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.186756170934093		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 1.186756170934093 | validation: 0.789743357592614]
	TIME [epoch: 24.7 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7998750349094229		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.7998750349094229 | validation: 0.6337657637281794]
	TIME [epoch: 24.7 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6810355175499959		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.6810355175499959 | validation: 0.6291334797336033]
	TIME [epoch: 24.7 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8012249559681714		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.8012249559681714 | validation: 0.8093184465249212]
	TIME [epoch: 24.7 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7884175631033855		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.7884175631033855 | validation: 0.6926152695166613]
	TIME [epoch: 24.7 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7257567249957608		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.7257567249957608 | validation: 0.6724876793882433]
	TIME [epoch: 24.8 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6543019265707984		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.6543019265707984 | validation: 0.8579184652996509]
	TIME [epoch: 24.7 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8648289775928613		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.8648289775928613 | validation: 0.7417895863031342]
	TIME [epoch: 24.7 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6825597922588124		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.6825597922588124 | validation: 0.6606979987990921]
	TIME [epoch: 24.8 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6068198820256576		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.6068198820256576 | validation: 0.6323730587876373]
	TIME [epoch: 24.7 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6149698090599467		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.6149698090599467 | validation: 0.6123956377226244]
	TIME [epoch: 24.7 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5639808599660774		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.5639808599660774 | validation: 0.8451765032940025]
	TIME [epoch: 24.7 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.772326602066645		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.772326602066645 | validation: 0.9171867084709446]
	TIME [epoch: 24.7 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5575045854495106		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 1.5575045854495106 | validation: 0.747986352063964]
	TIME [epoch: 24.7 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6011111397064672		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.6011111397064672 | validation: 0.5555699871280984]
	TIME [epoch: 24.7 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5406353210585688		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.5406353210585688 | validation: 0.6685736514891246]
	TIME [epoch: 24.7 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5781733402737597		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.5781733402737597 | validation: 0.5958207047283343]
	TIME [epoch: 24.7 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5597494703660673		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.5597494703660673 | validation: 0.6388774234013255]
	TIME [epoch: 24.7 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5445718071572426		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.5445718071572426 | validation: 0.6119791803766716]
	TIME [epoch: 24.7 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8041799665933362		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.8041799665933362 | validation: 0.8437095505634948]
	TIME [epoch: 24.7 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8170198339228851		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.8170198339228851 | validation: 0.8094293141721147]
	TIME [epoch: 24.7 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8877790564855368		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.8877790564855368 | validation: 0.8163365255059387]
	TIME [epoch: 24.7 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8229438242386994		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.8229438242386994 | validation: 0.8334159476728377]
	TIME [epoch: 24.7 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7426639620415587		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.7426639620415587 | validation: 0.6172534446876884]
	TIME [epoch: 24.7 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7892908025263523		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.7892908025263523 | validation: 0.8407560055305863]
	TIME [epoch: 24.7 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8376859234424897		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.8376859234424897 | validation: 0.7489606878432754]
	TIME [epoch: 24.7 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7580287613742647		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 0.7580287613742647 | validation: 0.8242278616015488]
	TIME [epoch: 24.7 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6435816369661935		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.6435816369661935 | validation: 0.5559046963341768]
	TIME [epoch: 24.7 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5934838007206905		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.5934838007206905 | validation: 0.6279723914358395]
	TIME [epoch: 24.7 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5985361126949158		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.5985361126949158 | validation: 0.5918399584742281]
	TIME [epoch: 24.7 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6297307731565062		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.6297307731565062 | validation: 0.6276052025753869]
	TIME [epoch: 24.7 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.789725038267614		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.789725038267614 | validation: 1.787280286025624]
	TIME [epoch: 24.7 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.378924078296714		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 1.378924078296714 | validation: 1.071991478088945]
	TIME [epoch: 24.7 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.873596460051749		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.873596460051749 | validation: 0.8398285102239392]
	TIME [epoch: 24.7 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.712433145163075		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.712433145163075 | validation: 0.626828423005005]
	TIME [epoch: 24.7 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5784919924343742		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.5784919924343742 | validation: 0.6233752041128723]
	TIME [epoch: 24.7 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5820644321058606		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.5820644321058606 | validation: 0.5232779195577119]
	TIME [epoch: 24.7 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5861614648419592		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5861614648419592 | validation: 0.7012469585046464]
	TIME [epoch: 24.7 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6517215692096028		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.6517215692096028 | validation: 0.590825672014729]
	TIME [epoch: 24.7 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.510477552078532		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.510477552078532 | validation: 0.5451392940839302]
	TIME [epoch: 24.7 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5094148492498695		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.5094148492498695 | validation: 0.5189268370428544]
	TIME [epoch: 24.7 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4743483615907028		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.4743483615907028 | validation: 0.4939887298063827]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_568.pth
	Model improved!!!
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6009672867750853		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.6009672867750853 | validation: 1.6332401684204367]
	TIME [epoch: 24.7 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9988538119425816		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 1.9988538119425816 | validation: 1.664727690637152]
	TIME [epoch: 24.7 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2838975204051417		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 1.2838975204051417 | validation: 0.8635037821644028]
	TIME [epoch: 24.7 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8961975728335806		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.8961975728335806 | validation: 0.6925451831397663]
	TIME [epoch: 24.7 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6513673568880328		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.6513673568880328 | validation: 0.6692893741139495]
	TIME [epoch: 24.7 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6187660261323324		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.6187660261323324 | validation: 0.5687086828702463]
	TIME [epoch: 24.7 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5508634794652087		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.5508634794652087 | validation: 0.6253793739207879]
	TIME [epoch: 24.7 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6253999639326442		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.6253999639326442 | validation: 0.5675884428245138]
	TIME [epoch: 24.7 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.533775066536228		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.533775066536228 | validation: 0.5408465487575643]
	TIME [epoch: 24.7 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5673074355527772		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.5673074355527772 | validation: 0.609519906984171]
	TIME [epoch: 24.7 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6545837626469379		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.6545837626469379 | validation: 0.6047026512283027]
	TIME [epoch: 24.7 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6291442434470662		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.6291442434470662 | validation: 0.5719446673000801]
	TIME [epoch: 24.7 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5484238421476646		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.5484238421476646 | validation: 0.5931813617661056]
	TIME [epoch: 24.7 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5907238892940236		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.5907238892940236 | validation: 0.5348446995945402]
	TIME [epoch: 24.7 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5326859064082881		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.5326859064082881 | validation: 0.5794030288560001]
	TIME [epoch: 24.7 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5527828646348087		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.5527828646348087 | validation: 0.5766821462185477]
	TIME [epoch: 24.7 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5760636065780472		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.5760636065780472 | validation: 0.5683980395232875]
	TIME [epoch: 24.7 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5277655927566476		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.5277655927566476 | validation: 0.9844449343746027]
	TIME [epoch: 24.7 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5126199315793025		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 1.5126199315793025 | validation: 0.8436826275028126]
	TIME [epoch: 24.7 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8708845652325057		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.8708845652325057 | validation: 0.6445962928398481]
	TIME [epoch: 24.7 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5584748993492131		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.5584748993492131 | validation: 0.5967257184679141]
	TIME [epoch: 24.7 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9817724282972831		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.9817724282972831 | validation: 1.5762752485939098]
	TIME [epoch: 24.7 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0606250103434047		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 1.0606250103434047 | validation: 0.589849964522773]
	TIME [epoch: 24.7 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6791704463381005		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.6791704463381005 | validation: 0.5973685438005917]
	TIME [epoch: 24.7 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5946658036923589		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.5946658036923589 | validation: 0.6294198035502536]
	TIME [epoch: 24.7 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.827250109978996		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.827250109978996 | validation: 0.7433595844044868]
	TIME [epoch: 24.7 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7080072195833723		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.7080072195833723 | validation: 0.6111500414616647]
	TIME [epoch: 24.7 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0370704817462717		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 1.0370704817462717 | validation: 2.692856090944232]
	TIME [epoch: 24.7 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2924517350538967		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 2.2924517350538967 | validation: 1.806006016396245]
	TIME [epoch: 24.7 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5296860170891247		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 1.5296860170891247 | validation: 0.7386913175368122]
	TIME [epoch: 24.7 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.601237033310643		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.601237033310643 | validation: 0.5692532973470478]
	TIME [epoch: 24.7 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5197944054966078		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.5197944054966078 | validation: 0.7079273185755062]
	TIME [epoch: 24.7 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5864191568273358		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.5864191568273358 | validation: 0.6663359717365016]
	TIME [epoch: 24.7 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7373852832102741		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.7373852832102741 | validation: 0.6627585281545599]
	TIME [epoch: 24.7 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5473254911897321		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.5473254911897321 | validation: 0.5944856667225421]
	TIME [epoch: 24.7 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5322721228540358		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.5322721228540358 | validation: 0.5835713716144082]
	TIME [epoch: 24.7 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6519616312738252		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.6519616312738252 | validation: 0.6775564644507446]
	TIME [epoch: 24.7 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.567154027547128		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.567154027547128 | validation: 0.6347864590439465]
	TIME [epoch: 24.7 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6930710324691643		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.6930710324691643 | validation: 0.6718313417240321]
	TIME [epoch: 24.7 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.61070819248046		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.61070819248046 | validation: 0.584495629302375]
	TIME [epoch: 24.7 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5015855928885917		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.5015855928885917 | validation: 0.6882092779195241]
	TIME [epoch: 24.7 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.825753125686429		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.825753125686429 | validation: 1.5546182848807342]
	TIME [epoch: 24.7 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6677337557420078		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 2.6677337557420078 | validation: 3.1027610534163546]
	TIME [epoch: 24.7 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2924425144457174		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 3.2924425144457174 | validation: 3.04837751104324]
	TIME [epoch: 24.7 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4055809107735353		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 3.4055809107735353 | validation: 3.256912545267982]
	TIME [epoch: 24.7 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4723115844252055		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 3.4723115844252055 | validation: 3.026579979634638]
	TIME [epoch: 24.7 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2717718163150438		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 3.2717718163150438 | validation: 2.955309227125458]
	TIME [epoch: 24.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2632797711352906		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 3.2632797711352906 | validation: 3.140076581319444]
	TIME [epoch: 24.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.378118028711933		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 3.378118028711933 | validation: 2.9431114091796924]
	TIME [epoch: 24.7 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1967504622790757		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 3.1967504622790757 | validation: 2.904214208992729]
	TIME [epoch: 24.7 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.189274645651756		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 3.189274645651756 | validation: 3.040275611611843]
	TIME [epoch: 24.7 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.24025413797066		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 3.24025413797066 | validation: 2.9677396745188016]
	TIME [epoch: 24.7 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.156725891395824		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 3.156725891395824 | validation: 1.940758033853535]
	TIME [epoch: 24.7 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.524921026667086		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 1.524921026667086 | validation: 1.022296144202167]
	TIME [epoch: 24.7 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9247308327548395		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.9247308327548395 | validation: 0.8551869517634141]
	TIME [epoch: 24.7 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1082350432323311		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 1.1082350432323311 | validation: 0.959761895513137]
	TIME [epoch: 24.7 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7190236649209581		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.7190236649209581 | validation: 0.6900435990102289]
	TIME [epoch: 24.7 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5785559290772002		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.5785559290772002 | validation: 0.550851599031833]
	TIME [epoch: 24.7 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5534727907848748		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.5534727907848748 | validation: 0.5485175038458631]
	TIME [epoch: 24.7 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6046085478209415		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.6046085478209415 | validation: 0.5596126550362195]
	TIME [epoch: 24.7 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5138475976719565		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.5138475976719565 | validation: 0.555824188135581]
	TIME [epoch: 24.7 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48567717604929495		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.48567717604929495 | validation: 0.5185768300818225]
	TIME [epoch: 24.7 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5261122036902828		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.5261122036902828 | validation: 0.551571585014231]
	TIME [epoch: 24.7 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5929613773760963		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.5929613773760963 | validation: 0.7033340273740515]
	TIME [epoch: 24.7 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.022219215572702		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 1.022219215572702 | validation: 0.8838547780005308]
	TIME [epoch: 24.7 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6528154488201034		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.6528154488201034 | validation: 0.8949575228122941]
	TIME [epoch: 24.7 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8765995571282507		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.8765995571282507 | validation: 0.647359210774831]
	TIME [epoch: 24.7 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5394045051304868		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.5394045051304868 | validation: 0.487223259670493]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_636.pth
	Model improved!!!
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4715138970406524		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.4715138970406524 | validation: 0.5597394362928573]
	TIME [epoch: 24.7 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8921030864105709		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.8921030864105709 | validation: 0.9529121524174243]
	TIME [epoch: 24.7 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.991803158030953		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.991803158030953 | validation: 1.2976261710686878]
	TIME [epoch: 24.7 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8794689640962249		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.8794689640962249 | validation: 0.552482291641929]
	TIME [epoch: 24.7 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511493942771		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.511493942771 | validation: 0.5532173496880093]
	TIME [epoch: 24.7 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6369148542185429		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.6369148542185429 | validation: 0.555959896687702]
	TIME [epoch: 24.7 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.644353091524645		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.644353091524645 | validation: 0.6692398647683879]
	TIME [epoch: 24.7 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5748025432954285		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.5748025432954285 | validation: 0.6131822122863448]
	TIME [epoch: 24.7 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5953695022097641		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.5953695022097641 | validation: 0.5484539815069454]
	TIME [epoch: 24.7 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5119146778191572		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.5119146778191572 | validation: 0.5731276344055002]
	TIME [epoch: 24.7 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48987301090442703		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.48987301090442703 | validation: 0.5184207597938705]
	TIME [epoch: 24.7 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4672928839037708		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.4672928839037708 | validation: 0.6859540461248659]
	TIME [epoch: 24.7 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6468698741499225		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.6468698741499225 | validation: 0.6719320000657585]
	TIME [epoch: 24.7 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8005129002081686		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.8005129002081686 | validation: 0.8057008661824097]
	TIME [epoch: 24.7 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8226204495583884		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.8226204495583884 | validation: 0.6963635825950221]
	TIME [epoch: 24.7 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6177241587583635		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.6177241587583635 | validation: 0.678080444500835]
	TIME [epoch: 24.7 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6005721801890767		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.6005721801890767 | validation: 0.573266364165656]
	TIME [epoch: 24.7 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5036255636143099		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.5036255636143099 | validation: 0.5210273386631268]
	TIME [epoch: 24.7 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4659002541341109		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.4659002541341109 | validation: 0.4963961005596687]
	TIME [epoch: 24.7 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48168018127646617		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.48168018127646617 | validation: 0.4957131095438072]
	TIME [epoch: 24.7 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47826791839583516		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.47826791839583516 | validation: 0.5403386099341276]
	TIME [epoch: 24.7 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5862999219559923		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.5862999219559923 | validation: 0.5165073118890723]
	TIME [epoch: 24.7 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5584661000172748		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.5584661000172748 | validation: 0.528841113328266]
	TIME [epoch: 24.7 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4704214345872392		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.4704214345872392 | validation: 0.5117590811557713]
	TIME [epoch: 24.7 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46127415842917724		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.46127415842917724 | validation: 0.518909254624406]
	TIME [epoch: 24.7 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2332020606383423		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 1.2332020606383423 | validation: 2.792030491685687]
	TIME [epoch: 24.7 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4080876617743443		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 2.4080876617743443 | validation: 1.5335313098440235]
	TIME [epoch: 24.7 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0293873343565672		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 1.0293873343565672 | validation: 0.5963981551636093]
	TIME [epoch: 24.7 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.55503252886499		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.55503252886499 | validation: 0.5815627388229319]
	TIME [epoch: 24.7 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5163038084871928		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.5163038084871928 | validation: 0.6093261390762983]
	TIME [epoch: 24.7 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5018151344061946		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.5018151344061946 | validation: 0.5899570797910881]
	TIME [epoch: 24.7 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5692747943537841		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.5692747943537841 | validation: 0.5748159457959723]
	TIME [epoch: 24.7 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4903308472926508		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.4903308472926508 | validation: 0.6464096205366598]
	TIME [epoch: 24.7 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9159593759598812		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.9159593759598812 | validation: 0.5698147737541099]
	TIME [epoch: 24.7 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5442782914097669		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.5442782914097669 | validation: 0.6101738318605515]
	TIME [epoch: 24.7 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5037694019857213		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.5037694019857213 | validation: 0.573720692025423]
	TIME [epoch: 24.7 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5066880703784269		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.5066880703784269 | validation: 0.4803629879586805]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_673.pth
	Model improved!!!
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5113688316645486		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.5113688316645486 | validation: 0.9656057207753657]
	TIME [epoch: 24.7 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.000615391090905		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 1.000615391090905 | validation: 0.6513135856344431]
	TIME [epoch: 24.7 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5235950961572555		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.5235950961572555 | validation: 0.6124843802729703]
	TIME [epoch: 24.7 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7481800048318722		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.7481800048318722 | validation: 0.7223645558061608]
	TIME [epoch: 24.7 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6986923190695314		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.6986923190695314 | validation: 0.7536913724945508]
	TIME [epoch: 24.7 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7306189384553451		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.7306189384553451 | validation: 0.7454125199121444]
	TIME [epoch: 24.7 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6813204776058123		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.6813204776058123 | validation: 0.7073713596289324]
	TIME [epoch: 24.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.724595124540854		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.724595124540854 | validation: 0.7490065689012732]
	TIME [epoch: 24.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8535640659655405		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.8535640659655405 | validation: 0.8290634083177428]
	TIME [epoch: 24.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8634641128368967		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.8634641128368967 | validation: 0.7650795744855959]
	TIME [epoch: 24.7 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.76342737217679		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.76342737217679 | validation: 0.7725051246277039]
	TIME [epoch: 24.7 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7555010972378562		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.7555010972378562 | validation: 0.7160837495266035]
	TIME [epoch: 24.7 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7113118270279172		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.7113118270279172 | validation: 0.807395013771733]
	TIME [epoch: 24.7 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7967046514179867		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.7967046514179867 | validation: 0.6284236348401662]
	TIME [epoch: 24.7 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5374228805112631		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.5374228805112631 | validation: 0.5537484510175275]
	TIME [epoch: 24.7 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5255947804846524		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.5255947804846524 | validation: 0.5200501696831098]
	TIME [epoch: 24.7 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5782410322690036		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5782410322690036 | validation: 0.6222116833384432]
	TIME [epoch: 24.7 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6172353644327143		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.6172353644327143 | validation: 0.5688283804830452]
	TIME [epoch: 24.7 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5727808672250937		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.5727808672250937 | validation: 0.710695335289029]
	TIME [epoch: 24.7 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6563680072948181		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.6563680072948181 | validation: 0.6008209508863597]
	TIME [epoch: 24.7 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5532510555710108		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.5532510555710108 | validation: 0.6366280236889832]
	TIME [epoch: 24.7 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5562455115508599		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.5562455115508599 | validation: 0.6365566233267703]
	TIME [epoch: 24.7 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5402852974944704		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.5402852974944704 | validation: 0.6170136460729849]
	TIME [epoch: 24.7 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5328531100698537		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.5328531100698537 | validation: 0.5363972662324569]
	TIME [epoch: 24.7 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48877514786729914		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.48877514786729914 | validation: 0.5851665596020126]
	TIME [epoch: 24.7 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7604367972992205		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.7604367972992205 | validation: 0.9786578559056153]
	TIME [epoch: 24.7 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6782243605172769		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.6782243605172769 | validation: 0.5522724462612741]
	TIME [epoch: 24.7 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5073477568613065		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.5073477568613065 | validation: 0.5069061387385702]
	TIME [epoch: 24.7 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4778754085015581		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.4778754085015581 | validation: 0.5765899301747176]
	TIME [epoch: 24.7 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7184448166043428		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.7184448166043428 | validation: 0.729859934684079]
	TIME [epoch: 24.7 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6340530765648152		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.6340530765648152 | validation: 0.5866009327523107]
	TIME [epoch: 24.7 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5119338889621734		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.5119338889621734 | validation: 0.5839218590890308]
	TIME [epoch: 24.7 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6114923728630963		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.6114923728630963 | validation: 0.5629530929598819]
	TIME [epoch: 24.7 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5004628490370147		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.5004628490370147 | validation: 0.4764323669523258]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_707.pth
	Model improved!!!
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4988655494226496		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.4988655494226496 | validation: 0.6079941921716823]
	TIME [epoch: 24.7 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49078968267596224		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.49078968267596224 | validation: 0.5048333109269314]
	TIME [epoch: 24.7 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4941213087123887		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.4941213087123887 | validation: 0.5931834716259182]
	TIME [epoch: 24.7 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49888049956433506		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.49888049956433506 | validation: 0.5383661026477711]
	TIME [epoch: 24.7 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5366679133721161		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.5366679133721161 | validation: 0.5710421859237009]
	TIME [epoch: 24.7 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7068747707272858		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.7068747707272858 | validation: 1.0294180394433263]
	TIME [epoch: 24.7 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8337634857447589		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.8337634857447589 | validation: 0.949316512704201]
	TIME [epoch: 24.7 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7870447318156761		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.7870447318156761 | validation: 0.531564179633959]
	TIME [epoch: 24.7 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49474708376884896		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.49474708376884896 | validation: 0.4826947191454214]
	TIME [epoch: 24.7 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4568379743912643		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.4568379743912643 | validation: 0.49499348119619613]
	TIME [epoch: 24.7 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5189735648360297		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.5189735648360297 | validation: 0.6172153758730032]
	TIME [epoch: 24.7 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6062930174255912		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.6062930174255912 | validation: 0.6520610834464636]
	TIME [epoch: 24.7 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5356470189152914		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.5356470189152914 | validation: 0.6463597965912843]
	TIME [epoch: 24.7 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7127786912662493		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.7127786912662493 | validation: 0.6715744543026405]
	TIME [epoch: 24.7 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.516032752866678		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.516032752866678 | validation: 0.5141966184895287]
	TIME [epoch: 24.7 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47215826665365507		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.47215826665365507 | validation: 0.5169172578470784]
	TIME [epoch: 24.7 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5292805554678714		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.5292805554678714 | validation: 0.499175712225708]
	TIME [epoch: 24.7 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4894701215099455		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.4894701215099455 | validation: 0.5399008545219589]
	TIME [epoch: 24.7 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4659557688376178		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.4659557688376178 | validation: 0.5263103901496945]
	TIME [epoch: 24.7 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46711846391385725		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.46711846391385725 | validation: 0.49957962483851626]
	TIME [epoch: 24.7 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4750983143039806		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.4750983143039806 | validation: 0.6136671268574287]
	TIME [epoch: 24.7 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5627557089693773		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.5627557089693773 | validation: 0.6557614643198124]
	TIME [epoch: 24.7 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5844730631492873		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.5844730631492873 | validation: 0.5532725507819549]
	TIME [epoch: 24.7 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.529741928807875		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.529741928807875 | validation: 0.5360722988081336]
	TIME [epoch: 24.7 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5624746890950285		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.5624746890950285 | validation: 0.6249701348206699]
	TIME [epoch: 24.7 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6631638852459125		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.6631638852459125 | validation: 0.5399352009042241]
	TIME [epoch: 24.7 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5127367182522671		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.5127367182522671 | validation: 0.5364297768217436]
	TIME [epoch: 24.7 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5065482920371426		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.5065482920371426 | validation: 0.5403196945367706]
	TIME [epoch: 24.7 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4887519260857627		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.4887519260857627 | validation: 0.5113412881149659]
	TIME [epoch: 24.7 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5017175594975452		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.5017175594975452 | validation: 0.5192697384815687]
	TIME [epoch: 24.7 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47626162063080113		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.47626162063080113 | validation: 0.5213325773651054]
	TIME [epoch: 24.7 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6235753990709435		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.6235753990709435 | validation: 1.6035374078495852]
	TIME [epoch: 24.7 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.35820885203559		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 1.35820885203559 | validation: 0.628968260921798]
	TIME [epoch: 24.7 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5075924350299602		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.5075924350299602 | validation: 0.5641747463350184]
	TIME [epoch: 24.7 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7272917302169003		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.7272917302169003 | validation: 0.8104373969815835]
	TIME [epoch: 24.7 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6800865276129098		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.6800865276129098 | validation: 0.5212913891807959]
	TIME [epoch: 24.7 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5056098930726187		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.5056098930726187 | validation: 0.5682164792921093]
	TIME [epoch: 24.7 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5076710598268436		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.5076710598268436 | validation: 0.5144569950030642]
	TIME [epoch: 24.7 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46819239833553444		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.46819239833553444 | validation: 0.5172108452551206]
	TIME [epoch: 24.7 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46579811395922716		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.46579811395922716 | validation: 0.49237589764117234]
	TIME [epoch: 24.7 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4598720035164154		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.4598720035164154 | validation: 0.4916518859181904]
	TIME [epoch: 24.7 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49935119596713395		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.49935119596713395 | validation: 0.593040726994804]
	TIME [epoch: 24.7 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5762507704301092		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.5762507704301092 | validation: 0.6131872264450533]
	TIME [epoch: 24.7 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6382552132773578		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.6382552132773578 | validation: 0.6646784628815915]
	TIME [epoch: 24.7 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6355184846972791		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.6355184846972791 | validation: 0.5838115188557028]
	TIME [epoch: 24.7 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5921216495471254		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.5921216495471254 | validation: 0.6802123865727983]
	TIME [epoch: 24.7 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6661292158201384		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.6661292158201384 | validation: 0.5940388845512361]
	TIME [epoch: 24.7 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5476394045718156		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.5476394045718156 | validation: 0.6136374513339431]
	TIME [epoch: 24.7 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5507381182761829		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.5507381182761829 | validation: 0.5964883995069162]
	TIME [epoch: 24.7 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6001898554549394		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.6001898554549394 | validation: 0.6100492707509227]
	TIME [epoch: 24.7 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5852662172698517		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.5852662172698517 | validation: 0.5868664704500389]
	TIME [epoch: 24.7 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.540342868888164		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.540342868888164 | validation: 0.5536894647707474]
	TIME [epoch: 24.7 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5099396948868252		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.5099396948868252 | validation: 0.5462597930507848]
	TIME [epoch: 24.7 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5089479523855975		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.5089479523855975 | validation: 0.5510165908995853]
	TIME [epoch: 24.7 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5735207820596191		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.5735207820596191 | validation: 0.6973255148265581]
	TIME [epoch: 24.7 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6391737392127452		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.6391737392127452 | validation: 0.6026399092263802]
	TIME [epoch: 24.7 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5499898078590743		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.5499898078590743 | validation: 0.5090915847672219]
	TIME [epoch: 24.7 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4855724164607451		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.4855724164607451 | validation: 0.5105486090015573]
	TIME [epoch: 24.7 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.549340763809001		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.549340763809001 | validation: 0.5247266224616075]
	TIME [epoch: 24.7 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47541396110848055		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.47541396110848055 | validation: 0.5075420866022974]
	TIME [epoch: 24.7 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44813985648203103		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.44813985648203103 | validation: 0.4959578352006679]
	TIME [epoch: 24.7 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48988274666173715		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.48988274666173715 | validation: 0.594333976220395]
	TIME [epoch: 24.7 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5453257350937113		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.5453257350937113 | validation: 0.4860519663924557]
	TIME [epoch: 24.7 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47411709109409217		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.47411709109409217 | validation: 0.6682565648132414]
	TIME [epoch: 24.7 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7013285913926967		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.7013285913926967 | validation: 0.5493542424740084]
	TIME [epoch: 24.7 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48658818179713753		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.48658818179713753 | validation: 0.5374526039641377]
	TIME [epoch: 24.7 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4951356351570666		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.4951356351570666 | validation: 0.4948127812937034]
	TIME [epoch: 24.7 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4620841106324451		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.4620841106324451 | validation: 0.49499605155971654]
	TIME [epoch: 24.7 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4405931332050011		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.4405931332050011 | validation: 0.5175026738466092]
	TIME [epoch: 24.7 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5455337344078199		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.5455337344078199 | validation: 0.5559533952004502]
	TIME [epoch: 24.7 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5108259003092656		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.5108259003092656 | validation: 0.5245889495102771]
	TIME [epoch: 24.7 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4645646526737735		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.4645646526737735 | validation: 0.5281445571087673]
	TIME [epoch: 24.7 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5295771350764827		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.5295771350764827 | validation: 0.6634767469818736]
	TIME [epoch: 24.7 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5383640288636208		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.5383640288636208 | validation: 0.5417467676968806]
	TIME [epoch: 24.7 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5101960402708651		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.5101960402708651 | validation: 0.5142445540907441]
	TIME [epoch: 24.7 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4692575854970697		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.4692575854970697 | validation: 0.5303382486223505]
	TIME [epoch: 24.7 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49270722508098574		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.49270722508098574 | validation: 0.47822823178768814]
	TIME [epoch: 24.7 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.472138926917747		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.472138926917747 | validation: 0.4881764236241065]
	TIME [epoch: 24.7 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4560335986402882		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.4560335986402882 | validation: 0.4785901267576961]
	TIME [epoch: 24.7 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43816865528532123		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.43816865528532123 | validation: 0.48210092567997126]
	TIME [epoch: 24.7 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46825733171173245		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.46825733171173245 | validation: 0.565448572391465]
	TIME [epoch: 24.7 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677522312815585		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.5677522312815585 | validation: 0.9945514942893756]
	TIME [epoch: 24.7 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9482345687150432		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.9482345687150432 | validation: 0.7901465244425673]
	TIME [epoch: 24.7 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8376889327151698		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.8376889327151698 | validation: 0.7461726354653473]
	TIME [epoch: 24.7 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6670802446354648		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.6670802446354648 | validation: 0.5249098945115068]
	TIME [epoch: 24.7 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4728142780728919		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.4728142780728919 | validation: 0.47455221781690443]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_793.pth
	Model improved!!!
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44618350203189316		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.44618350203189316 | validation: 0.49378664402238776]
	TIME [epoch: 24.7 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45547438178798694		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.45547438178798694 | validation: 0.6986896028819934]
	TIME [epoch: 24.7 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8516770036058174		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.8516770036058174 | validation: 0.9837814225448637]
	TIME [epoch: 24.7 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7552234228348703		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.7552234228348703 | validation: 0.5944464096283458]
	TIME [epoch: 24.7 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5245955230112135		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.5245955230112135 | validation: 0.5505047525903771]
	TIME [epoch: 24.7 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5409798616514159		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.5409798616514159 | validation: 0.5159877624445852]
	TIME [epoch: 24.7 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46679944400779805		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.46679944400779805 | validation: 0.5087272135700923]
	TIME [epoch: 24.7 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4790443333838334		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.4790443333838334 | validation: 0.4519706788586392]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_801.pth
	Model improved!!!
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43631974390051154		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.43631974390051154 | validation: 0.5028825588146257]
	TIME [epoch: 24.7 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49774246934886607		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.49774246934886607 | validation: 0.48829209911265997]
	TIME [epoch: 24.7 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4853601273062303		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.4853601273062303 | validation: 0.5192927927338343]
	TIME [epoch: 24.8 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45042656181444074		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.45042656181444074 | validation: 0.4930207485538387]
	TIME [epoch: 24.7 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45372891175415675		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.45372891175415675 | validation: 0.5219285673042934]
	TIME [epoch: 24.7 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5036061292547364		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.5036061292547364 | validation: 0.5042417709211304]
	TIME [epoch: 24.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511105187553476		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.4511105187553476 | validation: 0.5360153682617105]
	TIME [epoch: 24.7 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49219022620693054		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.49219022620693054 | validation: 0.6026834747466107]
	TIME [epoch: 24.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5026391970298321		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.5026391970298321 | validation: 0.490798006541322]
	TIME [epoch: 24.7 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4556605320145933		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.4556605320145933 | validation: 0.5524932528997676]
	TIME [epoch: 24.7 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5087419410539322		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.5087419410539322 | validation: 0.5368845922807168]
	TIME [epoch: 24.7 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47712894258834415		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.47712894258834415 | validation: 0.5323660750245447]
	TIME [epoch: 24.7 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5040674866421616		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.5040674866421616 | validation: 0.5492388124245935]
	TIME [epoch: 24.7 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5634797171110082		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.5634797171110082 | validation: 0.5660248583279807]
	TIME [epoch: 24.7 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47023375863383654		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.47023375863383654 | validation: 0.5441205182791496]
	TIME [epoch: 24.7 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5415834636322924		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.5415834636322924 | validation: 0.5588045763248607]
	TIME [epoch: 24.7 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49768574715270525		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.49768574715270525 | validation: 0.5129321817953215]
	TIME [epoch: 24.7 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4899185801594368		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.4899185801594368 | validation: 0.5022342783104767]
	TIME [epoch: 24.7 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45079982202544944		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.45079982202544944 | validation: 0.4751038189084394]
	TIME [epoch: 24.7 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42633824599814174		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.42633824599814174 | validation: 0.47508058346402493]
	TIME [epoch: 24.7 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4387523832813319		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.4387523832813319 | validation: 0.46617242155590943]
	TIME [epoch: 24.7 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42921680382621524		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.42921680382621524 | validation: 0.4623157123684855]
	TIME [epoch: 24.7 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326586297999085		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.4326586297999085 | validation: 0.4703029612732136]
	TIME [epoch: 24.7 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4196581221767487		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.4196581221767487 | validation: 0.4497746820300158]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_825.pth
	Model improved!!!
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41748107701418075		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.41748107701418075 | validation: 0.5053106263844377]
	TIME [epoch: 24.7 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5193240690898306		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.5193240690898306 | validation: 0.6017379475011064]
	TIME [epoch: 24.7 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6755993337933733		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.6755993337933733 | validation: 0.6930065201467719]
	TIME [epoch: 24.7 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5634091009836387		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.5634091009836387 | validation: 0.531072400122074]
	TIME [epoch: 24.7 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4603357953472139		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.4603357953472139 | validation: 0.49653598229895196]
	TIME [epoch: 24.7 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46378540220579795		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.46378540220579795 | validation: 0.5246000781749972]
	TIME [epoch: 24.7 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49164620268257175		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.49164620268257175 | validation: 0.5462002396828785]
	TIME [epoch: 24.7 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5274917273224446		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.5274917273224446 | validation: 0.5424944809297927]
	TIME [epoch: 24.7 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47846719738682514		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.47846719738682514 | validation: 0.47456521613500424]
	TIME [epoch: 24.7 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4551985963616807		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.4551985963616807 | validation: 0.4863156358595223]
	TIME [epoch: 24.7 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4382715559568937		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.4382715559568937 | validation: 0.5359513236132449]
	TIME [epoch: 24.7 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4966285878120673		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.4966285878120673 | validation: 0.4838169615148886]
	TIME [epoch: 24.7 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4419780931793345		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.4419780931793345 | validation: 0.48653898437414483]
	TIME [epoch: 24.7 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4162272741464368		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.4162272741464368 | validation: 0.4482338357531783]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_839.pth
	Model improved!!!
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.404618602813797		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.404618602813797 | validation: 0.4574412331882618]
	TIME [epoch: 24.7 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5328992169913698		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.5328992169913698 | validation: 0.6036582318849828]
	TIME [epoch: 24.7 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47331867888781193		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.47331867888781193 | validation: 0.4420977016620548]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_842.pth
	Model improved!!!
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4324478192953387		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.4324478192953387 | validation: 0.6522135447543616]
	TIME [epoch: 24.7 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5993339296908469		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.5993339296908469 | validation: 0.47928827282230574]
	TIME [epoch: 24.7 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4904257142978685		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.4904257142978685 | validation: 0.738849558872293]
	TIME [epoch: 24.7 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.05750553299258		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 1.05750553299258 | validation: 1.3181081982200868]
	TIME [epoch: 24.7 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2556460160202783		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 1.2556460160202783 | validation: 0.8554109946318011]
	TIME [epoch: 24.7 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6921654179299551		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.6921654179299551 | validation: 0.48384087842696477]
	TIME [epoch: 24.7 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4821676286743338		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.4821676286743338 | validation: 0.5353199856778353]
	TIME [epoch: 24.7 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45312053210824366		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.45312053210824366 | validation: 0.4600646446813825]
	TIME [epoch: 24.7 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4194291266262251		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.4194291266262251 | validation: 0.4762596718387968]
	TIME [epoch: 24.7 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4844042117114545		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.4844042117114545 | validation: 0.49700351786138747]
	TIME [epoch: 24.7 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4701357516926954		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.4701357516926954 | validation: 0.46211189384895157]
	TIME [epoch: 24.7 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4144489627343282		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.4144489627343282 | validation: 0.4720626391944298]
	TIME [epoch: 24.8 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41380826091913747		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.41380826091913747 | validation: 0.47993683303605267]
	TIME [epoch: 24.7 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45612900359849906		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.45612900359849906 | validation: 0.4909561169905884]
	TIME [epoch: 24.7 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.481294589885191		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.481294589885191 | validation: 0.7653480949838709]
	TIME [epoch: 24.7 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7996662948512289		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.7996662948512289 | validation: 0.9705978585224453]
	TIME [epoch: 24.7 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7768466312451616		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.7768466312451616 | validation: 0.5679151109049261]
	TIME [epoch: 24.7 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47466526238310075		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.47466526238310075 | validation: 0.4704202636906783]
	TIME [epoch: 24.8 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42825825330427575		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.42825825330427575 | validation: 0.4751452734572312]
	TIME [epoch: 24.7 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43487274447314117		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.43487274447314117 | validation: 0.48531453892235177]
	TIME [epoch: 24.7 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44496904768540474		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.44496904768540474 | validation: 0.5136259270412739]
	TIME [epoch: 24.8 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49255167182492365		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.49255167182492365 | validation: 0.4889995952594008]
	TIME [epoch: 24.7 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4341849959288487		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.4341849959288487 | validation: 0.5168273502525128]
	TIME [epoch: 24.7 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47087196773491913		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.47087196773491913 | validation: 0.4925717936584178]
	TIME [epoch: 24.8 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47819887180303705		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.47819887180303705 | validation: 0.5029037375612773]
	TIME [epoch: 24.7 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45131663393647264		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.45131663393647264 | validation: 0.5075510844634239]
	TIME [epoch: 24.7 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47432252386337687		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.47432252386337687 | validation: 0.5238342316731274]
	TIME [epoch: 24.8 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5025261281776012		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.5025261281776012 | validation: 0.5092805007173411]
	TIME [epoch: 24.7 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4389428035088263		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.4389428035088263 | validation: 0.472446123966768]
	TIME [epoch: 24.7 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.411105501562694		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.411105501562694 | validation: 0.460654055693538]
	TIME [epoch: 24.8 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4221232311522022		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.4221232311522022 | validation: 0.4804266870691868]
	TIME [epoch: 24.7 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42038301712334475		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.42038301712334475 | validation: 0.487550931569668]
	TIME [epoch: 24.7 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4206182291145751		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.4206182291145751 | validation: 0.4706295524577315]
	TIME [epoch: 24.8 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4619064120052527		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.4619064120052527 | validation: 0.5162459343651462]
	TIME [epoch: 24.7 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4937042272401091		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.4937042272401091 | validation: 0.510983427632668]
	TIME [epoch: 24.7 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.462369803012535		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.462369803012535 | validation: 0.5111327477438217]
	TIME [epoch: 24.7 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4966718374292199		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.4966718374292199 | validation: 0.5524088810259182]
	TIME [epoch: 24.7 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5340493699209664		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.5340493699209664 | validation: 0.5573573610920862]
	TIME [epoch: 24.7 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5620579540405352		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.5620579540405352 | validation: 0.5939287461012234]
	TIME [epoch: 24.8 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.552922728830077		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.552922728830077 | validation: 0.5240905238103625]
	TIME [epoch: 24.7 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4607622702715916		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.4607622702715916 | validation: 0.4630987315250668]
	TIME [epoch: 24.7 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4481591641982546		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.4481591641982546 | validation: 0.5490741440890234]
	TIME [epoch: 24.7 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5430094770138963		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.5430094770138963 | validation: 0.5819397480518465]
	TIME [epoch: 24.7 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5803237998668654		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.5803237998668654 | validation: 0.5591835896834486]
	TIME [epoch: 24.7 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6020868101918473		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.6020868101918473 | validation: 0.6668550958561565]
	TIME [epoch: 24.7 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6303687152401147		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.6303687152401147 | validation: 0.575743736699499]
	TIME [epoch: 24.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.507804434600896		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.507804434600896 | validation: 0.5280564264462473]
	TIME [epoch: 24.7 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5316860843476208		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.5316860843476208 | validation: 0.6353002185056468]
	TIME [epoch: 24.7 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5822489266640655		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.5822489266640655 | validation: 0.5631885679097257]
	TIME [epoch: 24.7 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49287089072523993		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.49287089072523993 | validation: 0.5223924552266395]
	TIME [epoch: 24.7 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4756552285608802		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.4756552285608802 | validation: 0.5149878451237845]
	TIME [epoch: 24.7 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47833020029557305		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.47833020029557305 | validation: 0.4844132118376808]
	TIME [epoch: 24.7 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44022955990535184		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.44022955990535184 | validation: 0.477117522093424]
	TIME [epoch: 24.7 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40793483772859584		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.40793483772859584 | validation: 0.4610657445028198]
	TIME [epoch: 24.7 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4106825684108011		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.4106825684108011 | validation: 0.4676459558262202]
	TIME [epoch: 24.7 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4446650466714691		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.4446650466714691 | validation: 0.5205404470638845]
	TIME [epoch: 24.7 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44429962987775695		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.44429962987775695 | validation: 0.47024752225963085]
	TIME [epoch: 24.7 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4183106252792101		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.4183106252792101 | validation: 0.46939016975740283]
	TIME [epoch: 24.7 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43499100943843994		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.43499100943843994 | validation: 0.46772483966776807]
	TIME [epoch: 24.7 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43350287470938303		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.43350287470938303 | validation: 0.49172774467241104]
	TIME [epoch: 24.8 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44206777152513466		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.44206777152513466 | validation: 0.48322918598002196]
	TIME [epoch: 24.7 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4172484955726912		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.4172484955726912 | validation: 0.4607094500446192]
	TIME [epoch: 24.7 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4071903617128856		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.4071903617128856 | validation: 0.46812941436213334]
	TIME [epoch: 24.8 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42270632410967185		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.42270632410967185 | validation: 0.4629555958794733]
	TIME [epoch: 24.7 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44119149006668523		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.44119149006668523 | validation: 0.4287028467476766]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_907.pth
	Model improved!!!
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4034753195917264		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.4034753195917264 | validation: 0.45603738852520453]
	TIME [epoch: 24.7 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44191437860753013		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.44191437860753013 | validation: 0.5668464105676598]
	TIME [epoch: 24.7 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4541811509456519		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.4541811509456519 | validation: 0.46507621820532696]
	TIME [epoch: 24.7 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42296575807692405		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.42296575807692405 | validation: 0.44401114369267264]
	TIME [epoch: 24.7 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41540510767758565		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.41540510767758565 | validation: 0.4606409539426446]
	TIME [epoch: 24.7 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41300424271762265		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.41300424271762265 | validation: 0.45224442766028977]
	TIME [epoch: 24.7 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4069335847950806		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.4069335847950806 | validation: 0.44966673004809904]
	TIME [epoch: 24.7 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4024227864375274		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.4024227864375274 | validation: 0.43797046524246613]
	TIME [epoch: 24.7 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39813229746282		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.39813229746282 | validation: 0.4548221883109359]
	TIME [epoch: 24.7 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4008928672451586		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.4008928672451586 | validation: 0.4796131738991278]
	TIME [epoch: 24.7 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4351882537253903		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.4351882537253903 | validation: 0.48525707737358453]
	TIME [epoch: 24.7 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4528017920776566		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.4528017920776566 | validation: 0.4755908660418923]
	TIME [epoch: 24.8 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4228744358273059		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.4228744358273059 | validation: 0.47477830796709386]
	TIME [epoch: 24.7 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42548985476028334		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.42548985476028334 | validation: 0.470314708684203]
	TIME [epoch: 24.7 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45367378154695587		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.45367378154695587 | validation: 0.5280028957689529]
	TIME [epoch: 24.7 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4460454598230806		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.4460454598230806 | validation: 0.5128803896369403]
	TIME [epoch: 24.7 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49925393513261773		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.49925393513261773 | validation: 0.509635149535135]
	TIME [epoch: 24.7 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4181514410120128		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.4181514410120128 | validation: 0.4379910120245781]
	TIME [epoch: 24.7 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3921598815219338		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.3921598815219338 | validation: 0.4396034834702121]
	TIME [epoch: 24.7 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4025625081336794		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.4025625081336794 | validation: 0.4422957244869539]
	TIME [epoch: 24.7 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39480916338985095		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.39480916338985095 | validation: 0.46124767340520395]
	TIME [epoch: 24.7 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45427864574739063		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.45427864574739063 | validation: 0.4714853083245427]
	TIME [epoch: 24.7 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4240914393935814		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.4240914393935814 | validation: 0.4739959412730201]
	TIME [epoch: 24.7 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48494251424592816		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.48494251424592816 | validation: 0.4663667718628484]
	TIME [epoch: 24.7 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4175385806650752		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.4175385806650752 | validation: 0.45865618725577206]
	TIME [epoch: 24.7 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4172626084971444		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.4172626084971444 | validation: 0.4877783766294104]
	TIME [epoch: 24.7 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4944684577172262		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.4944684577172262 | validation: 0.6051395113305766]
	TIME [epoch: 24.7 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5713155497173749		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.5713155497173749 | validation: 0.5498307388429745]
	TIME [epoch: 24.7 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45887542921428415		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.45887542921428415 | validation: 0.471854134498048]
	TIME [epoch: 24.7 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40606397010837086		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.40606397010837086 | validation: 0.4378918396655118]
	TIME [epoch: 24.7 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925913795764058		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.3925913795764058 | validation: 0.4511024794311162]
	TIME [epoch: 24.7 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3950892684254278		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.3950892684254278 | validation: 0.4485793866845492]
	TIME [epoch: 24.7 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.533206440584495		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.533206440584495 | validation: 0.7209700016341083]
	TIME [epoch: 24.7 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6174651683521639		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.6174651683521639 | validation: 0.5501264757194276]
	TIME [epoch: 24.7 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4454922976962116		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.4454922976962116 | validation: 0.4417204283927202]
	TIME [epoch: 24.7 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42097216062284737		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.42097216062284737 | validation: 0.5046996685407041]
	TIME [epoch: 24.7 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43861541115152874		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.43861541115152874 | validation: 0.44845368117379353]
	TIME [epoch: 24.7 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3985226418563552		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.3985226418563552 | validation: 0.45245333206118504]
	TIME [epoch: 24.7 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46068418628697666		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.46068418628697666 | validation: 0.5110121074140443]
	TIME [epoch: 24.7 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49746469964651413		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.49746469964651413 | validation: 0.5099786798835707]
	TIME [epoch: 24.7 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47365824435243764		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.47365824435243764 | validation: 0.4858862421244252]
	TIME [epoch: 24.7 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43313323914342916		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.43313323914342916 | validation: 0.4527606310184892]
	TIME [epoch: 24.7 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3946910094628803		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.3946910094628803 | validation: 0.45576255210090594]
	TIME [epoch: 24.7 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4062905343238737		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.4062905343238737 | validation: 0.4373922084425734]
	TIME [epoch: 24.7 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3988969282932786		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.3988969282932786 | validation: 0.45056211959213294]
	TIME [epoch: 24.7 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4053201628407798		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.4053201628407798 | validation: 0.4487405538048465]
	TIME [epoch: 24.7 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4068965398778849		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.4068965398778849 | validation: 0.4476896306538475]
	TIME [epoch: 24.7 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4413419559084186		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.4413419559084186 | validation: 0.5586615326425008]
	TIME [epoch: 24.7 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4699527000729058		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.4699527000729058 | validation: 0.4668175913907102]
	TIME [epoch: 24.7 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40255113188356384		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.40255113188356384 | validation: 0.44571258691104176]
	TIME [epoch: 24.7 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41018245938406184		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.41018245938406184 | validation: 0.48355979659850357]
	TIME [epoch: 24.7 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4497935647794893		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.4497935647794893 | validation: 0.48205146152671396]
	TIME [epoch: 24.7 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40450250800662274		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.40450250800662274 | validation: 0.43752625036703197]
	TIME [epoch: 24.7 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40430852797113936		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.40430852797113936 | validation: 0.48213459066345793]
	TIME [epoch: 24.7 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4220745837274631		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.4220745837274631 | validation: 0.44503220049273345]
	TIME [epoch: 24.7 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40466641740796927		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.40466641740796927 | validation: 0.44613508579175515]
	TIME [epoch: 24.7 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916615046341337		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.3916615046341337 | validation: 0.45270632838962593]
	TIME [epoch: 24.7 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4006096559905894		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.4006096559905894 | validation: 0.444117917493127]
	TIME [epoch: 24.7 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3901922675159214		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.3901922675159214 | validation: 0.45469554416793273]
	TIME [epoch: 24.7 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39907560826310806		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.39907560826310806 | validation: 0.43287445448079853]
	TIME [epoch: 24.7 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39749317089176617		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.39749317089176617 | validation: 0.5042033131907935]
	TIME [epoch: 24.7 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42205753664326906		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.42205753664326906 | validation: 0.4329273211735126]
	TIME [epoch: 24.7 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38388449218052373		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.38388449218052373 | validation: 0.44285174558835194]
	TIME [epoch: 24.7 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3893464578110799		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.3893464578110799 | validation: 0.44357340529402145]
	TIME [epoch: 24.7 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4007799141554571		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.4007799141554571 | validation: 0.44483667680139977]
	TIME [epoch: 24.7 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929479637027139		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.3929479637027139 | validation: 0.45105768271264735]
	TIME [epoch: 24.7 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3961537115155715		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.3961537115155715 | validation: 0.4545418302407701]
	TIME [epoch: 24.7 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41204846354069896		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.41204846354069896 | validation: 0.5024239334157935]
	TIME [epoch: 24.7 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49941410529934505		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.49941410529934505 | validation: 0.5569840145028497]
	TIME [epoch: 24.7 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4509295856219884		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.4509295856219884 | validation: 0.4453097854054838]
	TIME [epoch: 24.7 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3872046757485889		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.3872046757485889 | validation: 0.42962695720177835]
	TIME [epoch: 24.7 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3787786403432233		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.3787786403432233 | validation: 0.43172239375458604]
	TIME [epoch: 24.7 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3952097972481287		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.3952097972481287 | validation: 0.4373657690652415]
	TIME [epoch: 24.7 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42494861683934054		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.42494861683934054 | validation: 0.49097498082999624]
	TIME [epoch: 24.7 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4581620510168912		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.4581620510168912 | validation: 0.5425066708197248]
	TIME [epoch: 24.7 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47464864746599467		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.47464864746599467 | validation: 0.4464617412787115]
	TIME [epoch: 24.7 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.389033455167122		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.389033455167122 | validation: 0.44053724106230435]
	TIME [epoch: 24.7 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3987993686536717		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.3987993686536717 | validation: 0.440447593356448]
	TIME [epoch: 24.7 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38285420462586284		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.38285420462586284 | validation: 0.4381644444031483]
	TIME [epoch: 24.7 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39590736715588043		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.39590736715588043 | validation: 0.42246331751142197]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_987.pth
	Model improved!!!
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39777260297044315		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.39777260297044315 | validation: 0.48011396214451524]
	TIME [epoch: 24.7 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4255042498854947		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.4255042498854947 | validation: 0.4399981085020946]
	TIME [epoch: 24.7 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38665261824751185		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.38665261824751185 | validation: 0.4391609101460289]
	TIME [epoch: 24.7 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3885657200843502		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.3885657200843502 | validation: 0.43827058726402757]
	TIME [epoch: 24.7 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3973715193865493		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.3973715193865493 | validation: 0.44389653291574066]
	TIME [epoch: 24.7 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4400391850741142		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.4400391850741142 | validation: 0.4799525694648196]
	TIME [epoch: 24.7 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4213974125674999		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.4213974125674999 | validation: 0.4483178698406662]
	TIME [epoch: 24.7 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39933696740025726		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.39933696740025726 | validation: 0.4718025241462367]
	TIME [epoch: 24.7 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4071295454594481		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.4071295454594481 | validation: 0.44569559363094047]
	TIME [epoch: 24.7 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4079057330200711		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.4079057330200711 | validation: 0.4454019179535038]
	TIME [epoch: 24.7 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39194383386956466		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.39194383386956466 | validation: 0.45411163789165204]
	TIME [epoch: 24.7 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41996177340658797		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.41996177340658797 | validation: 0.47999598057214343]
	TIME [epoch: 24.7 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48455875725388614		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.48455875725388614 | validation: 0.5447605509106893]
	TIME [epoch: 24.7 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4978611375156054		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.4978611375156054 | validation: 0.4799838261041224]
	TIME [epoch: 24.7 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44159788635175523		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.44159788635175523 | validation: 0.49676589538849486]
	TIME [epoch: 24.7 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4559902975542101		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.4559902975542101 | validation: 0.5121383803833256]
	TIME [epoch: 24.7 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4578538312653564		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.4578538312653564 | validation: 0.4957347584127365]
	TIME [epoch: 24.7 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43913948561784594		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.43913948561784594 | validation: 0.47615088649087517]
	TIME [epoch: 24.7 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41919538598317607		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.41919538598317607 | validation: 0.4768090321084255]
	TIME [epoch: 24.7 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.438305410777848		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.438305410777848 | validation: 0.6132040057773016]
	TIME [epoch: 24.7 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6242874720037295		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.6242874720037295 | validation: 0.7551436452982577]
	TIME [epoch: 24.7 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6922641547949268		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.6922641547949268 | validation: 0.6788581773034105]
	TIME [epoch: 24.7 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5412818040243272		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.5412818040243272 | validation: 0.4974964981674688]
	TIME [epoch: 24.7 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4271599216892852		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.4271599216892852 | validation: 0.4910348069305144]
	TIME [epoch: 24.7 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4269463169708641		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.4269463169708641 | validation: 0.4349510498275113]
	TIME [epoch: 24.7 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925250461821773		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.3925250461821773 | validation: 0.47361310189110606]
	TIME [epoch: 24.7 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42040089979237383		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.42040089979237383 | validation: 0.44055264814981066]
	TIME [epoch: 24.7 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38555038303034844		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.38555038303034844 | validation: 0.44111157829440073]
	TIME [epoch: 24.7 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3894332108769463		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.3894332108769463 | validation: 0.4537801322145967]
	TIME [epoch: 24.7 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3859151298043408		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.3859151298043408 | validation: 0.43968352499115]
	TIME [epoch: 24.7 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783225966779504		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.3783225966779504 | validation: 0.42412365064573293]
	TIME [epoch: 24.7 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3768769937180463		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.3768769937180463 | validation: 0.4222647219949066]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_1019.pth
	Model improved!!!
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3789940845980175		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.3789940845980175 | validation: 0.4336616565176074]
	TIME [epoch: 24.7 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38273290573803537		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.38273290573803537 | validation: 0.4754564737021133]
	TIME [epoch: 24.7 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43254266118823237		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.43254266118823237 | validation: 0.4732135418862017]
	TIME [epoch: 24.7 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492891360618958		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.4492891360618958 | validation: 0.5048719511439549]
	TIME [epoch: 24.7 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4417965104955862		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.4417965104955862 | validation: 0.5126443028915324]
	TIME [epoch: 24.7 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44115911998921287		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.44115911998921287 | validation: 0.4668939987451542]
	TIME [epoch: 24.7 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4083565433836332		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.4083565433836332 | validation: 0.4441785746718314]
	TIME [epoch: 24.7 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38410417539547975		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.38410417539547975 | validation: 0.4470206020896218]
	TIME [epoch: 24.7 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39992055783600233		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.39992055783600233 | validation: 0.4503168546148683]
	TIME [epoch: 24.7 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4088986934326924		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.4088986934326924 | validation: 0.46378490740919703]
	TIME [epoch: 24.7 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933169507372784		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.3933169507372784 | validation: 0.43375067811428497]
	TIME [epoch: 24.7 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.375347334366563		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.375347334366563 | validation: 0.4447230010287588]
	TIME [epoch: 24.7 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40828302162076524		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.40828302162076524 | validation: 0.4939402075704974]
	TIME [epoch: 24.7 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4523656809883687		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.4523656809883687 | validation: 0.463263636999708]
	TIME [epoch: 24.7 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3928635340907437		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.3928635340907437 | validation: 0.4425231919332039]
	TIME [epoch: 24.7 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38989235607692013		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.38989235607692013 | validation: 0.46142274889487833]
	TIME [epoch: 24.7 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42180673768749755		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.42180673768749755 | validation: 0.4734304975210565]
	TIME [epoch: 24.7 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43392845848140116		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.43392845848140116 | validation: 0.4738549617280846]
	TIME [epoch: 24.7 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42293239810584715		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.42293239810584715 | validation: 0.47662521290963694]
	TIME [epoch: 24.7 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4002416265319251		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.4002416265319251 | validation: 0.4489796417904215]
	TIME [epoch: 24.7 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39007514949326927		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.39007514949326927 | validation: 0.4350862997099108]
	TIME [epoch: 24.7 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3920851357590624		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.3920851357590624 | validation: 0.4605195711378532]
	TIME [epoch: 24.7 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4183595454659852		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.4183595454659852 | validation: 0.45741545319393356]
	TIME [epoch: 24.7 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3971627880040369		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.3971627880040369 | validation: 0.45155342424980915]
	TIME [epoch: 24.7 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.391036932543143		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.391036932543143 | validation: 0.4663191482038394]
	TIME [epoch: 24.7 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3932921441625004		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.3932921441625004 | validation: 0.4832011262568053]
	TIME [epoch: 24.7 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40662675490820305		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.40662675490820305 | validation: 0.4401156054018709]
	TIME [epoch: 24.7 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4037207779223465		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.4037207779223465 | validation: 0.4721802839700233]
	TIME [epoch: 24.7 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.405611761215253		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.405611761215253 | validation: 0.4454418000363208]
	TIME [epoch: 24.7 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4015695301886437		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.4015695301886437 | validation: 0.47380372180560687]
	TIME [epoch: 24.7 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41608292743845793		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.41608292743845793 | validation: 0.4547797339417809]
	TIME [epoch: 24.7 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44119845578747496		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.44119845578747496 | validation: 0.4841828479000651]
	TIME [epoch: 24.7 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4377503227764931		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.4377503227764931 | validation: 0.46655924513658664]
	TIME [epoch: 24.7 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4189406002583205		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.4189406002583205 | validation: 0.4611272580506737]
	TIME [epoch: 24.7 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3963194277149631		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.3963194277149631 | validation: 0.45333124413139075]
	TIME [epoch: 24.7 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38818731387150074		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.38818731387150074 | validation: 0.44238101731521234]
	TIME [epoch: 24.7 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.388420629248899		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.388420629248899 | validation: 0.4323239661147959]
	TIME [epoch: 24.7 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38775118521084057		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.38775118521084057 | validation: 0.4461208765525963]
	TIME [epoch: 24.7 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38797535417976736		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.38797535417976736 | validation: 0.45514903558253933]
	TIME [epoch: 24.7 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39727482194312086		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.39727482194312086 | validation: 0.44639859651104713]
	TIME [epoch: 24.7 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40247390771475067		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.40247390771475067 | validation: 0.46909807141415344]
	TIME [epoch: 24.7 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4458734818147012		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.4458734818147012 | validation: 0.5040224130464064]
	TIME [epoch: 24.7 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5475413790621437		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.5475413790621437 | validation: 0.7274998086885092]
	TIME [epoch: 24.7 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6421596158705263		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.6421596158705263 | validation: 0.6634435382156915]
	TIME [epoch: 24.7 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5918554860284231		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.5918554860284231 | validation: 0.5343053015757063]
	TIME [epoch: 24.7 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5401154917607724		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.5401154917607724 | validation: 0.6780200187811062]
	TIME [epoch: 24.7 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6109567618934115		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.6109567618934115 | validation: 0.5445028779301742]
	TIME [epoch: 24.7 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49278369603226524		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.49278369603226524 | validation: 0.49344459415148384]
	TIME [epoch: 24.7 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492166084157403		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.4492166084157403 | validation: 0.4575700996279856]
	TIME [epoch: 24.7 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40908348177750253		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.40908348177750253 | validation: 0.42755408030284403]
	TIME [epoch: 24.7 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39133610075293446		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.39133610075293446 | validation: 0.43811013537673565]
	TIME [epoch: 24.7 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3893998058862942		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.3893998058862942 | validation: 0.4455754962430031]
	TIME [epoch: 24.7 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39390577856677894		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.39390577856677894 | validation: 0.43149480979024546]
	TIME [epoch: 24.7 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3881627149375145		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.3881627149375145 | validation: 0.4250328563693611]
	TIME [epoch: 24.7 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3809455347951153		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.3809455347951153 | validation: 0.45053439209215024]
	TIME [epoch: 24.7 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39706672188404635		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.39706672188404635 | validation: 0.46415170906925585]
	TIME [epoch: 24.7 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4111104972161219		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.4111104972161219 | validation: 0.47091841054678724]
	TIME [epoch: 24.7 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3866169791297698		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.3866169791297698 | validation: 0.4584335875172314]
	TIME [epoch: 24.7 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3922949904455089		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.3922949904455089 | validation: 0.4469724622907201]
	TIME [epoch: 24.7 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39812284267604325		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.39812284267604325 | validation: 0.45101247892830176]
	TIME [epoch: 24.7 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41158125936831863		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.41158125936831863 | validation: 0.49425148603929686]
	TIME [epoch: 24.7 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45044950859024535		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.45044950859024535 | validation: 0.4792850292676525]
	TIME [epoch: 24.7 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4257330709966748		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.4257330709966748 | validation: 0.46469094902469976]
	TIME [epoch: 24.7 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4100045862090527		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.4100045862090527 | validation: 0.4559522087041139]
	TIME [epoch: 24.7 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4039519430915288		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.4039519430915288 | validation: 0.4748364223735485]
	TIME [epoch: 24.7 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3989343873901714		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.3989343873901714 | validation: 0.46141848947828734]
	TIME [epoch: 24.7 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4065542182573726		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.4065542182573726 | validation: 0.47869987350130544]
	TIME [epoch: 24.7 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4368341572121294		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.4368341572121294 | validation: 0.49162015711719464]
	TIME [epoch: 24.7 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4431408966974243		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.4431408966974243 | validation: 0.501138647028819]
	TIME [epoch: 24.7 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46739110110800697		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.46739110110800697 | validation: 0.5591851177386076]
	TIME [epoch: 24.7 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5466773689793627		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.5466773689793627 | validation: 0.5569548778409157]
	TIME [epoch: 24.7 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5193264799748303		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.5193264799748303 | validation: 0.539147248413853]
	TIME [epoch: 24.7 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5134596353720863		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.5134596353720863 | validation: 0.5319078969312357]
	TIME [epoch: 24.7 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49587561825199766		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.49587561825199766 | validation: 0.5320279456887081]
	TIME [epoch: 24.7 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5019655834213257		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.5019655834213257 | validation: 0.5502180842834975]
	TIME [epoch: 24.7 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5032986858786201		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.5032986858786201 | validation: 0.5219551714141929]
	TIME [epoch: 24.7 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45808118586397856		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.45808118586397856 | validation: 0.4835064059461439]
	TIME [epoch: 24.7 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4163133508105565		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.4163133508105565 | validation: 0.4653398313640926]
	TIME [epoch: 24.7 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4028170223068669		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.4028170223068669 | validation: 0.44887052800167965]
	TIME [epoch: 24.7 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41021154469848065		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.41021154469848065 | validation: 0.49643031548432914]
	TIME [epoch: 24.7 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4702470723631401		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.4702470723631401 | validation: 0.5094705547227144]
	TIME [epoch: 24.7 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46073475530503255		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.46073475530503255 | validation: 0.4965354460329103]
	TIME [epoch: 24.7 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42642971334390917		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.42642971334390917 | validation: 0.4657793551066031]
	TIME [epoch: 24.7 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41984422429474116		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.41984422429474116 | validation: 0.4713852840768101]
	TIME [epoch: 24.7 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45185633381045504		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.45185633381045504 | validation: 0.4912333649698079]
	TIME [epoch: 24.7 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44084571343719425		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.44084571343719425 | validation: 0.49753490435877423]
	TIME [epoch: 24.7 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4267068690141015		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.4267068690141015 | validation: 0.4617268452467308]
	TIME [epoch: 24.7 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4129193322168283		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.4129193322168283 | validation: 0.46141747221933316]
	TIME [epoch: 24.7 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3983159026383528		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.3983159026383528 | validation: 0.46946329388487273]
	TIME [epoch: 24.7 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4117315325966229		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.4117315325966229 | validation: 0.462529488094815]
	TIME [epoch: 24.7 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39190554360758273		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.39190554360758273 | validation: 0.45215396872785063]
	TIME [epoch: 24.7 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3938880594801347		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.3938880594801347 | validation: 0.45712114025420114]
	TIME [epoch: 24.7 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.400079168006652		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.400079168006652 | validation: 0.4391557273209332]
	TIME [epoch: 24.7 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3852905678167945		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.3852905678167945 | validation: 0.4258980229912716]
	TIME [epoch: 24.7 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3793576112481617		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.3793576112481617 | validation: 0.44324309725089645]
	TIME [epoch: 24.7 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3837507225596727		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.3837507225596727 | validation: 0.44501572562808306]
	TIME [epoch: 24.7 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3884052932301211		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.3884052932301211 | validation: 0.44737204561197674]
	TIME [epoch: 24.7 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38553435036646677		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.38553435036646677 | validation: 0.4482660115255275]
	TIME [epoch: 24.7 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810263815597415		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.3810263815597415 | validation: 0.45070507744663274]
	TIME [epoch: 24.7 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3839445721056611		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.3839445721056611 | validation: 0.43513950754219355]
	TIME [epoch: 24.7 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3768692591746575		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.3768692591746575 | validation: 0.4338350822350481]
	TIME [epoch: 24.7 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3827345895132541		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.3827345895132541 | validation: 0.4323532751489526]
	TIME [epoch: 24.7 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810734405616042		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.3810734405616042 | validation: 0.43321200719372116]
	TIME [epoch: 24.7 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3816685164973752		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.3816685164973752 | validation: 0.4446365321900923]
	TIME [epoch: 24.7 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38206048915648055		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.38206048915648055 | validation: 0.43896369274499253]
	TIME [epoch: 24.7 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38250728530349415		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.38250728530349415 | validation: 0.43878336496012793]
	TIME [epoch: 24.7 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783385616195048		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.3783385616195048 | validation: 0.42786536507056755]
	TIME [epoch: 24.7 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3837905088208054		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.3837905088208054 | validation: 0.4256475036896199]
	TIME [epoch: 24.7 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3812623063315188		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.3812623063315188 | validation: 0.4244522471090514]
	TIME [epoch: 24.7 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37706226778941676		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.37706226778941676 | validation: 0.4299145963838467]
	TIME [epoch: 24.7 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.381418417641104		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.381418417641104 | validation: 0.4475760768594229]
	TIME [epoch: 24.7 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4151455066689431		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.4151455066689431 | validation: 0.4668740846758558]
	TIME [epoch: 24.7 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4276326991065629		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.4276326991065629 | validation: 0.48804113477625705]
	TIME [epoch: 24.7 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41044931606481444		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.41044931606481444 | validation: 0.45557850848089887]
	TIME [epoch: 24.7 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39008941559859245		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.39008941559859245 | validation: 0.45546912891895364]
	TIME [epoch: 24.7 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3838476334831361		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.3838476334831361 | validation: 0.4309062299979526]
	TIME [epoch: 24.7 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39183103619041026		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.39183103619041026 | validation: 0.4662945923177398]
	TIME [epoch: 24.7 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41287000288853837		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.41287000288853837 | validation: 0.45515636786693237]
	TIME [epoch: 24.7 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4121816452623033		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.4121816452623033 | validation: 0.4601266757317985]
	TIME [epoch: 24.7 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41709789885625004		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.41709789885625004 | validation: 0.48624055974199026]
	TIME [epoch: 24.7 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45479771686643716		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.45479771686643716 | validation: 0.4923117778999807]
	TIME [epoch: 24.7 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4716489240119949		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.4716489240119949 | validation: 0.5444956652089664]
	TIME [epoch: 24.7 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5301261364351398		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.5301261364351398 | validation: 0.5663432900232513]
	TIME [epoch: 24.7 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5035937917403039		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.5035937917403039 | validation: 0.5133586643133817]
	TIME [epoch: 24.7 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48994231912903385		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.48994231912903385 | validation: 0.5297903236680445]
	TIME [epoch: 24.7 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49560083201371274		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.49560083201371274 | validation: 0.5216109839798111]
	TIME [epoch: 24.7 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.478588381655505		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.478588381655505 | validation: 0.49029378245574556]
	TIME [epoch: 24.7 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43346562148549517		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.43346562148549517 | validation: 0.47219727499290065]
	TIME [epoch: 24.7 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4296200153312789		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.4296200153312789 | validation: 0.48048637761689306]
	TIME [epoch: 24.7 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4323112924073356		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.4323112924073356 | validation: 0.4765027506690562]
	TIME [epoch: 24.7 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4181604725981929		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.4181604725981929 | validation: 0.4676187641238782]
	TIME [epoch: 24.7 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42166745994047994		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.42166745994047994 | validation: 0.47400801783678265]
	TIME [epoch: 24.7 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42252606694532213		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.42252606694532213 | validation: 0.4625313601575833]
	TIME [epoch: 24.7 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42511708737832654		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.42511708737832654 | validation: 0.47569299338636045]
	TIME [epoch: 24.7 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4273662793643408		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.4273662793643408 | validation: 0.4720920385950764]
	TIME [epoch: 24.7 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40478675588906604		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.40478675588906604 | validation: 0.4566783988956926]
	TIME [epoch: 24.7 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40182682270884296		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.40182682270884296 | validation: 0.4594499927266064]
	TIME [epoch: 24.7 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41713672189618595		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.41713672189618595 | validation: 0.45966978986939416]
	TIME [epoch: 24.7 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41465172070332557		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.41465172070332557 | validation: 0.46382990676590324]
	TIME [epoch: 24.7 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.418621639653593		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.418621639653593 | validation: 0.47435562264462955]
	TIME [epoch: 24.7 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40301736798361737		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.40301736798361737 | validation: 0.4450573654823542]
	TIME [epoch: 24.7 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38624791708160783		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.38624791708160783 | validation: 0.4604970547199463]
	TIME [epoch: 24.7 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38966143922327057		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.38966143922327057 | validation: 0.4535212418237134]
	TIME [epoch: 24.7 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39648635789585995		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.39648635789585995 | validation: 0.45567915072512566]
	TIME [epoch: 24.7 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39502098274418207		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.39502098274418207 | validation: 0.4370837514758818]
	TIME [epoch: 24.7 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38579763228937736		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.38579763228937736 | validation: 0.4445248888749578]
	TIME [epoch: 24.7 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3870748990662487		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.3870748990662487 | validation: 0.4511153403982487]
	TIME [epoch: 24.7 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4078365765812677		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.4078365765812677 | validation: 0.45295762685825863]
	TIME [epoch: 24.7 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42013454360457086		[learning rate: 0.00019071]
	Learning Rate: 0.000190715
	LOSS [training: 0.42013454360457086 | validation: 0.46610516271726254]
	TIME [epoch: 24.7 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4063418853821098		[learning rate: 0.00019004]
	Learning Rate: 0.00019004
	LOSS [training: 0.4063418853821098 | validation: 0.4647627746697204]
	TIME [epoch: 24.7 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41596535950224944		[learning rate: 0.00018937]
	Learning Rate: 0.000189369
	LOSS [training: 0.41596535950224944 | validation: 0.475006176889747]
	TIME [epoch: 24.7 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4342194775825618		[learning rate: 0.0001887]
	Learning Rate: 0.000188699
	LOSS [training: 0.4342194775825618 | validation: 0.4815303328001214]
	TIME [epoch: 24.7 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43662854333276085		[learning rate: 0.00018803]
	Learning Rate: 0.000188032
	LOSS [training: 0.43662854333276085 | validation: 0.47047408639135896]
	TIME [epoch: 24.7 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409497573681822		[learning rate: 0.00018737]
	Learning Rate: 0.000187367
	LOSS [training: 0.409497573681822 | validation: 0.4739894895451824]
	TIME [epoch: 24.7 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42755684119455645		[learning rate: 0.0001867]
	Learning Rate: 0.000186704
	LOSS [training: 0.42755684119455645 | validation: 0.48678873495014174]
	TIME [epoch: 24.7 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4248317716086132		[learning rate: 0.00018604]
	Learning Rate: 0.000186044
	LOSS [training: 0.4248317716086132 | validation: 0.46632753547307837]
	TIME [epoch: 24.7 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4269141997669069		[learning rate: 0.00018539]
	Learning Rate: 0.000185386
	LOSS [training: 0.4269141997669069 | validation: 0.4749661360135253]
	TIME [epoch: 24.7 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4165186248043142		[learning rate: 0.00018473]
	Learning Rate: 0.00018473
	LOSS [training: 0.4165186248043142 | validation: 0.4507945217966943]
	TIME [epoch: 24.7 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39404142831776756		[learning rate: 0.00018408]
	Learning Rate: 0.000184077
	LOSS [training: 0.39404142831776756 | validation: 0.456543921428779]
	TIME [epoch: 24.7 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3931856334163645		[learning rate: 0.00018343]
	Learning Rate: 0.000183426
	LOSS [training: 0.3931856334163645 | validation: 0.4445250638656998]
	TIME [epoch: 24.7 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39831203869186077		[learning rate: 0.00018278]
	Learning Rate: 0.000182778
	LOSS [training: 0.39831203869186077 | validation: 0.45593782886756146]
	TIME [epoch: 24.7 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3932253483969159		[learning rate: 0.00018213]
	Learning Rate: 0.000182131
	LOSS [training: 0.3932253483969159 | validation: 0.44689757528297186]
	TIME [epoch: 24.7 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3795927581740017		[learning rate: 0.00018149]
	Learning Rate: 0.000181487
	LOSS [training: 0.3795927581740017 | validation: 0.4305851644950302]
	TIME [epoch: 24.7 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3911288764651769		[learning rate: 0.00018085]
	Learning Rate: 0.000180846
	LOSS [training: 0.3911288764651769 | validation: 0.43008527527369]
	TIME [epoch: 24.7 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38319708514658823		[learning rate: 0.00018021]
	Learning Rate: 0.000180206
	LOSS [training: 0.38319708514658823 | validation: 0.4382828291491386]
	TIME [epoch: 24.7 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.388614300190822		[learning rate: 0.00017957]
	Learning Rate: 0.000179569
	LOSS [training: 0.388614300190822 | validation: 0.43959571147644666]
	TIME [epoch: 24.7 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3865787075554531		[learning rate: 0.00017893]
	Learning Rate: 0.000178934
	LOSS [training: 0.3865787075554531 | validation: 0.4327602388805981]
	TIME [epoch: 24.7 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3862036399556578		[learning rate: 0.0001783]
	Learning Rate: 0.000178301
	LOSS [training: 0.3862036399556578 | validation: 0.4374778715205882]
	TIME [epoch: 24.7 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3894799090596883		[learning rate: 0.00017767]
	Learning Rate: 0.000177671
	LOSS [training: 0.3894799090596883 | validation: 0.43606869412657817]
	TIME [epoch: 24.7 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38424177289153394		[learning rate: 0.00017704]
	Learning Rate: 0.000177042
	LOSS [training: 0.38424177289153394 | validation: 0.4251714454001663]
	TIME [epoch: 24.7 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38521354723660195		[learning rate: 0.00017642]
	Learning Rate: 0.000176416
	LOSS [training: 0.38521354723660195 | validation: 0.43010234630084937]
	TIME [epoch: 24.7 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3797410345700971		[learning rate: 0.00017579]
	Learning Rate: 0.000175792
	LOSS [training: 0.3797410345700971 | validation: 0.4262063125260466]
	TIME [epoch: 24.7 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778229433164901		[learning rate: 0.00017517]
	Learning Rate: 0.000175171
	LOSS [training: 0.3778229433164901 | validation: 0.427917844469239]
	TIME [epoch: 24.7 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3778013707338928		[learning rate: 0.00017455]
	Learning Rate: 0.000174551
	LOSS [training: 0.3778013707338928 | validation: 0.4273099567635654]
	TIME [epoch: 24.7 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3794740175351732		[learning rate: 0.00017393]
	Learning Rate: 0.000173934
	LOSS [training: 0.3794740175351732 | validation: 0.4276084729260353]
	TIME [epoch: 24.7 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3813605078683648		[learning rate: 0.00017332]
	Learning Rate: 0.000173319
	LOSS [training: 0.3813605078683648 | validation: 0.45712342514005544]
	TIME [epoch: 24.7 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3926013540258213		[learning rate: 0.00017271]
	Learning Rate: 0.000172706
	LOSS [training: 0.3926013540258213 | validation: 0.45070209980746967]
	TIME [epoch: 24.7 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38756280908859764		[learning rate: 0.0001721]
	Learning Rate: 0.000172095
	LOSS [training: 0.38756280908859764 | validation: 0.4281677778147515]
	TIME [epoch: 24.7 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3804419130117386		[learning rate: 0.00017149]
	Learning Rate: 0.000171487
	LOSS [training: 0.3804419130117386 | validation: 0.4238498029638514]
	TIME [epoch: 24.7 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3721660140268921		[learning rate: 0.00017088]
	Learning Rate: 0.00017088
	LOSS [training: 0.3721660140268921 | validation: 0.43289701293878097]
	TIME [epoch: 24.7 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37786594094711384		[learning rate: 0.00017028]
	Learning Rate: 0.000170276
	LOSS [training: 0.37786594094711384 | validation: 0.44289183071133237]
	TIME [epoch: 24.7 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3888172343206321		[learning rate: 0.00016967]
	Learning Rate: 0.000169674
	LOSS [training: 0.3888172343206321 | validation: 0.4447835252076963]
	TIME [epoch: 24.7 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3892650631569178		[learning rate: 0.00016907]
	Learning Rate: 0.000169074
	LOSS [training: 0.3892650631569178 | validation: 0.4373120275918408]
	TIME [epoch: 24.7 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38776769936999883		[learning rate: 0.00016848]
	Learning Rate: 0.000168476
	LOSS [training: 0.38776769936999883 | validation: 0.4184562681397852]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_1203.pth
	Model improved!!!
EPOCH 1204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4004125610288477		[learning rate: 0.00016788]
	Learning Rate: 0.00016788
	LOSS [training: 0.4004125610288477 | validation: 0.4805258022141786]
	TIME [epoch: 24.7 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41691855607728334		[learning rate: 0.00016729]
	Learning Rate: 0.000167287
	LOSS [training: 0.41691855607728334 | validation: 0.44255098205595433]
	TIME [epoch: 24.7 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39755177785747164		[learning rate: 0.0001667]
	Learning Rate: 0.000166695
	LOSS [training: 0.39755177785747164 | validation: 0.4463286429143405]
	TIME [epoch: 24.7 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38424567389851005		[learning rate: 0.00016611]
	Learning Rate: 0.000166106
	LOSS [training: 0.38424567389851005 | validation: 0.4241524605297736]
	TIME [epoch: 24.7 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37768625964718666		[learning rate: 0.00016552]
	Learning Rate: 0.000165518
	LOSS [training: 0.37768625964718666 | validation: 0.44318407478155897]
	TIME [epoch: 24.7 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4160529964146645		[learning rate: 0.00016493]
	Learning Rate: 0.000164933
	LOSS [training: 0.4160529964146645 | validation: 0.5102867597134249]
	TIME [epoch: 24.7 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45792299751684745		[learning rate: 0.00016435]
	Learning Rate: 0.00016435
	LOSS [training: 0.45792299751684745 | validation: 0.49641811792233065]
	TIME [epoch: 24.7 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4300017384196887		[learning rate: 0.00016377]
	Learning Rate: 0.000163769
	LOSS [training: 0.4300017384196887 | validation: 0.44226001438617685]
	TIME [epoch: 24.7 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3836446394067754		[learning rate: 0.00016319]
	Learning Rate: 0.00016319
	LOSS [training: 0.3836446394067754 | validation: 0.4433157026341777]
	TIME [epoch: 24.7 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3971009002414795		[learning rate: 0.00016261]
	Learning Rate: 0.000162613
	LOSS [training: 0.3971009002414795 | validation: 0.4580377975573306]
	TIME [epoch: 24.7 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4038901013493795		[learning rate: 0.00016204]
	Learning Rate: 0.000162037
	LOSS [training: 0.4038901013493795 | validation: 0.4561681798139048]
	TIME [epoch: 24.7 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4256075131713456		[learning rate: 0.00016146]
	Learning Rate: 0.000161464
	LOSS [training: 0.4256075131713456 | validation: 0.5186687431090408]
	TIME [epoch: 24.7 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4753472231503526		[learning rate: 0.00016089]
	Learning Rate: 0.000160893
	LOSS [training: 0.4753472231503526 | validation: 0.4922003934207422]
	TIME [epoch: 24.7 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41273251797748073		[learning rate: 0.00016032]
	Learning Rate: 0.000160325
	LOSS [training: 0.41273251797748073 | validation: 0.4321811202958946]
	TIME [epoch: 24.7 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38012103089609905		[learning rate: 0.00015976]
	Learning Rate: 0.000159758
	LOSS [training: 0.38012103089609905 | validation: 0.432666041801818]
	TIME [epoch: 24.7 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.374103857269946		[learning rate: 0.00015919]
	Learning Rate: 0.000159193
	LOSS [training: 0.374103857269946 | validation: 0.4321764697742609]
	TIME [epoch: 24.7 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37316109934067276		[learning rate: 0.00015863]
	Learning Rate: 0.00015863
	LOSS [training: 0.37316109934067276 | validation: 0.42851023041309894]
	TIME [epoch: 24.7 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37371226223065757		[learning rate: 0.00015807]
	Learning Rate: 0.000158069
	LOSS [training: 0.37371226223065757 | validation: 0.4421054024161801]
	TIME [epoch: 24.7 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3891854874329237		[learning rate: 0.00015751]
	Learning Rate: 0.00015751
	LOSS [training: 0.3891854874329237 | validation: 0.4388053395132326]
	TIME [epoch: 24.7 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3764877340270442		[learning rate: 0.00015695]
	Learning Rate: 0.000156953
	LOSS [training: 0.3764877340270442 | validation: 0.43195091423391474]
	TIME [epoch: 24.7 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3712116947161842		[learning rate: 0.0001564]
	Learning Rate: 0.000156398
	LOSS [training: 0.3712116947161842 | validation: 0.4447522909193137]
	TIME [epoch: 24.7 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37501843172144106		[learning rate: 0.00015584]
	Learning Rate: 0.000155845
	LOSS [training: 0.37501843172144106 | validation: 0.4562171517560008]
	TIME [epoch: 24.7 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4160508501127703		[learning rate: 0.00015529]
	Learning Rate: 0.000155294
	LOSS [training: 0.4160508501127703 | validation: 0.5397164273092335]
	TIME [epoch: 24.7 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4728437964926749		[learning rate: 0.00015474]
	Learning Rate: 0.000154745
	LOSS [training: 0.4728437964926749 | validation: 0.4907887258310505]
	TIME [epoch: 24.7 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40305876685138303		[learning rate: 0.0001542]
	Learning Rate: 0.000154197
	LOSS [training: 0.40305876685138303 | validation: 0.42801911177041374]
	TIME [epoch: 24.7 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3701787604816683		[learning rate: 0.00015365]
	Learning Rate: 0.000153652
	LOSS [training: 0.3701787604816683 | validation: 0.41953578230103233]
	TIME [epoch: 24.7 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37180423958363756		[learning rate: 0.00015311]
	Learning Rate: 0.000153109
	LOSS [training: 0.37180423958363756 | validation: 0.42932669589242833]
	TIME [epoch: 24.7 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37686576306078		[learning rate: 0.00015257]
	Learning Rate: 0.000152567
	LOSS [training: 0.37686576306078 | validation: 0.4291353288937437]
	TIME [epoch: 24.7 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3846790931987818		[learning rate: 0.00015203]
	Learning Rate: 0.000152028
	LOSS [training: 0.3846790931987818 | validation: 0.4469956773375844]
	TIME [epoch: 24.7 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38545500104267105		[learning rate: 0.00015149]
	Learning Rate: 0.00015149
	LOSS [training: 0.38545500104267105 | validation: 0.4321345858689924]
	TIME [epoch: 24.7 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38443746382172794		[learning rate: 0.00015095]
	Learning Rate: 0.000150955
	LOSS [training: 0.38443746382172794 | validation: 0.46199232748930236]
	TIME [epoch: 24.7 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4057107119497902		[learning rate: 0.00015042]
	Learning Rate: 0.000150421
	LOSS [training: 0.4057107119497902 | validation: 0.45221491828717225]
	TIME [epoch: 24.7 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4104957077080022		[learning rate: 0.00014989]
	Learning Rate: 0.000149889
	LOSS [training: 0.4104957077080022 | validation: 0.45334448117076576]
	TIME [epoch: 24.7 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41436889947220407		[learning rate: 0.00014936]
	Learning Rate: 0.000149359
	LOSS [training: 0.41436889947220407 | validation: 0.4577803532927844]
	TIME [epoch: 24.7 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41090251369553993		[learning rate: 0.00014883]
	Learning Rate: 0.000148831
	LOSS [training: 0.41090251369553993 | validation: 0.4491672225390035]
	TIME [epoch: 24.7 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3999992089961448		[learning rate: 0.0001483]
	Learning Rate: 0.000148304
	LOSS [training: 0.3999992089961448 | validation: 0.44752749629435]
	TIME [epoch: 24.7 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41423460405386386		[learning rate: 0.00014778]
	Learning Rate: 0.00014778
	LOSS [training: 0.41423460405386386 | validation: 0.4733941857743814]
	TIME [epoch: 24.7 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4451096981393189		[learning rate: 0.00014726]
	Learning Rate: 0.000147257
	LOSS [training: 0.4451096981393189 | validation: 0.500457733549339]
	TIME [epoch: 24.7 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.436530496877426		[learning rate: 0.00014674]
	Learning Rate: 0.000146737
	LOSS [training: 0.436530496877426 | validation: 0.45821494659604434]
	TIME [epoch: 24.7 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40456050605435784		[learning rate: 0.00014622]
	Learning Rate: 0.000146218
	LOSS [training: 0.40456050605435784 | validation: 0.45603340608465104]
	TIME [epoch: 24.7 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41469440732318896		[learning rate: 0.0001457]
	Learning Rate: 0.000145701
	LOSS [training: 0.41469440732318896 | validation: 0.46110677336239314]
	TIME [epoch: 24.7 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40568970481336797		[learning rate: 0.00014519]
	Learning Rate: 0.000145185
	LOSS [training: 0.40568970481336797 | validation: 0.43778430438249244]
	TIME [epoch: 24.7 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3814360435146609		[learning rate: 0.00014467]
	Learning Rate: 0.000144672
	LOSS [training: 0.3814360435146609 | validation: 0.43823491285872784]
	TIME [epoch: 24.7 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37553285088028093		[learning rate: 0.00014416]
	Learning Rate: 0.00014416
	LOSS [training: 0.37553285088028093 | validation: 0.43625281568401486]
	TIME [epoch: 24.7 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3783543750682947		[learning rate: 0.00014365]
	Learning Rate: 0.000143651
	LOSS [training: 0.3783543750682947 | validation: 0.4371361110485063]
	TIME [epoch: 24.7 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.376688375457608		[learning rate: 0.00014314]
	Learning Rate: 0.000143143
	LOSS [training: 0.376688375457608 | validation: 0.4323947508404939]
	TIME [epoch: 24.7 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3695292273837528		[learning rate: 0.00014264]
	Learning Rate: 0.000142637
	LOSS [training: 0.3695292273837528 | validation: 0.42453449690503947]
	TIME [epoch: 24.7 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3767442096041306		[learning rate: 0.00014213]
	Learning Rate: 0.000142132
	LOSS [training: 0.3767442096041306 | validation: 0.44307720435704406]
	TIME [epoch: 24.7 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38600508791032906		[learning rate: 0.00014163]
	Learning Rate: 0.00014163
	LOSS [training: 0.38600508791032906 | validation: 0.43806442290733494]
	TIME [epoch: 24.7 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3978457795549362		[learning rate: 0.00014113]
	Learning Rate: 0.000141129
	LOSS [training: 0.3978457795549362 | validation: 0.4633719739002146]
	TIME [epoch: 24.7 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.400990766966737		[learning rate: 0.00014063]
	Learning Rate: 0.00014063
	LOSS [training: 0.400990766966737 | validation: 0.4553971568647354]
	TIME [epoch: 24.7 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42248291203344535		[learning rate: 0.00014013]
	Learning Rate: 0.000140132
	LOSS [training: 0.42248291203344535 | validation: 0.5143871814405141]
	TIME [epoch: 24.7 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.457706035997699		[learning rate: 0.00013964]
	Learning Rate: 0.000139637
	LOSS [training: 0.457706035997699 | validation: 0.502150698197094]
	TIME [epoch: 24.7 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367676009985054		[learning rate: 0.00013914]
	Learning Rate: 0.000139143
	LOSS [training: 0.4367676009985054 | validation: 0.4416942361187739]
	TIME [epoch: 24.7 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38638333914828477		[learning rate: 0.00013865]
	Learning Rate: 0.000138651
	LOSS [training: 0.38638333914828477 | validation: 0.434819698346309]
	TIME [epoch: 24.7 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38011153236015927		[learning rate: 0.00013816]
	Learning Rate: 0.000138161
	LOSS [training: 0.38011153236015927 | validation: 0.42823731415087624]
	TIME [epoch: 24.7 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37625156608697363		[learning rate: 0.00013767]
	Learning Rate: 0.000137672
	LOSS [training: 0.37625156608697363 | validation: 0.4232067701131469]
	TIME [epoch: 24.7 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36857372928511434		[learning rate: 0.00013719]
	Learning Rate: 0.000137185
	LOSS [training: 0.36857372928511434 | validation: 0.4286164956382666]
	TIME [epoch: 24.7 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3745882721765225		[learning rate: 0.0001367]
	Learning Rate: 0.0001367
	LOSS [training: 0.3745882721765225 | validation: 0.4171043995139507]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_1262.pth
	Model improved!!!
EPOCH 1263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37065940154764365		[learning rate: 0.00013622]
	Learning Rate: 0.000136217
	LOSS [training: 0.37065940154764365 | validation: 0.41766744374463416]
	TIME [epoch: 24.7 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37241181858470085		[learning rate: 0.00013574]
	Learning Rate: 0.000135735
	LOSS [training: 0.37241181858470085 | validation: 0.43266589164852376]
	TIME [epoch: 24.7 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3743576888269898		[learning rate: 0.00013526]
	Learning Rate: 0.000135255
	LOSS [training: 0.3743576888269898 | validation: 0.42696927484163527]
	TIME [epoch: 24.7 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3748205121040505		[learning rate: 0.00013478]
	Learning Rate: 0.000134777
	LOSS [training: 0.3748205121040505 | validation: 0.42865982813042763]
	TIME [epoch: 24.7 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3708361843879087		[learning rate: 0.0001343]
	Learning Rate: 0.0001343
	LOSS [training: 0.3708361843879087 | validation: 0.45097234989041324]
	TIME [epoch: 24.7 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38405828275617976		[learning rate: 0.00013383]
	Learning Rate: 0.000133825
	LOSS [training: 0.38405828275617976 | validation: 0.42672899390233]
	TIME [epoch: 24.7 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3808441491097294		[learning rate: 0.00013335]
	Learning Rate: 0.000133352
	LOSS [training: 0.3808441491097294 | validation: 0.43609520262206697]
	TIME [epoch: 24.7 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38053121941728557		[learning rate: 0.00013288]
	Learning Rate: 0.000132881
	LOSS [training: 0.38053121941728557 | validation: 0.44420259884444563]
	TIME [epoch: 24.7 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3790100910805343		[learning rate: 0.00013241]
	Learning Rate: 0.000132411
	LOSS [training: 0.3790100910805343 | validation: 0.43415929362408195]
	TIME [epoch: 24.7 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37236612799474167		[learning rate: 0.00013194]
	Learning Rate: 0.000131942
	LOSS [training: 0.37236612799474167 | validation: 0.43285635350484386]
	TIME [epoch: 24.7 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.373189502299496		[learning rate: 0.00013148]
	Learning Rate: 0.000131476
	LOSS [training: 0.373189502299496 | validation: 0.4418155890553942]
	TIME [epoch: 24.7 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3775779430216567		[learning rate: 0.00013101]
	Learning Rate: 0.000131011
	LOSS [training: 0.3775779430216567 | validation: 0.4346820288572603]
	TIME [epoch: 24.7 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.371430917400838		[learning rate: 0.00013055]
	Learning Rate: 0.000130548
	LOSS [training: 0.371430917400838 | validation: 0.423935463633647]
	TIME [epoch: 24.7 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37323743030396117		[learning rate: 0.00013009]
	Learning Rate: 0.000130086
	LOSS [training: 0.37323743030396117 | validation: 0.42899235820896553]
	TIME [epoch: 24.7 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37232311620558395		[learning rate: 0.00012963]
	Learning Rate: 0.000129626
	LOSS [training: 0.37232311620558395 | validation: 0.42643873768877344]
	TIME [epoch: 24.7 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3739096940871787		[learning rate: 0.00012917]
	Learning Rate: 0.000129168
	LOSS [training: 0.3739096940871787 | validation: 0.4344565105338784]
	TIME [epoch: 24.7 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37779905254310175		[learning rate: 0.00012871]
	Learning Rate: 0.000128711
	LOSS [training: 0.37779905254310175 | validation: 0.42676387083558914]
	TIME [epoch: 24.7 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36797233396958656		[learning rate: 0.00012826]
	Learning Rate: 0.000128256
	LOSS [training: 0.36797233396958656 | validation: 0.4266355002427902]
	TIME [epoch: 24.7 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3761711825068531		[learning rate: 0.0001278]
	Learning Rate: 0.000127802
	LOSS [training: 0.3761711825068531 | validation: 0.4467839450127177]
	TIME [epoch: 24.7 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3810000397894139		[learning rate: 0.00012735]
	Learning Rate: 0.00012735
	LOSS [training: 0.3810000397894139 | validation: 0.44554554700890336]
	TIME [epoch: 24.7 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3856780094109988		[learning rate: 0.0001269]
	Learning Rate: 0.0001269
	LOSS [training: 0.3856780094109988 | validation: 0.43710927167258745]
	TIME [epoch: 24.7 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.371485644243159		[learning rate: 0.00012645]
	Learning Rate: 0.000126451
	LOSS [training: 0.371485644243159 | validation: 0.4261412553480548]
	TIME [epoch: 24.7 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3676531179621302		[learning rate: 0.000126]
	Learning Rate: 0.000126004
	LOSS [training: 0.3676531179621302 | validation: 0.4130627009245758]
	TIME [epoch: 24.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240310_004323/states/model_tr_study6_1285.pth
	Model improved!!!
EPOCH 1286/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37089408083593833		[learning rate: 0.00012556]
	Learning Rate: 0.000125559
	LOSS [training: 0.37089408083593833 | validation: 0.42655517137119775]
	TIME [epoch: 24.7 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3678610005638412		[learning rate: 0.00012511]
	Learning Rate: 0.000125115
	LOSS [training: 0.3678610005638412 | validation: 0.428466385450962]
	TIME [epoch: 24.7 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3666092741620476		[learning rate: 0.00012467]
	Learning Rate: 0.000124672
	LOSS [training: 0.3666092741620476 | validation: 0.42664382201211776]
	TIME [epoch: 24.7 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37572035267888015		[learning rate: 0.00012423]
	Learning Rate: 0.000124231
	LOSS [training: 0.37572035267888015 | validation: 0.4349800846879605]
	TIME [epoch: 24.7 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38452217905259733		[learning rate: 0.00012379]
	Learning Rate: 0.000123792
	LOSS [training: 0.38452217905259733 | validation: 0.44897310136431884]
	TIME [epoch: 24.7 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4182917833499845		[learning rate: 0.00012335]
	Learning Rate: 0.000123354
	LOSS [training: 0.4182917833499845 | validation: 0.48350126914063807]
	TIME [epoch: 24.7 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4327738725060702		[learning rate: 0.00012292]
	Learning Rate: 0.000122918
	LOSS [training: 0.4327738725060702 | validation: 0.464979560361735]
	TIME [epoch: 24.7 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4199122910330929		[learning rate: 0.00012248]
	Learning Rate: 0.000122483
	LOSS [training: 0.4199122910330929 | validation: 0.46299325475656505]
	TIME [epoch: 24.7 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4379141802184713		[learning rate: 0.00012205]
	Learning Rate: 0.00012205
	LOSS [training: 0.4379141802184713 | validation: 0.4685146946630192]
	TIME [epoch: 24.7 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4282670844638695		[learning rate: 0.00012162]
	Learning Rate: 0.000121619
	LOSS [training: 0.4282670844638695 | validation: 0.4621393908987777]
	TIME [epoch: 24.7 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4289926222774915		[learning rate: 0.00012119]
	Learning Rate: 0.000121189
	LOSS [training: 0.4289926222774915 | validation: 0.4732633445227009]
	TIME [epoch: 24.7 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4317688440346087		[learning rate: 0.00012076]
	Learning Rate: 0.00012076
	LOSS [training: 0.4317688440346087 | validation: 0.46236143657942813]
	TIME [epoch: 24.7 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4072445315309665		[learning rate: 0.00012033]
	Learning Rate: 0.000120333
	LOSS [training: 0.4072445315309665 | validation: 0.4645255752649649]
	TIME [epoch: 24.7 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4262284836751529		[learning rate: 0.00011991]
	Learning Rate: 0.000119907
	LOSS [training: 0.4262284836751529 | validation: 0.48730959122067335]
	TIME [epoch: 24.7 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4594453074036529		[learning rate: 0.00011948]
	Learning Rate: 0.000119483
	LOSS [training: 0.4594453074036529 | validation: 0.5005312998472655]
	TIME [epoch: 24.7 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45425297328451597		[learning rate: 0.00011906]
	Learning Rate: 0.000119061
	LOSS [training: 0.45425297328451597 | validation: 0.48438179742511495]
	TIME [epoch: 24.7 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4500617969751699		[learning rate: 0.00011864]
	Learning Rate: 0.00011864
	LOSS [training: 0.4500617969751699 | validation: 0.48450481838831366]
	TIME [epoch: 24.7 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43499842926587545		[learning rate: 0.00011822]
	Learning Rate: 0.00011822
	LOSS [training: 0.43499842926587545 | validation: 0.4648501394185199]
	TIME [epoch: 24.7 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4267892504778077		[learning rate: 0.0001178]
	Learning Rate: 0.000117802
	LOSS [training: 0.4267892504778077 | validation: 0.4967485589712526]
	TIME [epoch: 24.7 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4529681947965071		[learning rate: 0.00011739]
	Learning Rate: 0.000117386
	LOSS [training: 0.4529681947965071 | validation: 0.4773432966342845]
	TIME [epoch: 24.7 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43227016644693284		[learning rate: 0.00011697]
	Learning Rate: 0.000116971
	LOSS [training: 0.43227016644693284 | validation: 0.4546782130755389]
	TIME [epoch: 24.7 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40796204574395245		[learning rate: 0.00011656]
	Learning Rate: 0.000116557
	LOSS [training: 0.40796204574395245 | validation: 0.45547864393736276]
	TIME [epoch: 24.7 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4007778223930658		[learning rate: 0.00011614]
	Learning Rate: 0.000116145
	LOSS [training: 0.4007778223930658 | validation: 0.4456244587040798]
	TIME [epoch: 24.7 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40033804509571913		[learning rate: 0.00011573]
	Learning Rate: 0.000115734
	LOSS [training: 0.40033804509571913 | validation: 0.4430257167332288]
	TIME [epoch: 24.7 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.384710198707212		[learning rate: 0.00011532]
	Learning Rate: 0.000115325
	LOSS [training: 0.384710198707212 | validation: 0.45994203210862117]
	TIME [epoch: 24.7 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4010534039910634		[learning rate: 0.00011492]
	Learning Rate: 0.000114917
	LOSS [training: 0.4010534039910634 | validation: 0.4597699223196791]
	TIME [epoch: 24.7 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41148444362804293		[learning rate: 0.00011451]
	Learning Rate: 0.000114511
	LOSS [training: 0.41148444362804293 | validation: 0.4646113342653941]
	TIME [epoch: 24.7 sec]
EPOCH 1313/2000:
	Training over batches...
