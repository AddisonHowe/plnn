Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r3', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4019784501

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.09321511198435		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.09321511198435 | validation: 9.173906677500234]
	TIME [epoch: 54.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.806212422305741		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.806212422305741 | validation: 7.277547594963752]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.350563190365849		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.350563190365849 | validation: 7.01566281179968]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.372324219656081		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.372324219656081 | validation: 6.2745619688908425]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.990660153593036		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.990660153593036 | validation: 6.103546539580341]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.80581533294758		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.80581533294758 | validation: 6.92184051532361]
	TIME [epoch: 9.78 sec]
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.94129330021822		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.94129330021822 | validation: 5.922036318236608]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.595745231959226		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.595745231959226 | validation: 5.654989365037102]
	TIME [epoch: 9.96 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.418845798071966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.418845798071966 | validation: 5.620415854152862]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.484002207123469		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.484002207123469 | validation: 5.637367379965524]
	TIME [epoch: 9.78 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.276610183499976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.276610183499976 | validation: 5.460039421153052]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.605619152855168		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.605619152855168 | validation: 5.23802900016309]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.207763907881498		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.207763907881498 | validation: 4.520542334395609]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.831947856862522		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.831947856862522 | validation: 5.203828264140568]
	TIME [epoch: 9.75 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.779863741257139		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.779863741257139 | validation: 4.303669153076423]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.489868087696786		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.489868087696786 | validation: 4.289970197755925]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.457688972089352		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.457688972089352 | validation: 4.136107077820958]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.122563769148679		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.122563769148679 | validation: 4.135426315297674]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.220879918828043		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.220879918828043 | validation: 3.7975615114022343]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.891938870958195		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.891938870958195 | validation: 3.7762859800463024]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.076921101881135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.076921101881135 | validation: 3.521959460856531]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7929205885726764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7929205885726764 | validation: 3.5242199781937873]
	TIME [epoch: 9.79 sec]
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.006808768480683		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.006808768480683 | validation: 3.584230500119626]
	TIME [epoch: 9.76 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6984536694511205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6984536694511205 | validation: 3.405399047436705]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9546082346191804		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9546082346191804 | validation: 3.3054119908986266]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.641108374594828		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.641108374594828 | validation: 3.4211582060304897]
	TIME [epoch: 9.78 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.847624975271973		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.847624975271973 | validation: 3.381422264497553]
	TIME [epoch: 9.77 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5744977164825373		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5744977164825373 | validation: 3.2682413700787722]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_28.pth
	Model improved!!!
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5106701931661464		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5106701931661464 | validation: 3.257279097264282]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_29.pth
	Model improved!!!
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.388951047648356		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.388951047648356 | validation: 3.0320748861082087]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2283471798644383		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2283471798644383 | validation: 2.8538081081125903]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.284703911442098		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.284703911442098 | validation: 2.71863117730436]
	TIME [epoch: 9.79 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_32.pth
	Model improved!!!
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0361274617455125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0361274617455125 | validation: 3.040764952419179]
	TIME [epoch: 9.77 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7384290611824875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7384290611824875 | validation: 2.834283606993089]
	TIME [epoch: 9.78 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.861144229488181		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.861144229488181 | validation: 2.2743625644159433]
	TIME [epoch: 9.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_35.pth
	Model improved!!!
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.575321827323002		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.575321827323002 | validation: 2.3126802064915677]
	TIME [epoch: 9.76 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.124020596518117		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.124020596518117 | validation: 3.6515592148841725]
	TIME [epoch: 9.75 sec]
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9387820948743277		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9387820948743277 | validation: 5.537139785752589]
	TIME [epoch: 9.77 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.526341492853265		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.526341492853265 | validation: 3.546029742134932]
	TIME [epoch: 9.76 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.489457401751303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.489457401751303 | validation: 2.7835308999669803]
	TIME [epoch: 9.75 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9848204237868132		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9848204237868132 | validation: 3.0070955791157874]
	TIME [epoch: 9.78 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1044432195587186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1044432195587186 | validation: 3.4231281936578433]
	TIME [epoch: 9.76 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.053932886182809		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.053932886182809 | validation: 4.330689642405488]
	TIME [epoch: 9.76 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.130317109328426		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.130317109328426 | validation: 3.6615813374460915]
	TIME [epoch: 9.76 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.9932751996116047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.9932751996116047 | validation: 3.96369391272476]
	TIME [epoch: 9.77 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6412154154916707		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6412154154916707 | validation: 3.562155148938452]
	TIME [epoch: 9.76 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.049139510125633		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.049139510125633 | validation: 3.356739434123747]
	TIME [epoch: 9.75 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4156373281399963		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4156373281399963 | validation: 2.9738647251650696]
	TIME [epoch: 9.78 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7197281310330346		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7197281310330346 | validation: 3.2220859260979315]
	TIME [epoch: 9.75 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.28062634228361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.28062634228361 | validation: 4.42548414685533]
	TIME [epoch: 9.75 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.112097639117215		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.112097639117215 | validation: 3.2605947551111893]
	TIME [epoch: 9.76 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6770293476678235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6770293476678235 | validation: 3.4397742931717983]
	TIME [epoch: 9.75 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5322998270502053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5322998270502053 | validation: 3.0135579332701683]
	TIME [epoch: 9.74 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4094084945179617		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4094084945179617 | validation: 2.98795856067023]
	TIME [epoch: 9.77 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.253220773331235		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.253220773331235 | validation: 2.913054713573684]
	TIME [epoch: 9.75 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1912694829001635		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1912694829001635 | validation: 2.9097591602266504]
	TIME [epoch: 9.75 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1662961066185518		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1662961066185518 | validation: 2.8880036490413046]
	TIME [epoch: 9.75 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.187719124793001		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.187719124793001 | validation: 2.830064050698443]
	TIME [epoch: 9.77 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.07634901090616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.07634901090616 | validation: 2.7607481612760534]
	TIME [epoch: 9.75 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.062777741863653		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.062777741863653 | validation: 2.672371338389262]
	TIME [epoch: 9.75 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0512339374070923		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0512339374070923 | validation: 2.8539727616295143]
	TIME [epoch: 9.77 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4854786175419905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4854786175419905 | validation: 5.485547936701819]
	TIME [epoch: 9.76 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.538141590864909		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.538141590864909 | validation: 3.0472960611398436]
	TIME [epoch: 9.75 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4350765555010327		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4350765555010327 | validation: 2.788831713148029]
	TIME [epoch: 9.78 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.8725072719541407		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8725072719541407 | validation: 3.388938984006454]
	TIME [epoch: 9.76 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4121042886419737		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4121042886419737 | validation: 4.678549024052576]
	TIME [epoch: 9.76 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.193045798071416		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.193045798071416 | validation: 3.0790782453031413]
	TIME [epoch: 9.76 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.154392432314979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.154392432314979 | validation: 2.763059136067416]
	TIME [epoch: 9.75 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.040232579155792		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.040232579155792 | validation: 2.747232387504871]
	TIME [epoch: 9.75 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.029393494887553		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.029393494887553 | validation: 2.731538138180421]
	TIME [epoch: 9.75 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.010600249151039		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.010600249151039 | validation: 2.5258947504986264]
	TIME [epoch: 9.78 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0451851714983205		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0451851714983205 | validation: 2.5761741831826623]
	TIME [epoch: 9.74 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8041861951510225		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8041861951510225 | validation: 2.140757448371048]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_73.pth
	Model improved!!!
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8235162046679094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8235162046679094 | validation: 2.754474297760047]
	TIME [epoch: 9.79 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0095975875601497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.0095975875601497 | validation: 1.344850392926155]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_75.pth
	Model improved!!!
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.383060781480985		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.383060781480985 | validation: 1.2223389976584262]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_76.pth
	Model improved!!!
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5491645658734288		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5491645658734288 | validation: 1.5701767273584954]
	TIME [epoch: 9.77 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5359155789965437		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.5359155789965437 | validation: 1.8065464474862278]
	TIME [epoch: 9.75 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.297794676965432		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.297794676965432 | validation: 1.0781886127811822]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6127404773145861		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.6127404773145861 | validation: 2.49257961715955]
	TIME [epoch: 9.77 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6995753718889106		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6995753718889106 | validation: 5.582805180044791]
	TIME [epoch: 9.75 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.5988176784816925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.5988176784816925 | validation: 5.019926912987564]
	TIME [epoch: 9.76 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.217237021148841		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.217237021148841 | validation: 4.917852260608375]
	TIME [epoch: 9.75 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.173998322795616		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.173998322795616 | validation: 4.772712710873862]
	TIME [epoch: 9.77 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.019632678955428		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.019632678955428 | validation: 6.0294627295131455]
	TIME [epoch: 9.75 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.457590933248911		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.457590933248911 | validation: 4.864802040063101]
	TIME [epoch: 9.74 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.6375962187303488		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6375962187303488 | validation: 2.6175557444129596]
	TIME [epoch: 9.77 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4170268046130157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4170268046130157 | validation: 0.9517978051169569]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_88.pth
	Model improved!!!
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.104111013491016		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.104111013491016 | validation: 1.9710878915607402]
	TIME [epoch: 9.75 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.268013211413305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.268013211413305 | validation: 2.1371464043272246]
	TIME [epoch: 9.76 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4769885982066904		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4769885982066904 | validation: 0.9322776398366881]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_91.pth
	Model improved!!!
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2596497169194558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.2596497169194558 | validation: 0.9080751356477705]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_92.pth
	Model improved!!!
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1392099019374533		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1392099019374533 | validation: 1.2645517990933777]
	TIME [epoch: 9.76 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0248288195993358		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.0248288195993358 | validation: 0.9606247887974004]
	TIME [epoch: 9.75 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8204031115959772		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 0.8204031115959772 | validation: 1.6803467181268088]
	TIME [epoch: 9.76 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4035550216594574		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.4035550216594574 | validation: 1.066428683835796]
	TIME [epoch: 9.76 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1333608622204847		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1333608622204847 | validation: 0.9038095678733185]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.482435550418462		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.482435550418462 | validation: 2.3575289686258363]
	TIME [epoch: 9.75 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3809927769179124		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.3809927769179124 | validation: 1.214607996155702]
	TIME [epoch: 9.76 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1748096405309214		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 1.1748096405309214 | validation: 1.8642261823932336]
	TIME [epoch: 9.78 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2740627280854384		[learning rate: 0.0099806]
	Learning Rate: 0.00998063
	LOSS [training: 1.2740627280854384 | validation: 1.0165122910916926]
	TIME [epoch: 9.77 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9846522554966887		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 0.9846522554966887 | validation: 1.0369902496581933]
	TIME [epoch: 9.75 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3653416138541994		[learning rate: 0.0099324]
	Learning Rate: 0.00993236
	LOSS [training: 1.3653416138541994 | validation: 1.7353673899760114]
	TIME [epoch: 9.78 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.183545349788945		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 1.183545349788945 | validation: 1.0326737991791464]
	TIME [epoch: 9.75 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1827064167043742		[learning rate: 0.0098843]
	Learning Rate: 0.00988433
	LOSS [training: 1.1827064167043742 | validation: 0.9899339968279818]
	TIME [epoch: 9.76 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1373722181281631		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 1.1373722181281631 | validation: 1.124820776923572]
	TIME [epoch: 9.77 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.905261244149586		[learning rate: 0.0098365]
	Learning Rate: 0.00983653
	LOSS [training: 0.905261244149586 | validation: 0.8985179025865406]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_107.pth
	Model improved!!!
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7748716322907272		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 0.7748716322907272 | validation: 0.9046114982981118]
	TIME [epoch: 9.76 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8315737244917335		[learning rate: 0.009789]
	Learning Rate: 0.00978897
	LOSS [training: 0.8315737244917335 | validation: 1.0738313393613619]
	TIME [epoch: 9.79 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8355356672685881		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 0.8355356672685881 | validation: 0.7480457225305435]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7880989995125006		[learning rate: 0.0097416]
	Learning Rate: 0.00974163
	LOSS [training: 0.7880989995125006 | validation: 1.015341046811599]
	TIME [epoch: 9.76 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9492058154705024		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 0.9492058154705024 | validation: 0.8958060462599758]
	TIME [epoch: 9.76 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7667076711486658		[learning rate: 0.0096945]
	Learning Rate: 0.00969452
	LOSS [training: 0.7667076711486658 | validation: 1.449259861731971]
	TIME [epoch: 9.77 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8996903902016861		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 0.8996903902016861 | validation: 0.7361158653555226]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_114.pth
	Model improved!!!
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.735402103507067		[learning rate: 0.0096476]
	Learning Rate: 0.00964764
	LOSS [training: 0.735402103507067 | validation: 1.007194542878136]
	TIME [epoch: 9.77 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0300148574262227		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 1.0300148574262227 | validation: 0.9250906415104546]
	TIME [epoch: 9.78 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8082742065839973		[learning rate: 0.009601]
	Learning Rate: 0.00960098
	LOSS [training: 0.8082742065839973 | validation: 0.8000565638106614]
	TIME [epoch: 9.76 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8237027069813019		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 0.8237027069813019 | validation: 1.6166792486634542]
	TIME [epoch: 9.76 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9424937789212823		[learning rate: 0.0095546]
	Learning Rate: 0.00955456
	LOSS [training: 0.9424937789212823 | validation: 0.7339123626136261]
	TIME [epoch: 9.78 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_119.pth
	Model improved!!!
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.828033452841878		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 0.828033452841878 | validation: 0.7145870476886239]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_120.pth
	Model improved!!!
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5424139513203687		[learning rate: 0.0095084]
	Learning Rate: 0.00950835
	LOSS [training: 1.5424139513203687 | validation: 0.7432906300062305]
	TIME [epoch: 9.76 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8439616323883588		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 0.8439616323883588 | validation: 2.051214183163086]
	TIME [epoch: 9.77 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.304377819050336		[learning rate: 0.0094624]
	Learning Rate: 0.00946237
	LOSS [training: 1.304377819050336 | validation: 0.701007154188024]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_123.pth
	Model improved!!!
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4141707360536908		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 1.4141707360536908 | validation: 1.4970183390689205]
	TIME [epoch: 9.75 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8788735556795702		[learning rate: 0.0094166]
	Learning Rate: 0.00941661
	LOSS [training: 0.8788735556795702 | validation: 0.7728311684404323]
	TIME [epoch: 9.75 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7264367725157251		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 0.7264367725157251 | validation: 0.6603098255693064]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_126.pth
	Model improved!!!
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7750514583638539		[learning rate: 0.0093711]
	Learning Rate: 0.00937108
	LOSS [training: 0.7750514583638539 | validation: 0.9625543573217852]
	TIME [epoch: 9.75 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.012654110945408		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 1.012654110945408 | validation: 0.888921889474182]
	TIME [epoch: 9.75 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8235215386951993		[learning rate: 0.0093258]
	Learning Rate: 0.00932576
	LOSS [training: 0.8235215386951993 | validation: 0.852758641443817]
	TIME [epoch: 9.77 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.894328413216779		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 0.894328413216779 | validation: 0.9002134204844492]
	TIME [epoch: 9.76 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1431536563327982		[learning rate: 0.0092807]
	Learning Rate: 0.00928066
	LOSS [training: 1.1431536563327982 | validation: 1.7072187040195683]
	TIME [epoch: 9.75 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9864179602299629		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 0.9864179602299629 | validation: 0.6893646501893411]
	TIME [epoch: 9.77 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7460097118795233		[learning rate: 0.0092358]
	Learning Rate: 0.00923578
	LOSS [training: 0.7460097118795233 | validation: 0.6769408442425234]
	TIME [epoch: 9.75 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7325282703046426		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 0.7325282703046426 | validation: 0.8741338576180141]
	TIME [epoch: 9.75 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7926929449762327		[learning rate: 0.0091911]
	Learning Rate: 0.00919112
	LOSS [training: 0.7926929449762327 | validation: 0.7591210697934442]
	TIME [epoch: 9.76 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.381993346029026		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.381993346029026 | validation: 2.746749994485997]
	TIME [epoch: 9.76 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.636080618712016		[learning rate: 0.0091467]
	Learning Rate: 0.00914667
	LOSS [training: 1.636080618712016 | validation: 1.3866220818808352]
	TIME [epoch: 9.75 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1141258366579998		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 1.1141258366579998 | validation: 0.680108461921395]
	TIME [epoch: 9.75 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5923997340203729		[learning rate: 0.0091024]
	Learning Rate: 0.00910244
	LOSS [training: 0.5923997340203729 | validation: 0.589374077225945]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8577771081932705		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 0.8577771081932705 | validation: 0.8389425292214991]
	TIME [epoch: 9.75 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4088438598991369		[learning rate: 0.0090584]
	Learning Rate: 0.00905842
	LOSS [training: 1.4088438598991369 | validation: 0.9658513614751207]
	TIME [epoch: 9.75 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.783091734468002		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 0.783091734468002 | validation: 0.6327872496278483]
	TIME [epoch: 9.78 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6171869746781433		[learning rate: 0.0090146]
	Learning Rate: 0.00901462
	LOSS [training: 0.6171869746781433 | validation: 0.5600997851957183]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_143.pth
	Model improved!!!
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.585724582912145		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 0.585724582912145 | validation: 0.5126967369225441]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_144.pth
	Model improved!!!
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6783736234076378		[learning rate: 0.008971]
	Learning Rate: 0.00897103
	LOSS [training: 0.6783736234076378 | validation: 3.600543546702663]
	TIME [epoch: 9.78 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5092147464486283		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 1.5092147464486283 | validation: 0.6319931948418428]
	TIME [epoch: 9.76 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6899938551222421		[learning rate: 0.0089276]
	Learning Rate: 0.00892764
	LOSS [training: 0.6899938551222421 | validation: 0.807427888764509]
	TIME [epoch: 9.75 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8215759913039278		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 0.8215759913039278 | validation: 0.6540758997779069]
	TIME [epoch: 9.78 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6939336287594183		[learning rate: 0.0088845]
	Learning Rate: 0.00888447
	LOSS [training: 0.6939336287594183 | validation: 0.5052843613220063]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_149.pth
	Model improved!!!
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8262502635057245		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 0.8262502635057245 | validation: 0.9192978241357996]
	TIME [epoch: 9.76 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9939910193017871		[learning rate: 0.0088415]
	Learning Rate: 0.00884151
	LOSS [training: 0.9939910193017871 | validation: 0.770046019608371]
	TIME [epoch: 9.78 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7681993344702145		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 0.7681993344702145 | validation: 0.8377354796199574]
	TIME [epoch: 9.75 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7888540162398959		[learning rate: 0.0087988]
	Learning Rate: 0.00879875
	LOSS [training: 0.7888540162398959 | validation: 0.7726624952549608]
	TIME [epoch: 9.75 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7054410638634131		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 0.7054410638634131 | validation: 0.61655122340041]
	TIME [epoch: 9.75 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.660070704886698		[learning rate: 0.0087562]
	Learning Rate: 0.0087562
	LOSS [training: 0.660070704886698 | validation: 0.9881702040556668]
	TIME [epoch: 9.78 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9494771254295585		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 0.9494771254295585 | validation: 0.7378058318110349]
	TIME [epoch: 9.75 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7757179637884		[learning rate: 0.0087139]
	Learning Rate: 0.00871386
	LOSS [training: 0.7757179637884 | validation: 0.7655402346659571]
	TIME [epoch: 9.75 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6567005308131924		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 0.6567005308131924 | validation: 1.071761099487355]
	TIME [epoch: 9.78 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9098159217056148		[learning rate: 0.0086717]
	Learning Rate: 0.00867172
	LOSS [training: 0.9098159217056148 | validation: 0.88621510824372]
	TIME [epoch: 9.76 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.672980319279871		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 0.672980319279871 | validation: 0.5220043725326565]
	TIME [epoch: 9.75 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6476536039596376		[learning rate: 0.0086298]
	Learning Rate: 0.00862979
	LOSS [training: 0.6476536039596376 | validation: 0.5615040414972204]
	TIME [epoch: 9.78 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7337085100500265		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 0.7337085100500265 | validation: 0.5344051362364494]
	TIME [epoch: 9.77 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5824275953188548		[learning rate: 0.0085881]
	Learning Rate: 0.00858805
	LOSS [training: 0.5824275953188548 | validation: 0.4813300140479486]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_163.pth
	Model improved!!!
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6790302087727248		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 0.6790302087727248 | validation: 0.7024962326034794]
	TIME [epoch: 9.77 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6189207526322322		[learning rate: 0.0085465]
	Learning Rate: 0.00854652
	LOSS [training: 0.6189207526322322 | validation: 0.7210339569326033]
	TIME [epoch: 9.76 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7169893446658337		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 0.7169893446658337 | validation: 0.5821682534807582]
	TIME [epoch: 9.76 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5086505105538368		[learning rate: 0.0085052]
	Learning Rate: 0.00850519
	LOSS [training: 0.5086505105538368 | validation: 0.7925541515912673]
	TIME [epoch: 9.77 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8770203295026999		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 0.8770203295026999 | validation: 0.7587954999941634]
	TIME [epoch: 9.79 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8995085138267956		[learning rate: 0.0084641]
	Learning Rate: 0.00846406
	LOSS [training: 0.8995085138267956 | validation: 1.0040490514727005]
	TIME [epoch: 9.77 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8057643987583928		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.8057643987583928 | validation: 0.9972194086814002]
	TIME [epoch: 9.77 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9772185100698311		[learning rate: 0.0084231]
	Learning Rate: 0.00842313
	LOSS [training: 0.9772185100698311 | validation: 0.8142246209037418]
	TIME [epoch: 9.78 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7461153039317411		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.7461153039317411 | validation: 0.8541216112853778]
	TIME [epoch: 9.77 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7007677486152499		[learning rate: 0.0083824]
	Learning Rate: 0.0083824
	LOSS [training: 0.7007677486152499 | validation: 0.6416810206084728]
	TIME [epoch: 9.77 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.986628778206341		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 0.986628778206341 | validation: 0.7763144528212256]
	TIME [epoch: 9.78 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7188080082597716		[learning rate: 0.0083419]
	Learning Rate: 0.00834186
	LOSS [training: 0.7188080082597716 | validation: 0.5347199768380706]
	TIME [epoch: 9.78 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5717757199920441		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 0.5717757199920441 | validation: 0.7407283294096653]
	TIME [epoch: 9.77 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3171341967630317		[learning rate: 0.0083015]
	Learning Rate: 0.00830153
	LOSS [training: 1.3171341967630317 | validation: 0.6135813127640359]
	TIME [epoch: 9.77 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7418372309786553		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 0.7418372309786553 | validation: 0.5733259598703511]
	TIME [epoch: 9.79 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9743327287495533		[learning rate: 0.0082614]
	Learning Rate: 0.00826138
	LOSS [training: 0.9743327287495533 | validation: 1.6708500163718722]
	TIME [epoch: 9.77 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1861532880833896		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 1.1861532880833896 | validation: 0.5931716087294802]
	TIME [epoch: 9.76 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6391867650702577		[learning rate: 0.0082214]
	Learning Rate: 0.00822143
	LOSS [training: 0.6391867650702577 | validation: 0.5608854638314285]
	TIME [epoch: 9.79 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.637112648302921		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 0.637112648302921 | validation: 0.5165752340966479]
	TIME [epoch: 9.76 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5408032392158442		[learning rate: 0.0081817]
	Learning Rate: 0.00818167
	LOSS [training: 0.5408032392158442 | validation: 0.5925838797538946]
	TIME [epoch: 9.77 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6359242501108404		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.6359242501108404 | validation: 0.6191184240645632]
	TIME [epoch: 9.79 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6167724339368809		[learning rate: 0.0081421]
	Learning Rate: 0.00814211
	LOSS [training: 0.6167724339368809 | validation: 0.6626747617314616]
	TIME [epoch: 9.77 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5534873660207367		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 0.5534873660207367 | validation: 0.9142302897391628]
	TIME [epoch: 9.76 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.688779547052484		[learning rate: 0.0081027]
	Learning Rate: 0.00810273
	LOSS [training: 0.688779547052484 | validation: 0.6265675015672757]
	TIME [epoch: 9.78 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6650580019187247		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 0.6650580019187247 | validation: 0.9675611904959729]
	TIME [epoch: 9.78 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1507918623251263		[learning rate: 0.0080636]
	Learning Rate: 0.00806355
	LOSS [training: 1.1507918623251263 | validation: 0.7445185446027336]
	TIME [epoch: 9.77 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8038280370657345		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 0.8038280370657345 | validation: 0.9998659628288917]
	TIME [epoch: 9.77 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6438786238730222		[learning rate: 0.0080246]
	Learning Rate: 0.00802456
	LOSS [training: 0.6438786238730222 | validation: 0.6140714816203827]
	TIME [epoch: 9.79 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6221723221473123		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 0.6221723221473123 | validation: 0.7130614119640126]
	TIME [epoch: 9.77 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7705021502333305		[learning rate: 0.0079858]
	Learning Rate: 0.00798575
	LOSS [training: 0.7705021502333305 | validation: 0.628094556800946]
	TIME [epoch: 9.77 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6976340656692226		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.6976340656692226 | validation: 0.7835229181618361]
	TIME [epoch: 9.79 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.705852337033483		[learning rate: 0.0079471]
	Learning Rate: 0.00794713
	LOSS [training: 0.705852337033483 | validation: 0.746241473178111]
	TIME [epoch: 9.77 sec]
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6959304721946904		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 0.6959304721946904 | validation: 0.8062061670236621]
	TIME [epoch: 9.77 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1060945785518286		[learning rate: 0.0079087]
	Learning Rate: 0.0079087
	LOSS [training: 1.1060945785518286 | validation: 0.8268382120853492]
	TIME [epoch: 9.8 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.864769377454946		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 0.864769377454946 | validation: 1.0675679600478245]
	TIME [epoch: 9.77 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0334547042572724		[learning rate: 0.0078705]
	Learning Rate: 0.00787046
	LOSS [training: 1.0334547042572724 | validation: 0.7681578796914879]
	TIME [epoch: 9.76 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7629924930712002		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 0.7629924930712002 | validation: 0.7273459137378154]
	TIME [epoch: 9.77 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7185964859280638		[learning rate: 0.0078324]
	Learning Rate: 0.0078324
	LOSS [training: 0.7185964859280638 | validation: 0.637437332334508]
	TIME [epoch: 9.77 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.53225009072398		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 0.53225009072398 | validation: 0.5244178846593676]
	TIME [epoch: 9.76 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6930227365150055		[learning rate: 0.0077945]
	Learning Rate: 0.00779452
	LOSS [training: 0.6930227365150055 | validation: 0.6080077217384432]
	TIME [epoch: 9.77 sec]
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6306136707116924		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 0.6306136707116924 | validation: 0.551541469916782]
	TIME [epoch: 9.78 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5798935550694628		[learning rate: 0.0077568]
	Learning Rate: 0.00775683
	LOSS [training: 0.5798935550694628 | validation: 0.7122372081703]
	TIME [epoch: 9.77 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7420473865784064		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 0.7420473865784064 | validation: 0.7778520699190716]
	TIME [epoch: 9.76 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6880940023075546		[learning rate: 0.0077193]
	Learning Rate: 0.00771932
	LOSS [training: 0.6880940023075546 | validation: 0.7869707052552297]
	TIME [epoch: 9.79 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7580959514974366		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.7580959514974366 | validation: 0.6296254004304065]
	TIME [epoch: 9.76 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7140275292298522		[learning rate: 0.007682]
	Learning Rate: 0.00768199
	LOSS [training: 0.7140275292298522 | validation: 0.7758242083416762]
	TIME [epoch: 9.77 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7249183184510455		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 0.7249183184510455 | validation: 1.2942537930968985]
	TIME [epoch: 9.78 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7730859329758686		[learning rate: 0.0076448]
	Learning Rate: 0.00764484
	LOSS [training: 0.7730859329758686 | validation: 0.7050176777084987]
	TIME [epoch: 9.76 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6778468867682363		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 0.6778468867682363 | validation: 0.6926695390246935]
	TIME [epoch: 9.77 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6916564948998619		[learning rate: 0.0076079]
	Learning Rate: 0.00760787
	LOSS [training: 0.6916564948998619 | validation: 0.7181250588009034]
	TIME [epoch: 9.78 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5788260650778179		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 0.5788260650778179 | validation: 0.7120136257791433]
	TIME [epoch: 9.76 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6935533803152119		[learning rate: 0.0075711]
	Learning Rate: 0.00757108
	LOSS [training: 0.6935533803152119 | validation: 0.7421656831635705]
	TIME [epoch: 9.76 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393973190198448		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 0.6393973190198448 | validation: 0.5750027080846082]
	TIME [epoch: 9.76 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8042745459171667		[learning rate: 0.0075345]
	Learning Rate: 0.00753447
	LOSS [training: 0.8042745459171667 | validation: 0.5114839345025609]
	TIME [epoch: 9.79 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5747756799272935		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.5747756799272935 | validation: 0.75261002435524]
	TIME [epoch: 9.76 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6355995034088797		[learning rate: 0.007498]
	Learning Rate: 0.00749803
	LOSS [training: 0.6355995034088797 | validation: 0.5902332605650287]
	TIME [epoch: 9.76 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.54939605466459		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.54939605466459 | validation: 0.6650208810882886]
	TIME [epoch: 9.78 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6357584300444293		[learning rate: 0.0074618]
	Learning Rate: 0.00746177
	LOSS [training: 0.6357584300444293 | validation: 0.7072285750446113]
	TIME [epoch: 9.76 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5478727233197366		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.5478727233197366 | validation: 0.5754838452320604]
	TIME [epoch: 9.76 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5762494916969935		[learning rate: 0.0074257]
	Learning Rate: 0.00742569
	LOSS [training: 0.5762494916969935 | validation: 0.557178874519919]
	TIME [epoch: 9.79 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6431464639914305		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.6431464639914305 | validation: 1.0996629668016258]
	TIME [epoch: 9.76 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6329870804029045		[learning rate: 0.0073898]
	Learning Rate: 0.00738978
	LOSS [training: 1.6329870804029045 | validation: 0.7387209553047484]
	TIME [epoch: 9.76 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6694277045031806		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.6694277045031806 | validation: 1.1307762063997204]
	TIME [epoch: 9.77 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9408596098881024		[learning rate: 0.007354]
	Learning Rate: 0.00735405
	LOSS [training: 0.9408596098881024 | validation: 0.5425395859347854]
	TIME [epoch: 9.77 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5853115002726493		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.5853115002726493 | validation: 0.6418832462855971]
	TIME [epoch: 9.76 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6142435250179675		[learning rate: 0.0073185]
	Learning Rate: 0.00731848
	LOSS [training: 0.6142435250179675 | validation: 0.5300302365259129]
	TIME [epoch: 9.77 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6238957909554499		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.6238957909554499 | validation: 1.0065549098258324]
	TIME [epoch: 9.78 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7025204611244293		[learning rate: 0.0072831]
	Learning Rate: 0.00728309
	LOSS [training: 0.7025204611244293 | validation: 0.5822767905498801]
	TIME [epoch: 9.76 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5723809391984094		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.5723809391984094 | validation: 0.7606310104749079]
	TIME [epoch: 9.76 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5399131684314739		[learning rate: 0.0072479]
	Learning Rate: 0.00724787
	LOSS [training: 0.5399131684314739 | validation: 0.5081328232026278]
	TIME [epoch: 9.78 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5732858637260069		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.5732858637260069 | validation: 0.5516061857304959]
	TIME [epoch: 9.76 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5168916884271246		[learning rate: 0.0072128]
	Learning Rate: 0.00721282
	LOSS [training: 0.5168916884271246 | validation: 0.8880761057009954]
	TIME [epoch: 9.76 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.604448340735395		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 0.604448340735395 | validation: 0.5446231084174182]
	TIME [epoch: 9.79 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5287110909801789		[learning rate: 0.0071779]
	Learning Rate: 0.00717794
	LOSS [training: 0.5287110909801789 | validation: 0.7678788442288789]
	TIME [epoch: 9.76 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7029720809553559		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 0.7029720809553559 | validation: 0.5159173723808207]
	TIME [epoch: 9.75 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5749999930850913		[learning rate: 0.0071432]
	Learning Rate: 0.00714323
	LOSS [training: 0.5749999930850913 | validation: 0.6930244360233477]
	TIME [epoch: 9.77 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5415375202801334		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 0.5415375202801334 | validation: 0.4645218212447334]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_240.pth
	Model improved!!!
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5368992614212702		[learning rate: 0.0071087]
	Learning Rate: 0.00710869
	LOSS [training: 0.5368992614212702 | validation: 0.4378955226549386]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_241.pth
	Model improved!!!
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5382795212330829		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.5382795212330829 | validation: 2.0899649682197943]
	TIME [epoch: 9.77 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4589190335883706		[learning rate: 0.0070743]
	Learning Rate: 0.00707431
	LOSS [training: 2.4589190335883706 | validation: 1.2211871423753562]
	TIME [epoch: 9.78 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8128519297365845		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.8128519297365845 | validation: 0.5460752066507543]
	TIME [epoch: 9.75 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5236643309753192		[learning rate: 0.0070401]
	Learning Rate: 0.0070401
	LOSS [training: 0.5236643309753192 | validation: 0.6076123005176138]
	TIME [epoch: 9.76 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.303510864947467		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 1.303510864947467 | validation: 2.012565270996459]
	TIME [epoch: 9.78 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.144214305476964		[learning rate: 0.0070061]
	Learning Rate: 0.00700606
	LOSS [training: 1.144214305476964 | validation: 0.5984597930795761]
	TIME [epoch: 9.75 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.678014532014276		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.678014532014276 | validation: 0.6113339875341663]
	TIME [epoch: 9.74 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5668045047133525		[learning rate: 0.0069722]
	Learning Rate: 0.00697218
	LOSS [training: 0.5668045047133525 | validation: 0.5945664147664234]
	TIME [epoch: 9.78 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5257291996579568		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 0.5257291996579568 | validation: 0.5317822755931395]
	TIME [epoch: 9.75 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6203373532631848		[learning rate: 0.0069385]
	Learning Rate: 0.00693846
	LOSS [training: 0.6203373532631848 | validation: 0.4996475632579571]
	TIME [epoch: 9.76 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5351094358002129		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.5351094358002129 | validation: 0.512484942666113]
	TIME [epoch: 9.77 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6280831197929297		[learning rate: 0.0069049]
	Learning Rate: 0.00690491
	LOSS [training: 0.6280831197929297 | validation: 0.6117936102839883]
	TIME [epoch: 9.76 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.732942903796929		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.732942903796929 | validation: 0.7802714448150357]
	TIME [epoch: 9.75 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8906374496601785		[learning rate: 0.0068715]
	Learning Rate: 0.00687152
	LOSS [training: 1.8906374496601785 | validation: 0.6696533670717493]
	TIME [epoch: 9.77 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6458014238960934		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.6458014238960934 | validation: 0.5266467150347697]
	TIME [epoch: 9.76 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5767419010562784		[learning rate: 0.0068383]
	Learning Rate: 0.00683829
	LOSS [training: 0.5767419010562784 | validation: 0.5423456418356467]
	TIME [epoch: 9.75 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5091182101630423		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.5091182101630423 | validation: 0.561160086933253]
	TIME [epoch: 9.76 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6336055549953488		[learning rate: 0.0068052]
	Learning Rate: 0.00680522
	LOSS [training: 0.6336055549953488 | validation: 0.6215064346859849]
	TIME [epoch: 9.77 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.613683784667602		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 0.613683784667602 | validation: 0.6321196699443661]
	TIME [epoch: 9.75 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6641601441378607		[learning rate: 0.0067723]
	Learning Rate: 0.00677231
	LOSS [training: 0.6641601441378607 | validation: 0.6989234292210941]
	TIME [epoch: 9.75 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6431756969181116		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.6431756969181116 | validation: 1.4818047849838214]
	TIME [epoch: 9.77 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2767903905821725		[learning rate: 0.0067396]
	Learning Rate: 0.00673956
	LOSS [training: 1.2767903905821725 | validation: 0.715166056128616]
	TIME [epoch: 9.76 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.672323065585928		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.672323065585928 | validation: 0.656539078023268]
	TIME [epoch: 9.75 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6708024091710965		[learning rate: 0.006707]
	Learning Rate: 0.00670697
	LOSS [training: 0.6708024091710965 | validation: 0.8464288537641591]
	TIME [epoch: 9.78 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393917609203805		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.6393917609203805 | validation: 0.6602489062974058]
	TIME [epoch: 9.76 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7814124845853029		[learning rate: 0.0066745]
	Learning Rate: 0.00667454
	LOSS [training: 0.7814124845853029 | validation: 1.1227516043126522]
	TIME [epoch: 9.76 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7544165171008818		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.7544165171008818 | validation: 0.6181260572184739]
	TIME [epoch: 9.77 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6011370901015026		[learning rate: 0.0066423]
	Learning Rate: 0.00664226
	LOSS [training: 0.6011370901015026 | validation: 0.5704726380986023]
	TIME [epoch: 9.78 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9094622284413395		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.9094622284413395 | validation: 0.8295028789736012]
	TIME [epoch: 9.76 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7378760332843186		[learning rate: 0.0066101]
	Learning Rate: 0.00661014
	LOSS [training: 0.7378760332843186 | validation: 0.6274329686254717]
	TIME [epoch: 9.76 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6000731319839441		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.6000731319839441 | validation: 0.6261948677076139]
	TIME [epoch: 9.77 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6009037823589257		[learning rate: 0.0065782]
	Learning Rate: 0.00657817
	LOSS [training: 0.6009037823589257 | validation: 0.582803314883437]
	TIME [epoch: 9.75 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7374947289231324		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.7374947289231324 | validation: 0.8407679614391895]
	TIME [epoch: 9.75 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7266134264407083		[learning rate: 0.0065464]
	Learning Rate: 0.00654636
	LOSS [training: 0.7266134264407083 | validation: 0.7181659016143958]
	TIME [epoch: 9.78 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6753988096956356		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.6753988096956356 | validation: 1.2346746754697484]
	TIME [epoch: 9.75 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8963093716856712		[learning rate: 0.0065147]
	Learning Rate: 0.0065147
	LOSS [training: 0.8963093716856712 | validation: 0.6575856933799427]
	TIME [epoch: 9.76 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8061195645377361		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.8061195645377361 | validation: 0.850787144454516]
	TIME [epoch: 9.78 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6707907004525264		[learning rate: 0.0064832]
	Learning Rate: 0.0064832
	LOSS [training: 0.6707907004525264 | validation: 0.6797509013665054]
	TIME [epoch: 9.76 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6160590452203588		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.6160590452203588 | validation: 0.5716474876087506]
	TIME [epoch: 9.76 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.087436115254035		[learning rate: 0.0064518]
	Learning Rate: 0.00645185
	LOSS [training: 1.087436115254035 | validation: 1.0366469026234888]
	TIME [epoch: 9.77 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8392687428312289		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.8392687428312289 | validation: 0.6618953315962709]
	TIME [epoch: 9.76 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5676077511621205		[learning rate: 0.0064206]
	Learning Rate: 0.00642065
	LOSS [training: 0.5676077511621205 | validation: 0.6301657297732556]
	TIME [epoch: 9.75 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5704627535941359		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.5704627535941359 | validation: 0.5450443293887152]
	TIME [epoch: 9.75 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5647013056109884		[learning rate: 0.0063896]
	Learning Rate: 0.0063896
	LOSS [training: 0.5647013056109884 | validation: 0.4987984307505952]
	TIME [epoch: 9.78 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6299229999879067		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.6299229999879067 | validation: 0.44454729345345784]
	TIME [epoch: 9.75 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4749273952622112		[learning rate: 0.0063587]
	Learning Rate: 0.0063587
	LOSS [training: 0.4749273952622112 | validation: 0.8010241450768608]
	TIME [epoch: 9.76 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6687791258632592		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.6687791258632592 | validation: 0.6261083776253996]
	TIME [epoch: 9.78 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5741217838471641		[learning rate: 0.006328]
	Learning Rate: 0.00632795
	LOSS [training: 0.5741217838471641 | validation: 0.45383297812971923]
	TIME [epoch: 9.76 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5388655696535054		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.5388655696535054 | validation: 0.5890427842312815]
	TIME [epoch: 9.75 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5842292313274455		[learning rate: 0.0062974]
	Learning Rate: 0.00629735
	LOSS [training: 0.5842292313274455 | validation: 0.5518029545363556]
	TIME [epoch: 9.78 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4976005983706626		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.4976005983706626 | validation: 0.5787017168166823]
	TIME [epoch: 9.76 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5410286848053372		[learning rate: 0.0062669]
	Learning Rate: 0.0062669
	LOSS [training: 0.5410286848053372 | validation: 0.4838291801476618]
	TIME [epoch: 9.75 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.489135245357074		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.489135245357074 | validation: 0.5823678114204713]
	TIME [epoch: 9.77 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5427486353735359		[learning rate: 0.0062366]
	Learning Rate: 0.00623659
	LOSS [training: 0.5427486353735359 | validation: 0.5905522453031293]
	TIME [epoch: 9.75 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5972007709759316		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.5972007709759316 | validation: 0.5673586311353169]
	TIME [epoch: 9.76 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4894290235724078		[learning rate: 0.0062064]
	Learning Rate: 0.00620643
	LOSS [training: 0.4894290235724078 | validation: 0.532358992032745]
	TIME [epoch: 9.75 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5229108682089894		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.5229108682089894 | validation: 0.506273167602519]
	TIME [epoch: 9.78 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5816066069995609		[learning rate: 0.0061764]
	Learning Rate: 0.00617642
	LOSS [training: 0.5816066069995609 | validation: 0.5957512504742252]
	TIME [epoch: 9.76 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4783309206666792		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.4783309206666792 | validation: 0.5010403732289241]
	TIME [epoch: 9.75 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6384484387734101		[learning rate: 0.0061466]
	Learning Rate: 0.00614655
	LOSS [training: 0.6384484387734101 | validation: 0.5738540143628216]
	TIME [epoch: 9.77 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5781667655619314		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.5781667655619314 | validation: 0.5347858151930346]
	TIME [epoch: 9.75 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5280800300843548		[learning rate: 0.0061168]
	Learning Rate: 0.00611683
	LOSS [training: 0.5280800300843548 | validation: 0.4732593446055673]
	TIME [epoch: 9.75 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5625115350692474		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.5625115350692474 | validation: 1.0528798449619674]
	TIME [epoch: 9.76 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9487743184769364		[learning rate: 0.0060872]
	Learning Rate: 0.00608725
	LOSS [training: 0.9487743184769364 | validation: 0.6483511145842914]
	TIME [epoch: 9.75 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5447504416756908		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.5447504416756908 | validation: 0.487363041798458]
	TIME [epoch: 9.74 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5013441676645316		[learning rate: 0.0060578]
	Learning Rate: 0.00605781
	LOSS [training: 0.5013441676645316 | validation: 0.7721960586964706]
	TIME [epoch: 9.77 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5915929702957611		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.5915929702957611 | validation: 0.44937352586825474]
	TIME [epoch: 9.76 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.520505530302151		[learning rate: 0.0060285]
	Learning Rate: 0.00602852
	LOSS [training: 0.520505530302151 | validation: 0.4434196355477066]
	TIME [epoch: 9.75 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4380377998836609		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 0.4380377998836609 | validation: 0.5318419718449261]
	TIME [epoch: 9.75 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5064968181482472		[learning rate: 0.0059994]
	Learning Rate: 0.00599936
	LOSS [training: 0.5064968181482472 | validation: 0.5486726513030246]
	TIME [epoch: 9.77 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4654510539474705		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 0.4654510539474705 | validation: 0.41140568704495445]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_312.pth
	Model improved!!!
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.529840899721531		[learning rate: 0.0059704]
	Learning Rate: 0.00597035
	LOSS [training: 0.529840899721531 | validation: 0.6978204819225675]
	TIME [epoch: 9.76 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7525847152468681		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 0.7525847152468681 | validation: 1.0195903974601626]
	TIME [epoch: 9.78 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6882494870570876		[learning rate: 0.0059415]
	Learning Rate: 0.00594148
	LOSS [training: 0.6882494870570876 | validation: 0.4392106992424683]
	TIME [epoch: 9.75 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6245757633712358		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 0.6245757633712358 | validation: 0.6994726095077038]
	TIME [epoch: 9.76 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1737549833340502		[learning rate: 0.0059127]
	Learning Rate: 0.00591275
	LOSS [training: 1.1737549833340502 | validation: 1.2140384209862345]
	TIME [epoch: 9.77 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0005671197708048		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 1.0005671197708048 | validation: 0.5106926282620481]
	TIME [epoch: 9.76 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6880840570143982		[learning rate: 0.0058842]
	Learning Rate: 0.00588416
	LOSS [training: 0.6880840570143982 | validation: 0.7081374444316131]
	TIME [epoch: 9.76 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5155172421936614		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.5155172421936614 | validation: 0.4348768382257729]
	TIME [epoch: 9.77 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7643985817554979		[learning rate: 0.0058557]
	Learning Rate: 0.0058557
	LOSS [training: 0.7643985817554979 | validation: 0.611468746981299]
	TIME [epoch: 9.76 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8233314704485636		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.8233314704485636 | validation: 0.7564115370429008]
	TIME [epoch: 9.76 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.634083924401807		[learning rate: 0.0058274]
	Learning Rate: 0.00582738
	LOSS [training: 0.634083924401807 | validation: 0.5084267796477233]
	TIME [epoch: 9.76 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6660663924009645		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.6660663924009645 | validation: 0.5397671699264603]
	TIME [epoch: 9.77 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4902215832598903		[learning rate: 0.0057992]
	Learning Rate: 0.0057992
	LOSS [training: 0.4902215832598903 | validation: 0.4685828545588072]
	TIME [epoch: 9.75 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41065600343096326		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.41065600343096326 | validation: 0.3987352969070262]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_326.pth
	Model improved!!!
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4679042486760422		[learning rate: 0.0057712]
	Learning Rate: 0.00577116
	LOSS [training: 0.4679042486760422 | validation: 0.4653121509691711]
	TIME [epoch: 9.78 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4642829346367036		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.4642829346367036 | validation: 0.36648479215780927]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_328.pth
	Model improved!!!
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.408128403814419		[learning rate: 0.0057433]
	Learning Rate: 0.00574325
	LOSS [training: 0.408128403814419 | validation: 0.6743060874780668]
	TIME [epoch: 9.75 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5264503150816606		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.5264503150816606 | validation: 0.44133540147810424]
	TIME [epoch: 9.77 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.510847326962721		[learning rate: 0.0057155]
	Learning Rate: 0.00571548
	LOSS [training: 0.510847326962721 | validation: 0.4732594951015161]
	TIME [epoch: 9.76 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5836732788680516		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.5836732788680516 | validation: 0.503837346304898]
	TIME [epoch: 9.75 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5957632214791527		[learning rate: 0.0056878]
	Learning Rate: 0.00568784
	LOSS [training: 0.5957632214791527 | validation: 0.6142978251990515]
	TIME [epoch: 9.78 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5563709211037076		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.5563709211037076 | validation: 0.6461986062056413]
	TIME [epoch: 9.75 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5807635910661375		[learning rate: 0.0056603]
	Learning Rate: 0.00566033
	LOSS [training: 0.5807635910661375 | validation: 0.47724488901432927]
	TIME [epoch: 9.75 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48558383656598936		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 0.48558383656598936 | validation: 0.5191492829210865]
	TIME [epoch: 9.77 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4968771227735198		[learning rate: 0.005633]
	Learning Rate: 0.00563296
	LOSS [training: 0.4968771227735198 | validation: 0.447431822908644]
	TIME [epoch: 9.76 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4872948908760236		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 0.4872948908760236 | validation: 0.4944727193783801]
	TIME [epoch: 9.76 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4887688991249523		[learning rate: 0.0056057]
	Learning Rate: 0.00560572
	LOSS [training: 0.4887688991249523 | validation: 0.5128699105291125]
	TIME [epoch: 9.75 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5279627584765818		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.5279627584765818 | validation: 0.36151513467266755]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_340.pth
	Model improved!!!
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5355941260061845		[learning rate: 0.0055786]
	Learning Rate: 0.00557861
	LOSS [training: 0.5355941260061845 | validation: 0.44253348490663874]
	TIME [epoch: 9.77 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5706026939909352		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.5706026939909352 | validation: 0.8195535856173314]
	TIME [epoch: 9.76 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7290662790424651		[learning rate: 0.0055516]
	Learning Rate: 0.00555164
	LOSS [training: 0.7290662790424651 | validation: 0.77673420570917]
	TIME [epoch: 9.77 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9205603148535723		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.9205603148535723 | validation: 0.7322501087897831]
	TIME [epoch: 9.75 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8778980114577841		[learning rate: 0.0055248]
	Learning Rate: 0.00552479
	LOSS [training: 0.8778980114577841 | validation: 0.6766516934125066]
	TIME [epoch: 9.75 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6510199779334698		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.6510199779334698 | validation: 0.5641241921450965]
	TIME [epoch: 9.76 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5826167906507721		[learning rate: 0.0054981]
	Learning Rate: 0.00549807
	LOSS [training: 0.5826167906507721 | validation: 0.5803951350034735]
	TIME [epoch: 9.74 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4884502009815221		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.4884502009815221 | validation: 0.4308302944831806]
	TIME [epoch: 9.75 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.751088627798708		[learning rate: 0.0054715]
	Learning Rate: 0.00547149
	LOSS [training: 0.751088627798708 | validation: 0.7995074565918785]
	TIME [epoch: 9.75 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6821383676783459		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.6821383676783459 | validation: 0.48688621305437424]
	TIME [epoch: 9.75 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5178324903012175		[learning rate: 0.005445]
	Learning Rate: 0.00544503
	LOSS [training: 0.5178324903012175 | validation: 0.4880067392256288]
	TIME [epoch: 9.74 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39597040357222185		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.39597040357222185 | validation: 0.3303811921547275]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_352.pth
	Model improved!!!
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3648376367353191		[learning rate: 0.0054187]
	Learning Rate: 0.0054187
	LOSS [training: 0.3648376367353191 | validation: 0.40392756791988904]
	TIME [epoch: 9.78 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.357995175677076		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.357995175677076 | validation: 0.33700645411670854]
	TIME [epoch: 9.75 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40153002123174897		[learning rate: 0.0053925]
	Learning Rate: 0.00539249
	LOSS [training: 0.40153002123174897 | validation: 0.583725388441974]
	TIME [epoch: 9.76 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5613964083728656		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.5613964083728656 | validation: 1.38908038224059]
	TIME [epoch: 9.77 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8770659200294155		[learning rate: 0.0053664]
	Learning Rate: 0.00536641
	LOSS [training: 0.8770659200294155 | validation: 0.7414057184092306]
	TIME [epoch: 9.74 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9327106403704079		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.9327106403704079 | validation: 0.906880814782445]
	TIME [epoch: 9.76 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0014000391914408		[learning rate: 0.0053405]
	Learning Rate: 0.00534046
	LOSS [training: 1.0014000391914408 | validation: 0.6649176678644552]
	TIME [epoch: 9.77 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6667080885485123		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.6667080885485123 | validation: 0.7859228187720644]
	TIME [epoch: 9.76 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7648206570441639		[learning rate: 0.0053146]
	Learning Rate: 0.00531464
	LOSS [training: 0.7648206570441639 | validation: 0.8924338082529181]
	TIME [epoch: 9.75 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.581858495744463		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.581858495744463 | validation: 0.47123715447066944]
	TIME [epoch: 9.77 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5471645108985059		[learning rate: 0.0052889]
	Learning Rate: 0.00528894
	LOSS [training: 0.5471645108985059 | validation: 0.4532692062678483]
	TIME [epoch: 9.75 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4826943908415687		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.4826943908415687 | validation: 0.4749001701691158]
	TIME [epoch: 9.76 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.56113881675777		[learning rate: 0.0052634]
	Learning Rate: 0.00526336
	LOSS [training: 0.56113881675777 | validation: 0.5104462663659092]
	TIME [epoch: 9.75 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5104421273444132		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.5104421273444132 | validation: 0.42232043752509413]
	TIME [epoch: 9.78 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.583818324614047		[learning rate: 0.0052379]
	Learning Rate: 0.00523791
	LOSS [training: 0.583818324614047 | validation: 1.0427706686642157]
	TIME [epoch: 9.76 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7201418854157874		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.7201418854157874 | validation: 0.7271289468525908]
	TIME [epoch: 9.75 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6828397796922594		[learning rate: 0.0052126]
	Learning Rate: 0.00521258
	LOSS [training: 0.6828397796922594 | validation: 0.3761291204468681]
	TIME [epoch: 9.77 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4121809657845016		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.4121809657845016 | validation: 0.6460384240889482]
	TIME [epoch: 9.75 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4951427160383305		[learning rate: 0.0051874]
	Learning Rate: 0.00518737
	LOSS [training: 0.4951427160383305 | validation: 0.3709712028612478]
	TIME [epoch: 9.75 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43154589514989994		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.43154589514989994 | validation: 0.4535195663126892]
	TIME [epoch: 9.78 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43691577066610743		[learning rate: 0.0051623]
	Learning Rate: 0.00516229
	LOSS [training: 0.43691577066610743 | validation: 0.5508120875082717]
	TIME [epoch: 9.76 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43945239604799397		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.43945239604799397 | validation: 0.5122388606328128]
	TIME [epoch: 9.74 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5805681781715167		[learning rate: 0.0051373]
	Learning Rate: 0.00513732
	LOSS [training: 0.5805681781715167 | validation: 0.4614142791759424]
	TIME [epoch: 9.76 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4769350967469038		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.4769350967469038 | validation: 0.4110842497524088]
	TIME [epoch: 9.76 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45865879795985165		[learning rate: 0.0051125]
	Learning Rate: 0.00511248
	LOSS [training: 0.45865879795985165 | validation: 0.4712749436959747]
	TIME [epoch: 9.76 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6423908835166134		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.6423908835166134 | validation: 0.6338763491200746]
	TIME [epoch: 9.75 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5594584794959424		[learning rate: 0.0050878]
	Learning Rate: 0.00508776
	LOSS [training: 0.5594584794959424 | validation: 0.43315340378597667]
	TIME [epoch: 9.78 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42900394556032617		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.42900394556032617 | validation: 0.6406463811474916]
	TIME [epoch: 9.76 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6588366558321292		[learning rate: 0.0050632]
	Learning Rate: 0.00506315
	LOSS [training: 0.6588366558321292 | validation: 0.5268532257302421]
	TIME [epoch: 9.75 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5128783701639144		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.5128783701639144 | validation: 0.42085103317023215]
	TIME [epoch: 9.78 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47650364012088164		[learning rate: 0.0050387]
	Learning Rate: 0.00503867
	LOSS [training: 0.47650364012088164 | validation: 0.4720199675984837]
	TIME [epoch: 9.76 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5738240295394774		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.5738240295394774 | validation: 0.7384896600556156]
	TIME [epoch: 9.75 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7496920085344592		[learning rate: 0.0050143]
	Learning Rate: 0.0050143
	LOSS [training: 0.7496920085344592 | validation: 0.8459321820103068]
	TIME [epoch: 9.77 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2432422961186664		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 1.2432422961186664 | validation: 1.2512448633729214]
	TIME [epoch: 9.76 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0246171139743756		[learning rate: 0.0049901]
	Learning Rate: 0.00499005
	LOSS [training: 1.0246171139743756 | validation: 0.7560330055425274]
	TIME [epoch: 9.75 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7175475473532641		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.7175475473532641 | validation: 0.5294761357201762]
	TIME [epoch: 9.76 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48305859202547674		[learning rate: 0.0049659]
	Learning Rate: 0.00496592
	LOSS [training: 0.48305859202547674 | validation: 0.6372310703152039]
	TIME [epoch: 9.76 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5259407559298316		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.5259407559298316 | validation: 0.4837106820471128]
	TIME [epoch: 9.75 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4842260171651468		[learning rate: 0.0049419]
	Learning Rate: 0.00494191
	LOSS [training: 0.4842260171651468 | validation: 0.43644837246931595]
	TIME [epoch: 9.76 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4475206184036426		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.4475206184036426 | validation: 0.4721389782640899]
	TIME [epoch: 9.77 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4901866802916808		[learning rate: 0.004918]
	Learning Rate: 0.00491801
	LOSS [training: 0.4901866802916808 | validation: 0.4646630965532381]
	TIME [epoch: 9.74 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47112018809314415		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.47112018809314415 | validation: 0.4928015259303086]
	TIME [epoch: 9.75 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5011598024132166		[learning rate: 0.0048942]
	Learning Rate: 0.00489423
	LOSS [training: 0.5011598024132166 | validation: 0.3872212885729374]
	TIME [epoch: 9.77 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8307524100327035		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.8307524100327035 | validation: 0.7539379205802088]
	TIME [epoch: 9.75 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7944751151291889		[learning rate: 0.0048706]
	Learning Rate: 0.00487056
	LOSS [training: 0.7944751151291889 | validation: 0.6226100132789537]
	TIME [epoch: 9.75 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5623407706988045		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.5623407706988045 | validation: 0.45274085420143734]
	TIME [epoch: 9.78 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4585560045783845		[learning rate: 0.004847]
	Learning Rate: 0.00484701
	LOSS [training: 0.4585560045783845 | validation: 0.396348208176119]
	TIME [epoch: 9.76 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5329018070525569		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.5329018070525569 | validation: 0.47695160303536244]
	TIME [epoch: 9.76 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5339459510284935		[learning rate: 0.0048236]
	Learning Rate: 0.00482357
	LOSS [training: 0.5339459510284935 | validation: 0.4999615174136581]
	TIME [epoch: 9.77 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5626457966266722		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.5626457966266722 | validation: 0.45861798317820085]
	TIME [epoch: 9.75 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5711822505347296		[learning rate: 0.0048002]
	Learning Rate: 0.00480024
	LOSS [training: 0.5711822505347296 | validation: 0.5176687197178237]
	TIME [epoch: 9.76 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.561879820182788		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.561879820182788 | validation: 0.7498765950787464]
	TIME [epoch: 9.76 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8856814164001707		[learning rate: 0.004777]
	Learning Rate: 0.00477703
	LOSS [training: 1.8856814164001707 | validation: 2.2793104861604014]
	TIME [epoch: 9.77 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.3892628269775567		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 2.3892628269775567 | validation: 1.8534108220775494]
	TIME [epoch: 9.75 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4969749653386288		[learning rate: 0.0047539]
	Learning Rate: 0.00475393
	LOSS [training: 1.4969749653386288 | validation: 0.8350665107444567]
	TIME [epoch: 9.76 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8189800582638412		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.8189800582638412 | validation: 0.8082302844854417]
	TIME [epoch: 9.77 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.674724669886163		[learning rate: 0.0047309]
	Learning Rate: 0.00473094
	LOSS [training: 0.674724669886163 | validation: 0.5305108815302676]
	TIME [epoch: 9.75 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5000857163101253		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.5000857163101253 | validation: 0.44836690125620704]
	TIME [epoch: 9.75 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5023538456224832		[learning rate: 0.0047081]
	Learning Rate: 0.00470806
	LOSS [training: 0.5023538456224832 | validation: 0.5137926067239819]
	TIME [epoch: 9.77 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5744677169895963		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.5744677169895963 | validation: 0.47191688660127556]
	TIME [epoch: 9.75 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5587977739429093		[learning rate: 0.0046853]
	Learning Rate: 0.00468529
	LOSS [training: 0.5587977739429093 | validation: 0.6912635587814729]
	TIME [epoch: 9.76 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.623181606719109		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.623181606719109 | validation: 0.505338630670953]
	TIME [epoch: 9.77 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5822735059772917		[learning rate: 0.0046626]
	Learning Rate: 0.00466264
	LOSS [training: 0.5822735059772917 | validation: 0.5250100098444491]
	TIME [epoch: 9.75 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5343486761326512		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.5343486761326512 | validation: 0.45615786414613707]
	TIME [epoch: 9.75 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.439165779543605		[learning rate: 0.0046401]
	Learning Rate: 0.00464009
	LOSS [training: 0.439165779543605 | validation: 0.436379568798105]
	TIME [epoch: 9.75 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.515297021028086		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.515297021028086 | validation: 0.6119135888779328]
	TIME [epoch: 9.78 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9559160348061274		[learning rate: 0.0046177]
	Learning Rate: 0.00461765
	LOSS [training: 0.9559160348061274 | validation: 2.223951418279187]
	TIME [epoch: 9.76 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0618830453124297		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 2.0618830453124297 | validation: 0.5851024501458829]
	TIME [epoch: 9.75 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.609767670171222		[learning rate: 0.0045953]
	Learning Rate: 0.00459532
	LOSS [training: 0.609767670171222 | validation: 0.5893337679516806]
	TIME [epoch: 9.79 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6112992302645402		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.6112992302645402 | validation: 0.6754677011902516]
	TIME [epoch: 9.76 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6734061448729017		[learning rate: 0.0045731]
	Learning Rate: 0.0045731
	LOSS [training: 0.6734061448729017 | validation: 0.7098534868072934]
	TIME [epoch: 9.76 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5764770140848435		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.5764770140848435 | validation: 0.6606716427044501]
	TIME [epoch: 9.77 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8339028385722616		[learning rate: 0.004551]
	Learning Rate: 0.00455098
	LOSS [training: 0.8339028385722616 | validation: 0.8789215318686462]
	TIME [epoch: 9.75 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6930823918228024		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.6930823918228024 | validation: 0.41601420584121424]
	TIME [epoch: 9.76 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39194629680467774		[learning rate: 0.004529]
	Learning Rate: 0.00452898
	LOSS [training: 0.39194629680467774 | validation: 0.4361566034025222]
	TIME [epoch: 9.76 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3861527149971159		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.3861527149971159 | validation: 0.40223451460249876]
	TIME [epoch: 9.76 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40412359852006474		[learning rate: 0.0045071]
	Learning Rate: 0.00450707
	LOSS [training: 0.40412359852006474 | validation: 0.4237195929847237]
	TIME [epoch: 9.75 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4678189657735052		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.4678189657735052 | validation: 0.46742820022887843]
	TIME [epoch: 9.75 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4684963064932518		[learning rate: 0.0044853]
	Learning Rate: 0.00448528
	LOSS [training: 0.4684963064932518 | validation: 0.46829158864839315]
	TIME [epoch: 9.79 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4789927475897707		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.4789927475897707 | validation: 0.5065444257597806]
	TIME [epoch: 9.75 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5352259159728414		[learning rate: 0.0044636]
	Learning Rate: 0.00446359
	LOSS [training: 0.5352259159728414 | validation: 0.5410129820982205]
	TIME [epoch: 9.76 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6351044865935329		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.6351044865935329 | validation: 0.6579488448463581]
	TIME [epoch: 9.78 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6451267042274996		[learning rate: 0.004442]
	Learning Rate: 0.004442
	LOSS [training: 0.6451267042274996 | validation: 0.542635247242537]
	TIME [epoch: 9.74 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4858807885144551		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.4858807885144551 | validation: 0.38541621633283013]
	TIME [epoch: 9.75 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4183986863384308		[learning rate: 0.0044205]
	Learning Rate: 0.00442052
	LOSS [training: 0.4183986863384308 | validation: 0.4066669431649159]
	TIME [epoch: 9.79 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3972092736175605		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.3972092736175605 | validation: 0.3631724622072372]
	TIME [epoch: 9.75 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4241453131819261		[learning rate: 0.0043991]
	Learning Rate: 0.00439915
	LOSS [training: 0.4241453131819261 | validation: 0.599148928184865]
	TIME [epoch: 9.77 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48443380201023317		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.48443380201023317 | validation: 0.5291775682665348]
	TIME [epoch: 9.78 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5111361825852092		[learning rate: 0.0043779]
	Learning Rate: 0.00437787
	LOSS [training: 0.5111361825852092 | validation: 0.558326742740917]
	TIME [epoch: 9.76 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6604818901503825		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.6604818901503825 | validation: 0.40034894681586713]
	TIME [epoch: 9.75 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.368876313543081		[learning rate: 0.0043567]
	Learning Rate: 0.0043567
	LOSS [training: 0.368876313543081 | validation: 0.5191641074701342]
	TIME [epoch: 9.76 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6001871872335501		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.6001871872335501 | validation: 0.5852743424299099]
	TIME [epoch: 9.77 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7920228554098848		[learning rate: 0.0043356]
	Learning Rate: 0.00433563
	LOSS [training: 0.7920228554098848 | validation: 0.5956660770879527]
	TIME [epoch: 9.75 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5392858835585138		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.5392858835585138 | validation: 0.64897620471111]
	TIME [epoch: 9.74 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6552766204221172		[learning rate: 0.0043147]
	Learning Rate: 0.00431467
	LOSS [training: 0.6552766204221172 | validation: 0.6030235890741963]
	TIME [epoch: 9.78 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5438044207520314		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.5438044207520314 | validation: 0.4387015088284655]
	TIME [epoch: 9.75 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4423240231217017		[learning rate: 0.0042938]
	Learning Rate: 0.0042938
	LOSS [training: 0.4423240231217017 | validation: 0.4395410544531311]
	TIME [epoch: 9.77 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47874970868256905		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.47874970868256905 | validation: 0.5711971989853831]
	TIME [epoch: 9.78 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5601189293207854		[learning rate: 0.004273]
	Learning Rate: 0.00427304
	LOSS [training: 0.5601189293207854 | validation: 0.4984197381041126]
	TIME [epoch: 9.75 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5066946744066524		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.5066946744066524 | validation: 0.4356052209944445]
	TIME [epoch: 9.77 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4453312590250652		[learning rate: 0.0042524]
	Learning Rate: 0.00425238
	LOSS [training: 0.4453312590250652 | validation: 0.6610492729084719]
	TIME [epoch: 9.77 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4446648756890199		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.4446648756890199 | validation: 0.3075761547508345]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_454.pth
	Model improved!!!
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3469834461771798		[learning rate: 0.0042318]
	Learning Rate: 0.00423181
	LOSS [training: 0.3469834461771798 | validation: 0.33810441774400235]
	TIME [epoch: 9.74 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35671570416439646		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.35671570416439646 | validation: 0.39814550345473254]
	TIME [epoch: 9.76 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3638277778469926		[learning rate: 0.0042113]
	Learning Rate: 0.00421135
	LOSS [training: 0.3638277778469926 | validation: 0.37348487415483245]
	TIME [epoch: 9.75 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3699029096987434		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.3699029096987434 | validation: 0.4914927538856578]
	TIME [epoch: 9.74 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5109689509738808		[learning rate: 0.004191]
	Learning Rate: 0.00419098
	LOSS [training: 0.5109689509738808 | validation: 0.5031296209478575]
	TIME [epoch: 9.75 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5094057334649769		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.5094057334649769 | validation: 0.46543023383175197]
	TIME [epoch: 9.77 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36672371937087317		[learning rate: 0.0041707]
	Learning Rate: 0.00417071
	LOSS [training: 0.36672371937087317 | validation: 0.3311506057988254]
	TIME [epoch: 9.75 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6001904826578979		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.6001904826578979 | validation: 0.8654805704060741]
	TIME [epoch: 9.73 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7337604869387249		[learning rate: 0.0041505]
	Learning Rate: 0.00415055
	LOSS [training: 0.7337604869387249 | validation: 0.6181374815999626]
	TIME [epoch: 9.78 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5219452154541471		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.5219452154541471 | validation: 0.5400368089301969]
	TIME [epoch: 9.75 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5485350825393489		[learning rate: 0.0041305]
	Learning Rate: 0.00413047
	LOSS [training: 0.5485350825393489 | validation: 0.5318963339068686]
	TIME [epoch: 9.76 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44460301045191974		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.44460301045191974 | validation: 0.34657631697632013]
	TIME [epoch: 9.77 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3926777889588621		[learning rate: 0.0041105]
	Learning Rate: 0.0041105
	LOSS [training: 0.3926777889588621 | validation: 0.42556209034726467]
	TIME [epoch: 9.75 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.504658410036478		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.504658410036478 | validation: 0.412149081803113]
	TIME [epoch: 9.76 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4518074564397316		[learning rate: 0.0040906]
	Learning Rate: 0.00409062
	LOSS [training: 0.4518074564397316 | validation: 0.4343627067921023]
	TIME [epoch: 9.76 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47844243251386837		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.47844243251386837 | validation: 0.4479458480589554]
	TIME [epoch: 9.76 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45006190494094084		[learning rate: 0.0040708]
	Learning Rate: 0.00407084
	LOSS [training: 0.45006190494094084 | validation: 0.37348191963632]
	TIME [epoch: 9.75 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.472051554375443		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.472051554375443 | validation: 0.4844528659079627]
	TIME [epoch: 9.74 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5055316485375599		[learning rate: 0.0040512]
	Learning Rate: 0.00405116
	LOSS [training: 0.5055316485375599 | validation: 0.6189758566097683]
	TIME [epoch: 9.76 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5638894310080708		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.5638894310080708 | validation: 0.4548818314348796]
	TIME [epoch: 9.75 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5223474171351662		[learning rate: 0.0040316]
	Learning Rate: 0.00403157
	LOSS [training: 0.5223474171351662 | validation: 0.5209872800860929]
	TIME [epoch: 9.74 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6377425035427804		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.6377425035427804 | validation: 0.5733885864454266]
	TIME [epoch: 9.77 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6620621176542398		[learning rate: 0.0040121]
	Learning Rate: 0.00401207
	LOSS [training: 0.6620621176542398 | validation: 0.6563434679855981]
	TIME [epoch: 9.75 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8297207393494697		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.8297207393494697 | validation: 0.6436872904212426]
	TIME [epoch: 9.76 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.686501065132355		[learning rate: 0.0039927]
	Learning Rate: 0.00399267
	LOSS [training: 0.686501065132355 | validation: 0.651349223947024]
	TIME [epoch: 9.77 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6421138670236973		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.6421138670236973 | validation: 0.6139828491489192]
	TIME [epoch: 9.77 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5630527880659482		[learning rate: 0.0039734]
	Learning Rate: 0.00397336
	LOSS [training: 0.5630527880659482 | validation: 0.45653085683576294]
	TIME [epoch: 9.75 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5421796015679999		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.5421796015679999 | validation: 0.43660855429354706]
	TIME [epoch: 9.77 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4827145560344084		[learning rate: 0.0039541]
	Learning Rate: 0.00395415
	LOSS [training: 0.4827145560344084 | validation: 0.6334200941846045]
	TIME [epoch: 9.76 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7960298621082869		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.7960298621082869 | validation: 0.6583936386364309]
	TIME [epoch: 9.75 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.558177690948981		[learning rate: 0.003935]
	Learning Rate: 0.00393502
	LOSS [training: 0.558177690948981 | validation: 0.492253002170023]
	TIME [epoch: 9.75 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.527251606205158		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.527251606205158 | validation: 0.5153999172599127]
	TIME [epoch: 9.78 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5082059335046718		[learning rate: 0.003916]
	Learning Rate: 0.00391599
	LOSS [training: 0.5082059335046718 | validation: 0.4977037784990844]
	TIME [epoch: 9.74 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5084255629013297		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.5084255629013297 | validation: 0.5065946979232661]
	TIME [epoch: 9.74 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5334738123228857		[learning rate: 0.0038971]
	Learning Rate: 0.00389706
	LOSS [training: 0.5334738123228857 | validation: 0.5204729675801463]
	TIME [epoch: 9.76 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5806327643572183		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.5806327643572183 | validation: 0.5789566081455378]
	TIME [epoch: 9.74 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6756028914180827		[learning rate: 0.0038782]
	Learning Rate: 0.00387821
	LOSS [training: 0.6756028914180827 | validation: 0.7136430166727611]
	TIME [epoch: 9.75 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6412305077314014		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.6412305077314014 | validation: 0.6578731886010555]
	TIME [epoch: 9.76 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5816796197656574		[learning rate: 0.0038595]
	Learning Rate: 0.00385946
	LOSS [training: 0.5816796197656574 | validation: 0.4850043767212901]
	TIME [epoch: 9.76 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4874102109114446		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.4874102109114446 | validation: 0.4962223392232754]
	TIME [epoch: 9.74 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5749945767423116		[learning rate: 0.0038408]
	Learning Rate: 0.00384079
	LOSS [training: 0.5749945767423116 | validation: 0.4976412258069944]
	TIME [epoch: 9.75 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.506087943299848		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.506087943299848 | validation: 0.4066442318539667]
	TIME [epoch: 9.76 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4161389757770852		[learning rate: 0.0038222]
	Learning Rate: 0.00382222
	LOSS [training: 0.4161389757770852 | validation: 0.48271498942136676]
	TIME [epoch: 9.74 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49785208646563506		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.49785208646563506 | validation: 0.4557118796759599]
	TIME [epoch: 9.75 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5832668456094512		[learning rate: 0.0038037]
	Learning Rate: 0.00380374
	LOSS [training: 0.5832668456094512 | validation: 0.7818094912446267]
	TIME [epoch: 9.77 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6407417631264776		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.6407417631264776 | validation: 0.46711077712370896]
	TIME [epoch: 9.75 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4494462964823688		[learning rate: 0.0037853]
	Learning Rate: 0.00378534
	LOSS [training: 0.4494462964823688 | validation: 0.4172395360937782]
	TIME [epoch: 9.75 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3847328769825408		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.3847328769825408 | validation: 0.35584290807670527]
	TIME [epoch: 9.77 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3903801110550721		[learning rate: 0.003767]
	Learning Rate: 0.00376704
	LOSS [training: 0.3903801110550721 | validation: 0.42195834178968655]
	TIME [epoch: 9.76 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4008664214181972		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.4008664214181972 | validation: 0.47394992831407046]
	TIME [epoch: 9.76 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6343544288120153		[learning rate: 0.0037488]
	Learning Rate: 0.00374882
	LOSS [training: 0.6343544288120153 | validation: 0.5785071248998492]
	TIME [epoch: 9.76 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5212879238867527		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.5212879238867527 | validation: 0.4669471038511579]
	TIME [epoch: 9.76 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40941619313754785		[learning rate: 0.0037307]
	Learning Rate: 0.00373069
	LOSS [training: 0.40941619313754785 | validation: 0.37217219622743075]
	TIME [epoch: 9.75 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3916438603276702		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.3916438603276702 | validation: 0.4146077593563652]
	TIME [epoch: 9.76 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3693661247538179		[learning rate: 0.0037127]
	Learning Rate: 0.00371265
	LOSS [training: 0.3693661247538179 | validation: 0.3216357158704344]
	TIME [epoch: 9.76 sec]
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38544047910626816		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.38544047910626816 | validation: 0.36683207334036255]
	TIME [epoch: 9.75 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4263670509812604		[learning rate: 0.0036947]
	Learning Rate: 0.0036947
	LOSS [training: 0.4263670509812604 | validation: 0.5058190465165702]
	TIME [epoch: 9.74 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4331525647046197		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.4331525647046197 | validation: 0.4248734284146849]
	TIME [epoch: 9.77 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4634613511203988		[learning rate: 0.0036768]
	Learning Rate: 0.00367683
	LOSS [training: 0.4634613511203988 | validation: 0.4288567702045451]
	TIME [epoch: 9.75 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42915429985494374		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.42915429985494374 | validation: 0.442815680052838]
	TIME [epoch: 9.75 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4759104839382745		[learning rate: 0.0036591]
	Learning Rate: 0.00365905
	LOSS [training: 0.4759104839382745 | validation: 0.5270798159255261]
	TIME [epoch: 9.77 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46252971557375916		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.46252971557375916 | validation: 0.40329779055714954]
	TIME [epoch: 9.75 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4156104321837487		[learning rate: 0.0036414]
	Learning Rate: 0.00364136
	LOSS [training: 0.4156104321837487 | validation: 0.3596628755495906]
	TIME [epoch: 9.75 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38153780616609434		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.38153780616609434 | validation: 0.36824821156100285]
	TIME [epoch: 9.77 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3937688181208687		[learning rate: 0.0036237]
	Learning Rate: 0.00362375
	LOSS [training: 0.3937688181208687 | validation: 0.4024973074138527]
	TIME [epoch: 9.76 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4788056856629136		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.4788056856629136 | validation: 0.6508025941314902]
	TIME [epoch: 9.75 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48642874135310743		[learning rate: 0.0036062]
	Learning Rate: 0.00360622
	LOSS [training: 0.48642874135310743 | validation: 0.39592355413788904]
	TIME [epoch: 9.76 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35899493048252934		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.35899493048252934 | validation: 0.36473589636499226]
	TIME [epoch: 9.76 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34964044250089926		[learning rate: 0.0035888]
	Learning Rate: 0.00358878
	LOSS [training: 0.34964044250089926 | validation: 0.3549983782597834]
	TIME [epoch: 9.75 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4706143699780772		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.4706143699780772 | validation: 0.4527494195018788]
	TIME [epoch: 9.75 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5394950626108843		[learning rate: 0.0035714]
	Learning Rate: 0.00357143
	LOSS [training: 0.5394950626108843 | validation: 0.5536187558137475]
	TIME [epoch: 9.75 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47083023971046145		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.47083023971046145 | validation: 0.48053136054675116]
	TIME [epoch: 9.74 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4407119456627308		[learning rate: 0.0035542]
	Learning Rate: 0.00355416
	LOSS [training: 0.4407119456627308 | validation: 0.36186884975179406]
	TIME [epoch: 9.74 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3863188489858177		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.3863188489858177 | validation: 0.44042819865996563]
	TIME [epoch: 9.77 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5221310510678163		[learning rate: 0.003537]
	Learning Rate: 0.00353697
	LOSS [training: 0.5221310510678163 | validation: 0.4748445478956762]
	TIME [epoch: 9.75 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6152720207835457		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.6152720207835457 | validation: 0.765892547845663]
	TIME [epoch: 9.75 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9024936910884017		[learning rate: 0.0035199]
	Learning Rate: 0.00351987
	LOSS [training: 0.9024936910884017 | validation: 0.737359468079861]
	TIME [epoch: 9.75 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0142596745680155		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 1.0142596745680155 | validation: 1.1139670284392567]
	TIME [epoch: 9.75 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8679537975793876		[learning rate: 0.0035028]
	Learning Rate: 0.00350285
	LOSS [training: 0.8679537975793876 | validation: 0.4820972829197955]
	TIME [epoch: 9.74 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5838966177424192		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.5838966177424192 | validation: 0.5430684831350083]
	TIME [epoch: 9.75 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4932398803420151		[learning rate: 0.0034859]
	Learning Rate: 0.00348591
	LOSS [training: 0.4932398803420151 | validation: 0.46337320918383995]
	TIME [epoch: 9.75 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4547488291112822		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.4547488291112822 | validation: 0.565592027698823]
	TIME [epoch: 9.75 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49538138203082094		[learning rate: 0.003469]
	Learning Rate: 0.00346905
	LOSS [training: 0.49538138203082094 | validation: 0.7025169985390983]
	TIME [epoch: 9.75 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7072129555129077		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.7072129555129077 | validation: 0.6007255462216962]
	TIME [epoch: 9.77 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5241222938789581		[learning rate: 0.0034523]
	Learning Rate: 0.00345227
	LOSS [training: 0.5241222938789581 | validation: 0.5091236504492672]
	TIME [epoch: 9.75 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5102618414043715		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.5102618414043715 | validation: 0.5055640243641785]
	TIME [epoch: 9.74 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5103439494124937		[learning rate: 0.0034356]
	Learning Rate: 0.00343558
	LOSS [training: 0.5103439494124937 | validation: 0.7396525999467476]
	TIME [epoch: 9.77 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7627742275301626		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.7627742275301626 | validation: 0.8875767424036942]
	TIME [epoch: 9.74 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.725563435887825		[learning rate: 0.003419]
	Learning Rate: 0.00341897
	LOSS [training: 0.725563435887825 | validation: 0.5756806832515975]
	TIME [epoch: 9.73 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6653973260460989		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.6653973260460989 | validation: 0.6143431054863423]
	TIME [epoch: 9.75 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5808589810758896		[learning rate: 0.0034024]
	Learning Rate: 0.00340243
	LOSS [training: 0.5808589810758896 | validation: 0.5480012925144699]
	TIME [epoch: 9.75 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5086505298950307		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.5086505298950307 | validation: 0.4890358193123109]
	TIME [epoch: 9.75 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4462396992847807		[learning rate: 0.003386]
	Learning Rate: 0.00338598
	LOSS [training: 0.4462396992847807 | validation: 0.440352418676879]
	TIME [epoch: 9.75 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45914483028801617		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.45914483028801617 | validation: 0.37558985244307236]
	TIME [epoch: 9.75 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4109141743628618		[learning rate: 0.0033696]
	Learning Rate: 0.0033696
	LOSS [training: 0.4109141743628618 | validation: 0.5493851664678017]
	TIME [epoch: 9.74 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5854686636187114		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.5854686636187114 | validation: 0.508242222641809]
	TIME [epoch: 9.74 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5731602367541228		[learning rate: 0.0033533]
	Learning Rate: 0.00335331
	LOSS [training: 0.5731602367541228 | validation: 0.7243243658099785]
	TIME [epoch: 9.75 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7970206708705179		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.7970206708705179 | validation: 0.7334094544998025]
	TIME [epoch: 9.74 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6826629104916158		[learning rate: 0.0033371]
	Learning Rate: 0.00333709
	LOSS [training: 0.6826629104916158 | validation: 0.6325866751144875]
	TIME [epoch: 9.74 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6552061182853428		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.6552061182853428 | validation: 0.6924528609834415]
	TIME [epoch: 9.76 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7463749619867468		[learning rate: 0.003321]
	Learning Rate: 0.00332096
	LOSS [training: 0.7463749619867468 | validation: 0.861532605465732]
	TIME [epoch: 9.75 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8936473742644591		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.8936473742644591 | validation: 0.8899299999460618]
	TIME [epoch: 9.75 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9272307291996367		[learning rate: 0.0033049]
	Learning Rate: 0.0033049
	LOSS [training: 0.9272307291996367 | validation: 0.7978847776783476]
	TIME [epoch: 9.77 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9340586668965886		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.9340586668965886 | validation: 0.712312806327901]
	TIME [epoch: 9.75 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6317119363605987		[learning rate: 0.0032889]
	Learning Rate: 0.00328891
	LOSS [training: 0.6317119363605987 | validation: 0.4545884821139404]
	TIME [epoch: 9.74 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6682404043727894		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.6682404043727894 | validation: 0.7544594267315108]
	TIME [epoch: 9.76 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7175699019195886		[learning rate: 0.003273]
	Learning Rate: 0.00327301
	LOSS [training: 0.7175699019195886 | validation: 0.704699129109549]
	TIME [epoch: 9.75 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6300148120661883		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.6300148120661883 | validation: 0.49175884300846634]
	TIME [epoch: 9.75 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4562282644749566		[learning rate: 0.0032572]
	Learning Rate: 0.00325718
	LOSS [training: 0.4562282644749566 | validation: 0.4040736799121452]
	TIME [epoch: 9.74 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4160852899754697		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.4160852899754697 | validation: 0.4021193318395929]
	TIME [epoch: 9.77 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4114537724846922		[learning rate: 0.0032414]
	Learning Rate: 0.00324143
	LOSS [training: 0.4114537724846922 | validation: 0.5047961184283801]
	TIME [epoch: 9.74 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40155416320251647		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.40155416320251647 | validation: 0.4548736190722448]
	TIME [epoch: 9.73 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3717828833871432		[learning rate: 0.0032258]
	Learning Rate: 0.00322576
	LOSS [training: 0.3717828833871432 | validation: 0.4443052010557697]
	TIME [epoch: 9.77 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40026355012910253		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.40026355012910253 | validation: 0.48097873833219423]
	TIME [epoch: 9.74 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5479141250150306		[learning rate: 0.0032102]
	Learning Rate: 0.00321016
	LOSS [training: 0.5479141250150306 | validation: 0.5369795248085102]
	TIME [epoch: 9.74 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.642725206322986		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.642725206322986 | validation: 0.7683974747747117]
	TIME [epoch: 9.77 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8358143966174086		[learning rate: 0.0031946]
	Learning Rate: 0.00319463
	LOSS [training: 0.8358143966174086 | validation: 0.7137143830630245]
	TIME [epoch: 9.75 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6045988254174028		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.6045988254174028 | validation: 0.4308718061330295]
	TIME [epoch: 9.74 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4373393758804216		[learning rate: 0.0031792]
	Learning Rate: 0.00317918
	LOSS [training: 0.4373393758804216 | validation: 0.5363109885317014]
	TIME [epoch: 9.75 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5870226890579271		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.5870226890579271 | validation: 0.654295141332467]
	TIME [epoch: 9.76 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6625659194688495		[learning rate: 0.0031638]
	Learning Rate: 0.00316381
	LOSS [training: 0.6625659194688495 | validation: 0.5203923317657375]
	TIME [epoch: 9.74 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44903975391640943		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.44903975391640943 | validation: 0.3735216369247532]
	TIME [epoch: 9.74 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39585640957886675		[learning rate: 0.0031485]
	Learning Rate: 0.00314851
	LOSS [training: 0.39585640957886675 | validation: 0.3866864201110257]
	TIME [epoch: 9.76 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.418744796890752		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.418744796890752 | validation: 0.42063446731161935]
	TIME [epoch: 9.74 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4182116117990808		[learning rate: 0.0031333]
	Learning Rate: 0.00313329
	LOSS [training: 0.4182116117990808 | validation: 0.3211488780830236]
	TIME [epoch: 9.74 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3472302792232874		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.3472302792232874 | validation: 0.36761634598663057]
	TIME [epoch: 9.77 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3243693998991965		[learning rate: 0.0031181]
	Learning Rate: 0.00311813
	LOSS [training: 0.3243693998991965 | validation: 0.32112653200692237]
	TIME [epoch: 9.74 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36065502068160304		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.36065502068160304 | validation: 0.47644685913241147]
	TIME [epoch: 9.74 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41147062390089406		[learning rate: 0.0031031]
	Learning Rate: 0.00310305
	LOSS [training: 0.41147062390089406 | validation: 0.5752244121929877]
	TIME [epoch: 9.76 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47586966252676277		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.47586966252676277 | validation: 0.36068888343212224]
	TIME [epoch: 9.74 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3880005761742366		[learning rate: 0.003088]
	Learning Rate: 0.00308805
	LOSS [training: 0.3880005761742366 | validation: 0.5083705629834012]
	TIME [epoch: 9.74 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5278757971567403		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.5278757971567403 | validation: 0.5211301878978112]
	TIME [epoch: 9.74 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49007607332580533		[learning rate: 0.0030731]
	Learning Rate: 0.00307312
	LOSS [training: 0.49007607332580533 | validation: 0.45354963650581315]
	TIME [epoch: 9.74 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41026772916000526		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.41026772916000526 | validation: 0.3986529145226566]
	TIME [epoch: 9.74 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3402427233188389		[learning rate: 0.0030583]
	Learning Rate: 0.00305825
	LOSS [training: 0.3402427233188389 | validation: 0.3375912429017087]
	TIME [epoch: 9.73 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3672643095616487		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.3672643095616487 | validation: 0.41951047318405915]
	TIME [epoch: 9.77 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38132113375853904		[learning rate: 0.0030435]
	Learning Rate: 0.00304347
	LOSS [training: 0.38132113375853904 | validation: 0.4482137713250935]
	TIME [epoch: 9.73 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3866094807797108		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.3866094807797108 | validation: 0.41739272274734457]
	TIME [epoch: 9.75 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34568774533605345		[learning rate: 0.0030287]
	Learning Rate: 0.00302875
	LOSS [training: 0.34568774533605345 | validation: 0.365485787033344]
	TIME [epoch: 9.77 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4076300855819802		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.4076300855819802 | validation: 0.4417679955510724]
	TIME [epoch: 9.74 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4616029311338874		[learning rate: 0.0030141]
	Learning Rate: 0.0030141
	LOSS [training: 0.4616029311338874 | validation: 0.45735109024555765]
	TIME [epoch: 9.73 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40453503795447326		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.40453503795447326 | validation: 0.4927452403649173]
	TIME [epoch: 9.76 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4690341611758752		[learning rate: 0.0029995]
	Learning Rate: 0.00299953
	LOSS [training: 0.4690341611758752 | validation: 0.35842826482556406]
	TIME [epoch: 9.75 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3933110322469945		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.3933110322469945 | validation: 0.5784138976385712]
	TIME [epoch: 9.74 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4105765757537161		[learning rate: 0.002985]
	Learning Rate: 0.00298502
	LOSS [training: 0.4105765757537161 | validation: 0.32080132454217625]
	TIME [epoch: 9.75 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3873198457380088		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.3873198457380088 | validation: 0.3503675619949631]
	TIME [epoch: 9.75 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3603430600481664		[learning rate: 0.0029706]
	Learning Rate: 0.00297059
	LOSS [training: 0.3603430600481664 | validation: 0.38996903210977724]
	TIME [epoch: 9.74 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3954730153188984		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.3954730153188984 | validation: 0.3661437885958426]
	TIME [epoch: 9.74 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3825911086324836		[learning rate: 0.0029562]
	Learning Rate: 0.00295622
	LOSS [training: 0.3825911086324836 | validation: 0.3474236184662573]
	TIME [epoch: 9.76 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37637248550077995		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.37637248550077995 | validation: 0.363390895733863]
	TIME [epoch: 9.74 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42265924243854974		[learning rate: 0.0029419]
	Learning Rate: 0.00294192
	LOSS [training: 0.42265924243854974 | validation: 0.43430807750814543]
	TIME [epoch: 9.75 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4442941631208551		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.4442941631208551 | validation: 0.4185218403450269]
	TIME [epoch: 9.76 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4681536923258928		[learning rate: 0.0029277]
	Learning Rate: 0.0029277
	LOSS [training: 0.4681536923258928 | validation: 0.48268390825962776]
	TIME [epoch: 9.75 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5438325775439294		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.5438325775439294 | validation: 0.5205962835946778]
	TIME [epoch: 9.75 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48225152914737385		[learning rate: 0.0029135]
	Learning Rate: 0.00291354
	LOSS [training: 0.48225152914737385 | validation: 0.40449675317627015]
	TIME [epoch: 9.76 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4043340709265566		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.4043340709265566 | validation: 0.34484338945970733]
	TIME [epoch: 9.74 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3738452117951998		[learning rate: 0.0028995]
	Learning Rate: 0.00289945
	LOSS [training: 0.3738452117951998 | validation: 0.4751723323064918]
	TIME [epoch: 9.73 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35719630258722235		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.35719630258722235 | validation: 0.36784120821273475]
	TIME [epoch: 9.75 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3305166896673486		[learning rate: 0.0028854]
	Learning Rate: 0.00288543
	LOSS [training: 0.3305166896673486 | validation: 0.32234478702713387]
	TIME [epoch: 9.76 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3195725221328738		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.3195725221328738 | validation: 0.35569948985018285]
	TIME [epoch: 9.74 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3773338679186796		[learning rate: 0.0028715]
	Learning Rate: 0.00287148
	LOSS [training: 0.3773338679186796 | validation: 0.330464235060833]
	TIME [epoch: 9.75 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3658103920800152		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.3658103920800152 | validation: 0.3500923298424398]
	TIME [epoch: 9.76 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3211145109628579		[learning rate: 0.0028576]
	Learning Rate: 0.00285759
	LOSS [training: 0.3211145109628579 | validation: 0.34358300465954617]
	TIME [epoch: 9.74 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3312864882958929		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.3312864882958929 | validation: 0.3155490219887564]
	TIME [epoch: 9.75 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3535947880351954		[learning rate: 0.0028438]
	Learning Rate: 0.00284377
	LOSS [training: 0.3535947880351954 | validation: 0.4284687947864888]
	TIME [epoch: 9.76 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38363886171137496		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.38363886171137496 | validation: 0.3826689575776785]
	TIME [epoch: 9.74 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4185375577133216		[learning rate: 0.00283]
	Learning Rate: 0.00283002
	LOSS [training: 0.4185375577133216 | validation: 0.43022550666908776]
	TIME [epoch: 9.74 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4793168468113377		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.4793168468113377 | validation: 0.4531185435968664]
	TIME [epoch: 9.75 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45472493900923083		[learning rate: 0.0028163]
	Learning Rate: 0.00281633
	LOSS [training: 0.45472493900923083 | validation: 0.5254961957949054]
	TIME [epoch: 9.75 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4597523697061622		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.4597523697061622 | validation: 0.41206419483523976]
	TIME [epoch: 9.75 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40074153000357915		[learning rate: 0.0028027]
	Learning Rate: 0.00280272
	LOSS [training: 0.40074153000357915 | validation: 0.3290879163349569]
	TIME [epoch: 9.76 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33993739360119407		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.33993739360119407 | validation: 0.3218465374103812]
	TIME [epoch: 9.76 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3126495429329982		[learning rate: 0.0027892]
	Learning Rate: 0.00278916
	LOSS [training: 0.3126495429329982 | validation: 0.36465455472307495]
	TIME [epoch: 9.75 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3412851572575911		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.3412851572575911 | validation: 0.40252188482244733]
	TIME [epoch: 9.74 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3779637795640516		[learning rate: 0.0027757]
	Learning Rate: 0.00277567
	LOSS [training: 0.3779637795640516 | validation: 0.41120806819963035]
	TIME [epoch: 9.78 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35729702078956666		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.35729702078956666 | validation: 0.3758581820960504]
	TIME [epoch: 9.75 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33713864321745246		[learning rate: 0.0027623]
	Learning Rate: 0.00276225
	LOSS [training: 0.33713864321745246 | validation: 0.31066561885922683]
	TIME [epoch: 9.75 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4094699102648627		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.4094699102648627 | validation: 0.4044034919227798]
	TIME [epoch: 9.76 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4192874853166525		[learning rate: 0.0027489]
	Learning Rate: 0.00274889
	LOSS [training: 0.4192874853166525 | validation: 0.4098806006009119]
	TIME [epoch: 9.74 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3707572851054361		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.3707572851054361 | validation: 0.3379219854752637]
	TIME [epoch: 9.75 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4460199980901921		[learning rate: 0.0027356]
	Learning Rate: 0.0027356
	LOSS [training: 0.4460199980901921 | validation: 0.5544649862181094]
	TIME [epoch: 9.76 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6342637535242309		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.6342637535242309 | validation: 0.4970642510147912]
	TIME [epoch: 9.74 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4698505800404192		[learning rate: 0.0027224]
	Learning Rate: 0.00272237
	LOSS [training: 0.4698505800404192 | validation: 0.3776948314698225]
	TIME [epoch: 9.75 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40811067239914706		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.40811067239914706 | validation: 0.3793388765103673]
	TIME [epoch: 9.75 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.367471744326245		[learning rate: 0.0027092]
	Learning Rate: 0.00270921
	LOSS [training: 0.367471744326245 | validation: 0.3289714466608868]
	TIME [epoch: 9.76 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32978567928823027		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.32978567928823027 | validation: 0.3228544728631338]
	TIME [epoch: 9.76 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3101329498092025		[learning rate: 0.0026961]
	Learning Rate: 0.00269611
	LOSS [training: 0.3101329498092025 | validation: 0.3699267857073157]
	TIME [epoch: 9.75 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41309721657083587		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.41309721657083587 | validation: 0.4104437930083132]
	TIME [epoch: 9.78 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4439612608362715		[learning rate: 0.0026831]
	Learning Rate: 0.00268307
	LOSS [training: 0.4439612608362715 | validation: 0.42832676744265796]
	TIME [epoch: 9.74 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6317449623535786		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.6317449623535786 | validation: 0.7907537046673372]
	TIME [epoch: 9.75 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8058136699951849		[learning rate: 0.0026701]
	Learning Rate: 0.00267009
	LOSS [training: 0.8058136699951849 | validation: 0.637718320739311]
	TIME [epoch: 9.77 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5905322555835946		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.5905322555835946 | validation: 0.4476626696340169]
	TIME [epoch: 9.73 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4329620265080208		[learning rate: 0.0026572]
	Learning Rate: 0.00265718
	LOSS [training: 0.4329620265080208 | validation: 0.3309393835911779]
	TIME [epoch: 9.74 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36534805918413277		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.36534805918413277 | validation: 0.39236115695812507]
	TIME [epoch: 9.76 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193346708303348		[learning rate: 0.0026443]
	Learning Rate: 0.00264433
	LOSS [training: 0.5193346708303348 | validation: 0.5171838072294921]
	TIME [epoch: 9.74 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6055192171257858		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.6055192171257858 | validation: 0.5995159483098884]
	TIME [epoch: 9.98 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5888452468348604		[learning rate: 0.0026315]
	Learning Rate: 0.00263154
	LOSS [training: 0.5888452468348604 | validation: 0.5000363003907077]
	TIME [epoch: 9.77 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5086743578136217		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.5086743578136217 | validation: 0.6075378191693004]
	TIME [epoch: 9.78 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6602774409391561		[learning rate: 0.0026188]
	Learning Rate: 0.00261882
	LOSS [training: 0.6602774409391561 | validation: 0.5904385679257944]
	TIME [epoch: 9.76 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6541476583419514		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.6541476583419514 | validation: 0.519318491388692]
	TIME [epoch: 9.76 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4710952099995901		[learning rate: 0.0026062]
	Learning Rate: 0.00260615
	LOSS [training: 0.4710952099995901 | validation: 0.4763796599595815]
	TIME [epoch: 9.79 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6127851508548016		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.6127851508548016 | validation: 0.6473314294417503]
	TIME [epoch: 9.77 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7148604763901197		[learning rate: 0.0025936]
	Learning Rate: 0.00259355
	LOSS [training: 0.7148604763901197 | validation: 0.6821638661512266]
	TIME [epoch: 9.76 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.660637342956033		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.660637342956033 | validation: 0.5274110589944693]
	TIME [epoch: 9.79 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.756747711915439		[learning rate: 0.002581]
	Learning Rate: 0.00258101
	LOSS [training: 0.756747711915439 | validation: 0.7615365774563934]
	TIME [epoch: 9.77 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.798101693382643		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.798101693382643 | validation: 0.7214280779095071]
	TIME [epoch: 9.76 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6997734101045776		[learning rate: 0.0025685]
	Learning Rate: 0.00256853
	LOSS [training: 0.6997734101045776 | validation: 0.5515216181638057]
	TIME [epoch: 9.77 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.562431635061285		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.562431635061285 | validation: 0.4276486013716955]
	TIME [epoch: 9.78 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41102917537247896		[learning rate: 0.0025561]
	Learning Rate: 0.00255611
	LOSS [training: 0.41102917537247896 | validation: 0.4057682979225098]
	TIME [epoch: 9.76 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37887432735530446		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.37887432735530446 | validation: 0.3524524080742003]
	TIME [epoch: 9.77 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3168137220041828		[learning rate: 0.0025437]
	Learning Rate: 0.00254375
	LOSS [training: 0.3168137220041828 | validation: 0.3196606259393788]
	TIME [epoch: 9.78 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3204920243425093		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.3204920243425093 | validation: 0.3307853627718639]
	TIME [epoch: 9.77 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4326721760671507		[learning rate: 0.0025314]
	Learning Rate: 0.00253144
	LOSS [training: 0.4326721760671507 | validation: 0.5542754536513728]
	TIME [epoch: 9.77 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43485553173519653		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.43485553173519653 | validation: 0.41275927087147607]
	TIME [epoch: 9.79 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3955003825244119		[learning rate: 0.0025192]
	Learning Rate: 0.0025192
	LOSS [training: 0.3955003825244119 | validation: 0.40825561039050384]
	TIME [epoch: 9.76 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34314261899309206		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.34314261899309206 | validation: 0.3386996147821033]
	TIME [epoch: 9.77 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36953208248895375		[learning rate: 0.002507]
	Learning Rate: 0.00250702
	LOSS [training: 0.36953208248895375 | validation: 0.40150568799805075]
	TIME [epoch: 9.78 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38650180193526007		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.38650180193526007 | validation: 0.3974336888683482]
	TIME [epoch: 9.77 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46489621324168995		[learning rate: 0.0024949]
	Learning Rate: 0.0024949
	LOSS [training: 0.46489621324168995 | validation: 0.5781657197070946]
	TIME [epoch: 9.77 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5164659088045959		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.5164659088045959 | validation: 0.5140530360690923]
	TIME [epoch: 9.78 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4780876776320307		[learning rate: 0.0024828]
	Learning Rate: 0.00248283
	LOSS [training: 0.4780876776320307 | validation: 0.4649816455226366]
	TIME [epoch: 9.78 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44527751364128115		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.44527751364128115 | validation: 0.533886763053802]
	TIME [epoch: 9.76 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48658162054339427		[learning rate: 0.0024708]
	Learning Rate: 0.00247083
	LOSS [training: 0.48658162054339427 | validation: 0.5259142155935823]
	TIME [epoch: 9.77 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4895660003510002		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.4895660003510002 | validation: 0.48087810019299826]
	TIME [epoch: 9.78 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4917195751791585		[learning rate: 0.0024589]
	Learning Rate: 0.00245888
	LOSS [training: 0.4917195751791585 | validation: 0.5423113910703585]
	TIME [epoch: 9.76 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45276266077917066		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.45276266077917066 | validation: 0.47222274857563207]
	TIME [epoch: 9.77 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4387544126037296		[learning rate: 0.002447]
	Learning Rate: 0.00244699
	LOSS [training: 0.4387544126037296 | validation: 0.3617911591691653]
	TIME [epoch: 9.78 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.332221737506231		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.332221737506231 | validation: 0.3446709125467529]
	TIME [epoch: 9.76 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3547680229443478		[learning rate: 0.0024352]
	Learning Rate: 0.00243515
	LOSS [training: 0.3547680229443478 | validation: 0.3214593057815965]
	TIME [epoch: 9.76 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3432326404296205		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.3432326404296205 | validation: 0.35359479615060646]
	TIME [epoch: 9.78 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42443620703118456		[learning rate: 0.0024234]
	Learning Rate: 0.00242338
	LOSS [training: 0.42443620703118456 | validation: 0.5290228646358751]
	TIME [epoch: 9.76 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4901512697691722		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.4901512697691722 | validation: 0.5322652427501242]
	TIME [epoch: 9.76 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4997231898225876		[learning rate: 0.0024117]
	Learning Rate: 0.00241166
	LOSS [training: 0.4997231898225876 | validation: 0.5232915842495468]
	TIME [epoch: 9.76 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4245548072480697		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.4245548072480697 | validation: 0.41600689099819677]
	TIME [epoch: 9.78 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3909926273694755		[learning rate: 0.0024]
	Learning Rate: 0.0024
	LOSS [training: 0.3909926273694755 | validation: 0.40787086527906596]
	TIME [epoch: 9.75 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34898738998841955		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.34898738998841955 | validation: 0.3703154627029288]
	TIME [epoch: 9.75 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3527373846576132		[learning rate: 0.0023884]
	Learning Rate: 0.00238839
	LOSS [training: 0.3527373846576132 | validation: 0.38641164258198507]
	TIME [epoch: 9.77 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3896496233268954		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.3896496233268954 | validation: 0.39335124029477947]
	TIME [epoch: 9.75 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4401935683939023		[learning rate: 0.0023768]
	Learning Rate: 0.00237684
	LOSS [training: 0.4401935683939023 | validation: 0.49858477184606287]
	TIME [epoch: 9.76 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4040263173298305		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.4040263173298305 | validation: 0.4011673757037802]
	TIME [epoch: 9.78 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3982474961338262		[learning rate: 0.0023653]
	Learning Rate: 0.00236535
	LOSS [training: 0.3982474961338262 | validation: 0.4375645996409932]
	TIME [epoch: 9.76 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4094155765105148		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.4094155765105148 | validation: 0.37929998820082256]
	TIME [epoch: 9.75 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3362575609653858		[learning rate: 0.0023539]
	Learning Rate: 0.00235391
	LOSS [training: 0.3362575609653858 | validation: 0.3206190418199131]
	TIME [epoch: 9.77 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31277775510864647		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.31277775510864647 | validation: 0.3386845546492585]
	TIME [epoch: 9.76 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3542471605682849		[learning rate: 0.0023425]
	Learning Rate: 0.00234252
	LOSS [training: 0.3542471605682849 | validation: 0.4187399385309979]
	TIME [epoch: 9.76 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34257522882269004		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.34257522882269004 | validation: 0.3559879408071266]
	TIME [epoch: 9.77 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3353100911003619		[learning rate: 0.0023312]
	Learning Rate: 0.0023312
	LOSS [training: 0.3353100911003619 | validation: 0.3325153211199225]
	TIME [epoch: 9.77 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3368023052864638		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.3368023052864638 | validation: 0.3783911091331952]
	TIME [epoch: 9.75 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3300378406096029		[learning rate: 0.0023199]
	Learning Rate: 0.00231992
	LOSS [training: 0.3300378406096029 | validation: 0.32599316758142566]
	TIME [epoch: 9.76 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32380253193920583		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.32380253193920583 | validation: 0.3528295392648768]
	TIME [epoch: 9.77 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40532199811428776		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.40532199811428776 | validation: 0.37014495415897786]
	TIME [epoch: 9.75 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3900446836239772		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.3900446836239772 | validation: 0.5502088295331232]
	TIME [epoch: 9.76 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43178001133479266		[learning rate: 0.0022975]
	Learning Rate: 0.00229754
	LOSS [training: 0.43178001133479266 | validation: 0.37175413895797976]
	TIME [epoch: 9.78 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.431974784096467		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.431974784096467 | validation: 0.4840568648771333]
	TIME [epoch: 9.76 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.551609959572551		[learning rate: 0.0022864]
	Learning Rate: 0.00228643
	LOSS [training: 0.551609959572551 | validation: 0.6122235906086886]
	TIME [epoch: 9.75 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5456464087904017		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.5456464087904017 | validation: 0.5110163599941282]
	TIME [epoch: 9.78 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5070400000971796		[learning rate: 0.0022754]
	Learning Rate: 0.00227537
	LOSS [training: 0.5070400000971796 | validation: 0.46513971008241534]
	TIME [epoch: 9.76 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.471857531332167		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.471857531332167 | validation: 0.4963801318637176]
	TIME [epoch: 9.75 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43812787229642913		[learning rate: 0.0022644]
	Learning Rate: 0.00226437
	LOSS [training: 0.43812787229642913 | validation: 0.49137325497722006]
	TIME [epoch: 9.76 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44933045498303825		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.44933045498303825 | validation: 0.4862166878034579]
	TIME [epoch: 9.76 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5610451160851946		[learning rate: 0.0022534]
	Learning Rate: 0.00225342
	LOSS [training: 0.5610451160851946 | validation: 0.6205896410267998]
	TIME [epoch: 9.76 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5149906594694762		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.5149906594694762 | validation: 0.4543053460313866]
	TIME [epoch: 9.76 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4084401627503332		[learning rate: 0.0022425]
	Learning Rate: 0.00224252
	LOSS [training: 0.4084401627503332 | validation: 0.3874312464977413]
	TIME [epoch: 9.77 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35894285288305305		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.35894285288305305 | validation: 0.35618431791275784]
	TIME [epoch: 9.76 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33613586026050746		[learning rate: 0.0022317]
	Learning Rate: 0.00223168
	LOSS [training: 0.33613586026050746 | validation: 0.3031890102299133]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_719.pth
	Model improved!!!
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.290020124904503		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.290020124904503 | validation: 0.2526666967293262]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_720.pth
	Model improved!!!
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2771761149401435		[learning rate: 0.0022209]
	Learning Rate: 0.00222089
	LOSS [training: 0.2771761149401435 | validation: 0.3064922160333452]
	TIME [epoch: 9.76 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2946551304164927		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.2946551304164927 | validation: 0.42174452946483415]
	TIME [epoch: 9.75 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5291370196726086		[learning rate: 0.0022101]
	Learning Rate: 0.00221015
	LOSS [training: 0.5291370196726086 | validation: 0.40097326132744643]
	TIME [epoch: 9.77 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3682475607210358		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.3682475607210358 | validation: 0.3272290760026347]
	TIME [epoch: 9.76 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3630173028821669		[learning rate: 0.0021995]
	Learning Rate: 0.00219946
	LOSS [training: 0.3630173028821669 | validation: 0.32291154707528086]
	TIME [epoch: 9.75 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38169316037701617		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.38169316037701617 | validation: 0.47045355754257956]
	TIME [epoch: 9.77 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.557129637514666		[learning rate: 0.0021888]
	Learning Rate: 0.00218882
	LOSS [training: 0.557129637514666 | validation: 0.5264800711466397]
	TIME [epoch: 9.75 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5274459390120225		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.5274459390120225 | validation: 0.4227954467177457]
	TIME [epoch: 9.76 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4768038418787855		[learning rate: 0.0021782]
	Learning Rate: 0.00217824
	LOSS [training: 0.4768038418787855 | validation: 0.4869491471786938]
	TIME [epoch: 9.75 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4957671963136289		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.4957671963136289 | validation: 0.466603341518554]
	TIME [epoch: 9.75 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5422928533957412		[learning rate: 0.0021677]
	Learning Rate: 0.0021677
	LOSS [training: 0.5422928533957412 | validation: 0.5049065939905116]
	TIME [epoch: 9.75 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5825190649219899		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.5825190649219899 | validation: 0.5768673463181293]
	TIME [epoch: 9.75 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5693609317231301		[learning rate: 0.0021572]
	Learning Rate: 0.00215722
	LOSS [training: 0.5693609317231301 | validation: 0.5258756353963928]
	TIME [epoch: 9.78 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4723410549744533		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.4723410549744533 | validation: 0.5149584403882902]
	TIME [epoch: 9.75 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4840178971498507		[learning rate: 0.0021468]
	Learning Rate: 0.00214679
	LOSS [training: 0.4840178971498507 | validation: 0.4258854359129063]
	TIME [epoch: 9.76 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5007162397587483		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.5007162397587483 | validation: 0.5206147399824916]
	TIME [epoch: 9.77 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48066096533690345		[learning rate: 0.0021364]
	Learning Rate: 0.00213641
	LOSS [training: 0.48066096533690345 | validation: 0.3979364052937537]
	TIME [epoch: 9.75 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3679551386273711		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.3679551386273711 | validation: 0.31812388184497536]
	TIME [epoch: 9.75 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3300615176025549		[learning rate: 0.0021261]
	Learning Rate: 0.00212608
	LOSS [training: 0.3300615176025549 | validation: 0.31154225990780116]
	TIME [epoch: 9.76 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29141729761187085		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.29141729761187085 | validation: 0.2805462605533208]
	TIME [epoch: 9.75 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30684955903877625		[learning rate: 0.0021158]
	Learning Rate: 0.0021158
	LOSS [training: 0.30684955903877625 | validation: 0.30069232658310824]
	TIME [epoch: 9.75 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33332216588042074		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.33332216588042074 | validation: 0.5107496181046995]
	TIME [epoch: 9.76 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3747638037964108		[learning rate: 0.0021056]
	Learning Rate: 0.00210556
	LOSS [training: 0.3747638037964108 | validation: 0.2990724211657502]
	TIME [epoch: 9.77 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2856964751778781		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.2856964751778781 | validation: 0.2890815594851955]
	TIME [epoch: 9.75 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2912820380477689		[learning rate: 0.0020954]
	Learning Rate: 0.00209538
	LOSS [training: 0.2912820380477689 | validation: 0.30016159399675285]
	TIME [epoch: 9.75 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3008872607510873		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.3008872607510873 | validation: 0.2972541098936724]
	TIME [epoch: 9.77 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30828927890973834		[learning rate: 0.0020852]
	Learning Rate: 0.00208525
	LOSS [training: 0.30828927890973834 | validation: 0.28643174737852006]
	TIME [epoch: 9.75 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3317072926542628		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.3317072926542628 | validation: 0.3594686325391491]
	TIME [epoch: 9.75 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3368987467316419		[learning rate: 0.0020752]
	Learning Rate: 0.00207517
	LOSS [training: 0.3368987467316419 | validation: 0.3838373639596502]
	TIME [epoch: 9.76 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32761190945982366		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.32761190945982366 | validation: 0.34140932639612287]
	TIME [epoch: 9.75 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3226777663673157		[learning rate: 0.0020651]
	Learning Rate: 0.00206513
	LOSS [training: 0.3226777663673157 | validation: 0.375510015977411]
	TIME [epoch: 9.75 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35788269710193044		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.35788269710193044 | validation: 0.37230103949444254]
	TIME [epoch: 9.77 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3619788282845208		[learning rate: 0.0020551]
	Learning Rate: 0.00205514
	LOSS [training: 0.3619788282845208 | validation: 0.33788673689119547]
	TIME [epoch: 9.76 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3569502487993235		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.3569502487993235 | validation: 0.3311511123215727]
	TIME [epoch: 9.74 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33449219039739414		[learning rate: 0.0020452]
	Learning Rate: 0.0020452
	LOSS [training: 0.33449219039739414 | validation: 0.34303529721454196]
	TIME [epoch: 9.75 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29075381059914973		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.29075381059914973 | validation: 0.2956021611475175]
	TIME [epoch: 9.75 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3033478777877733		[learning rate: 0.0020353]
	Learning Rate: 0.00203531
	LOSS [training: 0.3033478777877733 | validation: 0.27734844865334146]
	TIME [epoch: 9.75 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2807007829482243		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.2807007829482243 | validation: 0.3003488029805335]
	TIME [epoch: 9.74 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2932839515745077		[learning rate: 0.0020255]
	Learning Rate: 0.00202547
	LOSS [training: 0.2932839515745077 | validation: 0.28432021757547576]
	TIME [epoch: 9.76 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2807079158230958		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.2807079158230958 | validation: 0.27060144391898006]
	TIME [epoch: 9.74 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.265319122259063		[learning rate: 0.0020157]
	Learning Rate: 0.00201568
	LOSS [training: 0.265319122259063 | validation: 0.2615720434512896]
	TIME [epoch: 9.73 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2654021493014947		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.2654021493014947 | validation: 0.2933675511881658]
	TIME [epoch: 9.77 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2777794649707911		[learning rate: 0.0020059]
	Learning Rate: 0.00200593
	LOSS [training: 0.2777794649707911 | validation: 0.25493103144324736]
	TIME [epoch: 9.74 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28664909744865125		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.28664909744865125 | validation: 0.31691783968596]
	TIME [epoch: 9.75 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34875607635774697		[learning rate: 0.0019962]
	Learning Rate: 0.00199623
	LOSS [training: 0.34875607635774697 | validation: 0.2788709066633044]
	TIME [epoch: 9.77 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2831404409877545		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.2831404409877545 | validation: 0.2898026769095623]
	TIME [epoch: 9.74 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2729576926597045		[learning rate: 0.0019866]
	Learning Rate: 0.00198658
	LOSS [training: 0.2729576926597045 | validation: 0.28516879152669744]
	TIME [epoch: 9.75 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2922070691574036		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.2922070691574036 | validation: 0.28473449835933323]
	TIME [epoch: 9.76 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.296502755214786		[learning rate: 0.001977]
	Learning Rate: 0.00197697
	LOSS [training: 0.296502755214786 | validation: 0.29203793486776547]
	TIME [epoch: 9.76 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2716303033462507		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.2716303033462507 | validation: 0.2540118410583617]
	TIME [epoch: 9.75 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2756541548337006		[learning rate: 0.0019674]
	Learning Rate: 0.00196741
	LOSS [training: 0.2756541548337006 | validation: 0.27500145057832726]
	TIME [epoch: 9.74 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3053123545257674		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.3053123545257674 | validation: 0.2559771804493806]
	TIME [epoch: 9.77 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28639814864798485		[learning rate: 0.0019579]
	Learning Rate: 0.0019579
	LOSS [training: 0.28639814864798485 | validation: 0.3064918665500704]
	TIME [epoch: 9.74 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32718691494247054		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.32718691494247054 | validation: 0.2900146099596367]
	TIME [epoch: 9.75 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32190217444599833		[learning rate: 0.0019484]
	Learning Rate: 0.00194843
	LOSS [training: 0.32190217444599833 | validation: 0.3135761596729147]
	TIME [epoch: 9.76 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3067125988545212		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.3067125988545212 | validation: 0.28191709844248103]
	TIME [epoch: 9.75 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2968509812429139		[learning rate: 0.001939]
	Learning Rate: 0.00193901
	LOSS [training: 0.2968509812429139 | validation: 0.3300466643493157]
	TIME [epoch: 9.75 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2891035811279001		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.2891035811279001 | validation: 0.26690109123039896]
	TIME [epoch: 9.77 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2781487003153663		[learning rate: 0.0019296]
	Learning Rate: 0.00192963
	LOSS [training: 0.2781487003153663 | validation: 0.30120593036576665]
	TIME [epoch: 9.75 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30562912519532104		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.30562912519532104 | validation: 0.27806034715678457]
	TIME [epoch: 9.74 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33408652658729154		[learning rate: 0.0019203]
	Learning Rate: 0.0019203
	LOSS [training: 0.33408652658729154 | validation: 0.37113962056660826]
	TIME [epoch: 9.74 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36674524809472453		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.36674524809472453 | validation: 0.4102970142748331]
	TIME [epoch: 9.76 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45172300242572205		[learning rate: 0.001911]
	Learning Rate: 0.00191101
	LOSS [training: 0.45172300242572205 | validation: 0.43007019314276923]
	TIME [epoch: 9.75 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42775204790611066		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.42775204790611066 | validation: 0.4596681514850101]
	TIME [epoch: 9.74 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.392641932795287		[learning rate: 0.0019018]
	Learning Rate: 0.00190177
	LOSS [training: 0.392641932795287 | validation: 0.35272329730995405]
	TIME [epoch: 9.76 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3642275391224635		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.3642275391224635 | validation: 0.3544199990590755]
	TIME [epoch: 9.75 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4013895544011672		[learning rate: 0.0018926]
	Learning Rate: 0.00189257
	LOSS [training: 0.4013895544011672 | validation: 0.3410285424494551]
	TIME [epoch: 9.75 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3680019843501777		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.3680019843501777 | validation: 0.316483018687412]
	TIME [epoch: 9.76 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3557768510632151		[learning rate: 0.0018834]
	Learning Rate: 0.00188342
	LOSS [training: 0.3557768510632151 | validation: 0.31994868536353255]
	TIME [epoch: 9.76 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32113320124803174		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.32113320124803174 | validation: 0.31006256349021]
	TIME [epoch: 9.75 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3017135358232187		[learning rate: 0.0018743]
	Learning Rate: 0.00187431
	LOSS [training: 0.3017135358232187 | validation: 0.3113521130807866]
	TIME [epoch: 9.76 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3295568866240357		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.3295568866240357 | validation: 0.39314459263316]
	TIME [epoch: 9.75 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31254746365103714		[learning rate: 0.0018652]
	Learning Rate: 0.00186525
	LOSS [training: 0.31254746365103714 | validation: 0.30440512169278466]
	TIME [epoch: 9.74 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3047091880528386		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.3047091880528386 | validation: 0.3070846033675407]
	TIME [epoch: 9.75 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.275640187437601		[learning rate: 0.0018562]
	Learning Rate: 0.00185623
	LOSS [training: 0.275640187437601 | validation: 0.27383599571392386]
	TIME [epoch: 9.75 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27240985991056155		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.27240985991056155 | validation: 0.2677109296412589]
	TIME [epoch: 9.74 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29303230192086244		[learning rate: 0.0018473]
	Learning Rate: 0.00184725
	LOSS [training: 0.29303230192086244 | validation: 0.3026311504591048]
	TIME [epoch: 9.74 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29639092903377556		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.29639092903377556 | validation: 0.2933302391758387]
	TIME [epoch: 9.77 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2833842078866495		[learning rate: 0.0018383]
	Learning Rate: 0.00183832
	LOSS [training: 0.2833842078866495 | validation: 0.32659291321066286]
	TIME [epoch: 9.74 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30674916176006933		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.30674916176006933 | validation: 0.2907676965219937]
	TIME [epoch: 9.75 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30389898044238695		[learning rate: 0.0018294]
	Learning Rate: 0.00182943
	LOSS [training: 0.30389898044238695 | validation: 0.3262892905900358]
	TIME [epoch: 9.76 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2906566991266044		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.2906566991266044 | validation: 0.28433079742320616]
	TIME [epoch: 9.75 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3012373703659975		[learning rate: 0.0018206]
	Learning Rate: 0.00182058
	LOSS [training: 0.3012373703659975 | validation: 0.2978453248932912]
	TIME [epoch: 9.73 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2837381602764471		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.2837381602764471 | validation: 0.29706840269286816]
	TIME [epoch: 9.75 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3184761494450991		[learning rate: 0.0018118]
	Learning Rate: 0.00181178
	LOSS [training: 0.3184761494450991 | validation: 0.4274926498498185]
	TIME [epoch: 9.74 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37671784187021273		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.37671784187021273 | validation: 0.34464999604200963]
	TIME [epoch: 9.74 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36064772273941126		[learning rate: 0.001803]
	Learning Rate: 0.00180302
	LOSS [training: 0.36064772273941126 | validation: 0.3833861867510377]
	TIME [epoch: 9.75 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3894294536182004		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.3894294536182004 | validation: 0.34507741524444285]
	TIME [epoch: 9.75 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3571647202888265		[learning rate: 0.0017943]
	Learning Rate: 0.0017943
	LOSS [training: 0.3571647202888265 | validation: 0.3472777788389918]
	TIME [epoch: 9.74 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3271072311988521		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.3271072311988521 | validation: 0.30659981232950795]
	TIME [epoch: 9.72 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30156985419565785		[learning rate: 0.0017856]
	Learning Rate: 0.00178562
	LOSS [training: 0.30156985419565785 | validation: 0.31356814518200554]
	TIME [epoch: 9.76 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28205246296038744		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.28205246296038744 | validation: 0.2784245023796808]
	TIME [epoch: 9.74 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2766335762213446		[learning rate: 0.001777]
	Learning Rate: 0.00177699
	LOSS [training: 0.2766335762213446 | validation: 0.2888068171580819]
	TIME [epoch: 9.75 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2699602688714481		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.2699602688714481 | validation: 0.2735548291153614]
	TIME [epoch: 9.74 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.281507430678754		[learning rate: 0.0017684]
	Learning Rate: 0.00176839
	LOSS [training: 0.281507430678754 | validation: 0.3305055384534485]
	TIME [epoch: 9.73 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34720575581044744		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.34720575581044744 | validation: 0.34919720276144117]
	TIME [epoch: 9.75 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32230547971950607		[learning rate: 0.0017598]
	Learning Rate: 0.00175984
	LOSS [training: 0.32230547971950607 | validation: 0.345471495564832]
	TIME [epoch: 9.75 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29867374715572853		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.29867374715572853 | validation: 0.31854277888967025]
	TIME [epoch: 9.74 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3216295040548059		[learning rate: 0.0017513]
	Learning Rate: 0.00175133
	LOSS [training: 0.3216295040548059 | validation: 0.33549253252296396]
	TIME [epoch: 9.73 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3020946516545887		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.3020946516545887 | validation: 0.32475748330876386]
	TIME [epoch: 9.74 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.336840772282221		[learning rate: 0.0017429]
	Learning Rate: 0.00174286
	LOSS [training: 0.336840772282221 | validation: 0.34725877899024327]
	TIME [epoch: 9.75 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3100326975422657		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.3100326975422657 | validation: 0.3249897760754415]
	TIME [epoch: 9.73 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30745646324101034		[learning rate: 0.0017344]
	Learning Rate: 0.00173443
	LOSS [training: 0.30745646324101034 | validation: 0.26684990229956496]
	TIME [epoch: 9.73 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28106376835718766		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.28106376835718766 | validation: 0.27476309733754983]
	TIME [epoch: 9.76 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3438696302808869		[learning rate: 0.001726]
	Learning Rate: 0.00172605
	LOSS [training: 0.3438696302808869 | validation: 0.3660115440965204]
	TIME [epoch: 9.74 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34808656814835615		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.34808656814835615 | validation: 0.3001018901316659]
	TIME [epoch: 9.75 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.286843228815434		[learning rate: 0.0017177]
	Learning Rate: 0.0017177
	LOSS [training: 0.286843228815434 | validation: 0.26368339606312746]
	TIME [epoch: 9.76 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27326765118366314		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.27326765118366314 | validation: 0.2820883983222342]
	TIME [epoch: 9.73 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28261231750221716		[learning rate: 0.0017094]
	Learning Rate: 0.00170939
	LOSS [training: 0.28261231750221716 | validation: 0.31559139321170443]
	TIME [epoch: 9.73 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2684042583152383		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.2684042583152383 | validation: 0.28822301627846153]
	TIME [epoch: 9.74 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29911797364503717		[learning rate: 0.0017011]
	Learning Rate: 0.00170113
	LOSS [training: 0.29911797364503717 | validation: 0.2663833883117675]
	TIME [epoch: 9.73 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2942909887187318		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.2942909887187318 | validation: 0.2607552565569388]
	TIME [epoch: 9.75 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28314193236438745		[learning rate: 0.0016929]
	Learning Rate: 0.0016929
	LOSS [training: 0.28314193236438745 | validation: 0.31684179282008607]
	TIME [epoch: 9.75 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2877240367479004		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.2877240367479004 | validation: 0.2751085034636443]
	TIME [epoch: 9.76 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28390578860254667		[learning rate: 0.0016847]
	Learning Rate: 0.00168471
	LOSS [training: 0.28390578860254667 | validation: 0.27762625224882476]
	TIME [epoch: 9.74 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30507517757868713		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.30507517757868713 | validation: 0.2911476044194042]
	TIME [epoch: 9.72 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27939462055066666		[learning rate: 0.0016766]
	Learning Rate: 0.00167657
	LOSS [training: 0.27939462055066666 | validation: 0.27960116467725954]
	TIME [epoch: 9.75 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2968052904765015		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.2968052904765015 | validation: 0.36408652209403597]
	TIME [epoch: 9.73 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3176210394944913		[learning rate: 0.0016685]
	Learning Rate: 0.00166846
	LOSS [training: 0.3176210394944913 | validation: 0.3491437034078216]
	TIME [epoch: 9.74 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34660229045344565		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.34660229045344565 | validation: 0.27713436378438466]
	TIME [epoch: 9.75 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31475127787772783		[learning rate: 0.0016604]
	Learning Rate: 0.00166039
	LOSS [training: 0.31475127787772783 | validation: 0.3330503410008749]
	TIME [epoch: 9.74 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3572837969013529		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.3572837969013529 | validation: 0.34690836094704375]
	TIME [epoch: 9.72 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35268009709578174		[learning rate: 0.0016524]
	Learning Rate: 0.00165236
	LOSS [training: 0.35268009709578174 | validation: 0.3247347138318341]
	TIME [epoch: 9.74 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3801929041507594		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.3801929041507594 | validation: 0.4301388799342712]
	TIME [epoch: 9.73 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4762873279442827		[learning rate: 0.0016444]
	Learning Rate: 0.00164437
	LOSS [training: 0.4762873279442827 | validation: 0.4443998615557625]
	TIME [epoch: 9.74 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4896947383070257		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.4896947383070257 | validation: 0.4500995289065655]
	TIME [epoch: 9.74 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46618868664877927		[learning rate: 0.0016364]
	Learning Rate: 0.00163642
	LOSS [training: 0.46618868664877927 | validation: 0.38868297115928185]
	TIME [epoch: 9.76 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43435869519189235		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.43435869519189235 | validation: 0.36721923094294234]
	TIME [epoch: 9.74 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4181686951245254		[learning rate: 0.0016285]
	Learning Rate: 0.00162851
	LOSS [training: 0.4181686951245254 | validation: 0.39872067553044643]
	TIME [epoch: 9.74 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35955269329672257		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.35955269329672257 | validation: 0.28742270997652203]
	TIME [epoch: 9.74 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3125880143466012		[learning rate: 0.0016206]
	Learning Rate: 0.00162063
	LOSS [training: 0.3125880143466012 | validation: 0.2781808147707002]
	TIME [epoch: 9.73 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27123484993635083		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.27123484993635083 | validation: 0.25539045237105457]
	TIME [epoch: 9.75 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2651540234354278		[learning rate: 0.0016128]
	Learning Rate: 0.00161279
	LOSS [training: 0.2651540234354278 | validation: 0.24759061841087668]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_853.pth
	Model improved!!!
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2570576560148211		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.2570576560148211 | validation: 0.2701275909080043]
	TIME [epoch: 9.75 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27446104952550004		[learning rate: 0.001605]
	Learning Rate: 0.001605
	LOSS [training: 0.27446104952550004 | validation: 0.2686119478314492]
	TIME [epoch: 9.75 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26518600916478874		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.26518600916478874 | validation: 0.25246320528103594]
	TIME [epoch: 9.77 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2723879612093354		[learning rate: 0.0015972]
	Learning Rate: 0.00159723
	LOSS [training: 0.2723879612093354 | validation: 0.26167591420081815]
	TIME [epoch: 9.75 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27980453171691316		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.27980453171691316 | validation: 0.29972287053781205]
	TIME [epoch: 9.74 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31414432042801366		[learning rate: 0.0015895]
	Learning Rate: 0.00158951
	LOSS [training: 0.31414432042801366 | validation: 0.29219840094060057]
	TIME [epoch: 9.75 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3213445356075248		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.3213445356075248 | validation: 0.317137188877707]
	TIME [epoch: 9.74 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37540794394275717		[learning rate: 0.0015818]
	Learning Rate: 0.00158182
	LOSS [training: 0.37540794394275717 | validation: 0.3982371337568671]
	TIME [epoch: 9.74 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38394636541667737		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.38394636541667737 | validation: 0.3534525993361312]
	TIME [epoch: 9.74 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36104357542661614		[learning rate: 0.0015742]
	Learning Rate: 0.00157417
	LOSS [training: 0.36104357542661614 | validation: 0.295074603377307]
	TIME [epoch: 9.76 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3403312922571999		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.3403312922571999 | validation: 0.3480385945259324]
	TIME [epoch: 9.76 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3732411650709286		[learning rate: 0.0015666]
	Learning Rate: 0.00156656
	LOSS [training: 0.3732411650709286 | validation: 0.39171394904900714]
	TIME [epoch: 9.76 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35802685667205464		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.35802685667205464 | validation: 0.29217964065876284]
	TIME [epoch: 9.77 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2947806180192732		[learning rate: 0.001559]
	Learning Rate: 0.00155899
	LOSS [training: 0.2947806180192732 | validation: 0.27836673693934505]
	TIME [epoch: 9.76 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2605489133296416		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.2605489133296416 | validation: 0.2578539479641934]
	TIME [epoch: 9.75 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27056811422284166		[learning rate: 0.0015514]
	Learning Rate: 0.00155145
	LOSS [training: 0.27056811422284166 | validation: 0.3315382086769847]
	TIME [epoch: 9.76 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2941031815548778		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.2941031815548778 | validation: 0.29389457461246354]
	TIME [epoch: 9.75 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27441505639059305		[learning rate: 0.0015439]
	Learning Rate: 0.00154394
	LOSS [training: 0.27441505639059305 | validation: 0.2606464233520003]
	TIME [epoch: 9.74 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.267622784277337		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.267622784277337 | validation: 0.25509880058706835]
	TIME [epoch: 9.75 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2763550595133409		[learning rate: 0.0015365]
	Learning Rate: 0.00153648
	LOSS [training: 0.2763550595133409 | validation: 0.31835482042987345]
	TIME [epoch: 9.77 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30689338099046365		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.30689338099046365 | validation: 0.30093863154507766]
	TIME [epoch: 9.74 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29318817556004884		[learning rate: 0.001529]
	Learning Rate: 0.00152905
	LOSS [training: 0.29318817556004884 | validation: 0.30893728583800395]
	TIME [epoch: 9.75 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30069791182082445		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.30069791182082445 | validation: 0.3144670944963036]
	TIME [epoch: 9.77 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30246855535773254		[learning rate: 0.0015217]
	Learning Rate: 0.00152165
	LOSS [training: 0.30246855535773254 | validation: 0.2454353870801205]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_877.pth
	Model improved!!!
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2540376514795469		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.2540376514795469 | validation: 0.2924281729758594]
	TIME [epoch: 9.74 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2690957700096951		[learning rate: 0.0015143]
	Learning Rate: 0.00151429
	LOSS [training: 0.2690957700096951 | validation: 0.25804257167954786]
	TIME [epoch: 9.77 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29340650571322485		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.29340650571322485 | validation: 0.25332043110804214]
	TIME [epoch: 9.75 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2848171452423782		[learning rate: 0.001507]
	Learning Rate: 0.00150697
	LOSS [training: 0.2848171452423782 | validation: 0.29660860531932304]
	TIME [epoch: 9.75 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3106280492600876		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.3106280492600876 | validation: 0.27691298361419797]
	TIME [epoch: 9.77 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3010327594223455		[learning rate: 0.0014997]
	Learning Rate: 0.00149968
	LOSS [training: 0.3010327594223455 | validation: 0.2590627430203361]
	TIME [epoch: 9.74 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26744563901247115		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.26744563901247115 | validation: 0.25701383278762374]
	TIME [epoch: 9.75 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2739267271462097		[learning rate: 0.0014924]
	Learning Rate: 0.00149243
	LOSS [training: 0.2739267271462097 | validation: 0.277517518668786]
	TIME [epoch: 9.75 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.286168442686253		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.286168442686253 | validation: 0.2810251975811414]
	TIME [epoch: 9.75 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27232536471881275		[learning rate: 0.0014852]
	Learning Rate: 0.00148522
	LOSS [training: 0.27232536471881275 | validation: 0.2731653220524553]
	TIME [epoch: 9.74 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28024692316713745		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.28024692316713745 | validation: 0.2810592902454745]
	TIME [epoch: 9.74 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26074874815485005		[learning rate: 0.001478]
	Learning Rate: 0.00147803
	LOSS [training: 0.26074874815485005 | validation: 0.26711863091248406]
	TIME [epoch: 9.76 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2537226663220669		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.2537226663220669 | validation: 0.24651245309420222]
	TIME [epoch: 9.75 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25968021748057213		[learning rate: 0.0014709]
	Learning Rate: 0.00147089
	LOSS [training: 0.25968021748057213 | validation: 0.28095096546589376]
	TIME [epoch: 9.74 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2801957397001863		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.2801957397001863 | validation: 0.24022957362230707]
	TIME [epoch: 9.77 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_892.pth
	Model improved!!!
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27150761924355615		[learning rate: 0.0014638]
	Learning Rate: 0.00146377
	LOSS [training: 0.27150761924355615 | validation: 0.2587315251824145]
	TIME [epoch: 9.75 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2743338664171646		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.2743338664171646 | validation: 0.29004019036531664]
	TIME [epoch: 9.75 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2925012767715449		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.2925012767715449 | validation: 0.3061495373651358]
	TIME [epoch: 9.77 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2816910996691678		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.2816910996691678 | validation: 0.3304727967468027]
	TIME [epoch: 9.75 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33190632240378		[learning rate: 0.0014497]
	Learning Rate: 0.00144965
	LOSS [training: 0.33190632240378 | validation: 0.3587698762186464]
	TIME [epoch: 9.75 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3261918738465145		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.3261918738465145 | validation: 0.3157827683214845]
	TIME [epoch: 9.76 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32501292733939435		[learning rate: 0.0014426]
	Learning Rate: 0.00144264
	LOSS [training: 0.32501292733939435 | validation: 0.352195215190459]
	TIME [epoch: 9.77 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3283281870516963		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.3283281870516963 | validation: 0.31912009069498937]
	TIME [epoch: 9.75 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.294223731596559		[learning rate: 0.0014357]
	Learning Rate: 0.00143566
	LOSS [training: 0.294223731596559 | validation: 0.24420351807950155]
	TIME [epoch: 9.78 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27622467068122747		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.27622467068122747 | validation: 0.3213552364097076]
	TIME [epoch: 9.77 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37819630823100525		[learning rate: 0.0014287]
	Learning Rate: 0.00142872
	LOSS [training: 0.37819630823100525 | validation: 0.3665788081030528]
	TIME [epoch: 9.75 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3236330241094522		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.3236330241094522 | validation: 0.31622475610340983]
	TIME [epoch: 9.75 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32913675489328514		[learning rate: 0.0014218]
	Learning Rate: 0.00142181
	LOSS [training: 0.32913675489328514 | validation: 0.3629733519487311]
	TIME [epoch: 9.78 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3460961643296553		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.3460961643296553 | validation: 0.5115477667874362]
	TIME [epoch: 9.76 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4823687437512284		[learning rate: 0.0014149]
	Learning Rate: 0.00141494
	LOSS [training: 0.4823687437512284 | validation: 0.4530268345148227]
	TIME [epoch: 9.74 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40870057702138085		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.40870057702138085 | validation: 0.36336026467311505]
	TIME [epoch: 9.77 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35646369079467183		[learning rate: 0.0014081]
	Learning Rate: 0.00140809
	LOSS [training: 0.35646369079467183 | validation: 0.32138421296410885]
	TIME [epoch: 9.75 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156619883205957		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.3156619883205957 | validation: 0.31277482312099153]
	TIME [epoch: 9.75 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32027941643948143		[learning rate: 0.0014013]
	Learning Rate: 0.00140128
	LOSS [training: 0.32027941643948143 | validation: 0.32646352147336816]
	TIME [epoch: 9.76 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31624678228089365		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.31624678228089365 | validation: 0.292564758691626]
	TIME [epoch: 9.74 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30060877825968857		[learning rate: 0.0013945]
	Learning Rate: 0.00139451
	LOSS [training: 0.30060877825968857 | validation: 0.30734545628587595]
	TIME [epoch: 9.76 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.285566621926485		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.285566621926485 | validation: 0.30909409019825457]
	TIME [epoch: 9.75 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3516788238825244		[learning rate: 0.0013878]
	Learning Rate: 0.00138776
	LOSS [training: 0.3516788238825244 | validation: 0.2892454096729474]
	TIME [epoch: 9.78 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.305954778370775		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.305954778370775 | validation: 0.2682619138096164]
	TIME [epoch: 9.73 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28268948021141227		[learning rate: 0.0013811]
	Learning Rate: 0.00138105
	LOSS [training: 0.28268948021141227 | validation: 0.2760769358840053]
	TIME [epoch: 9.75 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2820266147790344		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.2820266147790344 | validation: 0.2643586766722894]
	TIME [epoch: 9.77 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2643878899343789		[learning rate: 0.0013744]
	Learning Rate: 0.00137437
	LOSS [training: 0.2643878899343789 | validation: 0.2654530573084289]
	TIME [epoch: 9.76 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2717743311506		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.2717743311506 | validation: 0.28448940902204667]
	TIME [epoch: 9.76 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28954012992475425		[learning rate: 0.0013677]
	Learning Rate: 0.00136773
	LOSS [training: 0.28954012992475425 | validation: 0.27431819373592553]
	TIME [epoch: 9.78 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2869350922299704		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.2869350922299704 | validation: 0.260661666869925]
	TIME [epoch: 9.76 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26707965217537044		[learning rate: 0.0013611]
	Learning Rate: 0.00136111
	LOSS [training: 0.26707965217537044 | validation: 0.27864026619833754]
	TIME [epoch: 9.75 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28119490612275116		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.28119490612275116 | validation: 0.28703438262843894]
	TIME [epoch: 9.77 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2780307085926542		[learning rate: 0.0013545]
	Learning Rate: 0.00135453
	LOSS [training: 0.2780307085926542 | validation: 0.26384578427266775]
	TIME [epoch: 9.76 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3241042341540763		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.3241042341540763 | validation: 0.3316647329467417]
	TIME [epoch: 9.75 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38083869993534997		[learning rate: 0.001348]
	Learning Rate: 0.00134798
	LOSS [training: 0.38083869993534997 | validation: 0.38324721202271883]
	TIME [epoch: 9.76 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38860266428811174		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.38860266428811174 | validation: 0.37258360739971763]
	TIME [epoch: 9.76 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4242246743894258		[learning rate: 0.0013415]
	Learning Rate: 0.00134146
	LOSS [training: 0.4242246743894258 | validation: 0.37403383953907665]
	TIME [epoch: 9.74 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4246738863333065		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.4246738863333065 | validation: 0.35002308558287154]
	TIME [epoch: 9.76 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3590699002838392		[learning rate: 0.001335]
	Learning Rate: 0.00133498
	LOSS [training: 0.3590699002838392 | validation: 0.34921975280119627]
	TIME [epoch: 9.77 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4128574195430422		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.4128574195430422 | validation: 0.39097561119318097]
	TIME [epoch: 9.75 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36147533171392926		[learning rate: 0.0013285]
	Learning Rate: 0.00132852
	LOSS [training: 0.36147533171392926 | validation: 0.30344931189393337]
	TIME [epoch: 9.75 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33032545549515746		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.33032545549515746 | validation: 0.32061577004565356]
	TIME [epoch: 9.77 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3770082536565642		[learning rate: 0.0013221]
	Learning Rate: 0.0013221
	LOSS [training: 0.3770082536565642 | validation: 0.3163772533277034]
	TIME [epoch: 9.75 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32906784557321833		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.32906784557321833 | validation: 0.3065321767661799]
	TIME [epoch: 9.75 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3186943898906595		[learning rate: 0.0013157]
	Learning Rate: 0.0013157
	LOSS [training: 0.3186943898906595 | validation: 0.362440835200222]
	TIME [epoch: 9.76 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3244588031167463		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.3244588031167463 | validation: 0.34113361862457636]
	TIME [epoch: 9.76 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31874590488557003		[learning rate: 0.0013093]
	Learning Rate: 0.00130934
	LOSS [training: 0.31874590488557003 | validation: 0.30680241450281737]
	TIME [epoch: 9.75 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3027843589163805		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.3027843589163805 | validation: 0.3031022624186065]
	TIME [epoch: 9.76 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30641681190161546		[learning rate: 0.001303]
	Learning Rate: 0.00130301
	LOSS [training: 0.30641681190161546 | validation: 0.34558471693285014]
	TIME [epoch: 9.75 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3201847392214522		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.3201847392214522 | validation: 0.2801701862125384]
	TIME [epoch: 9.75 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3248605802953405		[learning rate: 0.0012967]
	Learning Rate: 0.00129671
	LOSS [training: 0.3248605802953405 | validation: 0.3410781066800766]
	TIME [epoch: 9.75 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33129613353056747		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.33129613353056747 | validation: 0.326152706479832]
	TIME [epoch: 9.76 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3199714673185269		[learning rate: 0.0012904]
	Learning Rate: 0.00129044
	LOSS [training: 0.3199714673185269 | validation: 0.2931352172568702]
	TIME [epoch: 9.75 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3102091437468535		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.3102091437468535 | validation: 0.3103617527504763]
	TIME [epoch: 9.74 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40714741030345536		[learning rate: 0.0012842]
	Learning Rate: 0.0012842
	LOSS [training: 0.40714741030345536 | validation: 0.42844272250787463]
	TIME [epoch: 9.77 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4963534082027885		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.4963534082027885 | validation: 0.4652563707432993]
	TIME [epoch: 9.75 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5130770599622749		[learning rate: 0.001278]
	Learning Rate: 0.00127799
	LOSS [training: 0.5130770599622749 | validation: 0.5392947349458475]
	TIME [epoch: 9.75 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5968991724184219		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.5968991724184219 | validation: 0.524208962135949]
	TIME [epoch: 9.76 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5840598565478123		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.5840598565478123 | validation: 0.4325283724305189]
	TIME [epoch: 9.76 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39756011050841905		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.39756011050841905 | validation: 0.34645026142077845]
	TIME [epoch: 9.76 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3539187806123619		[learning rate: 0.0012657]
	Learning Rate: 0.00126566
	LOSS [training: 0.3539187806123619 | validation: 0.3346512447209561]
	TIME [epoch: 9.76 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4573703145171139		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.4573703145171139 | validation: 0.5295483281905959]
	TIME [epoch: 9.77 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5244997428157234		[learning rate: 0.0012595]
	Learning Rate: 0.00125954
	LOSS [training: 0.5244997428157234 | validation: 0.38410075170421776]
	TIME [epoch: 9.75 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3876316280234152		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.3876316280234152 | validation: 0.33403709458326064]
	TIME [epoch: 9.76 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42425650204473975		[learning rate: 0.0012534]
	Learning Rate: 0.00125344
	LOSS [training: 0.42425650204473975 | validation: 0.4809597174309005]
	TIME [epoch: 9.77 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6469335576766027		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.6469335576766027 | validation: 0.5054232002249734]
	TIME [epoch: 9.75 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6218769181627025		[learning rate: 0.0012474]
	Learning Rate: 0.00124738
	LOSS [training: 0.6218769181627025 | validation: 0.609145863701776]
	TIME [epoch: 9.74 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5784078158166432		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.5784078158166432 | validation: 0.4060551286364252]
	TIME [epoch: 9.77 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36698832553575744		[learning rate: 0.0012414]
	Learning Rate: 0.00124135
	LOSS [training: 0.36698832553575744 | validation: 0.3022076616664965]
	TIME [epoch: 9.73 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.337946656045726		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.337946656045726 | validation: 0.34889825400935254]
	TIME [epoch: 9.75 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3743374815706361		[learning rate: 0.0012353]
	Learning Rate: 0.00123535
	LOSS [training: 0.3743374815706361 | validation: 0.30616136742842254]
	TIME [epoch: 9.77 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3024493404422038		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.3024493404422038 | validation: 0.272849306650128]
	TIME [epoch: 9.75 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2790277250013008		[learning rate: 0.0012294]
	Learning Rate: 0.00122937
	LOSS [training: 0.2790277250013008 | validation: 0.28647636096223145]
	TIME [epoch: 9.75 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3063116903422651		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.3063116903422651 | validation: 0.300049621932087]
	TIME [epoch: 9.75 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3010074766460757		[learning rate: 0.0012234]
	Learning Rate: 0.00122343
	LOSS [training: 0.3010074766460757 | validation: 0.3019836269472891]
	TIME [epoch: 9.76 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34087702807887055		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.34087702807887055 | validation: 0.34712271899387775]
	TIME [epoch: 9.77 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3673891865071221		[learning rate: 0.0012175]
	Learning Rate: 0.00121751
	LOSS [training: 0.3673891865071221 | validation: 0.3531980054985314]
	TIME [epoch: 9.74 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4038396424309031		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.4038396424309031 | validation: 0.39690878900153004]
	TIME [epoch: 9.77 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4043129002348003		[learning rate: 0.0012116]
	Learning Rate: 0.00121163
	LOSS [training: 0.4043129002348003 | validation: 0.3548770952804398]
	TIME [epoch: 9.74 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3764318801207616		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.3764318801207616 | validation: 0.3215644967044497]
	TIME [epoch: 9.74 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3872165087765222		[learning rate: 0.0012058]
	Learning Rate: 0.00120577
	LOSS [training: 0.3872165087765222 | validation: 0.36665228143727363]
	TIME [epoch: 9.76 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36600829666116075		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.36600829666116075 | validation: 0.3463019834456608]
	TIME [epoch: 9.74 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3686593211470175		[learning rate: 0.0011999]
	Learning Rate: 0.00119994
	LOSS [training: 0.3686593211470175 | validation: 0.33258011259991016]
	TIME [epoch: 9.74 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32856617036690855		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.32856617036690855 | validation: 0.3156501160805792]
	TIME [epoch: 9.75 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2972746549363378		[learning rate: 0.0011941]
	Learning Rate: 0.00119413
	LOSS [training: 0.2972746549363378 | validation: 0.2865054363878825]
	TIME [epoch: 9.75 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2849221778277096		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.2849221778277096 | validation: 0.25628128725513327]
	TIME [epoch: 9.75 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2725785949117981		[learning rate: 0.0011884]
	Learning Rate: 0.00118836
	LOSS [training: 0.2725785949117981 | validation: 0.2889276657239489]
	TIME [epoch: 9.75 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27485217108684057		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.27485217108684057 | validation: 0.2829274873998214]
	TIME [epoch: 9.76 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2869464844251369		[learning rate: 0.0011826]
	Learning Rate: 0.00118261
	LOSS [training: 0.2869464844251369 | validation: 0.24947107349319111]
	TIME [epoch: 9.75 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.265942788036967		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.265942788036967 | validation: 0.26055666735814087]
	TIME [epoch: 9.74 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30778539610443145		[learning rate: 0.0011769]
	Learning Rate: 0.00117689
	LOSS [training: 0.30778539610443145 | validation: 0.2852916909579261]
	TIME [epoch: 9.76 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29590540364678447		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.29590540364678447 | validation: 0.3046200429659283]
	TIME [epoch: 9.74 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2900605889247861		[learning rate: 0.0011712]
	Learning Rate: 0.0011712
	LOSS [training: 0.2900605889247861 | validation: 0.28763765680082926]
	TIME [epoch: 9.73 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2876341686742322		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.2876341686742322 | validation: 0.28021073218395515]
	TIME [epoch: 9.76 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28296764158655324		[learning rate: 0.0011655]
	Learning Rate: 0.00116554
	LOSS [training: 0.28296764158655324 | validation: 0.26525217686798563]
	TIME [epoch: 9.74 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2625707889126616		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.2625707889126616 | validation: 0.2594544945404706]
	TIME [epoch: 9.74 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.269585909172205		[learning rate: 0.0011599]
	Learning Rate: 0.0011599
	LOSS [training: 0.269585909172205 | validation: 0.26633673123708657]
	TIME [epoch: 9.77 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26426966923243145		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.26426966923243145 | validation: 0.2605549720807104]
	TIME [epoch: 9.76 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26184992242408595		[learning rate: 0.0011543]
	Learning Rate: 0.00115429
	LOSS [training: 0.26184992242408595 | validation: 0.27233676001475376]
	TIME [epoch: 9.76 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26371000078673074		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.26371000078673074 | validation: 0.2737065315197926]
	TIME [epoch: 9.75 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2617008002638346		[learning rate: 0.0011487]
	Learning Rate: 0.00114871
	LOSS [training: 0.2617008002638346 | validation: 0.2727751917558358]
	TIME [epoch: 9.74 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2770534301462316		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.2770534301462316 | validation: 0.3112081676609831]
	TIME [epoch: 9.75 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2798576468398832		[learning rate: 0.0011432]
	Learning Rate: 0.00114316
	LOSS [training: 0.2798576468398832 | validation: 0.2686807722976781]
	TIME [epoch: 9.74 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2767701518934518		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.2767701518934518 | validation: 0.2677317877937146]
	TIME [epoch: 9.77 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2692587443639072		[learning rate: 0.0011376]
	Learning Rate: 0.00113763
	LOSS [training: 0.2692587443639072 | validation: 0.2659894813483793]
	TIME [epoch: 9.74 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29091958286659675		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.29091958286659675 | validation: 0.3027257883350529]
	TIME [epoch: 9.75 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31160917009498423		[learning rate: 0.0011321]
	Learning Rate: 0.00113213
	LOSS [training: 0.31160917009498423 | validation: 0.3324470460392297]
	TIME [epoch: 9.76 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3235620631091298		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.3235620631091298 | validation: 0.302964677643045]
	TIME [epoch: 9.73 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2914915482473175		[learning rate: 0.0011267]
	Learning Rate: 0.00112665
	LOSS [training: 0.2914915482473175 | validation: 0.2917158352363067]
	TIME [epoch: 9.74 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28343042994306666		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.28343042994306666 | validation: 0.2679222674017698]
	TIME [epoch: 9.76 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2781765841214877		[learning rate: 0.0011212]
	Learning Rate: 0.0011212
	LOSS [training: 0.2781765841214877 | validation: 0.2767538253933185]
	TIME [epoch: 9.76 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26822347686701076		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.26822347686701076 | validation: 0.2682678123946466]
	TIME [epoch: 9.73 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26612241678269033		[learning rate: 0.0011158]
	Learning Rate: 0.00111578
	LOSS [training: 0.26612241678269033 | validation: 0.2569555461122357]
	TIME [epoch: 9.76 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2877869701675036		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.2877869701675036 | validation: 0.27686501762658794]
	TIME [epoch: 9.76 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29398348721277767		[learning rate: 0.0011104]
	Learning Rate: 0.00111039
	LOSS [training: 0.29398348721277767 | validation: 0.24822056503375173]
	TIME [epoch: 9.74 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.279361561276796		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.279361561276796 | validation: 0.30090494836455256]
	TIME [epoch: 9.74 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29474689617328853		[learning rate: 0.001105]
	Learning Rate: 0.00110502
	LOSS [training: 0.29474689617328853 | validation: 0.2842151058366284]
	TIME [epoch: 9.77 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2849188419152669		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.2849188419152669 | validation: 0.30924843209357006]
	TIME [epoch: 9.75 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3403704686530863		[learning rate: 0.0010997]
	Learning Rate: 0.00109967
	LOSS [training: 0.3403704686530863 | validation: 0.34987917334847524]
	TIME [epoch: 9.74 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33299625322240917		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.33299625322240917 | validation: 0.2824939154472372]
	TIME [epoch: 9.76 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28410752878172485		[learning rate: 0.0010944]
	Learning Rate: 0.00109435
	LOSS [training: 0.28410752878172485 | validation: 0.2891121020848999]
	TIME [epoch: 9.75 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2913056918060031		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.2913056918060031 | validation: 0.29064951444631165]
	TIME [epoch: 9.75 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29440200805699873		[learning rate: 0.0010891]
	Learning Rate: 0.00108906
	LOSS [training: 0.29440200805699873 | validation: 0.3141186099571084]
	TIME [epoch: 9.77 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3109289425114775		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.3109289425114775 | validation: 0.3328579944925819]
	TIME [epoch: 9.75 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29429309048035934		[learning rate: 0.0010838]
	Learning Rate: 0.0010838
	LOSS [training: 0.29429309048035934 | validation: 0.3244178235017358]
	TIME [epoch: 9.75 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3195313281464743		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.3195313281464743 | validation: 0.3527498826368889]
	TIME [epoch: 9.75 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38096249166664453		[learning rate: 0.0010786]
	Learning Rate: 0.00107855
	LOSS [training: 0.38096249166664453 | validation: 0.41130720701217]
	TIME [epoch: 9.76 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3767581908014125		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.3767581908014125 | validation: 0.3119927427407386]
	TIME [epoch: 9.75 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3252046027587542		[learning rate: 0.0010733]
	Learning Rate: 0.00107334
	LOSS [training: 0.3252046027587542 | validation: 0.33716803443598026]
	TIME [epoch: 9.75 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3442658467153847		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.3442658467153847 | validation: 0.39027687413988593]
	TIME [epoch: 9.76 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3496084289514019		[learning rate: 0.0010681]
	Learning Rate: 0.00106815
	LOSS [training: 0.3496084289514019 | validation: 0.3898142850084611]
	TIME [epoch: 9.75 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3528728026153597		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.3528728026153597 | validation: 0.37549458279213754]
	TIME [epoch: 9.74 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33529979931933923		[learning rate: 0.001063]
	Learning Rate: 0.00106298
	LOSS [training: 0.33529979931933923 | validation: 0.3197542428913515]
	TIME [epoch: 9.76 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3001769674202845		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.3001769674202845 | validation: 0.3318745457166423]
	TIME [epoch: 9.75 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30847762953379776		[learning rate: 0.0010578]
	Learning Rate: 0.00105784
	LOSS [training: 0.30847762953379776 | validation: 0.29761970852137287]
	TIME [epoch: 9.74 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29788389494492207		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.29788389494492207 | validation: 0.3111554132020278]
	TIME [epoch: 9.75 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27810653550989695		[learning rate: 0.0010527]
	Learning Rate: 0.00105273
	LOSS [training: 0.27810653550989695 | validation: 0.2561015833156021]
	TIME [epoch: 9.76 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2706930383683805		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.2706930383683805 | validation: 0.2816758185102399]
	TIME [epoch: 9.75 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2651103399889717		[learning rate: 0.0010476]
	Learning Rate: 0.00104764
	LOSS [training: 0.2651103399889717 | validation: 0.2781504432031335]
	TIME [epoch: 9.77 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27601221748883714		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.27601221748883714 | validation: 0.3053722455183966]
	TIME [epoch: 9.77 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29748821030626604		[learning rate: 0.0010426]
	Learning Rate: 0.00104257
	LOSS [training: 0.29748821030626604 | validation: 0.2973000699874649]
	TIME [epoch: 9.74 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2818550706786101		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.2818550706786101 | validation: 0.2767894762851658]
	TIME [epoch: 9.74 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2753552212559515		[learning rate: 0.0010375]
	Learning Rate: 0.00103753
	LOSS [training: 0.2753552212559515 | validation: 0.279167534659697]
	TIME [epoch: 9.76 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27547822032287966		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.27547822032287966 | validation: 0.27732258316367664]
	TIME [epoch: 9.73 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.286431544524286		[learning rate: 0.0010325]
	Learning Rate: 0.00103251
	LOSS [training: 0.286431544524286 | validation: 0.2690335910992011]
	TIME [epoch: 9.74 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2740387033709032		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.2740387033709032 | validation: 0.2556566694990087]
	TIME [epoch: 9.76 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28189128688806453		[learning rate: 0.0010275]
	Learning Rate: 0.00102752
	LOSS [training: 0.28189128688806453 | validation: 0.2795195998516957]
	TIME [epoch: 9.73 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2850264602107805		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.2850264602107805 | validation: 0.2613252980626519]
	TIME [epoch: 9.74 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28594368784674895		[learning rate: 0.0010225]
	Learning Rate: 0.00102255
	LOSS [training: 0.28594368784674895 | validation: 0.2776771004037903]
	TIME [epoch: 9.75 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2803000868861928		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.2803000868861928 | validation: 0.31655334047397754]
	TIME [epoch: 9.74 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3026964911810703		[learning rate: 0.0010176]
	Learning Rate: 0.0010176
	LOSS [training: 0.3026964911810703 | validation: 0.299957186902365]
	TIME [epoch: 9.74 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3079973738348758		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.3079973738348758 | validation: 0.29531662730110003]
	TIME [epoch: 9.77 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3109630960206576		[learning rate: 0.0010127]
	Learning Rate: 0.00101268
	LOSS [training: 0.3109630960206576 | validation: 0.2954682357175949]
	TIME [epoch: 9.75 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3048107270172117		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.3048107270172117 | validation: 0.2919927634756063]
	TIME [epoch: 9.75 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.281855171251664		[learning rate: 0.0010078]
	Learning Rate: 0.00100779
	LOSS [training: 0.281855171251664 | validation: 0.2930445912144379]
	TIME [epoch: 9.75 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29692264479423186		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.29692264479423186 | validation: 0.3069545315890167]
	TIME [epoch: 9.77 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3062087155484594		[learning rate: 0.0010029]
	Learning Rate: 0.00100291
	LOSS [training: 0.3062087155484594 | validation: 0.2783824232067222]
	TIME [epoch: 9.75 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30026168924656804		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.30026168924656804 | validation: 0.2842080360060083]
	TIME [epoch: 9.75 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2839091337571288		[learning rate: 0.00099806]
	Learning Rate: 0.000998063
	LOSS [training: 0.2839091337571288 | validation: 0.269929441569753]
	TIME [epoch: 9.76 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28083411589333246		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.28083411589333246 | validation: 0.280192507663582]
	TIME [epoch: 9.74 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27962353705103804		[learning rate: 0.00099324]
	Learning Rate: 0.000993237
	LOSS [training: 0.27962353705103804 | validation: 0.2639801519664854]
	TIME [epoch: 9.73 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2780375615933086		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.2780375615933086 | validation: 0.26266761624469054]
	TIME [epoch: 9.76 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26406227236982327		[learning rate: 0.00098843]
	Learning Rate: 0.000988433
	LOSS [training: 0.26406227236982327 | validation: 0.2718959862959888]
	TIME [epoch: 9.75 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2536406148420117		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.2536406148420117 | validation: 0.2935249975890682]
	TIME [epoch: 9.74 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28852767566275794		[learning rate: 0.00098365]
	Learning Rate: 0.000983653
	LOSS [training: 0.28852767566275794 | validation: 0.29200274753195044]
	TIME [epoch: 9.77 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2737427952955757		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.2737427952955757 | validation: 0.27330064978258894]
	TIME [epoch: 9.75 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25861265580915616		[learning rate: 0.0009789]
	Learning Rate: 0.000978897
	LOSS [training: 0.25861265580915616 | validation: 0.2644764355571753]
	TIME [epoch: 9.74 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26504817340407216		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.26504817340407216 | validation: 0.3068671045743829]
	TIME [epoch: 9.75 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30294785012006653		[learning rate: 0.00097416]
	Learning Rate: 0.000974163
	LOSS [training: 0.30294785012006653 | validation: 0.31209976121714744]
	TIME [epoch: 9.76 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28805001216689385		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.28805001216689385 | validation: 0.2618906516064815]
	TIME [epoch: 9.74 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27403679770257405		[learning rate: 0.00096945]
	Learning Rate: 0.000969452
	LOSS [training: 0.27403679770257405 | validation: 0.29628533300169346]
	TIME [epoch: 9.74 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2721524057553756		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.2721524057553756 | validation: 0.2868360605279054]
	TIME [epoch: 9.77 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.266836001255608		[learning rate: 0.00096476]
	Learning Rate: 0.000964764
	LOSS [training: 0.266836001255608 | validation: 0.26926498648802094]
	TIME [epoch: 9.75 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26904186532758595		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.26904186532758595 | validation: 0.3141668082342399]
	TIME [epoch: 9.75 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30584083967471365		[learning rate: 0.0009601]
	Learning Rate: 0.000960098
	LOSS [training: 0.30584083967471365 | validation: 0.2632502533330676]
	TIME [epoch: 9.76 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26740823374363404		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.26740823374363404 | validation: 0.29391186133926706]
	TIME [epoch: 9.75 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27864572167775775		[learning rate: 0.00095546]
	Learning Rate: 0.000955456
	LOSS [training: 0.27864572167775775 | validation: 0.2642306647755828]
	TIME [epoch: 9.74 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27354232527381306		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.27354232527381306 | validation: 0.2657875793375388]
	TIME [epoch: 9.75 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2776096418612386		[learning rate: 0.00095084]
	Learning Rate: 0.000950835
	LOSS [training: 0.2776096418612386 | validation: 0.2736356011889196]
	TIME [epoch: 9.75 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2805794544926501		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.2805794544926501 | validation: 0.2749632842220093]
	TIME [epoch: 9.74 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.270798136075758		[learning rate: 0.00094624]
	Learning Rate: 0.000946237
	LOSS [training: 0.270798136075758 | validation: 0.2689396208050368]
	TIME [epoch: 9.74 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26374359238974704		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.26374359238974704 | validation: 0.27252794923192275]
	TIME [epoch: 9.76 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2965462782901314		[learning rate: 0.00094166]
	Learning Rate: 0.000941661
	LOSS [training: 0.2965462782901314 | validation: 0.2935474267254503]
	TIME [epoch: 9.74 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2928374834929114		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.2928374834929114 | validation: 0.3079097201065633]
	TIME [epoch: 9.76 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27919272780635435		[learning rate: 0.00093711]
	Learning Rate: 0.000937108
	LOSS [training: 0.27919272780635435 | validation: 0.28430790498688346]
	TIME [epoch: 9.78 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2955721384560298		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.2955721384560298 | validation: 0.31413532812138284]
	TIME [epoch: 9.74 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28600512641113596		[learning rate: 0.00093258]
	Learning Rate: 0.000932576
	LOSS [training: 0.28600512641113596 | validation: 0.28585540491605504]
	TIME [epoch: 9.75 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29445639619927144		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.29445639619927144 | validation: 0.29187917633514376]
	TIME [epoch: 9.77 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3182992970192414		[learning rate: 0.00092807]
	Learning Rate: 0.000928066
	LOSS [training: 0.3182992970192414 | validation: 0.324612415643898]
	TIME [epoch: 9.75 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3458389991710644		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.3458389991710644 | validation: 0.3221519676920294]
	TIME [epoch: 9.75 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31439038004063		[learning rate: 0.00092358]
	Learning Rate: 0.000923578
	LOSS [training: 0.31439038004063 | validation: 0.2799146413606118]
	TIME [epoch: 9.77 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3057237654891428		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.3057237654891428 | validation: 0.3123542736987162]
	TIME [epoch: 9.75 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3100949943759005		[learning rate: 0.00091911]
	Learning Rate: 0.000919112
	LOSS [training: 0.3100949943759005 | validation: 0.30484772741455135]
	TIME [epoch: 9.74 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29670405337827244		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.29670405337827244 | validation: 0.2849642886956687]
	TIME [epoch: 9.74 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3022489518931844		[learning rate: 0.00091467]
	Learning Rate: 0.000914667
	LOSS [training: 0.3022489518931844 | validation: 0.26956770379648143]
	TIME [epoch: 9.76 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3051794016668944		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.3051794016668944 | validation: 0.30762945791690444]
	TIME [epoch: 9.74 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29463579838645265		[learning rate: 0.00091024]
	Learning Rate: 0.000910244
	LOSS [training: 0.29463579838645265 | validation: 0.2828728684382097]
	TIME [epoch: 9.76 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2976498341032038		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.2976498341032038 | validation: 0.293423113129854]
	TIME [epoch: 9.77 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3056851117081127		[learning rate: 0.00090584]
	Learning Rate: 0.000905843
	LOSS [training: 0.3056851117081127 | validation: 0.28095007256445365]
	TIME [epoch: 9.75 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30040153796740915		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.30040153796740915 | validation: 0.32443165273978514]
	TIME [epoch: 9.74 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31255796153111215		[learning rate: 0.00090146]
	Learning Rate: 0.000901462
	LOSS [training: 0.31255796153111215 | validation: 0.31319927356707966]
	TIME [epoch: 9.75 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32270339238274054		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.32270339238274054 | validation: 0.3021697662379391]
	TIME [epoch: 9.74 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3344064397537942		[learning rate: 0.0008971]
	Learning Rate: 0.000897103
	LOSS [training: 0.3344064397537942 | validation: 0.3100365852076383]
	TIME [epoch: 9.74 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33239604047632504		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.33239604047632504 | validation: 0.3366743531844005]
	TIME [epoch: 9.76 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3264835983738615		[learning rate: 0.00089276]
	Learning Rate: 0.000892764
	LOSS [training: 0.3264835983738615 | validation: 0.32631679427856575]
	TIME [epoch: 9.75 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33539266698426845		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.33539266698426845 | validation: 0.30937121812823054]
	TIME [epoch: 9.75 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31423380898687164		[learning rate: 0.00088845]
	Learning Rate: 0.000888447
	LOSS [training: 0.31423380898687164 | validation: 0.3060145832198606]
	TIME [epoch: 9.75 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29496512194775254		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.29496512194775254 | validation: 0.27307321059953105]
	TIME [epoch: 9.77 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2833602542608675		[learning rate: 0.00088415]
	Learning Rate: 0.000884151
	LOSS [training: 0.2833602542608675 | validation: 0.2755042758531285]
	TIME [epoch: 9.74 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2881603473185212		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.2881603473185212 | validation: 0.2763913572915652]
	TIME [epoch: 9.75 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2673720976847499		[learning rate: 0.00087988]
	Learning Rate: 0.000879875
	LOSS [training: 0.2673720976847499 | validation: 0.27599527691858944]
	TIME [epoch: 9.77 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2647108740887554		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.2647108740887554 | validation: 0.303865276861076]
	TIME [epoch: 9.75 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2719539091290591		[learning rate: 0.00087562]
	Learning Rate: 0.00087562
	LOSS [training: 0.2719539091290591 | validation: 0.2759536516917145]
	TIME [epoch: 9.74 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2710962613953902		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.2710962613953902 | validation: 0.27743748332738843]
	TIME [epoch: 9.77 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2828652350158675		[learning rate: 0.00087139]
	Learning Rate: 0.000871386
	LOSS [training: 0.2828652350158675 | validation: 0.3062860358503454]
	TIME [epoch: 9.75 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3123782502747354		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.3123782502747354 | validation: 0.30418006733840564]
	TIME [epoch: 9.75 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3006592345140553		[learning rate: 0.00086717]
	Learning Rate: 0.000867172
	LOSS [training: 0.3006592345140553 | validation: 0.3158923951618651]
	TIME [epoch: 9.76 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3094137072262434		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.3094137072262434 | validation: 0.31641070683066164]
	TIME [epoch: 9.75 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32751810253534425		[learning rate: 0.00086298]
	Learning Rate: 0.000862979
	LOSS [training: 0.32751810253534425 | validation: 0.30279140631027607]
	TIME [epoch: 9.75 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31454612235318535		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.31454612235318535 | validation: 0.3051610201661202]
	TIME [epoch: 9.74 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2931600109248368		[learning rate: 0.00085881]
	Learning Rate: 0.000858805
	LOSS [training: 0.2931600109248368 | validation: 0.2971303508212028]
	TIME [epoch: 9.77 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3023487439059243		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.3023487439059243 | validation: 0.2955493697487197]
	TIME [epoch: 9.73 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3014119460559877		[learning rate: 0.00085465]
	Learning Rate: 0.000854652
	LOSS [training: 0.3014119460559877 | validation: 0.2906159095754324]
	TIME [epoch: 9.74 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29271026170563896		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.29271026170563896 | validation: 0.29683630159607677]
	TIME [epoch: 9.76 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.297102391139329		[learning rate: 0.00085052]
	Learning Rate: 0.000850519
	LOSS [training: 0.297102391139329 | validation: 0.3067401174606427]
	TIME [epoch: 9.76 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31586477933460916		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.31586477933460916 | validation: 0.3298422967117034]
	TIME [epoch: 9.75 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.292456960352097		[learning rate: 0.00084641]
	Learning Rate: 0.000846406
	LOSS [training: 0.292456960352097 | validation: 0.27476652923765577]
	TIME [epoch: 9.77 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2720453178202365		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.2720453178202365 | validation: 0.3044819329108644]
	TIME [epoch: 9.75 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2862789122323226		[learning rate: 0.00084231]
	Learning Rate: 0.000842313
	LOSS [training: 0.2862789122323226 | validation: 0.2550011986574497]
	TIME [epoch: 9.75 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2718029003304169		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.2718029003304169 | validation: 0.27171969936010515]
	TIME [epoch: 9.76 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2687472465085343		[learning rate: 0.00083824]
	Learning Rate: 0.00083824
	LOSS [training: 0.2687472465085343 | validation: 0.2618968305398975]
	TIME [epoch: 9.75 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26189018280670545		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.26189018280670545 | validation: 0.26732182182926845]
	TIME [epoch: 9.74 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2579561084223509		[learning rate: 0.00083419]
	Learning Rate: 0.000834187
	LOSS [training: 0.2579561084223509 | validation: 0.27760803119421884]
	TIME [epoch: 9.74 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2833392162240222		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.2833392162240222 | validation: 0.3009829196807316]
	TIME [epoch: 9.76 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28789280453450716		[learning rate: 0.00083015]
	Learning Rate: 0.000830152
	LOSS [training: 0.28789280453450716 | validation: 0.31206253026444125]
	TIME [epoch: 9.74 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2746168664149984		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.2746168664149984 | validation: 0.25466773538032944]
	TIME [epoch: 9.74 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26979976519758797		[learning rate: 0.00082614]
	Learning Rate: 0.000826138
	LOSS [training: 0.26979976519758797 | validation: 0.2842736262076667]
	TIME [epoch: 9.78 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2618808276267128		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.2618808276267128 | validation: 0.2597589768416288]
	TIME [epoch: 9.75 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2609745991351343		[learning rate: 0.00082214]
	Learning Rate: 0.000822143
	LOSS [training: 0.2609745991351343 | validation: 0.2583933635010514]
	TIME [epoch: 9.74 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2752055164783678		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.2752055164783678 | validation: 0.29948187492581185]
	TIME [epoch: 9.77 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26706440910144563		[learning rate: 0.00081817]
	Learning Rate: 0.000818167
	LOSS [training: 0.26706440910144563 | validation: 0.2528468327212201]
	TIME [epoch: 9.75 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25176134412492734		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.25176134412492734 | validation: 0.24440785883005106]
	TIME [epoch: 9.74 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2473972059274921		[learning rate: 0.00081421]
	Learning Rate: 0.000814211
	LOSS [training: 0.2473972059274921 | validation: 0.24816310561760993]
	TIME [epoch: 9.76 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2759901200623414		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.2759901200623414 | validation: 0.30401914210072983]
	TIME [epoch: 9.75 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27206116936387537		[learning rate: 0.00081027]
	Learning Rate: 0.000810273
	LOSS [training: 0.27206116936387537 | validation: 0.2749679219119215]
	TIME [epoch: 9.75 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2682180373572146		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.2682180373572146 | validation: 0.27815683870317015]
	TIME [epoch: 9.76 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2626040580579119		[learning rate: 0.00080636]
	Learning Rate: 0.000806355
	LOSS [training: 0.2626040580579119 | validation: 0.2480165207423273]
	TIME [epoch: 9.76 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25375355944484906		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.25375355944484906 | validation: 0.24719676743665833]
	TIME [epoch: 9.75 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25696364027386276		[learning rate: 0.00080246]
	Learning Rate: 0.000802456
	LOSS [training: 0.25696364027386276 | validation: 0.244153365311688]
	TIME [epoch: 9.74 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24940867027431826		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.24940867027431826 | validation: 0.2618933300007908]
	TIME [epoch: 9.76 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2571904328206856		[learning rate: 0.00079858]
	Learning Rate: 0.000798575
	LOSS [training: 0.2571904328206856 | validation: 0.22799412820480192]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1143.pth
	Model improved!!!
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24975153283148002		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.24975153283148002 | validation: 0.23202386834842917]
	TIME [epoch: 9.74 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25763042472013936		[learning rate: 0.00079471]
	Learning Rate: 0.000794713
	LOSS [training: 0.25763042472013936 | validation: 0.24458699636277564]
	TIME [epoch: 9.75 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2527100022660019		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.2527100022660019 | validation: 0.2676747506435002]
	TIME [epoch: 9.74 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25469737849888385		[learning rate: 0.00079087]
	Learning Rate: 0.00079087
	LOSS [training: 0.25469737849888385 | validation: 0.23053399190123208]
	TIME [epoch: 9.74 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26513870651841465		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.26513870651841465 | validation: 0.2459832208546224]
	TIME [epoch: 9.76 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26082480710536077		[learning rate: 0.00078705]
	Learning Rate: 0.000787046
	LOSS [training: 0.26082480710536077 | validation: 0.26666439624357596]
	TIME [epoch: 9.73 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2543507819276586		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.2543507819276586 | validation: 0.24948502738446585]
	TIME [epoch: 9.74 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24731009513484986		[learning rate: 0.00078324]
	Learning Rate: 0.00078324
	LOSS [training: 0.24731009513484986 | validation: 0.2634672018667172]
	TIME [epoch: 9.75 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2667486298379388		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.2667486298379388 | validation: 0.26624397945538525]
	TIME [epoch: 9.75 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30340853039688537		[learning rate: 0.00077945]
	Learning Rate: 0.000779452
	LOSS [training: 0.30340853039688537 | validation: 0.28301603010783666]
	TIME [epoch: 9.74 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2995605905158774		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.2995605905158774 | validation: 0.28359520174035474]
	TIME [epoch: 9.74 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2944443225026415		[learning rate: 0.00077568]
	Learning Rate: 0.000775683
	LOSS [training: 0.2944443225026415 | validation: 0.2774980379872724]
	TIME [epoch: 9.77 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.288163755225104		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.288163755225104 | validation: 0.26887860674527686]
	TIME [epoch: 9.74 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29326662750959487		[learning rate: 0.00077193]
	Learning Rate: 0.000771932
	LOSS [training: 0.29326662750959487 | validation: 0.2682989683256778]
	TIME [epoch: 9.74 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32937658305812273		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.32937658305812273 | validation: 0.32026898080032945]
	TIME [epoch: 9.75 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3790997687110213		[learning rate: 0.0007682]
	Learning Rate: 0.000768199
	LOSS [training: 0.3790997687110213 | validation: 0.34397242671355244]
	TIME [epoch: 9.74 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35187449718148645		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.35187449718148645 | validation: 0.3179076772545951]
	TIME [epoch: 9.75 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.332656947231171		[learning rate: 0.00076448]
	Learning Rate: 0.000764484
	LOSS [training: 0.332656947231171 | validation: 0.2837444810781534]
	TIME [epoch: 9.76 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32215821537510425		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.32215821537510425 | validation: 0.30651604378231384]
	TIME [epoch: 9.75 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32246510602249795		[learning rate: 0.00076079]
	Learning Rate: 0.000760787
	LOSS [training: 0.32246510602249795 | validation: 0.2713730779775897]
	TIME [epoch: 9.74 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31046602412351765		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.31046602412351765 | validation: 0.31295770926853334]
	TIME [epoch: 9.75 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33662748466487324		[learning rate: 0.00075711]
	Learning Rate: 0.000757108
	LOSS [training: 0.33662748466487324 | validation: 0.33132143346271775]
	TIME [epoch: 9.75 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36848036302239157		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.36848036302239157 | validation: 0.33415472060434154]
	TIME [epoch: 9.74 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35759558242688716		[learning rate: 0.00075345]
	Learning Rate: 0.000753447
	LOSS [training: 0.35759558242688716 | validation: 0.3414186040114855]
	TIME [epoch: 9.74 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3707348574717034		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.3707348574717034 | validation: 0.3774693695758492]
	TIME [epoch: 9.75 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3818232483028366		[learning rate: 0.0007498]
	Learning Rate: 0.000749803
	LOSS [training: 0.3818232483028366 | validation: 0.35681619298938444]
	TIME [epoch: 9.73 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4258647282626945		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.4258647282626945 | validation: 0.38089139146500417]
	TIME [epoch: 9.75 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4020049665698096		[learning rate: 0.00074618]
	Learning Rate: 0.000746177
	LOSS [training: 0.4020049665698096 | validation: 0.3629650915769667]
	TIME [epoch: 9.76 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37522563215683513		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.37522563215683513 | validation: 0.3324475369866462]
	TIME [epoch: 9.75 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33056096375114197		[learning rate: 0.00074257]
	Learning Rate: 0.000742569
	LOSS [training: 0.33056096375114197 | validation: 0.28099109363493946]
	TIME [epoch: 9.74 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2915298530583564		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.2915298530583564 | validation: 0.26717889781227816]
	TIME [epoch: 9.76 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2736895743842049		[learning rate: 0.00073898]
	Learning Rate: 0.000738978
	LOSS [training: 0.2736895743842049 | validation: 0.2544393415301401]
	TIME [epoch: 9.75 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2637342517884126		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.2637342517884126 | validation: 0.28658650965596977]
	TIME [epoch: 9.73 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2807202962103813		[learning rate: 0.0007354]
	Learning Rate: 0.000735405
	LOSS [training: 0.2807202962103813 | validation: 0.2579119820007079]
	TIME [epoch: 9.74 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26430995510843996		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.26430995510843996 | validation: 0.2680819360766351]
	TIME [epoch: 9.75 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2733033439171153		[learning rate: 0.00073185]
	Learning Rate: 0.000731848
	LOSS [training: 0.2733033439171153 | validation: 0.2505306383201599]
	TIME [epoch: 9.73 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26533214355966733		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.26533214355966733 | validation: 0.26215131611642684]
	TIME [epoch: 9.74 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26236520919276723		[learning rate: 0.00072831]
	Learning Rate: 0.000728309
	LOSS [training: 0.26236520919276723 | validation: 0.2583440656471466]
	TIME [epoch: 9.76 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2937208556719476		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.2937208556719476 | validation: 0.3101671323397993]
	TIME [epoch: 9.75 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3073398918888402		[learning rate: 0.00072479]
	Learning Rate: 0.000724787
	LOSS [training: 0.3073398918888402 | validation: 0.2915125218163249]
	TIME [epoch: 9.73 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2825923651346699		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.2825923651346699 | validation: 0.2552220620772596]
	TIME [epoch: 9.74 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2619466753529129		[learning rate: 0.00072128]
	Learning Rate: 0.000721282
	LOSS [training: 0.2619466753529129 | validation: 0.2598925096022432]
	TIME [epoch: 9.73 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2512876193040294		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.2512876193040294 | validation: 0.24362805317011735]
	TIME [epoch: 9.74 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24205150039532802		[learning rate: 0.00071779]
	Learning Rate: 0.000717794
	LOSS [training: 0.24205150039532802 | validation: 0.24802149309856653]
	TIME [epoch: 9.75 sec]
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2484547420487861		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.2484547420487861 | validation: 0.2426462505651891]
	TIME [epoch: 9.73 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24971019467229466		[learning rate: 0.00071432]
	Learning Rate: 0.000714323
	LOSS [training: 0.24971019467229466 | validation: 0.24319091634675502]
	TIME [epoch: 9.74 sec]
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23654400273150436		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.23654400273150436 | validation: 0.24688991040239594]
	TIME [epoch: 9.74 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2424234968752288		[learning rate: 0.00071087]
	Learning Rate: 0.000710869
	LOSS [training: 0.2424234968752288 | validation: 0.249813382050109]
	TIME [epoch: 9.75 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.244594149569041		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.244594149569041 | validation: 0.2507017018089557]
	TIME [epoch: 9.74 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24483376014590336		[learning rate: 0.00070743]
	Learning Rate: 0.000707431
	LOSS [training: 0.24483376014590336 | validation: 0.24135694524120266]
	TIME [epoch: 9.73 sec]
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24110110826366835		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.24110110826366835 | validation: 0.2515311364474703]
	TIME [epoch: 9.75 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24666067132971237		[learning rate: 0.00070401]
	Learning Rate: 0.00070401
	LOSS [training: 0.24666067132971237 | validation: 0.23130275363888594]
	TIME [epoch: 9.74 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27092668820523785		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.27092668820523785 | validation: 0.29291429924702167]
	TIME [epoch: 9.73 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.274085132693786		[learning rate: 0.00070061]
	Learning Rate: 0.000700606
	LOSS [training: 0.274085132693786 | validation: 0.26610533437347267]
	TIME [epoch: 9.75 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26237840255149747		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.26237840255149747 | validation: 0.2912903123689016]
	TIME [epoch: 9.74 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26415839510270456		[learning rate: 0.00069722]
	Learning Rate: 0.000697218
	LOSS [training: 0.26415839510270456 | validation: 0.2512607048366172]
	TIME [epoch: 9.73 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25309037006533097		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.25309037006533097 | validation: 0.2518917077716575]
	TIME [epoch: 9.75 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24711403021156086		[learning rate: 0.00069385]
	Learning Rate: 0.000693846
	LOSS [training: 0.24711403021156086 | validation: 0.25338768759777486]
	TIME [epoch: 9.73 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2654512025883786		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.2654512025883786 | validation: 0.27355962232014025]
	TIME [epoch: 9.73 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26370205412993414		[learning rate: 0.00069049]
	Learning Rate: 0.000690491
	LOSS [training: 0.26370205412993414 | validation: 0.28938741810523916]
	TIME [epoch: 9.74 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27443933471446746		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.27443933471446746 | validation: 0.29569576435647404]
	TIME [epoch: 9.74 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2631101899373521		[learning rate: 0.00068715]
	Learning Rate: 0.000687152
	LOSS [training: 0.2631101899373521 | validation: 0.29706201464874077]
	TIME [epoch: 9.72 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.294427099569756		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.294427099569756 | validation: 0.310632280842638]
	TIME [epoch: 9.73 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2803598140744743		[learning rate: 0.00068383]
	Learning Rate: 0.000683829
	LOSS [training: 0.2803598140744743 | validation: 0.29313065868803784]
	TIME [epoch: 9.75 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2664278511499376		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.2664278511499376 | validation: 0.283147925281314]
	TIME [epoch: 9.72 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2692833844482783		[learning rate: 0.00068052]
	Learning Rate: 0.000680522
	LOSS [training: 0.2692833844482783 | validation: 0.2793136930158262]
	TIME [epoch: 9.74 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2662879546341113		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.2662879546341113 | validation: 0.2816803435352333]
	TIME [epoch: 9.76 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26897702742702545		[learning rate: 0.00067723]
	Learning Rate: 0.000677231
	LOSS [training: 0.26897702742702545 | validation: 0.30866507583840147]
	TIME [epoch: 9.74 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2716967959604686		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.2716967959604686 | validation: 0.29198381320114825]
	TIME [epoch: 9.72 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27551484671524495		[learning rate: 0.00067396]
	Learning Rate: 0.000673956
	LOSS [training: 0.27551484671524495 | validation: 0.273649721013708]
	TIME [epoch: 9.75 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26612832482916415		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.26612832482916415 | validation: 0.25823680765834717]
	TIME [epoch: 9.73 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2735483768415605		[learning rate: 0.0006707]
	Learning Rate: 0.000670697
	LOSS [training: 0.2735483768415605 | validation: 0.2574362887111908]
	TIME [epoch: 9.73 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25348911616027825		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.25348911616027825 | validation: 0.2820073245281391]
	TIME [epoch: 9.74 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2610263439971288		[learning rate: 0.00066745]
	Learning Rate: 0.000667454
	LOSS [training: 0.2610263439971288 | validation: 0.28697484065374135]
	TIME [epoch: 9.74 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.262878262557135		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.262878262557135 | validation: 0.2616902094570733]
	TIME [epoch: 9.73 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2538086415202145		[learning rate: 0.00066423]
	Learning Rate: 0.000664226
	LOSS [training: 0.2538086415202145 | validation: 0.2663372102832092]
	TIME [epoch: 9.73 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2573858682509407		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.2573858682509407 | validation: 0.28574475150679596]
	TIME [epoch: 9.76 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2579103710101552		[learning rate: 0.00066101]
	Learning Rate: 0.000661014
	LOSS [training: 0.2579103710101552 | validation: 0.2808722600751576]
	TIME [epoch: 9.73 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27534298537554036		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.27534298537554036 | validation: 0.287956463900394]
	TIME [epoch: 9.74 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2510048648510214		[learning rate: 0.00065782]
	Learning Rate: 0.000657817
	LOSS [training: 0.2510048648510214 | validation: 0.2561661331782]
	TIME [epoch: 9.74 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2448698726419635		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.2448698726419635 | validation: 0.2603115225992477]
	TIME [epoch: 9.73 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24999728446650896		[learning rate: 0.00065464]
	Learning Rate: 0.000654636
	LOSS [training: 0.24999728446650896 | validation: 0.23657046389514544]
	TIME [epoch: 9.72 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24776707003327236		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.24776707003327236 | validation: 0.25620318689195465]
	TIME [epoch: 9.75 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24166840114056268		[learning rate: 0.00065147]
	Learning Rate: 0.000651471
	LOSS [training: 0.24166840114056268 | validation: 0.23682709002403912]
	TIME [epoch: 9.74 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.249109847935977		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.249109847935977 | validation: 0.25568300416712464]
	TIME [epoch: 9.74 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2672569142123173		[learning rate: 0.00064832]
	Learning Rate: 0.00064832
	LOSS [training: 0.2672569142123173 | validation: 0.27262219586075903]
	TIME [epoch: 9.75 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2724481353396317		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.2724481353396317 | validation: 0.2827389278684252]
	TIME [epoch: 9.74 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26234414985003485		[learning rate: 0.00064519]
	Learning Rate: 0.000645185
	LOSS [training: 0.26234414985003485 | validation: 0.267150172037624]
	TIME [epoch: 9.75 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25639247109273244		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.25639247109273244 | validation: 0.25936037277108775]
	TIME [epoch: 9.72 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25154692380463994		[learning rate: 0.00064206]
	Learning Rate: 0.000642065
	LOSS [training: 0.25154692380463994 | validation: 0.264956095663944]
	TIME [epoch: 9.76 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25024172466059674		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.25024172466059674 | validation: 0.25507301047216435]
	TIME [epoch: 9.73 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.248970310190363		[learning rate: 0.00063896]
	Learning Rate: 0.00063896
	LOSS [training: 0.248970310190363 | validation: 0.23858392498203415]
	TIME [epoch: 9.73 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24799127625949816		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.24799127625949816 | validation: 0.2552228869236425]
	TIME [epoch: 9.75 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27463012032604767		[learning rate: 0.00063587]
	Learning Rate: 0.00063587
	LOSS [training: 0.27463012032604767 | validation: 0.260116548067585]
	TIME [epoch: 9.73 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24610993928431452		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.24610993928431452 | validation: 0.24365424308895656]
	TIME [epoch: 9.72 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2484823556410749		[learning rate: 0.0006328]
	Learning Rate: 0.000632795
	LOSS [training: 0.2484823556410749 | validation: 0.24533335306055334]
	TIME [epoch: 9.75 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.243771074511479		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.243771074511479 | validation: 0.2529478117522093]
	TIME [epoch: 9.74 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2483930733304116		[learning rate: 0.00062974]
	Learning Rate: 0.000629735
	LOSS [training: 0.2483930733304116 | validation: 0.2418904284137234]
	TIME [epoch: 9.74 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24572872037928245		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.24572872037928245 | validation: 0.24756482005032118]
	TIME [epoch: 9.73 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23516606359130288		[learning rate: 0.00062669]
	Learning Rate: 0.00062669
	LOSS [training: 0.23516606359130288 | validation: 0.22175765312357584]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1243.pth
	Model improved!!!
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24482078957677653		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.24482078957677653 | validation: 0.23772319065666672]
	TIME [epoch: 9.73 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2331503216245238		[learning rate: 0.00062366]
	Learning Rate: 0.000623659
	LOSS [training: 0.2331503216245238 | validation: 0.24879733210891677]
	TIME [epoch: 9.73 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24178820137409573		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.24178820137409573 | validation: 0.2421201827626152]
	TIME [epoch: 9.75 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24015936751097783		[learning rate: 0.00062064]
	Learning Rate: 0.000620643
	LOSS [training: 0.24015936751097783 | validation: 0.2374630925815353]
	TIME [epoch: 9.73 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24403730625641282		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.24403730625641282 | validation: 0.2378274132637631]
	TIME [epoch: 9.74 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.249825873729374		[learning rate: 0.00061764]
	Learning Rate: 0.000617642
	LOSS [training: 0.249825873729374 | validation: 0.24007770859730365]
	TIME [epoch: 9.76 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27045236755963853		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.27045236755963853 | validation: 0.28250968836064666]
	TIME [epoch: 9.73 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26093882439030536		[learning rate: 0.00061466]
	Learning Rate: 0.000614655
	LOSS [training: 0.26093882439030536 | validation: 0.24013876775400905]
	TIME [epoch: 9.73 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24586856231269866		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.24586856231269866 | validation: 0.2148597030174377]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1252.pth
	Model improved!!!
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2412287791218522		[learning rate: 0.00061168]
	Learning Rate: 0.000611683
	LOSS [training: 0.2412287791218522 | validation: 0.22054419872200817]
	TIME [epoch: 9.73 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24706837711446009		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.24706837711446009 | validation: 0.23274304082717895]
	TIME [epoch: 9.73 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24332688071103403		[learning rate: 0.00060872]
	Learning Rate: 0.000608725
	LOSS [training: 0.24332688071103403 | validation: 0.2636596728324189]
	TIME [epoch: 9.76 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25623185956973965		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.25623185956973965 | validation: 0.2665394276540864]
	TIME [epoch: 9.74 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.254997978266848		[learning rate: 0.00060578]
	Learning Rate: 0.000605781
	LOSS [training: 0.254997978266848 | validation: 0.23743980804789075]
	TIME [epoch: 9.73 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23948688266524018		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.23948688266524018 | validation: 0.23398942735941183]
	TIME [epoch: 9.74 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24385952494924892		[learning rate: 0.00060285]
	Learning Rate: 0.000602852
	LOSS [training: 0.24385952494924892 | validation: 0.23193784220445515]
	TIME [epoch: 9.75 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23380465913456971		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.23380465913456971 | validation: 0.23071367379375946]
	TIME [epoch: 9.74 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23846530849826691		[learning rate: 0.00059994]
	Learning Rate: 0.000599936
	LOSS [training: 0.23846530849826691 | validation: 0.26100882110311874]
	TIME [epoch: 9.73 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2381759027076224		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.2381759027076224 | validation: 0.23794896440002852]
	TIME [epoch: 9.75 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23227937315948766		[learning rate: 0.00059704]
	Learning Rate: 0.000597035
	LOSS [training: 0.23227937315948766 | validation: 0.22385082123966837]
	TIME [epoch: 9.74 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22965141327447758		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.22965141327447758 | validation: 0.23638547971333831]
	TIME [epoch: 9.73 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2334677460157677		[learning rate: 0.00059415]
	Learning Rate: 0.000594148
	LOSS [training: 0.2334677460157677 | validation: 0.26100173524717263]
	TIME [epoch: 9.75 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24986054887503154		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.24986054887503154 | validation: 0.23547443600281873]
	TIME [epoch: 9.73 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23872210778981895		[learning rate: 0.00059128]
	Learning Rate: 0.000591275
	LOSS [training: 0.23872210778981895 | validation: 0.22568864393521715]
	TIME [epoch: 9.75 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23545680476630643		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.23545680476630643 | validation: 0.22586353954973926]
	TIME [epoch: 9.76 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23267538479945976		[learning rate: 0.00058842]
	Learning Rate: 0.000588416
	LOSS [training: 0.23267538479945976 | validation: 0.24604166505327194]
	TIME [epoch: 9.75 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23546518508698902		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.23546518508698902 | validation: 0.2330050306143684]
	TIME [epoch: 9.74 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24423143723898638		[learning rate: 0.00058557]
	Learning Rate: 0.00058557
	LOSS [training: 0.24423143723898638 | validation: 0.3111659853805466]
	TIME [epoch: 9.74 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2827784382068336		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.2827784382068336 | validation: 0.2999127988646216]
	TIME [epoch: 9.75 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2447249156138862		[learning rate: 0.00058274]
	Learning Rate: 0.000582738
	LOSS [training: 0.2447249156138862 | validation: 0.23746980302514537]
	TIME [epoch: 9.74 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24010247770189022		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.24010247770189022 | validation: 0.23023917084098372]
	TIME [epoch: 9.72 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24049136529985288		[learning rate: 0.00057992]
	Learning Rate: 0.00057992
	LOSS [training: 0.24049136529985288 | validation: 0.2449269300518113]
	TIME [epoch: 9.76 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25105099255252716		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.25105099255252716 | validation: 0.25324328192855783]
	TIME [epoch: 9.74 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24015541378110888		[learning rate: 0.00057712]
	Learning Rate: 0.000577116
	LOSS [training: 0.24015541378110888 | validation: 0.2275555427809114]
	TIME [epoch: 9.74 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23878842713364135		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.23878842713364135 | validation: 0.24857890578895292]
	TIME [epoch: 9.76 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2375204701446374		[learning rate: 0.00057433]
	Learning Rate: 0.000574325
	LOSS [training: 0.2375204701446374 | validation: 0.2585619078767064]
	TIME [epoch: 9.74 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23984511193177077		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.23984511193177077 | validation: 0.2103818267468239]
	TIME [epoch: 9.72 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1280.pth
	Model improved!!!
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23227179272961304		[learning rate: 0.00057155]
	Learning Rate: 0.000571548
	LOSS [training: 0.23227179272961304 | validation: 0.25292493993899207]
	TIME [epoch: 9.74 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2401245860744871		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.2401245860744871 | validation: 0.2397944009525013]
	TIME [epoch: 9.74 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23742823065979182		[learning rate: 0.00056878]
	Learning Rate: 0.000568784
	LOSS [training: 0.23742823065979182 | validation: 0.23630839858282626]
	TIME [epoch: 9.75 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2467133405998919		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.2467133405998919 | validation: 0.22938285054066593]
	TIME [epoch: 9.75 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24571453348885539		[learning rate: 0.00056603]
	Learning Rate: 0.000566033
	LOSS [training: 0.24571453348885539 | validation: 0.2122562298576486]
	TIME [epoch: 9.76 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23340750297085275		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.23340750297085275 | validation: 0.2349432020645655]
	TIME [epoch: 9.75 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2316140250156689		[learning rate: 0.0005633]
	Learning Rate: 0.000563296
	LOSS [training: 0.2316140250156689 | validation: 0.22629290688897732]
	TIME [epoch: 9.74 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2395418694891489		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.2395418694891489 | validation: 0.23918656587204376]
	TIME [epoch: 9.77 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23590018919255326		[learning rate: 0.00056057]
	Learning Rate: 0.000560572
	LOSS [training: 0.23590018919255326 | validation: 0.23236518167992531]
	TIME [epoch: 9.75 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2512416533036682		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.2512416533036682 | validation: 0.2235649064329301]
	TIME [epoch: 9.75 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23915197631355803		[learning rate: 0.00055786]
	Learning Rate: 0.000557861
	LOSS [training: 0.23915197631355803 | validation: 0.24494601532870186]
	TIME [epoch: 9.76 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23839128197149212		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.23839128197149212 | validation: 0.23294723706065654]
	TIME [epoch: 9.75 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2474730831762142		[learning rate: 0.00055516]
	Learning Rate: 0.000555164
	LOSS [training: 0.2474730831762142 | validation: 0.2202988381750494]
	TIME [epoch: 9.75 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.239562907170945		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.239562907170945 | validation: 0.25004804298302136]
	TIME [epoch: 9.75 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23964729840232385		[learning rate: 0.00055248]
	Learning Rate: 0.000552479
	LOSS [training: 0.23964729840232385 | validation: 0.21889796143518495]
	TIME [epoch: 9.77 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24801627187943098		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.24801627187943098 | validation: 0.26111418174210527]
	TIME [epoch: 9.75 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27556251681384775		[learning rate: 0.00054981]
	Learning Rate: 0.000549807
	LOSS [training: 0.27556251681384775 | validation: 0.2681669486911082]
	TIME [epoch: 9.75 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26074435867162643		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.26074435867162643 | validation: 0.22588898135353183]
	TIME [epoch: 9.77 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25606045539550143		[learning rate: 0.00054715]
	Learning Rate: 0.000547149
	LOSS [training: 0.25606045539550143 | validation: 0.2473833561965906]
	TIME [epoch: 9.75 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25751709834218006		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.25751709834218006 | validation: 0.2508112314271417]
	TIME [epoch: 9.75 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24544527752004983		[learning rate: 0.0005445]
	Learning Rate: 0.000544503
	LOSS [training: 0.24544527752004983 | validation: 0.24318177042171193]
	TIME [epoch: 9.76 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24440578433588311		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.24440578433588311 | validation: 0.23457212970415534]
	TIME [epoch: 9.75 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2518054709136851		[learning rate: 0.00054187]
	Learning Rate: 0.000541869
	LOSS [training: 0.2518054709136851 | validation: 0.21712869315512998]
	TIME [epoch: 9.74 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24102285267150753		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.24102285267150753 | validation: 0.22352517156918622]
	TIME [epoch: 9.75 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23915426971157533		[learning rate: 0.00053925]
	Learning Rate: 0.000539249
	LOSS [training: 0.23915426971157533 | validation: 0.23798834993793436]
	TIME [epoch: 9.75 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24950258676918807		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.24950258676918807 | validation: 0.2566206331405337]
	TIME [epoch: 9.74 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24056158980846312		[learning rate: 0.00053664]
	Learning Rate: 0.000536641
	LOSS [training: 0.24056158980846312 | validation: 0.23295357992282306]
	TIME [epoch: 9.75 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23453658336881866		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.23453658336881866 | validation: 0.24190645785080242]
	TIME [epoch: 9.76 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23639279615703773		[learning rate: 0.00053405]
	Learning Rate: 0.000534046
	LOSS [training: 0.23639279615703773 | validation: 0.2308660099851218]
	TIME [epoch: 9.74 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23367078383623574		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.23367078383623574 | validation: 0.23712917214232612]
	TIME [epoch: 9.74 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2408970247456632		[learning rate: 0.00053146]
	Learning Rate: 0.000531464
	LOSS [training: 0.2408970247456632 | validation: 0.2565206090709164]
	TIME [epoch: 9.77 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23708669328288803		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.23708669328288803 | validation: 0.22940182222390135]
	TIME [epoch: 9.74 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23260268368430218		[learning rate: 0.00052889]
	Learning Rate: 0.000528894
	LOSS [training: 0.23260268368430218 | validation: 0.22366705386768004]
	TIME [epoch: 9.74 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23228596528451456		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.23228596528451456 | validation: 0.23101176335867604]
	TIME [epoch: 9.77 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23307211070827322		[learning rate: 0.00052634]
	Learning Rate: 0.000526336
	LOSS [training: 0.23307211070827322 | validation: 0.22885808417879708]
	TIME [epoch: 9.73 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23190949227408914		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.23190949227408914 | validation: 0.23100670534564727]
	TIME [epoch: 9.74 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2294198226750015		[learning rate: 0.00052379]
	Learning Rate: 0.000523791
	LOSS [training: 0.2294198226750015 | validation: 0.22972754443362295]
	TIME [epoch: 9.76 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22984737768389482		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.22984737768389482 | validation: 0.21300625693709993]
	TIME [epoch: 9.75 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23452818614883472		[learning rate: 0.00052126]
	Learning Rate: 0.000521258
	LOSS [training: 0.23452818614883472 | validation: 0.23682376069075847]
	TIME [epoch: 9.75 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23355837608341248		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.23355837608341248 | validation: 0.22664445620077853]
	TIME [epoch: 9.75 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2433941014355709		[learning rate: 0.00051874]
	Learning Rate: 0.000518737
	LOSS [training: 0.2433941014355709 | validation: 0.23201731505750586]
	TIME [epoch: 9.76 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23095472163865666		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.23095472163865666 | validation: 0.23478079149968856]
	TIME [epoch: 9.74 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25001603814754825		[learning rate: 0.00051623]
	Learning Rate: 0.000516229
	LOSS [training: 0.25001603814754825 | validation: 0.2338245370731351]
	TIME [epoch: 9.74 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2406444742335169		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.2406444742335169 | validation: 0.26683471853451163]
	TIME [epoch: 9.76 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2577881668996571		[learning rate: 0.00051373]
	Learning Rate: 0.000513732
	LOSS [training: 0.2577881668996571 | validation: 0.2626034413718363]
	TIME [epoch: 9.74 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2617950730472548		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.2617950730472548 | validation: 0.2533679474240563]
	TIME [epoch: 9.74 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26068759042887224		[learning rate: 0.00051125]
	Learning Rate: 0.000511248
	LOSS [training: 0.26068759042887224 | validation: 0.27085684020748785]
	TIME [epoch: 9.76 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2586570428833084		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.2586570428833084 | validation: 0.25047916802404074]
	TIME [epoch: 9.74 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24007591606945047		[learning rate: 0.00050878]
	Learning Rate: 0.000508776
	LOSS [training: 0.24007591606945047 | validation: 0.24693261419195808]
	TIME [epoch: 9.73 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23830076383012488		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.23830076383012488 | validation: 0.24746068262549092]
	TIME [epoch: 9.75 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23918479136208753		[learning rate: 0.00050632]
	Learning Rate: 0.000506315
	LOSS [training: 0.23918479136208753 | validation: 0.24230803868700862]
	TIME [epoch: 9.74 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25926825048417695		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.25926825048417695 | validation: 0.255064145911338]
	TIME [epoch: 9.74 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2663186737968707		[learning rate: 0.00050387]
	Learning Rate: 0.000503867
	LOSS [training: 0.2663186737968707 | validation: 0.24830431367418299]
	TIME [epoch: 9.74 sec]
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2514052489072773		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.2514052489072773 | validation: 0.2545276477226566]
	TIME [epoch: 9.75 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24677381280439295		[learning rate: 0.00050143]
	Learning Rate: 0.00050143
	LOSS [training: 0.24677381280439295 | validation: 0.25408663492891015]
	TIME [epoch: 9.74 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24404706793951486		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.24404706793951486 | validation: 0.23499416293505576]
	TIME [epoch: 9.73 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24365037021458824		[learning rate: 0.00049901]
	Learning Rate: 0.000499005
	LOSS [training: 0.24365037021458824 | validation: 0.24557475267191542]
	TIME [epoch: 9.75 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26001625167504683		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.26001625167504683 | validation: 0.24045607163758256]
	TIME [epoch: 9.73 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23941806461600262		[learning rate: 0.00049659]
	Learning Rate: 0.000496592
	LOSS [training: 0.23941806461600262 | validation: 0.24905758202538955]
	TIME [epoch: 9.73 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2505000748680618		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.2505000748680618 | validation: 0.22428198207656402]
	TIME [epoch: 9.75 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24058618813951033		[learning rate: 0.00049419]
	Learning Rate: 0.000494191
	LOSS [training: 0.24058618813951033 | validation: 0.24394175584042072]
	TIME [epoch: 9.73 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24320357649045293		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.24320357649045293 | validation: 0.2347686043558884]
	TIME [epoch: 9.73 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2378591218451256		[learning rate: 0.0004918]
	Learning Rate: 0.000491801
	LOSS [training: 0.2378591218451256 | validation: 0.24618339938167033]
	TIME [epoch: 9.74 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2271341890414953		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.2271341890414953 | validation: 0.21039474681498724]
	TIME [epoch: 9.73 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22307735177152183		[learning rate: 0.00048942]
	Learning Rate: 0.000489423
	LOSS [training: 0.22307735177152183 | validation: 0.2106246336925777]
	TIME [epoch: 9.73 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2323108267726653		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.2323108267726653 | validation: 0.21854875176477667]
	TIME [epoch: 9.74 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23352534530670796		[learning rate: 0.00048706]
	Learning Rate: 0.000487056
	LOSS [training: 0.23352534530670796 | validation: 0.23939170685312014]
	TIME [epoch: 9.74 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24105503520073243		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.24105503520073243 | validation: 0.2485329648868113]
	TIME [epoch: 9.73 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2408391253699958		[learning rate: 0.0004847]
	Learning Rate: 0.000484701
	LOSS [training: 0.2408391253699958 | validation: 0.21766513374423951]
	TIME [epoch: 9.73 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2480807638836769		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.2480807638836769 | validation: 0.23295043442073166]
	TIME [epoch: 9.74 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2608238701663828		[learning rate: 0.00048236]
	Learning Rate: 0.000482357
	LOSS [training: 0.2608238701663828 | validation: 0.26824694181562825]
	TIME [epoch: 9.73 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25713499537926665		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.25713499537926665 | validation: 0.2383833274115308]
	TIME [epoch: 9.73 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23294192352044898		[learning rate: 0.00048002]
	Learning Rate: 0.000480024
	LOSS [training: 0.23294192352044898 | validation: 0.24102070347169616]
	TIME [epoch: 9.75 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23512350450103706		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.23512350450103706 | validation: 0.25000034055902093]
	TIME [epoch: 9.73 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22280254185007506		[learning rate: 0.0004777]
	Learning Rate: 0.000477703
	LOSS [training: 0.22280254185007506 | validation: 0.22127547266818653]
	TIME [epoch: 9.73 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22418176113816118		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.22418176113816118 | validation: 0.24204517702173775]
	TIME [epoch: 9.75 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22739691810235935		[learning rate: 0.00047539]
	Learning Rate: 0.000475393
	LOSS [training: 0.22739691810235935 | validation: 0.2219106057168278]
	TIME [epoch: 9.73 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22635417390333784		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.22635417390333784 | validation: 0.2334191365572906]
	TIME [epoch: 9.73 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2247407239634632		[learning rate: 0.00047309]
	Learning Rate: 0.000473094
	LOSS [training: 0.2247407239634632 | validation: 0.23041152983356264]
	TIME [epoch: 9.73 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23447717412169916		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.23447717412169916 | validation: 0.2121352508111842]
	TIME [epoch: 9.74 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22750136352825806		[learning rate: 0.00047081]
	Learning Rate: 0.000470806
	LOSS [training: 0.22750136352825806 | validation: 0.21412516197023793]
	TIME [epoch: 9.73 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2265559037240547		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.2265559037240547 | validation: 0.22203610782045402]
	TIME [epoch: 9.72 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22728857080846532		[learning rate: 0.00046853]
	Learning Rate: 0.000468529
	LOSS [training: 0.22728857080846532 | validation: 0.24505405934734625]
	TIME [epoch: 9.75 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2376486090017142		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.2376486090017142 | validation: 0.2310299085949504]
	TIME [epoch: 9.73 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23259968872201847		[learning rate: 0.00046626]
	Learning Rate: 0.000466264
	LOSS [training: 0.23259968872201847 | validation: 0.23765307473955358]
	TIME [epoch: 9.72 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2328183538769662		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.2328183538769662 | validation: 0.22813344658517495]
	TIME [epoch: 9.75 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2271127472042263		[learning rate: 0.00046401]
	Learning Rate: 0.000464009
	LOSS [training: 0.2271127472042263 | validation: 0.21022880241026948]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1367.pth
	Model improved!!!
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23149003498673776		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.23149003498673776 | validation: 0.23832153221678035]
	TIME [epoch: 9.74 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23988838572975607		[learning rate: 0.00046177]
	Learning Rate: 0.000461765
	LOSS [training: 0.23988838572975607 | validation: 0.23425399491117144]
	TIME [epoch: 9.75 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23681934302096946		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.23681934302096946 | validation: 0.21753891329738287]
	TIME [epoch: 9.74 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23933507200539778		[learning rate: 0.00045953]
	Learning Rate: 0.000459532
	LOSS [training: 0.23933507200539778 | validation: 0.2390755344949506]
	TIME [epoch: 9.75 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22608488148722686		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.22608488148722686 | validation: 0.23969156917987883]
	TIME [epoch: 9.75 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23820975267302705		[learning rate: 0.00045731]
	Learning Rate: 0.00045731
	LOSS [training: 0.23820975267302705 | validation: 0.25197943240383197]
	TIME [epoch: 9.75 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2393661842729323		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.2393661842729323 | validation: 0.2545111488021162]
	TIME [epoch: 9.74 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23018355545111832		[learning rate: 0.0004551]
	Learning Rate: 0.000455098
	LOSS [training: 0.23018355545111832 | validation: 0.23428148028097295]
	TIME [epoch: 9.74 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22742059348230265		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.22742059348230265 | validation: 0.22949532019129737]
	TIME [epoch: 9.76 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24304330978827576		[learning rate: 0.0004529]
	Learning Rate: 0.000452898
	LOSS [training: 0.24304330978827576 | validation: 0.23887230288543232]
	TIME [epoch: 9.74 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24936231586715193		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.24936231586715193 | validation: 0.23602453520193248]
	TIME [epoch: 9.74 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23714866838196152		[learning rate: 0.00045071]
	Learning Rate: 0.000450708
	LOSS [training: 0.23714866838196152 | validation: 0.2287301131050098]
	TIME [epoch: 9.76 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23384437885196557		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.23384437885196557 | validation: 0.24395764080110824]
	TIME [epoch: 9.74 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.232097988365288		[learning rate: 0.00044853]
	Learning Rate: 0.000448528
	LOSS [training: 0.232097988365288 | validation: 0.22911334090018506]
	TIME [epoch: 9.74 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2353015071059648		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.2353015071059648 | validation: 0.23089344815553559]
	TIME [epoch: 9.76 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2456632172146847		[learning rate: 0.00044636]
	Learning Rate: 0.000446359
	LOSS [training: 0.2456632172146847 | validation: 0.22225914673845257]
	TIME [epoch: 9.74 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22863196788079473		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.22863196788079473 | validation: 0.22036272633176354]
	TIME [epoch: 9.74 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2448902054783742		[learning rate: 0.0004442]
	Learning Rate: 0.0004442
	LOSS [training: 0.2448902054783742 | validation: 0.24178924533436807]
	TIME [epoch: 9.74 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22957610024843295		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.22957610024843295 | validation: 0.243647314817323]
	TIME [epoch: 9.75 sec]
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2415966871092594		[learning rate: 0.00044205]
	Learning Rate: 0.000442052
	LOSS [training: 0.2415966871092594 | validation: 0.2396516881654128]
	TIME [epoch: 9.74 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24793947080278578		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.24793947080278578 | validation: 0.23293038397536175]
	TIME [epoch: 9.74 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25048995789054895		[learning rate: 0.00043991]
	Learning Rate: 0.000439915
	LOSS [training: 0.25048995789054895 | validation: 0.23402700580323213]
	TIME [epoch: 9.76 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2461679409719877		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.2461679409719877 | validation: 0.25151406069200016]
	TIME [epoch: 9.74 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2530410213710454		[learning rate: 0.00043779]
	Learning Rate: 0.000437787
	LOSS [training: 0.2530410213710454 | validation: 0.24668274371385157]
	TIME [epoch: 9.74 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23427408475668393		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.23427408475668393 | validation: 0.2226141218292131]
	TIME [epoch: 9.76 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2394675580074821		[learning rate: 0.00043567]
	Learning Rate: 0.00043567
	LOSS [training: 0.2394675580074821 | validation: 0.23420058332093124]
	TIME [epoch: 9.74 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24976588870894717		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.24976588870894717 | validation: 0.22706329320165405]
	TIME [epoch: 9.74 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2368819095081268		[learning rate: 0.00043356]
	Learning Rate: 0.000433563
	LOSS [training: 0.2368819095081268 | validation: 0.2414620167902124]
	TIME [epoch: 9.76 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.242164925099629		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.242164925099629 | validation: 0.2409810217936559]
	TIME [epoch: 9.75 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2507175354339363		[learning rate: 0.00043147]
	Learning Rate: 0.000431467
	LOSS [training: 0.2507175354339363 | validation: 0.2537701755546208]
	TIME [epoch: 9.73 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25240246579719183		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.25240246579719183 | validation: 0.24269924275053242]
	TIME [epoch: 9.75 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26847389587611437		[learning rate: 0.00042938]
	Learning Rate: 0.00042938
	LOSS [training: 0.26847389587611437 | validation: 0.2584593887302817]
	TIME [epoch: 9.75 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2643801032509899		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.2643801032509899 | validation: 0.25447454599965913]
	TIME [epoch: 9.74 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25912685419431825		[learning rate: 0.0004273]
	Learning Rate: 0.000427304
	LOSS [training: 0.25912685419431825 | validation: 0.2668482904941626]
	TIME [epoch: 9.74 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25929762963718617		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.25929762963718617 | validation: 0.2480637935101136]
	TIME [epoch: 9.76 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26356359223627923		[learning rate: 0.00042524]
	Learning Rate: 0.000425238
	LOSS [training: 0.26356359223627923 | validation: 0.2574678880975646]
	TIME [epoch: 9.74 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26163670204329825		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.26163670204329825 | validation: 0.252852003458733]
	TIME [epoch: 9.74 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2642922207484487		[learning rate: 0.00042318]
	Learning Rate: 0.000423181
	LOSS [training: 0.2642922207484487 | validation: 0.2538589087689546]
	TIME [epoch: 9.76 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26554137745033646		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.26554137745033646 | validation: 0.24928503188533385]
	TIME [epoch: 9.74 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2772871578490427		[learning rate: 0.00042113]
	Learning Rate: 0.000421135
	LOSS [training: 0.2772871578490427 | validation: 0.27700082569571904]
	TIME [epoch: 9.74 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2676210881716258		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.2676210881716258 | validation: 0.23145178208785233]
	TIME [epoch: 9.76 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2491008363137764		[learning rate: 0.0004191]
	Learning Rate: 0.000419098
	LOSS [training: 0.2491008363137764 | validation: 0.24014273888661705]
	TIME [epoch: 9.74 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25267778568005983		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.25267778568005983 | validation: 0.24916632393938032]
	TIME [epoch: 9.74 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2619576459521117		[learning rate: 0.00041707]
	Learning Rate: 0.000417072
	LOSS [training: 0.2619576459521117 | validation: 0.24752017624589706]
	TIME [epoch: 9.75 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2464676843521275		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.2464676843521275 | validation: 0.2355003766887688]
	TIME [epoch: 9.75 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23654570145574816		[learning rate: 0.00041505]
	Learning Rate: 0.000415055
	LOSS [training: 0.23654570145574816 | validation: 0.22115505020852763]
	TIME [epoch: 9.74 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23585607306841552		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.23585607306841552 | validation: 0.23122514976550976]
	TIME [epoch: 9.74 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23258031867703655		[learning rate: 0.00041305]
	Learning Rate: 0.000413048
	LOSS [training: 0.23258031867703655 | validation: 0.24997693670401963]
	TIME [epoch: 9.76 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2384976277094138		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.2384976277094138 | validation: 0.2532836089415886]
	TIME [epoch: 9.74 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23523778664284797		[learning rate: 0.00041105]
	Learning Rate: 0.00041105
	LOSS [training: 0.23523778664284797 | validation: 0.2215373025912181]
	TIME [epoch: 9.74 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22222714662755486		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.22222714662755486 | validation: 0.23124745959729687]
	TIME [epoch: 9.76 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24168669474027138		[learning rate: 0.00040906]
	Learning Rate: 0.000409062
	LOSS [training: 0.24168669474027138 | validation: 0.2375771443750393]
	TIME [epoch: 9.74 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23995777610290886		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.23995777610290886 | validation: 0.23800186136255086]
	TIME [epoch: 9.75 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23907864896448		[learning rate: 0.00040708]
	Learning Rate: 0.000407084
	LOSS [training: 0.23907864896448 | validation: 0.23656098529370567]
	TIME [epoch: 9.77 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24368677365523914		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.24368677365523914 | validation: 0.24490440337950067]
	TIME [epoch: 9.75 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23885367193167614		[learning rate: 0.00040512]
	Learning Rate: 0.000405116
	LOSS [training: 0.23885367193167614 | validation: 0.24491308818775984]
	TIME [epoch: 9.74 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24460282319286913		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.24460282319286913 | validation: 0.2398352610346719]
	TIME [epoch: 9.76 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23953300026897026		[learning rate: 0.00040316]
	Learning Rate: 0.000403157
	LOSS [training: 0.23953300026897026 | validation: 0.23779215530049366]
	TIME [epoch: 9.74 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2394288345972085		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.2394288345972085 | validation: 0.23601454746068812]
	TIME [epoch: 9.74 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24314907121997162		[learning rate: 0.00040121]
	Learning Rate: 0.000401207
	LOSS [training: 0.24314907121997162 | validation: 0.23593249581597492]
	TIME [epoch: 9.74 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23670234413721145		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.23670234413721145 | validation: 0.2298571748762469]
	TIME [epoch: 9.76 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23561236211750672		[learning rate: 0.00039927]
	Learning Rate: 0.000399267
	LOSS [training: 0.23561236211750672 | validation: 0.21517913863914487]
	TIME [epoch: 9.74 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23068448929807234		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.23068448929807234 | validation: 0.23533167458920837]
	TIME [epoch: 9.74 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2417969393561612		[learning rate: 0.00039734]
	Learning Rate: 0.000397336
	LOSS [training: 0.2417969393561612 | validation: 0.2591518635487641]
	TIME [epoch: 9.76 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24763726495857097		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.24763726495857097 | validation: 0.27287319251490444]
	TIME [epoch: 9.74 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2638532013556042		[learning rate: 0.00039541]
	Learning Rate: 0.000395415
	LOSS [training: 0.2638532013556042 | validation: 0.2472785445528137]
	TIME [epoch: 9.75 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24862737876470895		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.24862737876470895 | validation: 0.23602033433330735]
	TIME [epoch: 9.75 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24393157027904086		[learning rate: 0.0003935]
	Learning Rate: 0.000393502
	LOSS [training: 0.24393157027904086 | validation: 0.23573382046975955]
	TIME [epoch: 9.73 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24379523205201364		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.24379523205201364 | validation: 0.25788094437281806]
	TIME [epoch: 9.74 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25747085764376304		[learning rate: 0.0003916]
	Learning Rate: 0.000391599
	LOSS [training: 0.25747085764376304 | validation: 0.24726538557975122]
	TIME [epoch: 9.75 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25199870049851414		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.25199870049851414 | validation: 0.2343312169805037]
	TIME [epoch: 9.74 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24393839590143873		[learning rate: 0.00038971]
	Learning Rate: 0.000389706
	LOSS [training: 0.24393839590143873 | validation: 0.22098100686565234]
	TIME [epoch: 9.74 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24288131630500115		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.24288131630500115 | validation: 0.2408925870022953]
	TIME [epoch: 9.74 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2468797887662971		[learning rate: 0.00038782]
	Learning Rate: 0.000387821
	LOSS [training: 0.2468797887662971 | validation: 0.24957053680372412]
	TIME [epoch: 9.75 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2589359275874318		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.2589359275874318 | validation: 0.25536003079875264]
	TIME [epoch: 9.74 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25636951559388993		[learning rate: 0.00038595]
	Learning Rate: 0.000385946
	LOSS [training: 0.25636951559388993 | validation: 0.2574443134282205]
	TIME [epoch: 9.74 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2521124905756439		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.2521124905756439 | validation: 0.23796374742141663]
	TIME [epoch: 9.76 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26267229208528015		[learning rate: 0.00038408]
	Learning Rate: 0.000384079
	LOSS [training: 0.26267229208528015 | validation: 0.25382020672294753]
	TIME [epoch: 9.73 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26914728946208405		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.26914728946208405 | validation: 0.24455570907489202]
	TIME [epoch: 9.74 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26027273214432234		[learning rate: 0.00038222]
	Learning Rate: 0.000382222
	LOSS [training: 0.26027273214432234 | validation: 0.22516456493417664]
	TIME [epoch: 9.76 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25060668556937643		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.25060668556937643 | validation: 0.24577745127122014]
	TIME [epoch: 9.74 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2636977546480077		[learning rate: 0.00038037]
	Learning Rate: 0.000380374
	LOSS [training: 0.2636977546480077 | validation: 0.2689995116903326]
	TIME [epoch: 9.74 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2604643843704314		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.2604643843704314 | validation: 0.23379760931121746]
	TIME [epoch: 9.76 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24424257562053944		[learning rate: 0.00037853]
	Learning Rate: 0.000378534
	LOSS [training: 0.24424257562053944 | validation: 0.2339930672791788]
	TIME [epoch: 9.74 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.237982626115144		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.237982626115144 | validation: 0.249719501724595]
	TIME [epoch: 9.75 sec]
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22960129208442148		[learning rate: 0.0003767]
	Learning Rate: 0.000376704
	LOSS [training: 0.22960129208442148 | validation: 0.23628952338945944]
	TIME [epoch: 9.75 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24461100926687024		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.24461100926687024 | validation: 0.2481699140589514]
	TIME [epoch: 9.76 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24264106830818832		[learning rate: 0.00037488]
	Learning Rate: 0.000374882
	LOSS [training: 0.24264106830818832 | validation: 0.23541978173670686]
	TIME [epoch: 9.74 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2270532248006254		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.2270532248006254 | validation: 0.22524468038334408]
	TIME [epoch: 9.74 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23744926152723583		[learning rate: 0.00037307]
	Learning Rate: 0.000373069
	LOSS [training: 0.23744926152723583 | validation: 0.22141245616717592]
	TIME [epoch: 9.76 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22310703188695333		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.22310703188695333 | validation: 0.23555108895440413]
	TIME [epoch: 9.74 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22992235290209315		[learning rate: 0.00037127]
	Learning Rate: 0.000371265
	LOSS [training: 0.22992235290209315 | validation: 0.23521945746371942]
	TIME [epoch: 9.74 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23457219645160626		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.23457219645160626 | validation: 0.23573588211801824]
	TIME [epoch: 9.76 sec]
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2301251302679983		[learning rate: 0.00036947]
	Learning Rate: 0.00036947
	LOSS [training: 0.2301251302679983 | validation: 0.23930858023818866]
	TIME [epoch: 9.74 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24068938998572662		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.24068938998572662 | validation: 0.24600691045679313]
	TIME [epoch: 9.74 sec]
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23797596900253262		[learning rate: 0.00036768]
	Learning Rate: 0.000367683
	LOSS [training: 0.23797596900253262 | validation: 0.2382568677736034]
	TIME [epoch: 9.76 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23029889154573957		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.23029889154573957 | validation: 0.25041006984455727]
	TIME [epoch: 9.75 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23609680472694355		[learning rate: 0.00036591]
	Learning Rate: 0.000365905
	LOSS [training: 0.23609680472694355 | validation: 0.24532946591754404]
	TIME [epoch: 9.73 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.234118476696989		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.234118476696989 | validation: 0.2494998163740169]
	TIME [epoch: 9.74 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24154075541668657		[learning rate: 0.00036414]
	Learning Rate: 0.000364136
	LOSS [training: 0.24154075541668657 | validation: 0.2256966669542777]
	TIME [epoch: 9.76 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23183699129067864		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.23183699129067864 | validation: 0.23729395223301075]
	TIME [epoch: 9.74 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22384431927081624		[learning rate: 0.00036237]
	Learning Rate: 0.000362375
	LOSS [training: 0.22384431927081624 | validation: 0.22859039768225736]
	TIME [epoch: 9.74 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2226936637148746		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.2226936637148746 | validation: 0.2117031944777397]
	TIME [epoch: 9.76 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2271875194307202		[learning rate: 0.00036062]
	Learning Rate: 0.000360622
	LOSS [training: 0.2271875194307202 | validation: 0.22611872093191765]
	TIME [epoch: 9.73 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22677750744505434		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.22677750744505434 | validation: 0.2172632295218686]
	TIME [epoch: 9.74 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23329368338242493		[learning rate: 0.00035888]
	Learning Rate: 0.000358878
	LOSS [training: 0.23329368338242493 | validation: 0.2327312145633503]
	TIME [epoch: 9.76 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23219002619041143		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.23219002619041143 | validation: 0.22304127473540789]
	TIME [epoch: 9.74 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2225927016108081		[learning rate: 0.00035714]
	Learning Rate: 0.000357143
	LOSS [training: 0.2225927016108081 | validation: 0.22250626222580835]
	TIME [epoch: 9.74 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22528764846956925		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.22528764846956925 | validation: 0.21204175655466231]
	TIME [epoch: 9.76 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2358361519098254		[learning rate: 0.00035542]
	Learning Rate: 0.000355416
	LOSS [training: 0.2358361519098254 | validation: 0.22762612081510442]
	TIME [epoch: 9.75 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2372483997760257		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.2372483997760257 | validation: 0.22654342822414208]
	TIME [epoch: 9.74 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2277676306559322		[learning rate: 0.0003537]
	Learning Rate: 0.000353697
	LOSS [training: 0.2277676306559322 | validation: 0.2230975933374542]
	TIME [epoch: 9.74 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22544714405993688		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.22544714405993688 | validation: 0.2225079498382953]
	TIME [epoch: 9.76 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22026768439587582		[learning rate: 0.00035199]
	Learning Rate: 0.000351987
	LOSS [training: 0.22026768439587582 | validation: 0.21417261568795526]
	TIME [epoch: 9.74 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2271768038301257		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.2271768038301257 | validation: 0.21643619394232527]
	TIME [epoch: 9.74 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2249428764894379		[learning rate: 0.00035028]
	Learning Rate: 0.000350285
	LOSS [training: 0.2249428764894379 | validation: 0.2269905342888923]
	TIME [epoch: 9.76 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22942832897558638		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.22942832897558638 | validation: 0.2104853184871977]
	TIME [epoch: 9.74 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2191315270662828		[learning rate: 0.00034859]
	Learning Rate: 0.000348591
	LOSS [training: 0.2191315270662828 | validation: 0.21350190395747917]
	TIME [epoch: 9.74 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23179705569684012		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.23179705569684012 | validation: 0.21345319675009258]
	TIME [epoch: 9.76 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22196348005433456		[learning rate: 0.0003469]
	Learning Rate: 0.000346905
	LOSS [training: 0.22196348005433456 | validation: 0.22961572186315984]
	TIME [epoch: 9.74 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21803024354627198		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.21803024354627198 | validation: 0.22029426725153833]
	TIME [epoch: 9.74 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22752531034171947		[learning rate: 0.00034523]
	Learning Rate: 0.000345227
	LOSS [training: 0.22752531034171947 | validation: 0.22513207467296048]
	TIME [epoch: 9.75 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22836328159254515		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.22836328159254515 | validation: 0.23947561513874754]
	TIME [epoch: 9.75 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22872439458977292		[learning rate: 0.00034356]
	Learning Rate: 0.000343558
	LOSS [training: 0.22872439458977292 | validation: 0.2158823310243109]
	TIME [epoch: 9.74 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2246780035582535		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.2246780035582535 | validation: 0.22250962773918495]
	TIME [epoch: 9.75 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22322124339518953		[learning rate: 0.0003419]
	Learning Rate: 0.000341897
	LOSS [training: 0.22322124339518953 | validation: 0.2233127668435112]
	TIME [epoch: 9.75 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2212944949896798		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.2212944949896798 | validation: 0.2190685655623898]
	TIME [epoch: 9.74 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2204437705199723		[learning rate: 0.00034024]
	Learning Rate: 0.000340243
	LOSS [training: 0.2204437705199723 | validation: 0.2175250716808459]
	TIME [epoch: 9.74 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22409592154922137		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.22409592154922137 | validation: 0.21674348170098406]
	TIME [epoch: 9.76 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2300582130361098		[learning rate: 0.0003386]
	Learning Rate: 0.000338598
	LOSS [training: 0.2300582130361098 | validation: 0.23535948056763192]
	TIME [epoch: 9.74 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22328397830060998		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.22328397830060998 | validation: 0.23435269527874877]
	TIME [epoch: 9.74 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22401060596156147		[learning rate: 0.00033696]
	Learning Rate: 0.00033696
	LOSS [training: 0.22401060596156147 | validation: 0.24831649066517072]
	TIME [epoch: 9.76 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2197193508971643		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.2197193508971643 | validation: 0.22245869328184192]
	TIME [epoch: 9.75 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2278111534021658		[learning rate: 0.00033533]
	Learning Rate: 0.000335331
	LOSS [training: 0.2278111534021658 | validation: 0.23686187233767572]
	TIME [epoch: 9.74 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22772681985514737		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.22772681985514737 | validation: 0.227410902145346]
	TIME [epoch: 9.76 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2334445019368964		[learning rate: 0.00033371]
	Learning Rate: 0.000333709
	LOSS [training: 0.2334445019368964 | validation: 0.21260822724991754]
	TIME [epoch: 9.75 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22887850035685883		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.22887850035685883 | validation: 0.22849697266533017]
	TIME [epoch: 9.74 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22867394550480197		[learning rate: 0.0003321]
	Learning Rate: 0.000332096
	LOSS [training: 0.22867394550480197 | validation: 0.25369333249913295]
	TIME [epoch: 9.75 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23191451703603755		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.23191451703603755 | validation: 0.24624306684781366]
	TIME [epoch: 9.75 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.235217459853924		[learning rate: 0.00033049]
	Learning Rate: 0.00033049
	LOSS [training: 0.235217459853924 | validation: 0.22136951545277314]
	TIME [epoch: 9.75 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23033964049622072		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.23033964049622072 | validation: 0.24932215684889578]
	TIME [epoch: 9.74 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2405506092273252		[learning rate: 0.00032889]
	Learning Rate: 0.000328891
	LOSS [training: 0.2405506092273252 | validation: 0.22604938174189543]
	TIME [epoch: 9.76 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23098407686449648		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.23098407686449648 | validation: 0.2286649838632384]
	TIME [epoch: 9.74 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2356901515589201		[learning rate: 0.0003273]
	Learning Rate: 0.000327301
	LOSS [training: 0.2356901515589201 | validation: 0.22622432933944445]
	TIME [epoch: 9.74 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2364679316670665		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.2364679316670665 | validation: 0.2377643828759504]
	TIME [epoch: 9.75 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2400446254308831		[learning rate: 0.00032572]
	Learning Rate: 0.000325718
	LOSS [training: 0.2400446254308831 | validation: 0.2083198494060018]
	TIME [epoch: 9.74 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1513.pth
	Model improved!!!
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2388956424082609		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.2388956424082609 | validation: 0.23678584034403125]
	TIME [epoch: 9.74 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24237643947514692		[learning rate: 0.00032414]
	Learning Rate: 0.000324143
	LOSS [training: 0.24237643947514692 | validation: 0.23273754362396182]
	TIME [epoch: 9.76 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24672262039714804		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.24672262039714804 | validation: 0.24546735963444746]
	TIME [epoch: 9.75 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23835547817402314		[learning rate: 0.00032258]
	Learning Rate: 0.000322576
	LOSS [training: 0.23835547817402314 | validation: 0.22640090279396763]
	TIME [epoch: 9.75 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23326019380433333		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.23326019380433333 | validation: 0.2540474695388594]
	TIME [epoch: 9.75 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23521617169990625		[learning rate: 0.00032102]
	Learning Rate: 0.000321016
	LOSS [training: 0.23521617169990625 | validation: 0.22682776920754713]
	TIME [epoch: 9.76 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22878291914279242		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.22878291914279242 | validation: 0.21097801587163095]
	TIME [epoch: 9.74 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23828701913045305		[learning rate: 0.00031946]
	Learning Rate: 0.000319463
	LOSS [training: 0.23828701913045305 | validation: 0.21664747862017023]
	TIME [epoch: 9.74 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2268847515924124		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.2268847515924124 | validation: 0.2315410385836938]
	TIME [epoch: 9.76 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2326773299907074		[learning rate: 0.00031792]
	Learning Rate: 0.000317918
	LOSS [training: 0.2326773299907074 | validation: 0.21367568004857126]
	TIME [epoch: 9.74 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2361694610260882		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.2361694610260882 | validation: 0.22698400235255928]
	TIME [epoch: 9.74 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23647085433104403		[learning rate: 0.00031638]
	Learning Rate: 0.000316381
	LOSS [training: 0.23647085433104403 | validation: 0.23566192718972198]
	TIME [epoch: 9.77 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22529193380106077		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.22529193380106077 | validation: 0.2372209296579122]
	TIME [epoch: 9.74 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24202902137283946		[learning rate: 0.00031485]
	Learning Rate: 0.000314851
	LOSS [training: 0.24202902137283946 | validation: 0.22752933567324327]
	TIME [epoch: 9.74 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23427831371617044		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.23427831371617044 | validation: 0.22372013740837485]
	TIME [epoch: 9.76 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22701873775545223		[learning rate: 0.00031333]
	Learning Rate: 0.000313329
	LOSS [training: 0.22701873775545223 | validation: 0.2223401075206681]
	TIME [epoch: 9.74 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23231723253194075		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.23231723253194075 | validation: 0.23912457762834133]
	TIME [epoch: 9.74 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.254031657116965		[learning rate: 0.00031181]
	Learning Rate: 0.000311813
	LOSS [training: 0.254031657116965 | validation: 0.2374482863770887]
	TIME [epoch: 9.75 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2466951909662785		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.2466951909662785 | validation: 0.23962192516718453]
	TIME [epoch: 9.74 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24411594968466938		[learning rate: 0.00031031]
	Learning Rate: 0.000310305
	LOSS [training: 0.24411594968466938 | validation: 0.24369458929473348]
	TIME [epoch: 9.73 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24147431617096865		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.24147431617096865 | validation: 0.23084014942775993]
	TIME [epoch: 9.75 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22282806481036563		[learning rate: 0.0003088]
	Learning Rate: 0.000308805
	LOSS [training: 0.22282806481036563 | validation: 0.2143784123421921]
	TIME [epoch: 9.76 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23609452952373386		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.23609452952373386 | validation: 0.23713220791714917]
	TIME [epoch: 9.74 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2422175630372298		[learning rate: 0.00030731]
	Learning Rate: 0.000307312
	LOSS [training: 0.2422175630372298 | validation: 0.22325053588959937]
	TIME [epoch: 9.74 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23010059726302892		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.23010059726302892 | validation: 0.2331262515461433]
	TIME [epoch: 9.76 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2288244223363393		[learning rate: 0.00030583]
	Learning Rate: 0.000305826
	LOSS [training: 0.2288244223363393 | validation: 0.23165103936069756]
	TIME [epoch: 9.74 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23188881823972968		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.23188881823972968 | validation: 0.2182779705916653]
	TIME [epoch: 9.74 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2382937913959336		[learning rate: 0.00030435]
	Learning Rate: 0.000304347
	LOSS [training: 0.2382937913959336 | validation: 0.235727002813824]
	TIME [epoch: 9.75 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2408311081317775		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.2408311081317775 | validation: 0.22537538530831785]
	TIME [epoch: 9.75 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23928337895298463		[learning rate: 0.00030287]
	Learning Rate: 0.000302875
	LOSS [training: 0.23928337895298463 | validation: 0.22513880438556833]
	TIME [epoch: 9.74 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2324471160069789		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.2324471160069789 | validation: 0.2372914900934046]
	TIME [epoch: 9.76 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2493118549354174		[learning rate: 0.00030141]
	Learning Rate: 0.00030141
	LOSS [training: 0.2493118549354174 | validation: 0.23358033004330195]
	TIME [epoch: 9.74 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2498216181215954		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.2498216181215954 | validation: 0.2350001415405876]
	TIME [epoch: 9.74 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24800903037051586		[learning rate: 0.00029995]
	Learning Rate: 0.000299953
	LOSS [training: 0.24800903037051586 | validation: 0.23818658965099032]
	TIME [epoch: 9.74 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2429780458772927		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.2429780458772927 | validation: 0.23580402347484467]
	TIME [epoch: 9.75 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2345305713647506		[learning rate: 0.0002985]
	Learning Rate: 0.000298502
	LOSS [training: 0.2345305713647506 | validation: 0.23988314099307673]
	TIME [epoch: 9.74 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23900667225749644		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.23900667225749644 | validation: 0.24447516530976515]
	TIME [epoch: 9.74 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23683139550619292		[learning rate: 0.00029706]
	Learning Rate: 0.000297059
	LOSS [training: 0.23683139550619292 | validation: 0.225789067659491]
	TIME [epoch: 9.76 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24578825971925333		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.24578825971925333 | validation: 0.2491609547888747]
	TIME [epoch: 9.74 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23824528526594224		[learning rate: 0.00029562]
	Learning Rate: 0.000295622
	LOSS [training: 0.23824528526594224 | validation: 0.24021745482383666]
	TIME [epoch: 9.73 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2417664357134101		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.2417664357134101 | validation: 0.25615458694731014]
	TIME [epoch: 9.76 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24022092204463769		[learning rate: 0.00029419]
	Learning Rate: 0.000294193
	LOSS [training: 0.24022092204463769 | validation: 0.22900737589590095]
	TIME [epoch: 9.74 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23281492213790295		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.23281492213790295 | validation: 0.23729720855420952]
	TIME [epoch: 9.74 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2321566787319987		[learning rate: 0.00029277]
	Learning Rate: 0.00029277
	LOSS [training: 0.2321566787319987 | validation: 0.23176792504141872]
	TIME [epoch: 9.75 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22619189908168744		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.22619189908168744 | validation: 0.2138817024170591]
	TIME [epoch: 9.75 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21767866899238078		[learning rate: 0.00029135]
	Learning Rate: 0.000291354
	LOSS [training: 0.21767866899238078 | validation: 0.22674889108072052]
	TIME [epoch: 9.74 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23258892584338797		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.23258892584338797 | validation: 0.2184677936576746]
	TIME [epoch: 9.74 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23260370326193414		[learning rate: 0.00028995]
	Learning Rate: 0.000289945
	LOSS [training: 0.23260370326193414 | validation: 0.23715007177247377]
	TIME [epoch: 9.76 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22749733697626923		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.22749733697626923 | validation: 0.219029805900066]
	TIME [epoch: 9.74 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22868083914402745		[learning rate: 0.00028854]
	Learning Rate: 0.000288543
	LOSS [training: 0.22868083914402745 | validation: 0.2378260698406789]
	TIME [epoch: 9.74 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22289864642159504		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.22289864642159504 | validation: 0.22472849162913944]
	TIME [epoch: 9.76 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22280937539323742		[learning rate: 0.00028715]
	Learning Rate: 0.000287148
	LOSS [training: 0.22280937539323742 | validation: 0.22208871907633398]
	TIME [epoch: 9.73 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2171308217747378		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.2171308217747378 | validation: 0.20853081527892073]
	TIME [epoch: 9.74 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2272525139592679		[learning rate: 0.00028576]
	Learning Rate: 0.000285759
	LOSS [training: 0.2272525139592679 | validation: 0.22333030820615982]
	TIME [epoch: 9.75 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23153193915970313		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.23153193915970313 | validation: 0.23680415847241826]
	TIME [epoch: 9.74 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23048585563064802		[learning rate: 0.00028438]
	Learning Rate: 0.000284377
	LOSS [training: 0.23048585563064802 | validation: 0.22913305188546687]
	TIME [epoch: 9.74 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23470323781664165		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.23470323781664165 | validation: 0.22626933258637788]
	TIME [epoch: 9.76 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2451944283479913		[learning rate: 0.000283]
	Learning Rate: 0.000283002
	LOSS [training: 0.2451944283479913 | validation: 0.2367817279943484]
	TIME [epoch: 9.74 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23127456202543337		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.23127456202543337 | validation: 0.21553446571549784]
	TIME [epoch: 9.73 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22074732351042597		[learning rate: 0.00028163]
	Learning Rate: 0.000281633
	LOSS [training: 0.22074732351042597 | validation: 0.2297916615143977]
	TIME [epoch: 9.73 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21812892237532186		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.21812892237532186 | validation: 0.22509439110649632]
	TIME [epoch: 9.76 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22400057360376194		[learning rate: 0.00028027]
	Learning Rate: 0.000280272
	LOSS [training: 0.22400057360376194 | validation: 0.23015343832946095]
	TIME [epoch: 9.74 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22084914131732591		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.22084914131732591 | validation: 0.22948274836885335]
	TIME [epoch: 9.73 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.222938960866033		[learning rate: 0.00027892]
	Learning Rate: 0.000278916
	LOSS [training: 0.222938960866033 | validation: 0.21207381882396423]
	TIME [epoch: 9.76 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23293578861914727		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.23293578861914727 | validation: 0.20640338381997855]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1578.pth
	Model improved!!!
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21800354243065043		[learning rate: 0.00027757]
	Learning Rate: 0.000277567
	LOSS [training: 0.21800354243065043 | validation: 0.22791373092693534]
	TIME [epoch: 9.74 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22500920190773419		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.22500920190773419 | validation: 0.2174167106107888]
	TIME [epoch: 9.77 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2287610387455012		[learning rate: 0.00027623]
	Learning Rate: 0.000276225
	LOSS [training: 0.2287610387455012 | validation: 0.22248503078439263]
	TIME [epoch: 9.74 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23242367740184094		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.23242367740184094 | validation: 0.2138810817722019]
	TIME [epoch: 9.74 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22212472477695133		[learning rate: 0.00027489]
	Learning Rate: 0.000274889
	LOSS [training: 0.22212472477695133 | validation: 0.22773104513663484]
	TIME [epoch: 9.76 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23160480897055918		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.23160480897055918 | validation: 0.22650320422950498]
	TIME [epoch: 9.75 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22496101875375607		[learning rate: 0.00027356]
	Learning Rate: 0.00027356
	LOSS [training: 0.22496101875375607 | validation: 0.24085102916443277]
	TIME [epoch: 9.74 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2260027808994966		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.2260027808994966 | validation: 0.22276868572212877]
	TIME [epoch: 9.75 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22390569516837378		[learning rate: 0.00027224]
	Learning Rate: 0.000272237
	LOSS [training: 0.22390569516837378 | validation: 0.22685716316221638]
	TIME [epoch: 9.75 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21861834712007727		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.21861834712007727 | validation: 0.21624017271676338]
	TIME [epoch: 9.74 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22463684781992477		[learning rate: 0.00027092]
	Learning Rate: 0.000270921
	LOSS [training: 0.22463684781992477 | validation: 0.21471728095930023]
	TIME [epoch: 9.74 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22364650079917398		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.22364650079917398 | validation: 0.23783346463084074]
	TIME [epoch: 9.76 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2204626273999561		[learning rate: 0.00026961]
	Learning Rate: 0.000269611
	LOSS [training: 0.2204626273999561 | validation: 0.21055863998049526]
	TIME [epoch: 9.75 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22184443303457266		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.22184443303457266 | validation: 0.21738943989951337]
	TIME [epoch: 9.74 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2260956164835723		[learning rate: 0.00026831]
	Learning Rate: 0.000268307
	LOSS [training: 0.2260956164835723 | validation: 0.22006084669978723]
	TIME [epoch: 9.77 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2222654207061801		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.2222654207061801 | validation: 0.22585013029258766]
	TIME [epoch: 9.74 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22837731413477771		[learning rate: 0.00026701]
	Learning Rate: 0.000267009
	LOSS [training: 0.22837731413477771 | validation: 0.22288678715727783]
	TIME [epoch: 9.74 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22788562145490113		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.22788562145490113 | validation: 0.21152281671835974]
	TIME [epoch: 9.75 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21763457935428127		[learning rate: 0.00026572]
	Learning Rate: 0.000265718
	LOSS [training: 0.21763457935428127 | validation: 0.23027142521585553]
	TIME [epoch: 9.75 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23111215444460478		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.23111215444460478 | validation: 0.20709060360770906]
	TIME [epoch: 9.75 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23967228626641335		[learning rate: 0.00026443]
	Learning Rate: 0.000264433
	LOSS [training: 0.23967228626641335 | validation: 0.23774731034608465]
	TIME [epoch: 9.74 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2416489807360774		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.2416489807360774 | validation: 0.25714961104740774]
	TIME [epoch: 9.74 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2363684021615206		[learning rate: 0.00026315]
	Learning Rate: 0.000263154
	LOSS [training: 0.2363684021615206 | validation: 0.231091177973839]
	TIME [epoch: 9.73 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22569227379216622		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.22569227379216622 | validation: 0.23798795154428562]
	TIME [epoch: 9.74 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22515321352433343		[learning rate: 0.00026188]
	Learning Rate: 0.000261882
	LOSS [training: 0.22515321352433343 | validation: 0.22980522260719055]
	TIME [epoch: 9.76 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22749019487225905		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.22749019487225905 | validation: 0.23773981899485122]
	TIME [epoch: 9.74 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22737575668641435		[learning rate: 0.00026062]
	Learning Rate: 0.000260615
	LOSS [training: 0.22737575668641435 | validation: 0.2354284838014709]
	TIME [epoch: 9.75 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22472749824621047		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.22472749824621047 | validation: 0.22244948008304344]
	TIME [epoch: 9.76 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22339632542547427		[learning rate: 0.00025936]
	Learning Rate: 0.000259355
	LOSS [training: 0.22339632542547427 | validation: 0.21568243907881227]
	TIME [epoch: 9.75 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22361553972182446		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.22361553972182446 | validation: 0.22266803000321564]
	TIME [epoch: 9.74 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22293848650270168		[learning rate: 0.0002581]
	Learning Rate: 0.000258101
	LOSS [training: 0.22293848650270168 | validation: 0.220542409053677]
	TIME [epoch: 9.75 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22123489004803595		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.22123489004803595 | validation: 0.23185553903820869]
	TIME [epoch: 9.74 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2167050393014686		[learning rate: 0.00025685]
	Learning Rate: 0.000256853
	LOSS [training: 0.2167050393014686 | validation: 0.22072210941759848]
	TIME [epoch: 9.74 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22306897264701941		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.22306897264701941 | validation: 0.23720175816038933]
	TIME [epoch: 9.73 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22733955511039028		[learning rate: 0.00025561]
	Learning Rate: 0.000255611
	LOSS [training: 0.22733955511039028 | validation: 0.23727218549646098]
	TIME [epoch: 9.76 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2287595606843989		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.2287595606843989 | validation: 0.2397128345476522]
	TIME [epoch: 9.74 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22785631020463235		[learning rate: 0.00025437]
	Learning Rate: 0.000254375
	LOSS [training: 0.22785631020463235 | validation: 0.2249937574190728]
	TIME [epoch: 9.74 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22659110079617975		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.22659110079617975 | validation: 0.22439083022039719]
	TIME [epoch: 9.76 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2350206542878425		[learning rate: 0.00025314]
	Learning Rate: 0.000253144
	LOSS [training: 0.2350206542878425 | validation: 0.23607680500503428]
	TIME [epoch: 9.73 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23925566573672152		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.23925566573672152 | validation: 0.23110160982882363]
	TIME [epoch: 9.73 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23344366190961266		[learning rate: 0.00025192]
	Learning Rate: 0.00025192
	LOSS [training: 0.23344366190961266 | validation: 0.24762538471872458]
	TIME [epoch: 9.76 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23467559130699014		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.23467559130699014 | validation: 0.2228436696901961]
	TIME [epoch: 9.74 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23315302371014762		[learning rate: 0.0002507]
	Learning Rate: 0.000250702
	LOSS [training: 0.23315302371014762 | validation: 0.23526194441054518]
	TIME [epoch: 9.75 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23518245764026058		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.23518245764026058 | validation: 0.2550163089115021]
	TIME [epoch: 9.77 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24407423104088788		[learning rate: 0.00024949]
	Learning Rate: 0.00024949
	LOSS [training: 0.24407423104088788 | validation: 0.2616789051392455]
	TIME [epoch: 9.76 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23553048210059443		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.23553048210059443 | validation: 0.24955624961446318]
	TIME [epoch: 9.74 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23517610402704497		[learning rate: 0.00024828]
	Learning Rate: 0.000248283
	LOSS [training: 0.23517610402704497 | validation: 0.2449184034988761]
	TIME [epoch: 9.75 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23091084709803938		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.23091084709803938 | validation: 0.2537422702111726]
	TIME [epoch: 9.75 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2351166857292692		[learning rate: 0.00024708]
	Learning Rate: 0.000247083
	LOSS [training: 0.2351166857292692 | validation: 0.23864550385115318]
	TIME [epoch: 9.73 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23232599000721157		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.23232599000721157 | validation: 0.2396765831337006]
	TIME [epoch: 9.74 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23129261041936283		[learning rate: 0.00024589]
	Learning Rate: 0.000245888
	LOSS [training: 0.23129261041936283 | validation: 0.2129759181163806]
	TIME [epoch: 9.75 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23198803869759743		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.23198803869759743 | validation: 0.2421379770483902]
	TIME [epoch: 9.73 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2375184732047717		[learning rate: 0.0002447]
	Learning Rate: 0.000244699
	LOSS [training: 0.2375184732047717 | validation: 0.2367505763697715]
	TIME [epoch: 9.73 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23716545282085089		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.23716545282085089 | validation: 0.24599350511628534]
	TIME [epoch: 9.76 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23495211755563156		[learning rate: 0.00024352]
	Learning Rate: 0.000243515
	LOSS [training: 0.23495211755563156 | validation: 0.23786516987639345]
	TIME [epoch: 9.74 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23300300433662652		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.23300300433662652 | validation: 0.24011064861823742]
	TIME [epoch: 9.74 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23890460324500423		[learning rate: 0.00024234]
	Learning Rate: 0.000242338
	LOSS [training: 0.23890460324500423 | validation: 0.24177920135373673]
	TIME [epoch: 9.76 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2336306303608276		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.2336306303608276 | validation: 0.2443561935158018]
	TIME [epoch: 9.73 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23726192474961733		[learning rate: 0.00024117]
	Learning Rate: 0.000241166
	LOSS [training: 0.23726192474961733 | validation: 0.25530748439185524]
	TIME [epoch: 9.74 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23264593598909317		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.23264593598909317 | validation: 0.24043284949433968]
	TIME [epoch: 9.75 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23524283642521895		[learning rate: 0.00024]
	Learning Rate: 0.00024
	LOSS [training: 0.23524283642521895 | validation: 0.22855529143611414]
	TIME [epoch: 9.75 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23737301997326976		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.23737301997326976 | validation: 0.24646163526685755]
	TIME [epoch: 9.73 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2436209865998657		[learning rate: 0.00023884]
	Learning Rate: 0.000238839
	LOSS [training: 0.2436209865998657 | validation: 0.26062246718041915]
	TIME [epoch: 9.73 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2354734086714596		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.2354734086714596 | validation: 0.24418298547882777]
	TIME [epoch: 9.76 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23709551022444497		[learning rate: 0.00023768]
	Learning Rate: 0.000237684
	LOSS [training: 0.23709551022444497 | validation: 0.23273113746911775]
	TIME [epoch: 9.74 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23280490814545313		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.23280490814545313 | validation: 0.24953053185278898]
	TIME [epoch: 9.74 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.239326742631668		[learning rate: 0.00023653]
	Learning Rate: 0.000236535
	LOSS [training: 0.239326742631668 | validation: 0.2568293951707207]
	TIME [epoch: 9.75 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24619540062677486		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.24619540062677486 | validation: 0.25653249886656654]
	TIME [epoch: 9.73 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2380202860823301		[learning rate: 0.00023539]
	Learning Rate: 0.000235391
	LOSS [training: 0.2380202860823301 | validation: 0.25474963270443524]
	TIME [epoch: 9.74 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2347315499675716		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.2347315499675716 | validation: 0.23982262150426736]
	TIME [epoch: 9.76 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2365649448897334		[learning rate: 0.00023425]
	Learning Rate: 0.000234252
	LOSS [training: 0.2365649448897334 | validation: 0.228408515854051]
	TIME [epoch: 9.73 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24030101262600173		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.24030101262600173 | validation: 0.24507948931732884]
	TIME [epoch: 9.73 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23085410938342257		[learning rate: 0.00023312]
	Learning Rate: 0.00023312
	LOSS [training: 0.23085410938342257 | validation: 0.23088900409425264]
	TIME [epoch: 9.74 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.226634536653272		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.226634536653272 | validation: 0.24509570262240213]
	TIME [epoch: 9.75 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23157897775649613		[learning rate: 0.00023199]
	Learning Rate: 0.000231992
	LOSS [training: 0.23157897775649613 | validation: 0.2322835211432618]
	TIME [epoch: 9.74 sec]
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22542680698138123		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.22542680698138123 | validation: 0.24140054607767694]
	TIME [epoch: 9.75 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22485422001630978		[learning rate: 0.00023087]
	Learning Rate: 0.00023087
	LOSS [training: 0.22485422001630978 | validation: 0.2257275888781574]
	TIME [epoch: 9.77 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21840610610293482		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.21840610610293482 | validation: 0.2161225185565731]
	TIME [epoch: 9.74 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22547562154456133		[learning rate: 0.00022975]
	Learning Rate: 0.000229754
	LOSS [training: 0.22547562154456133 | validation: 0.20627910777446523]
	TIME [epoch: 9.76 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1657.pth
	Model improved!!!
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21673766994815935		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.21673766994815935 | validation: 0.2200957380150618]
	TIME [epoch: 9.76 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22516219620202116		[learning rate: 0.00022864]
	Learning Rate: 0.000228643
	LOSS [training: 0.22516219620202116 | validation: 0.23343990528066783]
	TIME [epoch: 9.73 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22157614618239574		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.22157614618239574 | validation: 0.22769709193065024]
	TIME [epoch: 9.74 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22199443412652667		[learning rate: 0.00022754]
	Learning Rate: 0.000227537
	LOSS [training: 0.22199443412652667 | validation: 0.22734709418862056]
	TIME [epoch: 9.75 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22894932787386074		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.22894932787386074 | validation: 0.24062168739327314]
	TIME [epoch: 9.74 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21530416921164916		[learning rate: 0.00022644]
	Learning Rate: 0.000226437
	LOSS [training: 0.21530416921164916 | validation: 0.22261169053941962]
	TIME [epoch: 9.75 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21144695487229473		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.21144695487229473 | validation: 0.22819012636616934]
	TIME [epoch: 9.75 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21766105796097995		[learning rate: 0.00022534]
	Learning Rate: 0.000225342
	LOSS [training: 0.21766105796097995 | validation: 0.22003474717080632]
	TIME [epoch: 9.73 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22160769832758556		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.22160769832758556 | validation: 0.21376510098195348]
	TIME [epoch: 9.74 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22597878092021664		[learning rate: 0.00022425]
	Learning Rate: 0.000224252
	LOSS [training: 0.22597878092021664 | validation: 0.21691633267055416]
	TIME [epoch: 9.75 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2237184641734654		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.2237184641734654 | validation: 0.2237203639393351]
	TIME [epoch: 9.76 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21694716349901483		[learning rate: 0.00022317]
	Learning Rate: 0.000223168
	LOSS [training: 0.21694716349901483 | validation: 0.2166508505048483]
	TIME [epoch: 9.73 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2180051767079032		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.2180051767079032 | validation: 0.22599780472023007]
	TIME [epoch: 9.73 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22092724213193415		[learning rate: 0.00022209]
	Learning Rate: 0.000222089
	LOSS [training: 0.22092724213193415 | validation: 0.23723214598562933]
	TIME [epoch: 9.75 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22039562307352628		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.22039562307352628 | validation: 0.2154888529428468]
	TIME [epoch: 9.73 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22722765634593856		[learning rate: 0.00022101]
	Learning Rate: 0.000221015
	LOSS [training: 0.22722765634593856 | validation: 0.22086777594103588]
	TIME [epoch: 9.74 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22169543421237167		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.22169543421237167 | validation: 0.23441003318211603]
	TIME [epoch: 9.75 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2213345553635388		[learning rate: 0.00021995]
	Learning Rate: 0.000219946
	LOSS [training: 0.2213345553635388 | validation: 0.21576813663831526]
	TIME [epoch: 9.73 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21450315779779866		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.21450315779779866 | validation: 0.20651166645874386]
	TIME [epoch: 9.74 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21479879732245805		[learning rate: 0.00021888]
	Learning Rate: 0.000218882
	LOSS [training: 0.21479879732245805 | validation: 0.2227049106167543]
	TIME [epoch: 9.74 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23479915849496164		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.23479915849496164 | validation: 0.23383511331279835]
	TIME [epoch: 9.73 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22679243937997517		[learning rate: 0.00021782]
	Learning Rate: 0.000217824
	LOSS [training: 0.22679243937997517 | validation: 0.21933814113666714]
	TIME [epoch: 9.73 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2235137680667874		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.2235137680667874 | validation: 0.2391389652365392]
	TIME [epoch: 9.74 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22355341555262406		[learning rate: 0.00021677]
	Learning Rate: 0.00021677
	LOSS [training: 0.22355341555262406 | validation: 0.22611587590244886]
	TIME [epoch: 9.75 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2265908757553876		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.2265908757553876 | validation: 0.21984576902789754]
	TIME [epoch: 9.74 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22052264087006884		[learning rate: 0.00021572]
	Learning Rate: 0.000215722
	LOSS [training: 0.22052264087006884 | validation: 0.21157872064130673]
	TIME [epoch: 9.74 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2225805565290357		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.2225805565290357 | validation: 0.23066216620568342]
	TIME [epoch: 9.77 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21241451220093371		[learning rate: 0.00021468]
	Learning Rate: 0.000214679
	LOSS [training: 0.21241451220093371 | validation: 0.22675672151365156]
	TIME [epoch: 9.74 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22472289579751742		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.22472289579751742 | validation: 0.2088009516852197]
	TIME [epoch: 9.74 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22227917571851327		[learning rate: 0.00021364]
	Learning Rate: 0.000213641
	LOSS [training: 0.22227917571851327 | validation: 0.22528121727473555]
	TIME [epoch: 9.76 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22134966811273893		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.22134966811273893 | validation: 0.22642339544287957]
	TIME [epoch: 9.75 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22415730823239258		[learning rate: 0.00021261]
	Learning Rate: 0.000212608
	LOSS [training: 0.22415730823239258 | validation: 0.2207050403486268]
	TIME [epoch: 9.73 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21625683146097235		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.21625683146097235 | validation: 0.22771912609238698]
	TIME [epoch: 9.74 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21451414343207356		[learning rate: 0.00021158]
	Learning Rate: 0.00021158
	LOSS [training: 0.21451414343207356 | validation: 0.22055036288778485]
	TIME [epoch: 9.74 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.217082577000225		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.217082577000225 | validation: 0.24410665236424944]
	TIME [epoch: 9.73 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22033367151570507		[learning rate: 0.00021056]
	Learning Rate: 0.000210556
	LOSS [training: 0.22033367151570507 | validation: 0.22770238526580783]
	TIME [epoch: 9.74 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2188996758815514		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.2188996758815514 | validation: 0.21739580735958958]
	TIME [epoch: 9.75 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.214977254598086		[learning rate: 0.00020954]
	Learning Rate: 0.000209538
	LOSS [training: 0.214977254598086 | validation: 0.21459543368532114]
	TIME [epoch: 9.74 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22790802439928792		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.22790802439928792 | validation: 0.21464470561607926]
	TIME [epoch: 9.73 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21916875165393984		[learning rate: 0.00020852]
	Learning Rate: 0.000208525
	LOSS [training: 0.21916875165393984 | validation: 0.2285548391066837]
	TIME [epoch: 9.76 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2205025711801089		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.2205025711801089 | validation: 0.22342165764534197]
	TIME [epoch: 9.72 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22203564480192362		[learning rate: 0.00020752]
	Learning Rate: 0.000207516
	LOSS [training: 0.22203564480192362 | validation: 0.21838248936198576]
	TIME [epoch: 9.74 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22269675484475746		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.22269675484475746 | validation: 0.21833444920390155]
	TIME [epoch: 9.76 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22180108709827864		[learning rate: 0.00020651]
	Learning Rate: 0.000206513
	LOSS [training: 0.22180108709827864 | validation: 0.2388005371305144]
	TIME [epoch: 9.73 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21987976092543232		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.21987976092543232 | validation: 0.21294785720262738]
	TIME [epoch: 9.74 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21867599760745082		[learning rate: 0.00020551]
	Learning Rate: 0.000205514
	LOSS [training: 0.21867599760745082 | validation: 0.2152795753228341]
	TIME [epoch: 9.75 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22042236972621976		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.22042236972621976 | validation: 0.2255277367384744]
	TIME [epoch: 9.75 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22156593060755467		[learning rate: 0.00020452]
	Learning Rate: 0.000204521
	LOSS [training: 0.22156593060755467 | validation: 0.219061628401087]
	TIME [epoch: 9.73 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2186283957677233		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.2186283957677233 | validation: 0.21951132050813996]
	TIME [epoch: 9.75 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21839617753789584		[learning rate: 0.00020353]
	Learning Rate: 0.000203531
	LOSS [training: 0.21839617753789584 | validation: 0.2156515647225129]
	TIME [epoch: 9.75 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23047552904511273		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.23047552904511273 | validation: 0.22850221940902424]
	TIME [epoch: 9.73 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22092947521365805		[learning rate: 0.00020255]
	Learning Rate: 0.000202547
	LOSS [training: 0.22092947521365805 | validation: 0.21167642111627152]
	TIME [epoch: 9.74 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21244039611511378		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.21244039611511378 | validation: 0.21329953083398492]
	TIME [epoch: 9.74 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2136537722304069		[learning rate: 0.00020157]
	Learning Rate: 0.000201568
	LOSS [training: 0.2136537722304069 | validation: 0.22157575717403416]
	TIME [epoch: 9.74 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21403907080629944		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.21403907080629944 | validation: 0.2160154064903964]
	TIME [epoch: 9.73 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2222246665516554		[learning rate: 0.00020059]
	Learning Rate: 0.000200593
	LOSS [training: 0.2222246665516554 | validation: 0.22058314343441943]
	TIME [epoch: 9.76 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21522341155067407		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.21522341155067407 | validation: 0.21277562275059936]
	TIME [epoch: 9.73 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22153942975712554		[learning rate: 0.00019962]
	Learning Rate: 0.000199623
	LOSS [training: 0.22153942975712554 | validation: 0.23370492227243234]
	TIME [epoch: 9.74 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22115007665506034		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.22115007665506034 | validation: 0.21358384066860645]
	TIME [epoch: 9.74 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2181783240364618		[learning rate: 0.00019866]
	Learning Rate: 0.000198658
	LOSS [training: 0.2181783240364618 | validation: 0.22638359058641797]
	TIME [epoch: 9.72 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2182690186295539		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.2182690186295539 | validation: 0.22596780925350193]
	TIME [epoch: 9.72 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22297330598964016		[learning rate: 0.0001977]
	Learning Rate: 0.000197697
	LOSS [training: 0.22297330598964016 | validation: 0.21514075086137346]
	TIME [epoch: 9.76 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2241028679683806		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.2241028679683806 | validation: 0.2216023554599449]
	TIME [epoch: 9.73 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23017613522611718		[learning rate: 0.00019674]
	Learning Rate: 0.000196741
	LOSS [training: 0.23017613522611718 | validation: 0.22484995044053754]
	TIME [epoch: 9.74 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23855570013383048		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.23855570013383048 | validation: 0.2444524868775176]
	TIME [epoch: 9.74 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22597742825775544		[learning rate: 0.00019579]
	Learning Rate: 0.00019579
	LOSS [training: 0.22597742825775544 | validation: 0.2292791826856429]
	TIME [epoch: 9.76 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24123108443601343		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.24123108443601343 | validation: 0.2435700566493484]
	TIME [epoch: 9.75 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2328690463908898		[learning rate: 0.00019484]
	Learning Rate: 0.000194843
	LOSS [training: 0.2328690463908898 | validation: 0.22205381691206405]
	TIME [epoch: 9.73 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.232642756994198		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.232642756994198 | validation: 0.23026205321057577]
	TIME [epoch: 9.76 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23810096603438077		[learning rate: 0.0001939]
	Learning Rate: 0.000193901
	LOSS [training: 0.23810096603438077 | validation: 0.22919977914416115]
	TIME [epoch: 9.74 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23666112676050202		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.23666112676050202 | validation: 0.2365428598212138]
	TIME [epoch: 9.73 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2308874700981975		[learning rate: 0.00019296]
	Learning Rate: 0.000192963
	LOSS [training: 0.2308874700981975 | validation: 0.23055899356779627]
	TIME [epoch: 9.75 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2355687554237449		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.2355687554237449 | validation: 0.2195072952893512]
	TIME [epoch: 9.75 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2408076940790897		[learning rate: 0.00019203]
	Learning Rate: 0.00019203
	LOSS [training: 0.2408076940790897 | validation: 0.22710776544255182]
	TIME [epoch: 9.74 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24140272337642482		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.24140272337642482 | validation: 0.20836800848109843]
	TIME [epoch: 9.76 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23319131567811063		[learning rate: 0.0001911]
	Learning Rate: 0.000191101
	LOSS [training: 0.23319131567811063 | validation: 0.2335374100251022]
	TIME [epoch: 9.73 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22958745222783686		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.22958745222783686 | validation: 0.23851662856708736]
	TIME [epoch: 9.73 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24055324772568634		[learning rate: 0.00019018]
	Learning Rate: 0.000190177
	LOSS [training: 0.24055324772568634 | validation: 0.22713565371331101]
	TIME [epoch: 9.73 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2338082169187045		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.2338082169187045 | validation: 0.23548742819888752]
	TIME [epoch: 9.75 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23846527758519248		[learning rate: 0.00018926]
	Learning Rate: 0.000189257
	LOSS [training: 0.23846527758519248 | validation: 0.22529156718847176]
	TIME [epoch: 9.73 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24032385661250194		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.24032385661250194 | validation: 0.234775542535619]
	TIME [epoch: 9.74 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24656977584801792		[learning rate: 0.00018834]
	Learning Rate: 0.000188342
	LOSS [training: 0.24656977584801792 | validation: 0.23791212232179873]
	TIME [epoch: 9.76 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24660388421171828		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.24660388421171828 | validation: 0.2431524006420662]
	TIME [epoch: 9.74 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2609502329781253		[learning rate: 0.00018743]
	Learning Rate: 0.000187431
	LOSS [training: 0.2609502329781253 | validation: 0.24067503241090518]
	TIME [epoch: 9.72 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23688344869525763		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.23688344869525763 | validation: 0.23925602157382195]
	TIME [epoch: 9.75 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24540641064192967		[learning rate: 0.00018652]
	Learning Rate: 0.000186525
	LOSS [training: 0.24540641064192967 | validation: 0.23340319300574308]
	TIME [epoch: 9.74 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.234991465837951		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.234991465837951 | validation: 0.21710153204421181]
	TIME [epoch: 9.74 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23888228876490433		[learning rate: 0.00018562]
	Learning Rate: 0.000185623
	LOSS [training: 0.23888228876490433 | validation: 0.22818461574888305]
	TIME [epoch: 9.74 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23332308997540485		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.23332308997540485 | validation: 0.21336825675119714]
	TIME [epoch: 9.75 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2367731626772184		[learning rate: 0.00018473]
	Learning Rate: 0.000184725
	LOSS [training: 0.2367731626772184 | validation: 0.22027892067372343]
	TIME [epoch: 9.73 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23965693776267774		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.23965693776267774 | validation: 0.25052447149946366]
	TIME [epoch: 9.73 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22986939178028037		[learning rate: 0.00018383]
	Learning Rate: 0.000183832
	LOSS [training: 0.22986939178028037 | validation: 0.22659758166988966]
	TIME [epoch: 9.76 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23293936198604231		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.23293936198604231 | validation: 0.23138608147482437]
	TIME [epoch: 9.74 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23847170911499047		[learning rate: 0.00018294]
	Learning Rate: 0.000182943
	LOSS [training: 0.23847170911499047 | validation: 0.24292431258090666]
	TIME [epoch: 9.73 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24450801420436657		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.24450801420436657 | validation: 0.24144873637791645]
	TIME [epoch: 9.75 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24414121200364206		[learning rate: 0.00018206]
	Learning Rate: 0.000182058
	LOSS [training: 0.24414121200364206 | validation: 0.23894459518953767]
	TIME [epoch: 9.74 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23741008722657764		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.23741008722657764 | validation: 0.236909558667557]
	TIME [epoch: 9.73 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23877174275906113		[learning rate: 0.00018118]
	Learning Rate: 0.000181178
	LOSS [training: 0.23877174275906113 | validation: 0.2290320613275303]
	TIME [epoch: 9.76 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24039751207586463		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.24039751207586463 | validation: 0.24318478886350156]
	TIME [epoch: 9.74 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.239646412931985		[learning rate: 0.0001803]
	Learning Rate: 0.000180302
	LOSS [training: 0.239646412931985 | validation: 0.23886449678887714]
	TIME [epoch: 9.74 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23787929968400653		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.23787929968400653 | validation: 0.23475153546575642]
	TIME [epoch: 9.73 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23829774072768678		[learning rate: 0.00017943]
	Learning Rate: 0.00017943
	LOSS [training: 0.23829774072768678 | validation: 0.2391757294806107]
	TIME [epoch: 9.73 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23907361070286526		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.23907361070286526 | validation: 0.24045482126307904]
	TIME [epoch: 9.72 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2329771572229439		[learning rate: 0.00017856]
	Learning Rate: 0.000178562
	LOSS [training: 0.2329771572229439 | validation: 0.23068608007045938]
	TIME [epoch: 9.73 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23034655360155026		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.23034655360155026 | validation: 0.22718100984567471]
	TIME [epoch: 9.77 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22761305901248458		[learning rate: 0.0001777]
	Learning Rate: 0.000177699
	LOSS [training: 0.22761305901248458 | validation: 0.226751537097218]
	TIME [epoch: 9.73 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23389411378243827		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.23389411378243827 | validation: 0.22467663163687335]
	TIME [epoch: 9.74 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23428812778877278		[learning rate: 0.00017684]
	Learning Rate: 0.000176839
	LOSS [training: 0.23428812778877278 | validation: 0.23766341863921858]
	TIME [epoch: 9.76 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24006553447653928		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.24006553447653928 | validation: 0.23285572300745158]
	TIME [epoch: 9.73 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23021187227627998		[learning rate: 0.00017598]
	Learning Rate: 0.000175984
	LOSS [training: 0.23021187227627998 | validation: 0.23527296797992073]
	TIME [epoch: 9.74 sec]
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22822577575876926		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.22822577575876926 | validation: 0.2215500059752271]
	TIME [epoch: 9.75 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22915902149287884		[learning rate: 0.00017513]
	Learning Rate: 0.000175133
	LOSS [training: 0.22915902149287884 | validation: 0.22677739802205338]
	TIME [epoch: 9.74 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2335920376222535		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.2335920376222535 | validation: 0.2164731972106234]
	TIME [epoch: 9.72 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23143383702564005		[learning rate: 0.00017429]
	Learning Rate: 0.000174286
	LOSS [training: 0.23143383702564005 | validation: 0.22543974366613426]
	TIME [epoch: 9.73 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23641773273756517		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.23641773273756517 | validation: 0.2305607890833769]
	TIME [epoch: 9.74 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2378366713908636		[learning rate: 0.00017344]
	Learning Rate: 0.000173443
	LOSS [training: 0.2378366713908636 | validation: 0.22621968936785122]
	TIME [epoch: 9.74 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23822790249103298		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.23822790249103298 | validation: 0.22462096400086473]
	TIME [epoch: 9.73 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23516823028609543		[learning rate: 0.0001726]
	Learning Rate: 0.000172605
	LOSS [training: 0.23516823028609543 | validation: 0.22733191604132263]
	TIME [epoch: 9.74 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23842418424291897		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.23842418424291897 | validation: 0.21465523904666875]
	TIME [epoch: 9.73 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23491964751589373		[learning rate: 0.00017177]
	Learning Rate: 0.00017177
	LOSS [training: 0.23491964751589373 | validation: 0.2155646707933854]
	TIME [epoch: 9.73 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23914814626134345		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.23914814626134345 | validation: 0.22962455631565662]
	TIME [epoch: 9.75 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23067985449437298		[learning rate: 0.00017094]
	Learning Rate: 0.000170939
	LOSS [training: 0.23067985449437298 | validation: 0.2207803148747689]
	TIME [epoch: 9.74 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23044109378866465		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.23044109378866465 | validation: 0.21209393078141156]
	TIME [epoch: 9.74 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23730168569296167		[learning rate: 0.00017011]
	Learning Rate: 0.000170113
	LOSS [training: 0.23730168569296167 | validation: 0.22216696278475098]
	TIME [epoch: 9.76 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23870489507166698		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.23870489507166698 | validation: 0.23453775712565736]
	TIME [epoch: 9.74 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22678049544852188		[learning rate: 0.00016929]
	Learning Rate: 0.00016929
	LOSS [training: 0.22678049544852188 | validation: 0.2286779573069866]
	TIME [epoch: 9.73 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23693928304089665		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.23693928304089665 | validation: 0.2211202898508696]
	TIME [epoch: 9.75 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23230215666122422		[learning rate: 0.00016847]
	Learning Rate: 0.000168471
	LOSS [training: 0.23230215666122422 | validation: 0.22299728667398]
	TIME [epoch: 9.75 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22536193953289022		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.22536193953289022 | validation: 0.21842336276704066]
	TIME [epoch: 9.73 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23050736054891838		[learning rate: 0.00016766]
	Learning Rate: 0.000167657
	LOSS [training: 0.23050736054891838 | validation: 0.22017781681354862]
	TIME [epoch: 9.74 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2255701044368723		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.2255701044368723 | validation: 0.21225672322741293]
	TIME [epoch: 9.75 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22661404966758375		[learning rate: 0.00016685]
	Learning Rate: 0.000166846
	LOSS [training: 0.22661404966758375 | validation: 0.21184331796295822]
	TIME [epoch: 9.73 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22122673039508886		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.22122673039508886 | validation: 0.2103533830529957]
	TIME [epoch: 9.73 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22153597472724443		[learning rate: 0.00016604]
	Learning Rate: 0.000166039
	LOSS [training: 0.22153597472724443 | validation: 0.2266809105909313]
	TIME [epoch: 9.77 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22235462888513796		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.22235462888513796 | validation: 0.2202624089815783]
	TIME [epoch: 9.73 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22290034657662267		[learning rate: 0.00016524]
	Learning Rate: 0.000165236
	LOSS [training: 0.22290034657662267 | validation: 0.2297753167955079]
	TIME [epoch: 9.73 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22637403047110033		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.22637403047110033 | validation: 0.22499928736989]
	TIME [epoch: 9.75 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23157811424168856		[learning rate: 0.00016444]
	Learning Rate: 0.000164437
	LOSS [training: 0.23157811424168856 | validation: 0.21100579959004173]
	TIME [epoch: 9.75 sec]
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22470000347897662		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.22470000347897662 | validation: 0.20750801230994625]
	TIME [epoch: 9.75 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22138093881075044		[learning rate: 0.00016364]
	Learning Rate: 0.000163642
	LOSS [training: 0.22138093881075044 | validation: 0.22746337883207862]
	TIME [epoch: 9.74 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22012177908571262		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.22012177908571262 | validation: 0.2242462506733767]
	TIME [epoch: 9.75 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22649309846956256		[learning rate: 0.00016285]
	Learning Rate: 0.000162851
	LOSS [training: 0.22649309846956256 | validation: 0.2443695238893315]
	TIME [epoch: 9.73 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23115456188328715		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.23115456188328715 | validation: 0.23575780692989015]
	TIME [epoch: 9.74 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23022416606960086		[learning rate: 0.00016206]
	Learning Rate: 0.000162063
	LOSS [training: 0.23022416606960086 | validation: 0.23315228312772057]
	TIME [epoch: 9.75 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22816717477800347		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.22816717477800347 | validation: 0.22859240233090802]
	TIME [epoch: 9.74 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2220434358315147		[learning rate: 0.00016128]
	Learning Rate: 0.000161279
	LOSS [training: 0.2220434358315147 | validation: 0.23923687600110163]
	TIME [epoch: 9.73 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.231231774368646		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.231231774368646 | validation: 0.2199515910686104]
	TIME [epoch: 9.75 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2273273332518282		[learning rate: 0.0001605]
	Learning Rate: 0.000160499
	LOSS [training: 0.2273273332518282 | validation: 0.22761000612864193]
	TIME [epoch: 9.75 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22546616022582805		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.22546616022582805 | validation: 0.21640959138162977]
	TIME [epoch: 9.73 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2171016847213107		[learning rate: 0.00015972]
	Learning Rate: 0.000159723
	LOSS [training: 0.2171016847213107 | validation: 0.22088645363992906]
	TIME [epoch: 9.76 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2211101660375728		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.2211101660375728 | validation: 0.21121038629349692]
	TIME [epoch: 9.74 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22297709421915818		[learning rate: 0.00015895]
	Learning Rate: 0.000158951
	LOSS [training: 0.22297709421915818 | validation: 0.22817677355226074]
	TIME [epoch: 9.72 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22100853945202953		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.22100853945202953 | validation: 0.22638040226002587]
	TIME [epoch: 9.75 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21987374531334222		[learning rate: 0.00015818]
	Learning Rate: 0.000158182
	LOSS [training: 0.21987374531334222 | validation: 0.2187750568552029]
	TIME [epoch: 9.75 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22754825696394748		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.22754825696394748 | validation: 0.2307562733558889]
	TIME [epoch: 9.74 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22543470488578973		[learning rate: 0.00015742]
	Learning Rate: 0.000157417
	LOSS [training: 0.22543470488578973 | validation: 0.23663143111575438]
	TIME [epoch: 9.74 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2297117871045126		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.2297117871045126 | validation: 0.21780637981871087]
	TIME [epoch: 9.75 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22859605883790093		[learning rate: 0.00015666]
	Learning Rate: 0.000156656
	LOSS [training: 0.22859605883790093 | validation: 0.23953549706265245]
	TIME [epoch: 9.73 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22703991368228219		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.22703991368228219 | validation: 0.21459580038291676]
	TIME [epoch: 9.72 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.229591380075024		[learning rate: 0.0001559]
	Learning Rate: 0.000155899
	LOSS [training: 0.229591380075024 | validation: 0.20682105549952526]
	TIME [epoch: 9.76 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22476778442043602		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.22476778442043602 | validation: 0.2199795337234047]
	TIME [epoch: 9.74 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23089044602381312		[learning rate: 0.00015514]
	Learning Rate: 0.000155145
	LOSS [training: 0.23089044602381312 | validation: 0.22864683603527894]
	TIME [epoch: 9.72 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23741469315009905		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.23741469315009905 | validation: 0.2377718671902489]
	TIME [epoch: 9.75 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23225640200159212		[learning rate: 0.00015439]
	Learning Rate: 0.000154394
	LOSS [training: 0.23225640200159212 | validation: 0.20857520494818943]
	TIME [epoch: 9.73 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22727153543274956		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.22727153543274956 | validation: 0.23289022626779654]
	TIME [epoch: 9.73 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22488895378488855		[learning rate: 0.00015365]
	Learning Rate: 0.000153648
	LOSS [training: 0.22488895378488855 | validation: 0.21907700183666032]
	TIME [epoch: 9.75 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23353753881659212		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.23353753881659212 | validation: 0.23202492615970183]
	TIME [epoch: 9.73 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22427267805982148		[learning rate: 0.0001529]
	Learning Rate: 0.000152905
	LOSS [training: 0.22427267805982148 | validation: 0.22927231818000843]
	TIME [epoch: 9.73 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22953402052509975		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.22953402052509975 | validation: 0.19526785415842376]
	TIME [epoch: 9.73 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1826.pth
	Model improved!!!
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22478954002233426		[learning rate: 0.00015217]
	Learning Rate: 0.000152165
	LOSS [training: 0.22478954002233426 | validation: 0.21641653740026634]
	TIME [epoch: 9.75 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21845782257996352		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.21845782257996352 | validation: 0.2239884868399686]
	TIME [epoch: 9.74 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22776080041007188		[learning rate: 0.00015143]
	Learning Rate: 0.00015143
	LOSS [training: 0.22776080041007188 | validation: 0.22785891164756802]
	TIME [epoch: 9.75 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2264886053006605		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.2264886053006605 | validation: 0.2128134235601718]
	TIME [epoch: 9.76 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2199341313848005		[learning rate: 0.0001507]
	Learning Rate: 0.000150697
	LOSS [training: 0.2199341313848005 | validation: 0.20358377987391552]
	TIME [epoch: 9.75 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23171302229442511		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.23171302229442511 | validation: 0.2241862110818397]
	TIME [epoch: 9.75 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2245363544350405		[learning rate: 0.00014997]
	Learning Rate: 0.000149968
	LOSS [training: 0.2245363544350405 | validation: 0.20892357158323457]
	TIME [epoch: 9.76 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2218646867122409		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.2218646867122409 | validation: 0.20846129502969682]
	TIME [epoch: 9.74 sec]
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22499687609042218		[learning rate: 0.00014924]
	Learning Rate: 0.000149243
	LOSS [training: 0.22499687609042218 | validation: 0.22075072974384027]
	TIME [epoch: 9.73 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23189711027781534		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.23189711027781534 | validation: 0.2054453552546962]
	TIME [epoch: 9.76 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22337805166301142		[learning rate: 0.00014852]
	Learning Rate: 0.000148522
	LOSS [training: 0.22337805166301142 | validation: 0.21596818506476095]
	TIME [epoch: 9.74 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21679610077858938		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.21679610077858938 | validation: 0.22272680205743134]
	TIME [epoch: 9.74 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21860122495240733		[learning rate: 0.0001478]
	Learning Rate: 0.000147803
	LOSS [training: 0.21860122495240733 | validation: 0.21293886471749396]
	TIME [epoch: 9.74 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22337969523189294		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.22337969523189294 | validation: 0.22342107599985245]
	TIME [epoch: 9.76 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22428056411005745		[learning rate: 0.00014709]
	Learning Rate: 0.000147089
	LOSS [training: 0.22428056411005745 | validation: 0.21178702702697905]
	TIME [epoch: 9.73 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2288682219740132		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.2288682219740132 | validation: 0.2226788795610102]
	TIME [epoch: 9.73 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22814502679166987		[learning rate: 0.00014638]
	Learning Rate: 0.000146377
	LOSS [training: 0.22814502679166987 | validation: 0.23255566947992667]
	TIME [epoch: 9.75 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22357775079540226		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.22357775079540226 | validation: 0.2238905996129023]
	TIME [epoch: 9.73 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22744845808325875		[learning rate: 0.00014567]
	Learning Rate: 0.000145669
	LOSS [training: 0.22744845808325875 | validation: 0.20756194482111798]
	TIME [epoch: 9.73 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21916724207014174		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.21916724207014174 | validation: 0.21320126056770008]
	TIME [epoch: 9.75 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22143029311316537		[learning rate: 0.00014497]
	Learning Rate: 0.000144965
	LOSS [training: 0.22143029311316537 | validation: 0.21469470832340684]
	TIME [epoch: 9.74 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21742072764909404		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.21742072764909404 | validation: 0.2279527520575437]
	TIME [epoch: 9.73 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2247861425480014		[learning rate: 0.00014426]
	Learning Rate: 0.000144264
	LOSS [training: 0.2247861425480014 | validation: 0.20763787877088405]
	TIME [epoch: 9.75 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22081633645918317		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.22081633645918317 | validation: 0.21981871455401183]
	TIME [epoch: 9.73 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22414961593998015		[learning rate: 0.00014357]
	Learning Rate: 0.000143566
	LOSS [training: 0.22414961593998015 | validation: 0.21288640517083457]
	TIME [epoch: 9.73 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22478281937528727		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.22478281937528727 | validation: 0.22399888799054432]
	TIME [epoch: 9.74 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21979083811180922		[learning rate: 0.00014287]
	Learning Rate: 0.000142872
	LOSS [training: 0.21979083811180922 | validation: 0.21723469661058672]
	TIME [epoch: 9.74 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21819078184925006		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.21819078184925006 | validation: 0.228946924698551]
	TIME [epoch: 9.73 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22874260325298326		[learning rate: 0.00014218]
	Learning Rate: 0.000142181
	LOSS [training: 0.22874260325298326 | validation: 0.22654404632208827]
	TIME [epoch: 9.73 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22552376127004878		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.22552376127004878 | validation: 0.22327365392504342]
	TIME [epoch: 9.75 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22174318602271384		[learning rate: 0.00014149]
	Learning Rate: 0.000141494
	LOSS [training: 0.22174318602271384 | validation: 0.22779904782666754]
	TIME [epoch: 9.73 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21835473000637706		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.21835473000637706 | validation: 0.21873861737809505]
	TIME [epoch: 9.72 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22190408296330855		[learning rate: 0.00014081]
	Learning Rate: 0.000140809
	LOSS [training: 0.22190408296330855 | validation: 0.21520930455463608]
	TIME [epoch: 9.76 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2201322826346642		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.2201322826346642 | validation: 0.22681828371173163]
	TIME [epoch: 9.73 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22612408358287422		[learning rate: 0.00014013]
	Learning Rate: 0.000140128
	LOSS [training: 0.22612408358287422 | validation: 0.22447125293517098]
	TIME [epoch: 9.72 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22500658868528706		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.22500658868528706 | validation: 0.21676708206195283]
	TIME [epoch: 9.73 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22668274356560136		[learning rate: 0.00013945]
	Learning Rate: 0.000139451
	LOSS [training: 0.22668274356560136 | validation: 0.2129011419381884]
	TIME [epoch: 9.73 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22075874060351214		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.22075874060351214 | validation: 0.21656731420058023]
	TIME [epoch: 9.73 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22518293778029336		[learning rate: 0.00013878]
	Learning Rate: 0.000138776
	LOSS [training: 0.22518293778029336 | validation: 0.2238200785751242]
	TIME [epoch: 9.74 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21386073682000642		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.21386073682000642 | validation: 0.2162501194721414]
	TIME [epoch: 9.74 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22779973361392533		[learning rate: 0.00013811]
	Learning Rate: 0.000138105
	LOSS [training: 0.22779973361392533 | validation: 0.2057815318325046]
	TIME [epoch: 9.73 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2265142877233688		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.2265142877233688 | validation: 0.20721709499430666]
	TIME [epoch: 9.74 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22090083407487757		[learning rate: 0.00013744]
	Learning Rate: 0.000137437
	LOSS [training: 0.22090083407487757 | validation: 0.21255393625884886]
	TIME [epoch: 9.75 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21997714432249404		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.21997714432249404 | validation: 0.22846025834617523]
	TIME [epoch: 9.72 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22483021802043793		[learning rate: 0.00013677]
	Learning Rate: 0.000136773
	LOSS [training: 0.22483021802043793 | validation: 0.22914834925330327]
	TIME [epoch: 9.72 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2269043584022302		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.2269043584022302 | validation: 0.22769738737950942]
	TIME [epoch: 9.74 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22362717665037754		[learning rate: 0.00013611]
	Learning Rate: 0.000136111
	LOSS [training: 0.22362717665037754 | validation: 0.23058211722154617]
	TIME [epoch: 9.73 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2287240282974062		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.2287240282974062 | validation: 0.22831409229275562]
	TIME [epoch: 9.74 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2204168860399452		[learning rate: 0.00013545]
	Learning Rate: 0.000135453
	LOSS [training: 0.2204168860399452 | validation: 0.230727522465209]
	TIME [epoch: 9.75 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22479941960105113		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.22479941960105113 | validation: 0.2269089859186524]
	TIME [epoch: 9.73 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2202366946537644		[learning rate: 0.0001348]
	Learning Rate: 0.000134798
	LOSS [training: 0.2202366946537644 | validation: 0.20902329644990056]
	TIME [epoch: 9.73 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.221177049231949		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.221177049231949 | validation: 0.22727402803477867]
	TIME [epoch: 9.74 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21590179388906683		[learning rate: 0.00013415]
	Learning Rate: 0.000134146
	LOSS [training: 0.21590179388906683 | validation: 0.22277387828718592]
	TIME [epoch: 9.74 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22662909094266487		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.22662909094266487 | validation: 0.21761985034044795]
	TIME [epoch: 9.73 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22388524462912987		[learning rate: 0.0001335]
	Learning Rate: 0.000133498
	LOSS [training: 0.22388524462912987 | validation: 0.22566154724615956]
	TIME [epoch: 9.73 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22709218835724335		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.22709218835724335 | validation: 0.22180670773733724]
	TIME [epoch: 9.75 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21986922528154995		[learning rate: 0.00013285]
	Learning Rate: 0.000132852
	LOSS [training: 0.21986922528154995 | validation: 0.21719359738083774]
	TIME [epoch: 9.74 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21710049497564654		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.21710049497564654 | validation: 0.21247746377376067]
	TIME [epoch: 9.73 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21248091052285414		[learning rate: 0.00013221]
	Learning Rate: 0.00013221
	LOSS [training: 0.21248091052285414 | validation: 0.2044086227653775]
	TIME [epoch: 9.76 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22135775838233446		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.22135775838233446 | validation: 0.21990896928868295]
	TIME [epoch: 9.74 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21569851470239598		[learning rate: 0.00013157]
	Learning Rate: 0.00013157
	LOSS [training: 0.21569851470239598 | validation: 0.210239810956952]
	TIME [epoch: 9.74 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22394971582446344		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.22394971582446344 | validation: 0.21188693801335184]
	TIME [epoch: 9.74 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22679902552581338		[learning rate: 0.00013093]
	Learning Rate: 0.000130934
	LOSS [training: 0.22679902552581338 | validation: 0.21374479341151456]
	TIME [epoch: 9.73 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22218381881096408		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.22218381881096408 | validation: 0.22043965572070467]
	TIME [epoch: 9.72 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22044735033497825		[learning rate: 0.0001303]
	Learning Rate: 0.000130301
	LOSS [training: 0.22044735033497825 | validation: 0.20989645711216148]
	TIME [epoch: 9.75 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21410151964904817		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.21410151964904817 | validation: 0.21190659289538352]
	TIME [epoch: 9.75 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21962502872821538		[learning rate: 0.00012967]
	Learning Rate: 0.000129671
	LOSS [training: 0.21962502872821538 | validation: 0.21563475680880345]
	TIME [epoch: 9.74 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21757325360926597		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.21757325360926597 | validation: 0.2147122743380929]
	TIME [epoch: 9.74 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21960730933445913		[learning rate: 0.00012904]
	Learning Rate: 0.000129044
	LOSS [training: 0.21960730933445913 | validation: 0.21837400415847405]
	TIME [epoch: 9.76 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2237186736386212		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.2237186736386212 | validation: 0.21839612001811226]
	TIME [epoch: 9.74 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21935329791746253		[learning rate: 0.00012842]
	Learning Rate: 0.00012842
	LOSS [training: 0.21935329791746253 | validation: 0.228175901806515]
	TIME [epoch: 9.74 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22171110514457007		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.22171110514457007 | validation: 0.2120767619148749]
	TIME [epoch: 9.75 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22324223741291443		[learning rate: 0.0001278]
	Learning Rate: 0.000127799
	LOSS [training: 0.22324223741291443 | validation: 0.21133253188920392]
	TIME [epoch: 9.74 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22270852176519468		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.22270852176519468 | validation: 0.2127195651184367]
	TIME [epoch: 9.73 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21311017864248633		[learning rate: 0.00012718]
	Learning Rate: 0.000127181
	LOSS [training: 0.21311017864248633 | validation: 0.22081257197505824]
	TIME [epoch: 9.77 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2216964953739521		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.2216964953739521 | validation: 0.2219230825486909]
	TIME [epoch: 9.75 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22077169935426477		[learning rate: 0.00012657]
	Learning Rate: 0.000126566
	LOSS [training: 0.22077169935426477 | validation: 0.231754267993458]
	TIME [epoch: 9.73 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2227872064121185		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.2227872064121185 | validation: 0.21715053919294192]
	TIME [epoch: 9.74 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22339636208280425		[learning rate: 0.00012595]
	Learning Rate: 0.000125954
	LOSS [training: 0.22339636208280425 | validation: 0.21074910397095498]
	TIME [epoch: 9.74 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21833567879753346		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.21833567879753346 | validation: 0.21836932086801442]
	TIME [epoch: 9.72 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2228165084545032		[learning rate: 0.00012534]
	Learning Rate: 0.000125345
	LOSS [training: 0.2228165084545032 | validation: 0.2211176522246515]
	TIME [epoch: 9.74 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22187166026062716		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.22187166026062716 | validation: 0.21375068087009128]
	TIME [epoch: 9.75 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2239971723187424		[learning rate: 0.00012474]
	Learning Rate: 0.000124738
	LOSS [training: 0.2239971723187424 | validation: 0.21377899820263685]
	TIME [epoch: 9.73 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22598804632376185		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.22598804632376185 | validation: 0.2246936185051915]
	TIME [epoch: 9.73 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22273138345735455		[learning rate: 0.00012414]
	Learning Rate: 0.000124135
	LOSS [training: 0.22273138345735455 | validation: 0.2232033871250903]
	TIME [epoch: 9.74 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2243843640369007		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.2243843640369007 | validation: 0.22549481869761104]
	TIME [epoch: 9.72 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22415931823873397		[learning rate: 0.00012353]
	Learning Rate: 0.000123535
	LOSS [training: 0.22415931823873397 | validation: 0.23174870237521483]
	TIME [epoch: 9.73 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22518778463300965		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.22518778463300965 | validation: 0.22778649037656729]
	TIME [epoch: 9.75 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21694640115270616		[learning rate: 0.00012294]
	Learning Rate: 0.000122937
	LOSS [training: 0.21694640115270616 | validation: 0.22066124058018016]
	TIME [epoch: 9.75 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2202108197421186		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.2202108197421186 | validation: 0.23622261547876233]
	TIME [epoch: 9.74 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22876716677408732		[learning rate: 0.00012234]
	Learning Rate: 0.000122343
	LOSS [training: 0.22876716677408732 | validation: 0.2188404134619782]
	TIME [epoch: 9.75 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2195270349884138		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.2195270349884138 | validation: 0.21223859983349322]
	TIME [epoch: 9.74 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21971914179742927		[learning rate: 0.00012175]
	Learning Rate: 0.000121751
	LOSS [training: 0.21971914179742927 | validation: 0.21047896212243428]
	TIME [epoch: 9.73 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2202116823245272		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.2202116823245272 | validation: 0.21088010263546594]
	TIME [epoch: 9.74 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22158779984456692		[learning rate: 0.00012116]
	Learning Rate: 0.000121163
	LOSS [training: 0.22158779984456692 | validation: 0.2081852284817454]
	TIME [epoch: 9.76 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21901088112165673		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.21901088112165673 | validation: 0.22668758358071384]
	TIME [epoch: 9.74 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2220788272407052		[learning rate: 0.00012058]
	Learning Rate: 0.000120577
	LOSS [training: 0.2220788272407052 | validation: 0.21380548724864715]
	TIME [epoch: 9.74 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22210359729991222		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.22210359729991222 | validation: 0.21585040938035532]
	TIME [epoch: 9.76 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21547131520548293		[learning rate: 0.00011999]
	Learning Rate: 0.000119994
	LOSS [training: 0.21547131520548293 | validation: 0.22485651716178892]
	TIME [epoch: 9.74 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2243966326119761		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.2243966326119761 | validation: 0.21551213765535607]
	TIME [epoch: 9.75 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22288469033859074		[learning rate: 0.00011941]
	Learning Rate: 0.000119413
	LOSS [training: 0.22288469033859074 | validation: 0.21001135566832407]
	TIME [epoch: 9.76 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23031637162123558		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.23031637162123558 | validation: 0.21049898041806414]
	TIME [epoch: 9.74 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22195235300074642		[learning rate: 0.00011884]
	Learning Rate: 0.000118836
	LOSS [training: 0.22195235300074642 | validation: 0.2139752998206729]
	TIME [epoch: 9.73 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22304742110505776		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.22304742110505776 | validation: 0.23337678533714268]
	TIME [epoch: 9.75 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2169620832928668		[learning rate: 0.00011826]
	Learning Rate: 0.000118261
	LOSS [training: 0.2169620832928668 | validation: 0.2223866236073763]
	TIME [epoch: 9.74 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21739647451623983		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.21739647451623983 | validation: 0.2236278340185311]
	TIME [epoch: 9.73 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22327401107645944		[learning rate: 0.00011769]
	Learning Rate: 0.000117689
	LOSS [training: 0.22327401107645944 | validation: 0.215593913752435]
	TIME [epoch: 9.73 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2178561666864513		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.2178561666864513 | validation: 0.22620279843190408]
	TIME [epoch: 9.74 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.222530466996328		[learning rate: 0.00011712]
	Learning Rate: 0.00011712
	LOSS [training: 0.222530466996328 | validation: 0.19721375234538946]
	TIME [epoch: 9.73 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22165228566576384		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.22165228566576384 | validation: 0.22417592131192712]
	TIME [epoch: 9.74 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22020274874298754		[learning rate: 0.00011655]
	Learning Rate: 0.000116554
	LOSS [training: 0.22020274874298754 | validation: 0.22297915952431216]
	TIME [epoch: 9.77 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21540701512028174		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.21540701512028174 | validation: 0.2193444786172231]
	TIME [epoch: 9.72 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.225191933851366		[learning rate: 0.00011599]
	Learning Rate: 0.00011599
	LOSS [training: 0.225191933851366 | validation: 0.2205834733841666]
	TIME [epoch: 9.74 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23021664558435515		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.23021664558435515 | validation: 0.22912007180207777]
	TIME [epoch: 9.76 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22833284564623485		[learning rate: 0.00011543]
	Learning Rate: 0.000115429
	LOSS [training: 0.22833284564623485 | validation: 0.22422132638221556]
	TIME [epoch: 9.73 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22256246029802		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.22256246029802 | validation: 0.21084263704480427]
	TIME [epoch: 9.73 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22556214199265395		[learning rate: 0.00011487]
	Learning Rate: 0.000114871
	LOSS [training: 0.22556214199265395 | validation: 0.22750368038665617]
	TIME [epoch: 9.75 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22096231643311662		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.22096231643311662 | validation: 0.21908070975909838]
	TIME [epoch: 9.75 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.227248320910155		[learning rate: 0.00011432]
	Learning Rate: 0.000114316
	LOSS [training: 0.227248320910155 | validation: 0.22533036662880468]
	TIME [epoch: 9.72 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23471154053084214		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.23471154053084214 | validation: 0.22810498767172427]
	TIME [epoch: 9.72 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23014072351479903		[learning rate: 0.00011376]
	Learning Rate: 0.000113763
	LOSS [training: 0.23014072351479903 | validation: 0.2202951068434449]
	TIME [epoch: 9.76 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22871282570867138		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.22871282570867138 | validation: 0.2259878578475354]
	TIME [epoch: 9.73 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22937924255065706		[learning rate: 0.00011321]
	Learning Rate: 0.000113213
	LOSS [training: 0.22937924255065706 | validation: 0.2235029757340736]
	TIME [epoch: 9.73 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22081330246163913		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.22081330246163913 | validation: 0.21948640981536505]
	TIME [epoch: 9.76 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2208414141785065		[learning rate: 0.00011267]
	Learning Rate: 0.000112665
	LOSS [training: 0.2208414141785065 | validation: 0.22070678468489086]
	TIME [epoch: 9.74 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22288141624350805		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.22288141624350805 | validation: 0.20228008148967241]
	TIME [epoch: 9.73 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2273105948638748		[learning rate: 0.00011212]
	Learning Rate: 0.00011212
	LOSS [training: 0.2273105948638748 | validation: 0.21561242751713497]
	TIME [epoch: 9.75 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2191025280742987		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.2191025280742987 | validation: 0.2318862304473378]
	TIME [epoch: 9.73 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22137611107631255		[learning rate: 0.00011158]
	Learning Rate: 0.000111578
	LOSS [training: 0.22137611107631255 | validation: 0.23505879223096304]
	TIME [epoch: 9.73 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21667862550993994		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.21667862550993994 | validation: 0.2168785926299224]
	TIME [epoch: 9.78 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2200693884503635		[learning rate: 0.00011104]
	Learning Rate: 0.000111039
	LOSS [training: 0.2200693884503635 | validation: 0.2177175049359413]
	TIME [epoch: 9.75 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22071220001822267		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.22071220001822267 | validation: 0.21606051145579588]
	TIME [epoch: 9.74 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2229019089019671		[learning rate: 0.0001105]
	Learning Rate: 0.000110502
	LOSS [training: 0.2229019089019671 | validation: 0.2221226004269521]
	TIME [epoch: 9.74 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21287730442873182		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.21287730442873182 | validation: 0.2296114663874813]
	TIME [epoch: 9.76 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2177800708269107		[learning rate: 0.00010997]
	Learning Rate: 0.000109967
	LOSS [training: 0.2177800708269107 | validation: 0.2145763418559311]
	TIME [epoch: 9.74 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21933957902133253		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.21933957902133253 | validation: 0.21868058886051508]
	TIME [epoch: 9.73 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22473337888617378		[learning rate: 0.00010944]
	Learning Rate: 0.000109435
	LOSS [training: 0.22473337888617378 | validation: 0.2332949616496362]
	TIME [epoch: 9.75 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22164313151182496		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.22164313151182496 | validation: 0.23483062384591022]
	TIME [epoch: 9.74 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22562673764144706		[learning rate: 0.00010891]
	Learning Rate: 0.000108906
	LOSS [training: 0.22562673764144706 | validation: 0.23331178384761464]
	TIME [epoch: 9.73 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22357043456879494		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.22357043456879494 | validation: 0.22109949672119125]
	TIME [epoch: 9.74 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2215737364779537		[learning rate: 0.00010838]
	Learning Rate: 0.00010838
	LOSS [training: 0.2215737364779537 | validation: 0.22962522875830405]
	TIME [epoch: 9.74 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.219047865032638		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.219047865032638 | validation: 0.22507342835884778]
	TIME [epoch: 9.74 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21907154801263662		[learning rate: 0.00010786]
	Learning Rate: 0.000107855
	LOSS [training: 0.21907154801263662 | validation: 0.22618582784850005]
	TIME [epoch: 9.76 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22353077135184649		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.22353077135184649 | validation: 0.20472578036788608]
	TIME [epoch: 9.74 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21300728448577502		[learning rate: 0.00010733]
	Learning Rate: 0.000107334
	LOSS [training: 0.21300728448577502 | validation: 0.21950720937686527]
	TIME [epoch: 9.76 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22847173169102047		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.22847173169102047 | validation: 0.22466519560034642]
	TIME [epoch: 9.75 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2282311349640543		[learning rate: 0.00010681]
	Learning Rate: 0.000106815
	LOSS [training: 0.2282311349640543 | validation: 0.20845122826370102]
	TIME [epoch: 9.76 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22767280896872094		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.22767280896872094 | validation: 0.20878658322829338]
	TIME [epoch: 9.74 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2235005542676463		[learning rate: 0.0001063]
	Learning Rate: 0.000106298
	LOSS [training: 0.2235005542676463 | validation: 0.221032018874659]
	TIME [epoch: 9.75 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22104676859614045		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.22104676859614045 | validation: 0.2117859898134374]
	TIME [epoch: 9.77 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2174261286371467		[learning rate: 0.00010578]
	Learning Rate: 0.000105784
	LOSS [training: 0.2174261286371467 | validation: 0.22409786926798356]
	TIME [epoch: 9.74 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22849360343569458		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.22849360343569458 | validation: 0.19446485362025415]
	TIME [epoch: 9.75 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240219_183145/states/model_tr_study6_1978.pth
	Model improved!!!
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22729295078837194		[learning rate: 0.00010527]
	Learning Rate: 0.000105273
	LOSS [training: 0.22729295078837194 | validation: 0.21056204557304456]
	TIME [epoch: 9.79 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21698177390415418		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.21698177390415418 | validation: 0.214976596970202]
	TIME [epoch: 9.76 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21705895978673356		[learning rate: 0.00010476]
	Learning Rate: 0.000104764
	LOSS [training: 0.21705895978673356 | validation: 0.20764934817711292]
	TIME [epoch: 9.75 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2155690853824283		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.2155690853824283 | validation: 0.21497244701048907]
	TIME [epoch: 9.76 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2216754412998004		[learning rate: 0.00010426]
	Learning Rate: 0.000104257
	LOSS [training: 0.2216754412998004 | validation: 0.22103324684404135]
	TIME [epoch: 9.75 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22844814237071		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.22844814237071 | validation: 0.2156838557433365]
	TIME [epoch: 9.74 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22547660541296785		[learning rate: 0.00010375]
	Learning Rate: 0.000103753
	LOSS [training: 0.22547660541296785 | validation: 0.22419114847166696]
	TIME [epoch: 9.75 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2227201068121841		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.2227201068121841 | validation: 0.22912074349797412]
	TIME [epoch: 9.76 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.228989197498134		[learning rate: 0.00010325]
	Learning Rate: 0.000103251
	LOSS [training: 0.228989197498134 | validation: 0.22485802043459294]
	TIME [epoch: 9.73 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2241071439074088		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.2241071439074088 | validation: 0.22574992652386136]
	TIME [epoch: 9.75 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21983425295175002		[learning rate: 0.00010275]
	Learning Rate: 0.000102752
	LOSS [training: 0.21983425295175002 | validation: 0.21603423195534677]
	TIME [epoch: 9.77 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22118332607454788		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.22118332607454788 | validation: 0.22978734758645225]
	TIME [epoch: 9.76 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.222714242119941		[learning rate: 0.00010225]
	Learning Rate: 0.000102255
	LOSS [training: 0.222714242119941 | validation: 0.2312242166541698]
	TIME [epoch: 9.74 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2244966306855743		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.2244966306855743 | validation: 0.20817886207433137]
	TIME [epoch: 9.76 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22856223045305754		[learning rate: 0.00010176]
	Learning Rate: 0.00010176
	LOSS [training: 0.22856223045305754 | validation: 0.22301655233167647]
	TIME [epoch: 9.75 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21818567934451308		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.21818567934451308 | validation: 0.21195879265006948]
	TIME [epoch: 9.75 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21054517855021465		[learning rate: 0.00010127]
	Learning Rate: 0.000101268
	LOSS [training: 0.21054517855021465 | validation: 0.21695593252217535]
	TIME [epoch: 9.77 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22494680394460528		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.22494680394460528 | validation: 0.22263714980945565]
	TIME [epoch: 9.76 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2197844426170974		[learning rate: 0.00010078]
	Learning Rate: 0.000100779
	LOSS [training: 0.2197844426170974 | validation: 0.21295507323266327]
	TIME [epoch: 9.76 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22253615613883965		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.22253615613883965 | validation: 0.2258465129384954]
	TIME [epoch: 9.76 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2245096238597069		[learning rate: 0.00010029]
	Learning Rate: 0.000100291
	LOSS [training: 0.2245096238597069 | validation: 0.21409248020000704]
	TIME [epoch: 9.75 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22017858842485394		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.22017858842485394 | validation: 0.21350651261340833]
	TIME [epoch: 9.75 sec]
Finished training in 19636.589 seconds.
