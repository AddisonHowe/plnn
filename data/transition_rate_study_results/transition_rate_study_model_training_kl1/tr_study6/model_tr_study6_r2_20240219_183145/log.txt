Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r2', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r2', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=100, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=100, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 1784733839

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.878518142576734		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.878518142576734 | validation: 9.05091105489411]
	TIME [epoch: 54.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 5/5] avg loss: 9.114809101735826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.114809101735826 | validation: 8.928617845382577]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.716065629160852		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.716065629160852 | validation: 8.060719623691915]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 5/5] avg loss: 8.213833416475715		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.213833416475715 | validation: 7.642486472620081]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.906714443110696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.906714443110696 | validation: 7.1995367474461425]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.56509443498935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.56509443498935 | validation: 7.050537379310249]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.2610407103371655		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2610407103371655 | validation: 6.789756496137081]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.95492696190537		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.95492696190537 | validation: 6.712973793347289]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.9099973778188275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9099973778188275 | validation: 7.1302289145659055]
	TIME [epoch: 9.51 sec]
EPOCH 10/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.834057763987434		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.834057763987434 | validation: 6.372397880606926]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.631719041565843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.631719041565843 | validation: 6.185452537161955]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.674704181416739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.674704181416739 | validation: 6.140962775337106]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.1686060748253855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1686060748253855 | validation: 6.107915779906034]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.473310388106375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.473310388106375 | validation: 5.292901004326479]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.471032508030882		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.471032508030882 | validation: 4.789258642221827]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.8529292708462375		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.8529292708462375 | validation: 4.4680796148432265]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.220993715381665		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.220993715381665 | validation: 3.148940370053424]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.7873157187359565		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7873157187359565 | validation: 6.098059847067778]
	TIME [epoch: 9.53 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.17743646941956		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.17743646941956 | validation: 3.478621455099262]
	TIME [epoch: 9.52 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.334476430152575		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.334476430152575 | validation: 3.1488756182383573]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.42278639410101		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.42278639410101 | validation: 2.864144582344481]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.153039354871802		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.153039354871802 | validation: 2.6550430053293006]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9484256794771584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9484256794771584 | validation: 2.6914528428295426]
	TIME [epoch: 9.51 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3810026162561186		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3810026162561186 | validation: 5.005226717203117]
	TIME [epoch: 9.54 sec]
EPOCH 25/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.288148307920961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.288148307920961 | validation: 2.9540534915992827]
	TIME [epoch: 9.52 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.937838648505748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.937838648505748 | validation: 2.6938644147333126]
	TIME [epoch: 9.52 sec]
EPOCH 27/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.289819707732441		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.289819707732441 | validation: 2.866047646748057]
	TIME [epoch: 9.51 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4274809046959414		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4274809046959414 | validation: 3.7523890774940436]
	TIME [epoch: 9.53 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2852232858907526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2852232858907526 | validation: 2.6748424581651875]
	TIME [epoch: 9.52 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0121573116048546		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0121573116048546 | validation: 4.3764370201465]
	TIME [epoch: 9.51 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.48181690306619		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.48181690306619 | validation: 3.956307737279344]
	TIME [epoch: 9.53 sec]
EPOCH 32/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.314922974543907		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.314922974543907 | validation: 3.1877534519398054]
	TIME [epoch: 9.51 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.938689911411749		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.938689911411749 | validation: 3.2301425674367934]
	TIME [epoch: 9.51 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.975269215654818		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.975269215654818 | validation: 4.650594605322675]
	TIME [epoch: 9.52 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.873878495405589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.873878495405589 | validation: 3.221769639247458]
	TIME [epoch: 9.53 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.082464073698079		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.082464073698079 | validation: 2.4491342009502977]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_36.pth
	Model improved!!!
EPOCH 37/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6421732350277276		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.6421732350277276 | validation: 2.2800355711766906]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.920128301068222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.920128301068222 | validation: 3.047004060593476]
	TIME [epoch: 9.53 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7789498837534303		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7789498837534303 | validation: 2.4973219636077197]
	TIME [epoch: 9.52 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4162806862053925		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4162806862053925 | validation: 2.3944426815947026]
	TIME [epoch: 9.53 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.547574743017718		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.547574743017718 | validation: 5.958222108895864]
	TIME [epoch: 9.53 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.529527691158032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.529527691158032 | validation: 4.869264703980961]
	TIME [epoch: 9.55 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.4574478417740995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.4574478417740995 | validation: 3.817216881677036]
	TIME [epoch: 9.53 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.258467104986692		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.258467104986692 | validation: 3.0220839453160036]
	TIME [epoch: 9.52 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 5/5] avg loss: 7.134562006150979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.134562006150979 | validation: 4.264685670067679]
	TIME [epoch: 9.52 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.748167156453981		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.748167156453981 | validation: 3.0523537475943]
	TIME [epoch: 9.55 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4932225363743967		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4932225363743967 | validation: 3.5220947718411275]
	TIME [epoch: 9.52 sec]
EPOCH 48/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.157410157465025		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.157410157465025 | validation: 2.837785026959454]
	TIME [epoch: 9.53 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1423325246160108		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1423325246160108 | validation: 3.1918884973242894]
	TIME [epoch: 9.54 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.238192297513696		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.238192297513696 | validation: 4.223468685641171]
	TIME [epoch: 9.53 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.6167384068998105		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.6167384068998105 | validation: 6.173178436134492]
	TIME [epoch: 9.52 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.603749719881935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.603749719881935 | validation: 2.943093096774353]
	TIME [epoch: 9.52 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1371311142175173		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1371311142175173 | validation: 2.7658641073927224]
	TIME [epoch: 9.55 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.043337285100969		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.043337285100969 | validation: 2.48998368652176]
	TIME [epoch: 9.51 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8951407938664855		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8951407938664855 | validation: 2.5686553711822735]
	TIME [epoch: 9.52 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9128649967378166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9128649967378166 | validation: 2.3287502369234234]
	TIME [epoch: 9.53 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.453353118535599		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.453353118535599 | validation: 2.4957127619338695]
	TIME [epoch: 9.55 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.683178537201826		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.683178537201826 | validation: 2.1134602215147753]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_58.pth
	Model improved!!!
EPOCH 59/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.814704401193883		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.814704401193883 | validation: 2.6912209188935776]
	TIME [epoch: 9.52 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7139411635613166		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7139411635613166 | validation: 2.2619346256410022]
	TIME [epoch: 9.53 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.103018159854752		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.103018159854752 | validation: 2.6393341238676546]
	TIME [epoch: 9.52 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4546207357586094		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4546207357586094 | validation: 2.551688658750009]
	TIME [epoch: 9.52 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.404530725155823		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.404530725155823 | validation: 2.1721606755273224]
	TIME [epoch: 9.51 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.301902400794966		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.301902400794966 | validation: 2.723475757648867]
	TIME [epoch: 9.53 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4122687500203446		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4122687500203446 | validation: 2.139520078388681]
	TIME [epoch: 9.51 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1640009817696733		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1640009817696733 | validation: 3.2191663182924657]
	TIME [epoch: 9.51 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.3452374066901935		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.3452374066901935 | validation: 2.4385173498544144]
	TIME [epoch: 9.51 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.430324936524701		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.430324936524701 | validation: 2.277443560173763]
	TIME [epoch: 9.53 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2766955570248135		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.2766955570248135 | validation: 2.064323316558127]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_69.pth
	Model improved!!!
EPOCH 70/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.166020870220964		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.166020870220964 | validation: 1.9571381952637825]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_70.pth
	Model improved!!!
EPOCH 71/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1068685508802796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.1068685508802796 | validation: 1.7654517526744418]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_71.pth
	Model improved!!!
EPOCH 72/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.4958458656415408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.4958458656415408 | validation: 4.018403596125722]
	TIME [epoch: 9.53 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.29732504731282		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.29732504731282 | validation: 3.5981040381150753]
	TIME [epoch: 9.51 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.430362615842906		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.430362615842906 | validation: 3.651273309183417]
	TIME [epoch: 9.52 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.1250688958824275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.1250688958824275 | validation: 3.400718444985875]
	TIME [epoch: 9.54 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.5053077852625476		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5053077852625476 | validation: 2.7075729437283518]
	TIME [epoch: 9.51 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2435448105879194		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2435448105879194 | validation: 2.9801407458461378]
	TIME [epoch: 9.52 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.3376021930673554		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3376021930673554 | validation: 2.9363674274642197]
	TIME [epoch: 9.54 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1065920537596234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1065920537596234 | validation: 2.626749298269362]
	TIME [epoch: 9.53 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.1078910122519146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1078910122519146 | validation: 3.556451619062384]
	TIME [epoch: 9.51 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.322502034215315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.322502034215315 | validation: 2.6951237959017353]
	TIME [epoch: 9.5 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2409696523369314		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2409696523369314 | validation: 2.604024784962287]
	TIME [epoch: 9.53 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.048619846426087		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.048619846426087 | validation: 2.4786634253658884]
	TIME [epoch: 9.51 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.011058901344425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.011058901344425 | validation: 2.377230403762226]
	TIME [epoch: 9.51 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7504927191166693		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7504927191166693 | validation: 2.7546110347306247]
	TIME [epoch: 9.5 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.2069002222185263		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2069002222185263 | validation: 2.4207577981020045]
	TIME [epoch: 9.54 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9368795269325494		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9368795269325494 | validation: 2.411706153006867]
	TIME [epoch: 9.52 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8416273085271513		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8416273085271513 | validation: 2.267796992414432]
	TIME [epoch: 9.51 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.774428496175591		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.774428496175591 | validation: 2.3061573216311113]
	TIME [epoch: 9.52 sec]
EPOCH 90/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9937350533516396		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.9937350533516396 | validation: 2.8638851446579485]
	TIME [epoch: 9.52 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7627405104427125		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7627405104427125 | validation: 2.402101136631562]
	TIME [epoch: 9.51 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0610705151114876		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0610705151114876 | validation: 2.4405655929581203]
	TIME [epoch: 9.51 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.989302220352137		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.989302220352137 | validation: 2.458708597891737]
	TIME [epoch: 9.54 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.976030170721583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.976030170721583 | validation: 2.417339352439072]
	TIME [epoch: 9.51 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.990421311442551		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.990421311442551 | validation: 2.4025750904051297]
	TIME [epoch: 9.51 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.043550209351887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.043550209351887 | validation: 2.4098707187314545]
	TIME [epoch: 9.52 sec]
EPOCH 97/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.350718925307877		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.350718925307877 | validation: 2.2967392490022553]
	TIME [epoch: 9.53 sec]
EPOCH 98/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8281785504964922		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8281785504964922 | validation: 2.1619103404275077]
	TIME [epoch: 9.5 sec]
EPOCH 99/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7273608572902774		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7273608572902774 | validation: 2.121456322859414]
	TIME [epoch: 9.51 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.73349466372584		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.73349466372584 | validation: 2.131661290672342]
	TIME [epoch: 9.53 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7605030171481983		[learning rate: 0.0099806]
	Learning Rate: 0.00998063
	LOSS [training: 2.7605030171481983 | validation: 2.247775639405928]
	TIME [epoch: 9.52 sec]
EPOCH 102/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.723700873560155		[learning rate: 0.0099565]
	Learning Rate: 0.00995647
	LOSS [training: 2.723700873560155 | validation: 2.2327838743920867]
	TIME [epoch: 9.52 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7282325843661384		[learning rate: 0.0099324]
	Learning Rate: 0.00993236
	LOSS [training: 2.7282325843661384 | validation: 2.091242594263145]
	TIME [epoch: 9.52 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.757800993606182		[learning rate: 0.0099083]
	Learning Rate: 0.00990832
	LOSS [training: 2.757800993606182 | validation: 4.754476165550843]
	TIME [epoch: 9.54 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4844108706970642		[learning rate: 0.0098843]
	Learning Rate: 0.00988433
	LOSS [training: 3.4844108706970642 | validation: 2.353578645232944]
	TIME [epoch: 9.52 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.104541022764048		[learning rate: 0.0098604]
	Learning Rate: 0.0098604
	LOSS [training: 3.104541022764048 | validation: 2.389253630255079]
	TIME [epoch: 9.51 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.989037637219148		[learning rate: 0.0098365]
	Learning Rate: 0.00983653
	LOSS [training: 2.989037637219148 | validation: 5.875225042239792]
	TIME [epoch: 9.51 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.546162770677229		[learning rate: 0.0098127]
	Learning Rate: 0.00981272
	LOSS [training: 6.546162770677229 | validation: 6.217752392876537]
	TIME [epoch: 9.55 sec]
EPOCH 109/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.557040380890252		[learning rate: 0.009789]
	Learning Rate: 0.00978897
	LOSS [training: 6.557040380890252 | validation: 6.204875912765332]
	TIME [epoch: 9.52 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.508606106522161		[learning rate: 0.0097653]
	Learning Rate: 0.00976527
	LOSS [training: 6.508606106522161 | validation: 6.160283539850541]
	TIME [epoch: 9.52 sec]
EPOCH 111/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.469605591282049		[learning rate: 0.0097416]
	Learning Rate: 0.00974163
	LOSS [training: 6.469605591282049 | validation: 6.121293770473551]
	TIME [epoch: 9.53 sec]
EPOCH 112/2000:
	Training over batches...
		[batch 5/5] avg loss: 6.435636505167992		[learning rate: 0.009718]
	Learning Rate: 0.00971805
	LOSS [training: 6.435636505167992 | validation: 6.0312295138105565]
	TIME [epoch: 9.53 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 5/5] avg loss: 5.422898287423177		[learning rate: 0.0096945]
	Learning Rate: 0.00969452
	LOSS [training: 5.422898287423177 | validation: 2.2171533511467776]
	TIME [epoch: 9.51 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4399547827035315		[learning rate: 0.0096711]
	Learning Rate: 0.00967105
	LOSS [training: 3.4399547827035315 | validation: 3.347102768332761]
	TIME [epoch: 9.51 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.056524488076223		[learning rate: 0.0096476]
	Learning Rate: 0.00964764
	LOSS [training: 4.056524488076223 | validation: 4.484025522561862]
	TIME [epoch: 9.54 sec]
EPOCH 116/2000:
	Training over batches...
		[batch 5/5] avg loss: 4.082597323282544		[learning rate: 0.0096243]
	Learning Rate: 0.00962428
	LOSS [training: 4.082597323282544 | validation: 2.9381747218896885]
	TIME [epoch: 9.53 sec]
EPOCH 117/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.712289148355199		[learning rate: 0.009601]
	Learning Rate: 0.00960098
	LOSS [training: 3.712289148355199 | validation: 2.8048128690103034]
	TIME [epoch: 9.52 sec]
EPOCH 118/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.7007376582705396		[learning rate: 0.0095777]
	Learning Rate: 0.00957774
	LOSS [training: 3.7007376582705396 | validation: 2.6864892155658753]
	TIME [epoch: 9.51 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.137469789101233		[learning rate: 0.0095546]
	Learning Rate: 0.00955456
	LOSS [training: 3.137469789101233 | validation: 2.8045060892572575]
	TIME [epoch: 9.54 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.337881748014317		[learning rate: 0.0095314]
	Learning Rate: 0.00953143
	LOSS [training: 3.337881748014317 | validation: 3.248782679514472]
	TIME [epoch: 9.52 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.150860779324995		[learning rate: 0.0095084]
	Learning Rate: 0.00950835
	LOSS [training: 3.150860779324995 | validation: 2.232060752479305]
	TIME [epoch: 9.51 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.691985118996656		[learning rate: 0.0094853]
	Learning Rate: 0.00948533
	LOSS [training: 2.691985118996656 | validation: 1.9106456146434738]
	TIME [epoch: 9.53 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9809675337131967		[learning rate: 0.0094624]
	Learning Rate: 0.00946237
	LOSS [training: 1.9809675337131967 | validation: 2.6601481297044733]
	TIME [epoch: 9.53 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.2813942383033337		[learning rate: 0.0094395]
	Learning Rate: 0.00943946
	LOSS [training: 2.2813942383033337 | validation: 1.6396378483867624]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_124.pth
	Model improved!!!
EPOCH 125/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.411135905624351		[learning rate: 0.0094166]
	Learning Rate: 0.00941661
	LOSS [training: 2.411135905624351 | validation: 1.902405177532996]
	TIME [epoch: 9.54 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.653448069964438		[learning rate: 0.0093938]
	Learning Rate: 0.00939382
	LOSS [training: 2.653448069964438 | validation: 2.686012909338215]
	TIME [epoch: 9.55 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0566972974977236		[learning rate: 0.0093711]
	Learning Rate: 0.00937108
	LOSS [training: 3.0566972974977236 | validation: 2.002955465020444]
	TIME [epoch: 9.53 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.205123204935313		[learning rate: 0.0093484]
	Learning Rate: 0.00934839
	LOSS [training: 2.205123204935313 | validation: 1.7511579228545724]
	TIME [epoch: 9.52 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0384655251351504		[learning rate: 0.0093258]
	Learning Rate: 0.00932576
	LOSS [training: 2.0384655251351504 | validation: 1.5944610742199812]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_129.pth
	Model improved!!!
EPOCH 130/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8672808692911869		[learning rate: 0.0093032]
	Learning Rate: 0.00930318
	LOSS [training: 1.8672808692911869 | validation: 1.6089143963495338]
	TIME [epoch: 9.54 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.9067073785608968		[learning rate: 0.0092807]
	Learning Rate: 0.00928066
	LOSS [training: 1.9067073785608968 | validation: 2.3717760281629996]
	TIME [epoch: 9.53 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.322875197532526		[learning rate: 0.0092582]
	Learning Rate: 0.00925819
	LOSS [training: 2.322875197532526 | validation: 1.775189692589012]
	TIME [epoch: 9.52 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6984907564633218		[learning rate: 0.0092358]
	Learning Rate: 0.00923578
	LOSS [training: 1.6984907564633218 | validation: 1.2598702742878127]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_133.pth
	Model improved!!!
EPOCH 134/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4489509519702346		[learning rate: 0.0092134]
	Learning Rate: 0.00921342
	LOSS [training: 1.4489509519702346 | validation: 1.4815254690008852]
	TIME [epoch: 9.53 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.582399092787544		[learning rate: 0.0091911]
	Learning Rate: 0.00919112
	LOSS [training: 1.582399092787544 | validation: 1.177214165331045]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_135.pth
	Model improved!!!
EPOCH 136/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.3031674508506612		[learning rate: 0.0091689]
	Learning Rate: 0.00916887
	LOSS [training: 1.3031674508506612 | validation: 1.1157032522927361]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_136.pth
	Model improved!!!
EPOCH 137/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1453091464244995		[learning rate: 0.0091467]
	Learning Rate: 0.00914667
	LOSS [training: 1.1453091464244995 | validation: 1.2451964957438262]
	TIME [epoch: 9.54 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5282717978983367		[learning rate: 0.0091245]
	Learning Rate: 0.00912453
	LOSS [training: 1.5282717978983367 | validation: 1.0985991632097767]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_138.pth
	Model improved!!!
EPOCH 139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9900770522717097		[learning rate: 0.0091024]
	Learning Rate: 0.00910244
	LOSS [training: 0.9900770522717097 | validation: 0.6952777431951719]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_139.pth
	Model improved!!!
EPOCH 140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9445009640547097		[learning rate: 0.0090804]
	Learning Rate: 0.00908041
	LOSS [training: 0.9445009640547097 | validation: 0.7559622799492353]
	TIME [epoch: 9.54 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7804072043401576		[learning rate: 0.0090584]
	Learning Rate: 0.00905842
	LOSS [training: 0.7804072043401576 | validation: 0.8886992085315005]
	TIME [epoch: 9.52 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2326051603999753		[learning rate: 0.0090365]
	Learning Rate: 0.00903649
	LOSS [training: 1.2326051603999753 | validation: 1.1130102205615564]
	TIME [epoch: 9.52 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1198503053382953		[learning rate: 0.0090146]
	Learning Rate: 0.00901462
	LOSS [training: 1.1198503053382953 | validation: 0.9419376926893737]
	TIME [epoch: 9.53 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9921020760368867		[learning rate: 0.0089928]
	Learning Rate: 0.0089928
	LOSS [training: 0.9921020760368867 | validation: 0.784265985019197]
	TIME [epoch: 9.53 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8218475440475401		[learning rate: 0.008971]
	Learning Rate: 0.00897103
	LOSS [training: 0.8218475440475401 | validation: 0.6440062735332905]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_145.pth
	Model improved!!!
EPOCH 146/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1174724796715925		[learning rate: 0.0089493]
	Learning Rate: 0.00894931
	LOSS [training: 1.1174724796715925 | validation: 0.8925862538012013]
	TIME [epoch: 9.52 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8340693430117927		[learning rate: 0.0089276]
	Learning Rate: 0.00892764
	LOSS [training: 0.8340693430117927 | validation: 0.6555018631457905]
	TIME [epoch: 9.53 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8784837354716031		[learning rate: 0.008906]
	Learning Rate: 0.00890603
	LOSS [training: 0.8784837354716031 | validation: 1.2160123714207154]
	TIME [epoch: 9.52 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1053836684765113		[learning rate: 0.0088845]
	Learning Rate: 0.00888447
	LOSS [training: 1.1053836684765113 | validation: 0.9600008130769883]
	TIME [epoch: 9.51 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7682744217280718		[learning rate: 0.008863]
	Learning Rate: 0.00886296
	LOSS [training: 0.7682744217280718 | validation: 1.219879835280027]
	TIME [epoch: 9.52 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0252119774690318		[learning rate: 0.0088415]
	Learning Rate: 0.00884151
	LOSS [training: 1.0252119774690318 | validation: 1.0183957489648985]
	TIME [epoch: 9.52 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8433486773119897		[learning rate: 0.0088201]
	Learning Rate: 0.0088201
	LOSS [training: 0.8433486773119897 | validation: 0.6143063337822682]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_152.pth
	Model improved!!!
EPOCH 153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.751563117713783		[learning rate: 0.0087988]
	Learning Rate: 0.00879875
	LOSS [training: 0.751563117713783 | validation: 1.022370336568296]
	TIME [epoch: 9.52 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7761269722019948		[learning rate: 0.0087775]
	Learning Rate: 0.00877745
	LOSS [training: 0.7761269722019948 | validation: 0.72281439870534]
	TIME [epoch: 9.54 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9404263615662802		[learning rate: 0.0087562]
	Learning Rate: 0.0087562
	LOSS [training: 0.9404263615662802 | validation: 0.7696909835584128]
	TIME [epoch: 9.51 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9729084156401907		[learning rate: 0.008735]
	Learning Rate: 0.008735
	LOSS [training: 0.9729084156401907 | validation: 0.8734495484318902]
	TIME [epoch: 9.52 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9953361017939768		[learning rate: 0.0087139]
	Learning Rate: 0.00871386
	LOSS [training: 0.9953361017939768 | validation: 1.054815923552311]
	TIME [epoch: 9.53 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8801363439613896		[learning rate: 0.0086928]
	Learning Rate: 0.00869276
	LOSS [training: 0.8801363439613896 | validation: 0.7130791365651012]
	TIME [epoch: 9.52 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8473966306170077		[learning rate: 0.0086717]
	Learning Rate: 0.00867172
	LOSS [training: 0.8473966306170077 | validation: 0.8548928884886065]
	TIME [epoch: 9.52 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8464215916043667		[learning rate: 0.0086507]
	Learning Rate: 0.00865073
	LOSS [training: 0.8464215916043667 | validation: 0.6807805524963653]
	TIME [epoch: 9.52 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7259021457453663		[learning rate: 0.0086298]
	Learning Rate: 0.00862979
	LOSS [training: 0.7259021457453663 | validation: 0.61553134559392]
	TIME [epoch: 9.53 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7254116990194875		[learning rate: 0.0086089]
	Learning Rate: 0.00860889
	LOSS [training: 0.7254116990194875 | validation: 1.0383118895773058]
	TIME [epoch: 9.51 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.648948522022868		[learning rate: 0.0085881]
	Learning Rate: 0.00858805
	LOSS [training: 1.648948522022868 | validation: 0.9753573864918079]
	TIME [epoch: 9.51 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9041195639856063		[learning rate: 0.0085673]
	Learning Rate: 0.00856726
	LOSS [training: 0.9041195639856063 | validation: 0.759452340825431]
	TIME [epoch: 9.53 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7944429106431427		[learning rate: 0.0085465]
	Learning Rate: 0.00854652
	LOSS [training: 0.7944429106431427 | validation: 0.5954907371635254]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_165.pth
	Model improved!!!
EPOCH 166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8054425357147028		[learning rate: 0.0085258]
	Learning Rate: 0.00852583
	LOSS [training: 0.8054425357147028 | validation: 0.7913988554707473]
	TIME [epoch: 9.53 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7723694834691717		[learning rate: 0.0085052]
	Learning Rate: 0.00850519
	LOSS [training: 0.7723694834691717 | validation: 2.4973059790688303]
	TIME [epoch: 9.53 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.619713126959791		[learning rate: 0.0084846]
	Learning Rate: 0.0084846
	LOSS [training: 2.619713126959791 | validation: 1.7169485088066025]
	TIME [epoch: 9.55 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.321740296794617		[learning rate: 0.0084641]
	Learning Rate: 0.00846406
	LOSS [training: 1.321740296794617 | validation: 0.6552817237871503]
	TIME [epoch: 9.53 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7268420470259571		[learning rate: 0.0084436]
	Learning Rate: 0.00844357
	LOSS [training: 0.7268420470259571 | validation: 0.6463798197534634]
	TIME [epoch: 9.53 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6913178609645257		[learning rate: 0.0084231]
	Learning Rate: 0.00842313
	LOSS [training: 0.6913178609645257 | validation: 0.5798289191118298]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_171.pth
	Model improved!!!
EPOCH 172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.705884583390583		[learning rate: 0.0084027]
	Learning Rate: 0.00840274
	LOSS [training: 0.705884583390583 | validation: 1.813192968455603]
	TIME [epoch: 9.53 sec]
EPOCH 173/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.439980968341664		[learning rate: 0.0083824]
	Learning Rate: 0.0083824
	LOSS [training: 2.439980968341664 | validation: 2.927409445223267]
	TIME [epoch: 9.53 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9171694476214496		[learning rate: 0.0083621]
	Learning Rate: 0.00836211
	LOSS [training: 2.9171694476214496 | validation: 1.7749753618500999]
	TIME [epoch: 9.54 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0873729134496606		[learning rate: 0.0083419]
	Learning Rate: 0.00834186
	LOSS [training: 2.0873729134496606 | validation: 1.1202264000422801]
	TIME [epoch: 9.55 sec]
EPOCH 176/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2769295419675393		[learning rate: 0.0083217]
	Learning Rate: 0.00832167
	LOSS [training: 1.2769295419675393 | validation: 0.5923766130406745]
	TIME [epoch: 9.53 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2198957619046946		[learning rate: 0.0083015]
	Learning Rate: 0.00830153
	LOSS [training: 1.2198957619046946 | validation: 0.8296763874490375]
	TIME [epoch: 9.53 sec]
EPOCH 178/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5431555068192044		[learning rate: 0.0082814]
	Learning Rate: 0.00828143
	LOSS [training: 1.5431555068192044 | validation: 0.7941683867919528]
	TIME [epoch: 9.55 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7495305836010164		[learning rate: 0.0082614]
	Learning Rate: 0.00826138
	LOSS [training: 0.7495305836010164 | validation: 0.7959419136099646]
	TIME [epoch: 9.54 sec]
EPOCH 180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6789790477045095		[learning rate: 0.0082414]
	Learning Rate: 0.00824138
	LOSS [training: 0.6789790477045095 | validation: 0.7607433891869437]
	TIME [epoch: 9.53 sec]
EPOCH 181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8684863773785401		[learning rate: 0.0082214]
	Learning Rate: 0.00822143
	LOSS [training: 0.8684863773785401 | validation: 0.8014423521926276]
	TIME [epoch: 9.54 sec]
EPOCH 182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7715372539584314		[learning rate: 0.0082015]
	Learning Rate: 0.00820153
	LOSS [training: 0.7715372539584314 | validation: 1.5287100352410834]
	TIME [epoch: 9.54 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1495878559771673		[learning rate: 0.0081817]
	Learning Rate: 0.00818167
	LOSS [training: 1.1495878559771673 | validation: 0.801911016802226]
	TIME [epoch: 9.53 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7829657258740422		[learning rate: 0.0081619]
	Learning Rate: 0.00816187
	LOSS [training: 0.7829657258740422 | validation: 1.755760426113654]
	TIME [epoch: 9.53 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0085973694531123		[learning rate: 0.0081421]
	Learning Rate: 0.00814211
	LOSS [training: 1.0085973694531123 | validation: 1.2255595624580107]
	TIME [epoch: 9.54 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9151133333691535		[learning rate: 0.0081224]
	Learning Rate: 0.0081224
	LOSS [training: 0.9151133333691535 | validation: 0.5869351871387339]
	TIME [epoch: 9.53 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.0422670931165374		[learning rate: 0.0081027]
	Learning Rate: 0.00810273
	LOSS [training: 1.0422670931165374 | validation: 1.2255332054110561]
	TIME [epoch: 9.53 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9028929752110637		[learning rate: 0.0080831]
	Learning Rate: 0.00808312
	LOSS [training: 0.9028929752110637 | validation: 0.6327635700855336]
	TIME [epoch: 9.54 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.69842265264659		[learning rate: 0.0080636]
	Learning Rate: 0.00806355
	LOSS [training: 0.69842265264659 | validation: 0.862477536072351]
	TIME [epoch: 9.53 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8823729853381987		[learning rate: 0.008044]
	Learning Rate: 0.00804403
	LOSS [training: 0.8823729853381987 | validation: 0.7051907642694163]
	TIME [epoch: 9.52 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8367843497885266		[learning rate: 0.0080246]
	Learning Rate: 0.00802456
	LOSS [training: 0.8367843497885266 | validation: 0.7340784701840977]
	TIME [epoch: 9.53 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.698785837483385		[learning rate: 0.0080051]
	Learning Rate: 0.00800513
	LOSS [training: 0.698785837483385 | validation: 0.6190609069007291]
	TIME [epoch: 9.54 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6516975429543054		[learning rate: 0.0079858]
	Learning Rate: 0.00798575
	LOSS [training: 0.6516975429543054 | validation: 0.7868001349389095]
	TIME [epoch: 9.53 sec]
EPOCH 194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7461551663392342		[learning rate: 0.0079664]
	Learning Rate: 0.00796642
	LOSS [training: 0.7461551663392342 | validation: 1.2772855742381748]
	TIME [epoch: 9.52 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9962261262689776		[learning rate: 0.0079471]
	Learning Rate: 0.00794713
	LOSS [training: 0.9962261262689776 | validation: 0.5365852057636509]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5817511544422191		[learning rate: 0.0079279]
	Learning Rate: 0.00792789
	LOSS [training: 0.5817511544422191 | validation: 0.6953019273826797]
	TIME [epoch: 9.53 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8726837335773924		[learning rate: 0.0079087]
	Learning Rate: 0.0079087
	LOSS [training: 0.8726837335773924 | validation: 0.5626381037192172]
	TIME [epoch: 9.52 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6080973132740518		[learning rate: 0.0078896]
	Learning Rate: 0.00788956
	LOSS [training: 0.6080973132740518 | validation: 0.6590696494673793]
	TIME [epoch: 9.52 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7849345470542552		[learning rate: 0.0078705]
	Learning Rate: 0.00787046
	LOSS [training: 0.7849345470542552 | validation: 0.7200990928763642]
	TIME [epoch: 9.54 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6753537855452387		[learning rate: 0.0078514]
	Learning Rate: 0.0078514
	LOSS [training: 0.6753537855452387 | validation: 0.6546752679761052]
	TIME [epoch: 9.52 sec]
EPOCH 201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6579410440647242		[learning rate: 0.0078324]
	Learning Rate: 0.0078324
	LOSS [training: 0.6579410440647242 | validation: 0.5957404756921797]
	TIME [epoch: 9.52 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6819329832748141		[learning rate: 0.0078134]
	Learning Rate: 0.00781344
	LOSS [training: 0.6819329832748141 | validation: 0.7563750376316547]
	TIME [epoch: 9.54 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7130314602004264		[learning rate: 0.0077945]
	Learning Rate: 0.00779452
	LOSS [training: 0.7130314602004264 | validation: 0.4875229767044425]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193651819881157		[learning rate: 0.0077757]
	Learning Rate: 0.00777565
	LOSS [training: 0.5193651819881157 | validation: 0.5096119953966772]
	TIME [epoch: 9.52 sec]
EPOCH 205/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.5784827502514207		[learning rate: 0.0077568]
	Learning Rate: 0.00775683
	LOSS [training: 1.5784827502514207 | validation: 2.1483878396172185]
	TIME [epoch: 9.51 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4317103923304997		[learning rate: 0.0077381]
	Learning Rate: 0.00773805
	LOSS [training: 1.4317103923304997 | validation: 0.5856648828619672]
	TIME [epoch: 9.54 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.249338109553126		[learning rate: 0.0077193]
	Learning Rate: 0.00771932
	LOSS [training: 1.249338109553126 | validation: 1.097030080844424]
	TIME [epoch: 9.53 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.883159078321024		[learning rate: 0.0077006]
	Learning Rate: 0.00770063
	LOSS [training: 0.883159078321024 | validation: 1.3649040028703696]
	TIME [epoch: 9.52 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.660342796293946		[learning rate: 0.007682]
	Learning Rate: 0.00768199
	LOSS [training: 2.660342796293946 | validation: 2.3981972877711857]
	TIME [epoch: 9.54 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.8568678614737792		[learning rate: 0.0076634]
	Learning Rate: 0.00766339
	LOSS [training: 2.8568678614737792 | validation: 2.302711758795266]
	TIME [epoch: 9.52 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.0052739710371794		[learning rate: 0.0076448]
	Learning Rate: 0.00764484
	LOSS [training: 3.0052739710371794 | validation: 2.458464139675276]
	TIME [epoch: 9.52 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.6303361702948336		[learning rate: 0.0076263]
	Learning Rate: 0.00762633
	LOSS [training: 1.6303361702948336 | validation: 0.7006623089923903]
	TIME [epoch: 9.52 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6314735289368447		[learning rate: 0.0076079]
	Learning Rate: 0.00760787
	LOSS [training: 0.6314735289368447 | validation: 0.4996296001904584]
	TIME [epoch: 9.54 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5126384159733338		[learning rate: 0.0075895]
	Learning Rate: 0.00758945
	LOSS [training: 0.5126384159733338 | validation: 0.5290281041111262]
	TIME [epoch: 9.52 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7195717382891331		[learning rate: 0.0075711]
	Learning Rate: 0.00757108
	LOSS [training: 0.7195717382891331 | validation: 2.7371474663941275]
	TIME [epoch: 9.52 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6932508581020267		[learning rate: 0.0075528]
	Learning Rate: 0.00755275
	LOSS [training: 2.6932508581020267 | validation: 1.0576501879461961]
	TIME [epoch: 9.53 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8363416091943634		[learning rate: 0.0075345]
	Learning Rate: 0.00753447
	LOSS [training: 0.8363416091943634 | validation: 0.49580170616853325]
	TIME [epoch: 9.52 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5494114037229293		[learning rate: 0.0075162]
	Learning Rate: 0.00751623
	LOSS [training: 0.5494114037229293 | validation: 0.5925329180429866]
	TIME [epoch: 9.52 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6595931918716585		[learning rate: 0.007498]
	Learning Rate: 0.00749803
	LOSS [training: 0.6595931918716585 | validation: 0.7130985139800389]
	TIME [epoch: 9.52 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6868076666675509		[learning rate: 0.0074799]
	Learning Rate: 0.00747988
	LOSS [training: 0.6868076666675509 | validation: 0.6762080986410481]
	TIME [epoch: 9.53 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6460478921812853		[learning rate: 0.0074618]
	Learning Rate: 0.00746177
	LOSS [training: 0.6460478921812853 | validation: 0.6884775786135074]
	TIME [epoch: 9.52 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7584404337629647		[learning rate: 0.0074437]
	Learning Rate: 0.00744371
	LOSS [training: 0.7584404337629647 | validation: 0.83909102796685]
	TIME [epoch: 9.52 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6826449489450459		[learning rate: 0.0074257]
	Learning Rate: 0.00742569
	LOSS [training: 0.6826449489450459 | validation: 0.651859763800069]
	TIME [epoch: 9.54 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6227713364202715		[learning rate: 0.0074077]
	Learning Rate: 0.00740771
	LOSS [training: 0.6227713364202715 | validation: 0.47136064195041444]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_224.pth
	Model improved!!!
EPOCH 225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.538759718119822		[learning rate: 0.0073898]
	Learning Rate: 0.00738978
	LOSS [training: 0.538759718119822 | validation: 0.7612640995662753]
	TIME [epoch: 9.52 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8332640776106395		[learning rate: 0.0073719]
	Learning Rate: 0.00737189
	LOSS [training: 0.8332640776106395 | validation: 0.5683796878438326]
	TIME [epoch: 9.52 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1685997101383092		[learning rate: 0.007354]
	Learning Rate: 0.00735405
	LOSS [training: 1.1685997101383092 | validation: 0.5907658027214244]
	TIME [epoch: 9.54 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6130153757127443		[learning rate: 0.0073362]
	Learning Rate: 0.00733624
	LOSS [training: 0.6130153757127443 | validation: 0.5594580371326293]
	TIME [epoch: 9.52 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5105262675211563		[learning rate: 0.0073185]
	Learning Rate: 0.00731848
	LOSS [training: 0.5105262675211563 | validation: 0.4837802848284092]
	TIME [epoch: 9.52 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4771688399963864		[learning rate: 0.0073008]
	Learning Rate: 0.00730077
	LOSS [training: 0.4771688399963864 | validation: 0.46893900693430696]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_230.pth
	Model improved!!!
EPOCH 231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5723949847460309		[learning rate: 0.0072831]
	Learning Rate: 0.00728309
	LOSS [training: 0.5723949847460309 | validation: 0.7213257348342547]
	TIME [epoch: 9.53 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5129109625141159		[learning rate: 0.0072655]
	Learning Rate: 0.00726546
	LOSS [training: 0.5129109625141159 | validation: 0.4245047086044393]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_232.pth
	Model improved!!!
EPOCH 233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7249389790539278		[learning rate: 0.0072479]
	Learning Rate: 0.00724787
	LOSS [training: 0.7249389790539278 | validation: 0.6388218935843015]
	TIME [epoch: 9.54 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.603449080639881		[learning rate: 0.0072303]
	Learning Rate: 0.00723033
	LOSS [training: 0.603449080639881 | validation: 0.42822782936004034]
	TIME [epoch: 9.53 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.1547409691248034		[learning rate: 0.0072128]
	Learning Rate: 0.00721282
	LOSS [training: 2.1547409691248034 | validation: 3.44740752263117]
	TIME [epoch: 9.52 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.94481316674038		[learning rate: 0.0071954]
	Learning Rate: 0.00719536
	LOSS [training: 3.94481316674038 | validation: 2.739875728645809]
	TIME [epoch: 9.52 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.09554962551847		[learning rate: 0.0071779]
	Learning Rate: 0.00717794
	LOSS [training: 3.09554962551847 | validation: 2.239471751822908]
	TIME [epoch: 9.55 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.4548506511345805		[learning rate: 0.0071606]
	Learning Rate: 0.00716057
	LOSS [training: 3.4548506511345805 | validation: 3.8010512211520355]
	TIME [epoch: 9.52 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.048270899160311		[learning rate: 0.0071432]
	Learning Rate: 0.00714323
	LOSS [training: 2.048270899160311 | validation: 0.9730258242224877]
	TIME [epoch: 9.52 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7128507700141882		[learning rate: 0.0071259]
	Learning Rate: 0.00712594
	LOSS [training: 0.7128507700141882 | validation: 0.6323760213478937]
	TIME [epoch: 9.53 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5445353586918235		[learning rate: 0.0071087]
	Learning Rate: 0.00710869
	LOSS [training: 0.5445353586918235 | validation: 0.682059009083422]
	TIME [epoch: 9.53 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5152856767049967		[learning rate: 0.0070915]
	Learning Rate: 0.00709148
	LOSS [training: 0.5152856767049967 | validation: 1.7171014733610925]
	TIME [epoch: 9.52 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2032890649277057		[learning rate: 0.0070743]
	Learning Rate: 0.00707431
	LOSS [training: 1.2032890649277057 | validation: 0.47461200043690954]
	TIME [epoch: 9.52 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5995339019382919		[learning rate: 0.0070572]
	Learning Rate: 0.00705719
	LOSS [training: 0.5995339019382919 | validation: 0.49815633976361035]
	TIME [epoch: 9.54 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6145705454476841		[learning rate: 0.0070401]
	Learning Rate: 0.0070401
	LOSS [training: 0.6145705454476841 | validation: 0.4739098371926467]
	TIME [epoch: 9.52 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47442197661228447		[learning rate: 0.0070231]
	Learning Rate: 0.00702306
	LOSS [training: 0.47442197661228447 | validation: 0.5049425619361477]
	TIME [epoch: 9.52 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4753061960126635		[learning rate: 0.0070061]
	Learning Rate: 0.00700606
	LOSS [training: 0.4753061960126635 | validation: 0.39412694409402593]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_247.pth
	Model improved!!!
EPOCH 248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5680056077005047		[learning rate: 0.0069891]
	Learning Rate: 0.0069891
	LOSS [training: 0.5680056077005047 | validation: 0.4263040478675194]
	TIME [epoch: 9.52 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5011547113001444		[learning rate: 0.0069722]
	Learning Rate: 0.00697218
	LOSS [training: 0.5011547113001444 | validation: 0.6305645242515987]
	TIME [epoch: 9.5 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.651225618330741		[learning rate: 0.0069553]
	Learning Rate: 0.0069553
	LOSS [training: 1.651225618330741 | validation: 1.593147530260431]
	TIME [epoch: 9.51 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1471120194635698		[learning rate: 0.0069385]
	Learning Rate: 0.00693846
	LOSS [training: 1.1471120194635698 | validation: 0.3710024982784486]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_251.pth
	Model improved!!!
EPOCH 252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5256318173540997		[learning rate: 0.0069217]
	Learning Rate: 0.00692166
	LOSS [training: 0.5256318173540997 | validation: 0.4513928762503221]
	TIME [epoch: 9.52 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9012100129782187		[learning rate: 0.0069049]
	Learning Rate: 0.00690491
	LOSS [training: 0.9012100129782187 | validation: 0.8058654426534264]
	TIME [epoch: 9.52 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5342731477560828		[learning rate: 0.0068882]
	Learning Rate: 0.00688819
	LOSS [training: 0.5342731477560828 | validation: 0.5452397957131219]
	TIME [epoch: 9.53 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6362720428956754		[learning rate: 0.0068715]
	Learning Rate: 0.00687152
	LOSS [training: 0.6362720428956754 | validation: 0.6077267306889435]
	TIME [epoch: 9.52 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5832033277862504		[learning rate: 0.0068549]
	Learning Rate: 0.00685488
	LOSS [training: 0.5832033277862504 | validation: 0.4550173250887848]
	TIME [epoch: 9.51 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42201771074266226		[learning rate: 0.0068383]
	Learning Rate: 0.00683829
	LOSS [training: 0.42201771074266226 | validation: 0.3603260442216434]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_257.pth
	Model improved!!!
EPOCH 258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6670714510681681		[learning rate: 0.0068217]
	Learning Rate: 0.00682173
	LOSS [training: 0.6670714510681681 | validation: 0.5640922172121341]
	TIME [epoch: 9.54 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4740740142520828		[learning rate: 0.0068052]
	Learning Rate: 0.00680522
	LOSS [training: 0.4740740142520828 | validation: 0.4344433667697678]
	TIME [epoch: 9.76 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.209922621563296		[learning rate: 0.0067887]
	Learning Rate: 0.00678874
	LOSS [training: 1.209922621563296 | validation: 1.8652338243049982]
	TIME [epoch: 9.53 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.76223339739903		[learning rate: 0.0067723]
	Learning Rate: 0.00677231
	LOSS [training: 1.76223339739903 | validation: 0.670067342711591]
	TIME [epoch: 9.55 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4741416754641195		[learning rate: 0.0067559]
	Learning Rate: 0.00675592
	LOSS [training: 0.4741416754641195 | validation: 0.5552143534372767]
	TIME [epoch: 9.53 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.658437648990007		[learning rate: 0.0067396]
	Learning Rate: 0.00673956
	LOSS [training: 0.658437648990007 | validation: 0.8990334439078558]
	TIME [epoch: 9.53 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6303583073241688		[learning rate: 0.0067232]
	Learning Rate: 0.00672325
	LOSS [training: 0.6303583073241688 | validation: 0.5412914420764515]
	TIME [epoch: 9.53 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.668635498212904		[learning rate: 0.006707]
	Learning Rate: 0.00670697
	LOSS [training: 0.668635498212904 | validation: 0.4735167868185295]
	TIME [epoch: 9.55 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42053199715407663		[learning rate: 0.0066907]
	Learning Rate: 0.00669073
	LOSS [training: 0.42053199715407663 | validation: 0.5259725630984977]
	TIME [epoch: 9.53 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5452789243437942		[learning rate: 0.0066745]
	Learning Rate: 0.00667454
	LOSS [training: 0.5452789243437942 | validation: 0.7960275152354782]
	TIME [epoch: 9.53 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6655797679894978		[learning rate: 0.0066584]
	Learning Rate: 0.00665838
	LOSS [training: 0.6655797679894978 | validation: 0.5811845393408511]
	TIME [epoch: 9.55 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5544469444409261		[learning rate: 0.0066423]
	Learning Rate: 0.00664226
	LOSS [training: 0.5544469444409261 | validation: 0.4956835959711705]
	TIME [epoch: 9.53 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41800330133060026		[learning rate: 0.0066262]
	Learning Rate: 0.00662618
	LOSS [training: 0.41800330133060026 | validation: 0.5853591583822859]
	TIME [epoch: 9.53 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5273401327863881		[learning rate: 0.0066101]
	Learning Rate: 0.00661014
	LOSS [training: 0.5273401327863881 | validation: 0.34881279741925]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_271.pth
	Model improved!!!
EPOCH 272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4435764038366018		[learning rate: 0.0065941]
	Learning Rate: 0.00659414
	LOSS [training: 0.4435764038366018 | validation: 0.45430062536553645]
	TIME [epoch: 9.54 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5742285948198209		[learning rate: 0.0065782]
	Learning Rate: 0.00657817
	LOSS [training: 0.5742285948198209 | validation: 0.8116175007903076]
	TIME [epoch: 9.53 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5953137468728498		[learning rate: 0.0065622]
	Learning Rate: 0.00656225
	LOSS [training: 0.5953137468728498 | validation: 0.4332261220567137]
	TIME [epoch: 9.53 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6310541013957637		[learning rate: 0.0065464]
	Learning Rate: 0.00654636
	LOSS [training: 0.6310541013957637 | validation: 0.436028981630606]
	TIME [epoch: 9.55 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4121428722932253		[learning rate: 0.0065305]
	Learning Rate: 0.00653051
	LOSS [training: 0.4121428722932253 | validation: 0.3792497793817273]
	TIME [epoch: 9.53 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3656686567937023		[learning rate: 0.0065147]
	Learning Rate: 0.0065147
	LOSS [training: 0.3656686567937023 | validation: 0.39053703256445077]
	TIME [epoch: 9.52 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5303181567319599		[learning rate: 0.0064989]
	Learning Rate: 0.00649893
	LOSS [training: 0.5303181567319599 | validation: 0.49207409104976435]
	TIME [epoch: 9.54 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5407697272806115		[learning rate: 0.0064832]
	Learning Rate: 0.0064832
	LOSS [training: 0.5407697272806115 | validation: 0.5451745799015609]
	TIME [epoch: 9.54 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6755652757279372		[learning rate: 0.0064675]
	Learning Rate: 0.00646751
	LOSS [training: 0.6755652757279372 | validation: 0.6603891138543867]
	TIME [epoch: 9.53 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7988102617327268		[learning rate: 0.0064518]
	Learning Rate: 0.00645185
	LOSS [training: 0.7988102617327268 | validation: 0.4220036037829277]
	TIME [epoch: 9.53 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38654356382232613		[learning rate: 0.0064362]
	Learning Rate: 0.00643623
	LOSS [training: 0.38654356382232613 | validation: 0.5086401456758872]
	TIME [epoch: 9.55 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7502533461234984		[learning rate: 0.0064206]
	Learning Rate: 0.00642065
	LOSS [training: 0.7502533461234984 | validation: 0.43377743980066724]
	TIME [epoch: 9.52 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4797506549816199		[learning rate: 0.0064051]
	Learning Rate: 0.00640511
	LOSS [training: 0.4797506549816199 | validation: 0.47988094495750383]
	TIME [epoch: 9.53 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4758256200494725		[learning rate: 0.0063896]
	Learning Rate: 0.0063896
	LOSS [training: 0.4758256200494725 | validation: 0.371130227749219]
	TIME [epoch: 9.54 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46511257565343334		[learning rate: 0.0063741]
	Learning Rate: 0.00637413
	LOSS [training: 0.46511257565343334 | validation: 0.32341736836336993]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_286.pth
	Model improved!!!
EPOCH 287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4122103931227297		[learning rate: 0.0063587]
	Learning Rate: 0.0063587
	LOSS [training: 0.4122103931227297 | validation: 0.40062195819659374]
	TIME [epoch: 9.52 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6071116937785874		[learning rate: 0.0063433]
	Learning Rate: 0.00634331
	LOSS [training: 0.6071116937785874 | validation: 0.755066595146669]
	TIME [epoch: 9.52 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5520470752032355		[learning rate: 0.006328]
	Learning Rate: 0.00632795
	LOSS [training: 0.5520470752032355 | validation: 0.5436051808547762]
	TIME [epoch: 9.54 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42347559534083185		[learning rate: 0.0063126]
	Learning Rate: 0.00631263
	LOSS [training: 0.42347559534083185 | validation: 0.356983986442694]
	TIME [epoch: 9.53 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5811946356914285		[learning rate: 0.0062974]
	Learning Rate: 0.00629735
	LOSS [training: 0.5811946356914285 | validation: 0.45009782474521737]
	TIME [epoch: 9.52 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4448190297317204		[learning rate: 0.0062821]
	Learning Rate: 0.00628211
	LOSS [training: 0.4448190297317204 | validation: 0.4514239330783043]
	TIME [epoch: 9.54 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3519547345562434		[learning rate: 0.0062669]
	Learning Rate: 0.0062669
	LOSS [training: 0.3519547345562434 | validation: 0.5905503429125826]
	TIME [epoch: 9.52 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4148841578134054		[learning rate: 0.0062517]
	Learning Rate: 0.00625173
	LOSS [training: 0.4148841578134054 | validation: 0.6044845086337101]
	TIME [epoch: 9.52 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.444529799010885		[learning rate: 0.0062366]
	Learning Rate: 0.00623659
	LOSS [training: 0.444529799010885 | validation: 0.28207741485889704]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_295.pth
	Model improved!!!
EPOCH 296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9527328425799014		[learning rate: 0.0062215]
	Learning Rate: 0.00622149
	LOSS [training: 0.9527328425799014 | validation: 1.3190639374618076]
	TIME [epoch: 9.55 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7753674561454996		[learning rate: 0.0062064]
	Learning Rate: 0.00620643
	LOSS [training: 0.7753674561454996 | validation: 0.3655337641209269]
	TIME [epoch: 9.52 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32886209625960494		[learning rate: 0.0061914]
	Learning Rate: 0.00619141
	LOSS [training: 0.32886209625960494 | validation: 0.41989372540355546]
	TIME [epoch: 9.51 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4566978068635665		[learning rate: 0.0061764]
	Learning Rate: 0.00617642
	LOSS [training: 0.4566978068635665 | validation: 0.3694071248391284]
	TIME [epoch: 9.54 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.512080236156673		[learning rate: 0.0061615]
	Learning Rate: 0.00616147
	LOSS [training: 0.512080236156673 | validation: 0.4205040067914999]
	TIME [epoch: 9.52 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.563349302004078		[learning rate: 0.0061466]
	Learning Rate: 0.00614655
	LOSS [training: 0.563349302004078 | validation: 0.38595998950863303]
	TIME [epoch: 9.51 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4524642517098493		[learning rate: 0.0061317]
	Learning Rate: 0.00613167
	LOSS [training: 0.4524642517098493 | validation: 0.3185170751166122]
	TIME [epoch: 9.51 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33684735990534564		[learning rate: 0.0061168]
	Learning Rate: 0.00611683
	LOSS [training: 0.33684735990534564 | validation: 0.33750466967813436]
	TIME [epoch: 9.54 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45512365361416585		[learning rate: 0.006102]
	Learning Rate: 0.00610202
	LOSS [training: 0.45512365361416585 | validation: 0.6374790919392751]
	TIME [epoch: 9.51 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.584266579416582		[learning rate: 0.0060872]
	Learning Rate: 0.00608725
	LOSS [training: 0.584266579416582 | validation: 0.6074815059802022]
	TIME [epoch: 9.52 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4875903462082875		[learning rate: 0.0060725]
	Learning Rate: 0.00607251
	LOSS [training: 0.4875903462082875 | validation: 0.3012749060799233]
	TIME [epoch: 9.54 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33222985886374257		[learning rate: 0.0060578]
	Learning Rate: 0.00605781
	LOSS [training: 0.33222985886374257 | validation: 0.3551471233977436]
	TIME [epoch: 9.52 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7045056405651691		[learning rate: 0.0060431]
	Learning Rate: 0.00604315
	LOSS [training: 0.7045056405651691 | validation: 2.7247035885396076]
	TIME [epoch: 9.51 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.9636157201089954		[learning rate: 0.0060285]
	Learning Rate: 0.00602852
	LOSS [training: 2.9636157201089954 | validation: 2.202934391544061]
	TIME [epoch: 9.51 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7962803824500795		[learning rate: 0.0060139]
	Learning Rate: 0.00601392
	LOSS [training: 2.7962803824500795 | validation: 2.1734016866911805]
	TIME [epoch: 9.54 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.806425305033607		[learning rate: 0.0059994]
	Learning Rate: 0.00599936
	LOSS [training: 2.806425305033607 | validation: 2.1339783317235894]
	TIME [epoch: 9.51 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.750764717104911		[learning rate: 0.0059848]
	Learning Rate: 0.00598484
	LOSS [training: 2.750764717104911 | validation: 2.141148591910099]
	TIME [epoch: 9.52 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 5/5] avg loss: 3.298924977621445		[learning rate: 0.0059704]
	Learning Rate: 0.00597035
	LOSS [training: 3.298924977621445 | validation: 2.192740179368232]
	TIME [epoch: 9.53 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.846950242914282		[learning rate: 0.0059559]
	Learning Rate: 0.0059559
	LOSS [training: 2.846950242914282 | validation: 2.1574606988266742]
	TIME [epoch: 9.52 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.0335959323534163		[learning rate: 0.0059415]
	Learning Rate: 0.00594148
	LOSS [training: 2.0335959323534163 | validation: 1.8909804747726582]
	TIME [epoch: 9.52 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.678085637916615		[learning rate: 0.0059271]
	Learning Rate: 0.0059271
	LOSS [training: 2.678085637916615 | validation: 2.2282885094389524]
	TIME [epoch: 9.52 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.514297528374441		[learning rate: 0.0059127]
	Learning Rate: 0.00591275
	LOSS [training: 2.514297528374441 | validation: 0.8996463396747026]
	TIME [epoch: 9.54 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7486024043629196		[learning rate: 0.0058984]
	Learning Rate: 0.00589844
	LOSS [training: 0.7486024043629196 | validation: 0.5448989744407485]
	TIME [epoch: 9.52 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48986910453081955		[learning rate: 0.0058842]
	Learning Rate: 0.00588416
	LOSS [training: 0.48986910453081955 | validation: 0.4504171304222755]
	TIME [epoch: 9.52 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6070477767187736		[learning rate: 0.0058699]
	Learning Rate: 0.00586991
	LOSS [training: 0.6070477767187736 | validation: 0.4376273618901577]
	TIME [epoch: 9.54 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3699328999997073		[learning rate: 0.0058557]
	Learning Rate: 0.0058557
	LOSS [training: 0.3699328999997073 | validation: 0.4295134641451848]
	TIME [epoch: 9.52 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3710707685934461		[learning rate: 0.0058415]
	Learning Rate: 0.00584153
	LOSS [training: 0.3710707685934461 | validation: 0.4401626081316692]
	TIME [epoch: 9.52 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45773619586633085		[learning rate: 0.0058274]
	Learning Rate: 0.00582738
	LOSS [training: 0.45773619586633085 | validation: 0.4510951660957844]
	TIME [epoch: 9.52 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39044461091107896		[learning rate: 0.0058133]
	Learning Rate: 0.00581328
	LOSS [training: 0.39044461091107896 | validation: 0.4637827002443624]
	TIME [epoch: 9.53 sec]
EPOCH 325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38117540808759165		[learning rate: 0.0057992]
	Learning Rate: 0.0057992
	LOSS [training: 0.38117540808759165 | validation: 0.43114465238027927]
	TIME [epoch: 9.52 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45354949001667205		[learning rate: 0.0057852]
	Learning Rate: 0.00578517
	LOSS [training: 0.45354949001667205 | validation: 0.6481874442620904]
	TIME [epoch: 9.52 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5733313374862506		[learning rate: 0.0057712]
	Learning Rate: 0.00577116
	LOSS [training: 0.5733313374862506 | validation: 0.4539024188364463]
	TIME [epoch: 9.53 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44728636482235745		[learning rate: 0.0057572]
	Learning Rate: 0.00575719
	LOSS [training: 0.44728636482235745 | validation: 0.40922183982838156]
	TIME [epoch: 9.52 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3684484082872171		[learning rate: 0.0057433]
	Learning Rate: 0.00574325
	LOSS [training: 0.3684484082872171 | validation: 0.4976288359838409]
	TIME [epoch: 9.52 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.446735505996389		[learning rate: 0.0057293]
	Learning Rate: 0.00572935
	LOSS [training: 0.446735505996389 | validation: 0.3437920650672882]
	TIME [epoch: 9.52 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3912489528900978		[learning rate: 0.0057155]
	Learning Rate: 0.00571548
	LOSS [training: 0.3912489528900978 | validation: 0.4978830527405929]
	TIME [epoch: 9.52 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.584094675838682		[learning rate: 0.0057016]
	Learning Rate: 0.00570164
	LOSS [training: 0.584094675838682 | validation: 0.49415221239447493]
	TIME [epoch: 9.51 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6390183581245267		[learning rate: 0.0056878]
	Learning Rate: 0.00568784
	LOSS [training: 0.6390183581245267 | validation: 0.3267808394559387]
	TIME [epoch: 9.52 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9818473480384654		[learning rate: 0.0056741]
	Learning Rate: 0.00567407
	LOSS [training: 0.9818473480384654 | validation: 1.3929137930479605]
	TIME [epoch: 9.54 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.4767071874158937		[learning rate: 0.0056603]
	Learning Rate: 0.00566033
	LOSS [training: 1.4767071874158937 | validation: 2.0015012838988673]
	TIME [epoch: 9.52 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.6744615780617984		[learning rate: 0.0056466]
	Learning Rate: 0.00564663
	LOSS [training: 2.6744615780617984 | validation: 2.2202507432576066]
	TIME [epoch: 9.51 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.7708703229577494		[learning rate: 0.005633]
	Learning Rate: 0.00563296
	LOSS [training: 2.7708703229577494 | validation: 2.1386023194718375]
	TIME [epoch: 9.53 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 5/5] avg loss: 2.5389711793119933		[learning rate: 0.0056193]
	Learning Rate: 0.00561933
	LOSS [training: 2.5389711793119933 | validation: 1.0018951260034712]
	TIME [epoch: 9.52 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.7104209111162507		[learning rate: 0.0056057]
	Learning Rate: 0.00560572
	LOSS [training: 1.7104209111162507 | validation: 1.16089686309912]
	TIME [epoch: 9.52 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7711165448454389		[learning rate: 0.0055922]
	Learning Rate: 0.00559215
	LOSS [training: 0.7711165448454389 | validation: 0.4194933001401867]
	TIME [epoch: 9.52 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4245995196007851		[learning rate: 0.0055786]
	Learning Rate: 0.00557861
	LOSS [training: 0.4245995196007851 | validation: 0.684952211986488]
	TIME [epoch: 9.54 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5651990493060152		[learning rate: 0.0055651]
	Learning Rate: 0.00556511
	LOSS [training: 0.5651990493060152 | validation: 0.5497151732716791]
	TIME [epoch: 9.53 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4295286090365219		[learning rate: 0.0055516]
	Learning Rate: 0.00555164
	LOSS [training: 0.4295286090365219 | validation: 0.38959319950484983]
	TIME [epoch: 9.51 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37343513677077145		[learning rate: 0.0055382]
	Learning Rate: 0.0055382
	LOSS [training: 0.37343513677077145 | validation: 0.3969290981847932]
	TIME [epoch: 9.53 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.017764589104529		[learning rate: 0.0055248]
	Learning Rate: 0.00552479
	LOSS [training: 1.017764589104529 | validation: 0.7317986443572579]
	TIME [epoch: 9.53 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6673199685469587		[learning rate: 0.0055114]
	Learning Rate: 0.00551141
	LOSS [training: 0.6673199685469587 | validation: 0.6536239250623257]
	TIME [epoch: 9.52 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5648873375404582		[learning rate: 0.0054981]
	Learning Rate: 0.00549807
	LOSS [training: 0.5648873375404582 | validation: 0.35317845139186754]
	TIME [epoch: 9.52 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3637164206776268		[learning rate: 0.0054848]
	Learning Rate: 0.00548476
	LOSS [training: 0.3637164206776268 | validation: 0.3350230335862605]
	TIME [epoch: 9.54 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4394099669861852		[learning rate: 0.0054715]
	Learning Rate: 0.00547149
	LOSS [training: 0.4394099669861852 | validation: 0.43866387694741676]
	TIME [epoch: 9.52 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48055836510109895		[learning rate: 0.0054582]
	Learning Rate: 0.00545824
	LOSS [training: 0.48055836510109895 | validation: 0.757174388929407]
	TIME [epoch: 9.52 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.603944460204825		[learning rate: 0.005445]
	Learning Rate: 0.00544503
	LOSS [training: 0.603944460204825 | validation: 0.3980623987664235]
	TIME [epoch: 9.53 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4271208044271885		[learning rate: 0.0054318]
	Learning Rate: 0.00543184
	LOSS [training: 0.4271208044271885 | validation: 0.4590218245770075]
	TIME [epoch: 9.53 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5088550405856521		[learning rate: 0.0054187]
	Learning Rate: 0.0054187
	LOSS [training: 0.5088550405856521 | validation: 0.33643157882648694]
	TIME [epoch: 9.52 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34698849836338536		[learning rate: 0.0054056]
	Learning Rate: 0.00540558
	LOSS [training: 0.34698849836338536 | validation: 0.32030737289958333]
	TIME [epoch: 9.52 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40237943189643743		[learning rate: 0.0053925]
	Learning Rate: 0.00539249
	LOSS [training: 0.40237943189643743 | validation: 0.38258417762158387]
	TIME [epoch: 9.53 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3319526166086388		[learning rate: 0.0053794]
	Learning Rate: 0.00537944
	LOSS [training: 0.3319526166086388 | validation: 0.33704354811026227]
	TIME [epoch: 9.51 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5160094776405412		[learning rate: 0.0053664]
	Learning Rate: 0.00536641
	LOSS [training: 0.5160094776405412 | validation: 0.7055755299921738]
	TIME [epoch: 9.52 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6306324175505923		[learning rate: 0.0053534]
	Learning Rate: 0.00535342
	LOSS [training: 0.6306324175505923 | validation: 0.5264445114554246]
	TIME [epoch: 9.53 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40834616230022647		[learning rate: 0.0053405]
	Learning Rate: 0.00534046
	LOSS [training: 0.40834616230022647 | validation: 0.5257084017310761]
	TIME [epoch: 9.52 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7887689885730359		[learning rate: 0.0053275]
	Learning Rate: 0.00532754
	LOSS [training: 0.7887689885730359 | validation: 0.4727054291882896]
	TIME [epoch: 9.52 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5894424429126375		[learning rate: 0.0053146]
	Learning Rate: 0.00531464
	LOSS [training: 0.5894424429126375 | validation: 0.5657910692079658]
	TIME [epoch: 9.52 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38288190744605016		[learning rate: 0.0053018]
	Learning Rate: 0.00530177
	LOSS [training: 0.38288190744605016 | validation: 0.3624872895007232]
	TIME [epoch: 9.54 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3882443656326601		[learning rate: 0.0052889]
	Learning Rate: 0.00528894
	LOSS [training: 0.3882443656326601 | validation: 0.4346006210332385]
	TIME [epoch: 9.52 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44886985703278237		[learning rate: 0.0052761]
	Learning Rate: 0.00527613
	LOSS [training: 0.44886985703278237 | validation: 0.35339447929055384]
	TIME [epoch: 9.52 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5607448561790243		[learning rate: 0.0052634]
	Learning Rate: 0.00526336
	LOSS [training: 0.5607448561790243 | validation: 0.4488915294491481]
	TIME [epoch: 9.54 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40596495405826405		[learning rate: 0.0052506]
	Learning Rate: 0.00525062
	LOSS [training: 0.40596495405826405 | validation: 0.30916794514445184]
	TIME [epoch: 9.52 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3714124308410649		[learning rate: 0.0052379]
	Learning Rate: 0.00523791
	LOSS [training: 0.3714124308410649 | validation: 0.39224825959704535]
	TIME [epoch: 9.51 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42489117509718044		[learning rate: 0.0052252]
	Learning Rate: 0.00522523
	LOSS [training: 0.42489117509718044 | validation: 0.4903119886090866]
	TIME [epoch: 9.51 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38510865140167655		[learning rate: 0.0052126]
	Learning Rate: 0.00521258
	LOSS [training: 0.38510865140167655 | validation: 0.382679863288312]
	TIME [epoch: 9.53 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7137605446896556		[learning rate: 0.0052]
	Learning Rate: 0.00519996
	LOSS [training: 0.7137605446896556 | validation: 0.4233330058469693]
	TIME [epoch: 9.52 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.502781506382252		[learning rate: 0.0051874]
	Learning Rate: 0.00518737
	LOSS [training: 0.502781506382252 | validation: 0.5525890099103071]
	TIME [epoch: 9.51 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45217935910280704		[learning rate: 0.0051748]
	Learning Rate: 0.00517481
	LOSS [training: 0.45217935910280704 | validation: 0.3172491457925671]
	TIME [epoch: 9.54 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8295558463866863		[learning rate: 0.0051623]
	Learning Rate: 0.00516229
	LOSS [training: 0.8295558463866863 | validation: 0.4793681273278055]
	TIME [epoch: 9.52 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4357191970619014		[learning rate: 0.0051498]
	Learning Rate: 0.00514979
	LOSS [training: 0.4357191970619014 | validation: 0.45452760748853577]
	TIME [epoch: 9.51 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43817302735853125		[learning rate: 0.0051373]
	Learning Rate: 0.00513732
	LOSS [training: 0.43817302735853125 | validation: 0.5124656358835102]
	TIME [epoch: 9.52 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5432756498691086		[learning rate: 0.0051249]
	Learning Rate: 0.00512489
	LOSS [training: 0.5432756498691086 | validation: 0.5245491691309152]
	TIME [epoch: 9.54 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47463610080107854		[learning rate: 0.0051125]
	Learning Rate: 0.00511248
	LOSS [training: 0.47463610080107854 | validation: 0.5419000296356133]
	TIME [epoch: 9.52 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4507965949297854		[learning rate: 0.0051001]
	Learning Rate: 0.0051001
	LOSS [training: 0.4507965949297854 | validation: 0.3844878199616845]
	TIME [epoch: 9.52 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4399957546472151		[learning rate: 0.0050878]
	Learning Rate: 0.00508776
	LOSS [training: 0.4399957546472151 | validation: 0.4294318587904718]
	TIME [epoch: 9.54 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5019361599236059		[learning rate: 0.0050754]
	Learning Rate: 0.00507544
	LOSS [training: 0.5019361599236059 | validation: 0.7382617000751356]
	TIME [epoch: 9.52 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5365881946423399		[learning rate: 0.0050632]
	Learning Rate: 0.00506315
	LOSS [training: 0.5365881946423399 | validation: 0.3297976467572143]
	TIME [epoch: 9.52 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43114332502397695		[learning rate: 0.0050509]
	Learning Rate: 0.0050509
	LOSS [training: 0.43114332502397695 | validation: 0.5204982693545186]
	TIME [epoch: 9.52 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4584110758301166		[learning rate: 0.0050387]
	Learning Rate: 0.00503867
	LOSS [training: 0.4584110758301166 | validation: 0.3402640052929402]
	TIME [epoch: 9.55 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4284927461107966		[learning rate: 0.0050265]
	Learning Rate: 0.00502647
	LOSS [training: 0.4284927461107966 | validation: 0.7712912435159613]
	TIME [epoch: 9.52 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6303912595006053		[learning rate: 0.0050143]
	Learning Rate: 0.0050143
	LOSS [training: 0.6303912595006053 | validation: 0.6450577304524211]
	TIME [epoch: 9.52 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4690965089397598		[learning rate: 0.0050022]
	Learning Rate: 0.00500216
	LOSS [training: 0.4690965089397598 | validation: 0.31541391625438103]
	TIME [epoch: 9.54 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.360180469089987		[learning rate: 0.0049901]
	Learning Rate: 0.00499005
	LOSS [training: 0.360180469089987 | validation: 0.3120431847977414]
	TIME [epoch: 9.53 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48783560885569716		[learning rate: 0.004978]
	Learning Rate: 0.00497797
	LOSS [training: 0.48783560885569716 | validation: 0.9699964652742267]
	TIME [epoch: 9.52 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8012913572169158		[learning rate: 0.0049659]
	Learning Rate: 0.00496592
	LOSS [training: 0.8012913572169158 | validation: 0.7920873041480715]
	TIME [epoch: 9.52 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6496015015758492		[learning rate: 0.0049539]
	Learning Rate: 0.0049539
	LOSS [training: 0.6496015015758492 | validation: 0.5309426303761527]
	TIME [epoch: 9.54 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5424413823140966		[learning rate: 0.0049419]
	Learning Rate: 0.00494191
	LOSS [training: 0.5424413823140966 | validation: 0.6324065733038805]
	TIME [epoch: 9.52 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5197331904849247		[learning rate: 0.0049299]
	Learning Rate: 0.00492994
	LOSS [training: 0.5197331904849247 | validation: 0.8283696322955589]
	TIME [epoch: 9.51 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7311026692095282		[learning rate: 0.004918]
	Learning Rate: 0.00491801
	LOSS [training: 0.7311026692095282 | validation: 0.32361281277908027]
	TIME [epoch: 9.54 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34335640235444076		[learning rate: 0.0049061]
	Learning Rate: 0.0049061
	LOSS [training: 0.34335640235444076 | validation: 0.4906508083422674]
	TIME [epoch: 9.52 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3585883938247495		[learning rate: 0.0048942]
	Learning Rate: 0.00489423
	LOSS [training: 0.3585883938247495 | validation: 0.4045454470371827]
	TIME [epoch: 9.51 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3832375256030291		[learning rate: 0.0048824]
	Learning Rate: 0.00488238
	LOSS [training: 0.3832375256030291 | validation: 0.2517481682274467]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_396.pth
	Model improved!!!
EPOCH 397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29183462580866243		[learning rate: 0.0048706]
	Learning Rate: 0.00487056
	LOSS [training: 0.29183462580866243 | validation: 0.3319688686494405]
	TIME [epoch: 9.53 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31749683021548664		[learning rate: 0.0048588]
	Learning Rate: 0.00485877
	LOSS [training: 0.31749683021548664 | validation: 0.2828937090830223]
	TIME [epoch: 9.52 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6031420101158521		[learning rate: 0.004847]
	Learning Rate: 0.00484701
	LOSS [training: 0.6031420101158521 | validation: 0.6255151886228891]
	TIME [epoch: 9.51 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6325963841438345		[learning rate: 0.0048353]
	Learning Rate: 0.00483527
	LOSS [training: 0.6325963841438345 | validation: 0.5166167478257832]
	TIME [epoch: 9.53 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5150557022122177		[learning rate: 0.0048236]
	Learning Rate: 0.00482357
	LOSS [training: 0.5150557022122177 | validation: 0.5238605370368228]
	TIME [epoch: 9.51 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9061186030943377		[learning rate: 0.0048119]
	Learning Rate: 0.00481189
	LOSS [training: 0.9061186030943377 | validation: 0.5131232479766159]
	TIME [epoch: 9.51 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5593398519421167		[learning rate: 0.0048002]
	Learning Rate: 0.00480024
	LOSS [training: 0.5593398519421167 | validation: 0.9331896835663004]
	TIME [epoch: 9.52 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6478958936908974		[learning rate: 0.0047886]
	Learning Rate: 0.00478862
	LOSS [training: 0.6478958936908974 | validation: 0.4606112964911694]
	TIME [epoch: 9.52 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4177849269634975		[learning rate: 0.004777]
	Learning Rate: 0.00477703
	LOSS [training: 0.4177849269634975 | validation: 0.39141071903182595]
	TIME [epoch: 9.51 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29867385087361675		[learning rate: 0.0047655]
	Learning Rate: 0.00476546
	LOSS [training: 0.29867385087361675 | validation: 0.2859591563570985]
	TIME [epoch: 9.51 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43166254679629584		[learning rate: 0.0047539]
	Learning Rate: 0.00475393
	LOSS [training: 0.43166254679629584 | validation: 0.4159843675795192]
	TIME [epoch: 9.53 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.450332889103611		[learning rate: 0.0047424]
	Learning Rate: 0.00474242
	LOSS [training: 0.450332889103611 | validation: 0.46021980150091035]
	TIME [epoch: 9.52 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4767084105421646		[learning rate: 0.0047309]
	Learning Rate: 0.00473094
	LOSS [training: 0.4767084105421646 | validation: 0.335344466646173]
	TIME [epoch: 9.51 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4314486120011399		[learning rate: 0.0047195]
	Learning Rate: 0.00471949
	LOSS [training: 0.4314486120011399 | validation: 0.49794161395886455]
	TIME [epoch: 9.52 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5009519304028864		[learning rate: 0.0047081]
	Learning Rate: 0.00470806
	LOSS [training: 0.5009519304028864 | validation: 0.5092375780403136]
	TIME [epoch: 9.52 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5273249575297394		[learning rate: 0.0046967]
	Learning Rate: 0.00469666
	LOSS [training: 0.5273249575297394 | validation: 0.5806898885688091]
	TIME [epoch: 9.51 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47016296106767985		[learning rate: 0.0046853]
	Learning Rate: 0.00468529
	LOSS [training: 0.47016296106767985 | validation: 0.3660507224709954]
	TIME [epoch: 9.51 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.47470474505526844		[learning rate: 0.004674]
	Learning Rate: 0.00467395
	LOSS [training: 0.47470474505526844 | validation: 0.6441630571429794]
	TIME [epoch: 9.54 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6020495860466183		[learning rate: 0.0046626]
	Learning Rate: 0.00466264
	LOSS [training: 0.6020495860466183 | validation: 0.4738281146058908]
	TIME [epoch: 9.51 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6966076419902762		[learning rate: 0.0046513]
	Learning Rate: 0.00465135
	LOSS [training: 0.6966076419902762 | validation: 0.6808140250238196]
	TIME [epoch: 9.52 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6543312613197759		[learning rate: 0.0046401]
	Learning Rate: 0.00464009
	LOSS [training: 0.6543312613197759 | validation: 0.579059574670285]
	TIME [epoch: 9.52 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.571499655302329		[learning rate: 0.0046289]
	Learning Rate: 0.00462886
	LOSS [training: 0.571499655302329 | validation: 0.6082786429057772]
	TIME [epoch: 9.52 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5680644528801622		[learning rate: 0.0046177]
	Learning Rate: 0.00461765
	LOSS [training: 0.5680644528801622 | validation: 0.5760217555754177]
	TIME [epoch: 9.51 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5106266816210786		[learning rate: 0.0046065]
	Learning Rate: 0.00460647
	LOSS [training: 0.5106266816210786 | validation: 0.6432128523101152]
	TIME [epoch: 9.51 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5955910225849406		[learning rate: 0.0045953]
	Learning Rate: 0.00459532
	LOSS [training: 0.5955910225849406 | validation: 0.5445405972183521]
	TIME [epoch: 9.53 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5008054396116391		[learning rate: 0.0045842]
	Learning Rate: 0.0045842
	LOSS [training: 0.5008054396116391 | validation: 0.47828812655509995]
	TIME [epoch: 9.52 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5071868157121852		[learning rate: 0.0045731]
	Learning Rate: 0.0045731
	LOSS [training: 0.5071868157121852 | validation: 0.62934009294633]
	TIME [epoch: 9.52 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5770796867688329		[learning rate: 0.004562]
	Learning Rate: 0.00456203
	LOSS [training: 0.5770796867688329 | validation: 0.48278041876700833]
	TIME [epoch: 9.53 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5265305542393197		[learning rate: 0.004551]
	Learning Rate: 0.00455098
	LOSS [training: 0.5265305542393197 | validation: 0.5204907850158298]
	TIME [epoch: 9.53 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5299316878463567		[learning rate: 0.00454]
	Learning Rate: 0.00453997
	LOSS [training: 0.5299316878463567 | validation: 0.599695668589243]
	TIME [epoch: 9.51 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4758074035622323		[learning rate: 0.004529]
	Learning Rate: 0.00452898
	LOSS [training: 0.4758074035622323 | validation: 0.38511215591991954]
	TIME [epoch: 9.51 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193352276192467		[learning rate: 0.004518]
	Learning Rate: 0.00451801
	LOSS [training: 0.5193352276192467 | validation: 0.5091674848537979]
	TIME [epoch: 9.54 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5265547757922557		[learning rate: 0.0045071]
	Learning Rate: 0.00450707
	LOSS [training: 0.5265547757922557 | validation: 0.5715191101780077]
	TIME [epoch: 9.51 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5552779123774867		[learning rate: 0.0044962]
	Learning Rate: 0.00449616
	LOSS [training: 0.5552779123774867 | validation: 0.544633382405613]
	TIME [epoch: 9.52 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5135077279908632		[learning rate: 0.0044853]
	Learning Rate: 0.00448528
	LOSS [training: 0.5135077279908632 | validation: 0.5542442855160993]
	TIME [epoch: 9.53 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7499722676008589		[learning rate: 0.0044744]
	Learning Rate: 0.00447442
	LOSS [training: 0.7499722676008589 | validation: 1.1833773206722737]
	TIME [epoch: 9.52 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.1606367635633377		[learning rate: 0.0044636]
	Learning Rate: 0.00446359
	LOSS [training: 1.1606367635633377 | validation: 0.35643192827713827]
	TIME [epoch: 9.51 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4496820484353895		[learning rate: 0.0044528]
	Learning Rate: 0.00445278
	LOSS [training: 0.4496820484353895 | validation: 0.4562587274279734]
	TIME [epoch: 9.52 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5695692457089205		[learning rate: 0.004442]
	Learning Rate: 0.004442
	LOSS [training: 0.5695692457089205 | validation: 0.6138151232918196]
	TIME [epoch: 9.53 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49594405957001264		[learning rate: 0.0044313]
	Learning Rate: 0.00443125
	LOSS [training: 0.49594405957001264 | validation: 0.36138213450027173]
	TIME [epoch: 9.51 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44649733768039734		[learning rate: 0.0044205]
	Learning Rate: 0.00442052
	LOSS [training: 0.44649733768039734 | validation: 0.4635391767291489]
	TIME [epoch: 9.51 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.44344392023833124		[learning rate: 0.0044098]
	Learning Rate: 0.00440982
	LOSS [training: 0.44344392023833124 | validation: 1.2403173184550127]
	TIME [epoch: 9.53 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9627410997642869		[learning rate: 0.0043991]
	Learning Rate: 0.00439915
	LOSS [training: 0.9627410997642869 | validation: 0.3577498526860866]
	TIME [epoch: 9.51 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48017070127988326		[learning rate: 0.0043885]
	Learning Rate: 0.0043885
	LOSS [training: 0.48017070127988326 | validation: 0.9183119279271665]
	TIME [epoch: 9.51 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5022440336557912		[learning rate: 0.0043779]
	Learning Rate: 0.00437787
	LOSS [training: 0.5022440336557912 | validation: 0.3098954671201396]
	TIME [epoch: 9.52 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3743531218788576		[learning rate: 0.0043673]
	Learning Rate: 0.00436727
	LOSS [training: 0.3743531218788576 | validation: 0.3582937784314889]
	TIME [epoch: 9.53 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2702193473516713		[learning rate: 0.0043567]
	Learning Rate: 0.0043567
	LOSS [training: 0.2702193473516713 | validation: 0.27457871377350723]
	TIME [epoch: 9.51 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5308827368352576		[learning rate: 0.0043462]
	Learning Rate: 0.00434616
	LOSS [training: 0.5308827368352576 | validation: 0.4345038360796947]
	TIME [epoch: 9.51 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.332419299954666		[learning rate: 0.0043356]
	Learning Rate: 0.00433563
	LOSS [training: 0.332419299954666 | validation: 0.2172084570100963]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_445.pth
	Model improved!!!
EPOCH 446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29216037090756936		[learning rate: 0.0043251]
	Learning Rate: 0.00432514
	LOSS [training: 0.29216037090756936 | validation: 0.7599879642293377]
	TIME [epoch: 9.52 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9425975601948984		[learning rate: 0.0043147]
	Learning Rate: 0.00431467
	LOSS [training: 0.9425975601948984 | validation: 0.22909256097329345]
	TIME [epoch: 9.51 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2850765786895647		[learning rate: 0.0043042]
	Learning Rate: 0.00430422
	LOSS [training: 0.2850765786895647 | validation: 0.2546942734556735]
	TIME [epoch: 9.52 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2895464313816763		[learning rate: 0.0042938]
	Learning Rate: 0.0042938
	LOSS [training: 0.2895464313816763 | validation: 0.2835366229403683]
	TIME [epoch: 9.53 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30412433095233954		[learning rate: 0.0042834]
	Learning Rate: 0.00428341
	LOSS [training: 0.30412433095233954 | validation: 0.30884678926205267]
	TIME [epoch: 9.52 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30926942839333205		[learning rate: 0.004273]
	Learning Rate: 0.00427304
	LOSS [training: 0.30926942839333205 | validation: 0.3458771776989768]
	TIME [epoch: 9.52 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4764940513976995		[learning rate: 0.0042627]
	Learning Rate: 0.00426269
	LOSS [training: 0.4764940513976995 | validation: 0.6274992976239164]
	TIME [epoch: 9.54 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7029043549541386		[learning rate: 0.0042524]
	Learning Rate: 0.00425238
	LOSS [training: 0.7029043549541386 | validation: 0.6658695428673732]
	TIME [epoch: 9.51 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7469528585153296		[learning rate: 0.0042421]
	Learning Rate: 0.00424208
	LOSS [training: 0.7469528585153296 | validation: 0.34332880226117274]
	TIME [epoch: 9.51 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3607293908157109		[learning rate: 0.0042318]
	Learning Rate: 0.00423181
	LOSS [training: 0.3607293908157109 | validation: 0.34693799204316816]
	TIME [epoch: 9.51 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5442181227894034		[learning rate: 0.0042216]
	Learning Rate: 0.00422157
	LOSS [training: 0.5442181227894034 | validation: 0.4639675605081021]
	TIME [epoch: 9.53 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39866593892735935		[learning rate: 0.0042113]
	Learning Rate: 0.00421135
	LOSS [training: 0.39866593892735935 | validation: 0.3881149268507734]
	TIME [epoch: 9.51 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3706795267518043		[learning rate: 0.0042012]
	Learning Rate: 0.00420115
	LOSS [training: 0.3706795267518043 | validation: 0.402568912682037]
	TIME [epoch: 9.51 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38894990118842243		[learning rate: 0.004191]
	Learning Rate: 0.00419098
	LOSS [training: 0.38894990118842243 | validation: 0.40453564275001547]
	TIME [epoch: 9.53 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3616811403824155		[learning rate: 0.0041808]
	Learning Rate: 0.00418084
	LOSS [training: 0.3616811403824155 | validation: 0.43409305439539053]
	TIME [epoch: 9.51 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4101938756075709		[learning rate: 0.0041707]
	Learning Rate: 0.00417071
	LOSS [training: 0.4101938756075709 | validation: 0.3542957330126954]
	TIME [epoch: 9.51 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4323790475922019		[learning rate: 0.0041606]
	Learning Rate: 0.00416062
	LOSS [training: 0.4323790475922019 | validation: 0.29411758427606993]
	TIME [epoch: 9.51 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3476158188819038		[learning rate: 0.0041505]
	Learning Rate: 0.00415055
	LOSS [training: 0.3476158188819038 | validation: 0.31740147825132403]
	TIME [epoch: 9.53 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45941821135781824		[learning rate: 0.0041405]
	Learning Rate: 0.0041405
	LOSS [training: 0.45941821135781824 | validation: 0.499203076765142]
	TIME [epoch: 9.51 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.502315188232944		[learning rate: 0.0041305]
	Learning Rate: 0.00413047
	LOSS [training: 0.502315188232944 | validation: 0.36686132426886203]
	TIME [epoch: 9.51 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39628760311155775		[learning rate: 0.0041205]
	Learning Rate: 0.00412048
	LOSS [training: 0.39628760311155775 | validation: 0.3307147675924477]
	TIME [epoch: 9.54 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45333721827400053		[learning rate: 0.0041105]
	Learning Rate: 0.0041105
	LOSS [training: 0.45333721827400053 | validation: 0.3430880391317018]
	TIME [epoch: 9.52 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.298116454725026		[learning rate: 0.0041005]
	Learning Rate: 0.00410055
	LOSS [training: 0.298116454725026 | validation: 0.400137977787677]
	TIME [epoch: 9.52 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3741385347331828		[learning rate: 0.0040906]
	Learning Rate: 0.00409062
	LOSS [training: 0.3741385347331828 | validation: 0.49395641813416447]
	TIME [epoch: 9.52 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3931979447653653		[learning rate: 0.0040807]
	Learning Rate: 0.00408072
	LOSS [training: 0.3931979447653653 | validation: 0.342549016972933]
	TIME [epoch: 9.54 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3465940433183266		[learning rate: 0.0040708]
	Learning Rate: 0.00407084
	LOSS [training: 0.3465940433183266 | validation: 0.41342747885145015]
	TIME [epoch: 9.51 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4429288888365422		[learning rate: 0.004061]
	Learning Rate: 0.00406099
	LOSS [training: 0.4429288888365422 | validation: 0.43429494748780906]
	TIME [epoch: 9.51 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43356695802552		[learning rate: 0.0040512]
	Learning Rate: 0.00405116
	LOSS [training: 0.43356695802552 | validation: 0.3837606829579407]
	TIME [epoch: 9.53 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41356423053645663		[learning rate: 0.0040413]
	Learning Rate: 0.00404135
	LOSS [training: 0.41356423053645663 | validation: 0.5097653005516704]
	TIME [epoch: 9.52 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37375526103827006		[learning rate: 0.0040316]
	Learning Rate: 0.00403157
	LOSS [training: 0.37375526103827006 | validation: 0.32878316196881]
	TIME [epoch: 9.51 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39816656840483644		[learning rate: 0.0040218]
	Learning Rate: 0.00402181
	LOSS [training: 0.39816656840483644 | validation: 0.36944610884007745]
	TIME [epoch: 9.52 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39817062924156854		[learning rate: 0.0040121]
	Learning Rate: 0.00401207
	LOSS [training: 0.39817062924156854 | validation: 0.5155108529983571]
	TIME [epoch: 9.53 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4723284267453799		[learning rate: 0.0040024]
	Learning Rate: 0.00400236
	LOSS [training: 0.4723284267453799 | validation: 0.3103101426126707]
	TIME [epoch: 9.51 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2975577596953355		[learning rate: 0.0039927]
	Learning Rate: 0.00399267
	LOSS [training: 0.2975577596953355 | validation: 0.22403021771235523]
	TIME [epoch: 9.51 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.31617221371939136		[learning rate: 0.003983]
	Learning Rate: 0.003983
	LOSS [training: 0.31617221371939136 | validation: 0.2786715454424264]
	TIME [epoch: 9.53 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3688101093086948		[learning rate: 0.0039734]
	Learning Rate: 0.00397336
	LOSS [training: 0.3688101093086948 | validation: 0.347265959089485]
	TIME [epoch: 9.51 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27579776679890894		[learning rate: 0.0039637]
	Learning Rate: 0.00396374
	LOSS [training: 0.27579776679890894 | validation: 0.2126025383508543]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_482.pth
	Model improved!!!
EPOCH 483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25739229203968517		[learning rate: 0.0039541]
	Learning Rate: 0.00395415
	LOSS [training: 0.25739229203968517 | validation: 0.2385081373358464]
	TIME [epoch: 9.53 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3574236381577877		[learning rate: 0.0039446]
	Learning Rate: 0.00394457
	LOSS [training: 0.3574236381577877 | validation: 0.34595969543495414]
	TIME [epoch: 9.53 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5939821912950125		[learning rate: 0.003935]
	Learning Rate: 0.00393502
	LOSS [training: 0.5939821912950125 | validation: 1.0995562057445976]
	TIME [epoch: 9.51 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9437823658835882		[learning rate: 0.0039255]
	Learning Rate: 0.0039255
	LOSS [training: 0.9437823658835882 | validation: 0.3696838408270335]
	TIME [epoch: 9.52 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37188647435579525		[learning rate: 0.003916]
	Learning Rate: 0.00391599
	LOSS [training: 0.37188647435579525 | validation: 0.349568971338332]
	TIME [epoch: 9.52 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3622316453902753		[learning rate: 0.0039065]
	Learning Rate: 0.00390651
	LOSS [training: 0.3622316453902753 | validation: 0.3809194968537515]
	TIME [epoch: 9.5 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43951914459238955		[learning rate: 0.0038971]
	Learning Rate: 0.00389706
	LOSS [training: 0.43951914459238955 | validation: 0.482857790321881]
	TIME [epoch: 9.5 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4260451657695031		[learning rate: 0.0038876]
	Learning Rate: 0.00388762
	LOSS [training: 0.4260451657695031 | validation: 0.518002343763977]
	TIME [epoch: 9.52 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3745102743012219		[learning rate: 0.0038782]
	Learning Rate: 0.00387821
	LOSS [training: 0.3745102743012219 | validation: 0.40201518556971244]
	TIME [epoch: 9.52 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36412197412876		[learning rate: 0.0038688]
	Learning Rate: 0.00386882
	LOSS [training: 0.36412197412876 | validation: 0.3838824883214711]
	TIME [epoch: 9.51 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3697384219355431		[learning rate: 0.0038595]
	Learning Rate: 0.00385946
	LOSS [training: 0.3697384219355431 | validation: 0.5317346195752733]
	TIME [epoch: 9.51 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3701513707403741		[learning rate: 0.0038501]
	Learning Rate: 0.00385011
	LOSS [training: 0.3701513707403741 | validation: 0.35466041110809626]
	TIME [epoch: 9.53 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38711721792291104		[learning rate: 0.0038408]
	Learning Rate: 0.00384079
	LOSS [training: 0.38711721792291104 | validation: 0.3304964577161748]
	TIME [epoch: 9.51 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34520457868235116		[learning rate: 0.0038315]
	Learning Rate: 0.0038315
	LOSS [training: 0.34520457868235116 | validation: 0.44119914051441866]
	TIME [epoch: 9.51 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38751620531896336		[learning rate: 0.0038222]
	Learning Rate: 0.00382222
	LOSS [training: 0.38751620531896336 | validation: 0.3243333759060254]
	TIME [epoch: 9.52 sec]
EPOCH 498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2519744865828908		[learning rate: 0.003813]
	Learning Rate: 0.00381297
	LOSS [training: 0.2519744865828908 | validation: 0.44343855626374934]
	TIME [epoch: 9.52 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34127837476547146		[learning rate: 0.0038037]
	Learning Rate: 0.00380374
	LOSS [training: 0.34127837476547146 | validation: 0.27624820879800266]
	TIME [epoch: 9.5 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23923857522644676		[learning rate: 0.0037945]
	Learning Rate: 0.00379453
	LOSS [training: 0.23923857522644676 | validation: 0.24238965428271533]
	TIME [epoch: 9.52 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21463207124149478		[learning rate: 0.0037853]
	Learning Rate: 0.00378534
	LOSS [training: 0.21463207124149478 | validation: 0.20191425921233602]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_501.pth
	Model improved!!!
EPOCH 502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22266307027743037		[learning rate: 0.0037762]
	Learning Rate: 0.00377618
	LOSS [training: 0.22266307027743037 | validation: 0.21687174974212514]
	TIME [epoch: 9.51 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3486031029437369		[learning rate: 0.003767]
	Learning Rate: 0.00376704
	LOSS [training: 0.3486031029437369 | validation: 0.5354501310744412]
	TIME [epoch: 9.51 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6929285023075674		[learning rate: 0.0037579]
	Learning Rate: 0.00375792
	LOSS [training: 0.6929285023075674 | validation: 0.7838429861893367]
	TIME [epoch: 9.52 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5213336212805245		[learning rate: 0.0037488]
	Learning Rate: 0.00374882
	LOSS [training: 0.5213336212805245 | validation: 0.2904679762070194]
	TIME [epoch: 9.52 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34333558740352427		[learning rate: 0.0037397]
	Learning Rate: 0.00373975
	LOSS [training: 0.34333558740352427 | validation: 0.37260480938466545]
	TIME [epoch: 9.51 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4081973336386354		[learning rate: 0.0037307]
	Learning Rate: 0.00373069
	LOSS [training: 0.4081973336386354 | validation: 0.5704954652255204]
	TIME [epoch: 9.51 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5942885903695676		[learning rate: 0.0037217]
	Learning Rate: 0.00372166
	LOSS [training: 0.5942885903695676 | validation: 0.43543596300839327]
	TIME [epoch: 9.52 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3167849805488507		[learning rate: 0.0037127]
	Learning Rate: 0.00371265
	LOSS [training: 0.3167849805488507 | validation: 0.19574159599084706]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_509.pth
	Model improved!!!
EPOCH 510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28077799548462357		[learning rate: 0.0037037]
	Learning Rate: 0.00370366
	LOSS [training: 0.28077799548462357 | validation: 0.2682514443219289]
	TIME [epoch: 9.5 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2785366968726481		[learning rate: 0.0036947]
	Learning Rate: 0.0036947
	LOSS [training: 0.2785366968726481 | validation: 0.27801919471688474]
	TIME [epoch: 9.52 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30096474820933233		[learning rate: 0.0036858]
	Learning Rate: 0.00368575
	LOSS [training: 0.30096474820933233 | validation: 0.2976396276590505]
	TIME [epoch: 9.51 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2946026054798677		[learning rate: 0.0036768]
	Learning Rate: 0.00367683
	LOSS [training: 0.2946026054798677 | validation: 0.4924974820335724]
	TIME [epoch: 9.5 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42992085291698034		[learning rate: 0.0036679]
	Learning Rate: 0.00366793
	LOSS [training: 0.42992085291698034 | validation: 0.26828300945750433]
	TIME [epoch: 9.5 sec]
EPOCH 515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2509383917499448		[learning rate: 0.0036591]
	Learning Rate: 0.00365905
	LOSS [training: 0.2509383917499448 | validation: 0.22251421834485485]
	TIME [epoch: 9.52 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23131601856130019		[learning rate: 0.0036502]
	Learning Rate: 0.00365019
	LOSS [training: 0.23131601856130019 | validation: 0.24366828589504885]
	TIME [epoch: 9.5 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4386673295907485		[learning rate: 0.0036414]
	Learning Rate: 0.00364136
	LOSS [training: 0.4386673295907485 | validation: 0.46265225485144534]
	TIME [epoch: 9.51 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4802262650212172		[learning rate: 0.0036325]
	Learning Rate: 0.00363254
	LOSS [training: 0.4802262650212172 | validation: 0.39604958961856257]
	TIME [epoch: 9.53 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4104375156090515		[learning rate: 0.0036237]
	Learning Rate: 0.00362375
	LOSS [training: 0.4104375156090515 | validation: 0.2400974574625397]
	TIME [epoch: 9.52 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2710512522386834		[learning rate: 0.003615]
	Learning Rate: 0.00361497
	LOSS [training: 0.2710512522386834 | validation: 0.2674470412205671]
	TIME [epoch: 9.5 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2875156667117831		[learning rate: 0.0036062]
	Learning Rate: 0.00360622
	LOSS [training: 0.2875156667117831 | validation: 0.24449486742004575]
	TIME [epoch: 9.51 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2973117459268646		[learning rate: 0.0035975]
	Learning Rate: 0.00359749
	LOSS [training: 0.2973117459268646 | validation: 0.2907358522285034]
	TIME [epoch: 9.53 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2344511202254334		[learning rate: 0.0035888]
	Learning Rate: 0.00358878
	LOSS [training: 0.2344511202254334 | validation: 0.2749634364291152]
	TIME [epoch: 9.52 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2968567434485333		[learning rate: 0.0035801]
	Learning Rate: 0.0035801
	LOSS [training: 0.2968567434485333 | validation: 0.304773620849554]
	TIME [epoch: 9.51 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30003896934445756		[learning rate: 0.0035714]
	Learning Rate: 0.00357143
	LOSS [training: 0.30003896934445756 | validation: 0.31189305822939695]
	TIME [epoch: 9.52 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29950580312020353		[learning rate: 0.0035628]
	Learning Rate: 0.00356278
	LOSS [training: 0.29950580312020353 | validation: 0.2981632479610202]
	TIME [epoch: 9.5 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156394222406078		[learning rate: 0.0035542]
	Learning Rate: 0.00355416
	LOSS [training: 0.3156394222406078 | validation: 0.3146978823471488]
	TIME [epoch: 9.5 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30666283774050856		[learning rate: 0.0035456]
	Learning Rate: 0.00354555
	LOSS [training: 0.30666283774050856 | validation: 0.517467321561935]
	TIME [epoch: 9.51 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8936642203662359		[learning rate: 0.003537]
	Learning Rate: 0.00353697
	LOSS [training: 0.8936642203662359 | validation: 0.45683382821172247]
	TIME [epoch: 9.53 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3875507696927014		[learning rate: 0.0035284]
	Learning Rate: 0.00352841
	LOSS [training: 0.3875507696927014 | validation: 0.5888898006240686]
	TIME [epoch: 9.51 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49891176413737215		[learning rate: 0.0035199]
	Learning Rate: 0.00351987
	LOSS [training: 0.49891176413737215 | validation: 0.404022000947258]
	TIME [epoch: 9.5 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3410601066659161		[learning rate: 0.0035113]
	Learning Rate: 0.00351135
	LOSS [training: 0.3410601066659161 | validation: 0.3949994798356171]
	TIME [epoch: 9.53 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5196525393409431		[learning rate: 0.0035028]
	Learning Rate: 0.00350285
	LOSS [training: 0.5196525393409431 | validation: 0.31432650753412483]
	TIME [epoch: 9.52 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43781493981393194		[learning rate: 0.0034944]
	Learning Rate: 0.00349437
	LOSS [training: 0.43781493981393194 | validation: 0.5847513284039255]
	TIME [epoch: 9.51 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8817138462679084		[learning rate: 0.0034859]
	Learning Rate: 0.00348591
	LOSS [training: 0.8817138462679084 | validation: 1.042904585687836]
	TIME [epoch: 9.53 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8394461354821239		[learning rate: 0.0034775]
	Learning Rate: 0.00347747
	LOSS [training: 0.8394461354821239 | validation: 0.38219052235032097]
	TIME [epoch: 9.53 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34897426107202		[learning rate: 0.003469]
	Learning Rate: 0.00346905
	LOSS [training: 0.34897426107202 | validation: 0.42249724228923974]
	TIME [epoch: 9.51 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5148522281903584		[learning rate: 0.0034607]
	Learning Rate: 0.00346065
	LOSS [training: 0.5148522281903584 | validation: 0.7021857637200657]
	TIME [epoch: 9.52 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6551875882886413		[learning rate: 0.0034523]
	Learning Rate: 0.00345227
	LOSS [training: 0.6551875882886413 | validation: 0.6256094739680014]
	TIME [epoch: 9.54 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5423740645893822		[learning rate: 0.0034439]
	Learning Rate: 0.00344392
	LOSS [training: 0.5423740645893822 | validation: 0.45740785017119734]
	TIME [epoch: 9.51 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41070405230679186		[learning rate: 0.0034356]
	Learning Rate: 0.00343558
	LOSS [training: 0.41070405230679186 | validation: 0.5168081214693517]
	TIME [epoch: 9.5 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3918237956386018		[learning rate: 0.0034273]
	Learning Rate: 0.00342726
	LOSS [training: 0.3918237956386018 | validation: 0.498268027554893]
	TIME [epoch: 9.53 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5604150682068262		[learning rate: 0.003419]
	Learning Rate: 0.00341897
	LOSS [training: 0.5604150682068262 | validation: 0.3580693826121298]
	TIME [epoch: 9.53 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41046690829973526		[learning rate: 0.0034107]
	Learning Rate: 0.00341069
	LOSS [training: 0.41046690829973526 | validation: 0.4957438854032111]
	TIME [epoch: 9.51 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.495634282613903		[learning rate: 0.0034024]
	Learning Rate: 0.00340243
	LOSS [training: 0.495634282613903 | validation: 0.489984885800438]
	TIME [epoch: 9.51 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38821373193933606		[learning rate: 0.0033942]
	Learning Rate: 0.0033942
	LOSS [training: 0.38821373193933606 | validation: 0.331491944724872]
	TIME [epoch: 9.54 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36066647446887207		[learning rate: 0.003386]
	Learning Rate: 0.00338598
	LOSS [training: 0.36066647446887207 | validation: 0.37357023389325905]
	TIME [epoch: 9.53 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.356224966016184		[learning rate: 0.0033778]
	Learning Rate: 0.00337778
	LOSS [training: 0.356224966016184 | validation: 0.3409858595357191]
	TIME [epoch: 9.53 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.128735082110536		[learning rate: 0.0033696]
	Learning Rate: 0.0033696
	LOSS [training: 1.128735082110536 | validation: 0.8290312720587497]
	TIME [epoch: 9.53 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6772923634579707		[learning rate: 0.0033614]
	Learning Rate: 0.00336145
	LOSS [training: 0.6772923634579707 | validation: 0.38707854789258106]
	TIME [epoch: 9.54 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3931260538084271		[learning rate: 0.0033533]
	Learning Rate: 0.00335331
	LOSS [training: 0.3931260538084271 | validation: 0.46930147679307865]
	TIME [epoch: 9.52 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3922018382000195		[learning rate: 0.0033452]
	Learning Rate: 0.00334519
	LOSS [training: 0.3922018382000195 | validation: 0.4556034144378194]
	TIME [epoch: 9.52 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7629723363886122		[learning rate: 0.0033371]
	Learning Rate: 0.00333709
	LOSS [training: 0.7629723363886122 | validation: 0.49360003637108696]
	TIME [epoch: 9.53 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4162926337732101		[learning rate: 0.003329]
	Learning Rate: 0.00332902
	LOSS [training: 0.4162926337732101 | validation: 0.34420052362882375]
	TIME [epoch: 9.52 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35612246940805725		[learning rate: 0.003321]
	Learning Rate: 0.00332096
	LOSS [training: 0.35612246940805725 | validation: 0.3203623699261]
	TIME [epoch: 9.51 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3646084306032247		[learning rate: 0.0033129]
	Learning Rate: 0.00331292
	LOSS [training: 0.3646084306032247 | validation: 0.3011801237510566]
	TIME [epoch: 9.53 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33878904806062937		[learning rate: 0.0033049]
	Learning Rate: 0.0033049
	LOSS [training: 0.33878904806062937 | validation: 0.3415085439719768]
	TIME [epoch: 9.52 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3379346988121684		[learning rate: 0.0032969]
	Learning Rate: 0.0032969
	LOSS [training: 0.3379346988121684 | validation: 0.32127334591368817]
	TIME [epoch: 9.52 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3088071270905882		[learning rate: 0.0032889]
	Learning Rate: 0.00328891
	LOSS [training: 0.3088071270905882 | validation: 0.33300560334549006]
	TIME [epoch: 9.51 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3143242682645616		[learning rate: 0.003281]
	Learning Rate: 0.00328095
	LOSS [training: 0.3143242682645616 | validation: 0.3725966937947425]
	TIME [epoch: 9.53 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4664360442395628		[learning rate: 0.003273]
	Learning Rate: 0.00327301
	LOSS [training: 0.4664360442395628 | validation: 0.3387304825169132]
	TIME [epoch: 9.51 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3458623345833695		[learning rate: 0.0032651]
	Learning Rate: 0.00326509
	LOSS [training: 0.3458623345833695 | validation: 0.39668518932739993]
	TIME [epoch: 9.52 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3049220828336499		[learning rate: 0.0032572]
	Learning Rate: 0.00325718
	LOSS [training: 0.3049220828336499 | validation: 0.2566279719822756]
	TIME [epoch: 9.53 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25584209349649856		[learning rate: 0.0032493]
	Learning Rate: 0.0032493
	LOSS [training: 0.25584209349649856 | validation: 0.23671509133724833]
	TIME [epoch: 9.51 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28205870647183107		[learning rate: 0.0032414]
	Learning Rate: 0.00324143
	LOSS [training: 0.28205870647183107 | validation: 0.29355890391546197]
	TIME [epoch: 9.52 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3114817296874836		[learning rate: 0.0032336]
	Learning Rate: 0.00323358
	LOSS [training: 0.3114817296874836 | validation: 0.4594410132412445]
	TIME [epoch: 9.52 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3840984313031816		[learning rate: 0.0032258]
	Learning Rate: 0.00322576
	LOSS [training: 0.3840984313031816 | validation: 0.2875274985468404]
	TIME [epoch: 9.54 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40534177878220373		[learning rate: 0.0032179]
	Learning Rate: 0.00321795
	LOSS [training: 0.40534177878220373 | validation: 0.4754727728260266]
	TIME [epoch: 9.52 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5565268011940099		[learning rate: 0.0032102]
	Learning Rate: 0.00321016
	LOSS [training: 0.5565268011940099 | validation: 0.48282987837187735]
	TIME [epoch: 9.51 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4983568648025062		[learning rate: 0.0032024]
	Learning Rate: 0.00320239
	LOSS [training: 0.4983568648025062 | validation: 0.5900401406541501]
	TIME [epoch: 9.52 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8330051012612121		[learning rate: 0.0031946]
	Learning Rate: 0.00319463
	LOSS [training: 0.8330051012612121 | validation: 0.5818380037302817]
	TIME [epoch: 9.52 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.554645593413397		[learning rate: 0.0031869]
	Learning Rate: 0.0031869
	LOSS [training: 0.554645593413397 | validation: 0.42382251951834593]
	TIME [epoch: 9.51 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3391975226485781		[learning rate: 0.0031792]
	Learning Rate: 0.00317918
	LOSS [training: 0.3391975226485781 | validation: 0.43631533795508687]
	TIME [epoch: 9.52 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3548376534678098		[learning rate: 0.0031715]
	Learning Rate: 0.00317149
	LOSS [training: 0.3548376534678098 | validation: 0.2907499015008777]
	TIME [epoch: 9.54 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2340736053578741		[learning rate: 0.0031638]
	Learning Rate: 0.00316381
	LOSS [training: 0.2340736053578741 | validation: 0.20526877724650242]
	TIME [epoch: 9.5 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2676641087903914		[learning rate: 0.0031562]
	Learning Rate: 0.00315615
	LOSS [training: 0.2676641087903914 | validation: 0.23052972192544516]
	TIME [epoch: 9.51 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.274594398439456		[learning rate: 0.0031485]
	Learning Rate: 0.00314851
	LOSS [training: 0.274594398439456 | validation: 0.2842132856595167]
	TIME [epoch: 9.52 sec]
EPOCH 578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33765480200719494		[learning rate: 0.0031409]
	Learning Rate: 0.00314089
	LOSS [training: 0.33765480200719494 | validation: 0.2862263481117408]
	TIME [epoch: 9.52 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30506478652524127		[learning rate: 0.0031333]
	Learning Rate: 0.00313329
	LOSS [training: 0.30506478652524127 | validation: 0.25567574961072304]
	TIME [epoch: 9.51 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28498092243872597		[learning rate: 0.0031257]
	Learning Rate: 0.0031257
	LOSS [training: 0.28498092243872597 | validation: 0.25554007675592033]
	TIME [epoch: 9.51 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3107115680165077		[learning rate: 0.0031181]
	Learning Rate: 0.00311813
	LOSS [training: 0.3107115680165077 | validation: 0.41976219946610643]
	TIME [epoch: 9.53 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34800533212053625		[learning rate: 0.0031106]
	Learning Rate: 0.00311059
	LOSS [training: 0.34800533212053625 | validation: 0.28196413382593716]
	TIME [epoch: 9.5 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3047707640684214		[learning rate: 0.0031031]
	Learning Rate: 0.00310305
	LOSS [training: 0.3047707640684214 | validation: 0.34411780995595176]
	TIME [epoch: 9.5 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5818023708128566		[learning rate: 0.0030955]
	Learning Rate: 0.00309554
	LOSS [training: 0.5818023708128566 | validation: 0.41363161471876664]
	TIME [epoch: 9.53 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3793182380154409		[learning rate: 0.003088]
	Learning Rate: 0.00308805
	LOSS [training: 0.3793182380154409 | validation: 0.4502375905029979]
	TIME [epoch: 9.51 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36895756851602884		[learning rate: 0.0030806]
	Learning Rate: 0.00308057
	LOSS [training: 0.36895756851602884 | validation: 0.32765216385815216]
	TIME [epoch: 9.5 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34935923893865173		[learning rate: 0.0030731]
	Learning Rate: 0.00307312
	LOSS [training: 0.34935923893865173 | validation: 0.2945335488860413]
	TIME [epoch: 9.51 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48671062105458623		[learning rate: 0.0030657]
	Learning Rate: 0.00306568
	LOSS [training: 0.48671062105458623 | validation: 0.550928345767141]
	TIME [epoch: 9.52 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4922684886876093		[learning rate: 0.0030583]
	Learning Rate: 0.00305825
	LOSS [training: 0.4922684886876093 | validation: 0.4181209137327879]
	TIME [epoch: 9.5 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45208179354734623		[learning rate: 0.0030509]
	Learning Rate: 0.00305085
	LOSS [training: 0.45208179354734623 | validation: 0.400298283370622]
	TIME [epoch: 9.51 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33179593637544474		[learning rate: 0.0030435]
	Learning Rate: 0.00304347
	LOSS [training: 0.33179593637544474 | validation: 0.28608379418282676]
	TIME [epoch: 9.53 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3067443406149912		[learning rate: 0.0030361]
	Learning Rate: 0.0030361
	LOSS [training: 0.3067443406149912 | validation: 0.36107190587728694]
	TIME [epoch: 9.52 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.287090939887751		[learning rate: 0.0030287]
	Learning Rate: 0.00302875
	LOSS [training: 0.287090939887751 | validation: 0.3282327079736618]
	TIME [epoch: 9.51 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3701898842321623		[learning rate: 0.0030214]
	Learning Rate: 0.00302142
	LOSS [training: 0.3701898842321623 | validation: 0.440670229701219]
	TIME [epoch: 9.51 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38569038800100797		[learning rate: 0.0030141]
	Learning Rate: 0.0030141
	LOSS [training: 0.38569038800100797 | validation: 0.49511313470290574]
	TIME [epoch: 9.54 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43284018145402864		[learning rate: 0.0030068]
	Learning Rate: 0.0030068
	LOSS [training: 0.43284018145402864 | validation: 0.3238981678460209]
	TIME [epoch: 9.51 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3036621079178742		[learning rate: 0.0029995]
	Learning Rate: 0.00299953
	LOSS [training: 0.3036621079178742 | validation: 0.2434972835868026]
	TIME [epoch: 9.52 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3042350333867369		[learning rate: 0.0029923]
	Learning Rate: 0.00299226
	LOSS [training: 0.3042350333867369 | validation: 0.30981062681779953]
	TIME [epoch: 9.53 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30986040776970525		[learning rate: 0.002985]
	Learning Rate: 0.00298502
	LOSS [training: 0.30986040776970525 | validation: 0.2734493147276272]
	TIME [epoch: 9.52 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39460100376689244		[learning rate: 0.0029778]
	Learning Rate: 0.00297779
	LOSS [training: 0.39460100376689244 | validation: 0.6577942312131421]
	TIME [epoch: 9.51 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.2354148329103132		[learning rate: 0.0029706]
	Learning Rate: 0.00297059
	LOSS [training: 1.2354148329103132 | validation: 0.8269571646523138]
	TIME [epoch: 9.51 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7919166803881054		[learning rate: 0.0029634]
	Learning Rate: 0.00296339
	LOSS [training: 0.7919166803881054 | validation: 0.33982278657188075]
	TIME [epoch: 9.53 sec]
EPOCH 603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5283770903234567		[learning rate: 0.0029562]
	Learning Rate: 0.00295622
	LOSS [training: 0.5283770903234567 | validation: 0.5747155290727453]
	TIME [epoch: 9.5 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4978280923181299		[learning rate: 0.0029491]
	Learning Rate: 0.00294906
	LOSS [training: 0.4978280923181299 | validation: 0.2755969682949341]
	TIME [epoch: 9.51 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2844753836963028		[learning rate: 0.0029419]
	Learning Rate: 0.00294192
	LOSS [training: 0.2844753836963028 | validation: 0.2884257699723158]
	TIME [epoch: 9.53 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3520335953371304		[learning rate: 0.0029348]
	Learning Rate: 0.0029348
	LOSS [training: 0.3520335953371304 | validation: 0.3178950507637099]
	TIME [epoch: 9.52 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2846108373298229		[learning rate: 0.0029277]
	Learning Rate: 0.0029277
	LOSS [training: 0.2846108373298229 | validation: 0.28420526216485015]
	TIME [epoch: 9.51 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24811969906311576		[learning rate: 0.0029206]
	Learning Rate: 0.00292061
	LOSS [training: 0.24811969906311576 | validation: 0.2517866298350633]
	TIME [epoch: 9.52 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.263621926909977		[learning rate: 0.0029135]
	Learning Rate: 0.00291354
	LOSS [training: 0.263621926909977 | validation: 0.2609888154222593]
	TIME [epoch: 9.52 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25730421661735475		[learning rate: 0.0029065]
	Learning Rate: 0.00290649
	LOSS [training: 0.25730421661735475 | validation: 0.34387023456295873]
	TIME [epoch: 9.51 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3447747387880574		[learning rate: 0.0028995]
	Learning Rate: 0.00289945
	LOSS [training: 0.3447747387880574 | validation: 0.3124220533470419]
	TIME [epoch: 9.51 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27473311576077725		[learning rate: 0.0028924]
	Learning Rate: 0.00289243
	LOSS [training: 0.27473311576077725 | validation: 0.3032050064353492]
	TIME [epoch: 9.52 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27102801174759233		[learning rate: 0.0028854]
	Learning Rate: 0.00288543
	LOSS [training: 0.27102801174759233 | validation: 0.303270149494058]
	TIME [epoch: 9.51 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3822350473186088		[learning rate: 0.0028784]
	Learning Rate: 0.00287844
	LOSS [training: 0.3822350473186088 | validation: 0.25223361809662026]
	TIME [epoch: 9.52 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.310752599728924		[learning rate: 0.0028715]
	Learning Rate: 0.00287148
	LOSS [training: 0.310752599728924 | validation: 0.34961836858571604]
	TIME [epoch: 9.51 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33275168743637495		[learning rate: 0.0028645]
	Learning Rate: 0.00286453
	LOSS [training: 0.33275168743637495 | validation: 0.3294191956539186]
	TIME [epoch: 9.52 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35124820851918903		[learning rate: 0.0028576]
	Learning Rate: 0.00285759
	LOSS [training: 0.35124820851918903 | validation: 0.2682007214590738]
	TIME [epoch: 9.5 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.326418913160451		[learning rate: 0.0028507]
	Learning Rate: 0.00285067
	LOSS [training: 0.326418913160451 | validation: 0.3960088324921875]
	TIME [epoch: 9.5 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3724540897803353		[learning rate: 0.0028438]
	Learning Rate: 0.00284377
	LOSS [training: 0.3724540897803353 | validation: 0.3316444679397395]
	TIME [epoch: 9.53 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3157535771531257		[learning rate: 0.0028369]
	Learning Rate: 0.00283689
	LOSS [training: 0.3157535771531257 | validation: 0.23877280310496882]
	TIME [epoch: 9.52 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23588960187830343		[learning rate: 0.00283]
	Learning Rate: 0.00283002
	LOSS [training: 0.23588960187830343 | validation: 0.19237760508307122]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_621.pth
	Model improved!!!
EPOCH 622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2173326303502913		[learning rate: 0.0028232]
	Learning Rate: 0.00282317
	LOSS [training: 0.2173326303502913 | validation: 0.27227788414835813]
	TIME [epoch: 9.54 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30270868365006864		[learning rate: 0.0028163]
	Learning Rate: 0.00281633
	LOSS [training: 0.30270868365006864 | validation: 0.2842117654129126]
	TIME [epoch: 9.54 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2727708344606691		[learning rate: 0.0028095]
	Learning Rate: 0.00280952
	LOSS [training: 0.2727708344606691 | validation: 0.5504931630106427]
	TIME [epoch: 9.53 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.572369483226781		[learning rate: 0.0028027]
	Learning Rate: 0.00280272
	LOSS [training: 0.572369483226781 | validation: 0.5647962912593153]
	TIME [epoch: 9.53 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4941914074886783		[learning rate: 0.0027959]
	Learning Rate: 0.00279593
	LOSS [training: 0.4941914074886783 | validation: 0.3459262596219125]
	TIME [epoch: 9.54 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3217107282948848		[learning rate: 0.0027892]
	Learning Rate: 0.00278916
	LOSS [training: 0.3217107282948848 | validation: 0.35020519436477787]
	TIME [epoch: 9.53 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3519437000350619		[learning rate: 0.0027824]
	Learning Rate: 0.00278241
	LOSS [training: 0.3519437000350619 | validation: 0.24986339188839637]
	TIME [epoch: 9.52 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28786768558978365		[learning rate: 0.0027757]
	Learning Rate: 0.00277567
	LOSS [training: 0.28786768558978365 | validation: 0.3759875073743914]
	TIME [epoch: 9.53 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30303098693170033		[learning rate: 0.002769]
	Learning Rate: 0.00276895
	LOSS [training: 0.30303098693170033 | validation: 0.3074234236254194]
	TIME [epoch: 9.53 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2945098067682156		[learning rate: 0.0027623]
	Learning Rate: 0.00276225
	LOSS [training: 0.2945098067682156 | validation: 0.275348771905396]
	TIME [epoch: 9.52 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38717448368376955		[learning rate: 0.0027556]
	Learning Rate: 0.00275556
	LOSS [training: 0.38717448368376955 | validation: 0.4731844086386512]
	TIME [epoch: 9.53 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7155346527575895		[learning rate: 0.0027489]
	Learning Rate: 0.00274889
	LOSS [training: 0.7155346527575895 | validation: 0.7923553150239029]
	TIME [epoch: 9.54 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6187573924724041		[learning rate: 0.0027422]
	Learning Rate: 0.00274224
	LOSS [training: 0.6187573924724041 | validation: 0.39937384743992044]
	TIME [epoch: 9.53 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6393815197328063		[learning rate: 0.0027356]
	Learning Rate: 0.0027356
	LOSS [training: 0.6393815197328063 | validation: 0.31572160969670277]
	TIME [epoch: 9.52 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3553137686855862		[learning rate: 0.002729]
	Learning Rate: 0.00272898
	LOSS [training: 0.3553137686855862 | validation: 0.3421662081688574]
	TIME [epoch: 9.54 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34043321467832993		[learning rate: 0.0027224]
	Learning Rate: 0.00272237
	LOSS [training: 0.34043321467832993 | validation: 0.3155008441543648]
	TIME [epoch: 9.53 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3380353577288422		[learning rate: 0.0027158]
	Learning Rate: 0.00271578
	LOSS [training: 0.3380353577288422 | validation: 0.3411240943410187]
	TIME [epoch: 9.53 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2638790769712164		[learning rate: 0.0027092]
	Learning Rate: 0.00270921
	LOSS [training: 0.2638790769712164 | validation: 0.24198853736414866]
	TIME [epoch: 9.52 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2777551132143221		[learning rate: 0.0027026]
	Learning Rate: 0.00270265
	LOSS [training: 0.2777551132143221 | validation: 0.31062379752456337]
	TIME [epoch: 9.55 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3154459450844801		[learning rate: 0.0026961]
	Learning Rate: 0.00269611
	LOSS [training: 0.3154459450844801 | validation: 0.34821529438819954]
	TIME [epoch: 9.52 sec]
EPOCH 642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3221969136092106		[learning rate: 0.0026896]
	Learning Rate: 0.00268958
	LOSS [training: 0.3221969136092106 | validation: 0.31783673768964554]
	TIME [epoch: 9.52 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.278673902915478		[learning rate: 0.0026831]
	Learning Rate: 0.00268307
	LOSS [training: 0.278673902915478 | validation: 0.1929569835731205]
	TIME [epoch: 9.54 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2360000898534056		[learning rate: 0.0026766]
	Learning Rate: 0.00267657
	LOSS [training: 0.2360000898534056 | validation: 0.1726561726160537]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_644.pth
	Model improved!!!
EPOCH 645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2186956627340691		[learning rate: 0.0026701]
	Learning Rate: 0.00267009
	LOSS [training: 0.2186956627340691 | validation: 0.259422932952163]
	TIME [epoch: 9.52 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21599216311619207		[learning rate: 0.0026636]
	Learning Rate: 0.00266363
	LOSS [training: 0.21599216311619207 | validation: 0.18433600025640112]
	TIME [epoch: 9.53 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21589184354368735		[learning rate: 0.0026572]
	Learning Rate: 0.00265718
	LOSS [training: 0.21589184354368735 | validation: 0.2942249561096426]
	TIME [epoch: 9.54 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34405355453290304		[learning rate: 0.0026507]
	Learning Rate: 0.00265075
	LOSS [training: 0.34405355453290304 | validation: 0.27756768792973197]
	TIME [epoch: 9.52 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3229961163761512		[learning rate: 0.0026443]
	Learning Rate: 0.00264433
	LOSS [training: 0.3229961163761512 | validation: 0.24935537150817877]
	TIME [epoch: 9.52 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48481241992212015		[learning rate: 0.0026379]
	Learning Rate: 0.00263793
	LOSS [training: 0.48481241992212015 | validation: 1.1373660956588523]
	TIME [epoch: 9.54 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7175520654514325		[learning rate: 0.0026315]
	Learning Rate: 0.00263154
	LOSS [training: 0.7175520654514325 | validation: 0.24291952601236907]
	TIME [epoch: 9.52 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22165760561131762		[learning rate: 0.0026252]
	Learning Rate: 0.00262517
	LOSS [training: 0.22165760561131762 | validation: 0.20801327104708342]
	TIME [epoch: 9.52 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20060514135508045		[learning rate: 0.0026188]
	Learning Rate: 0.00261882
	LOSS [training: 0.20060514135508045 | validation: 0.22977619473569427]
	TIME [epoch: 9.51 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25089000929978283		[learning rate: 0.0026125]
	Learning Rate: 0.00261248
	LOSS [training: 0.25089000929978283 | validation: 0.33838326333538105]
	TIME [epoch: 9.54 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.6032074056641716		[learning rate: 0.0026062]
	Learning Rate: 0.00260615
	LOSS [training: 0.6032074056641716 | validation: 0.7259748992619605]
	TIME [epoch: 9.52 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.9508420065711123		[learning rate: 0.0025998]
	Learning Rate: 0.00259984
	LOSS [training: 0.9508420065711123 | validation: 0.5973821508614785]
	TIME [epoch: 9.52 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.40758240959548087		[learning rate: 0.0025936]
	Learning Rate: 0.00259355
	LOSS [training: 0.40758240959548087 | validation: 0.2596461978523261]
	TIME [epoch: 9.54 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3469408686803115		[learning rate: 0.0025873]
	Learning Rate: 0.00258727
	LOSS [training: 0.3469408686803115 | validation: 0.5613561763907241]
	TIME [epoch: 9.52 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41557268483311205		[learning rate: 0.002581]
	Learning Rate: 0.00258101
	LOSS [training: 0.41557268483311205 | validation: 0.19958825659476367]
	TIME [epoch: 9.52 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2689315542793889		[learning rate: 0.0025748]
	Learning Rate: 0.00257476
	LOSS [training: 0.2689315542793889 | validation: 0.22163410568694517]
	TIME [epoch: 9.52 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22043992232811466		[learning rate: 0.0025685]
	Learning Rate: 0.00256853
	LOSS [training: 0.22043992232811466 | validation: 0.20631803907578217]
	TIME [epoch: 9.54 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3025368374258609		[learning rate: 0.0025623]
	Learning Rate: 0.00256231
	LOSS [training: 0.3025368374258609 | validation: 0.3569512041164262]
	TIME [epoch: 9.52 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3427644067900164		[learning rate: 0.0025561]
	Learning Rate: 0.00255611
	LOSS [training: 0.3427644067900164 | validation: 0.255581678653748]
	TIME [epoch: 9.51 sec]
EPOCH 664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22279981268150353		[learning rate: 0.0025499]
	Learning Rate: 0.00254992
	LOSS [training: 0.22279981268150353 | validation: 0.18385561055285105]
	TIME [epoch: 9.54 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1968803471595803		[learning rate: 0.0025437]
	Learning Rate: 0.00254375
	LOSS [training: 0.1968803471595803 | validation: 0.2283202033735908]
	TIME [epoch: 9.52 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23628864290159174		[learning rate: 0.0025376]
	Learning Rate: 0.00253759
	LOSS [training: 0.23628864290159174 | validation: 0.2851208930950305]
	TIME [epoch: 9.52 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3074025377515172		[learning rate: 0.0025314]
	Learning Rate: 0.00253144
	LOSS [training: 0.3074025377515172 | validation: 0.26062077023158253]
	TIME [epoch: 9.52 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25008390121039886		[learning rate: 0.0025253]
	Learning Rate: 0.00252532
	LOSS [training: 0.25008390121039886 | validation: 0.23212549359957385]
	TIME [epoch: 9.54 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2026838856500086		[learning rate: 0.0025192]
	Learning Rate: 0.0025192
	LOSS [training: 0.2026838856500086 | validation: 0.23774825181028797]
	TIME [epoch: 9.53 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18721897667913423		[learning rate: 0.0025131]
	Learning Rate: 0.0025131
	LOSS [training: 0.18721897667913423 | validation: 0.2547150701243045]
	TIME [epoch: 9.52 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21750000510387785		[learning rate: 0.002507]
	Learning Rate: 0.00250702
	LOSS [training: 0.21750000510387785 | validation: 0.21326249981018794]
	TIME [epoch: 9.54 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3136633717311573		[learning rate: 0.002501]
	Learning Rate: 0.00250095
	LOSS [training: 0.3136633717311573 | validation: 1.1386545848830778]
	TIME [epoch: 9.52 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 5/5] avg loss: 1.8965010823849444		[learning rate: 0.0024949]
	Learning Rate: 0.0024949
	LOSS [training: 1.8965010823849444 | validation: 1.2227590083722906]
	TIME [epoch: 9.51 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.7727425861561665		[learning rate: 0.0024889]
	Learning Rate: 0.00248886
	LOSS [training: 0.7727425861561665 | validation: 0.2689925528444724]
	TIME [epoch: 9.52 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3418664315360952		[learning rate: 0.0024828]
	Learning Rate: 0.00248283
	LOSS [training: 0.3418664315360952 | validation: 0.3343183829122988]
	TIME [epoch: 9.54 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2910632774937535		[learning rate: 0.0024768]
	Learning Rate: 0.00247682
	LOSS [training: 0.2910632774937535 | validation: 0.2356043987618078]
	TIME [epoch: 9.52 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22445566258085764		[learning rate: 0.0024708]
	Learning Rate: 0.00247083
	LOSS [training: 0.22445566258085764 | validation: 0.1972465068894534]
	TIME [epoch: 9.52 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17751431455898262		[learning rate: 0.0024648]
	Learning Rate: 0.00246484
	LOSS [training: 0.17751431455898262 | validation: 0.1680530896283722]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_678.pth
	Model improved!!!
EPOCH 679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5516759837814693		[learning rate: 0.0024589]
	Learning Rate: 0.00245888
	LOSS [training: 0.5516759837814693 | validation: 0.5492198941372981]
	TIME [epoch: 9.52 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5833401650869262		[learning rate: 0.0024529]
	Learning Rate: 0.00245292
	LOSS [training: 0.5833401650869262 | validation: 0.42283182416230897]
	TIME [epoch: 9.52 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2895403139446565		[learning rate: 0.002447]
	Learning Rate: 0.00244699
	LOSS [training: 0.2895403139446565 | validation: 0.3209669675184309]
	TIME [epoch: 9.53 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2600161577270858		[learning rate: 0.0024411]
	Learning Rate: 0.00244106
	LOSS [training: 0.2600161577270858 | validation: 0.17594735781337595]
	TIME [epoch: 9.53 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17784106466991279		[learning rate: 0.0024352]
	Learning Rate: 0.00243515
	LOSS [training: 0.17784106466991279 | validation: 0.21798029259567053]
	TIME [epoch: 9.52 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18585428738027301		[learning rate: 0.0024293]
	Learning Rate: 0.00242926
	LOSS [training: 0.18585428738027301 | validation: 0.1663276309693148]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_684.pth
	Model improved!!!
EPOCH 685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18284518820115297		[learning rate: 0.0024234]
	Learning Rate: 0.00242338
	LOSS [training: 0.18284518820115297 | validation: 0.19456321308121827]
	TIME [epoch: 9.53 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2610761177814819		[learning rate: 0.0024175]
	Learning Rate: 0.00241751
	LOSS [training: 0.2610761177814819 | validation: 0.21628511473464052]
	TIME [epoch: 9.52 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23326315184889204		[learning rate: 0.0024117]
	Learning Rate: 0.00241166
	LOSS [training: 0.23326315184889204 | validation: 0.293961054944443]
	TIME [epoch: 9.51 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2816509361627605		[learning rate: 0.0024058]
	Learning Rate: 0.00240582
	LOSS [training: 0.2816509361627605 | validation: 0.25863059521655146]
	TIME [epoch: 9.53 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22850684021722328		[learning rate: 0.0024]
	Learning Rate: 0.0024
	LOSS [training: 0.22850684021722328 | validation: 0.20267220928315477]
	TIME [epoch: 9.53 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18788231848330267		[learning rate: 0.0023942]
	Learning Rate: 0.00239419
	LOSS [training: 0.18788231848330267 | validation: 0.1988322102030667]
	TIME [epoch: 9.51 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22391308686283345		[learning rate: 0.0023884]
	Learning Rate: 0.00238839
	LOSS [training: 0.22391308686283345 | validation: 0.2711956015294658]
	TIME [epoch: 9.52 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27013690365471443		[learning rate: 0.0023826]
	Learning Rate: 0.00238261
	LOSS [training: 0.27013690365471443 | validation: 0.182693790354755]
	TIME [epoch: 9.53 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20444278004517416		[learning rate: 0.0023768]
	Learning Rate: 0.00237684
	LOSS [training: 0.20444278004517416 | validation: 0.1684621253003834]
	TIME [epoch: 9.51 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26441144742130185		[learning rate: 0.0023711]
	Learning Rate: 0.00237109
	LOSS [training: 0.26441144742130185 | validation: 0.2817262669097792]
	TIME [epoch: 9.52 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2827401114958763		[learning rate: 0.0023653]
	Learning Rate: 0.00236535
	LOSS [training: 0.2827401114958763 | validation: 0.4451385541400208]
	TIME [epoch: 9.53 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34997918246439186		[learning rate: 0.0023596]
	Learning Rate: 0.00235962
	LOSS [training: 0.34997918246439186 | validation: 0.17875760887255887]
	TIME [epoch: 9.51 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17469743860825662		[learning rate: 0.0023539]
	Learning Rate: 0.00235391
	LOSS [training: 0.17469743860825662 | validation: 0.16178824706342695]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_697.pth
	Model improved!!!
EPOCH 698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15019812678687625		[learning rate: 0.0023482]
	Learning Rate: 0.00234821
	LOSS [training: 0.15019812678687625 | validation: 0.18448433158428182]
	TIME [epoch: 9.52 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21224169913849328		[learning rate: 0.0023425]
	Learning Rate: 0.00234252
	LOSS [training: 0.21224169913849328 | validation: 0.20211154695617345]
	TIME [epoch: 9.53 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1661215115236443		[learning rate: 0.0023369]
	Learning Rate: 0.00233685
	LOSS [training: 0.1661215115236443 | validation: 0.1352209547177886]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_700.pth
	Model improved!!!
EPOCH 701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15464340263927473		[learning rate: 0.0023312]
	Learning Rate: 0.0023312
	LOSS [training: 0.15464340263927473 | validation: 0.13933035780324252]
	TIME [epoch: 9.51 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17226841423262734		[learning rate: 0.0023256]
	Learning Rate: 0.00232555
	LOSS [training: 0.17226841423262734 | validation: 0.2642389323294123]
	TIME [epoch: 9.52 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2708337202086938		[learning rate: 0.0023199]
	Learning Rate: 0.00231992
	LOSS [training: 0.2708337202086938 | validation: 0.3133536003636934]
	TIME [epoch: 9.5 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3673411171058091		[learning rate: 0.0023143]
	Learning Rate: 0.00231431
	LOSS [training: 0.3673411171058091 | validation: 0.30982175952897334]
	TIME [epoch: 9.51 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.45582577790855083		[learning rate: 0.0023087]
	Learning Rate: 0.0023087
	LOSS [training: 0.45582577790855083 | validation: 0.45866059017915023]
	TIME [epoch: 9.51 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4636041982699729		[learning rate: 0.0023031]
	Learning Rate: 0.00230312
	LOSS [training: 0.4636041982699729 | validation: 0.48931139218361636]
	TIME [epoch: 9.54 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5444841064238702		[learning rate: 0.0022975]
	Learning Rate: 0.00229754
	LOSS [training: 0.5444841064238702 | validation: 0.37821613047419717]
	TIME [epoch: 9.51 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4156223405787804		[learning rate: 0.002292]
	Learning Rate: 0.00229198
	LOSS [training: 0.4156223405787804 | validation: 0.3489050671000664]
	TIME [epoch: 9.52 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3155342098887445		[learning rate: 0.0022864]
	Learning Rate: 0.00228643
	LOSS [training: 0.3155342098887445 | validation: 0.3910723662150487]
	TIME [epoch: 9.53 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3206885658106423		[learning rate: 0.0022809]
	Learning Rate: 0.0022809
	LOSS [training: 0.3206885658106423 | validation: 0.26069810174732033]
	TIME [epoch: 9.52 sec]
EPOCH 711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26606070451650055		[learning rate: 0.0022754]
	Learning Rate: 0.00227537
	LOSS [training: 0.26606070451650055 | validation: 0.21078614618604158]
	TIME [epoch: 9.5 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22441845985564396		[learning rate: 0.0022699]
	Learning Rate: 0.00226986
	LOSS [training: 0.22441845985564396 | validation: 0.2335750961138618]
	TIME [epoch: 9.51 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22667477511042247		[learning rate: 0.0022644]
	Learning Rate: 0.00226437
	LOSS [training: 0.22667477511042247 | validation: 0.19411457318387462]
	TIME [epoch: 9.53 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26820393479877935		[learning rate: 0.0022589]
	Learning Rate: 0.00225889
	LOSS [training: 0.26820393479877935 | validation: 0.27517934858151405]
	TIME [epoch: 9.52 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3373715259277853		[learning rate: 0.0022534]
	Learning Rate: 0.00225342
	LOSS [training: 0.3373715259277853 | validation: 0.3176986476607778]
	TIME [epoch: 9.51 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3247273265741724		[learning rate: 0.002248]
	Learning Rate: 0.00224796
	LOSS [training: 0.3247273265741724 | validation: 0.2847032579179486]
	TIME [epoch: 9.53 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19646878126628337		[learning rate: 0.0022425]
	Learning Rate: 0.00224252
	LOSS [training: 0.19646878126628337 | validation: 0.15508702589926399]
	TIME [epoch: 9.51 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24072471192031034		[learning rate: 0.0022371]
	Learning Rate: 0.00223709
	LOSS [training: 0.24072471192031034 | validation: 0.18088252467066135]
	TIME [epoch: 9.52 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.270685631215776		[learning rate: 0.0022317]
	Learning Rate: 0.00223168
	LOSS [training: 0.270685631215776 | validation: 0.2842170679876238]
	TIME [epoch: 9.52 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28715917684572523		[learning rate: 0.0022263]
	Learning Rate: 0.00222628
	LOSS [training: 0.28715917684572523 | validation: 0.39215734377454636]
	TIME [epoch: 9.54 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33485936779190156		[learning rate: 0.0022209]
	Learning Rate: 0.00222089
	LOSS [training: 0.33485936779190156 | validation: 0.28225510945109367]
	TIME [epoch: 9.51 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3203206404835502		[learning rate: 0.0022155]
	Learning Rate: 0.00221551
	LOSS [training: 0.3203206404835502 | validation: 0.30008917113379513]
	TIME [epoch: 9.5 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2028585007016873		[learning rate: 0.0022101]
	Learning Rate: 0.00221015
	LOSS [training: 0.2028585007016873 | validation: 0.19539849213257754]
	TIME [epoch: 9.53 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17287828769522767		[learning rate: 0.0022048]
	Learning Rate: 0.0022048
	LOSS [training: 0.17287828769522767 | validation: 0.3388133001880837]
	TIME [epoch: 9.51 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21554804987671977		[learning rate: 0.0021995]
	Learning Rate: 0.00219946
	LOSS [training: 0.21554804987671977 | validation: 0.15096613911595064]
	TIME [epoch: 9.5 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16080010335388412		[learning rate: 0.0021941]
	Learning Rate: 0.00219413
	LOSS [training: 0.16080010335388412 | validation: 0.21457900878573438]
	TIME [epoch: 9.53 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24947208887363836		[learning rate: 0.0021888]
	Learning Rate: 0.00218882
	LOSS [training: 0.24947208887363836 | validation: 0.30476397157332036]
	TIME [epoch: 9.53 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21531696661447933		[learning rate: 0.0021835]
	Learning Rate: 0.00218352
	LOSS [training: 0.21531696661447933 | validation: 0.19301057632379295]
	TIME [epoch: 9.51 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2215175782643274		[learning rate: 0.0021782]
	Learning Rate: 0.00217824
	LOSS [training: 0.2215175782643274 | validation: 0.230791752326768]
	TIME [epoch: 9.52 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3121173087818467		[learning rate: 0.002173]
	Learning Rate: 0.00217296
	LOSS [training: 0.3121173087818467 | validation: 0.2504169042914911]
	TIME [epoch: 9.52 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2887224799928103		[learning rate: 0.0021677]
	Learning Rate: 0.0021677
	LOSS [training: 0.2887224799928103 | validation: 0.2540681521606116]
	TIME [epoch: 9.51 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20227898936840066		[learning rate: 0.0021625]
	Learning Rate: 0.00216246
	LOSS [training: 0.20227898936840066 | validation: 0.19653761625923424]
	TIME [epoch: 9.51 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1676601232885477		[learning rate: 0.0021572]
	Learning Rate: 0.00215722
	LOSS [training: 0.1676601232885477 | validation: 0.24120116764963795]
	TIME [epoch: 9.52 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22776859798651175		[learning rate: 0.002152]
	Learning Rate: 0.002152
	LOSS [training: 0.22776859798651175 | validation: 0.26252788230746665]
	TIME [epoch: 9.52 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2238798497280398		[learning rate: 0.0021468]
	Learning Rate: 0.00214679
	LOSS [training: 0.2238798497280398 | validation: 0.2124119125192928]
	TIME [epoch: 9.51 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19072526241895862		[learning rate: 0.0021416]
	Learning Rate: 0.00214159
	LOSS [training: 0.19072526241895862 | validation: 0.15238525702336156]
	TIME [epoch: 9.51 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18381074568454098		[learning rate: 0.0021364]
	Learning Rate: 0.00213641
	LOSS [training: 0.18381074568454098 | validation: 0.1729656323406087]
	TIME [epoch: 9.53 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17669548507342778		[learning rate: 0.0021312]
	Learning Rate: 0.00213124
	LOSS [training: 0.17669548507342778 | validation: 0.24639722956039264]
	TIME [epoch: 9.51 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26523111526378107		[learning rate: 0.0021261]
	Learning Rate: 0.00212608
	LOSS [training: 0.26523111526378107 | validation: 0.4125910561208849]
	TIME [epoch: 9.5 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30752471623760746		[learning rate: 0.0021209]
	Learning Rate: 0.00212093
	LOSS [training: 0.30752471623760746 | validation: 0.3644801655017731]
	TIME [epoch: 9.52 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3322343643935204		[learning rate: 0.0021158]
	Learning Rate: 0.0021158
	LOSS [training: 0.3322343643935204 | validation: 0.43747474392609115]
	TIME [epoch: 9.53 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42121080348804557		[learning rate: 0.0021107]
	Learning Rate: 0.00211067
	LOSS [training: 0.42121080348804557 | validation: 0.3553353111346242]
	TIME [epoch: 9.5 sec]
EPOCH 743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2438070511557676		[learning rate: 0.0021056]
	Learning Rate: 0.00210556
	LOSS [training: 0.2438070511557676 | validation: 0.18700770434625377]
	TIME [epoch: 9.51 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18497146260580394		[learning rate: 0.0021005]
	Learning Rate: 0.00210047
	LOSS [training: 0.18497146260580394 | validation: 0.16979058665011215]
	TIME [epoch: 9.52 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21624367144373782		[learning rate: 0.0020954]
	Learning Rate: 0.00209538
	LOSS [training: 0.21624367144373782 | validation: 0.19895060128598221]
	TIME [epoch: 9.51 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35676253819977277		[learning rate: 0.0020903]
	Learning Rate: 0.00209031
	LOSS [training: 0.35676253819977277 | validation: 0.2802014968670714]
	TIME [epoch: 9.5 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3166496989337389		[learning rate: 0.0020852]
	Learning Rate: 0.00208525
	LOSS [training: 0.3166496989337389 | validation: 0.2832268794438893]
	TIME [epoch: 9.52 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2619220549109926		[learning rate: 0.0020802]
	Learning Rate: 0.0020802
	LOSS [training: 0.2619220549109926 | validation: 0.33136938185635517]
	TIME [epoch: 9.51 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33325610761585805		[learning rate: 0.0020752]
	Learning Rate: 0.00207517
	LOSS [training: 0.33325610761585805 | validation: 0.3668592110487528]
	TIME [epoch: 9.5 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35537971777589367		[learning rate: 0.0020701]
	Learning Rate: 0.00207014
	LOSS [training: 0.35537971777589367 | validation: 0.35121255202553125]
	TIME [epoch: 9.5 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.455177313233002		[learning rate: 0.0020651]
	Learning Rate: 0.00206513
	LOSS [training: 0.455177313233002 | validation: 0.3536049225143731]
	TIME [epoch: 9.52 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3146711347919468		[learning rate: 0.0020601]
	Learning Rate: 0.00206013
	LOSS [training: 0.3146711347919468 | validation: 0.4337354272795782]
	TIME [epoch: 9.51 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.34975332707120116		[learning rate: 0.0020551]
	Learning Rate: 0.00205514
	LOSS [training: 0.34975332707120116 | validation: 0.28522527512858437]
	TIME [epoch: 9.51 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28177526783261886		[learning rate: 0.0020502]
	Learning Rate: 0.00205017
	LOSS [training: 0.28177526783261886 | validation: 0.27279548348459537]
	TIME [epoch: 9.51 sec]
EPOCH 755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2670342827801314		[learning rate: 0.0020452]
	Learning Rate: 0.0020452
	LOSS [training: 0.2670342827801314 | validation: 0.2280107915631978]
	TIME [epoch: 9.52 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2531039441344337		[learning rate: 0.0020403]
	Learning Rate: 0.00204025
	LOSS [training: 0.2531039441344337 | validation: 0.2861916528733757]
	TIME [epoch: 9.51 sec]
EPOCH 757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.48764792539015395		[learning rate: 0.0020353]
	Learning Rate: 0.00203531
	LOSS [training: 0.48764792539015395 | validation: 0.3670609079219587]
	TIME [epoch: 9.5 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36569764177167186		[learning rate: 0.0020304]
	Learning Rate: 0.00203039
	LOSS [training: 0.36569764177167186 | validation: 0.21008219529279396]
	TIME [epoch: 9.53 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21842560126896768		[learning rate: 0.0020255]
	Learning Rate: 0.00202547
	LOSS [training: 0.21842560126896768 | validation: 0.1640529758622319]
	TIME [epoch: 9.51 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2023951093538406		[learning rate: 0.0020206]
	Learning Rate: 0.00202057
	LOSS [training: 0.2023951093538406 | validation: 0.24386043732285867]
	TIME [epoch: 9.5 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19450623357196464		[learning rate: 0.0020157]
	Learning Rate: 0.00201568
	LOSS [training: 0.19450623357196464 | validation: 0.14542618802176557]
	TIME [epoch: 9.53 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1810232895234114		[learning rate: 0.0020108]
	Learning Rate: 0.0020108
	LOSS [training: 0.1810232895234114 | validation: 0.5498204889958964]
	TIME [epoch: 9.52 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.41764824689356705		[learning rate: 0.0020059]
	Learning Rate: 0.00200593
	LOSS [training: 0.41764824689356705 | validation: 0.14862659075362236]
	TIME [epoch: 9.51 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17741909052589688		[learning rate: 0.0020011]
	Learning Rate: 0.00200107
	LOSS [training: 0.17741909052589688 | validation: 0.18010660638997286]
	TIME [epoch: 9.5 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.26338298720314324		[learning rate: 0.0019962]
	Learning Rate: 0.00199623
	LOSS [training: 0.26338298720314324 | validation: 0.2220273130143289]
	TIME [epoch: 9.52 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21137539973768096		[learning rate: 0.0019914]
	Learning Rate: 0.0019914
	LOSS [training: 0.21137539973768096 | validation: 0.20454774156426514]
	TIME [epoch: 9.51 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.29110633102519246		[learning rate: 0.0019866]
	Learning Rate: 0.00198658
	LOSS [training: 0.29110633102519246 | validation: 0.3036038245785499]
	TIME [epoch: 9.51 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.270778471904365		[learning rate: 0.0019818]
	Learning Rate: 0.00198177
	LOSS [training: 0.270778471904365 | validation: 0.17154632273743683]
	TIME [epoch: 9.53 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17542285498559657		[learning rate: 0.001977]
	Learning Rate: 0.00197697
	LOSS [training: 0.17542285498559657 | validation: 0.20287817601689276]
	TIME [epoch: 9.5 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30227308756804777		[learning rate: 0.0019722]
	Learning Rate: 0.00197218
	LOSS [training: 0.30227308756804777 | validation: 0.38690305993698504]
	TIME [epoch: 9.51 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.36507992427887903		[learning rate: 0.0019674]
	Learning Rate: 0.00196741
	LOSS [training: 0.36507992427887903 | validation: 0.16362207620829405]
	TIME [epoch: 9.5 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16742137063784962		[learning rate: 0.0019626]
	Learning Rate: 0.00196265
	LOSS [training: 0.16742137063784962 | validation: 0.1455454613010558]
	TIME [epoch: 9.52 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24441485827346526		[learning rate: 0.0019579]
	Learning Rate: 0.0019579
	LOSS [training: 0.24441485827346526 | validation: 0.29719856223440194]
	TIME [epoch: 9.51 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2541210825784554		[learning rate: 0.0019532]
	Learning Rate: 0.00195316
	LOSS [training: 0.2541210825784554 | validation: 0.20333735985351786]
	TIME [epoch: 9.51 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3471889127398677		[learning rate: 0.0019484]
	Learning Rate: 0.00194843
	LOSS [training: 0.3471889127398677 | validation: 0.22917397154740657]
	TIME [epoch: 9.52 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3199031837264724		[learning rate: 0.0019437]
	Learning Rate: 0.00194371
	LOSS [training: 0.3199031837264724 | validation: 0.18926387807138847]
	TIME [epoch: 9.5 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18907936928625366		[learning rate: 0.001939]
	Learning Rate: 0.00193901
	LOSS [training: 0.18907936928625366 | validation: 0.14964521698140595]
	TIME [epoch: 9.51 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16622752956200496		[learning rate: 0.0019343]
	Learning Rate: 0.00193431
	LOSS [training: 0.16622752956200496 | validation: 0.16032978860434458]
	TIME [epoch: 9.5 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2247808111159198		[learning rate: 0.0019296]
	Learning Rate: 0.00192963
	LOSS [training: 0.2247808111159198 | validation: 0.19844646824068435]
	TIME [epoch: 9.53 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18303634749940217		[learning rate: 0.001925]
	Learning Rate: 0.00192496
	LOSS [training: 0.18303634749940217 | validation: 0.15853348313253018]
	TIME [epoch: 9.51 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15541352944131587		[learning rate: 0.0019203]
	Learning Rate: 0.0019203
	LOSS [training: 0.15541352944131587 | validation: 0.17986309096869396]
	TIME [epoch: 9.51 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19583776300274885		[learning rate: 0.0019156]
	Learning Rate: 0.00191565
	LOSS [training: 0.19583776300274885 | validation: 0.17959799146970698]
	TIME [epoch: 9.53 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17752722604985877		[learning rate: 0.001911]
	Learning Rate: 0.00191101
	LOSS [training: 0.17752722604985877 | validation: 0.19623931233686398]
	TIME [epoch: 9.51 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17135962538210114		[learning rate: 0.0019064]
	Learning Rate: 0.00190638
	LOSS [training: 0.17135962538210114 | validation: 0.1678658398244698]
	TIME [epoch: 9.5 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17652464787398792		[learning rate: 0.0019018]
	Learning Rate: 0.00190177
	LOSS [training: 0.17652464787398792 | validation: 0.21969747654251964]
	TIME [epoch: 9.51 sec]
EPOCH 786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.235104273697389		[learning rate: 0.0018972]
	Learning Rate: 0.00189717
	LOSS [training: 0.235104273697389 | validation: 0.2205570780340425]
	TIME [epoch: 9.52 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1850599618085421		[learning rate: 0.0018926]
	Learning Rate: 0.00189257
	LOSS [training: 0.1850599618085421 | validation: 0.170200538926366]
	TIME [epoch: 9.5 sec]
EPOCH 788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19327346250939353		[learning rate: 0.001888]
	Learning Rate: 0.00188799
	LOSS [training: 0.19327346250939353 | validation: 0.17192680555110307]
	TIME [epoch: 9.5 sec]
EPOCH 789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2178532931886581		[learning rate: 0.0018834]
	Learning Rate: 0.00188342
	LOSS [training: 0.2178532931886581 | validation: 0.26187335750477325]
	TIME [epoch: 9.53 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2547336659530826		[learning rate: 0.0018789]
	Learning Rate: 0.00187886
	LOSS [training: 0.2547336659530826 | validation: 0.2825140622422341]
	TIME [epoch: 9.51 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2506685570166123		[learning rate: 0.0018743]
	Learning Rate: 0.00187431
	LOSS [training: 0.2506685570166123 | validation: 0.26727740044677156]
	TIME [epoch: 9.5 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2515745102792083		[learning rate: 0.0018698]
	Learning Rate: 0.00186978
	LOSS [training: 0.2515745102792083 | validation: 0.18651643537400417]
	TIME [epoch: 9.51 sec]
EPOCH 793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19324215922301752		[learning rate: 0.0018652]
	Learning Rate: 0.00186525
	LOSS [training: 0.19324215922301752 | validation: 0.18020664915916143]
	TIME [epoch: 9.53 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17473838625886998		[learning rate: 0.0018607]
	Learning Rate: 0.00186073
	LOSS [training: 0.17473838625886998 | validation: 0.16795382363262193]
	TIME [epoch: 9.5 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.195855110156621		[learning rate: 0.0018562]
	Learning Rate: 0.00185623
	LOSS [training: 0.195855110156621 | validation: 0.20484107875732321]
	TIME [epoch: 9.49 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19613824041054279		[learning rate: 0.0018517]
	Learning Rate: 0.00185174
	LOSS [training: 0.19613824041054279 | validation: 0.1958171075750789]
	TIME [epoch: 9.53 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2099919271606064		[learning rate: 0.0018473]
	Learning Rate: 0.00184725
	LOSS [training: 0.2099919271606064 | validation: 0.3288993641185974]
	TIME [epoch: 9.5 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3030345283204045		[learning rate: 0.0018428]
	Learning Rate: 0.00184278
	LOSS [training: 0.3030345283204045 | validation: 0.20585942195509574]
	TIME [epoch: 9.51 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2173249587143788		[learning rate: 0.0018383]
	Learning Rate: 0.00183832
	LOSS [training: 0.2173249587143788 | validation: 0.2565906129894367]
	TIME [epoch: 9.51 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22624254948189812		[learning rate: 0.0018339]
	Learning Rate: 0.00183387
	LOSS [training: 0.22624254948189812 | validation: 0.2509662430343022]
	TIME [epoch: 9.52 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.46822497634019333		[learning rate: 0.0018294]
	Learning Rate: 0.00182943
	LOSS [training: 0.46822497634019333 | validation: 0.8599994216159579]
	TIME [epoch: 9.51 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.8141002166463247		[learning rate: 0.001825]
	Learning Rate: 0.001825
	LOSS [training: 0.8141002166463247 | validation: 0.36419177841536604]
	TIME [epoch: 9.51 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3239472887520921		[learning rate: 0.0018206]
	Learning Rate: 0.00182058
	LOSS [training: 0.3239472887520921 | validation: 0.16792824536348383]
	TIME [epoch: 9.53 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23239365790769076		[learning rate: 0.0018162]
	Learning Rate: 0.00181618
	LOSS [training: 0.23239365790769076 | validation: 0.24307055427964888]
	TIME [epoch: 9.52 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28280799252737676		[learning rate: 0.0018118]
	Learning Rate: 0.00181178
	LOSS [training: 0.28280799252737676 | validation: 0.22068328444858387]
	TIME [epoch: 9.51 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2381811344567296		[learning rate: 0.0018074]
	Learning Rate: 0.00180739
	LOSS [training: 0.2381811344567296 | validation: 0.16151622584693837]
	TIME [epoch: 9.51 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20481039372436022		[learning rate: 0.001803]
	Learning Rate: 0.00180302
	LOSS [training: 0.20481039372436022 | validation: 0.15180033044785476]
	TIME [epoch: 9.53 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16534303944795825		[learning rate: 0.0017987]
	Learning Rate: 0.00179865
	LOSS [training: 0.16534303944795825 | validation: 0.27930210570692965]
	TIME [epoch: 9.5 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.244224311219314		[learning rate: 0.0017943]
	Learning Rate: 0.0017943
	LOSS [training: 0.244224311219314 | validation: 0.16461567537003968]
	TIME [epoch: 9.5 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17895639230752547		[learning rate: 0.00179]
	Learning Rate: 0.00178995
	LOSS [training: 0.17895639230752547 | validation: 0.20275961348683766]
	TIME [epoch: 9.53 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1908096441551366		[learning rate: 0.0017856]
	Learning Rate: 0.00178562
	LOSS [training: 0.1908096441551366 | validation: 0.1456152765338017]
	TIME [epoch: 9.51 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2005664930014957		[learning rate: 0.0017813]
	Learning Rate: 0.0017813
	LOSS [training: 0.2005664930014957 | validation: 0.23132825932183848]
	TIME [epoch: 9.5 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21376938404474113		[learning rate: 0.001777]
	Learning Rate: 0.00177699
	LOSS [training: 0.21376938404474113 | validation: 0.25870499386598794]
	TIME [epoch: 9.5 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2740145489014625		[learning rate: 0.0017727]
	Learning Rate: 0.00177269
	LOSS [training: 0.2740145489014625 | validation: 0.23413372019901948]
	TIME [epoch: 9.54 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2353806472071327		[learning rate: 0.0017684]
	Learning Rate: 0.00176839
	LOSS [training: 0.2353806472071327 | validation: 0.17213858812974672]
	TIME [epoch: 9.5 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18798202974313388		[learning rate: 0.0017641]
	Learning Rate: 0.00176411
	LOSS [training: 0.18798202974313388 | validation: 0.17343216234899025]
	TIME [epoch: 9.5 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1520063641709996		[learning rate: 0.0017598]
	Learning Rate: 0.00175984
	LOSS [training: 0.1520063641709996 | validation: 0.14758090530438486]
	TIME [epoch: 9.53 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1463767315688096		[learning rate: 0.0017556]
	Learning Rate: 0.00175558
	LOSS [training: 0.1463767315688096 | validation: 0.17946369049723962]
	TIME [epoch: 9.51 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5656664554913828		[learning rate: 0.0017513]
	Learning Rate: 0.00175133
	LOSS [training: 0.5656664554913828 | validation: 0.687586022466526]
	TIME [epoch: 9.51 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.584011902847158		[learning rate: 0.0017471]
	Learning Rate: 0.00174709
	LOSS [training: 0.584011902847158 | validation: 0.23565671346480432]
	TIME [epoch: 9.51 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21648814189383966		[learning rate: 0.0017429]
	Learning Rate: 0.00174286
	LOSS [training: 0.21648814189383966 | validation: 0.20280294296779766]
	TIME [epoch: 9.53 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16996206573000464		[learning rate: 0.0017386]
	Learning Rate: 0.00173864
	LOSS [training: 0.16996206573000464 | validation: 0.15101161750820594]
	TIME [epoch: 9.5 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18435047504786112		[learning rate: 0.0017344]
	Learning Rate: 0.00173443
	LOSS [training: 0.18435047504786112 | validation: 0.1801586958097101]
	TIME [epoch: 9.5 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1745081572805705		[learning rate: 0.0017302]
	Learning Rate: 0.00173024
	LOSS [training: 0.1745081572805705 | validation: 0.180812282023807]
	TIME [epoch: 9.52 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15727610948138784		[learning rate: 0.001726]
	Learning Rate: 0.00172605
	LOSS [training: 0.15727610948138784 | validation: 0.15664840594313875]
	TIME [epoch: 9.51 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15810876261854157		[learning rate: 0.0017219]
	Learning Rate: 0.00172187
	LOSS [training: 0.15810876261854157 | validation: 0.21567461068431754]
	TIME [epoch: 9.51 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.37127006729142453		[learning rate: 0.0017177]
	Learning Rate: 0.0017177
	LOSS [training: 0.37127006729142453 | validation: 0.3606030745047389]
	TIME [epoch: 9.51 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5481895644857582		[learning rate: 0.0017135]
	Learning Rate: 0.00171354
	LOSS [training: 0.5481895644857582 | validation: 0.7395790684866945]
	TIME [epoch: 9.52 sec]
EPOCH 829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5710961201921332		[learning rate: 0.0017094]
	Learning Rate: 0.00170939
	LOSS [training: 0.5710961201921332 | validation: 0.3928889726496215]
	TIME [epoch: 9.5 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5411380667841525		[learning rate: 0.0017053]
	Learning Rate: 0.00170526
	LOSS [training: 0.5411380667841525 | validation: 0.3792594324726701]
	TIME [epoch: 9.5 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.49304775965630715		[learning rate: 0.0017011]
	Learning Rate: 0.00170113
	LOSS [training: 0.49304775965630715 | validation: 0.4005679785258466]
	TIME [epoch: 9.52 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5358674584292815		[learning rate: 0.001697]
	Learning Rate: 0.00169701
	LOSS [training: 0.5358674584292815 | validation: 0.26418125545616283]
	TIME [epoch: 9.51 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2825317188870727		[learning rate: 0.0016929]
	Learning Rate: 0.0016929
	LOSS [training: 0.2825317188870727 | validation: 0.14879779020215342]
	TIME [epoch: 9.51 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1719663453970624		[learning rate: 0.0016888]
	Learning Rate: 0.0016888
	LOSS [training: 0.1719663453970624 | validation: 0.19802030331834264]
	TIME [epoch: 9.51 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1725668836885139		[learning rate: 0.0016847]
	Learning Rate: 0.00168471
	LOSS [training: 0.1725668836885139 | validation: 0.13303198178810646]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_835.pth
	Model improved!!!
EPOCH 836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14221511403083645		[learning rate: 0.0016806]
	Learning Rate: 0.00168064
	LOSS [training: 0.14221511403083645 | validation: 0.3163967246342068]
	TIME [epoch: 9.51 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3870862742311493		[learning rate: 0.0016766]
	Learning Rate: 0.00167657
	LOSS [training: 0.3870862742311493 | validation: 0.44123001318459476]
	TIME [epoch: 9.51 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25758124360708656		[learning rate: 0.0016725]
	Learning Rate: 0.00167251
	LOSS [training: 0.25758124360708656 | validation: 0.319877264014102]
	TIME [epoch: 9.53 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3573179385651248		[learning rate: 0.0016685]
	Learning Rate: 0.00166846
	LOSS [training: 0.3573179385651248 | validation: 0.3598024278829619]
	TIME [epoch: 9.51 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3377383497802858		[learning rate: 0.0016644]
	Learning Rate: 0.00166442
	LOSS [training: 0.3377383497802858 | validation: 0.2225310798148478]
	TIME [epoch: 9.51 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20956060124756215		[learning rate: 0.0016604]
	Learning Rate: 0.00166039
	LOSS [training: 0.20956060124756215 | validation: 0.20430302181603033]
	TIME [epoch: 9.52 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20030978410364103		[learning rate: 0.0016564]
	Learning Rate: 0.00165637
	LOSS [training: 0.20030978410364103 | validation: 0.16536025944697938]
	TIME [epoch: 9.51 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19189576797609975		[learning rate: 0.0016524]
	Learning Rate: 0.00165236
	LOSS [training: 0.19189576797609975 | validation: 0.1917210592462971]
	TIME [epoch: 9.5 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17027560626359584		[learning rate: 0.0016484]
	Learning Rate: 0.00164836
	LOSS [training: 0.17027560626359584 | validation: 0.3137165074895868]
	TIME [epoch: 9.52 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5040913086971741		[learning rate: 0.0016444]
	Learning Rate: 0.00164437
	LOSS [training: 0.5040913086971741 | validation: 0.48762971470947464]
	TIME [epoch: 9.52 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3857935588271936		[learning rate: 0.0016404]
	Learning Rate: 0.00164039
	LOSS [training: 0.3857935588271936 | validation: 0.2876092644775337]
	TIME [epoch: 9.5 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3497556285481418		[learning rate: 0.0016364]
	Learning Rate: 0.00163642
	LOSS [training: 0.3497556285481418 | validation: 0.2693788498609843]
	TIME [epoch: 9.5 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2690848624517051		[learning rate: 0.0016325]
	Learning Rate: 0.00163246
	LOSS [training: 0.2690848624517051 | validation: 0.2037641085535942]
	TIME [epoch: 9.52 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18192755361434024		[learning rate: 0.0016285]
	Learning Rate: 0.00162851
	LOSS [training: 0.18192755361434024 | validation: 0.1548958610832426]
	TIME [epoch: 9.51 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19430148902102568		[learning rate: 0.0016246]
	Learning Rate: 0.00162456
	LOSS [training: 0.19430148902102568 | validation: 0.1556488470456434]
	TIME [epoch: 9.5 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1570401130347933		[learning rate: 0.0016206]
	Learning Rate: 0.00162063
	LOSS [training: 0.1570401130347933 | validation: 0.1264807434682384]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_851.pth
	Model improved!!!
EPOCH 852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15040700495438486		[learning rate: 0.0016167]
	Learning Rate: 0.00161671
	LOSS [training: 0.15040700495438486 | validation: 0.12047280743821027]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_852.pth
	Model improved!!!
EPOCH 853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16826192733914389		[learning rate: 0.0016128]
	Learning Rate: 0.00161279
	LOSS [training: 0.16826192733914389 | validation: 0.13064416469651466]
	TIME [epoch: 9.51 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1622204298487116		[learning rate: 0.0016089]
	Learning Rate: 0.00160889
	LOSS [training: 0.1622204298487116 | validation: 0.14225864183186346]
	TIME [epoch: 9.5 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17710182025201354		[learning rate: 0.001605]
	Learning Rate: 0.001605
	LOSS [training: 0.17710182025201354 | validation: 0.16441858959952335]
	TIME [epoch: 9.51 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1644993172850969		[learning rate: 0.0016011]
	Learning Rate: 0.00160111
	LOSS [training: 0.1644993172850969 | validation: 0.14905473969682193]
	TIME [epoch: 9.51 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14483853121217893		[learning rate: 0.0015972]
	Learning Rate: 0.00159723
	LOSS [training: 0.14483853121217893 | validation: 0.19805361762268553]
	TIME [epoch: 9.5 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18953510826853517		[learning rate: 0.0015934]
	Learning Rate: 0.00159337
	LOSS [training: 0.18953510826853517 | validation: 0.19478713878600645]
	TIME [epoch: 9.5 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3297446116802746		[learning rate: 0.0015895]
	Learning Rate: 0.00158951
	LOSS [training: 0.3297446116802746 | validation: 0.3262443592952185]
	TIME [epoch: 9.52 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3135385041880986		[learning rate: 0.0015857]
	Learning Rate: 0.00158566
	LOSS [training: 0.3135385041880986 | validation: 0.2304712835074555]
	TIME [epoch: 9.5 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19946644018367668		[learning rate: 0.0015818]
	Learning Rate: 0.00158182
	LOSS [training: 0.19946644018367668 | validation: 0.145350090761471]
	TIME [epoch: 9.51 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14926941023015336		[learning rate: 0.001578]
	Learning Rate: 0.00157799
	LOSS [training: 0.14926941023015336 | validation: 0.17406457459086963]
	TIME [epoch: 9.52 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17042521321482051		[learning rate: 0.0015742]
	Learning Rate: 0.00157417
	LOSS [training: 0.17042521321482051 | validation: 0.21104502178428625]
	TIME [epoch: 9.51 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20360252953742922		[learning rate: 0.0015704]
	Learning Rate: 0.00157036
	LOSS [training: 0.20360252953742922 | validation: 0.20703963450744156]
	TIME [epoch: 9.51 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15073301535525782		[learning rate: 0.0015666]
	Learning Rate: 0.00156656
	LOSS [training: 0.15073301535525782 | validation: 0.18526766784243556]
	TIME [epoch: 9.51 sec]
EPOCH 866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3652899668691497		[learning rate: 0.0015628]
	Learning Rate: 0.00156277
	LOSS [training: 0.3652899668691497 | validation: 0.4252232086630346]
	TIME [epoch: 9.52 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39688617308269963		[learning rate: 0.001559]
	Learning Rate: 0.00155899
	LOSS [training: 0.39688617308269963 | validation: 0.3422004370066183]
	TIME [epoch: 9.5 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2900160437311428		[learning rate: 0.0015552]
	Learning Rate: 0.00155521
	LOSS [training: 0.2900160437311428 | validation: 0.24649116215305783]
	TIME [epoch: 9.5 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.38229766162224293		[learning rate: 0.0015514]
	Learning Rate: 0.00155145
	LOSS [training: 0.38229766162224293 | validation: 0.3044211549287085]
	TIME [epoch: 9.52 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3464236149809181		[learning rate: 0.0015477]
	Learning Rate: 0.00154769
	LOSS [training: 0.3464236149809181 | validation: 0.23177470278486614]
	TIME [epoch: 9.5 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20833143771618823		[learning rate: 0.0015439]
	Learning Rate: 0.00154394
	LOSS [training: 0.20833143771618823 | validation: 0.17838969776474076]
	TIME [epoch: 9.5 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27105073297261206		[learning rate: 0.0015402]
	Learning Rate: 0.00154021
	LOSS [training: 0.27105073297261206 | validation: 0.16894169735356074]
	TIME [epoch: 9.5 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2115845694201477		[learning rate: 0.0015365]
	Learning Rate: 0.00153648
	LOSS [training: 0.2115845694201477 | validation: 0.22182648237750535]
	TIME [epoch: 9.52 sec]
EPOCH 874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18662657154839626		[learning rate: 0.0015328]
	Learning Rate: 0.00153276
	LOSS [training: 0.18662657154839626 | validation: 0.1573314709888727]
	TIME [epoch: 9.5 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15477658641697034		[learning rate: 0.001529]
	Learning Rate: 0.00152905
	LOSS [training: 0.15477658641697034 | validation: 0.11989953841123299]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_875.pth
	Model improved!!!
EPOCH 876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13700206949858584		[learning rate: 0.0015253]
	Learning Rate: 0.00152535
	LOSS [training: 0.13700206949858584 | validation: 0.17731984839352571]
	TIME [epoch: 9.54 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21483440155581834		[learning rate: 0.0015217]
	Learning Rate: 0.00152165
	LOSS [training: 0.21483440155581834 | validation: 0.2558775491236435]
	TIME [epoch: 9.52 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1992927108432966		[learning rate: 0.001518]
	Learning Rate: 0.00151797
	LOSS [training: 0.1992927108432966 | validation: 0.16217569266836343]
	TIME [epoch: 9.52 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13564203134136257		[learning rate: 0.0015143]
	Learning Rate: 0.00151429
	LOSS [training: 0.13564203134136257 | validation: 0.156561114902836]
	TIME [epoch: 9.53 sec]
EPOCH 880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1365380604593153		[learning rate: 0.0015106]
	Learning Rate: 0.00151063
	LOSS [training: 0.1365380604593153 | validation: 0.13555166459944615]
	TIME [epoch: 9.53 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19404138366692672		[learning rate: 0.001507]
	Learning Rate: 0.00150697
	LOSS [training: 0.19404138366692672 | validation: 0.21990019169092795]
	TIME [epoch: 9.52 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1789314679478469		[learning rate: 0.0015033]
	Learning Rate: 0.00150332
	LOSS [training: 0.1789314679478469 | validation: 0.15735750069763088]
	TIME [epoch: 9.51 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12693841832630606		[learning rate: 0.0014997]
	Learning Rate: 0.00149968
	LOSS [training: 0.12693841832630606 | validation: 0.13939141584760062]
	TIME [epoch: 9.54 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14646910773182445		[learning rate: 0.0014961]
	Learning Rate: 0.00149605
	LOSS [training: 0.14646910773182445 | validation: 0.13368974253902302]
	TIME [epoch: 9.52 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1656816761981521		[learning rate: 0.0014924]
	Learning Rate: 0.00149243
	LOSS [training: 0.1656816761981521 | validation: 0.2305611484589125]
	TIME [epoch: 9.52 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1825883157952468		[learning rate: 0.0014888]
	Learning Rate: 0.00148882
	LOSS [training: 0.1825883157952468 | validation: 0.17828115770769368]
	TIME [epoch: 9.53 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14429983838663735		[learning rate: 0.0014852]
	Learning Rate: 0.00148522
	LOSS [training: 0.14429983838663735 | validation: 0.12236845469280691]
	TIME [epoch: 9.52 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11999945124266102		[learning rate: 0.0014816]
	Learning Rate: 0.00148162
	LOSS [training: 0.11999945124266102 | validation: 0.15497705533357695]
	TIME [epoch: 9.52 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25113815710847165		[learning rate: 0.001478]
	Learning Rate: 0.00147803
	LOSS [training: 0.25113815710847165 | validation: 0.15107233275110205]
	TIME [epoch: 9.52 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15476134469803773		[learning rate: 0.0014745]
	Learning Rate: 0.00147446
	LOSS [training: 0.15476134469803773 | validation: 0.14750870771881128]
	TIME [epoch: 9.54 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.134509095418123		[learning rate: 0.0014709]
	Learning Rate: 0.00147089
	LOSS [training: 0.134509095418123 | validation: 0.18055266987079222]
	TIME [epoch: 9.52 sec]
EPOCH 892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2835384792919946		[learning rate: 0.0014673]
	Learning Rate: 0.00146732
	LOSS [training: 0.2835384792919946 | validation: 0.37493683045368853]
	TIME [epoch: 9.52 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4409386918435021		[learning rate: 0.0014638]
	Learning Rate: 0.00146377
	LOSS [training: 0.4409386918435021 | validation: 0.31395903013861914]
	TIME [epoch: 9.54 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25330527771653333		[learning rate: 0.0014602]
	Learning Rate: 0.00146023
	LOSS [training: 0.25330527771653333 | validation: 0.13734277738406278]
	TIME [epoch: 9.52 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19687616163810845		[learning rate: 0.0014567]
	Learning Rate: 0.00145669
	LOSS [training: 0.19687616163810845 | validation: 0.22487367698073718]
	TIME [epoch: 9.51 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24095040482736896		[learning rate: 0.0014532]
	Learning Rate: 0.00145317
	LOSS [training: 0.24095040482736896 | validation: 0.2165498124097286]
	TIME [epoch: 9.52 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.42114523541848514		[learning rate: 0.0014497]
	Learning Rate: 0.00144965
	LOSS [training: 0.42114523541848514 | validation: 0.44239147932753087]
	TIME [epoch: 9.53 sec]
EPOCH 898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3293189459036328		[learning rate: 0.0014461]
	Learning Rate: 0.00144614
	LOSS [training: 0.3293189459036328 | validation: 0.1507135849879243]
	TIME [epoch: 9.52 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14259446374958404		[learning rate: 0.0014426]
	Learning Rate: 0.00144264
	LOSS [training: 0.14259446374958404 | validation: 0.2179676472958556]
	TIME [epoch: 9.52 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16637876831546478		[learning rate: 0.0014391]
	Learning Rate: 0.00143915
	LOSS [training: 0.16637876831546478 | validation: 0.1328349661959584]
	TIME [epoch: 9.54 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.257479971650753		[learning rate: 0.0014357]
	Learning Rate: 0.00143566
	LOSS [training: 0.257479971650753 | validation: 0.4839279663963079]
	TIME [epoch: 9.52 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.33388803859770194		[learning rate: 0.0014322]
	Learning Rate: 0.00143219
	LOSS [training: 0.33388803859770194 | validation: 0.23683497677889642]
	TIME [epoch: 9.52 sec]
EPOCH 903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.258891226861169		[learning rate: 0.0014287]
	Learning Rate: 0.00142872
	LOSS [training: 0.258891226861169 | validation: 0.2406915118895612]
	TIME [epoch: 9.52 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2797366713237406		[learning rate: 0.0014253]
	Learning Rate: 0.00142526
	LOSS [training: 0.2797366713237406 | validation: 0.2679326691850385]
	TIME [epoch: 9.53 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30337732367103054		[learning rate: 0.0014218]
	Learning Rate: 0.00142181
	LOSS [training: 0.30337732367103054 | validation: 0.2443082033022428]
	TIME [epoch: 9.51 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21882980319204542		[learning rate: 0.0014184]
	Learning Rate: 0.00141837
	LOSS [training: 0.21882980319204542 | validation: 0.17208460323172806]
	TIME [epoch: 9.52 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18614112908411334		[learning rate: 0.0014149]
	Learning Rate: 0.00141494
	LOSS [training: 0.18614112908411334 | validation: 0.20803838440154682]
	TIME [epoch: 9.54 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18692411456410282		[learning rate: 0.0014115]
	Learning Rate: 0.00141151
	LOSS [training: 0.18692411456410282 | validation: 0.1557011528251536]
	TIME [epoch: 9.52 sec]
EPOCH 909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1829714659295692		[learning rate: 0.0014081]
	Learning Rate: 0.00140809
	LOSS [training: 0.1829714659295692 | validation: 0.2201290423858583]
	TIME [epoch: 9.51 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2632391140180294		[learning rate: 0.0014047]
	Learning Rate: 0.00140469
	LOSS [training: 0.2632391140180294 | validation: 0.34304585279880717]
	TIME [epoch: 9.52 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3978307844002345		[learning rate: 0.0014013]
	Learning Rate: 0.00140128
	LOSS [training: 0.3978307844002345 | validation: 0.3085453665228558]
	TIME [epoch: 9.53 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3154845970380584		[learning rate: 0.0013979]
	Learning Rate: 0.00139789
	LOSS [training: 0.3154845970380584 | validation: 0.2087976146635568]
	TIME [epoch: 9.51 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19534879862938315		[learning rate: 0.0013945]
	Learning Rate: 0.00139451
	LOSS [training: 0.19534879862938315 | validation: 0.12728229050797954]
	TIME [epoch: 9.51 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14581623470030242		[learning rate: 0.0013911]
	Learning Rate: 0.00139113
	LOSS [training: 0.14581623470030242 | validation: 0.22814947608630035]
	TIME [epoch: 9.53 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2899307923650557		[learning rate: 0.0013878]
	Learning Rate: 0.00138776
	LOSS [training: 0.2899307923650557 | validation: 0.1974555159695284]
	TIME [epoch: 9.52 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1965708414797261		[learning rate: 0.0013844]
	Learning Rate: 0.00138441
	LOSS [training: 0.1965708414797261 | validation: 0.207572645442894]
	TIME [epoch: 9.52 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15665892981525592		[learning rate: 0.0013811]
	Learning Rate: 0.00138105
	LOSS [training: 0.15665892981525592 | validation: 0.1735070727037762]
	TIME [epoch: 9.51 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15275531330636088		[learning rate: 0.0013777]
	Learning Rate: 0.00137771
	LOSS [training: 0.15275531330636088 | validation: 0.11190466918146996]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_918.pth
	Model improved!!!
EPOCH 919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12079480636999226		[learning rate: 0.0013744]
	Learning Rate: 0.00137437
	LOSS [training: 0.12079480636999226 | validation: 0.10807076523088655]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_919.pth
	Model improved!!!
EPOCH 920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12790076596653185		[learning rate: 0.001371]
	Learning Rate: 0.00137105
	LOSS [training: 0.12790076596653185 | validation: 0.13449878133076065]
	TIME [epoch: 9.51 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14286307614709765		[learning rate: 0.0013677]
	Learning Rate: 0.00136773
	LOSS [training: 0.14286307614709765 | validation: 0.2303101977377601]
	TIME [epoch: 9.52 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5193394921768121		[learning rate: 0.0013644]
	Learning Rate: 0.00136442
	LOSS [training: 0.5193394921768121 | validation: 0.5304241276241551]
	TIME [epoch: 9.51 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4663714371628854		[learning rate: 0.0013611]
	Learning Rate: 0.00136111
	LOSS [training: 0.4663714371628854 | validation: 0.2284989807435186]
	TIME [epoch: 9.51 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1885104161617163		[learning rate: 0.0013578]
	Learning Rate: 0.00135782
	LOSS [training: 0.1885104161617163 | validation: 0.10939305038988899]
	TIME [epoch: 9.52 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12776731641500177		[learning rate: 0.0013545]
	Learning Rate: 0.00135453
	LOSS [training: 0.12776731641500177 | validation: 0.1465694381480592]
	TIME [epoch: 9.52 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1455783168915891		[learning rate: 0.0013513]
	Learning Rate: 0.00135125
	LOSS [training: 0.1455783168915891 | validation: 0.12737356280231513]
	TIME [epoch: 9.5 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14117585958511417		[learning rate: 0.001348]
	Learning Rate: 0.00134798
	LOSS [training: 0.14117585958511417 | validation: 0.11112527970147885]
	TIME [epoch: 9.51 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11963170293959717		[learning rate: 0.0013447]
	Learning Rate: 0.00134472
	LOSS [training: 0.11963170293959717 | validation: 0.10873719809311716]
	TIME [epoch: 9.53 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13992295434783786		[learning rate: 0.0013415]
	Learning Rate: 0.00134146
	LOSS [training: 0.13992295434783786 | validation: 0.16794217948319493]
	TIME [epoch: 9.51 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18434469115690288		[learning rate: 0.0013382]
	Learning Rate: 0.00133822
	LOSS [training: 0.18434469115690288 | validation: 0.21525583408660873]
	TIME [epoch: 9.51 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23012818362636844		[learning rate: 0.001335]
	Learning Rate: 0.00133498
	LOSS [training: 0.23012818362636844 | validation: 0.21411221638207267]
	TIME [epoch: 9.52 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20493360958708556		[learning rate: 0.0013317]
	Learning Rate: 0.00133174
	LOSS [training: 0.20493360958708556 | validation: 0.19670921371479275]
	TIME [epoch: 9.52 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21653586494517132		[learning rate: 0.0013285]
	Learning Rate: 0.00132852
	LOSS [training: 0.21653586494517132 | validation: 0.1966688714815949]
	TIME [epoch: 9.51 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28112256666234015		[learning rate: 0.0013253]
	Learning Rate: 0.0013253
	LOSS [training: 0.28112256666234015 | validation: 0.31892522228591863]
	TIME [epoch: 9.51 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30157114058722495		[learning rate: 0.0013221]
	Learning Rate: 0.0013221
	LOSS [training: 0.30157114058722495 | validation: 0.17666195035474222]
	TIME [epoch: 9.54 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21937737214236752		[learning rate: 0.0013189]
	Learning Rate: 0.0013189
	LOSS [training: 0.21937737214236752 | validation: 0.26869529394940556]
	TIME [epoch: 9.52 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27283608227544376		[learning rate: 0.0013157]
	Learning Rate: 0.0013157
	LOSS [training: 0.27283608227544376 | validation: 0.2715538548376309]
	TIME [epoch: 9.52 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2461327183020266		[learning rate: 0.0013125]
	Learning Rate: 0.00131252
	LOSS [training: 0.2461327183020266 | validation: 0.2045923432109262]
	TIME [epoch: 9.52 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17491053351826258		[learning rate: 0.0013093]
	Learning Rate: 0.00130934
	LOSS [training: 0.17491053351826258 | validation: 0.2276685344061501]
	TIME [epoch: 9.52 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27266023337790435		[learning rate: 0.0013062]
	Learning Rate: 0.00130617
	LOSS [training: 0.27266023337790435 | validation: 0.30633169698499685]
	TIME [epoch: 9.52 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2616501814745212		[learning rate: 0.001303]
	Learning Rate: 0.00130301
	LOSS [training: 0.2616501814745212 | validation: 0.23303788555023466]
	TIME [epoch: 9.51 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22572655373067801		[learning rate: 0.0012999]
	Learning Rate: 0.00129985
	LOSS [training: 0.22572655373067801 | validation: 0.22431594868832505]
	TIME [epoch: 9.53 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2089709206428007		[learning rate: 0.0012967]
	Learning Rate: 0.00129671
	LOSS [training: 0.2089709206428007 | validation: 0.19554848482815826]
	TIME [epoch: 9.51 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19304880690922713		[learning rate: 0.0012936]
	Learning Rate: 0.00129357
	LOSS [training: 0.19304880690922713 | validation: 0.19504414906809017]
	TIME [epoch: 9.51 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1578122171791979		[learning rate: 0.0012904]
	Learning Rate: 0.00129044
	LOSS [training: 0.1578122171791979 | validation: 0.18326361503838648]
	TIME [epoch: 9.52 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1860544837491465		[learning rate: 0.0012873]
	Learning Rate: 0.00128731
	LOSS [training: 0.1860544837491465 | validation: 0.1561275095240172]
	TIME [epoch: 9.52 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14893043315646864		[learning rate: 0.0012842]
	Learning Rate: 0.0012842
	LOSS [training: 0.14893043315646864 | validation: 0.15508317738342434]
	TIME [epoch: 9.5 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16096740232200038		[learning rate: 0.0012811]
	Learning Rate: 0.00128109
	LOSS [training: 0.16096740232200038 | validation: 0.11818480188109728]
	TIME [epoch: 9.51 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11572481334475568		[learning rate: 0.001278]
	Learning Rate: 0.00127799
	LOSS [training: 0.11572481334475568 | validation: 0.11117229017089038]
	TIME [epoch: 9.53 sec]
EPOCH 950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1257689597230311		[learning rate: 0.0012749]
	Learning Rate: 0.00127489
	LOSS [training: 0.1257689597230311 | validation: 0.12699705515512263]
	TIME [epoch: 9.51 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21967751800121685		[learning rate: 0.0012718]
	Learning Rate: 0.00127181
	LOSS [training: 0.21967751800121685 | validation: 0.28917459158858067]
	TIME [epoch: 9.5 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28016963073302203		[learning rate: 0.0012687]
	Learning Rate: 0.00126873
	LOSS [training: 0.28016963073302203 | validation: 0.18402939988630537]
	TIME [epoch: 9.51 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1881368803625861		[learning rate: 0.0012657]
	Learning Rate: 0.00126566
	LOSS [training: 0.1881368803625861 | validation: 0.16550294435115548]
	TIME [epoch: 9.51 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18824141552879362		[learning rate: 0.0012626]
	Learning Rate: 0.00126259
	LOSS [training: 0.18824141552879362 | validation: 0.21590639000319478]
	TIME [epoch: 9.5 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20478758222147792		[learning rate: 0.0012595]
	Learning Rate: 0.00125954
	LOSS [training: 0.20478758222147792 | validation: 0.2751571278629368]
	TIME [epoch: 9.5 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2878232544174414		[learning rate: 0.0012565]
	Learning Rate: 0.00125649
	LOSS [training: 0.2878232544174414 | validation: 0.3077558189753346]
	TIME [epoch: 9.53 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2709021363664328		[learning rate: 0.0012534]
	Learning Rate: 0.00125344
	LOSS [training: 0.2709021363664328 | validation: 0.33848424188442666]
	TIME [epoch: 9.5 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2800767134468996		[learning rate: 0.0012504]
	Learning Rate: 0.00125041
	LOSS [training: 0.2800767134468996 | validation: 0.2714071240639712]
	TIME [epoch: 9.5 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2789466174832897		[learning rate: 0.0012474]
	Learning Rate: 0.00124738
	LOSS [training: 0.2789466174832897 | validation: 0.3002037211090547]
	TIME [epoch: 9.52 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2661383531437095		[learning rate: 0.0012444]
	Learning Rate: 0.00124436
	LOSS [training: 0.2661383531437095 | validation: 0.1954711515768029]
	TIME [epoch: 9.51 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15636005394432342		[learning rate: 0.0012414]
	Learning Rate: 0.00124135
	LOSS [training: 0.15636005394432342 | validation: 0.2161293950813809]
	TIME [epoch: 9.5 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1756484751762571		[learning rate: 0.0012383]
	Learning Rate: 0.00123835
	LOSS [training: 0.1756484751762571 | validation: 0.17238399071686408]
	TIME [epoch: 9.5 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15457333675779966		[learning rate: 0.0012353]
	Learning Rate: 0.00123535
	LOSS [training: 0.15457333675779966 | validation: 0.16861964450281425]
	TIME [epoch: 9.52 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15843013391886196		[learning rate: 0.0012324]
	Learning Rate: 0.00123236
	LOSS [training: 0.15843013391886196 | validation: 0.13023517656450473]
	TIME [epoch: 9.5 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12169230247917892		[learning rate: 0.0012294]
	Learning Rate: 0.00122937
	LOSS [training: 0.12169230247917892 | validation: 0.14104403589408587]
	TIME [epoch: 9.5 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1582102350493903		[learning rate: 0.0012264]
	Learning Rate: 0.0012264
	LOSS [training: 0.1582102350493903 | validation: 0.21033494213863216]
	TIME [epoch: 9.53 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19788401921433768		[learning rate: 0.0012234]
	Learning Rate: 0.00122343
	LOSS [training: 0.19788401921433768 | validation: 0.17442286515074515]
	TIME [epoch: 9.51 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.218427049709776		[learning rate: 0.0012205]
	Learning Rate: 0.00122047
	LOSS [training: 0.218427049709776 | validation: 0.22259273414342937]
	TIME [epoch: 9.5 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2095590717799344		[learning rate: 0.0012175]
	Learning Rate: 0.00121751
	LOSS [training: 0.2095590717799344 | validation: 0.20248564854090198]
	TIME [epoch: 9.5 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19985670181519924		[learning rate: 0.0012146]
	Learning Rate: 0.00121457
	LOSS [training: 0.19985670181519924 | validation: 0.2092727806378136]
	TIME [epoch: 9.53 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1611897673622095		[learning rate: 0.0012116]
	Learning Rate: 0.00121163
	LOSS [training: 0.1611897673622095 | validation: 0.14803316956085585]
	TIME [epoch: 9.5 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1644945472131137		[learning rate: 0.0012087]
	Learning Rate: 0.00120869
	LOSS [training: 0.1644945472131137 | validation: 0.1641412904538845]
	TIME [epoch: 9.51 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16298351129852587		[learning rate: 0.0012058]
	Learning Rate: 0.00120577
	LOSS [training: 0.16298351129852587 | validation: 0.20431373671434924]
	TIME [epoch: 9.53 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18209756437980426		[learning rate: 0.0012028]
	Learning Rate: 0.00120285
	LOSS [training: 0.18209756437980426 | validation: 0.22514860177846605]
	TIME [epoch: 9.51 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18959315957557668		[learning rate: 0.0011999]
	Learning Rate: 0.00119994
	LOSS [training: 0.18959315957557668 | validation: 0.14114926114238546]
	TIME [epoch: 9.51 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13569729062197045		[learning rate: 0.001197]
	Learning Rate: 0.00119703
	LOSS [training: 0.13569729062197045 | validation: 0.12263153064458225]
	TIME [epoch: 9.52 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1234777822532173		[learning rate: 0.0011941]
	Learning Rate: 0.00119413
	LOSS [training: 0.1234777822532173 | validation: 0.12075222668250632]
	TIME [epoch: 9.53 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12694750683766923		[learning rate: 0.0011912]
	Learning Rate: 0.00119124
	LOSS [training: 0.12694750683766923 | validation: 0.1153969890344906]
	TIME [epoch: 9.51 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13627398897188406		[learning rate: 0.0011884]
	Learning Rate: 0.00118836
	LOSS [training: 0.13627398897188406 | validation: 0.12368027516644514]
	TIME [epoch: 9.51 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12286837929421761		[learning rate: 0.0011855]
	Learning Rate: 0.00118548
	LOSS [training: 0.12286837929421761 | validation: 0.13966436822987485]
	TIME [epoch: 9.53 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15524202824803923		[learning rate: 0.0011826]
	Learning Rate: 0.00118261
	LOSS [training: 0.15524202824803923 | validation: 0.16519731138014324]
	TIME [epoch: 9.51 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1519044793172053		[learning rate: 0.0011797]
	Learning Rate: 0.00117975
	LOSS [training: 0.1519044793172053 | validation: 0.15852266872612059]
	TIME [epoch: 9.51 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1996145577416014		[learning rate: 0.0011769]
	Learning Rate: 0.00117689
	LOSS [training: 0.1996145577416014 | validation: 0.1517187931326293]
	TIME [epoch: 9.5 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1793429748525512		[learning rate: 0.001174]
	Learning Rate: 0.00117404
	LOSS [training: 0.1793429748525512 | validation: 0.18725526513779625]
	TIME [epoch: 9.53 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24792388601737797		[learning rate: 0.0011712]
	Learning Rate: 0.0011712
	LOSS [training: 0.24792388601737797 | validation: 0.2521465287532492]
	TIME [epoch: 9.51 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.28675712275248866		[learning rate: 0.0011684]
	Learning Rate: 0.00116837
	LOSS [training: 0.28675712275248866 | validation: 0.21660355738395132]
	TIME [epoch: 9.51 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20364691990368616		[learning rate: 0.0011655]
	Learning Rate: 0.00116554
	LOSS [training: 0.20364691990368616 | validation: 0.14473261929047573]
	TIME [epoch: 9.52 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20125067139684943		[learning rate: 0.0011627]
	Learning Rate: 0.00116272
	LOSS [training: 0.20125067139684943 | validation: 0.2501697651379898]
	TIME [epoch: 9.5 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17483608764289538		[learning rate: 0.0011599]
	Learning Rate: 0.0011599
	LOSS [training: 0.17483608764289538 | validation: 0.16928381597232237]
	TIME [epoch: 9.5 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20126265977516042		[learning rate: 0.0011571]
	Learning Rate: 0.00115709
	LOSS [training: 0.20126265977516042 | validation: 0.1977647863158977]
	TIME [epoch: 9.5 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18866916495639968		[learning rate: 0.0011543]
	Learning Rate: 0.00115429
	LOSS [training: 0.18866916495639968 | validation: 0.17198407199649146]
	TIME [epoch: 9.52 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21503170108062752		[learning rate: 0.0011515]
	Learning Rate: 0.0011515
	LOSS [training: 0.21503170108062752 | validation: 0.21148802442304074]
	TIME [epoch: 9.5 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1918468293923214		[learning rate: 0.0011487]
	Learning Rate: 0.00114871
	LOSS [training: 0.1918468293923214 | validation: 0.15142201732345523]
	TIME [epoch: 9.49 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1578331155509547		[learning rate: 0.0011459]
	Learning Rate: 0.00114593
	LOSS [training: 0.1578331155509547 | validation: 0.18757917792493983]
	TIME [epoch: 9.51 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2188570493499352		[learning rate: 0.0011432]
	Learning Rate: 0.00114316
	LOSS [training: 0.2188570493499352 | validation: 0.2567286231556598]
	TIME [epoch: 9.5 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2764683629889624		[learning rate: 0.0011404]
	Learning Rate: 0.00114039
	LOSS [training: 0.2764683629889624 | validation: 0.3710243471348169]
	TIME [epoch: 9.5 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3417065638753794		[learning rate: 0.0011376]
	Learning Rate: 0.00113763
	LOSS [training: 0.3417065638753794 | validation: 0.26126048629021253]
	TIME [epoch: 9.5 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23473188928009764		[learning rate: 0.0011349]
	Learning Rate: 0.00113487
	LOSS [training: 0.23473188928009764 | validation: 0.194437398135959]
	TIME [epoch: 9.52 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15503968170928148		[learning rate: 0.0011321]
	Learning Rate: 0.00113213
	LOSS [training: 0.15503968170928148 | validation: 0.17635623901342234]
	TIME [epoch: 9.49 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1452374587535174		[learning rate: 0.0011294]
	Learning Rate: 0.00112939
	LOSS [training: 0.1452374587535174 | validation: 0.14487009925157668]
	TIME [epoch: 9.49 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16632677780236166		[learning rate: 0.0011267]
	Learning Rate: 0.00112665
	LOSS [training: 0.16632677780236166 | validation: 0.1573074131122268]
	TIME [epoch: 9.51 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15808358591716418		[learning rate: 0.0011239]
	Learning Rate: 0.00112392
	LOSS [training: 0.15808358591716418 | validation: 0.18833810038874418]
	TIME [epoch: 9.51 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19106093909135397		[learning rate: 0.0011212]
	Learning Rate: 0.0011212
	LOSS [training: 0.19106093909135397 | validation: 0.1318516191228887]
	TIME [epoch: 9.49 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16567665898695733		[learning rate: 0.0011185]
	Learning Rate: 0.00111849
	LOSS [training: 0.16567665898695733 | validation: 0.1761022748421676]
	TIME [epoch: 9.5 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15296335466754787		[learning rate: 0.0011158]
	Learning Rate: 0.00111578
	LOSS [training: 0.15296335466754787 | validation: 0.17912448943315448]
	TIME [epoch: 9.51 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1690812678561487		[learning rate: 0.0011131]
	Learning Rate: 0.00111308
	LOSS [training: 0.1690812678561487 | validation: 0.1548213100419966]
	TIME [epoch: 9.5 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17588008517677317		[learning rate: 0.0011104]
	Learning Rate: 0.00111039
	LOSS [training: 0.17588008517677317 | validation: 0.15928062597427642]
	TIME [epoch: 9.49 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16308694182151243		[learning rate: 0.0011077]
	Learning Rate: 0.0011077
	LOSS [training: 0.16308694182151243 | validation: 0.2083133643763936]
	TIME [epoch: 9.51 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19802837481424929		[learning rate: 0.001105]
	Learning Rate: 0.00110502
	LOSS [training: 0.19802837481424929 | validation: 0.21025045487017985]
	TIME [epoch: 9.5 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19640364350932957		[learning rate: 0.0011023]
	Learning Rate: 0.00110234
	LOSS [training: 0.19640364350932957 | validation: 0.1682571665664678]
	TIME [epoch: 9.5 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16217291677812182		[learning rate: 0.0010997]
	Learning Rate: 0.00109967
	LOSS [training: 0.16217291677812182 | validation: 0.15991332074412615]
	TIME [epoch: 9.51 sec]
EPOCH 1012/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16984779003855166		[learning rate: 0.001097]
	Learning Rate: 0.00109701
	LOSS [training: 0.16984779003855166 | validation: 0.13261827024364256]
	TIME [epoch: 9.5 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14277635405144362		[learning rate: 0.0010944]
	Learning Rate: 0.00109435
	LOSS [training: 0.14277635405144362 | validation: 0.14761506418316253]
	TIME [epoch: 9.5 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15538047693218998		[learning rate: 0.0010917]
	Learning Rate: 0.00109171
	LOSS [training: 0.15538047693218998 | validation: 0.14183170687097477]
	TIME [epoch: 9.5 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15814389083165975		[learning rate: 0.0010891]
	Learning Rate: 0.00108906
	LOSS [training: 0.15814389083165975 | validation: 0.16191924304540134]
	TIME [epoch: 9.51 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1850715969139891		[learning rate: 0.0010864]
	Learning Rate: 0.00108643
	LOSS [training: 0.1850715969139891 | validation: 0.1607296880547527]
	TIME [epoch: 9.49 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1457893512461698		[learning rate: 0.0010838]
	Learning Rate: 0.0010838
	LOSS [training: 0.1457893512461698 | validation: 0.13834577152498004]
	TIME [epoch: 9.5 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17561154210628604		[learning rate: 0.0010812]
	Learning Rate: 0.00108117
	LOSS [training: 0.17561154210628604 | validation: 0.2251664102686821]
	TIME [epoch: 9.51 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25629155957536054		[learning rate: 0.0010786]
	Learning Rate: 0.00107855
	LOSS [training: 0.25629155957536054 | validation: 0.1294954809284268]
	TIME [epoch: 9.51 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15259645273119726		[learning rate: 0.0010759]
	Learning Rate: 0.00107594
	LOSS [training: 0.15259645273119726 | validation: 0.15086174878066794]
	TIME [epoch: 9.5 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20867103562494127		[learning rate: 0.0010733]
	Learning Rate: 0.00107334
	LOSS [training: 0.20867103562494127 | validation: 0.1751969649816291]
	TIME [epoch: 9.5 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21448977276213116		[learning rate: 0.0010707]
	Learning Rate: 0.00107074
	LOSS [training: 0.21448977276213116 | validation: 0.18396920538248374]
	TIME [epoch: 9.51 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22691471347055053		[learning rate: 0.0010681]
	Learning Rate: 0.00106815
	LOSS [training: 0.22691471347055053 | validation: 0.1872666028312464]
	TIME [epoch: 9.5 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2311071667749316		[learning rate: 0.0010656]
	Learning Rate: 0.00106556
	LOSS [training: 0.2311071667749316 | validation: 0.2068845556388043]
	TIME [epoch: 9.5 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2544100396321455		[learning rate: 0.001063]
	Learning Rate: 0.00106298
	LOSS [training: 0.2544100396321455 | validation: 0.21294064069271065]
	TIME [epoch: 9.51 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23759969839386436		[learning rate: 0.0010604]
	Learning Rate: 0.00106041
	LOSS [training: 0.23759969839386436 | validation: 0.1849628315895526]
	TIME [epoch: 9.5 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17489239574907228		[learning rate: 0.0010578]
	Learning Rate: 0.00105784
	LOSS [training: 0.17489239574907228 | validation: 0.1541093130844401]
	TIME [epoch: 9.49 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19656924693033123		[learning rate: 0.0010553]
	Learning Rate: 0.00105528
	LOSS [training: 0.19656924693033123 | validation: 0.15462017023704278]
	TIME [epoch: 9.49 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19739555090337207		[learning rate: 0.0010527]
	Learning Rate: 0.00105273
	LOSS [training: 0.19739555090337207 | validation: 0.18863021451699566]
	TIME [epoch: 9.51 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1907003691758878		[learning rate: 0.0010502]
	Learning Rate: 0.00105018
	LOSS [training: 0.1907003691758878 | validation: 0.14366792918734925]
	TIME [epoch: 9.49 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.141474979426906		[learning rate: 0.0010476]
	Learning Rate: 0.00104764
	LOSS [training: 0.141474979426906 | validation: 0.14082171737095728]
	TIME [epoch: 9.49 sec]
EPOCH 1032/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12630157519274413		[learning rate: 0.0010451]
	Learning Rate: 0.0010451
	LOSS [training: 0.12630157519274413 | validation: 0.13093887723611794]
	TIME [epoch: 9.51 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13091431895692757		[learning rate: 0.0010426]
	Learning Rate: 0.00104257
	LOSS [training: 0.13091431895692757 | validation: 0.13065522605348215]
	TIME [epoch: 9.5 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1298923212988395		[learning rate: 0.00104]
	Learning Rate: 0.00104005
	LOSS [training: 0.1298923212988395 | validation: 0.1556276868573089]
	TIME [epoch: 9.49 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24194456628701078		[learning rate: 0.0010375]
	Learning Rate: 0.00103753
	LOSS [training: 0.24194456628701078 | validation: 0.2664567845167684]
	TIME [epoch: 9.49 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2765187336123195		[learning rate: 0.001035]
	Learning Rate: 0.00103502
	LOSS [training: 0.2765187336123195 | validation: 0.22160759676403696]
	TIME [epoch: 9.51 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.243448442481888		[learning rate: 0.0010325]
	Learning Rate: 0.00103251
	LOSS [training: 0.243448442481888 | validation: 0.17398229492915415]
	TIME [epoch: 9.5 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2548414082875139		[learning rate: 0.00103]
	Learning Rate: 0.00103001
	LOSS [training: 0.2548414082875139 | validation: 0.2685985716644185]
	TIME [epoch: 9.5 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2684673885731968		[learning rate: 0.0010275]
	Learning Rate: 0.00102752
	LOSS [training: 0.2684673885731968 | validation: 0.2597670847558318]
	TIME [epoch: 9.5 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3156109457824102		[learning rate: 0.001025]
	Learning Rate: 0.00102503
	LOSS [training: 0.3156109457824102 | validation: 0.19625066532717952]
	TIME [epoch: 9.51 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2784179561009398		[learning rate: 0.0010225]
	Learning Rate: 0.00102255
	LOSS [training: 0.2784179561009398 | validation: 0.22556376458977812]
	TIME [epoch: 9.5 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25618650818017724		[learning rate: 0.0010201]
	Learning Rate: 0.00102007
	LOSS [training: 0.25618650818017724 | validation: 0.32150865431430253]
	TIME [epoch: 9.5 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5688290225553538		[learning rate: 0.0010176]
	Learning Rate: 0.0010176
	LOSS [training: 0.5688290225553538 | validation: 0.6129770366691807]
	TIME [epoch: 9.51 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5514312517130978		[learning rate: 0.0010151]
	Learning Rate: 0.00101514
	LOSS [training: 0.5514312517130978 | validation: 0.3334213149120559]
	TIME [epoch: 9.5 sec]
EPOCH 1045/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3732050508813688		[learning rate: 0.0010127]
	Learning Rate: 0.00101268
	LOSS [training: 0.3732050508813688 | validation: 0.33715722072884985]
	TIME [epoch: 9.49 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.399912680822234		[learning rate: 0.0010102]
	Learning Rate: 0.00101023
	LOSS [training: 0.399912680822234 | validation: 0.25389756640823796]
	TIME [epoch: 9.51 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3312240028027429		[learning rate: 0.0010078]
	Learning Rate: 0.00100779
	LOSS [training: 0.3312240028027429 | validation: 0.2758671599473675]
	TIME [epoch: 9.51 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3549703614931098		[learning rate: 0.0010053]
	Learning Rate: 0.00100535
	LOSS [training: 0.3549703614931098 | validation: 0.2518875671154873]
	TIME [epoch: 9.5 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25505929678200584		[learning rate: 0.0010029]
	Learning Rate: 0.00100291
	LOSS [training: 0.25505929678200584 | validation: 0.18141433126522422]
	TIME [epoch: 9.49 sec]
EPOCH 1050/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18797603835646176		[learning rate: 0.0010005]
	Learning Rate: 0.00100048
	LOSS [training: 0.18797603835646176 | validation: 0.11383243214418552]
	TIME [epoch: 9.51 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11324148045950067		[learning rate: 0.00099806]
	Learning Rate: 0.000998063
	LOSS [training: 0.11324148045950067 | validation: 0.11656059769081235]
	TIME [epoch: 9.5 sec]
EPOCH 1052/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11226821330948508		[learning rate: 0.00099565]
	Learning Rate: 0.000995647
	LOSS [training: 0.11226821330948508 | validation: 0.12412718804161683]
	TIME [epoch: 9.49 sec]
EPOCH 1053/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14053460348023605		[learning rate: 0.00099324]
	Learning Rate: 0.000993237
	LOSS [training: 0.14053460348023605 | validation: 0.11235483606242279]
	TIME [epoch: 9.51 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15025123790033001		[learning rate: 0.00099083]
	Learning Rate: 0.000990832
	LOSS [training: 0.15025123790033001 | validation: 0.15213248588438172]
	TIME [epoch: 9.5 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13357082967351794		[learning rate: 0.00098843]
	Learning Rate: 0.000988433
	LOSS [training: 0.13357082967351794 | validation: 0.13089756378939243]
	TIME [epoch: 9.49 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15060821336457444		[learning rate: 0.00098604]
	Learning Rate: 0.00098604
	LOSS [training: 0.15060821336457444 | validation: 0.1771943641729425]
	TIME [epoch: 9.49 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18194838177329523		[learning rate: 0.00098365]
	Learning Rate: 0.000983653
	LOSS [training: 0.18194838177329523 | validation: 0.19793027103589247]
	TIME [epoch: 9.51 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21688849597715215		[learning rate: 0.00098127]
	Learning Rate: 0.000981272
	LOSS [training: 0.21688849597715215 | validation: 0.2122461624865209]
	TIME [epoch: 9.49 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22416821708551474		[learning rate: 0.0009789]
	Learning Rate: 0.000978897
	LOSS [training: 0.22416821708551474 | validation: 0.1979967025866262]
	TIME [epoch: 9.5 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17185051770856194		[learning rate: 0.00097653]
	Learning Rate: 0.000976527
	LOSS [training: 0.17185051770856194 | validation: 0.14863421082551603]
	TIME [epoch: 9.51 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13808061803626231		[learning rate: 0.00097416]
	Learning Rate: 0.000974163
	LOSS [training: 0.13808061803626231 | validation: 0.1318367706456886]
	TIME [epoch: 9.5 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13324769872809988		[learning rate: 0.0009718]
	Learning Rate: 0.000971805
	LOSS [training: 0.13324769872809988 | validation: 0.15940637995604642]
	TIME [epoch: 9.5 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13644680429102088		[learning rate: 0.00096945]
	Learning Rate: 0.000969452
	LOSS [training: 0.13644680429102088 | validation: 0.10592681699142427]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1063.pth
	Model improved!!!
EPOCH 1064/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.125383274366224		[learning rate: 0.00096711]
	Learning Rate: 0.000967105
	LOSS [training: 0.125383274366224 | validation: 0.1502653840497928]
	TIME [epoch: 9.51 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12683397821044365		[learning rate: 0.00096476]
	Learning Rate: 0.000964764
	LOSS [training: 0.12683397821044365 | validation: 0.09496089422540699]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1065.pth
	Model improved!!!
EPOCH 1066/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1289526729663824		[learning rate: 0.00096243]
	Learning Rate: 0.000962428
	LOSS [training: 0.1289526729663824 | validation: 0.21280694872527037]
	TIME [epoch: 9.5 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1978243971035928		[learning rate: 0.0009601]
	Learning Rate: 0.000960098
	LOSS [training: 0.1978243971035928 | validation: 0.18290618874376216]
	TIME [epoch: 9.52 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2839014410534605		[learning rate: 0.00095777]
	Learning Rate: 0.000957774
	LOSS [training: 0.2839014410534605 | validation: 0.40214114724255356]
	TIME [epoch: 9.5 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.5324586848451613		[learning rate: 0.00095546]
	Learning Rate: 0.000955456
	LOSS [training: 0.5324586848451613 | validation: 0.3259611855786846]
	TIME [epoch: 9.5 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2793370212444098		[learning rate: 0.00095314]
	Learning Rate: 0.000953143
	LOSS [training: 0.2793370212444098 | validation: 0.1540628406784113]
	TIME [epoch: 9.5 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2019875255377288		[learning rate: 0.00095084]
	Learning Rate: 0.000950835
	LOSS [training: 0.2019875255377288 | validation: 0.21590002644656403]
	TIME [epoch: 9.52 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23084129554791238		[learning rate: 0.00094853]
	Learning Rate: 0.000948533
	LOSS [training: 0.23084129554791238 | validation: 0.1525389493409597]
	TIME [epoch: 9.49 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16998020239302214		[learning rate: 0.00094624]
	Learning Rate: 0.000946237
	LOSS [training: 0.16998020239302214 | validation: 0.12559552817930308]
	TIME [epoch: 9.49 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2586968370600399		[learning rate: 0.00094395]
	Learning Rate: 0.000943946
	LOSS [training: 0.2586968370600399 | validation: 0.28073481598943445]
	TIME [epoch: 9.52 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23972413425829542		[learning rate: 0.00094166]
	Learning Rate: 0.000941661
	LOSS [training: 0.23972413425829542 | validation: 0.14304820410876923]
	TIME [epoch: 9.5 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16612257313542064		[learning rate: 0.00093938]
	Learning Rate: 0.000939382
	LOSS [training: 0.16612257313542064 | validation: 0.15840340978961298]
	TIME [epoch: 9.5 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16675021067822177		[learning rate: 0.00093711]
	Learning Rate: 0.000937108
	LOSS [training: 0.16675021067822177 | validation: 0.13369543058257283]
	TIME [epoch: 9.5 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1704808356116543		[learning rate: 0.00093484]
	Learning Rate: 0.000934839
	LOSS [training: 0.1704808356116543 | validation: 0.13853548527720455]
	TIME [epoch: 9.51 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14904690026552075		[learning rate: 0.00093258]
	Learning Rate: 0.000932576
	LOSS [training: 0.14904690026552075 | validation: 0.14293703988533618]
	TIME [epoch: 9.5 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2135367007125457		[learning rate: 0.00093032]
	Learning Rate: 0.000930318
	LOSS [training: 0.2135367007125457 | validation: 0.20969250737716927]
	TIME [epoch: 9.5 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19213386360410406		[learning rate: 0.00092807]
	Learning Rate: 0.000928066
	LOSS [training: 0.19213386360410406 | validation: 0.09453522055642641]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1081.pth
	Model improved!!!
EPOCH 1082/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10736297425294636		[learning rate: 0.00092582]
	Learning Rate: 0.00092582
	LOSS [training: 0.10736297425294636 | validation: 0.1034173773221247]
	TIME [epoch: 9.5 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10819782826489692		[learning rate: 0.00092358]
	Learning Rate: 0.000923578
	LOSS [training: 0.10819782826489692 | validation: 0.14815810644345345]
	TIME [epoch: 9.49 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12160051958331612		[learning rate: 0.00092134]
	Learning Rate: 0.000921342
	LOSS [training: 0.12160051958331612 | validation: 0.10883557223622546]
	TIME [epoch: 9.5 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10926459950742591		[learning rate: 0.00091911]
	Learning Rate: 0.000919112
	LOSS [training: 0.10926459950742591 | validation: 0.12246306375797686]
	TIME [epoch: 9.52 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13068055277486001		[learning rate: 0.00091689]
	Learning Rate: 0.000916887
	LOSS [training: 0.13068055277486001 | validation: 0.13397830661867047]
	TIME [epoch: 9.5 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13747007838720024		[learning rate: 0.00091467]
	Learning Rate: 0.000914667
	LOSS [training: 0.13747007838720024 | validation: 0.1603580526275733]
	TIME [epoch: 9.49 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17532368117656172		[learning rate: 0.00091245]
	Learning Rate: 0.000912453
	LOSS [training: 0.17532368117656172 | validation: 0.14621922569703585]
	TIME [epoch: 9.51 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27606340718314293		[learning rate: 0.00091024]
	Learning Rate: 0.000910244
	LOSS [training: 0.27606340718314293 | validation: 0.2354455216363219]
	TIME [epoch: 9.5 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23963769671890756		[learning rate: 0.00090804]
	Learning Rate: 0.000908041
	LOSS [training: 0.23963769671890756 | validation: 0.1291501240521566]
	TIME [epoch: 9.49 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17876144501599084		[learning rate: 0.00090584]
	Learning Rate: 0.000905843
	LOSS [training: 0.17876144501599084 | validation: 0.1867217823826015]
	TIME [epoch: 9.5 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19136242943374787		[learning rate: 0.00090365]
	Learning Rate: 0.000903649
	LOSS [training: 0.19136242943374787 | validation: 0.10702965062930997]
	TIME [epoch: 9.5 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10992752243488864		[learning rate: 0.00090146]
	Learning Rate: 0.000901462
	LOSS [training: 0.10992752243488864 | validation: 0.11536945972521202]
	TIME [epoch: 9.49 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10566319270841402		[learning rate: 0.00089928]
	Learning Rate: 0.00089928
	LOSS [training: 0.10566319270841402 | validation: 0.08517374313908156]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1094.pth
	Model improved!!!
EPOCH 1095/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08912754773412587		[learning rate: 0.0008971]
	Learning Rate: 0.000897103
	LOSS [training: 0.08912754773412587 | validation: 0.11842786639434834]
	TIME [epoch: 9.51 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1749693156252198		[learning rate: 0.00089493]
	Learning Rate: 0.000894931
	LOSS [training: 0.1749693156252198 | validation: 0.313512131583353]
	TIME [epoch: 9.49 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.3425527413224113		[learning rate: 0.00089276]
	Learning Rate: 0.000892764
	LOSS [training: 0.3425527413224113 | validation: 0.24476860284441768]
	TIME [epoch: 9.49 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22157510074841102		[learning rate: 0.0008906]
	Learning Rate: 0.000890603
	LOSS [training: 0.22157510074841102 | validation: 0.16833882796242575]
	TIME [epoch: 9.5 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30846442995585194		[learning rate: 0.00088845]
	Learning Rate: 0.000888447
	LOSS [training: 0.30846442995585194 | validation: 0.24670417993273247]
	TIME [epoch: 9.5 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.24788601752977227		[learning rate: 0.0008863]
	Learning Rate: 0.000886296
	LOSS [training: 0.24788601752977227 | validation: 0.17581362833108863]
	TIME [epoch: 9.49 sec]
EPOCH 1101/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.32602862102246266		[learning rate: 0.00088415]
	Learning Rate: 0.000884151
	LOSS [training: 0.32602862102246266 | validation: 0.3280571335442265]
	TIME [epoch: 9.49 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4373361015873344		[learning rate: 0.00088201]
	Learning Rate: 0.00088201
	LOSS [training: 0.4373361015873344 | validation: 0.3146482588528371]
	TIME [epoch: 9.51 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30523406588676527		[learning rate: 0.00087988]
	Learning Rate: 0.000879875
	LOSS [training: 0.30523406588676527 | validation: 0.1522286705506702]
	TIME [epoch: 9.5 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17862570508816591		[learning rate: 0.00087775]
	Learning Rate: 0.000877745
	LOSS [training: 0.17862570508816591 | validation: 0.16483944447170248]
	TIME [epoch: 9.5 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17144669642515176		[learning rate: 0.00087562]
	Learning Rate: 0.00087562
	LOSS [training: 0.17144669642515176 | validation: 0.10682174716951473]
	TIME [epoch: 9.52 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12380493834712632		[learning rate: 0.0008735]
	Learning Rate: 0.000873501
	LOSS [training: 0.12380493834712632 | validation: 0.12657497389382905]
	TIME [epoch: 9.5 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1349430928635021		[learning rate: 0.00087139]
	Learning Rate: 0.000871386
	LOSS [training: 0.1349430928635021 | validation: 0.171845630170373]
	TIME [epoch: 9.5 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1373435847664351		[learning rate: 0.00086928]
	Learning Rate: 0.000869277
	LOSS [training: 0.1373435847664351 | validation: 0.13270542208026245]
	TIME [epoch: 9.49 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14761521152780363		[learning rate: 0.00086717]
	Learning Rate: 0.000867172
	LOSS [training: 0.14761521152780363 | validation: 0.16523594479234802]
	TIME [epoch: 9.51 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14781388531663814		[learning rate: 0.00086507]
	Learning Rate: 0.000865073
	LOSS [training: 0.14781388531663814 | validation: 0.18044444301703322]
	TIME [epoch: 9.49 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18873895902186827		[learning rate: 0.00086298]
	Learning Rate: 0.000862979
	LOSS [training: 0.18873895902186827 | validation: 0.20437757279149213]
	TIME [epoch: 9.49 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15251268118574263		[learning rate: 0.00086089]
	Learning Rate: 0.000860889
	LOSS [training: 0.15251268118574263 | validation: 0.1276483304265964]
	TIME [epoch: 9.51 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10894797217657701		[learning rate: 0.00085881]
	Learning Rate: 0.000858805
	LOSS [training: 0.10894797217657701 | validation: 0.11307823851348234]
	TIME [epoch: 9.5 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14427574509703903		[learning rate: 0.00085673]
	Learning Rate: 0.000856726
	LOSS [training: 0.14427574509703903 | validation: 0.1182459489662351]
	TIME [epoch: 9.49 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1727437902782823		[learning rate: 0.00085465]
	Learning Rate: 0.000854652
	LOSS [training: 0.1727437902782823 | validation: 0.22204192971849512]
	TIME [epoch: 9.5 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20943062277198363		[learning rate: 0.00085258]
	Learning Rate: 0.000852583
	LOSS [training: 0.20943062277198363 | validation: 0.20624883001021949]
	TIME [epoch: 9.51 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16060277313656582		[learning rate: 0.00085052]
	Learning Rate: 0.000850519
	LOSS [training: 0.16060277313656582 | validation: 0.17352892260117572]
	TIME [epoch: 9.5 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18261085234527952		[learning rate: 0.00084846]
	Learning Rate: 0.00084846
	LOSS [training: 0.18261085234527952 | validation: 0.20699848528125325]
	TIME [epoch: 9.49 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17026661710221394		[learning rate: 0.00084641]
	Learning Rate: 0.000846406
	LOSS [training: 0.17026661710221394 | validation: 0.164764319676911]
	TIME [epoch: 9.51 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1744968160904681		[learning rate: 0.00084436]
	Learning Rate: 0.000844357
	LOSS [training: 0.1744968160904681 | validation: 0.2642176140827936]
	TIME [epoch: 9.5 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.27934860475643764		[learning rate: 0.00084231]
	Learning Rate: 0.000842313
	LOSS [training: 0.27934860475643764 | validation: 0.248444928928986]
	TIME [epoch: 9.5 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20721066471021704		[learning rate: 0.00084027]
	Learning Rate: 0.000840274
	LOSS [training: 0.20721066471021704 | validation: 0.2250383942685835]
	TIME [epoch: 9.5 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20780123895918817		[learning rate: 0.00083824]
	Learning Rate: 0.00083824
	LOSS [training: 0.20780123895918817 | validation: 0.20348295916217646]
	TIME [epoch: 9.52 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15477442063131702		[learning rate: 0.00083621]
	Learning Rate: 0.000836211
	LOSS [training: 0.15477442063131702 | validation: 0.15291587110849364]
	TIME [epoch: 9.5 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15665600592755669		[learning rate: 0.00083419]
	Learning Rate: 0.000834187
	LOSS [training: 0.15665600592755669 | validation: 0.14497333283956837]
	TIME [epoch: 9.5 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13101188782978485		[learning rate: 0.00083217]
	Learning Rate: 0.000832167
	LOSS [training: 0.13101188782978485 | validation: 0.15215316368841508]
	TIME [epoch: 9.51 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14884133438692998		[learning rate: 0.00083015]
	Learning Rate: 0.000830152
	LOSS [training: 0.14884133438692998 | validation: 0.16278989264393823]
	TIME [epoch: 9.5 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14625965830545237		[learning rate: 0.00082814]
	Learning Rate: 0.000828143
	LOSS [training: 0.14625965830545237 | validation: 0.09506845836381285]
	TIME [epoch: 9.49 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1243891212033487		[learning rate: 0.00082614]
	Learning Rate: 0.000826138
	LOSS [training: 0.1243891212033487 | validation: 0.0943800972197031]
	TIME [epoch: 9.49 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09962046861503891		[learning rate: 0.00082414]
	Learning Rate: 0.000824138
	LOSS [training: 0.09962046861503891 | validation: 0.08958267208986627]
	TIME [epoch: 9.51 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10185479874187334		[learning rate: 0.00082214]
	Learning Rate: 0.000822143
	LOSS [training: 0.10185479874187334 | validation: 0.10802722039304329]
	TIME [epoch: 9.49 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11686266523535813		[learning rate: 0.00082015]
	Learning Rate: 0.000820153
	LOSS [training: 0.11686266523535813 | validation: 0.13176075229156017]
	TIME [epoch: 9.5 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1363870123494007		[learning rate: 0.00081817]
	Learning Rate: 0.000818167
	LOSS [training: 0.1363870123494007 | validation: 0.11297122107122556]
	TIME [epoch: 9.51 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10042448831789023		[learning rate: 0.00081619]
	Learning Rate: 0.000816187
	LOSS [training: 0.10042448831789023 | validation: 0.11110286989199537]
	TIME [epoch: 9.5 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09757270672379233		[learning rate: 0.00081421]
	Learning Rate: 0.000814211
	LOSS [training: 0.09757270672379233 | validation: 0.08916321140617732]
	TIME [epoch: 9.5 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11602014170387456		[learning rate: 0.00081224]
	Learning Rate: 0.00081224
	LOSS [training: 0.11602014170387456 | validation: 0.09354176974753331]
	TIME [epoch: 9.49 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09356572354464056		[learning rate: 0.00081027]
	Learning Rate: 0.000810273
	LOSS [training: 0.09356572354464056 | validation: 0.11938536870999858]
	TIME [epoch: 9.52 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15792370067764927		[learning rate: 0.00080831]
	Learning Rate: 0.000808312
	LOSS [training: 0.15792370067764927 | validation: 0.16985198822034617]
	TIME [epoch: 9.49 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15869593882533478		[learning rate: 0.00080636]
	Learning Rate: 0.000806355
	LOSS [training: 0.15869593882533478 | validation: 0.10941949050719445]
	TIME [epoch: 9.49 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09134419601088781		[learning rate: 0.0008044]
	Learning Rate: 0.000804403
	LOSS [training: 0.09134419601088781 | validation: 0.08494222218534665]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1140.pth
	Model improved!!!
EPOCH 1141/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10147950240263201		[learning rate: 0.00080246]
	Learning Rate: 0.000802456
	LOSS [training: 0.10147950240263201 | validation: 0.07172950755735535]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1141.pth
	Model improved!!!
EPOCH 1142/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.084977620929922		[learning rate: 0.00080051]
	Learning Rate: 0.000800513
	LOSS [training: 0.084977620929922 | validation: 0.09811212802443767]
	TIME [epoch: 9.49 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10488247555680723		[learning rate: 0.00079858]
	Learning Rate: 0.000798575
	LOSS [training: 0.10488247555680723 | validation: 0.09567717323748413]
	TIME [epoch: 9.49 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09668133607667304		[learning rate: 0.00079664]
	Learning Rate: 0.000796642
	LOSS [training: 0.09668133607667304 | validation: 0.06901094046763585]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1144.pth
	Model improved!!!
EPOCH 1145/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0846250642284591		[learning rate: 0.00079471]
	Learning Rate: 0.000794713
	LOSS [training: 0.0846250642284591 | validation: 0.09521712080696887]
	TIME [epoch: 9.5 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08609383478296764		[learning rate: 0.00079279]
	Learning Rate: 0.00079279
	LOSS [training: 0.08609383478296764 | validation: 0.0849416257745985]
	TIME [epoch: 9.51 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.102728377600578		[learning rate: 0.00079087]
	Learning Rate: 0.00079087
	LOSS [training: 0.102728377600578 | validation: 0.10004976215634559]
	TIME [epoch: 9.53 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10993874286840144		[learning rate: 0.00078896]
	Learning Rate: 0.000788956
	LOSS [training: 0.10993874286840144 | validation: 0.0693862953181498]
	TIME [epoch: 9.5 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11449332348315591		[learning rate: 0.00078705]
	Learning Rate: 0.000787046
	LOSS [training: 0.11449332348315591 | validation: 0.1356985240702738]
	TIME [epoch: 9.51 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1964145141127335		[learning rate: 0.00078514]
	Learning Rate: 0.000785141
	LOSS [training: 0.1964145141127335 | validation: 0.169801127811227]
	TIME [epoch: 9.51 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17492610291788463		[learning rate: 0.00078324]
	Learning Rate: 0.00078324
	LOSS [training: 0.17492610291788463 | validation: 0.1284328443901995]
	TIME [epoch: 9.52 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14078395803657373		[learning rate: 0.00078134]
	Learning Rate: 0.000781344
	LOSS [training: 0.14078395803657373 | validation: 0.08953459174132661]
	TIME [epoch: 9.5 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08230734942441405		[learning rate: 0.00077945]
	Learning Rate: 0.000779452
	LOSS [training: 0.08230734942441405 | validation: 0.16868715279231977]
	TIME [epoch: 9.5 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1503717202951189		[learning rate: 0.00077757]
	Learning Rate: 0.000777565
	LOSS [training: 0.1503717202951189 | validation: 0.10181732464779857]
	TIME [epoch: 9.52 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10954361425385568		[learning rate: 0.00077568]
	Learning Rate: 0.000775683
	LOSS [training: 0.10954361425385568 | validation: 0.09945127481409269]
	TIME [epoch: 9.5 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17383001615173851		[learning rate: 0.00077381]
	Learning Rate: 0.000773805
	LOSS [training: 0.17383001615173851 | validation: 0.19492296354537011]
	TIME [epoch: 9.5 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17486847245331272		[learning rate: 0.00077193]
	Learning Rate: 0.000771932
	LOSS [training: 0.17486847245331272 | validation: 0.1487010602789263]
	TIME [epoch: 9.52 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1653374926092696		[learning rate: 0.00077006]
	Learning Rate: 0.000770063
	LOSS [training: 0.1653374926092696 | validation: 0.29450418289860997]
	TIME [epoch: 9.51 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.4793816307719679		[learning rate: 0.0007682]
	Learning Rate: 0.000768199
	LOSS [training: 0.4793816307719679 | validation: 0.3811907530505959]
	TIME [epoch: 9.5 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.39268563779830534		[learning rate: 0.00076634]
	Learning Rate: 0.000766339
	LOSS [training: 0.39268563779830534 | validation: 0.3234922617060779]
	TIME [epoch: 9.51 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35168112590797795		[learning rate: 0.00076448]
	Learning Rate: 0.000764484
	LOSS [training: 0.35168112590797795 | validation: 0.2414255620865421]
	TIME [epoch: 9.52 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2619758210187513		[learning rate: 0.00076263]
	Learning Rate: 0.000762633
	LOSS [training: 0.2619758210187513 | validation: 0.2576446740392158]
	TIME [epoch: 9.51 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25349008026827613		[learning rate: 0.00076079]
	Learning Rate: 0.000760787
	LOSS [training: 0.25349008026827613 | validation: 0.180028430206791]
	TIME [epoch: 9.5 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16630307798935198		[learning rate: 0.00075895]
	Learning Rate: 0.000758945
	LOSS [training: 0.16630307798935198 | validation: 0.14504400629747116]
	TIME [epoch: 9.52 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16340278014084053		[learning rate: 0.00075711]
	Learning Rate: 0.000757108
	LOSS [training: 0.16340278014084053 | validation: 0.2311166293962481]
	TIME [epoch: 9.51 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16851749537967994		[learning rate: 0.00075528]
	Learning Rate: 0.000755275
	LOSS [training: 0.16851749537967994 | validation: 0.11953487957178556]
	TIME [epoch: 9.5 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1677402125927649		[learning rate: 0.00075345]
	Learning Rate: 0.000753447
	LOSS [training: 0.1677402125927649 | validation: 0.2066553082647382]
	TIME [epoch: 9.51 sec]
EPOCH 1168/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2789020867007688		[learning rate: 0.00075162]
	Learning Rate: 0.000751623
	LOSS [training: 0.2789020867007688 | validation: 0.23116431872853974]
	TIME [epoch: 9.52 sec]
EPOCH 1169/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2322652195094926		[learning rate: 0.0007498]
	Learning Rate: 0.000749803
	LOSS [training: 0.2322652195094926 | validation: 0.18369468796736357]
	TIME [epoch: 9.5 sec]
EPOCH 1170/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15872345763841772		[learning rate: 0.00074799]
	Learning Rate: 0.000747988
	LOSS [training: 0.15872345763841772 | validation: 0.14158046288981485]
	TIME [epoch: 9.5 sec]
EPOCH 1171/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11844091092412265		[learning rate: 0.00074618]
	Learning Rate: 0.000746177
	LOSS [training: 0.11844091092412265 | validation: 0.11226759642899146]
	TIME [epoch: 9.52 sec]
EPOCH 1172/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10681492188937178		[learning rate: 0.00074437]
	Learning Rate: 0.000744371
	LOSS [training: 0.10681492188937178 | validation: 0.12254029238551811]
	TIME [epoch: 9.51 sec]
EPOCH 1173/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1136115724673541		[learning rate: 0.00074257]
	Learning Rate: 0.000742569
	LOSS [training: 0.1136115724673541 | validation: 0.10427241420608503]
	TIME [epoch: 9.5 sec]
EPOCH 1174/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08209247916332403		[learning rate: 0.00074077]
	Learning Rate: 0.000740771
	LOSS [training: 0.08209247916332403 | validation: 0.10276100903414787]
	TIME [epoch: 9.51 sec]
EPOCH 1175/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12577785572587455		[learning rate: 0.00073898]
	Learning Rate: 0.000738978
	LOSS [training: 0.12577785572587455 | validation: 0.1388757281855864]
	TIME [epoch: 9.52 sec]
EPOCH 1176/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13049863287802793		[learning rate: 0.00073719]
	Learning Rate: 0.000737189
	LOSS [training: 0.13049863287802793 | validation: 0.09051297836558385]
	TIME [epoch: 9.5 sec]
EPOCH 1177/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1015287621662039		[learning rate: 0.0007354]
	Learning Rate: 0.000735405
	LOSS [training: 0.1015287621662039 | validation: 0.08653996411800206]
	TIME [epoch: 9.5 sec]
EPOCH 1178/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07178379529624312		[learning rate: 0.00073362]
	Learning Rate: 0.000733624
	LOSS [training: 0.07178379529624312 | validation: 0.10311279924784718]
	TIME [epoch: 9.52 sec]
EPOCH 1179/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11585712017865783		[learning rate: 0.00073185]
	Learning Rate: 0.000731848
	LOSS [training: 0.11585712017865783 | validation: 0.13439816151048628]
	TIME [epoch: 9.51 sec]
EPOCH 1180/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11354003076636794		[learning rate: 0.00073008]
	Learning Rate: 0.000730077
	LOSS [training: 0.11354003076636794 | validation: 0.09723194054733193]
	TIME [epoch: 9.5 sec]
EPOCH 1181/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11222022912449678		[learning rate: 0.00072831]
	Learning Rate: 0.000728309
	LOSS [training: 0.11222022912449678 | validation: 0.12341493958867979]
	TIME [epoch: 9.5 sec]
EPOCH 1182/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1455707744239313		[learning rate: 0.00072655]
	Learning Rate: 0.000726546
	LOSS [training: 0.1455707744239313 | validation: 0.11172098135850496]
	TIME [epoch: 9.52 sec]
EPOCH 1183/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14042743547203979		[learning rate: 0.00072479]
	Learning Rate: 0.000724787
	LOSS [training: 0.14042743547203979 | validation: 0.08598533308727674]
	TIME [epoch: 9.5 sec]
EPOCH 1184/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08899285491063721		[learning rate: 0.00072303]
	Learning Rate: 0.000723033
	LOSS [training: 0.08899285491063721 | validation: 0.07836718243184822]
	TIME [epoch: 9.5 sec]
EPOCH 1185/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08230860112039186		[learning rate: 0.00072128]
	Learning Rate: 0.000721282
	LOSS [training: 0.08230860112039186 | validation: 0.07927156645430221]
	TIME [epoch: 9.52 sec]
EPOCH 1186/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07339747600768934		[learning rate: 0.00071954]
	Learning Rate: 0.000719536
	LOSS [training: 0.07339747600768934 | validation: 0.0708166562720718]
	TIME [epoch: 9.51 sec]
EPOCH 1187/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07294418582033682		[learning rate: 0.00071779]
	Learning Rate: 0.000717794
	LOSS [training: 0.07294418582033682 | validation: 0.06893540267401153]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1187.pth
	Model improved!!!
EPOCH 1188/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08510529265422825		[learning rate: 0.00071606]
	Learning Rate: 0.000716057
	LOSS [training: 0.08510529265422825 | validation: 0.09126709140804039]
	TIME [epoch: 9.5 sec]
EPOCH 1189/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07204378355234813		[learning rate: 0.00071432]
	Learning Rate: 0.000714323
	LOSS [training: 0.07204378355234813 | validation: 0.06667560743993535]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1189.pth
	Model improved!!!
EPOCH 1190/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07377939984071961		[learning rate: 0.00071259]
	Learning Rate: 0.000712594
	LOSS [training: 0.07377939984071961 | validation: 0.08621746821179166]
	TIME [epoch: 9.5 sec]
EPOCH 1191/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1017841438305949		[learning rate: 0.00071087]
	Learning Rate: 0.000710869
	LOSS [training: 0.1017841438305949 | validation: 0.15173614660713777]
	TIME [epoch: 9.49 sec]
EPOCH 1192/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1376432539756594		[learning rate: 0.00070915]
	Learning Rate: 0.000709148
	LOSS [training: 0.1376432539756594 | validation: 0.09292254833826974]
	TIME [epoch: 9.52 sec]
EPOCH 1193/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09806196229145345		[learning rate: 0.00070743]
	Learning Rate: 0.000707431
	LOSS [training: 0.09806196229145345 | validation: 0.06365503288422554]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1193.pth
	Model improved!!!
EPOCH 1194/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07163588754153126		[learning rate: 0.00070572]
	Learning Rate: 0.000705719
	LOSS [training: 0.07163588754153126 | validation: 0.0662832981862225]
	TIME [epoch: 9.5 sec]
EPOCH 1195/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07875960707717698		[learning rate: 0.00070401]
	Learning Rate: 0.00070401
	LOSS [training: 0.07875960707717698 | validation: 0.06996269064007234]
	TIME [epoch: 9.5 sec]
EPOCH 1196/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10875039081040945		[learning rate: 0.00070231]
	Learning Rate: 0.000702306
	LOSS [training: 0.10875039081040945 | validation: 0.13087922607212624]
	TIME [epoch: 9.5 sec]
EPOCH 1197/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16843964471763126		[learning rate: 0.00070061]
	Learning Rate: 0.000700606
	LOSS [training: 0.16843964471763126 | validation: 0.10148134943737314]
	TIME [epoch: 9.5 sec]
EPOCH 1198/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09969267448677163		[learning rate: 0.00069891]
	Learning Rate: 0.00069891
	LOSS [training: 0.09969267448677163 | validation: 0.0731814065586768]
	TIME [epoch: 9.5 sec]
EPOCH 1199/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10376095148486812		[learning rate: 0.00069722]
	Learning Rate: 0.000697218
	LOSS [training: 0.10376095148486812 | validation: 0.12241328757190222]
	TIME [epoch: 9.51 sec]
EPOCH 1200/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1552327150825123		[learning rate: 0.00069553]
	Learning Rate: 0.00069553
	LOSS [training: 0.1552327150825123 | validation: 0.174950089449084]
	TIME [epoch: 9.5 sec]
EPOCH 1201/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.30528443598299476		[learning rate: 0.00069385]
	Learning Rate: 0.000693846
	LOSS [training: 0.30528443598299476 | validation: 0.38624057744639956]
	TIME [epoch: 9.49 sec]
EPOCH 1202/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.43706975593909797		[learning rate: 0.00069217]
	Learning Rate: 0.000692166
	LOSS [training: 0.43706975593909797 | validation: 0.25834936321945096]
	TIME [epoch: 9.5 sec]
EPOCH 1203/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.35233804815960745		[learning rate: 0.00069049]
	Learning Rate: 0.000690491
	LOSS [training: 0.35233804815960745 | validation: 0.27142372260728725]
	TIME [epoch: 9.51 sec]
EPOCH 1204/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2719567561405079		[learning rate: 0.00068882]
	Learning Rate: 0.000688819
	LOSS [training: 0.2719567561405079 | validation: 0.14956804975644122]
	TIME [epoch: 9.5 sec]
EPOCH 1205/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18269037516690628		[learning rate: 0.00068715]
	Learning Rate: 0.000687152
	LOSS [training: 0.18269037516690628 | validation: 0.15892792667133004]
	TIME [epoch: 9.49 sec]
EPOCH 1206/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16308152933408127		[learning rate: 0.00068549]
	Learning Rate: 0.000685488
	LOSS [training: 0.16308152933408127 | validation: 0.1417400375554434]
	TIME [epoch: 9.51 sec]
EPOCH 1207/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.25143010671937727		[learning rate: 0.00068383]
	Learning Rate: 0.000683829
	LOSS [training: 0.25143010671937727 | validation: 0.3580838224981702]
	TIME [epoch: 9.5 sec]
EPOCH 1208/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2751748049844183		[learning rate: 0.00068217]
	Learning Rate: 0.000682173
	LOSS [training: 0.2751748049844183 | validation: 0.1165028982390671]
	TIME [epoch: 9.5 sec]
EPOCH 1209/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11199033799953886		[learning rate: 0.00068052]
	Learning Rate: 0.000680522
	LOSS [training: 0.11199033799953886 | validation: 0.16375777185957519]
	TIME [epoch: 9.51 sec]
EPOCH 1210/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20812122463374294		[learning rate: 0.00067887]
	Learning Rate: 0.000678874
	LOSS [training: 0.20812122463374294 | validation: 0.17979921886498365]
	TIME [epoch: 9.5 sec]
EPOCH 1211/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1413732879994997		[learning rate: 0.00067723]
	Learning Rate: 0.000677231
	LOSS [training: 0.1413732879994997 | validation: 0.09114265270031414]
	TIME [epoch: 9.49 sec]
EPOCH 1212/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10873818766154564		[learning rate: 0.00067559]
	Learning Rate: 0.000675592
	LOSS [training: 0.10873818766154564 | validation: 0.11077611327514639]
	TIME [epoch: 9.5 sec]
EPOCH 1213/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10142434101353456		[learning rate: 0.00067396]
	Learning Rate: 0.000673956
	LOSS [training: 0.10142434101353456 | validation: 0.08465934557551905]
	TIME [epoch: 9.52 sec]
EPOCH 1214/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11046347809267862		[learning rate: 0.00067232]
	Learning Rate: 0.000672325
	LOSS [training: 0.11046347809267862 | validation: 0.11018698624178733]
	TIME [epoch: 9.5 sec]
EPOCH 1215/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10458152088366546		[learning rate: 0.0006707]
	Learning Rate: 0.000670697
	LOSS [training: 0.10458152088366546 | validation: 0.1244914747795494]
	TIME [epoch: 9.49 sec]
EPOCH 1216/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1342618668635434		[learning rate: 0.00066907]
	Learning Rate: 0.000669073
	LOSS [training: 0.1342618668635434 | validation: 0.15556795007854043]
	TIME [epoch: 9.51 sec]
EPOCH 1217/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16830985854412966		[learning rate: 0.00066745]
	Learning Rate: 0.000667454
	LOSS [training: 0.16830985854412966 | validation: 0.18759366259240703]
	TIME [epoch: 9.5 sec]
EPOCH 1218/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1654280467071823		[learning rate: 0.00066584]
	Learning Rate: 0.000665838
	LOSS [training: 0.1654280467071823 | validation: 0.15311383835355774]
	TIME [epoch: 9.5 sec]
EPOCH 1219/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13231383824506368		[learning rate: 0.00066423]
	Learning Rate: 0.000664226
	LOSS [training: 0.13231383824506368 | validation: 0.14104370709636876]
	TIME [epoch: 9.49 sec]
EPOCH 1220/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11913381026207523		[learning rate: 0.00066262]
	Learning Rate: 0.000662618
	LOSS [training: 0.11913381026207523 | validation: 0.10227090040936049]
	TIME [epoch: 9.52 sec]
EPOCH 1221/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1206988549912005		[learning rate: 0.00066101]
	Learning Rate: 0.000661014
	LOSS [training: 0.1206988549912005 | validation: 0.11476009614718237]
	TIME [epoch: 9.49 sec]
EPOCH 1222/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10274170790871098		[learning rate: 0.00065941]
	Learning Rate: 0.000659414
	LOSS [training: 0.10274170790871098 | validation: 0.13809078581874745]
	TIME [epoch: 9.5 sec]
EPOCH 1223/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11683520808366965		[learning rate: 0.00065782]
	Learning Rate: 0.000657817
	LOSS [training: 0.11683520808366965 | validation: 0.12704582769322065]
	TIME [epoch: 9.51 sec]
EPOCH 1224/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12062916244112609		[learning rate: 0.00065622]
	Learning Rate: 0.000656225
	LOSS [training: 0.12062916244112609 | validation: 0.17370893348664468]
	TIME [epoch: 9.5 sec]
EPOCH 1225/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11604223399980315		[learning rate: 0.00065464]
	Learning Rate: 0.000654636
	LOSS [training: 0.11604223399980315 | validation: 0.10675065236406557]
	TIME [epoch: 9.49 sec]
EPOCH 1226/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08042144231594385		[learning rate: 0.00065305]
	Learning Rate: 0.000653051
	LOSS [training: 0.08042144231594385 | validation: 0.07819255586847834]
	TIME [epoch: 9.5 sec]
EPOCH 1227/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0667066925842891		[learning rate: 0.00065147]
	Learning Rate: 0.000651471
	LOSS [training: 0.0667066925842891 | validation: 0.0687503774290278]
	TIME [epoch: 9.51 sec]
EPOCH 1228/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09412448237190267		[learning rate: 0.00064989]
	Learning Rate: 0.000649893
	LOSS [training: 0.09412448237190267 | validation: 0.10363190320161375]
	TIME [epoch: 9.5 sec]
EPOCH 1229/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08989309365892521		[learning rate: 0.00064832]
	Learning Rate: 0.00064832
	LOSS [training: 0.08989309365892521 | validation: 0.08700123461043184]
	TIME [epoch: 9.49 sec]
EPOCH 1230/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09462705883327852		[learning rate: 0.00064675]
	Learning Rate: 0.000646751
	LOSS [training: 0.09462705883327852 | validation: 0.11419547716770202]
	TIME [epoch: 9.51 sec]
EPOCH 1231/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09331071779735971		[learning rate: 0.00064519]
	Learning Rate: 0.000645185
	LOSS [training: 0.09331071779735971 | validation: 0.10684078662864152]
	TIME [epoch: 9.5 sec]
EPOCH 1232/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10988314017220897		[learning rate: 0.00064362]
	Learning Rate: 0.000643623
	LOSS [training: 0.10988314017220897 | validation: 0.12136514329609913]
	TIME [epoch: 9.49 sec]
EPOCH 1233/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14305653651621128		[learning rate: 0.00064206]
	Learning Rate: 0.000642065
	LOSS [training: 0.14305653651621128 | validation: 0.17178599319947085]
	TIME [epoch: 9.49 sec]
EPOCH 1234/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17950210319453563		[learning rate: 0.00064051]
	Learning Rate: 0.000640511
	LOSS [training: 0.17950210319453563 | validation: 0.1800448447870663]
	TIME [epoch: 9.51 sec]
EPOCH 1235/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19701586556736994		[learning rate: 0.00063896]
	Learning Rate: 0.00063896
	LOSS [training: 0.19701586556736994 | validation: 0.23053327224831968]
	TIME [epoch: 9.49 sec]
EPOCH 1236/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21619719677579793		[learning rate: 0.00063741]
	Learning Rate: 0.000637413
	LOSS [training: 0.21619719677579793 | validation: 0.20381365366061485]
	TIME [epoch: 9.5 sec]
EPOCH 1237/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16308186327762486		[learning rate: 0.00063587]
	Learning Rate: 0.00063587
	LOSS [training: 0.16308186327762486 | validation: 0.10915634624544117]
	TIME [epoch: 9.51 sec]
EPOCH 1238/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10601380829072948		[learning rate: 0.00063433]
	Learning Rate: 0.000634331
	LOSS [training: 0.10601380829072948 | validation: 0.10979317870655741]
	TIME [epoch: 9.49 sec]
EPOCH 1239/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10296449769203678		[learning rate: 0.0006328]
	Learning Rate: 0.000632795
	LOSS [training: 0.10296449769203678 | validation: 0.10575176647891339]
	TIME [epoch: 9.5 sec]
EPOCH 1240/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11040790486038461		[learning rate: 0.00063126]
	Learning Rate: 0.000631263
	LOSS [training: 0.11040790486038461 | validation: 0.14097218513126827]
	TIME [epoch: 9.5 sec]
EPOCH 1241/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1362416969250496		[learning rate: 0.00062974]
	Learning Rate: 0.000629735
	LOSS [training: 0.1362416969250496 | validation: 0.11906222640092114]
	TIME [epoch: 9.51 sec]
EPOCH 1242/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10489540230182082		[learning rate: 0.00062821]
	Learning Rate: 0.00062821
	LOSS [training: 0.10489540230182082 | validation: 0.10248747189297255]
	TIME [epoch: 9.5 sec]
EPOCH 1243/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11417883168483589		[learning rate: 0.00062669]
	Learning Rate: 0.00062669
	LOSS [training: 0.11417883168483589 | validation: 0.1194514578263027]
	TIME [epoch: 9.5 sec]
EPOCH 1244/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0941044723552394		[learning rate: 0.00062517]
	Learning Rate: 0.000625173
	LOSS [training: 0.0941044723552394 | validation: 0.10443870838656917]
	TIME [epoch: 9.51 sec]
EPOCH 1245/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08553038955125417		[learning rate: 0.00062366]
	Learning Rate: 0.000623659
	LOSS [training: 0.08553038955125417 | validation: 0.07944840538912835]
	TIME [epoch: 9.5 sec]
EPOCH 1246/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08821600369269637		[learning rate: 0.00062215]
	Learning Rate: 0.000622149
	LOSS [training: 0.08821600369269637 | validation: 0.10059203998845266]
	TIME [epoch: 9.49 sec]
EPOCH 1247/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08751018065371494		[learning rate: 0.00062064]
	Learning Rate: 0.000620643
	LOSS [training: 0.08751018065371494 | validation: 0.11710932148607882]
	TIME [epoch: 9.49 sec]
EPOCH 1248/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10241570307296263		[learning rate: 0.00061914]
	Learning Rate: 0.000619141
	LOSS [training: 0.10241570307296263 | validation: 0.09039237775196911]
	TIME [epoch: 9.51 sec]
EPOCH 1249/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08043455217981692		[learning rate: 0.00061764]
	Learning Rate: 0.000617642
	LOSS [training: 0.08043455217981692 | validation: 0.07629191684755883]
	TIME [epoch: 9.49 sec]
EPOCH 1250/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07446471375100594		[learning rate: 0.00061615]
	Learning Rate: 0.000616147
	LOSS [training: 0.07446471375100594 | validation: 0.0997179180522625]
	TIME [epoch: 9.5 sec]
EPOCH 1251/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07660075689035856		[learning rate: 0.00061466]
	Learning Rate: 0.000614655
	LOSS [training: 0.07660075689035856 | validation: 0.0880812458758281]
	TIME [epoch: 9.51 sec]
EPOCH 1252/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.092895889307998		[learning rate: 0.00061317]
	Learning Rate: 0.000613167
	LOSS [training: 0.092895889307998 | validation: 0.10348105846776935]
	TIME [epoch: 9.5 sec]
EPOCH 1253/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11430558288166681		[learning rate: 0.00061168]
	Learning Rate: 0.000611683
	LOSS [training: 0.11430558288166681 | validation: 0.07691809129331992]
	TIME [epoch: 9.49 sec]
EPOCH 1254/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10213319577167981		[learning rate: 0.0006102]
	Learning Rate: 0.000610202
	LOSS [training: 0.10213319577167981 | validation: 0.0876300222477841]
	TIME [epoch: 9.5 sec]
EPOCH 1255/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08360363907113233		[learning rate: 0.00060872]
	Learning Rate: 0.000608725
	LOSS [training: 0.08360363907113233 | validation: 0.095864483103381]
	TIME [epoch: 9.51 sec]
EPOCH 1256/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08294988460577397		[learning rate: 0.00060725]
	Learning Rate: 0.000607251
	LOSS [training: 0.08294988460577397 | validation: 0.08466644381580488]
	TIME [epoch: 9.49 sec]
EPOCH 1257/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09549942683731831		[learning rate: 0.00060578]
	Learning Rate: 0.000605781
	LOSS [training: 0.09549942683731831 | validation: 0.10485776202730954]
	TIME [epoch: 9.49 sec]
EPOCH 1258/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08485679912864828		[learning rate: 0.00060431]
	Learning Rate: 0.000604315
	LOSS [training: 0.08485679912864828 | validation: 0.07909161158326171]
	TIME [epoch: 9.51 sec]
EPOCH 1259/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08107458017919128		[learning rate: 0.00060285]
	Learning Rate: 0.000602852
	LOSS [training: 0.08107458017919128 | validation: 0.07569379288650369]
	TIME [epoch: 9.49 sec]
EPOCH 1260/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07473471397084258		[learning rate: 0.00060139]
	Learning Rate: 0.000601392
	LOSS [training: 0.07473471397084258 | validation: 0.1057414230409389]
	TIME [epoch: 9.49 sec]
EPOCH 1261/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08481842302420563		[learning rate: 0.00059994]
	Learning Rate: 0.000599936
	LOSS [training: 0.08481842302420563 | validation: 0.07212830710358577]
	TIME [epoch: 9.49 sec]
EPOCH 1262/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0734617728941821		[learning rate: 0.00059848]
	Learning Rate: 0.000598484
	LOSS [training: 0.0734617728941821 | validation: 0.08725287747638931]
	TIME [epoch: 9.51 sec]
EPOCH 1263/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09450385008129503		[learning rate: 0.00059704]
	Learning Rate: 0.000597035
	LOSS [training: 0.09450385008129503 | validation: 0.07831540326776663]
	TIME [epoch: 9.5 sec]
EPOCH 1264/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08213053406283652		[learning rate: 0.00059559]
	Learning Rate: 0.00059559
	LOSS [training: 0.08213053406283652 | validation: 0.09537473105681098]
	TIME [epoch: 9.49 sec]
EPOCH 1265/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08690819015279708		[learning rate: 0.00059415]
	Learning Rate: 0.000594148
	LOSS [training: 0.08690819015279708 | validation: 0.10997867666562511]
	TIME [epoch: 9.51 sec]
EPOCH 1266/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11840680343294516		[learning rate: 0.00059271]
	Learning Rate: 0.00059271
	LOSS [training: 0.11840680343294516 | validation: 0.12070798597324818]
	TIME [epoch: 9.5 sec]
EPOCH 1267/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12143585767591239		[learning rate: 0.00059128]
	Learning Rate: 0.000591275
	LOSS [training: 0.12143585767591239 | validation: 0.13192917256513975]
	TIME [epoch: 9.5 sec]
EPOCH 1268/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11342785674448723		[learning rate: 0.00058984]
	Learning Rate: 0.000589844
	LOSS [training: 0.11342785674448723 | validation: 0.14118863508399582]
	TIME [epoch: 9.5 sec]
EPOCH 1269/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15957461971994397		[learning rate: 0.00058842]
	Learning Rate: 0.000588416
	LOSS [training: 0.15957461971994397 | validation: 0.12758702251367468]
	TIME [epoch: 9.51 sec]
EPOCH 1270/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1270717398604343		[learning rate: 0.00058699]
	Learning Rate: 0.000586991
	LOSS [training: 0.1270717398604343 | validation: 0.11080573836287688]
	TIME [epoch: 9.49 sec]
EPOCH 1271/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12154503361147975		[learning rate: 0.00058557]
	Learning Rate: 0.00058557
	LOSS [training: 0.12154503361147975 | validation: 0.17432654446739473]
	TIME [epoch: 9.49 sec]
EPOCH 1272/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15261724092858037		[learning rate: 0.00058415]
	Learning Rate: 0.000584153
	LOSS [training: 0.15261724092858037 | validation: 0.168457272982619]
	TIME [epoch: 9.51 sec]
EPOCH 1273/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17645363268340203		[learning rate: 0.00058274]
	Learning Rate: 0.000582738
	LOSS [training: 0.17645363268340203 | validation: 0.16906342065098223]
	TIME [epoch: 9.5 sec]
EPOCH 1274/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14890941537149177		[learning rate: 0.00058133]
	Learning Rate: 0.000581328
	LOSS [training: 0.14890941537149177 | validation: 0.1420691571487479]
	TIME [epoch: 9.5 sec]
EPOCH 1275/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13382869149416343		[learning rate: 0.00057992]
	Learning Rate: 0.00057992
	LOSS [training: 0.13382869149416343 | validation: 0.13501107580536276]
	TIME [epoch: 9.5 sec]
EPOCH 1276/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13843804792148678		[learning rate: 0.00057852]
	Learning Rate: 0.000578517
	LOSS [training: 0.13843804792148678 | validation: 0.1364296085249186]
	TIME [epoch: 9.51 sec]
EPOCH 1277/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1580649443410187		[learning rate: 0.00057712]
	Learning Rate: 0.000577116
	LOSS [training: 0.1580649443410187 | validation: 0.18325084438510952]
	TIME [epoch: 9.5 sec]
EPOCH 1278/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16718597086998893		[learning rate: 0.00057572]
	Learning Rate: 0.000575719
	LOSS [training: 0.16718597086998893 | validation: 0.1774084819418696]
	TIME [epoch: 9.5 sec]
EPOCH 1279/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13137653058991414		[learning rate: 0.00057433]
	Learning Rate: 0.000574325
	LOSS [training: 0.13137653058991414 | validation: 0.10301059695829967]
	TIME [epoch: 9.51 sec]
EPOCH 1280/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10123774614557508		[learning rate: 0.00057293]
	Learning Rate: 0.000572935
	LOSS [training: 0.10123774614557508 | validation: 0.11656356901164455]
	TIME [epoch: 9.5 sec]
EPOCH 1281/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11891865964945425		[learning rate: 0.00057155]
	Learning Rate: 0.000571548
	LOSS [training: 0.11891865964945425 | validation: 0.1416665634395656]
	TIME [epoch: 9.49 sec]
EPOCH 1282/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1462329883624029		[learning rate: 0.00057016]
	Learning Rate: 0.000570164
	LOSS [training: 0.1462329883624029 | validation: 0.12042735378892017]
	TIME [epoch: 9.51 sec]
EPOCH 1283/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11541081090617471		[learning rate: 0.00056878]
	Learning Rate: 0.000568784
	LOSS [training: 0.11541081090617471 | validation: 0.14377570357191796]
	TIME [epoch: 9.5 sec]
EPOCH 1284/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12431972490556568		[learning rate: 0.00056741]
	Learning Rate: 0.000567407
	LOSS [training: 0.12431972490556568 | validation: 0.1657492655178229]
	TIME [epoch: 9.49 sec]
EPOCH 1285/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1323014995611885		[learning rate: 0.00056603]
	Learning Rate: 0.000566033
	LOSS [training: 0.1323014995611885 | validation: 0.16788488484762543]
	TIME [epoch: 9.5 sec]
EPOCH 1286/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14514895022903532		[learning rate: 0.00056466]
	Learning Rate: 0.000564663
	LOSS [training: 0.14514895022903532 | validation: 0.10771876944375987]
	TIME [epoch: 9.52 sec]
EPOCH 1287/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10782366724094998		[learning rate: 0.0005633]
	Learning Rate: 0.000563296
	LOSS [training: 0.10782366724094998 | validation: 0.1112813189490031]
	TIME [epoch: 9.5 sec]
EPOCH 1288/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13051442302100455		[learning rate: 0.00056193]
	Learning Rate: 0.000561933
	LOSS [training: 0.13051442302100455 | validation: 0.10764069311040146]
	TIME [epoch: 9.5 sec]
EPOCH 1289/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14186595953752734		[learning rate: 0.00056057]
	Learning Rate: 0.000560572
	LOSS [training: 0.14186595953752734 | validation: 0.15717337091321942]
	TIME [epoch: 9.51 sec]
EPOCH 1290/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1458479098568765		[learning rate: 0.00055922]
	Learning Rate: 0.000559215
	LOSS [training: 0.1458479098568765 | validation: 0.16236425892627432]
	TIME [epoch: 9.5 sec]
EPOCH 1291/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17180855079283947		[learning rate: 0.00055786]
	Learning Rate: 0.000557861
	LOSS [training: 0.17180855079283947 | validation: 0.16751860979537958]
	TIME [epoch: 9.49 sec]
EPOCH 1292/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15711137250610369		[learning rate: 0.00055651]
	Learning Rate: 0.000556511
	LOSS [training: 0.15711137250610369 | validation: 0.14281958700049646]
	TIME [epoch: 9.49 sec]
EPOCH 1293/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1466420655731116		[learning rate: 0.00055516]
	Learning Rate: 0.000555164
	LOSS [training: 0.1466420655731116 | validation: 0.1429798631377788]
	TIME [epoch: 9.51 sec]
EPOCH 1294/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12245103564834506		[learning rate: 0.00055382]
	Learning Rate: 0.00055382
	LOSS [training: 0.12245103564834506 | validation: 0.0937298685690816]
	TIME [epoch: 9.5 sec]
EPOCH 1295/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11110151892772702		[learning rate: 0.00055248]
	Learning Rate: 0.000552479
	LOSS [training: 0.11110151892772702 | validation: 0.1093831536566518]
	TIME [epoch: 9.49 sec]
EPOCH 1296/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11316229020708628		[learning rate: 0.00055114]
	Learning Rate: 0.000551142
	LOSS [training: 0.11316229020708628 | validation: 0.12054274647936948]
	TIME [epoch: 9.51 sec]
EPOCH 1297/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10864790282491457		[learning rate: 0.00054981]
	Learning Rate: 0.000549807
	LOSS [training: 0.10864790282491457 | validation: 0.09628456736073977]
	TIME [epoch: 9.5 sec]
EPOCH 1298/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11247177218098019		[learning rate: 0.00054848]
	Learning Rate: 0.000548476
	LOSS [training: 0.11247177218098019 | validation: 0.11074910623929246]
	TIME [epoch: 9.49 sec]
EPOCH 1299/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12648036149757708		[learning rate: 0.00054715]
	Learning Rate: 0.000547149
	LOSS [training: 0.12648036149757708 | validation: 0.12504459275032442]
	TIME [epoch: 9.49 sec]
EPOCH 1300/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18200671672527782		[learning rate: 0.00054582]
	Learning Rate: 0.000545824
	LOSS [training: 0.18200671672527782 | validation: 0.21129710852163577]
	TIME [epoch: 9.51 sec]
EPOCH 1301/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23744128463494377		[learning rate: 0.0005445]
	Learning Rate: 0.000544503
	LOSS [training: 0.23744128463494377 | validation: 0.20508155604708353]
	TIME [epoch: 9.49 sec]
EPOCH 1302/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.23693457283953187		[learning rate: 0.00054318]
	Learning Rate: 0.000543185
	LOSS [training: 0.23693457283953187 | validation: 0.19600718882773835]
	TIME [epoch: 9.5 sec]
EPOCH 1303/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2435123818165196		[learning rate: 0.00054187]
	Learning Rate: 0.000541869
	LOSS [training: 0.2435123818165196 | validation: 0.20279670389056573]
	TIME [epoch: 9.51 sec]
EPOCH 1304/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20118033260692586		[learning rate: 0.00054056]
	Learning Rate: 0.000540558
	LOSS [training: 0.20118033260692586 | validation: 0.13618288148449648]
	TIME [epoch: 9.51 sec]
EPOCH 1305/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11097805193862202		[learning rate: 0.00053925]
	Learning Rate: 0.000539249
	LOSS [training: 0.11097805193862202 | validation: 0.07235911112652951]
	TIME [epoch: 9.5 sec]
EPOCH 1306/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08339797177951648		[learning rate: 0.00053794]
	Learning Rate: 0.000537944
	LOSS [training: 0.08339797177951648 | validation: 0.09248264895565995]
	TIME [epoch: 9.5 sec]
EPOCH 1307/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08053683323767039		[learning rate: 0.00053664]
	Learning Rate: 0.000536641
	LOSS [training: 0.08053683323767039 | validation: 0.09981297634883443]
	TIME [epoch: 9.51 sec]
EPOCH 1308/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11612373127236422		[learning rate: 0.00053534]
	Learning Rate: 0.000535342
	LOSS [training: 0.11612373127236422 | validation: 0.10634930674957324]
	TIME [epoch: 9.5 sec]
EPOCH 1309/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10915574798002332		[learning rate: 0.00053405]
	Learning Rate: 0.000534046
	LOSS [training: 0.10915574798002332 | validation: 0.08296817766308925]
	TIME [epoch: 9.49 sec]
EPOCH 1310/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08658726966142648		[learning rate: 0.00053275]
	Learning Rate: 0.000532754
	LOSS [training: 0.08658726966142648 | validation: 0.07567616847038684]
	TIME [epoch: 9.51 sec]
EPOCH 1311/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0771471013250021		[learning rate: 0.00053146]
	Learning Rate: 0.000531464
	LOSS [training: 0.0771471013250021 | validation: 0.10134659805747362]
	TIME [epoch: 9.5 sec]
EPOCH 1312/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10095081263076996		[learning rate: 0.00053018]
	Learning Rate: 0.000530177
	LOSS [training: 0.10095081263076996 | validation: 0.11040602347404858]
	TIME [epoch: 9.5 sec]
EPOCH 1313/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12071197453572806		[learning rate: 0.00052889]
	Learning Rate: 0.000528894
	LOSS [training: 0.12071197453572806 | validation: 0.16932655416382975]
	TIME [epoch: 9.49 sec]
EPOCH 1314/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15568524976524298		[learning rate: 0.00052761]
	Learning Rate: 0.000527613
	LOSS [training: 0.15568524976524298 | validation: 0.18611432575026599]
	TIME [epoch: 9.51 sec]
EPOCH 1315/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18153748560945843		[learning rate: 0.00052634]
	Learning Rate: 0.000526336
	LOSS [training: 0.18153748560945843 | validation: 0.1252714596366176]
	TIME [epoch: 9.5 sec]
EPOCH 1316/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12003898443072045		[learning rate: 0.00052506]
	Learning Rate: 0.000525062
	LOSS [training: 0.12003898443072045 | validation: 0.12247504837340425]
	TIME [epoch: 9.5 sec]
EPOCH 1317/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10921433164735446		[learning rate: 0.00052379]
	Learning Rate: 0.000523791
	LOSS [training: 0.10921433164735446 | validation: 0.11514155902117612]
	TIME [epoch: 9.5 sec]
EPOCH 1318/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09830787680972934		[learning rate: 0.00052252]
	Learning Rate: 0.000522523
	LOSS [training: 0.09830787680972934 | validation: 0.10978508733676869]
	TIME [epoch: 9.51 sec]
EPOCH 1319/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12125727953187919		[learning rate: 0.00052126]
	Learning Rate: 0.000521258
	LOSS [training: 0.12125727953187919 | validation: 0.16182893869247345]
	TIME [epoch: 9.5 sec]
EPOCH 1320/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15071351552816933		[learning rate: 0.00052]
	Learning Rate: 0.000519996
	LOSS [training: 0.15071351552816933 | validation: 0.1688737120076669]
	TIME [epoch: 9.49 sec]
EPOCH 1321/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16652346642627897		[learning rate: 0.00051874]
	Learning Rate: 0.000518737
	LOSS [training: 0.16652346642627897 | validation: 0.1408680242394095]
	TIME [epoch: 9.52 sec]
EPOCH 1322/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11697433349385263		[learning rate: 0.00051748]
	Learning Rate: 0.000517481
	LOSS [training: 0.11697433349385263 | validation: 0.12847415153834346]
	TIME [epoch: 9.49 sec]
EPOCH 1323/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11795928598612097		[learning rate: 0.00051623]
	Learning Rate: 0.000516229
	LOSS [training: 0.11795928598612097 | validation: 0.12870912255723677]
	TIME [epoch: 9.49 sec]
EPOCH 1324/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12542443644149967		[learning rate: 0.00051498]
	Learning Rate: 0.000514979
	LOSS [training: 0.12542443644149967 | validation: 0.12747998919043785]
	TIME [epoch: 9.51 sec]
EPOCH 1325/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12018754097438433		[learning rate: 0.00051373]
	Learning Rate: 0.000513732
	LOSS [training: 0.12018754097438433 | validation: 0.12466374627193602]
	TIME [epoch: 9.5 sec]
EPOCH 1326/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11936696425701339		[learning rate: 0.00051249]
	Learning Rate: 0.000512489
	LOSS [training: 0.11936696425701339 | validation: 0.10725151206442876]
	TIME [epoch: 9.49 sec]
EPOCH 1327/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10971803377319363		[learning rate: 0.00051125]
	Learning Rate: 0.000511248
	LOSS [training: 0.10971803377319363 | validation: 0.10490702771866114]
	TIME [epoch: 9.5 sec]
EPOCH 1328/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0949063361419056		[learning rate: 0.00051001]
	Learning Rate: 0.00051001
	LOSS [training: 0.0949063361419056 | validation: 0.11001915463577149]
	TIME [epoch: 9.51 sec]
EPOCH 1329/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10251419016758459		[learning rate: 0.00050878]
	Learning Rate: 0.000508776
	LOSS [training: 0.10251419016758459 | validation: 0.07684682995364213]
	TIME [epoch: 9.49 sec]
EPOCH 1330/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08172629482747767		[learning rate: 0.00050754]
	Learning Rate: 0.000507544
	LOSS [training: 0.08172629482747767 | validation: 0.08527400647775522]
	TIME [epoch: 9.49 sec]
EPOCH 1331/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08734356151792418		[learning rate: 0.00050632]
	Learning Rate: 0.000506315
	LOSS [training: 0.08734356151792418 | validation: 0.08904728673178564]
	TIME [epoch: 9.51 sec]
EPOCH 1332/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07957545168367271		[learning rate: 0.00050509]
	Learning Rate: 0.00050509
	LOSS [training: 0.07957545168367271 | validation: 0.09580701505597126]
	TIME [epoch: 9.5 sec]
EPOCH 1333/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0777218304116897		[learning rate: 0.00050387]
	Learning Rate: 0.000503867
	LOSS [training: 0.0777218304116897 | validation: 0.06118223757009129]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1333.pth
	Model improved!!!
EPOCH 1334/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07883740537275871		[learning rate: 0.00050265]
	Learning Rate: 0.000502647
	LOSS [training: 0.07883740537275871 | validation: 0.10411622287252752]
	TIME [epoch: 9.5 sec]
EPOCH 1335/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09903830499601816		[learning rate: 0.00050143]
	Learning Rate: 0.00050143
	LOSS [training: 0.09903830499601816 | validation: 0.10081940389387949]
	TIME [epoch: 9.51 sec]
EPOCH 1336/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09727998881819361		[learning rate: 0.00050022]
	Learning Rate: 0.000500216
	LOSS [training: 0.09727998881819361 | validation: 0.1098718946355978]
	TIME [epoch: 9.49 sec]
EPOCH 1337/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0989815633810356		[learning rate: 0.00049901]
	Learning Rate: 0.000499005
	LOSS [training: 0.0989815633810356 | validation: 0.13695339062128647]
	TIME [epoch: 9.49 sec]
EPOCH 1338/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0930391256183677		[learning rate: 0.0004978]
	Learning Rate: 0.000497797
	LOSS [training: 0.0930391256183677 | validation: 0.08121351241501028]
	TIME [epoch: 9.5 sec]
EPOCH 1339/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08374340824567691		[learning rate: 0.00049659]
	Learning Rate: 0.000496592
	LOSS [training: 0.08374340824567691 | validation: 0.08320847584887897]
	TIME [epoch: 9.5 sec]
EPOCH 1340/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0910325287454743		[learning rate: 0.00049539]
	Learning Rate: 0.00049539
	LOSS [training: 0.0910325287454743 | validation: 0.09289928814146833]
	TIME [epoch: 9.5 sec]
EPOCH 1341/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0896928589003162		[learning rate: 0.00049419]
	Learning Rate: 0.000494191
	LOSS [training: 0.0896928589003162 | validation: 0.08470579940045114]
	TIME [epoch: 9.5 sec]
EPOCH 1342/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0833924082481025		[learning rate: 0.00049299]
	Learning Rate: 0.000492995
	LOSS [training: 0.0833924082481025 | validation: 0.07634336475369764]
	TIME [epoch: 9.52 sec]
EPOCH 1343/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07983721991730211		[learning rate: 0.0004918]
	Learning Rate: 0.000491801
	LOSS [training: 0.07983721991730211 | validation: 0.08526884366813384]
	TIME [epoch: 9.5 sec]
EPOCH 1344/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.077119537091802		[learning rate: 0.00049061]
	Learning Rate: 0.00049061
	LOSS [training: 0.077119537091802 | validation: 0.08723705283442267]
	TIME [epoch: 9.49 sec]
EPOCH 1345/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07755712798755188		[learning rate: 0.00048942]
	Learning Rate: 0.000489423
	LOSS [training: 0.07755712798755188 | validation: 0.06472630264391696]
	TIME [epoch: 9.51 sec]
EPOCH 1346/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07441095445685318		[learning rate: 0.00048824]
	Learning Rate: 0.000488238
	LOSS [training: 0.07441095445685318 | validation: 0.0865474043698218]
	TIME [epoch: 9.5 sec]
EPOCH 1347/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07831397893190223		[learning rate: 0.00048706]
	Learning Rate: 0.000487056
	LOSS [training: 0.07831397893190223 | validation: 0.07972241453999704]
	TIME [epoch: 9.49 sec]
EPOCH 1348/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07533271746843544		[learning rate: 0.00048588]
	Learning Rate: 0.000485877
	LOSS [training: 0.07533271746843544 | validation: 0.08744241705793143]
	TIME [epoch: 9.49 sec]
EPOCH 1349/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08197474495081897		[learning rate: 0.0004847]
	Learning Rate: 0.000484701
	LOSS [training: 0.08197474495081897 | validation: 0.08886642488534309]
	TIME [epoch: 9.52 sec]
EPOCH 1350/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09104362196004831		[learning rate: 0.00048353]
	Learning Rate: 0.000483527
	LOSS [training: 0.09104362196004831 | validation: 0.09442611067215582]
	TIME [epoch: 9.49 sec]
EPOCH 1351/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09441785328775407		[learning rate: 0.00048236]
	Learning Rate: 0.000482357
	LOSS [training: 0.09441785328775407 | validation: 0.08101761163933704]
	TIME [epoch: 9.5 sec]
EPOCH 1352/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08730183471960166		[learning rate: 0.00048119]
	Learning Rate: 0.000481189
	LOSS [training: 0.08730183471960166 | validation: 0.10370786860659678]
	TIME [epoch: 9.51 sec]
EPOCH 1353/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09926708489366468		[learning rate: 0.00048002]
	Learning Rate: 0.000480024
	LOSS [training: 0.09926708489366468 | validation: 0.09303170190898348]
	TIME [epoch: 9.5 sec]
EPOCH 1354/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09981244338215398		[learning rate: 0.00047886]
	Learning Rate: 0.000478862
	LOSS [training: 0.09981244338215398 | validation: 0.0757831965977265]
	TIME [epoch: 9.49 sec]
EPOCH 1355/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08583808566132639		[learning rate: 0.0004777]
	Learning Rate: 0.000477703
	LOSS [training: 0.08583808566132639 | validation: 0.0819677633349822]
	TIME [epoch: 9.5 sec]
EPOCH 1356/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08236352097751891		[learning rate: 0.00047655]
	Learning Rate: 0.000476546
	LOSS [training: 0.08236352097751891 | validation: 0.09075405807360902]
	TIME [epoch: 9.51 sec]
EPOCH 1357/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07592707920074769		[learning rate: 0.00047539]
	Learning Rate: 0.000475393
	LOSS [training: 0.07592707920074769 | validation: 0.06132377127592789]
	TIME [epoch: 9.5 sec]
EPOCH 1358/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07711415024547688		[learning rate: 0.00047424]
	Learning Rate: 0.000474242
	LOSS [training: 0.07711415024547688 | validation: 0.08236733767276437]
	TIME [epoch: 9.5 sec]
EPOCH 1359/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09311513976085724		[learning rate: 0.00047309]
	Learning Rate: 0.000473094
	LOSS [training: 0.09311513976085724 | validation: 0.08350747219057884]
	TIME [epoch: 9.51 sec]
EPOCH 1360/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09172192792352221		[learning rate: 0.00047195]
	Learning Rate: 0.000471949
	LOSS [training: 0.09172192792352221 | validation: 0.10127458301237457]
	TIME [epoch: 9.5 sec]
EPOCH 1361/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1239566874667761		[learning rate: 0.00047081]
	Learning Rate: 0.000470806
	LOSS [training: 0.1239566874667761 | validation: 0.10519909379525466]
	TIME [epoch: 9.5 sec]
EPOCH 1362/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10146416545360341		[learning rate: 0.00046967]
	Learning Rate: 0.000469666
	LOSS [training: 0.10146416545360341 | validation: 0.10019133670607701]
	TIME [epoch: 9.5 sec]
EPOCH 1363/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0917838182381204		[learning rate: 0.00046853]
	Learning Rate: 0.000468529
	LOSS [training: 0.0917838182381204 | validation: 0.10602059121847993]
	TIME [epoch: 9.51 sec]
EPOCH 1364/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11689694449023584		[learning rate: 0.0004674]
	Learning Rate: 0.000467395
	LOSS [training: 0.11689694449023584 | validation: 0.13110558323642535]
	TIME [epoch: 9.49 sec]
EPOCH 1365/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1129414556902784		[learning rate: 0.00046626]
	Learning Rate: 0.000466264
	LOSS [training: 0.1129414556902784 | validation: 0.1314684578988086]
	TIME [epoch: 9.49 sec]
EPOCH 1366/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12413581732114246		[learning rate: 0.00046513]
	Learning Rate: 0.000465135
	LOSS [training: 0.12413581732114246 | validation: 0.10159977254791486]
	TIME [epoch: 9.51 sec]
EPOCH 1367/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0935783162573599		[learning rate: 0.00046401]
	Learning Rate: 0.000464009
	LOSS [training: 0.0935783162573599 | validation: 0.07764792926604723]
	TIME [epoch: 9.49 sec]
EPOCH 1368/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08333303747659684		[learning rate: 0.00046289]
	Learning Rate: 0.000462886
	LOSS [training: 0.08333303747659684 | validation: 0.08187671654866374]
	TIME [epoch: 9.5 sec]
EPOCH 1369/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10248328989047253		[learning rate: 0.00046177]
	Learning Rate: 0.000461765
	LOSS [training: 0.10248328989047253 | validation: 0.13045859774594823]
	TIME [epoch: 9.51 sec]
EPOCH 1370/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12198916438040812		[learning rate: 0.00046065]
	Learning Rate: 0.000460647
	LOSS [training: 0.12198916438040812 | validation: 0.12401445300159296]
	TIME [epoch: 9.5 sec]
EPOCH 1371/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09344692941795316		[learning rate: 0.00045953]
	Learning Rate: 0.000459532
	LOSS [training: 0.09344692941795316 | validation: 0.07867125560891976]
	TIME [epoch: 9.49 sec]
EPOCH 1372/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07876337228943482		[learning rate: 0.00045842]
	Learning Rate: 0.00045842
	LOSS [training: 0.07876337228943482 | validation: 0.08519348371043861]
	TIME [epoch: 9.49 sec]
EPOCH 1373/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07390776617039584		[learning rate: 0.00045731]
	Learning Rate: 0.00045731
	LOSS [training: 0.07390776617039584 | validation: 0.07957032850235382]
	TIME [epoch: 9.52 sec]
EPOCH 1374/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07762661255532109		[learning rate: 0.0004562]
	Learning Rate: 0.000456203
	LOSS [training: 0.07762661255532109 | validation: 0.09747970419935639]
	TIME [epoch: 9.5 sec]
EPOCH 1375/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0761169760661338		[learning rate: 0.0004551]
	Learning Rate: 0.000455098
	LOSS [training: 0.0761169760661338 | validation: 0.08101011567271614]
	TIME [epoch: 9.49 sec]
EPOCH 1376/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07861860795282596		[learning rate: 0.000454]
	Learning Rate: 0.000453997
	LOSS [training: 0.07861860795282596 | validation: 0.0858941070297091]
	TIME [epoch: 9.51 sec]
EPOCH 1377/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08625615164533018		[learning rate: 0.0004529]
	Learning Rate: 0.000452898
	LOSS [training: 0.08625615164533018 | validation: 0.11689586964542552]
	TIME [epoch: 9.5 sec]
EPOCH 1378/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1264728126566525		[learning rate: 0.0004518]
	Learning Rate: 0.000451801
	LOSS [training: 0.1264728126566525 | validation: 0.1132589340903725]
	TIME [epoch: 9.5 sec]
EPOCH 1379/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11143082052760085		[learning rate: 0.00045071]
	Learning Rate: 0.000450708
	LOSS [training: 0.11143082052760085 | validation: 0.12157957938099127]
	TIME [epoch: 9.5 sec]
EPOCH 1380/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10519537999774567		[learning rate: 0.00044962]
	Learning Rate: 0.000449616
	LOSS [training: 0.10519537999774567 | validation: 0.12444243351673627]
	TIME [epoch: 9.51 sec]
EPOCH 1381/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13205301104486286		[learning rate: 0.00044853]
	Learning Rate: 0.000448528
	LOSS [training: 0.13205301104486286 | validation: 0.12006613387661846]
	TIME [epoch: 9.5 sec]
EPOCH 1382/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10753087019383663		[learning rate: 0.00044744]
	Learning Rate: 0.000447442
	LOSS [training: 0.10753087019383663 | validation: 0.12325544787367303]
	TIME [epoch: 9.49 sec]
EPOCH 1383/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12924693571498214		[learning rate: 0.00044636]
	Learning Rate: 0.000446359
	LOSS [training: 0.12924693571498214 | validation: 0.12064761831887733]
	TIME [epoch: 9.51 sec]
EPOCH 1384/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1056034754213007		[learning rate: 0.00044528]
	Learning Rate: 0.000445278
	LOSS [training: 0.1056034754213007 | validation: 0.11543064657904535]
	TIME [epoch: 9.51 sec]
EPOCH 1385/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11444322197844228		[learning rate: 0.0004442]
	Learning Rate: 0.0004442
	LOSS [training: 0.11444322197844228 | validation: 0.09201325899834568]
	TIME [epoch: 9.51 sec]
EPOCH 1386/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10034273814060794		[learning rate: 0.00044313]
	Learning Rate: 0.000443125
	LOSS [training: 0.10034273814060794 | validation: 0.05715162043778236]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1386.pth
	Model improved!!!
EPOCH 1387/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08578371719048088		[learning rate: 0.00044205]
	Learning Rate: 0.000442052
	LOSS [training: 0.08578371719048088 | validation: 0.07992433948987851]
	TIME [epoch: 9.52 sec]
EPOCH 1388/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09808422304835156		[learning rate: 0.00044098]
	Learning Rate: 0.000440982
	LOSS [training: 0.09808422304835156 | validation: 0.09270967923034594]
	TIME [epoch: 9.49 sec]
EPOCH 1389/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0997133215659251		[learning rate: 0.00043991]
	Learning Rate: 0.000439915
	LOSS [training: 0.0997133215659251 | validation: 0.11023061895541097]
	TIME [epoch: 9.49 sec]
EPOCH 1390/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11232342693267008		[learning rate: 0.00043885]
	Learning Rate: 0.00043885
	LOSS [training: 0.11232342693267008 | validation: 0.1124982375068586]
	TIME [epoch: 9.51 sec]
EPOCH 1391/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0996630120401243		[learning rate: 0.00043779]
	Learning Rate: 0.000437787
	LOSS [training: 0.0996630120401243 | validation: 0.10475596844408586]
	TIME [epoch: 9.5 sec]
EPOCH 1392/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10494980446539652		[learning rate: 0.00043673]
	Learning Rate: 0.000436727
	LOSS [training: 0.10494980446539652 | validation: 0.12680496328978774]
	TIME [epoch: 9.49 sec]
EPOCH 1393/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13529828971406227		[learning rate: 0.00043567]
	Learning Rate: 0.00043567
	LOSS [training: 0.13529828971406227 | validation: 0.14187301636017602]
	TIME [epoch: 9.49 sec]
EPOCH 1394/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1485899841161233		[learning rate: 0.00043462]
	Learning Rate: 0.000434616
	LOSS [training: 0.1485899841161233 | validation: 0.1329044000303573]
	TIME [epoch: 9.51 sec]
EPOCH 1395/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17351707649581774		[learning rate: 0.00043356]
	Learning Rate: 0.000433563
	LOSS [training: 0.17351707649581774 | validation: 0.14440769895053168]
	TIME [epoch: 9.5 sec]
EPOCH 1396/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15245514457943124		[learning rate: 0.00043251]
	Learning Rate: 0.000432514
	LOSS [training: 0.15245514457943124 | validation: 0.10577964803456165]
	TIME [epoch: 9.49 sec]
EPOCH 1397/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12321987938160417		[learning rate: 0.00043147]
	Learning Rate: 0.000431467
	LOSS [training: 0.12321987938160417 | validation: 0.08488989937973049]
	TIME [epoch: 9.51 sec]
EPOCH 1398/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09660969858165817		[learning rate: 0.00043042]
	Learning Rate: 0.000430422
	LOSS [training: 0.09660969858165817 | validation: 0.07926184707128121]
	TIME [epoch: 9.49 sec]
EPOCH 1399/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09301774256513201		[learning rate: 0.00042938]
	Learning Rate: 0.00042938
	LOSS [training: 0.09301774256513201 | validation: 0.07793818062446135]
	TIME [epoch: 9.5 sec]
EPOCH 1400/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08976343719304061		[learning rate: 0.00042834]
	Learning Rate: 0.000428341
	LOSS [training: 0.08976343719304061 | validation: 0.07300908954952368]
	TIME [epoch: 9.49 sec]
EPOCH 1401/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08887897277962958		[learning rate: 0.0004273]
	Learning Rate: 0.000427304
	LOSS [training: 0.08887897277962958 | validation: 0.074403087853084]
	TIME [epoch: 9.51 sec]
EPOCH 1402/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08225964445916593		[learning rate: 0.00042627]
	Learning Rate: 0.000426269
	LOSS [training: 0.08225964445916593 | validation: 0.10514862060103086]
	TIME [epoch: 9.49 sec]
EPOCH 1403/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10797059054920359		[learning rate: 0.00042524]
	Learning Rate: 0.000425238
	LOSS [training: 0.10797059054920359 | validation: 0.0938619494849734]
	TIME [epoch: 9.49 sec]
EPOCH 1404/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10085466274568791		[learning rate: 0.00042421]
	Learning Rate: 0.000424208
	LOSS [training: 0.10085466274568791 | validation: 0.09182588796105541]
	TIME [epoch: 9.51 sec]
EPOCH 1405/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08831441695660583		[learning rate: 0.00042318]
	Learning Rate: 0.000423181
	LOSS [training: 0.08831441695660583 | validation: 0.09487670030060498]
	TIME [epoch: 9.5 sec]
EPOCH 1406/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09235792018749278		[learning rate: 0.00042216]
	Learning Rate: 0.000422157
	LOSS [training: 0.09235792018749278 | validation: 0.08152571021528551]
	TIME [epoch: 9.49 sec]
EPOCH 1407/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09613895073120785		[learning rate: 0.00042113]
	Learning Rate: 0.000421135
	LOSS [training: 0.09613895073120785 | validation: 0.07241436385998762]
	TIME [epoch: 9.5 sec]
EPOCH 1408/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09571127591287568		[learning rate: 0.00042012]
	Learning Rate: 0.000420115
	LOSS [training: 0.09571127591287568 | validation: 0.09023460856044425]
	TIME [epoch: 9.51 sec]
EPOCH 1409/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08690227118089952		[learning rate: 0.0004191]
	Learning Rate: 0.000419098
	LOSS [training: 0.08690227118089952 | validation: 0.1179166564694051]
	TIME [epoch: 9.5 sec]
EPOCH 1410/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09715066140636217		[learning rate: 0.00041808]
	Learning Rate: 0.000418084
	LOSS [training: 0.09715066140636217 | validation: 0.07158803021560703]
	TIME [epoch: 9.49 sec]
EPOCH 1411/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0726774487433544		[learning rate: 0.00041707]
	Learning Rate: 0.000417072
	LOSS [training: 0.0726774487433544 | validation: 0.07058960200962626]
	TIME [epoch: 9.51 sec]
EPOCH 1412/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0693480817352313		[learning rate: 0.00041606]
	Learning Rate: 0.000416062
	LOSS [training: 0.0693480817352313 | validation: 0.08282447402478678]
	TIME [epoch: 9.5 sec]
EPOCH 1413/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08310766180637215		[learning rate: 0.00041505]
	Learning Rate: 0.000415055
	LOSS [training: 0.08310766180637215 | validation: 0.0928052693248877]
	TIME [epoch: 9.49 sec]
EPOCH 1414/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10574037892167291		[learning rate: 0.00041405]
	Learning Rate: 0.00041405
	LOSS [training: 0.10574037892167291 | validation: 0.11819917433342508]
	TIME [epoch: 9.49 sec]
EPOCH 1415/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12726051500120134		[learning rate: 0.00041305]
	Learning Rate: 0.000413048
	LOSS [training: 0.12726051500120134 | validation: 0.15615135804129598]
	TIME [epoch: 9.51 sec]
EPOCH 1416/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22155138653316947		[learning rate: 0.00041205]
	Learning Rate: 0.000412048
	LOSS [training: 0.22155138653316947 | validation: 0.20108449992939334]
	TIME [epoch: 9.49 sec]
EPOCH 1417/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1891645696891966		[learning rate: 0.00041105]
	Learning Rate: 0.00041105
	LOSS [training: 0.1891645696891966 | validation: 0.16776291022251016]
	TIME [epoch: 9.5 sec]
EPOCH 1418/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.17612565592065108		[learning rate: 0.00041005]
	Learning Rate: 0.000410055
	LOSS [training: 0.17612565592065108 | validation: 0.18876934380302618]
	TIME [epoch: 9.51 sec]
EPOCH 1419/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1789549731508023		[learning rate: 0.00040906]
	Learning Rate: 0.000409062
	LOSS [training: 0.1789549731508023 | validation: 0.17348989684841068]
	TIME [epoch: 9.49 sec]
EPOCH 1420/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22048369493807077		[learning rate: 0.00040807]
	Learning Rate: 0.000408072
	LOSS [training: 0.22048369493807077 | validation: 0.17438980076604074]
	TIME [epoch: 9.49 sec]
EPOCH 1421/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19570051601330607		[learning rate: 0.00040708]
	Learning Rate: 0.000407084
	LOSS [training: 0.19570051601330607 | validation: 0.1291721346487593]
	TIME [epoch: 9.49 sec]
EPOCH 1422/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14621515532814006		[learning rate: 0.0004061]
	Learning Rate: 0.000406099
	LOSS [training: 0.14621515532814006 | validation: 0.10430706811436086]
	TIME [epoch: 9.51 sec]
EPOCH 1423/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1369926331298073		[learning rate: 0.00040512]
	Learning Rate: 0.000405116
	LOSS [training: 0.1369926331298073 | validation: 0.10192924397439836]
	TIME [epoch: 9.49 sec]
EPOCH 1424/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13194677898149956		[learning rate: 0.00040413]
	Learning Rate: 0.000404135
	LOSS [training: 0.13194677898149956 | validation: 0.09905013515368292]
	TIME [epoch: 9.49 sec]
EPOCH 1425/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1277127162467897		[learning rate: 0.00040316]
	Learning Rate: 0.000403157
	LOSS [training: 0.1277127162467897 | validation: 0.1266092134448917]
	TIME [epoch: 9.51 sec]
EPOCH 1426/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1443313234461437		[learning rate: 0.00040218]
	Learning Rate: 0.00040218
	LOSS [training: 0.1443313234461437 | validation: 0.12081056951164659]
	TIME [epoch: 9.5 sec]
EPOCH 1427/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1297116857580507		[learning rate: 0.00040121]
	Learning Rate: 0.000401207
	LOSS [training: 0.1297116857580507 | validation: 0.08375154104485003]
	TIME [epoch: 9.49 sec]
EPOCH 1428/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10307620587342795		[learning rate: 0.00040024]
	Learning Rate: 0.000400236
	LOSS [training: 0.10307620587342795 | validation: 0.06007319661353797]
	TIME [epoch: 9.5 sec]
EPOCH 1429/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08563105226115744		[learning rate: 0.00039927]
	Learning Rate: 0.000399267
	LOSS [training: 0.08563105226115744 | validation: 0.064020856252288]
	TIME [epoch: 9.51 sec]
EPOCH 1430/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07592049142404422		[learning rate: 0.0003983]
	Learning Rate: 0.0003983
	LOSS [training: 0.07592049142404422 | validation: 0.05740768146410249]
	TIME [epoch: 9.49 sec]
EPOCH 1431/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07166159533765862		[learning rate: 0.00039734]
	Learning Rate: 0.000397336
	LOSS [training: 0.07166159533765862 | validation: 0.06607447548081213]
	TIME [epoch: 9.49 sec]
EPOCH 1432/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0790748966207432		[learning rate: 0.00039637]
	Learning Rate: 0.000396374
	LOSS [training: 0.0790748966207432 | validation: 0.06723581497470896]
	TIME [epoch: 9.51 sec]
EPOCH 1433/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0698147489972146		[learning rate: 0.00039541]
	Learning Rate: 0.000395415
	LOSS [training: 0.0698147489972146 | validation: 0.0594201060729746]
	TIME [epoch: 9.5 sec]
EPOCH 1434/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07290154591549668		[learning rate: 0.00039446]
	Learning Rate: 0.000394457
	LOSS [training: 0.07290154591549668 | validation: 0.087817872938344]
	TIME [epoch: 9.49 sec]
EPOCH 1435/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09972491824562979		[learning rate: 0.0003935]
	Learning Rate: 0.000393502
	LOSS [training: 0.09972491824562979 | validation: 0.1288281933809705]
	TIME [epoch: 9.49 sec]
EPOCH 1436/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11252688447371602		[learning rate: 0.00039255]
	Learning Rate: 0.00039255
	LOSS [training: 0.11252688447371602 | validation: 0.09871144858361061]
	TIME [epoch: 9.51 sec]
EPOCH 1437/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11144428503292644		[learning rate: 0.0003916]
	Learning Rate: 0.000391599
	LOSS [training: 0.11144428503292644 | validation: 0.09358061405012301]
	TIME [epoch: 9.49 sec]
EPOCH 1438/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1517164946048328		[learning rate: 0.00039065]
	Learning Rate: 0.000390651
	LOSS [training: 0.1517164946048328 | validation: 0.1420402306213822]
	TIME [epoch: 9.5 sec]
EPOCH 1439/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.20117837965934182		[learning rate: 0.00038971]
	Learning Rate: 0.000389706
	LOSS [training: 0.20117837965934182 | validation: 0.21803412818224885]
	TIME [epoch: 9.51 sec]
EPOCH 1440/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2681159697071866		[learning rate: 0.00038876]
	Learning Rate: 0.000388762
	LOSS [training: 0.2681159697071866 | validation: 0.1841853778149983]
	TIME [epoch: 9.5 sec]
EPOCH 1441/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2044672749014455		[learning rate: 0.00038782]
	Learning Rate: 0.000387821
	LOSS [training: 0.2044672749014455 | validation: 0.13408754450261157]
	TIME [epoch: 9.5 sec]
EPOCH 1442/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13946606649343274		[learning rate: 0.00038688]
	Learning Rate: 0.000386882
	LOSS [training: 0.13946606649343274 | validation: 0.1022368970090981]
	TIME [epoch: 9.5 sec]
EPOCH 1443/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11774018083690865		[learning rate: 0.00038595]
	Learning Rate: 0.000385946
	LOSS [training: 0.11774018083690865 | validation: 0.10475770492925185]
	TIME [epoch: 9.51 sec]
EPOCH 1444/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10654401647532694		[learning rate: 0.00038501]
	Learning Rate: 0.000385011
	LOSS [training: 0.10654401647532694 | validation: 0.08927746504672765]
	TIME [epoch: 9.49 sec]
EPOCH 1445/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10647817679509167		[learning rate: 0.00038408]
	Learning Rate: 0.000384079
	LOSS [training: 0.10647817679509167 | validation: 0.10879518006715355]
	TIME [epoch: 9.49 sec]
EPOCH 1446/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11866091356788486		[learning rate: 0.00038315]
	Learning Rate: 0.00038315
	LOSS [training: 0.11866091356788486 | validation: 0.10399433094987233]
	TIME [epoch: 9.51 sec]
EPOCH 1447/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1365345518529563		[learning rate: 0.00038222]
	Learning Rate: 0.000382222
	LOSS [training: 0.1365345518529563 | validation: 0.14573893369130275]
	TIME [epoch: 9.5 sec]
EPOCH 1448/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16879520781157686		[learning rate: 0.0003813]
	Learning Rate: 0.000381297
	LOSS [training: 0.16879520781157686 | validation: 0.13023406894534298]
	TIME [epoch: 9.5 sec]
EPOCH 1449/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16990364644123251		[learning rate: 0.00038037]
	Learning Rate: 0.000380374
	LOSS [training: 0.16990364644123251 | validation: 0.13024827421141666]
	TIME [epoch: 9.5 sec]
EPOCH 1450/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.157485079764153		[learning rate: 0.00037945]
	Learning Rate: 0.000379453
	LOSS [training: 0.157485079764153 | validation: 0.10654153991806481]
	TIME [epoch: 9.51 sec]
EPOCH 1451/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10627454334570427		[learning rate: 0.00037853]
	Learning Rate: 0.000378534
	LOSS [training: 0.10627454334570427 | validation: 0.08180605455987411]
	TIME [epoch: 9.49 sec]
EPOCH 1452/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07885242500523428		[learning rate: 0.00037762]
	Learning Rate: 0.000377618
	LOSS [training: 0.07885242500523428 | validation: 0.057133039067912644]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1452.pth
	Model improved!!!
EPOCH 1453/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07646521180322619		[learning rate: 0.0003767]
	Learning Rate: 0.000376704
	LOSS [training: 0.07646521180322619 | validation: 0.08199055464715915]
	TIME [epoch: 9.52 sec]
EPOCH 1454/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07681250572045187		[learning rate: 0.00037579]
	Learning Rate: 0.000375792
	LOSS [training: 0.07681250572045187 | validation: 0.06653666253694791]
	TIME [epoch: 9.5 sec]
EPOCH 1455/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07152120560187963		[learning rate: 0.00037488]
	Learning Rate: 0.000374882
	LOSS [training: 0.07152120560187963 | validation: 0.08354405463370132]
	TIME [epoch: 9.5 sec]
EPOCH 1456/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07090997712583283		[learning rate: 0.00037397]
	Learning Rate: 0.000373975
	LOSS [training: 0.07090997712583283 | validation: 0.0765075855450825]
	TIME [epoch: 9.5 sec]
EPOCH 1457/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07298970206478694		[learning rate: 0.00037307]
	Learning Rate: 0.000373069
	LOSS [training: 0.07298970206478694 | validation: 0.07183744687380543]
	TIME [epoch: 9.51 sec]
EPOCH 1458/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06884109675433728		[learning rate: 0.00037217]
	Learning Rate: 0.000372166
	LOSS [training: 0.06884109675433728 | validation: 0.06826950246993226]
	TIME [epoch: 9.5 sec]
EPOCH 1459/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06857754590660507		[learning rate: 0.00037127]
	Learning Rate: 0.000371265
	LOSS [training: 0.06857754590660507 | validation: 0.08185185576227647]
	TIME [epoch: 9.5 sec]
EPOCH 1460/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06935761673582425		[learning rate: 0.00037037]
	Learning Rate: 0.000370366
	LOSS [training: 0.06935761673582425 | validation: 0.051558142646474465]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1460.pth
	Model improved!!!
EPOCH 1461/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06955603204517051		[learning rate: 0.00036947]
	Learning Rate: 0.00036947
	LOSS [training: 0.06955603204517051 | validation: 0.062423420856797675]
	TIME [epoch: 9.5 sec]
EPOCH 1462/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06663261118618383		[learning rate: 0.00036858]
	Learning Rate: 0.000368575
	LOSS [training: 0.06663261118618383 | validation: 0.04697368317740242]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1462.pth
	Model improved!!!
EPOCH 1463/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.067272159931871		[learning rate: 0.00036768]
	Learning Rate: 0.000367683
	LOSS [training: 0.067272159931871 | validation: 0.05648513111975846]
	TIME [epoch: 9.51 sec]
EPOCH 1464/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0652266300695115		[learning rate: 0.00036679]
	Learning Rate: 0.000366793
	LOSS [training: 0.0652266300695115 | validation: 0.07185131153846229]
	TIME [epoch: 9.5 sec]
EPOCH 1465/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07141264382237975		[learning rate: 0.00036591]
	Learning Rate: 0.000365905
	LOSS [training: 0.07141264382237975 | validation: 0.07169114221183462]
	TIME [epoch: 9.5 sec]
EPOCH 1466/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06409676848625932		[learning rate: 0.00036502]
	Learning Rate: 0.000365019
	LOSS [training: 0.06409676848625932 | validation: 0.05720549385778695]
	TIME [epoch: 9.73 sec]
EPOCH 1467/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06743440318630606		[learning rate: 0.00036414]
	Learning Rate: 0.000364136
	LOSS [training: 0.06743440318630606 | validation: 0.06522703829323578]
	TIME [epoch: 9.52 sec]
EPOCH 1468/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07805381905134394		[learning rate: 0.00036325]
	Learning Rate: 0.000363254
	LOSS [training: 0.07805381905134394 | validation: 0.07005056108703889]
	TIME [epoch: 9.5 sec]
EPOCH 1469/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06677632320961295		[learning rate: 0.00036237]
	Learning Rate: 0.000362375
	LOSS [training: 0.06677632320961295 | validation: 0.06565872329704803]
	TIME [epoch: 9.49 sec]
EPOCH 1470/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07351343917537916		[learning rate: 0.0003615]
	Learning Rate: 0.000361497
	LOSS [training: 0.07351343917537916 | validation: 0.0850816458979001]
	TIME [epoch: 9.52 sec]
EPOCH 1471/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10566999642651254		[learning rate: 0.00036062]
	Learning Rate: 0.000360622
	LOSS [training: 0.10566999642651254 | validation: 0.08949920010067691]
	TIME [epoch: 9.5 sec]
EPOCH 1472/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09584148536036548		[learning rate: 0.00035975]
	Learning Rate: 0.000359749
	LOSS [training: 0.09584148536036548 | validation: 0.07303260421417677]
	TIME [epoch: 9.5 sec]
EPOCH 1473/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09189048813874068		[learning rate: 0.00035888]
	Learning Rate: 0.000358878
	LOSS [training: 0.09189048813874068 | validation: 0.07702914085640786]
	TIME [epoch: 9.5 sec]
EPOCH 1474/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07303902703549195		[learning rate: 0.00035801]
	Learning Rate: 0.00035801
	LOSS [training: 0.07303902703549195 | validation: 0.05792940787431296]
	TIME [epoch: 9.52 sec]
EPOCH 1475/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07312939973802664		[learning rate: 0.00035714]
	Learning Rate: 0.000357143
	LOSS [training: 0.07312939973802664 | validation: 0.09019462988517532]
	TIME [epoch: 9.5 sec]
EPOCH 1476/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08102880921766284		[learning rate: 0.00035628]
	Learning Rate: 0.000356278
	LOSS [training: 0.08102880921766284 | validation: 0.07338278522058027]
	TIME [epoch: 9.5 sec]
EPOCH 1477/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07907644084717456		[learning rate: 0.00035542]
	Learning Rate: 0.000355416
	LOSS [training: 0.07907644084717456 | validation: 0.06681336482141526]
	TIME [epoch: 9.51 sec]
EPOCH 1478/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08500856301169266		[learning rate: 0.00035456]
	Learning Rate: 0.000354555
	LOSS [training: 0.08500856301169266 | validation: 0.06530706891921344]
	TIME [epoch: 9.5 sec]
EPOCH 1479/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0847199050313572		[learning rate: 0.0003537]
	Learning Rate: 0.000353697
	LOSS [training: 0.0847199050313572 | validation: 0.0795312273888366]
	TIME [epoch: 9.5 sec]
EPOCH 1480/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09405406193438987		[learning rate: 0.00035284]
	Learning Rate: 0.000352841
	LOSS [training: 0.09405406193438987 | validation: 0.07982985659399215]
	TIME [epoch: 9.5 sec]
EPOCH 1481/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0946606937787091		[learning rate: 0.00035199]
	Learning Rate: 0.000351987
	LOSS [training: 0.0946606937787091 | validation: 0.08578428455280339]
	TIME [epoch: 9.52 sec]
EPOCH 1482/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10440040988443407		[learning rate: 0.00035113]
	Learning Rate: 0.000351135
	LOSS [training: 0.10440040988443407 | validation: 0.08315571113109632]
	TIME [epoch: 9.5 sec]
EPOCH 1483/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10443686552079383		[learning rate: 0.00035028]
	Learning Rate: 0.000350285
	LOSS [training: 0.10443686552079383 | validation: 0.09454173364168987]
	TIME [epoch: 9.5 sec]
EPOCH 1484/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12943870058815973		[learning rate: 0.00034944]
	Learning Rate: 0.000349437
	LOSS [training: 0.12943870058815973 | validation: 0.18260405702254026]
	TIME [epoch: 9.52 sec]
EPOCH 1485/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.19567035228338495		[learning rate: 0.00034859]
	Learning Rate: 0.000348591
	LOSS [training: 0.19567035228338495 | validation: 0.1709732882515855]
	TIME [epoch: 9.5 sec]
EPOCH 1486/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18530015364840677		[learning rate: 0.00034775]
	Learning Rate: 0.000347747
	LOSS [training: 0.18530015364840677 | validation: 0.14688820319301485]
	TIME [epoch: 9.49 sec]
EPOCH 1487/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18775225016057936		[learning rate: 0.0003469]
	Learning Rate: 0.000346905
	LOSS [training: 0.18775225016057936 | validation: 0.13356209148370116]
	TIME [epoch: 9.5 sec]
EPOCH 1488/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1818986933728754		[learning rate: 0.00034607]
	Learning Rate: 0.000346065
	LOSS [training: 0.1818986933728754 | validation: 0.12249791576935382]
	TIME [epoch: 9.52 sec]
EPOCH 1489/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14923319780992164		[learning rate: 0.00034523]
	Learning Rate: 0.000345227
	LOSS [training: 0.14923319780992164 | validation: 0.11222248105708393]
	TIME [epoch: 9.49 sec]
EPOCH 1490/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1605408662653927		[learning rate: 0.00034439]
	Learning Rate: 0.000344392
	LOSS [training: 0.1605408662653927 | validation: 0.16675341559836818]
	TIME [epoch: 9.49 sec]
EPOCH 1491/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2383423673317205		[learning rate: 0.00034356]
	Learning Rate: 0.000343558
	LOSS [training: 0.2383423673317205 | validation: 0.17614852716175072]
	TIME [epoch: 9.51 sec]
EPOCH 1492/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22238516746673054		[learning rate: 0.00034273]
	Learning Rate: 0.000342726
	LOSS [training: 0.22238516746673054 | validation: 0.1767249480228677]
	TIME [epoch: 9.5 sec]
EPOCH 1493/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2584802702689083		[learning rate: 0.0003419]
	Learning Rate: 0.000341897
	LOSS [training: 0.2584802702689083 | validation: 0.1928968378733707]
	TIME [epoch: 9.49 sec]
EPOCH 1494/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.2366518145492243		[learning rate: 0.00034107]
	Learning Rate: 0.000341069
	LOSS [training: 0.2366518145492243 | validation: 0.15453985868049777]
	TIME [epoch: 9.5 sec]
EPOCH 1495/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.22007952931219116		[learning rate: 0.00034024]
	Learning Rate: 0.000340243
	LOSS [training: 0.22007952931219116 | validation: 0.20842302103497423]
	TIME [epoch: 9.51 sec]
EPOCH 1496/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.21961139318299408		[learning rate: 0.00033942]
	Learning Rate: 0.00033942
	LOSS [training: 0.21961139318299408 | validation: 0.12262822375803008]
	TIME [epoch: 9.49 sec]
EPOCH 1497/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14912345532859597		[learning rate: 0.0003386]
	Learning Rate: 0.000338598
	LOSS [training: 0.14912345532859597 | validation: 0.10895345381779695]
	TIME [epoch: 9.49 sec]
EPOCH 1498/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11870345359445567		[learning rate: 0.00033778]
	Learning Rate: 0.000337778
	LOSS [training: 0.11870345359445567 | validation: 0.10849012829075999]
	TIME [epoch: 9.52 sec]
EPOCH 1499/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12529761189290087		[learning rate: 0.00033696]
	Learning Rate: 0.00033696
	LOSS [training: 0.12529761189290087 | validation: 0.1041037102025504]
	TIME [epoch: 9.5 sec]
EPOCH 1500/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.14153300386101375		[learning rate: 0.00033614]
	Learning Rate: 0.000336145
	LOSS [training: 0.14153300386101375 | validation: 0.1449358022856013]
	TIME [epoch: 9.5 sec]
EPOCH 1501/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.18206554504440703		[learning rate: 0.00033533]
	Learning Rate: 0.000335331
	LOSS [training: 0.18206554504440703 | validation: 0.1260112775656639]
	TIME [epoch: 9.51 sec]
EPOCH 1502/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1435441039729703		[learning rate: 0.00033452]
	Learning Rate: 0.000334519
	LOSS [training: 0.1435441039729703 | validation: 0.11748978229785344]
	TIME [epoch: 9.5 sec]
EPOCH 1503/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.1505835105276483		[learning rate: 0.00033371]
	Learning Rate: 0.000333709
	LOSS [training: 0.1505835105276483 | validation: 0.12413486567282188]
	TIME [epoch: 9.5 sec]
EPOCH 1504/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.15057398171880398		[learning rate: 0.0003329]
	Learning Rate: 0.000332902
	LOSS [training: 0.15057398171880398 | validation: 0.11317534268223814]
	TIME [epoch: 9.49 sec]
EPOCH 1505/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11086328404506993		[learning rate: 0.0003321]
	Learning Rate: 0.000332096
	LOSS [training: 0.11086328404506993 | validation: 0.09794606400934022]
	TIME [epoch: 9.51 sec]
EPOCH 1506/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11078710635432938		[learning rate: 0.00033129]
	Learning Rate: 0.000331292
	LOSS [training: 0.11078710635432938 | validation: 0.09069159401658994]
	TIME [epoch: 9.5 sec]
EPOCH 1507/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10516520937635987		[learning rate: 0.00033049]
	Learning Rate: 0.00033049
	LOSS [training: 0.10516520937635987 | validation: 0.09325494811630261]
	TIME [epoch: 9.5 sec]
EPOCH 1508/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10502117261866761		[learning rate: 0.00032969]
	Learning Rate: 0.00032969
	LOSS [training: 0.10502117261866761 | validation: 0.07897687395689121]
	TIME [epoch: 9.5 sec]
EPOCH 1509/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0881817660225411		[learning rate: 0.00032889]
	Learning Rate: 0.000328891
	LOSS [training: 0.0881817660225411 | validation: 0.06958944025458527]
	TIME [epoch: 9.51 sec]
EPOCH 1510/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09902302610848644		[learning rate: 0.0003281]
	Learning Rate: 0.000328095
	LOSS [training: 0.09902302610848644 | validation: 0.12375723614289194]
	TIME [epoch: 9.5 sec]
EPOCH 1511/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11256481887434755		[learning rate: 0.0003273]
	Learning Rate: 0.000327301
	LOSS [training: 0.11256481887434755 | validation: 0.09580557409275926]
	TIME [epoch: 9.5 sec]
EPOCH 1512/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09072788724219905		[learning rate: 0.00032651]
	Learning Rate: 0.000326509
	LOSS [training: 0.09072788724219905 | validation: 0.07695891138716306]
	TIME [epoch: 9.51 sec]
EPOCH 1513/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09531115913767993		[learning rate: 0.00032572]
	Learning Rate: 0.000325718
	LOSS [training: 0.09531115913767993 | validation: 0.09057830216452946]
	TIME [epoch: 9.5 sec]
EPOCH 1514/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09130108807201705		[learning rate: 0.00032493]
	Learning Rate: 0.00032493
	LOSS [training: 0.09130108807201705 | validation: 0.09067288464665736]
	TIME [epoch: 9.5 sec]
EPOCH 1515/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08597543147143025		[learning rate: 0.00032414]
	Learning Rate: 0.000324143
	LOSS [training: 0.08597543147143025 | validation: 0.08676762932607211]
	TIME [epoch: 9.51 sec]
EPOCH 1516/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08222765261616558		[learning rate: 0.00032336]
	Learning Rate: 0.000323358
	LOSS [training: 0.08222765261616558 | validation: 0.07356700142837412]
	TIME [epoch: 9.51 sec]
EPOCH 1517/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09080602299124743		[learning rate: 0.00032258]
	Learning Rate: 0.000322576
	LOSS [training: 0.09080602299124743 | validation: 0.09338539592273279]
	TIME [epoch: 9.5 sec]
EPOCH 1518/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11052685136351928		[learning rate: 0.00032179]
	Learning Rate: 0.000321795
	LOSS [training: 0.11052685136351928 | validation: 0.09673730020144707]
	TIME [epoch: 9.5 sec]
EPOCH 1519/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10100519965004491		[learning rate: 0.00032102]
	Learning Rate: 0.000321016
	LOSS [training: 0.10100519965004491 | validation: 0.06927644138107733]
	TIME [epoch: 9.52 sec]
EPOCH 1520/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06333529610842767		[learning rate: 0.00032024]
	Learning Rate: 0.000320239
	LOSS [training: 0.06333529610842767 | validation: 0.06708076468660001]
	TIME [epoch: 9.5 sec]
EPOCH 1521/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06773460722073715		[learning rate: 0.00031946]
	Learning Rate: 0.000319463
	LOSS [training: 0.06773460722073715 | validation: 0.05826975638674366]
	TIME [epoch: 9.49 sec]
EPOCH 1522/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06421895811307719		[learning rate: 0.00031869]
	Learning Rate: 0.00031869
	LOSS [training: 0.06421895811307719 | validation: 0.07275911108609781]
	TIME [epoch: 9.51 sec]
EPOCH 1523/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06552750340386489		[learning rate: 0.00031792]
	Learning Rate: 0.000317918
	LOSS [training: 0.06552750340386489 | validation: 0.07311433744342742]
	TIME [epoch: 9.5 sec]
EPOCH 1524/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06659616994246795		[learning rate: 0.00031715]
	Learning Rate: 0.000317149
	LOSS [training: 0.06659616994246795 | validation: 0.05774237585768714]
	TIME [epoch: 9.5 sec]
EPOCH 1525/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06500755975353777		[learning rate: 0.00031638]
	Learning Rate: 0.000316381
	LOSS [training: 0.06500755975353777 | validation: 0.06647784318687104]
	TIME [epoch: 9.5 sec]
EPOCH 1526/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07430749696982139		[learning rate: 0.00031562]
	Learning Rate: 0.000315615
	LOSS [training: 0.07430749696982139 | validation: 0.06944689198169045]
	TIME [epoch: 9.52 sec]
EPOCH 1527/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07145767313486387		[learning rate: 0.00031485]
	Learning Rate: 0.000314851
	LOSS [training: 0.07145767313486387 | validation: 0.06481179812954192]
	TIME [epoch: 9.5 sec]
EPOCH 1528/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06373083892048013		[learning rate: 0.00031409]
	Learning Rate: 0.000314089
	LOSS [training: 0.06373083892048013 | validation: 0.06760109120312868]
	TIME [epoch: 9.5 sec]
EPOCH 1529/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061671542748250284		[learning rate: 0.00031333]
	Learning Rate: 0.000313329
	LOSS [training: 0.061671542748250284 | validation: 0.06771246717274801]
	TIME [epoch: 9.51 sec]
EPOCH 1530/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06128246456217211		[learning rate: 0.00031257]
	Learning Rate: 0.00031257
	LOSS [training: 0.06128246456217211 | validation: 0.06189566210692675]
	TIME [epoch: 9.51 sec]
EPOCH 1531/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06582119535406755		[learning rate: 0.00031181]
	Learning Rate: 0.000311813
	LOSS [training: 0.06582119535406755 | validation: 0.05623505307767207]
	TIME [epoch: 9.5 sec]
EPOCH 1532/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0637151302403183		[learning rate: 0.00031106]
	Learning Rate: 0.000311058
	LOSS [training: 0.0637151302403183 | validation: 0.07363348663086126]
	TIME [epoch: 9.5 sec]
EPOCH 1533/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07708327898993361		[learning rate: 0.00031031]
	Learning Rate: 0.000310305
	LOSS [training: 0.07708327898993361 | validation: 0.06205835382705892]
	TIME [epoch: 9.52 sec]
EPOCH 1534/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0665755453550803		[learning rate: 0.00030955]
	Learning Rate: 0.000309554
	LOSS [training: 0.0665755453550803 | validation: 0.05888101888681578]
	TIME [epoch: 9.5 sec]
EPOCH 1535/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06774069464782224		[learning rate: 0.0003088]
	Learning Rate: 0.000308805
	LOSS [training: 0.06774069464782224 | validation: 0.06397024615304592]
	TIME [epoch: 9.5 sec]
EPOCH 1536/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06468721291291307		[learning rate: 0.00030806]
	Learning Rate: 0.000308057
	LOSS [training: 0.06468721291291307 | validation: 0.05709765856025042]
	TIME [epoch: 9.52 sec]
EPOCH 1537/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06672472780792069		[learning rate: 0.00030731]
	Learning Rate: 0.000307312
	LOSS [training: 0.06672472780792069 | validation: 0.06882039463086286]
	TIME [epoch: 9.5 sec]
EPOCH 1538/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07579966806421977		[learning rate: 0.00030657]
	Learning Rate: 0.000306568
	LOSS [training: 0.07579966806421977 | validation: 0.06205850779828917]
	TIME [epoch: 9.5 sec]
EPOCH 1539/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.080477845374067		[learning rate: 0.00030583]
	Learning Rate: 0.000305826
	LOSS [training: 0.080477845374067 | validation: 0.06794907063132416]
	TIME [epoch: 9.5 sec]
EPOCH 1540/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08933537672789757		[learning rate: 0.00030509]
	Learning Rate: 0.000305085
	LOSS [training: 0.08933537672789757 | validation: 0.09693644590701127]
	TIME [epoch: 9.51 sec]
EPOCH 1541/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10052509754603989		[learning rate: 0.00030435]
	Learning Rate: 0.000304347
	LOSS [training: 0.10052509754603989 | validation: 0.09013722997013217]
	TIME [epoch: 9.51 sec]
EPOCH 1542/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0878288086048041		[learning rate: 0.00030361]
	Learning Rate: 0.00030361
	LOSS [training: 0.0878288086048041 | validation: 0.07897628695349646]
	TIME [epoch: 9.51 sec]
EPOCH 1543/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09431159003091641		[learning rate: 0.00030287]
	Learning Rate: 0.000302875
	LOSS [training: 0.09431159003091641 | validation: 0.11835601461128356]
	TIME [epoch: 9.52 sec]
EPOCH 1544/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09941950526498895		[learning rate: 0.00030214]
	Learning Rate: 0.000302142
	LOSS [training: 0.09941950526498895 | validation: 0.09601709042789779]
	TIME [epoch: 9.5 sec]
EPOCH 1545/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0934701634119973		[learning rate: 0.00030141]
	Learning Rate: 0.00030141
	LOSS [training: 0.0934701634119973 | validation: 0.09113969658122036]
	TIME [epoch: 9.5 sec]
EPOCH 1546/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10337622113800768		[learning rate: 0.00030068]
	Learning Rate: 0.000300681
	LOSS [training: 0.10337622113800768 | validation: 0.07117241553489219]
	TIME [epoch: 9.5 sec]
EPOCH 1547/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08561074107382016		[learning rate: 0.00029995]
	Learning Rate: 0.000299953
	LOSS [training: 0.08561074107382016 | validation: 0.07523812674240808]
	TIME [epoch: 9.52 sec]
EPOCH 1548/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07809960004775204		[learning rate: 0.00029923]
	Learning Rate: 0.000299226
	LOSS [training: 0.07809960004775204 | validation: 0.0898939760191547]
	TIME [epoch: 9.5 sec]
EPOCH 1549/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09247069431342253		[learning rate: 0.0002985]
	Learning Rate: 0.000298502
	LOSS [training: 0.09247069431342253 | validation: 0.07573710577042306]
	TIME [epoch: 9.5 sec]
EPOCH 1550/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09373873880139816		[learning rate: 0.00029778]
	Learning Rate: 0.000297779
	LOSS [training: 0.09373873880139816 | validation: 0.09073829507762379]
	TIME [epoch: 9.52 sec]
EPOCH 1551/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07317048990722196		[learning rate: 0.00029706]
	Learning Rate: 0.000297059
	LOSS [training: 0.07317048990722196 | validation: 0.0695161388825254]
	TIME [epoch: 9.51 sec]
EPOCH 1552/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07360574531576822		[learning rate: 0.00029634]
	Learning Rate: 0.000296339
	LOSS [training: 0.07360574531576822 | validation: 0.0694932857747288]
	TIME [epoch: 9.5 sec]
EPOCH 1553/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07216705968594755		[learning rate: 0.00029562]
	Learning Rate: 0.000295622
	LOSS [training: 0.07216705968594755 | validation: 0.07736801360484227]
	TIME [epoch: 9.5 sec]
EPOCH 1554/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07017904733621858		[learning rate: 0.00029491]
	Learning Rate: 0.000294906
	LOSS [training: 0.07017904733621858 | validation: 0.06644062024746926]
	TIME [epoch: 9.52 sec]
EPOCH 1555/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06166976892066782		[learning rate: 0.00029419]
	Learning Rate: 0.000294193
	LOSS [training: 0.06166976892066782 | validation: 0.07051156745006949]
	TIME [epoch: 9.5 sec]
EPOCH 1556/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059571593052987225		[learning rate: 0.00029348]
	Learning Rate: 0.00029348
	LOSS [training: 0.059571593052987225 | validation: 0.055640556294766455]
	TIME [epoch: 9.5 sec]
EPOCH 1557/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05608104798644089		[learning rate: 0.00029277]
	Learning Rate: 0.00029277
	LOSS [training: 0.05608104798644089 | validation: 0.05426872001784692]
	TIME [epoch: 9.52 sec]
EPOCH 1558/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0558640366004036		[learning rate: 0.00029206]
	Learning Rate: 0.000292061
	LOSS [training: 0.0558640366004036 | validation: 0.06136370391023245]
	TIME [epoch: 9.51 sec]
EPOCH 1559/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055498131751730725		[learning rate: 0.00029135]
	Learning Rate: 0.000291354
	LOSS [training: 0.055498131751730725 | validation: 0.05135110350769947]
	TIME [epoch: 9.5 sec]
EPOCH 1560/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06763102076296301		[learning rate: 0.00029065]
	Learning Rate: 0.000290649
	LOSS [training: 0.06763102076296301 | validation: 0.06887088035499128]
	TIME [epoch: 9.5 sec]
EPOCH 1561/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07634251568429153		[learning rate: 0.00028995]
	Learning Rate: 0.000289945
	LOSS [training: 0.07634251568429153 | validation: 0.08023182255809033]
	TIME [epoch: 9.52 sec]
EPOCH 1562/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07503891086233619		[learning rate: 0.00028924]
	Learning Rate: 0.000289243
	LOSS [training: 0.07503891086233619 | validation: 0.0806885947037154]
	TIME [epoch: 9.5 sec]
EPOCH 1563/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06893551365046778		[learning rate: 0.00028854]
	Learning Rate: 0.000288543
	LOSS [training: 0.06893551365046778 | validation: 0.05998862544313516]
	TIME [epoch: 9.51 sec]
EPOCH 1564/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0654381913150567		[learning rate: 0.00028784]
	Learning Rate: 0.000287844
	LOSS [training: 0.0654381913150567 | validation: 0.062341212332531766]
	TIME [epoch: 9.51 sec]
EPOCH 1565/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06944980309869404		[learning rate: 0.00028715]
	Learning Rate: 0.000287148
	LOSS [training: 0.06944980309869404 | validation: 0.05203729326220085]
	TIME [epoch: 9.5 sec]
EPOCH 1566/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056697451118713584		[learning rate: 0.00028645]
	Learning Rate: 0.000286453
	LOSS [training: 0.056697451118713584 | validation: 0.06633287545172013]
	TIME [epoch: 9.5 sec]
EPOCH 1567/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05677669054350236		[learning rate: 0.00028576]
	Learning Rate: 0.000285759
	LOSS [training: 0.05677669054350236 | validation: 0.04967858971600163]
	TIME [epoch: 9.51 sec]
EPOCH 1568/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06566209074294348		[learning rate: 0.00028507]
	Learning Rate: 0.000285067
	LOSS [training: 0.06566209074294348 | validation: 0.05705133306280335]
	TIME [epoch: 9.51 sec]
EPOCH 1569/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06574065867449781		[learning rate: 0.00028438]
	Learning Rate: 0.000284377
	LOSS [training: 0.06574065867449781 | validation: 0.07896832566770613]
	TIME [epoch: 9.5 sec]
EPOCH 1570/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07672160773961446		[learning rate: 0.00028369]
	Learning Rate: 0.000283689
	LOSS [training: 0.07672160773961446 | validation: 0.07375045284907396]
	TIME [epoch: 9.5 sec]
EPOCH 1571/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06741798530863656		[learning rate: 0.000283]
	Learning Rate: 0.000283002
	LOSS [training: 0.06741798530863656 | validation: 0.06822504138532491]
	TIME [epoch: 9.52 sec]
EPOCH 1572/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0684837348634236		[learning rate: 0.00028232]
	Learning Rate: 0.000282317
	LOSS [training: 0.0684837348634236 | validation: 0.06705450963648188]
	TIME [epoch: 9.5 sec]
EPOCH 1573/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06526650749206604		[learning rate: 0.00028163]
	Learning Rate: 0.000281633
	LOSS [training: 0.06526650749206604 | validation: 0.05944973145258624]
	TIME [epoch: 9.5 sec]
EPOCH 1574/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07092673167690469		[learning rate: 0.00028095]
	Learning Rate: 0.000280952
	LOSS [training: 0.07092673167690469 | validation: 0.06727277023909996]
	TIME [epoch: 9.5 sec]
EPOCH 1575/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07159185246037388		[learning rate: 0.00028027]
	Learning Rate: 0.000280272
	LOSS [training: 0.07159185246037388 | validation: 0.07890007793580188]
	TIME [epoch: 9.52 sec]
EPOCH 1576/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06509100442292497		[learning rate: 0.00027959]
	Learning Rate: 0.000279593
	LOSS [training: 0.06509100442292497 | validation: 0.06591921798720023]
	TIME [epoch: 9.51 sec]
EPOCH 1577/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.066570144594682		[learning rate: 0.00027892]
	Learning Rate: 0.000278916
	LOSS [training: 0.066570144594682 | validation: 0.065732100594699]
	TIME [epoch: 9.5 sec]
EPOCH 1578/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07148298308807859		[learning rate: 0.00027824]
	Learning Rate: 0.000278241
	LOSS [training: 0.07148298308807859 | validation: 0.057518562235547493]
	TIME [epoch: 9.52 sec]
EPOCH 1579/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06415929015499808		[learning rate: 0.00027757]
	Learning Rate: 0.000277567
	LOSS [training: 0.06415929015499808 | validation: 0.06600752700942925]
	TIME [epoch: 9.51 sec]
EPOCH 1580/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0683674884387244		[learning rate: 0.0002769]
	Learning Rate: 0.000276895
	LOSS [training: 0.0683674884387244 | validation: 0.06639790388173433]
	TIME [epoch: 9.51 sec]
EPOCH 1581/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07207325496174426		[learning rate: 0.00027623]
	Learning Rate: 0.000276225
	LOSS [training: 0.07207325496174426 | validation: 0.06859032933527115]
	TIME [epoch: 9.51 sec]
EPOCH 1582/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06737326968522048		[learning rate: 0.00027556]
	Learning Rate: 0.000275556
	LOSS [training: 0.06737326968522048 | validation: 0.09062330504257694]
	TIME [epoch: 9.51 sec]
EPOCH 1583/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0801743473958398		[learning rate: 0.00027489]
	Learning Rate: 0.000274889
	LOSS [training: 0.0801743473958398 | validation: 0.09255247201170519]
	TIME [epoch: 9.5 sec]
EPOCH 1584/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08199207280667384		[learning rate: 0.00027422]
	Learning Rate: 0.000274224
	LOSS [training: 0.08199207280667384 | validation: 0.08686855121317395]
	TIME [epoch: 9.5 sec]
EPOCH 1585/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09352045688130069		[learning rate: 0.00027356]
	Learning Rate: 0.00027356
	LOSS [training: 0.09352045688130069 | validation: 0.08772990957226412]
	TIME [epoch: 9.52 sec]
EPOCH 1586/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0825393629208637		[learning rate: 0.0002729]
	Learning Rate: 0.000272898
	LOSS [training: 0.0825393629208637 | validation: 0.07021965235533341]
	TIME [epoch: 9.5 sec]
EPOCH 1587/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06332227701878107		[learning rate: 0.00027224]
	Learning Rate: 0.000272237
	LOSS [training: 0.06332227701878107 | validation: 0.0746330823504329]
	TIME [epoch: 9.5 sec]
EPOCH 1588/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07490658139080619		[learning rate: 0.00027158]
	Learning Rate: 0.000271578
	LOSS [training: 0.07490658139080619 | validation: 0.06868176692008031]
	TIME [epoch: 9.51 sec]
EPOCH 1589/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06862055421260019		[learning rate: 0.00027092]
	Learning Rate: 0.000270921
	LOSS [training: 0.06862055421260019 | validation: 0.0907184499753222]
	TIME [epoch: 9.51 sec]
EPOCH 1590/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07675154926873667		[learning rate: 0.00027026]
	Learning Rate: 0.000270265
	LOSS [training: 0.07675154926873667 | validation: 0.07289039217046338]
	TIME [epoch: 9.5 sec]
EPOCH 1591/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06808961577126368		[learning rate: 0.00026961]
	Learning Rate: 0.000269611
	LOSS [training: 0.06808961577126368 | validation: 0.07466052083316384]
	TIME [epoch: 9.5 sec]
EPOCH 1592/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06503996692307629		[learning rate: 0.00026896]
	Learning Rate: 0.000268958
	LOSS [training: 0.06503996692307629 | validation: 0.06880831592583703]
	TIME [epoch: 9.52 sec]
EPOCH 1593/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059195828269174786		[learning rate: 0.00026831]
	Learning Rate: 0.000268307
	LOSS [training: 0.059195828269174786 | validation: 0.05826007066812323]
	TIME [epoch: 9.5 sec]
EPOCH 1594/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05894719349810461		[learning rate: 0.00026766]
	Learning Rate: 0.000267657
	LOSS [training: 0.05894719349810461 | validation: 0.05696612118902952]
	TIME [epoch: 9.5 sec]
EPOCH 1595/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06591623456973462		[learning rate: 0.00026701]
	Learning Rate: 0.000267009
	LOSS [training: 0.06591623456973462 | validation: 0.07565883736676493]
	TIME [epoch: 9.51 sec]
EPOCH 1596/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058250586551046		[learning rate: 0.00026636]
	Learning Rate: 0.000266363
	LOSS [training: 0.058250586551046 | validation: 0.05663010021113261]
	TIME [epoch: 9.5 sec]
EPOCH 1597/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059785886525937734		[learning rate: 0.00026572]
	Learning Rate: 0.000265718
	LOSS [training: 0.059785886525937734 | validation: 0.07324212046327905]
	TIME [epoch: 9.5 sec]
EPOCH 1598/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06568256764222612		[learning rate: 0.00026507]
	Learning Rate: 0.000265075
	LOSS [training: 0.06568256764222612 | validation: 0.05165232304140794]
	TIME [epoch: 9.5 sec]
EPOCH 1599/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06784746899458154		[learning rate: 0.00026443]
	Learning Rate: 0.000264433
	LOSS [training: 0.06784746899458154 | validation: 0.07050870070942084]
	TIME [epoch: 9.52 sec]
EPOCH 1600/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06061977797992263		[learning rate: 0.00026379]
	Learning Rate: 0.000263793
	LOSS [training: 0.06061977797992263 | validation: 0.06013449630604674]
	TIME [epoch: 9.5 sec]
EPOCH 1601/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05977710459688727		[learning rate: 0.00026315]
	Learning Rate: 0.000263154
	LOSS [training: 0.05977710459688727 | validation: 0.05166765250159873]
	TIME [epoch: 9.5 sec]
EPOCH 1602/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06672463156750358		[learning rate: 0.00026252]
	Learning Rate: 0.000262517
	LOSS [training: 0.06672463156750358 | validation: 0.06846359385860254]
	TIME [epoch: 9.51 sec]
EPOCH 1603/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057308098981286235		[learning rate: 0.00026188]
	Learning Rate: 0.000261882
	LOSS [training: 0.057308098981286235 | validation: 0.05222133682822525]
	TIME [epoch: 9.51 sec]
EPOCH 1604/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06287244165459756		[learning rate: 0.00026125]
	Learning Rate: 0.000261248
	LOSS [training: 0.06287244165459756 | validation: 0.051856758372722925]
	TIME [epoch: 9.5 sec]
EPOCH 1605/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06633987233102898		[learning rate: 0.00026062]
	Learning Rate: 0.000260615
	LOSS [training: 0.06633987233102898 | validation: 0.07888224562234325]
	TIME [epoch: 9.51 sec]
EPOCH 1606/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07047726666248093		[learning rate: 0.00025998]
	Learning Rate: 0.000259984
	LOSS [training: 0.07047726666248093 | validation: 0.07069763022260116]
	TIME [epoch: 9.52 sec]
EPOCH 1607/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061036729639866893		[learning rate: 0.00025936]
	Learning Rate: 0.000259355
	LOSS [training: 0.061036729639866893 | validation: 0.05579364146643766]
	TIME [epoch: 9.5 sec]
EPOCH 1608/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062627608890962		[learning rate: 0.00025873]
	Learning Rate: 0.000258727
	LOSS [training: 0.062627608890962 | validation: 0.06780633919349448]
	TIME [epoch: 9.5 sec]
EPOCH 1609/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05976655402685168		[learning rate: 0.0002581]
	Learning Rate: 0.000258101
	LOSS [training: 0.05976655402685168 | validation: 0.05665684224894038]
	TIME [epoch: 9.52 sec]
EPOCH 1610/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05898632160401297		[learning rate: 0.00025748]
	Learning Rate: 0.000257476
	LOSS [training: 0.05898632160401297 | validation: 0.05457322295257857]
	TIME [epoch: 9.5 sec]
EPOCH 1611/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0638165327719247		[learning rate: 0.00025685]
	Learning Rate: 0.000256853
	LOSS [training: 0.0638165327719247 | validation: 0.06136824341915223]
	TIME [epoch: 9.5 sec]
EPOCH 1612/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07779270715249866		[learning rate: 0.00025623]
	Learning Rate: 0.000256231
	LOSS [training: 0.07779270715249866 | validation: 0.08210515244749844]
	TIME [epoch: 9.5 sec]
EPOCH 1613/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0882026496535604		[learning rate: 0.00025561]
	Learning Rate: 0.000255611
	LOSS [training: 0.0882026496535604 | validation: 0.088778350461376]
	TIME [epoch: 9.52 sec]
EPOCH 1614/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0740700890454073		[learning rate: 0.00025499]
	Learning Rate: 0.000254992
	LOSS [training: 0.0740700890454073 | validation: 0.07391348104709339]
	TIME [epoch: 9.5 sec]
EPOCH 1615/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07792850817449173		[learning rate: 0.00025437]
	Learning Rate: 0.000254375
	LOSS [training: 0.07792850817449173 | validation: 0.06632928386243207]
	TIME [epoch: 9.5 sec]
EPOCH 1616/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06499118490533004		[learning rate: 0.00025376]
	Learning Rate: 0.000253759
	LOSS [training: 0.06499118490533004 | validation: 0.07358161055573671]
	TIME [epoch: 9.52 sec]
EPOCH 1617/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05588513503571516		[learning rate: 0.00025314]
	Learning Rate: 0.000253144
	LOSS [training: 0.05588513503571516 | validation: 0.061852447369359326]
	TIME [epoch: 9.5 sec]
EPOCH 1618/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06574413124545793		[learning rate: 0.00025253]
	Learning Rate: 0.000252532
	LOSS [training: 0.06574413124545793 | validation: 0.08281642249258901]
	TIME [epoch: 9.5 sec]
EPOCH 1619/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.064214888488621		[learning rate: 0.00025192]
	Learning Rate: 0.00025192
	LOSS [training: 0.064214888488621 | validation: 0.06563781801413196]
	TIME [epoch: 9.51 sec]
EPOCH 1620/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06226170084261282		[learning rate: 0.00025131]
	Learning Rate: 0.00025131
	LOSS [training: 0.06226170084261282 | validation: 0.0702341504645416]
	TIME [epoch: 9.52 sec]
EPOCH 1621/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06633363406667583		[learning rate: 0.0002507]
	Learning Rate: 0.000250702
	LOSS [training: 0.06633363406667583 | validation: 0.07646366733774652]
	TIME [epoch: 9.5 sec]
EPOCH 1622/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07033710577031126		[learning rate: 0.0002501]
	Learning Rate: 0.000250095
	LOSS [training: 0.07033710577031126 | validation: 0.059335103701593096]
	TIME [epoch: 9.5 sec]
EPOCH 1623/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05766803867800178		[learning rate: 0.00024949]
	Learning Rate: 0.00024949
	LOSS [training: 0.05766803867800178 | validation: 0.05151664494792749]
	TIME [epoch: 9.52 sec]
EPOCH 1624/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06542955113826954		[learning rate: 0.00024889]
	Learning Rate: 0.000248886
	LOSS [training: 0.06542955113826954 | validation: 0.07706330027980067]
	TIME [epoch: 9.51 sec]
EPOCH 1625/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06643436710916525		[learning rate: 0.00024828]
	Learning Rate: 0.000248283
	LOSS [training: 0.06643436710916525 | validation: 0.07391982782981439]
	TIME [epoch: 9.49 sec]
EPOCH 1626/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07863813809306713		[learning rate: 0.00024768]
	Learning Rate: 0.000247682
	LOSS [training: 0.07863813809306713 | validation: 0.06731177117195387]
	TIME [epoch: 9.5 sec]
EPOCH 1627/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06183449460755967		[learning rate: 0.00024708]
	Learning Rate: 0.000247083
	LOSS [training: 0.06183449460755967 | validation: 0.060551126610396015]
	TIME [epoch: 9.53 sec]
EPOCH 1628/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06302689590386332		[learning rate: 0.00024648]
	Learning Rate: 0.000246484
	LOSS [training: 0.06302689590386332 | validation: 0.055083852618053396]
	TIME [epoch: 9.5 sec]
EPOCH 1629/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07083589491852624		[learning rate: 0.00024589]
	Learning Rate: 0.000245888
	LOSS [training: 0.07083589491852624 | validation: 0.07958393526872289]
	TIME [epoch: 9.5 sec]
EPOCH 1630/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0803576649798609		[learning rate: 0.00024529]
	Learning Rate: 0.000245292
	LOSS [training: 0.0803576649798609 | validation: 0.06094197087582412]
	TIME [epoch: 9.52 sec]
EPOCH 1631/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07573020538309946		[learning rate: 0.0002447]
	Learning Rate: 0.000244699
	LOSS [training: 0.07573020538309946 | validation: 0.07213532639475202]
	TIME [epoch: 9.5 sec]
EPOCH 1632/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07738201439886674		[learning rate: 0.00024411]
	Learning Rate: 0.000244106
	LOSS [training: 0.07738201439886674 | validation: 0.07863036964893068]
	TIME [epoch: 9.5 sec]
EPOCH 1633/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0863191115157576		[learning rate: 0.00024352]
	Learning Rate: 0.000243515
	LOSS [training: 0.0863191115157576 | validation: 0.08803556000442887]
	TIME [epoch: 9.5 sec]
EPOCH 1634/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08049118033826348		[learning rate: 0.00024293]
	Learning Rate: 0.000242926
	LOSS [training: 0.08049118033826348 | validation: 0.06832081555371226]
	TIME [epoch: 9.51 sec]
EPOCH 1635/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0732450903581979		[learning rate: 0.00024234]
	Learning Rate: 0.000242338
	LOSS [training: 0.0732450903581979 | validation: 0.07108016243996718]
	TIME [epoch: 9.51 sec]
EPOCH 1636/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08199567954258222		[learning rate: 0.00024175]
	Learning Rate: 0.000241751
	LOSS [training: 0.08199567954258222 | validation: 0.07359858576687701]
	TIME [epoch: 9.5 sec]
EPOCH 1637/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07788452287814321		[learning rate: 0.00024117]
	Learning Rate: 0.000241166
	LOSS [training: 0.07788452287814321 | validation: 0.075147859672399]
	TIME [epoch: 9.52 sec]
EPOCH 1638/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08070374675078183		[learning rate: 0.00024058]
	Learning Rate: 0.000240582
	LOSS [training: 0.08070374675078183 | validation: 0.06041523448246652]
	TIME [epoch: 9.5 sec]
EPOCH 1639/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0710498461797073		[learning rate: 0.00024]
	Learning Rate: 0.00024
	LOSS [training: 0.0710498461797073 | validation: 0.07479913959605515]
	TIME [epoch: 9.5 sec]
EPOCH 1640/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07427673974323076		[learning rate: 0.00023942]
	Learning Rate: 0.000239419
	LOSS [training: 0.07427673974323076 | validation: 0.08498204503699378]
	TIME [epoch: 9.5 sec]
EPOCH 1641/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07164736100514311		[learning rate: 0.00023884]
	Learning Rate: 0.000238839
	LOSS [training: 0.07164736100514311 | validation: 0.05521998525822075]
	TIME [epoch: 9.52 sec]
EPOCH 1642/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07058573790360424		[learning rate: 0.00023826]
	Learning Rate: 0.000238261
	LOSS [training: 0.07058573790360424 | validation: 0.06471032148329123]
	TIME [epoch: 9.5 sec]
EPOCH 1643/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07497436411222566		[learning rate: 0.00023768]
	Learning Rate: 0.000237684
	LOSS [training: 0.07497436411222566 | validation: 0.05685917575514612]
	TIME [epoch: 9.5 sec]
EPOCH 1644/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09645139582047703		[learning rate: 0.00023711]
	Learning Rate: 0.000237109
	LOSS [training: 0.09645139582047703 | validation: 0.07700266607648704]
	TIME [epoch: 9.52 sec]
EPOCH 1645/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08445625662707953		[learning rate: 0.00023653]
	Learning Rate: 0.000236535
	LOSS [training: 0.08445625662707953 | validation: 0.07552120434591088]
	TIME [epoch: 9.51 sec]
EPOCH 1646/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07909027487628374		[learning rate: 0.00023596]
	Learning Rate: 0.000235962
	LOSS [training: 0.07909027487628374 | validation: 0.068025517152042]
	TIME [epoch: 9.5 sec]
EPOCH 1647/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08776681277096574		[learning rate: 0.00023539]
	Learning Rate: 0.000235391
	LOSS [training: 0.08776681277096574 | validation: 0.06031528426196735]
	TIME [epoch: 9.5 sec]
EPOCH 1648/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06388308962931744		[learning rate: 0.00023482]
	Learning Rate: 0.000234821
	LOSS [training: 0.06388308962931744 | validation: 0.07587079679660158]
	TIME [epoch: 9.52 sec]
EPOCH 1649/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07409067714139432		[learning rate: 0.00023425]
	Learning Rate: 0.000234252
	LOSS [training: 0.07409067714139432 | validation: 0.06521773293690689]
	TIME [epoch: 9.51 sec]
EPOCH 1650/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07576164317673566		[learning rate: 0.00023369]
	Learning Rate: 0.000233685
	LOSS [training: 0.07576164317673566 | validation: 0.05762612052177816]
	TIME [epoch: 9.51 sec]
EPOCH 1651/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0649417531289613		[learning rate: 0.00023312]
	Learning Rate: 0.00023312
	LOSS [training: 0.0649417531289613 | validation: 0.06529290225735483]
	TIME [epoch: 9.52 sec]
EPOCH 1652/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05926376010854527		[learning rate: 0.00023256]
	Learning Rate: 0.000232555
	LOSS [training: 0.05926376010854527 | validation: 0.061139107862557295]
	TIME [epoch: 9.51 sec]
EPOCH 1653/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05873744564512533		[learning rate: 0.00023199]
	Learning Rate: 0.000231992
	LOSS [training: 0.05873744564512533 | validation: 0.03912322141062473]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1653.pth
	Model improved!!!
EPOCH 1654/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05732682437800041		[learning rate: 0.00023143]
	Learning Rate: 0.000231431
	LOSS [training: 0.05732682437800041 | validation: 0.04648956057757842]
	TIME [epoch: 9.51 sec]
EPOCH 1655/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05598840403140735		[learning rate: 0.00023087]
	Learning Rate: 0.00023087
	LOSS [training: 0.05598840403140735 | validation: 0.059642753302384985]
	TIME [epoch: 9.51 sec]
EPOCH 1656/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06160375345656551		[learning rate: 0.00023031]
	Learning Rate: 0.000230312
	LOSS [training: 0.06160375345656551 | validation: 0.057410048619451697]
	TIME [epoch: 9.5 sec]
EPOCH 1657/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06103816243284234		[learning rate: 0.00022975]
	Learning Rate: 0.000229754
	LOSS [training: 0.06103816243284234 | validation: 0.06315290623593253]
	TIME [epoch: 9.5 sec]
EPOCH 1658/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054225995510551975		[learning rate: 0.0002292]
	Learning Rate: 0.000229198
	LOSS [training: 0.054225995510551975 | validation: 0.04565927313601356]
	TIME [epoch: 9.52 sec]
EPOCH 1659/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06834232571072868		[learning rate: 0.00022864]
	Learning Rate: 0.000228643
	LOSS [training: 0.06834232571072868 | validation: 0.07046044070011032]
	TIME [epoch: 9.5 sec]
EPOCH 1660/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06968440761100782		[learning rate: 0.00022809]
	Learning Rate: 0.000228089
	LOSS [training: 0.06968440761100782 | validation: 0.07711926839779708]
	TIME [epoch: 9.5 sec]
EPOCH 1661/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08079788473751333		[learning rate: 0.00022754]
	Learning Rate: 0.000227537
	LOSS [training: 0.08079788473751333 | validation: 0.06549660709447863]
	TIME [epoch: 9.51 sec]
EPOCH 1662/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06515752366766601		[learning rate: 0.00022699]
	Learning Rate: 0.000226987
	LOSS [training: 0.06515752366766601 | validation: 0.07392278573208319]
	TIME [epoch: 9.51 sec]
EPOCH 1663/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0740209711909121		[learning rate: 0.00022644]
	Learning Rate: 0.000226437
	LOSS [training: 0.0740209711909121 | validation: 0.06733892457452796]
	TIME [epoch: 9.5 sec]
EPOCH 1664/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06497402731335003		[learning rate: 0.00022589]
	Learning Rate: 0.000225889
	LOSS [training: 0.06497402731335003 | validation: 0.046168925265429255]
	TIME [epoch: 9.5 sec]
EPOCH 1665/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06865457330451713		[learning rate: 0.00022534]
	Learning Rate: 0.000225342
	LOSS [training: 0.06865457330451713 | validation: 0.059069946219455834]
	TIME [epoch: 9.52 sec]
EPOCH 1666/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07009402996002574		[learning rate: 0.0002248]
	Learning Rate: 0.000224796
	LOSS [training: 0.07009402996002574 | validation: 0.0631249266114883]
	TIME [epoch: 9.5 sec]
EPOCH 1667/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06631252073331126		[learning rate: 0.00022425]
	Learning Rate: 0.000224252
	LOSS [training: 0.06631252073331126 | validation: 0.06173270384219018]
	TIME [epoch: 9.5 sec]
EPOCH 1668/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07647181931899445		[learning rate: 0.00022371]
	Learning Rate: 0.000223709
	LOSS [training: 0.07647181931899445 | validation: 0.051848810831695034]
	TIME [epoch: 9.51 sec]
EPOCH 1669/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061737813642498564		[learning rate: 0.00022317]
	Learning Rate: 0.000223168
	LOSS [training: 0.061737813642498564 | validation: 0.06119941454801087]
	TIME [epoch: 9.5 sec]
EPOCH 1670/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0530834892129327		[learning rate: 0.00022263]
	Learning Rate: 0.000222628
	LOSS [training: 0.0530834892129327 | validation: 0.053660991639171575]
	TIME [epoch: 9.5 sec]
EPOCH 1671/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05735128383805689		[learning rate: 0.00022209]
	Learning Rate: 0.000222089
	LOSS [training: 0.05735128383805689 | validation: 0.05782044532621423]
	TIME [epoch: 9.49 sec]
EPOCH 1672/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057685463565741946		[learning rate: 0.00022155]
	Learning Rate: 0.000221551
	LOSS [training: 0.057685463565741946 | validation: 0.06925688557247595]
	TIME [epoch: 9.52 sec]
EPOCH 1673/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057523595628509186		[learning rate: 0.00022101]
	Learning Rate: 0.000221015
	LOSS [training: 0.057523595628509186 | validation: 0.058039283842857385]
	TIME [epoch: 9.5 sec]
EPOCH 1674/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05451686967604845		[learning rate: 0.00022048]
	Learning Rate: 0.00022048
	LOSS [training: 0.05451686967604845 | validation: 0.062329843451973]
	TIME [epoch: 9.51 sec]
EPOCH 1675/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05472203268700463		[learning rate: 0.00021995]
	Learning Rate: 0.000219946
	LOSS [training: 0.05472203268700463 | validation: 0.05348387030217449]
	TIME [epoch: 9.52 sec]
EPOCH 1676/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07052149469184772		[learning rate: 0.00021941]
	Learning Rate: 0.000219413
	LOSS [training: 0.07052149469184772 | validation: 0.07480352799231421]
	TIME [epoch: 9.51 sec]
EPOCH 1677/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0625177789295414		[learning rate: 0.00021888]
	Learning Rate: 0.000218882
	LOSS [training: 0.0625177789295414 | validation: 0.0681000294872354]
	TIME [epoch: 9.5 sec]
EPOCH 1678/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05906254270172038		[learning rate: 0.00021835]
	Learning Rate: 0.000218352
	LOSS [training: 0.05906254270172038 | validation: 0.06964036836427921]
	TIME [epoch: 9.5 sec]
EPOCH 1679/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06287821020056458		[learning rate: 0.00021782]
	Learning Rate: 0.000217824
	LOSS [training: 0.06287821020056458 | validation: 0.06823912640317674]
	TIME [epoch: 9.52 sec]
EPOCH 1680/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06743168861132855		[learning rate: 0.0002173]
	Learning Rate: 0.000217296
	LOSS [training: 0.06743168861132855 | validation: 0.0654818008562995]
	TIME [epoch: 9.5 sec]
EPOCH 1681/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07112914358208985		[learning rate: 0.00021677]
	Learning Rate: 0.00021677
	LOSS [training: 0.07112914358208985 | validation: 0.06461432647169472]
	TIME [epoch: 9.5 sec]
EPOCH 1682/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06582939869579782		[learning rate: 0.00021625]
	Learning Rate: 0.000216246
	LOSS [training: 0.06582939869579782 | validation: 0.06436767643241689]
	TIME [epoch: 9.52 sec]
EPOCH 1683/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08127431336345745		[learning rate: 0.00021572]
	Learning Rate: 0.000215722
	LOSS [training: 0.08127431336345745 | validation: 0.08179896105036383]
	TIME [epoch: 9.5 sec]
EPOCH 1684/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07079002187211689		[learning rate: 0.0002152]
	Learning Rate: 0.0002152
	LOSS [training: 0.07079002187211689 | validation: 0.07070207163328993]
	TIME [epoch: 9.5 sec]
EPOCH 1685/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0739023022565819		[learning rate: 0.00021468]
	Learning Rate: 0.000214679
	LOSS [training: 0.0739023022565819 | validation: 0.08454949552233681]
	TIME [epoch: 9.5 sec]
EPOCH 1686/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09521060772497703		[learning rate: 0.00021416]
	Learning Rate: 0.000214159
	LOSS [training: 0.09521060772497703 | validation: 0.09424166432995676]
	TIME [epoch: 9.52 sec]
EPOCH 1687/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10367991911360357		[learning rate: 0.00021364]
	Learning Rate: 0.000213641
	LOSS [training: 0.10367991911360357 | validation: 0.09756325031836006]
	TIME [epoch: 9.5 sec]
EPOCH 1688/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11243850624626832		[learning rate: 0.00021312]
	Learning Rate: 0.000213124
	LOSS [training: 0.11243850624626832 | validation: 0.0986095869260266]
	TIME [epoch: 9.5 sec]
EPOCH 1689/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.13612101405825677		[learning rate: 0.00021261]
	Learning Rate: 0.000212608
	LOSS [training: 0.13612101405825677 | validation: 0.12385922058096391]
	TIME [epoch: 9.52 sec]
EPOCH 1690/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.16101881072697452		[learning rate: 0.00021209]
	Learning Rate: 0.000212093
	LOSS [training: 0.16101881072697452 | validation: 0.12218834288423992]
	TIME [epoch: 9.5 sec]
EPOCH 1691/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.133791226801059		[learning rate: 0.00021158]
	Learning Rate: 0.00021158
	LOSS [training: 0.133791226801059 | validation: 0.11330312133771385]
	TIME [epoch: 9.5 sec]
EPOCH 1692/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.12671728111274896		[learning rate: 0.00021107]
	Learning Rate: 0.000211067
	LOSS [training: 0.12671728111274896 | validation: 0.08374508610834122]
	TIME [epoch: 9.5 sec]
EPOCH 1693/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0865038762728112		[learning rate: 0.00021056]
	Learning Rate: 0.000210556
	LOSS [training: 0.0865038762728112 | validation: 0.06669113985052447]
	TIME [epoch: 9.52 sec]
EPOCH 1694/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08632131300811544		[learning rate: 0.00021005]
	Learning Rate: 0.000210047
	LOSS [training: 0.08632131300811544 | validation: 0.09299482948786113]
	TIME [epoch: 9.5 sec]
EPOCH 1695/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08553344828425534		[learning rate: 0.00020954]
	Learning Rate: 0.000209538
	LOSS [training: 0.08553344828425534 | validation: 0.09139577246977502]
	TIME [epoch: 9.5 sec]
EPOCH 1696/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09451251269686692		[learning rate: 0.00020903]
	Learning Rate: 0.000209031
	LOSS [training: 0.09451251269686692 | validation: 0.08542825583739719]
	TIME [epoch: 9.52 sec]
EPOCH 1697/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08909681003349436		[learning rate: 0.00020852]
	Learning Rate: 0.000208525
	LOSS [training: 0.08909681003349436 | validation: 0.07963479288504342]
	TIME [epoch: 9.5 sec]
EPOCH 1698/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08698559642161215		[learning rate: 0.00020802]
	Learning Rate: 0.00020802
	LOSS [training: 0.08698559642161215 | validation: 0.07379492279463155]
	TIME [epoch: 9.5 sec]
EPOCH 1699/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09215985004883802		[learning rate: 0.00020752]
	Learning Rate: 0.000207516
	LOSS [training: 0.09215985004883802 | validation: 0.08652195976266891]
	TIME [epoch: 9.5 sec]
EPOCH 1700/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10308767258334509		[learning rate: 0.00020701]
	Learning Rate: 0.000207014
	LOSS [training: 0.10308767258334509 | validation: 0.0943843250903064]
	TIME [epoch: 9.51 sec]
EPOCH 1701/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10362050102023859		[learning rate: 0.00020651]
	Learning Rate: 0.000206513
	LOSS [training: 0.10362050102023859 | validation: 0.08708821464077675]
	TIME [epoch: 9.5 sec]
EPOCH 1702/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09366937654386183		[learning rate: 0.00020601]
	Learning Rate: 0.000206013
	LOSS [training: 0.09366937654386183 | validation: 0.07512958256155279]
	TIME [epoch: 9.5 sec]
EPOCH 1703/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08838819519441286		[learning rate: 0.00020551]
	Learning Rate: 0.000205514
	LOSS [training: 0.08838819519441286 | validation: 0.05841738523688882]
	TIME [epoch: 9.52 sec]
EPOCH 1704/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08166718118480912		[learning rate: 0.00020502]
	Learning Rate: 0.000205017
	LOSS [training: 0.08166718118480912 | validation: 0.06665505369717961]
	TIME [epoch: 9.51 sec]
EPOCH 1705/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07803515609067785		[learning rate: 0.00020452]
	Learning Rate: 0.000204521
	LOSS [training: 0.07803515609067785 | validation: 0.06646773012026644]
	TIME [epoch: 9.5 sec]
EPOCH 1706/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0747870445775376		[learning rate: 0.00020403]
	Learning Rate: 0.000204025
	LOSS [training: 0.0747870445775376 | validation: 0.07491915235816284]
	TIME [epoch: 9.5 sec]
EPOCH 1707/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0791083617361359		[learning rate: 0.00020353]
	Learning Rate: 0.000203531
	LOSS [training: 0.0791083617361359 | validation: 0.07266524240498137]
	TIME [epoch: 9.52 sec]
EPOCH 1708/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07804398415841599		[learning rate: 0.00020304]
	Learning Rate: 0.000203039
	LOSS [training: 0.07804398415841599 | validation: 0.07350483476864883]
	TIME [epoch: 9.5 sec]
EPOCH 1709/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0727471175190301		[learning rate: 0.00020255]
	Learning Rate: 0.000202547
	LOSS [training: 0.0727471175190301 | validation: 0.08184692033957779]
	TIME [epoch: 9.5 sec]
EPOCH 1710/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07534356056892319		[learning rate: 0.00020206]
	Learning Rate: 0.000202057
	LOSS [training: 0.07534356056892319 | validation: 0.07555947194944931]
	TIME [epoch: 9.52 sec]
EPOCH 1711/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0627834166898914		[learning rate: 0.00020157]
	Learning Rate: 0.000201568
	LOSS [training: 0.0627834166898914 | validation: 0.06059518623949851]
	TIME [epoch: 9.51 sec]
EPOCH 1712/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06499372735116009		[learning rate: 0.00020108]
	Learning Rate: 0.00020108
	LOSS [training: 0.06499372735116009 | validation: 0.0795307691677603]
	TIME [epoch: 9.5 sec]
EPOCH 1713/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07906735278746777		[learning rate: 0.00020059]
	Learning Rate: 0.000200593
	LOSS [training: 0.07906735278746777 | validation: 0.059063105880078785]
	TIME [epoch: 9.5 sec]
EPOCH 1714/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06348433752169333		[learning rate: 0.00020011]
	Learning Rate: 0.000200107
	LOSS [training: 0.06348433752169333 | validation: 0.05671141901523041]
	TIME [epoch: 9.52 sec]
EPOCH 1715/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05687903675454574		[learning rate: 0.00019962]
	Learning Rate: 0.000199623
	LOSS [training: 0.05687903675454574 | validation: 0.06704205269896178]
	TIME [epoch: 9.5 sec]
EPOCH 1716/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05805840906183011		[learning rate: 0.00019914]
	Learning Rate: 0.00019914
	LOSS [training: 0.05805840906183011 | validation: 0.05275800702295337]
	TIME [epoch: 9.51 sec]
EPOCH 1717/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05529035712819537		[learning rate: 0.00019866]
	Learning Rate: 0.000198658
	LOSS [training: 0.05529035712819537 | validation: 0.05333668090166131]
	TIME [epoch: 9.52 sec]
EPOCH 1718/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05338233449567949		[learning rate: 0.00019818]
	Learning Rate: 0.000198177
	LOSS [training: 0.05338233449567949 | validation: 0.05708268742658796]
	TIME [epoch: 9.5 sec]
EPOCH 1719/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054629112398429644		[learning rate: 0.0001977]
	Learning Rate: 0.000197697
	LOSS [training: 0.054629112398429644 | validation: 0.04696377501656999]
	TIME [epoch: 9.5 sec]
EPOCH 1720/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052932417084123884		[learning rate: 0.00019722]
	Learning Rate: 0.000197218
	LOSS [training: 0.052932417084123884 | validation: 0.05618327786148549]
	TIME [epoch: 9.5 sec]
EPOCH 1721/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05955107189951346		[learning rate: 0.00019674]
	Learning Rate: 0.000196741
	LOSS [training: 0.05955107189951346 | validation: 0.07043844267524994]
	TIME [epoch: 9.51 sec]
EPOCH 1722/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06938217561263049		[learning rate: 0.00019626]
	Learning Rate: 0.000196265
	LOSS [training: 0.06938217561263049 | validation: 0.06310516991061343]
	TIME [epoch: 9.5 sec]
EPOCH 1723/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06049515154704408		[learning rate: 0.00019579]
	Learning Rate: 0.00019579
	LOSS [training: 0.06049515154704408 | validation: 0.06677091770782767]
	TIME [epoch: 9.51 sec]
EPOCH 1724/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056935955403862794		[learning rate: 0.00019532]
	Learning Rate: 0.000195316
	LOSS [training: 0.056935955403862794 | validation: 0.05873051140230112]
	TIME [epoch: 9.51 sec]
EPOCH 1725/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056178399470927745		[learning rate: 0.00019484]
	Learning Rate: 0.000194843
	LOSS [training: 0.056178399470927745 | validation: 0.059934527281197116]
	TIME [epoch: 9.51 sec]
EPOCH 1726/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06875785705431044		[learning rate: 0.00019437]
	Learning Rate: 0.000194371
	LOSS [training: 0.06875785705431044 | validation: 0.08368430714950169]
	TIME [epoch: 9.5 sec]
EPOCH 1727/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0862498942470935		[learning rate: 0.0001939]
	Learning Rate: 0.000193901
	LOSS [training: 0.0862498942470935 | validation: 0.08175099894020069]
	TIME [epoch: 9.51 sec]
EPOCH 1728/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07553408878457238		[learning rate: 0.00019343]
	Learning Rate: 0.000193431
	LOSS [training: 0.07553408878457238 | validation: 0.07424915813403639]
	TIME [epoch: 9.51 sec]
EPOCH 1729/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08115451470852181		[learning rate: 0.00019296]
	Learning Rate: 0.000192963
	LOSS [training: 0.08115451470852181 | validation: 0.06904814152082599]
	TIME [epoch: 9.5 sec]
EPOCH 1730/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06701890463037574		[learning rate: 0.0001925]
	Learning Rate: 0.000192496
	LOSS [training: 0.06701890463037574 | validation: 0.05901760773214918]
	TIME [epoch: 9.5 sec]
EPOCH 1731/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06223635086665631		[learning rate: 0.00019203]
	Learning Rate: 0.00019203
	LOSS [training: 0.06223635086665631 | validation: 0.05361042052760301]
	TIME [epoch: 9.52 sec]
EPOCH 1732/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0556333585591509		[learning rate: 0.00019156]
	Learning Rate: 0.000191565
	LOSS [training: 0.0556333585591509 | validation: 0.06097552911804906]
	TIME [epoch: 9.51 sec]
EPOCH 1733/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057737125267292654		[learning rate: 0.0001911]
	Learning Rate: 0.000191101
	LOSS [training: 0.057737125267292654 | validation: 0.05370608940767374]
	TIME [epoch: 9.51 sec]
EPOCH 1734/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057537675582562696		[learning rate: 0.00019064]
	Learning Rate: 0.000190638
	LOSS [training: 0.057537675582562696 | validation: 0.06538779969991235]
	TIME [epoch: 9.51 sec]
EPOCH 1735/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061699316157922166		[learning rate: 0.00019018]
	Learning Rate: 0.000190177
	LOSS [training: 0.061699316157922166 | validation: 0.04334143518122366]
	TIME [epoch: 9.51 sec]
EPOCH 1736/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058078877520342555		[learning rate: 0.00018972]
	Learning Rate: 0.000189717
	LOSS [training: 0.058078877520342555 | validation: 0.0554487268383733]
	TIME [epoch: 9.5 sec]
EPOCH 1737/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060177880319526436		[learning rate: 0.00018926]
	Learning Rate: 0.000189257
	LOSS [training: 0.060177880319526436 | validation: 0.05983706690266065]
	TIME [epoch: 9.5 sec]
EPOCH 1738/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06047138173916813		[learning rate: 0.0001888]
	Learning Rate: 0.000188799
	LOSS [training: 0.06047138173916813 | validation: 0.05128794037678001]
	TIME [epoch: 9.52 sec]
EPOCH 1739/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0650330771225993		[learning rate: 0.00018834]
	Learning Rate: 0.000188342
	LOSS [training: 0.0650330771225993 | validation: 0.07085669083553102]
	TIME [epoch: 9.5 sec]
EPOCH 1740/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06935108836089308		[learning rate: 0.00018789]
	Learning Rate: 0.000187886
	LOSS [training: 0.06935108836089308 | validation: 0.05179204173632069]
	TIME [epoch: 9.5 sec]
EPOCH 1741/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05942456114538497		[learning rate: 0.00018743]
	Learning Rate: 0.000187431
	LOSS [training: 0.05942456114538497 | validation: 0.05769901093373383]
	TIME [epoch: 9.51 sec]
EPOCH 1742/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06121009777604223		[learning rate: 0.00018698]
	Learning Rate: 0.000186978
	LOSS [training: 0.06121009777604223 | validation: 0.0595752480673209]
	TIME [epoch: 9.51 sec]
EPOCH 1743/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07041889012133828		[learning rate: 0.00018652]
	Learning Rate: 0.000186525
	LOSS [training: 0.07041889012133828 | validation: 0.05705521496630912]
	TIME [epoch: 9.5 sec]
EPOCH 1744/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06576067157749192		[learning rate: 0.00018607]
	Learning Rate: 0.000186073
	LOSS [training: 0.06576067157749192 | validation: 0.062433509122815194]
	TIME [epoch: 9.5 sec]
EPOCH 1745/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07184640637296925		[learning rate: 0.00018562]
	Learning Rate: 0.000185623
	LOSS [training: 0.07184640637296925 | validation: 0.06862277790051112]
	TIME [epoch: 9.52 sec]
EPOCH 1746/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06901072397957718		[learning rate: 0.00018517]
	Learning Rate: 0.000185174
	LOSS [training: 0.06901072397957718 | validation: 0.057498836122354964]
	TIME [epoch: 9.5 sec]
EPOCH 1747/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07071364716307187		[learning rate: 0.00018473]
	Learning Rate: 0.000184725
	LOSS [training: 0.07071364716307187 | validation: 0.07082019503445106]
	TIME [epoch: 9.5 sec]
EPOCH 1748/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06189124475283364		[learning rate: 0.00018428]
	Learning Rate: 0.000184278
	LOSS [training: 0.06189124475283364 | validation: 0.06723154426972588]
	TIME [epoch: 9.51 sec]
EPOCH 1749/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06437982244654308		[learning rate: 0.00018383]
	Learning Rate: 0.000183832
	LOSS [training: 0.06437982244654308 | validation: 0.06835018769263121]
	TIME [epoch: 9.51 sec]
EPOCH 1750/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06059970556684757		[learning rate: 0.00018339]
	Learning Rate: 0.000183387
	LOSS [training: 0.06059970556684757 | validation: 0.04321684502883009]
	TIME [epoch: 9.5 sec]
EPOCH 1751/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05303903715441183		[learning rate: 0.00018294]
	Learning Rate: 0.000182943
	LOSS [training: 0.05303903715441183 | validation: 0.0707670464175104]
	TIME [epoch: 9.51 sec]
EPOCH 1752/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06203951901673247		[learning rate: 0.0001825]
	Learning Rate: 0.0001825
	LOSS [training: 0.06203951901673247 | validation: 0.07396033192480041]
	TIME [epoch: 9.52 sec]
EPOCH 1753/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06409822605908541		[learning rate: 0.00018206]
	Learning Rate: 0.000182058
	LOSS [training: 0.06409822605908541 | validation: 0.06726292053980097]
	TIME [epoch: 9.49 sec]
EPOCH 1754/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06440740482825659		[learning rate: 0.00018162]
	Learning Rate: 0.000181618
	LOSS [training: 0.06440740482825659 | validation: 0.0606990355549484]
	TIME [epoch: 9.5 sec]
EPOCH 1755/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05978454119746165		[learning rate: 0.00018118]
	Learning Rate: 0.000181178
	LOSS [training: 0.05978454119746165 | validation: 0.04164966892386694]
	TIME [epoch: 9.52 sec]
EPOCH 1756/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05542588924875447		[learning rate: 0.00018074]
	Learning Rate: 0.000180739
	LOSS [training: 0.05542588924875447 | validation: 0.060887076025197114]
	TIME [epoch: 9.5 sec]
EPOCH 1757/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0508273445696958		[learning rate: 0.0001803]
	Learning Rate: 0.000180302
	LOSS [training: 0.0508273445696958 | validation: 0.05487574698810395]
	TIME [epoch: 9.5 sec]
EPOCH 1758/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057935389743156776		[learning rate: 0.00017987]
	Learning Rate: 0.000179865
	LOSS [training: 0.057935389743156776 | validation: 0.05465997590438121]
	TIME [epoch: 9.5 sec]
EPOCH 1759/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06136907332059473		[learning rate: 0.00017943]
	Learning Rate: 0.00017943
	LOSS [training: 0.06136907332059473 | validation: 0.055510363220813666]
	TIME [epoch: 9.51 sec]
EPOCH 1760/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057105346776226494		[learning rate: 0.000179]
	Learning Rate: 0.000178996
	LOSS [training: 0.057105346776226494 | validation: 0.057091771095948006]
	TIME [epoch: 9.49 sec]
EPOCH 1761/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05670420263065286		[learning rate: 0.00017856]
	Learning Rate: 0.000178562
	LOSS [training: 0.05670420263065286 | validation: 0.0662512848534732]
	TIME [epoch: 9.5 sec]
EPOCH 1762/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06130886959642088		[learning rate: 0.00017813]
	Learning Rate: 0.00017813
	LOSS [training: 0.06130886959642088 | validation: 0.04537247081670965]
	TIME [epoch: 9.51 sec]
EPOCH 1763/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06146623826138041		[learning rate: 0.0001777]
	Learning Rate: 0.000177699
	LOSS [training: 0.06146623826138041 | validation: 0.05372994907256169]
	TIME [epoch: 9.5 sec]
EPOCH 1764/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05740743862749996		[learning rate: 0.00017727]
	Learning Rate: 0.000177268
	LOSS [training: 0.05740743862749996 | validation: 0.05805388904029883]
	TIME [epoch: 9.49 sec]
EPOCH 1765/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058883795050967844		[learning rate: 0.00017684]
	Learning Rate: 0.000176839
	LOSS [training: 0.058883795050967844 | validation: 0.06673552368339182]
	TIME [epoch: 9.49 sec]
EPOCH 1766/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0636368657584058		[learning rate: 0.00017641]
	Learning Rate: 0.000176411
	LOSS [training: 0.0636368657584058 | validation: 0.06357976777140482]
	TIME [epoch: 9.51 sec]
EPOCH 1767/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06967735799948571		[learning rate: 0.00017598]
	Learning Rate: 0.000175984
	LOSS [training: 0.06967735799948571 | validation: 0.038835522805210514]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1767.pth
	Model improved!!!
EPOCH 1768/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05828001062566054		[learning rate: 0.00017556]
	Learning Rate: 0.000175558
	LOSS [training: 0.05828001062566054 | validation: 0.05088568401944077]
	TIME [epoch: 9.5 sec]
EPOCH 1769/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06862633106000245		[learning rate: 0.00017513]
	Learning Rate: 0.000175133
	LOSS [training: 0.06862633106000245 | validation: 0.06832224647693819]
	TIME [epoch: 9.51 sec]
EPOCH 1770/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08145719731025622		[learning rate: 0.00017471]
	Learning Rate: 0.000174709
	LOSS [training: 0.08145719731025622 | validation: 0.06422309761733551]
	TIME [epoch: 9.5 sec]
EPOCH 1771/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07541397841331314		[learning rate: 0.00017429]
	Learning Rate: 0.000174286
	LOSS [training: 0.07541397841331314 | validation: 0.07987809926045583]
	TIME [epoch: 9.5 sec]
EPOCH 1772/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07653228115529595		[learning rate: 0.00017386]
	Learning Rate: 0.000173864
	LOSS [training: 0.07653228115529595 | validation: 0.04900479577744765]
	TIME [epoch: 9.49 sec]
EPOCH 1773/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07718166757300647		[learning rate: 0.00017344]
	Learning Rate: 0.000173443
	LOSS [training: 0.07718166757300647 | validation: 0.08858280166396552]
	TIME [epoch: 9.51 sec]
EPOCH 1774/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08072818224456971		[learning rate: 0.00017302]
	Learning Rate: 0.000173024
	LOSS [training: 0.08072818224456971 | validation: 0.07786696057070529]
	TIME [epoch: 9.49 sec]
EPOCH 1775/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07960854424263855		[learning rate: 0.0001726]
	Learning Rate: 0.000172605
	LOSS [training: 0.07960854424263855 | validation: 0.07291135648840935]
	TIME [epoch: 9.5 sec]
EPOCH 1776/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08009666671736734		[learning rate: 0.00017219]
	Learning Rate: 0.000172187
	LOSS [training: 0.08009666671736734 | validation: 0.06463381700952298]
	TIME [epoch: 9.51 sec]
EPOCH 1777/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06561635268042251		[learning rate: 0.00017177]
	Learning Rate: 0.00017177
	LOSS [training: 0.06561635268042251 | validation: 0.05812867141883614]
	TIME [epoch: 9.49 sec]
EPOCH 1778/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06073232282196671		[learning rate: 0.00017135]
	Learning Rate: 0.000171354
	LOSS [training: 0.06073232282196671 | validation: 0.05808951304457097]
	TIME [epoch: 9.5 sec]
EPOCH 1779/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0658434113324126		[learning rate: 0.00017094]
	Learning Rate: 0.000170939
	LOSS [training: 0.0658434113324126 | validation: 0.06934166250277593]
	TIME [epoch: 9.5 sec]
EPOCH 1780/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06195839621953429		[learning rate: 0.00017053]
	Learning Rate: 0.000170526
	LOSS [training: 0.06195839621953429 | validation: 0.06858798634237025]
	TIME [epoch: 9.52 sec]
EPOCH 1781/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05634654131487514		[learning rate: 0.00017011]
	Learning Rate: 0.000170113
	LOSS [training: 0.05634654131487514 | validation: 0.053912130792097966]
	TIME [epoch: 9.49 sec]
EPOCH 1782/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05210823893887344		[learning rate: 0.0001697]
	Learning Rate: 0.000169701
	LOSS [training: 0.05210823893887344 | validation: 0.061042182537532776]
	TIME [epoch: 9.49 sec]
EPOCH 1783/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06469156952267863		[learning rate: 0.00016929]
	Learning Rate: 0.00016929
	LOSS [training: 0.06469156952267863 | validation: 0.08069776290477494]
	TIME [epoch: 9.51 sec]
EPOCH 1784/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06893220831982041		[learning rate: 0.00016888]
	Learning Rate: 0.00016888
	LOSS [training: 0.06893220831982041 | validation: 0.07417303798859498]
	TIME [epoch: 9.5 sec]
EPOCH 1785/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05487975130746252		[learning rate: 0.00016847]
	Learning Rate: 0.000168471
	LOSS [training: 0.05487975130746252 | validation: 0.057080075318455166]
	TIME [epoch: 9.5 sec]
EPOCH 1786/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054095158032450665		[learning rate: 0.00016806]
	Learning Rate: 0.000168064
	LOSS [training: 0.054095158032450665 | validation: 0.05155756224961263]
	TIME [epoch: 9.5 sec]
EPOCH 1787/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05227652370742568		[learning rate: 0.00016766]
	Learning Rate: 0.000167657
	LOSS [training: 0.05227652370742568 | validation: 0.05768768404955704]
	TIME [epoch: 9.51 sec]
EPOCH 1788/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05040172612582615		[learning rate: 0.00016725]
	Learning Rate: 0.000167251
	LOSS [training: 0.05040172612582615 | validation: 0.06597272159121813]
	TIME [epoch: 9.5 sec]
EPOCH 1789/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06525913004605641		[learning rate: 0.00016685]
	Learning Rate: 0.000166846
	LOSS [training: 0.06525913004605641 | validation: 0.07271836203660735]
	TIME [epoch: 9.5 sec]
EPOCH 1790/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07945893950101378		[learning rate: 0.00016644]
	Learning Rate: 0.000166442
	LOSS [training: 0.07945893950101378 | validation: 0.0810705191361105]
	TIME [epoch: 9.52 sec]
EPOCH 1791/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061065168232638786		[learning rate: 0.00016604]
	Learning Rate: 0.000166039
	LOSS [training: 0.061065168232638786 | validation: 0.050700084236723626]
	TIME [epoch: 9.5 sec]
EPOCH 1792/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06032199443011928		[learning rate: 0.00016564]
	Learning Rate: 0.000165637
	LOSS [training: 0.06032199443011928 | validation: 0.06818718177447261]
	TIME [epoch: 9.5 sec]
EPOCH 1793/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054782048356948956		[learning rate: 0.00016524]
	Learning Rate: 0.000165236
	LOSS [training: 0.054782048356948956 | validation: 0.05186499551408083]
	TIME [epoch: 9.51 sec]
EPOCH 1794/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05481067048863301		[learning rate: 0.00016484]
	Learning Rate: 0.000164836
	LOSS [training: 0.05481067048863301 | validation: 0.04674249995176063]
	TIME [epoch: 9.51 sec]
EPOCH 1795/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05833244407815723		[learning rate: 0.00016444]
	Learning Rate: 0.000164437
	LOSS [training: 0.05833244407815723 | validation: 0.036953413941957065]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1795.pth
	Model improved!!!
EPOCH 1796/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05557813151875983		[learning rate: 0.00016404]
	Learning Rate: 0.000164039
	LOSS [training: 0.05557813151875983 | validation: 0.056437238181309225]
	TIME [epoch: 9.49 sec]
EPOCH 1797/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05920506469064858		[learning rate: 0.00016364]
	Learning Rate: 0.000163642
	LOSS [training: 0.05920506469064858 | validation: 0.0451845401389429]
	TIME [epoch: 9.52 sec]
EPOCH 1798/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06120571731749486		[learning rate: 0.00016325]
	Learning Rate: 0.000163246
	LOSS [training: 0.06120571731749486 | validation: 0.05877377563219022]
	TIME [epoch: 9.5 sec]
EPOCH 1799/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05911485369738902		[learning rate: 0.00016285]
	Learning Rate: 0.000162851
	LOSS [training: 0.05911485369738902 | validation: 0.0505375043668051]
	TIME [epoch: 9.49 sec]
EPOCH 1800/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05159982434705947		[learning rate: 0.00016246]
	Learning Rate: 0.000162456
	LOSS [training: 0.05159982434705947 | validation: 0.05381489111276949]
	TIME [epoch: 9.51 sec]
EPOCH 1801/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05168581294366403		[learning rate: 0.00016206]
	Learning Rate: 0.000162063
	LOSS [training: 0.05168581294366403 | validation: 0.067624938572897]
	TIME [epoch: 9.5 sec]
EPOCH 1802/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06052616120551964		[learning rate: 0.00016167]
	Learning Rate: 0.000161671
	LOSS [training: 0.06052616120551964 | validation: 0.05636312092481809]
	TIME [epoch: 9.5 sec]
EPOCH 1803/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060120538461117666		[learning rate: 0.00016128]
	Learning Rate: 0.000161279
	LOSS [training: 0.060120538461117666 | validation: 0.04007475971334694]
	TIME [epoch: 9.5 sec]
EPOCH 1804/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05084153804870659		[learning rate: 0.00016089]
	Learning Rate: 0.000160889
	LOSS [training: 0.05084153804870659 | validation: 0.05621556708936543]
	TIME [epoch: 9.51 sec]
EPOCH 1805/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056985127329131344		[learning rate: 0.0001605]
	Learning Rate: 0.000160499
	LOSS [training: 0.056985127329131344 | validation: 0.056134764077317705]
	TIME [epoch: 9.5 sec]
EPOCH 1806/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05510655459508286		[learning rate: 0.00016011]
	Learning Rate: 0.000160111
	LOSS [training: 0.05510655459508286 | validation: 0.05968626625292928]
	TIME [epoch: 9.49 sec]
EPOCH 1807/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05409472379553315		[learning rate: 0.00015972]
	Learning Rate: 0.000159723
	LOSS [training: 0.05409472379553315 | validation: 0.061744150293187645]
	TIME [epoch: 9.5 sec]
EPOCH 1808/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05551551222290747		[learning rate: 0.00015934]
	Learning Rate: 0.000159337
	LOSS [training: 0.05551551222290747 | validation: 0.0570048280840017]
	TIME [epoch: 9.5 sec]
EPOCH 1809/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057208773406097		[learning rate: 0.00015895]
	Learning Rate: 0.000158951
	LOSS [training: 0.057208773406097 | validation: 0.04767419640451992]
	TIME [epoch: 9.49 sec]
EPOCH 1810/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05224547287882743		[learning rate: 0.00015857]
	Learning Rate: 0.000158566
	LOSS [training: 0.05224547287882743 | validation: 0.05469280484579746]
	TIME [epoch: 9.49 sec]
EPOCH 1811/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054986075517659036		[learning rate: 0.00015818]
	Learning Rate: 0.000158182
	LOSS [training: 0.054986075517659036 | validation: 0.050263030638411144]
	TIME [epoch: 9.51 sec]
EPOCH 1812/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05797445488819519		[learning rate: 0.0001578]
	Learning Rate: 0.000157799
	LOSS [training: 0.05797445488819519 | validation: 0.05974740195590034]
	TIME [epoch: 9.5 sec]
EPOCH 1813/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055984174469815386		[learning rate: 0.00015742]
	Learning Rate: 0.000157417
	LOSS [training: 0.055984174469815386 | validation: 0.057035620809029075]
	TIME [epoch: 9.5 sec]
EPOCH 1814/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06548337033655806		[learning rate: 0.00015704]
	Learning Rate: 0.000157036
	LOSS [training: 0.06548337033655806 | validation: 0.061816540339754956]
	TIME [epoch: 9.51 sec]
EPOCH 1815/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06071025474296572		[learning rate: 0.00015666]
	Learning Rate: 0.000156656
	LOSS [training: 0.06071025474296572 | validation: 0.0537453779316194]
	TIME [epoch: 9.5 sec]
EPOCH 1816/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06271297671432767		[learning rate: 0.00015628]
	Learning Rate: 0.000156277
	LOSS [training: 0.06271297671432767 | validation: 0.06774958442207522]
	TIME [epoch: 9.5 sec]
EPOCH 1817/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06145472812257387		[learning rate: 0.0001559]
	Learning Rate: 0.000155899
	LOSS [training: 0.06145472812257387 | validation: 0.061153521139031164]
	TIME [epoch: 9.5 sec]
EPOCH 1818/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06034721543934923		[learning rate: 0.00015552]
	Learning Rate: 0.000155521
	LOSS [training: 0.06034721543934923 | validation: 0.058595796865692655]
	TIME [epoch: 9.51 sec]
EPOCH 1819/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06256703225945973		[learning rate: 0.00015514]
	Learning Rate: 0.000155145
	LOSS [training: 0.06256703225945973 | validation: 0.05583504710245808]
	TIME [epoch: 9.5 sec]
EPOCH 1820/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05326310052752496		[learning rate: 0.00015477]
	Learning Rate: 0.000154769
	LOSS [training: 0.05326310052752496 | validation: 0.06105901233015141]
	TIME [epoch: 9.5 sec]
EPOCH 1821/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05033851997112863		[learning rate: 0.00015439]
	Learning Rate: 0.000154394
	LOSS [training: 0.05033851997112863 | validation: 0.05953276417566855]
	TIME [epoch: 9.51 sec]
EPOCH 1822/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04974401600346921		[learning rate: 0.00015402]
	Learning Rate: 0.000154021
	LOSS [training: 0.04974401600346921 | validation: 0.0645525753114181]
	TIME [epoch: 9.51 sec]
EPOCH 1823/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05439786707264175		[learning rate: 0.00015365]
	Learning Rate: 0.000153648
	LOSS [training: 0.05439786707264175 | validation: 0.04561950117545598]
	TIME [epoch: 9.5 sec]
EPOCH 1824/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054492485863991524		[learning rate: 0.00015328]
	Learning Rate: 0.000153276
	LOSS [training: 0.054492485863991524 | validation: 0.038314252485414875]
	TIME [epoch: 9.49 sec]
EPOCH 1825/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05861694331763998		[learning rate: 0.0001529]
	Learning Rate: 0.000152905
	LOSS [training: 0.05861694331763998 | validation: 0.05799078689113916]
	TIME [epoch: 9.51 sec]
EPOCH 1826/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058726368467940805		[learning rate: 0.00015253]
	Learning Rate: 0.000152535
	LOSS [training: 0.058726368467940805 | validation: 0.06952825363137549]
	TIME [epoch: 9.5 sec]
EPOCH 1827/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06173823328033338		[learning rate: 0.00015217]
	Learning Rate: 0.000152165
	LOSS [training: 0.06173823328033338 | validation: 0.08408184676351392]
	TIME [epoch: 9.5 sec]
EPOCH 1828/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05758755607207585		[learning rate: 0.0001518]
	Learning Rate: 0.000151797
	LOSS [training: 0.05758755607207585 | validation: 0.06449366164849112]
	TIME [epoch: 9.51 sec]
EPOCH 1829/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06074879251791274		[learning rate: 0.00015143]
	Learning Rate: 0.00015143
	LOSS [training: 0.06074879251791274 | validation: 0.060122480786908725]
	TIME [epoch: 9.49 sec]
EPOCH 1830/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05737514629305508		[learning rate: 0.00015106]
	Learning Rate: 0.000151063
	LOSS [training: 0.05737514629305508 | validation: 0.0660042145853042]
	TIME [epoch: 9.49 sec]
EPOCH 1831/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06177094692583631		[learning rate: 0.0001507]
	Learning Rate: 0.000150697
	LOSS [training: 0.06177094692583631 | validation: 0.04755854096772378]
	TIME [epoch: 9.5 sec]
EPOCH 1832/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0557299067402192		[learning rate: 0.00015033]
	Learning Rate: 0.000150332
	LOSS [training: 0.0557299067402192 | validation: 0.06718527653529138]
	TIME [epoch: 9.52 sec]
EPOCH 1833/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05300658050926531		[learning rate: 0.00014997]
	Learning Rate: 0.000149968
	LOSS [training: 0.05300658050926531 | validation: 0.06760134456572602]
	TIME [epoch: 9.51 sec]
EPOCH 1834/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053600228651940404		[learning rate: 0.00014961]
	Learning Rate: 0.000149605
	LOSS [training: 0.053600228651940404 | validation: 0.03435003382167466]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r2_20240219_183145/states/model_tr_study6_1834.pth
	Model improved!!!
EPOCH 1835/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052938931332049764		[learning rate: 0.00014924]
	Learning Rate: 0.000149243
	LOSS [training: 0.052938931332049764 | validation: 0.062293742066229556]
	TIME [epoch: 9.51 sec]
EPOCH 1836/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06038362211799183		[learning rate: 0.00014888]
	Learning Rate: 0.000148882
	LOSS [training: 0.06038362211799183 | validation: 0.07169665199770646]
	TIME [epoch: 9.5 sec]
EPOCH 1837/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06274273184608516		[learning rate: 0.00014852]
	Learning Rate: 0.000148522
	LOSS [training: 0.06274273184608516 | validation: 0.061701126186689284]
	TIME [epoch: 9.5 sec]
EPOCH 1838/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05976993605721961		[learning rate: 0.00014816]
	Learning Rate: 0.000148162
	LOSS [training: 0.05976993605721961 | validation: 0.07236672592761494]
	TIME [epoch: 9.5 sec]
EPOCH 1839/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06769086059082648		[learning rate: 0.0001478]
	Learning Rate: 0.000147803
	LOSS [training: 0.06769086059082648 | validation: 0.08766035337727261]
	TIME [epoch: 9.51 sec]
EPOCH 1840/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07374187627648388		[learning rate: 0.00014745]
	Learning Rate: 0.000147446
	LOSS [training: 0.07374187627648388 | validation: 0.06881536302216096]
	TIME [epoch: 9.5 sec]
EPOCH 1841/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07580943521443449		[learning rate: 0.00014709]
	Learning Rate: 0.000147089
	LOSS [training: 0.07580943521443449 | validation: 0.09160441363871533]
	TIME [epoch: 9.49 sec]
EPOCH 1842/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.089058315400385		[learning rate: 0.00014673]
	Learning Rate: 0.000146732
	LOSS [training: 0.089058315400385 | validation: 0.09432572957624497]
	TIME [epoch: 9.52 sec]
EPOCH 1843/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08491550768024922		[learning rate: 0.00014638]
	Learning Rate: 0.000146377
	LOSS [training: 0.08491550768024922 | validation: 0.08319184890063835]
	TIME [epoch: 9.5 sec]
EPOCH 1844/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07764594493441804		[learning rate: 0.00014602]
	Learning Rate: 0.000146023
	LOSS [training: 0.07764594493441804 | validation: 0.07987573447740967]
	TIME [epoch: 9.5 sec]
EPOCH 1845/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08164678088103014		[learning rate: 0.00014567]
	Learning Rate: 0.000145669
	LOSS [training: 0.08164678088103014 | validation: 0.0778749188173284]
	TIME [epoch: 9.5 sec]
EPOCH 1846/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07335420540018936		[learning rate: 0.00014532]
	Learning Rate: 0.000145317
	LOSS [training: 0.07335420540018936 | validation: 0.08075757402749868]
	TIME [epoch: 9.52 sec]
EPOCH 1847/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06966612671508032		[learning rate: 0.00014497]
	Learning Rate: 0.000144965
	LOSS [training: 0.06966612671508032 | validation: 0.09208364464045359]
	TIME [epoch: 9.49 sec]
EPOCH 1848/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08169359284714146		[learning rate: 0.00014461]
	Learning Rate: 0.000144614
	LOSS [training: 0.08169359284714146 | validation: 0.07393910453712868]
	TIME [epoch: 9.5 sec]
EPOCH 1849/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07857299000462661		[learning rate: 0.00014426]
	Learning Rate: 0.000144264
	LOSS [training: 0.07857299000462661 | validation: 0.08158331293601646]
	TIME [epoch: 9.51 sec]
EPOCH 1850/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07773838715196935		[learning rate: 0.00014391]
	Learning Rate: 0.000143915
	LOSS [training: 0.07773838715196935 | validation: 0.07723188170202563]
	TIME [epoch: 9.5 sec]
EPOCH 1851/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07305735384033979		[learning rate: 0.00014357]
	Learning Rate: 0.000143566
	LOSS [training: 0.07305735384033979 | validation: 0.06999387936024296]
	TIME [epoch: 9.49 sec]
EPOCH 1852/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06126186849231126		[learning rate: 0.00014322]
	Learning Rate: 0.000143219
	LOSS [training: 0.06126186849231126 | validation: 0.07677448875248098]
	TIME [epoch: 9.52 sec]
EPOCH 1853/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06985061400752188		[learning rate: 0.00014287]
	Learning Rate: 0.000142872
	LOSS [training: 0.06985061400752188 | validation: 0.06597024636446887]
	TIME [epoch: 9.5 sec]
EPOCH 1854/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06639491376189846		[learning rate: 0.00014253]
	Learning Rate: 0.000142526
	LOSS [training: 0.06639491376189846 | validation: 0.0676467549356339]
	TIME [epoch: 9.5 sec]
EPOCH 1855/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.062326460144051944		[learning rate: 0.00014218]
	Learning Rate: 0.000142181
	LOSS [training: 0.062326460144051944 | validation: 0.05940684796485129]
	TIME [epoch: 9.49 sec]
EPOCH 1856/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06550442998502075		[learning rate: 0.00014184]
	Learning Rate: 0.000141837
	LOSS [training: 0.06550442998502075 | validation: 0.05587795271373954]
	TIME [epoch: 9.51 sec]
EPOCH 1857/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07533421588407328		[learning rate: 0.00014149]
	Learning Rate: 0.000141494
	LOSS [training: 0.07533421588407328 | validation: 0.06233558892761153]
	TIME [epoch: 9.5 sec]
EPOCH 1858/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0746003939726895		[learning rate: 0.00014115]
	Learning Rate: 0.000141151
	LOSS [training: 0.0746003939726895 | validation: 0.07224167566948869]
	TIME [epoch: 9.5 sec]
EPOCH 1859/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08018643382753779		[learning rate: 0.00014081]
	Learning Rate: 0.000140809
	LOSS [training: 0.08018643382753779 | validation: 0.07568307667863372]
	TIME [epoch: 9.5 sec]
EPOCH 1860/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08810593890086003		[learning rate: 0.00014047]
	Learning Rate: 0.000140468
	LOSS [training: 0.08810593890086003 | validation: 0.07867803402147415]
	TIME [epoch: 9.51 sec]
EPOCH 1861/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.10292576375743896		[learning rate: 0.00014013]
	Learning Rate: 0.000140128
	LOSS [training: 0.10292576375743896 | validation: 0.09703810031549155]
	TIME [epoch: 9.49 sec]
EPOCH 1862/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11492740247588525		[learning rate: 0.00013979]
	Learning Rate: 0.000139789
	LOSS [training: 0.11492740247588525 | validation: 0.0904310615608634]
	TIME [epoch: 9.5 sec]
EPOCH 1863/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.11377719506084553		[learning rate: 0.00013945]
	Learning Rate: 0.000139451
	LOSS [training: 0.11377719506084553 | validation: 0.08520219994895616]
	TIME [epoch: 9.52 sec]
EPOCH 1864/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0962239791981988		[learning rate: 0.00013911]
	Learning Rate: 0.000139113
	LOSS [training: 0.0962239791981988 | validation: 0.0848296945481454]
	TIME [epoch: 9.49 sec]
EPOCH 1865/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.08762975706309603		[learning rate: 0.00013878]
	Learning Rate: 0.000138776
	LOSS [training: 0.08762975706309603 | validation: 0.08313213460236434]
	TIME [epoch: 9.5 sec]
EPOCH 1866/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09646658583673082		[learning rate: 0.00013844]
	Learning Rate: 0.000138441
	LOSS [training: 0.09646658583673082 | validation: 0.09496371009626658]
	TIME [epoch: 9.5 sec]
EPOCH 1867/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.09691464790064647		[learning rate: 0.00013811]
	Learning Rate: 0.000138105
	LOSS [training: 0.09691464790064647 | validation: 0.07015688531137922]
	TIME [epoch: 9.5 sec]
EPOCH 1868/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07922768266129217		[learning rate: 0.00013777]
	Learning Rate: 0.000137771
	LOSS [training: 0.07922768266129217 | validation: 0.06424205114270488]
	TIME [epoch: 9.49 sec]
EPOCH 1869/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0762351526249856		[learning rate: 0.00013744]
	Learning Rate: 0.000137437
	LOSS [training: 0.0762351526249856 | validation: 0.06726016399757562]
	TIME [epoch: 9.5 sec]
EPOCH 1870/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07578857723971474		[learning rate: 0.0001371]
	Learning Rate: 0.000137105
	LOSS [training: 0.07578857723971474 | validation: 0.06030645730045605]
	TIME [epoch: 9.51 sec]
EPOCH 1871/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06197043349749343		[learning rate: 0.00013677]
	Learning Rate: 0.000136773
	LOSS [training: 0.06197043349749343 | validation: 0.04902200367360708]
	TIME [epoch: 9.49 sec]
EPOCH 1872/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06038710117589867		[learning rate: 0.00013644]
	Learning Rate: 0.000136442
	LOSS [training: 0.06038710117589867 | validation: 0.07067116615337124]
	TIME [epoch: 9.5 sec]
EPOCH 1873/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06551618595719602		[learning rate: 0.00013611]
	Learning Rate: 0.000136111
	LOSS [training: 0.06551618595719602 | validation: 0.07148737970124944]
	TIME [epoch: 9.5 sec]
EPOCH 1874/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06536154233518375		[learning rate: 0.00013578]
	Learning Rate: 0.000135782
	LOSS [training: 0.06536154233518375 | validation: 0.05656394150750003]
	TIME [epoch: 9.5 sec]
EPOCH 1875/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07070257275443861		[learning rate: 0.00013545]
	Learning Rate: 0.000135453
	LOSS [training: 0.07070257275443861 | validation: 0.05792288411645515]
	TIME [epoch: 9.5 sec]
EPOCH 1876/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0704408646748361		[learning rate: 0.00013513]
	Learning Rate: 0.000135125
	LOSS [training: 0.0704408646748361 | validation: 0.06605566192046046]
	TIME [epoch: 9.49 sec]
EPOCH 1877/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06559223218281769		[learning rate: 0.0001348]
	Learning Rate: 0.000134798
	LOSS [training: 0.06559223218281769 | validation: 0.055234643703705726]
	TIME [epoch: 9.51 sec]
EPOCH 1878/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05254309825291301		[learning rate: 0.00013447]
	Learning Rate: 0.000134472
	LOSS [training: 0.05254309825291301 | validation: 0.05531435986282196]
	TIME [epoch: 9.49 sec]
EPOCH 1879/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060683872543189986		[learning rate: 0.00013415]
	Learning Rate: 0.000134146
	LOSS [training: 0.060683872543189986 | validation: 0.05998176089803863]
	TIME [epoch: 9.49 sec]
EPOCH 1880/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05858185804741702		[learning rate: 0.00013382]
	Learning Rate: 0.000133822
	LOSS [training: 0.05858185804741702 | validation: 0.054515421395691]
	TIME [epoch: 9.51 sec]
EPOCH 1881/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058504307059641214		[learning rate: 0.0001335]
	Learning Rate: 0.000133498
	LOSS [training: 0.058504307059641214 | validation: 0.05146610280359045]
	TIME [epoch: 9.5 sec]
EPOCH 1882/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05575575625417837		[learning rate: 0.00013317]
	Learning Rate: 0.000133175
	LOSS [training: 0.05575575625417837 | validation: 0.06085019819336039]
	TIME [epoch: 9.5 sec]
EPOCH 1883/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055705632660754546		[learning rate: 0.00013285]
	Learning Rate: 0.000132852
	LOSS [training: 0.055705632660754546 | validation: 0.04932173536060636]
	TIME [epoch: 9.49 sec]
EPOCH 1884/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0648864072070512		[learning rate: 0.00013253]
	Learning Rate: 0.00013253
	LOSS [training: 0.0648864072070512 | validation: 0.053613429262557376]
	TIME [epoch: 9.51 sec]
EPOCH 1885/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056977306740287434		[learning rate: 0.00013221]
	Learning Rate: 0.00013221
	LOSS [training: 0.056977306740287434 | validation: 0.044635276614339414]
	TIME [epoch: 9.5 sec]
EPOCH 1886/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05422938264353262		[learning rate: 0.00013189]
	Learning Rate: 0.00013189
	LOSS [training: 0.05422938264353262 | validation: 0.04253846573916701]
	TIME [epoch: 9.5 sec]
EPOCH 1887/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06723325492126776		[learning rate: 0.00013157]
	Learning Rate: 0.00013157
	LOSS [training: 0.06723325492126776 | validation: 0.059082116667201756]
	TIME [epoch: 9.51 sec]
EPOCH 1888/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06629929827885594		[learning rate: 0.00013125]
	Learning Rate: 0.000131252
	LOSS [training: 0.06629929827885594 | validation: 0.05374414928512363]
	TIME [epoch: 9.5 sec]
EPOCH 1889/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06556353058277538		[learning rate: 0.00013093]
	Learning Rate: 0.000130934
	LOSS [training: 0.06556353058277538 | validation: 0.05247420842193515]
	TIME [epoch: 9.49 sec]
EPOCH 1890/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06333938561816485		[learning rate: 0.00013062]
	Learning Rate: 0.000130617
	LOSS [training: 0.06333938561816485 | validation: 0.06294708448581038]
	TIME [epoch: 9.49 sec]
EPOCH 1891/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06275263429209924		[learning rate: 0.0001303]
	Learning Rate: 0.000130301
	LOSS [training: 0.06275263429209924 | validation: 0.04938168234428857]
	TIME [epoch: 9.51 sec]
EPOCH 1892/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06060742111462183		[learning rate: 0.00012999]
	Learning Rate: 0.000129985
	LOSS [training: 0.06060742111462183 | validation: 0.07766311294611994]
	TIME [epoch: 9.49 sec]
EPOCH 1893/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.07053761110331354		[learning rate: 0.00012967]
	Learning Rate: 0.000129671
	LOSS [training: 0.07053761110331354 | validation: 0.06460021972719067]
	TIME [epoch: 9.49 sec]
EPOCH 1894/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06315736712146694		[learning rate: 0.00012936]
	Learning Rate: 0.000129357
	LOSS [training: 0.06315736712146694 | validation: 0.05959310599876261]
	TIME [epoch: 9.51 sec]
EPOCH 1895/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06780319677846267		[learning rate: 0.00012904]
	Learning Rate: 0.000129044
	LOSS [training: 0.06780319677846267 | validation: 0.0670514601623529]
	TIME [epoch: 9.49 sec]
EPOCH 1896/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06728628882958376		[learning rate: 0.00012873]
	Learning Rate: 0.000128731
	LOSS [training: 0.06728628882958376 | validation: 0.054017080384694556]
	TIME [epoch: 9.49 sec]
EPOCH 1897/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06181947384074023		[learning rate: 0.00012842]
	Learning Rate: 0.00012842
	LOSS [training: 0.06181947384074023 | validation: 0.050046064106336115]
	TIME [epoch: 9.49 sec]
EPOCH 1898/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059252632216856206		[learning rate: 0.00012811]
	Learning Rate: 0.000128109
	LOSS [training: 0.059252632216856206 | validation: 0.040025613877603165]
	TIME [epoch: 9.5 sec]
EPOCH 1899/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056613607704525136		[learning rate: 0.0001278]
	Learning Rate: 0.000127799
	LOSS [training: 0.056613607704525136 | validation: 0.06765708573766327]
	TIME [epoch: 9.49 sec]
EPOCH 1900/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06274729556973359		[learning rate: 0.00012749]
	Learning Rate: 0.000127489
	LOSS [training: 0.06274729556973359 | validation: 0.06358907635864214]
	TIME [epoch: 9.49 sec]
EPOCH 1901/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06123424662712114		[learning rate: 0.00012718]
	Learning Rate: 0.000127181
	LOSS [training: 0.06123424662712114 | validation: 0.04739941503533837]
	TIME [epoch: 9.51 sec]
EPOCH 1902/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.059681267460677256		[learning rate: 0.00012687]
	Learning Rate: 0.000126873
	LOSS [training: 0.059681267460677256 | validation: 0.06977007398417875]
	TIME [epoch: 9.49 sec]
EPOCH 1903/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06346953080554602		[learning rate: 0.00012657]
	Learning Rate: 0.000126566
	LOSS [training: 0.06346953080554602 | validation: 0.06222243313367917]
	TIME [epoch: 9.49 sec]
EPOCH 1904/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057163093406883844		[learning rate: 0.00012626]
	Learning Rate: 0.000126259
	LOSS [training: 0.057163093406883844 | validation: 0.05322563293137456]
	TIME [epoch: 9.49 sec]
EPOCH 1905/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05658775812452278		[learning rate: 0.00012595]
	Learning Rate: 0.000125954
	LOSS [training: 0.05658775812452278 | validation: 0.05531643293756015]
	TIME [epoch: 9.51 sec]
EPOCH 1906/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05470357325465963		[learning rate: 0.00012565]
	Learning Rate: 0.000125649
	LOSS [training: 0.05470357325465963 | validation: 0.04184537867154555]
	TIME [epoch: 9.5 sec]
EPOCH 1907/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06253781316925207		[learning rate: 0.00012534]
	Learning Rate: 0.000125345
	LOSS [training: 0.06253781316925207 | validation: 0.04881940854754916]
	TIME [epoch: 9.49 sec]
EPOCH 1908/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060278773180001036		[learning rate: 0.00012504]
	Learning Rate: 0.000125041
	LOSS [training: 0.060278773180001036 | validation: 0.054543237086255324]
	TIME [epoch: 9.5 sec]
EPOCH 1909/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05177209204111392		[learning rate: 0.00012474]
	Learning Rate: 0.000124738
	LOSS [training: 0.05177209204111392 | validation: 0.05836437818982065]
	TIME [epoch: 9.49 sec]
EPOCH 1910/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06269233143853176		[learning rate: 0.00012444]
	Learning Rate: 0.000124436
	LOSS [training: 0.06269233143853176 | validation: 0.05143151329559673]
	TIME [epoch: 9.49 sec]
EPOCH 1911/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05391997314657889		[learning rate: 0.00012414]
	Learning Rate: 0.000124135
	LOSS [training: 0.05391997314657889 | validation: 0.06010441375442591]
	TIME [epoch: 9.49 sec]
EPOCH 1912/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05149672419092753		[learning rate: 0.00012383]
	Learning Rate: 0.000123835
	LOSS [training: 0.05149672419092753 | validation: 0.05779646376503637]
	TIME [epoch: 9.5 sec]
EPOCH 1913/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05801833338407871		[learning rate: 0.00012353]
	Learning Rate: 0.000123535
	LOSS [training: 0.05801833338407871 | validation: 0.06226242347627458]
	TIME [epoch: 9.5 sec]
EPOCH 1914/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06482385074894766		[learning rate: 0.00012324]
	Learning Rate: 0.000123236
	LOSS [training: 0.06482385074894766 | validation: 0.04835988899717391]
	TIME [epoch: 9.49 sec]
EPOCH 1915/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0598770135964979		[learning rate: 0.00012294]
	Learning Rate: 0.000122937
	LOSS [training: 0.0598770135964979 | validation: 0.058726811036077325]
	TIME [epoch: 9.51 sec]
EPOCH 1916/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0599507230969894		[learning rate: 0.00012264]
	Learning Rate: 0.00012264
	LOSS [training: 0.0599507230969894 | validation: 0.056800260314395425]
	TIME [epoch: 9.49 sec]
EPOCH 1917/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0695246765129809		[learning rate: 0.00012234]
	Learning Rate: 0.000122343
	LOSS [training: 0.0695246765129809 | validation: 0.05889520535748016]
	TIME [epoch: 9.48 sec]
EPOCH 1918/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05374856427821258		[learning rate: 0.00012205]
	Learning Rate: 0.000122047
	LOSS [training: 0.05374856427821258 | validation: 0.04662365370267766]
	TIME [epoch: 9.5 sec]
EPOCH 1919/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054198516522248386		[learning rate: 0.00012175]
	Learning Rate: 0.000121751
	LOSS [training: 0.054198516522248386 | validation: 0.05652608367878138]
	TIME [epoch: 9.5 sec]
EPOCH 1920/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.058869386664775404		[learning rate: 0.00012146]
	Learning Rate: 0.000121457
	LOSS [training: 0.058869386664775404 | validation: 0.05850270796803418]
	TIME [epoch: 9.49 sec]
EPOCH 1921/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06701255563654929		[learning rate: 0.00012116]
	Learning Rate: 0.000121163
	LOSS [training: 0.06701255563654929 | validation: 0.06473634464331132]
	TIME [epoch: 9.48 sec]
EPOCH 1922/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0644881077652385		[learning rate: 0.00012087]
	Learning Rate: 0.000120869
	LOSS [training: 0.0644881077652385 | validation: 0.0611140808575908]
	TIME [epoch: 9.52 sec]
EPOCH 1923/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0638694907528589		[learning rate: 0.00012058]
	Learning Rate: 0.000120577
	LOSS [training: 0.0638694907528589 | validation: 0.05802575277439621]
	TIME [epoch: 9.49 sec]
EPOCH 1924/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05991071950722197		[learning rate: 0.00012028]
	Learning Rate: 0.000120285
	LOSS [training: 0.05991071950722197 | validation: 0.06427820593226334]
	TIME [epoch: 9.5 sec]
EPOCH 1925/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06599978481499783		[learning rate: 0.00011999]
	Learning Rate: 0.000119994
	LOSS [training: 0.06599978481499783 | validation: 0.0502114097842373]
	TIME [epoch: 9.49 sec]
EPOCH 1926/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.057528598133016064		[learning rate: 0.0001197]
	Learning Rate: 0.000119703
	LOSS [training: 0.057528598133016064 | validation: 0.05433454186737979]
	TIME [epoch: 9.51 sec]
EPOCH 1927/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05603606091379952		[learning rate: 0.00011941]
	Learning Rate: 0.000119413
	LOSS [training: 0.05603606091379952 | validation: 0.06436258328762688]
	TIME [epoch: 9.49 sec]
EPOCH 1928/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06329604085402664		[learning rate: 0.00011912]
	Learning Rate: 0.000119124
	LOSS [training: 0.06329604085402664 | validation: 0.06847817334188906]
	TIME [epoch: 9.49 sec]
EPOCH 1929/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05661671985069895		[learning rate: 0.00011884]
	Learning Rate: 0.000118836
	LOSS [training: 0.05661671985069895 | validation: 0.05371601685229495]
	TIME [epoch: 9.52 sec]
EPOCH 1930/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061125599806996		[learning rate: 0.00011855]
	Learning Rate: 0.000118548
	LOSS [training: 0.061125599806996 | validation: 0.05364309952475843]
	TIME [epoch: 9.5 sec]
EPOCH 1931/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06690611594918575		[learning rate: 0.00011826]
	Learning Rate: 0.000118261
	LOSS [training: 0.06690611594918575 | validation: 0.047551306162339026]
	TIME [epoch: 9.49 sec]
EPOCH 1932/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06534377455233684		[learning rate: 0.00011797]
	Learning Rate: 0.000117975
	LOSS [training: 0.06534377455233684 | validation: 0.06262158702758525]
	TIME [epoch: 9.51 sec]
EPOCH 1933/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06518117004351853		[learning rate: 0.00011769]
	Learning Rate: 0.000117689
	LOSS [training: 0.06518117004351853 | validation: 0.05557122025674094]
	TIME [epoch: 9.51 sec]
EPOCH 1934/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06264499323848768		[learning rate: 0.0001174]
	Learning Rate: 0.000117404
	LOSS [training: 0.06264499323848768 | validation: 0.06181999478677138]
	TIME [epoch: 9.49 sec]
EPOCH 1935/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0643768852940933		[learning rate: 0.00011712]
	Learning Rate: 0.00011712
	LOSS [training: 0.0643768852940933 | validation: 0.06562416071079598]
	TIME [epoch: 9.5 sec]
EPOCH 1936/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06379573314580235		[learning rate: 0.00011684]
	Learning Rate: 0.000116837
	LOSS [training: 0.06379573314580235 | validation: 0.06570141850610962]
	TIME [epoch: 9.51 sec]
EPOCH 1937/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06868454797846206		[learning rate: 0.00011655]
	Learning Rate: 0.000116554
	LOSS [training: 0.06868454797846206 | validation: 0.08489632307081056]
	TIME [epoch: 9.5 sec]
EPOCH 1938/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06782816255677379		[learning rate: 0.00011627]
	Learning Rate: 0.000116272
	LOSS [training: 0.06782816255677379 | validation: 0.06987966894073294]
	TIME [epoch: 9.5 sec]
EPOCH 1939/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06781766854577723		[learning rate: 0.00011599]
	Learning Rate: 0.00011599
	LOSS [training: 0.06781766854577723 | validation: 0.060700686983216116]
	TIME [epoch: 9.51 sec]
EPOCH 1940/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06239039603965364		[learning rate: 0.00011571]
	Learning Rate: 0.000115709
	LOSS [training: 0.06239039603965364 | validation: 0.06588479481769488]
	TIME [epoch: 9.51 sec]
EPOCH 1941/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.061237439048773636		[learning rate: 0.00011543]
	Learning Rate: 0.000115429
	LOSS [training: 0.061237439048773636 | validation: 0.06649156577021252]
	TIME [epoch: 9.49 sec]
EPOCH 1942/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06425606479894973		[learning rate: 0.00011515]
	Learning Rate: 0.00011515
	LOSS [training: 0.06425606479894973 | validation: 0.05869613708707514]
	TIME [epoch: 9.5 sec]
EPOCH 1943/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06346311367302719		[learning rate: 0.00011487]
	Learning Rate: 0.000114871
	LOSS [training: 0.06346311367302719 | validation: 0.052761336105597766]
	TIME [epoch: 9.52 sec]
EPOCH 1944/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0695922268173715		[learning rate: 0.00011459]
	Learning Rate: 0.000114593
	LOSS [training: 0.0695922268173715 | validation: 0.05325164633958109]
	TIME [epoch: 9.5 sec]
EPOCH 1945/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06106645863515612		[learning rate: 0.00011432]
	Learning Rate: 0.000114316
	LOSS [training: 0.06106645863515612 | validation: 0.052636894615242034]
	TIME [epoch: 9.5 sec]
EPOCH 1946/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054842543586388015		[learning rate: 0.00011404]
	Learning Rate: 0.000114039
	LOSS [training: 0.054842543586388015 | validation: 0.056462925990870244]
	TIME [epoch: 9.51 sec]
EPOCH 1947/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06044029349671881		[learning rate: 0.00011376]
	Learning Rate: 0.000113763
	LOSS [training: 0.06044029349671881 | validation: 0.056169106091403125]
	TIME [epoch: 9.5 sec]
EPOCH 1948/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05799304078694441		[learning rate: 0.00011349]
	Learning Rate: 0.000113487
	LOSS [training: 0.05799304078694441 | validation: 0.05619126248194873]
	TIME [epoch: 9.5 sec]
EPOCH 1949/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05443622914984177		[learning rate: 0.00011321]
	Learning Rate: 0.000113213
	LOSS [training: 0.05443622914984177 | validation: 0.054212313895566966]
	TIME [epoch: 9.49 sec]
EPOCH 1950/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05755744776702093		[learning rate: 0.00011294]
	Learning Rate: 0.000112939
	LOSS [training: 0.05755744776702093 | validation: 0.04842853014201645]
	TIME [epoch: 9.52 sec]
EPOCH 1951/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05753559091361958		[learning rate: 0.00011267]
	Learning Rate: 0.000112665
	LOSS [training: 0.05753559091361958 | validation: 0.05165372046675121]
	TIME [epoch: 9.49 sec]
EPOCH 1952/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05851972556415003		[learning rate: 0.00011239]
	Learning Rate: 0.000112392
	LOSS [training: 0.05851972556415003 | validation: 0.044101987053951]
	TIME [epoch: 9.49 sec]
EPOCH 1953/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05822450291302154		[learning rate: 0.00011212]
	Learning Rate: 0.00011212
	LOSS [training: 0.05822450291302154 | validation: 0.05921377575303799]
	TIME [epoch: 9.51 sec]
EPOCH 1954/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060263535932815915		[learning rate: 0.00011185]
	Learning Rate: 0.000111849
	LOSS [training: 0.060263535932815915 | validation: 0.0577276413364754]
	TIME [epoch: 9.5 sec]
EPOCH 1955/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06262651374855659		[learning rate: 0.00011158]
	Learning Rate: 0.000111578
	LOSS [training: 0.06262651374855659 | validation: 0.056365979505782544]
	TIME [epoch: 9.5 sec]
EPOCH 1956/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06008199660597839		[learning rate: 0.00011131]
	Learning Rate: 0.000111308
	LOSS [training: 0.06008199660597839 | validation: 0.06469779060757368]
	TIME [epoch: 9.49 sec]
EPOCH 1957/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05976009186440393		[learning rate: 0.00011104]
	Learning Rate: 0.000111039
	LOSS [training: 0.05976009186440393 | validation: 0.06491186167019249]
	TIME [epoch: 9.52 sec]
EPOCH 1958/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0631363055568355		[learning rate: 0.00011077]
	Learning Rate: 0.00011077
	LOSS [training: 0.0631363055568355 | validation: 0.050065548717983195]
	TIME [epoch: 9.5 sec]
EPOCH 1959/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05839416058734298		[learning rate: 0.0001105]
	Learning Rate: 0.000110502
	LOSS [training: 0.05839416058734298 | validation: 0.06835211848258364]
	TIME [epoch: 9.5 sec]
EPOCH 1960/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0625304985956885		[learning rate: 0.00011023]
	Learning Rate: 0.000110234
	LOSS [training: 0.0625304985956885 | validation: 0.06242173380681794]
	TIME [epoch: 9.51 sec]
EPOCH 1961/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06445781836105122		[learning rate: 0.00010997]
	Learning Rate: 0.000109967
	LOSS [training: 0.06445781836105122 | validation: 0.07244523914644484]
	TIME [epoch: 9.49 sec]
EPOCH 1962/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0625040763495465		[learning rate: 0.0001097]
	Learning Rate: 0.000109701
	LOSS [training: 0.0625040763495465 | validation: 0.06780607588877655]
	TIME [epoch: 9.5 sec]
EPOCH 1963/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06455838710257604		[learning rate: 0.00010944]
	Learning Rate: 0.000109435
	LOSS [training: 0.06455838710257604 | validation: 0.06343504872099037]
	TIME [epoch: 9.5 sec]
EPOCH 1964/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05884151011728965		[learning rate: 0.00010917]
	Learning Rate: 0.00010917
	LOSS [training: 0.05884151011728965 | validation: 0.06807050180310598]
	TIME [epoch: 9.51 sec]
EPOCH 1965/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06090910023302461		[learning rate: 0.00010891]
	Learning Rate: 0.000108906
	LOSS [training: 0.06090910023302461 | validation: 0.05934674187127565]
	TIME [epoch: 9.49 sec]
EPOCH 1966/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05999294165402359		[learning rate: 0.00010864]
	Learning Rate: 0.000108643
	LOSS [training: 0.05999294165402359 | validation: 0.07543968587701345]
	TIME [epoch: 9.49 sec]
EPOCH 1967/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06082206881416961		[learning rate: 0.00010838]
	Learning Rate: 0.00010838
	LOSS [training: 0.06082206881416961 | validation: 0.06214349962762761]
	TIME [epoch: 9.52 sec]
EPOCH 1968/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06492395632707056		[learning rate: 0.00010812]
	Learning Rate: 0.000108117
	LOSS [training: 0.06492395632707056 | validation: 0.052095643457755636]
	TIME [epoch: 9.5 sec]
EPOCH 1969/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053464974137463005		[learning rate: 0.00010786]
	Learning Rate: 0.000107855
	LOSS [training: 0.053464974137463005 | validation: 0.04937548460550236]
	TIME [epoch: 9.49 sec]
EPOCH 1970/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05140357744245425		[learning rate: 0.00010759]
	Learning Rate: 0.000107594
	LOSS [training: 0.05140357744245425 | validation: 0.05824099095783611]
	TIME [epoch: 9.5 sec]
EPOCH 1971/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055016481201505776		[learning rate: 0.00010733]
	Learning Rate: 0.000107334
	LOSS [training: 0.055016481201505776 | validation: 0.0644240160465757]
	TIME [epoch: 9.51 sec]
EPOCH 1972/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052475283450846365		[learning rate: 0.00010707]
	Learning Rate: 0.000107074
	LOSS [training: 0.052475283450846365 | validation: 0.05237452108117621]
	TIME [epoch: 9.49 sec]
EPOCH 1973/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05462993365081692		[learning rate: 0.00010681]
	Learning Rate: 0.000106815
	LOSS [training: 0.05462993365081692 | validation: 0.051939035474168185]
	TIME [epoch: 9.5 sec]
EPOCH 1974/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05661749533855699		[learning rate: 0.00010656]
	Learning Rate: 0.000106556
	LOSS [training: 0.05661749533855699 | validation: 0.04864085762585952]
	TIME [epoch: 9.51 sec]
EPOCH 1975/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05337208606524391		[learning rate: 0.0001063]
	Learning Rate: 0.000106298
	LOSS [training: 0.05337208606524391 | validation: 0.0608601358545656]
	TIME [epoch: 9.5 sec]
EPOCH 1976/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05676100524942681		[learning rate: 0.00010604]
	Learning Rate: 0.000106041
	LOSS [training: 0.05676100524942681 | validation: 0.06164152282670757]
	TIME [epoch: 9.49 sec]
EPOCH 1977/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.054045979878077056		[learning rate: 0.00010578]
	Learning Rate: 0.000105784
	LOSS [training: 0.054045979878077056 | validation: 0.04668158459828998]
	TIME [epoch: 9.5 sec]
EPOCH 1978/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.060467996957232796		[learning rate: 0.00010553]
	Learning Rate: 0.000105528
	LOSS [training: 0.060467996957232796 | validation: 0.060234296002929705]
	TIME [epoch: 9.52 sec]
EPOCH 1979/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04965956080707921		[learning rate: 0.00010527]
	Learning Rate: 0.000105273
	LOSS [training: 0.04965956080707921 | validation: 0.03829262812468014]
	TIME [epoch: 9.5 sec]
EPOCH 1980/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05209761486184043		[learning rate: 0.00010502]
	Learning Rate: 0.000105018
	LOSS [training: 0.05209761486184043 | validation: 0.04926754264461439]
	TIME [epoch: 9.5 sec]
EPOCH 1981/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.0529357909278528		[learning rate: 0.00010476]
	Learning Rate: 0.000104764
	LOSS [training: 0.0529357909278528 | validation: 0.045416567825699986]
	TIME [epoch: 9.51 sec]
EPOCH 1982/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05806422805463015		[learning rate: 0.00010451]
	Learning Rate: 0.00010451
	LOSS [training: 0.05806422805463015 | validation: 0.04655981888910171]
	TIME [epoch: 9.5 sec]
EPOCH 1983/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06296463117415606		[learning rate: 0.00010426]
	Learning Rate: 0.000104257
	LOSS [training: 0.06296463117415606 | validation: 0.051720376174703174]
	TIME [epoch: 9.5 sec]
EPOCH 1984/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06164081621666386		[learning rate: 0.000104]
	Learning Rate: 0.000104005
	LOSS [training: 0.06164081621666386 | validation: 0.048138626661540174]
	TIME [epoch: 9.5 sec]
EPOCH 1985/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05435374084721044		[learning rate: 0.00010375]
	Learning Rate: 0.000103753
	LOSS [training: 0.05435374084721044 | validation: 0.04606158681421192]
	TIME [epoch: 9.52 sec]
EPOCH 1986/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05022255784713423		[learning rate: 0.0001035]
	Learning Rate: 0.000103502
	LOSS [training: 0.05022255784713423 | validation: 0.06421702336503574]
	TIME [epoch: 9.5 sec]
EPOCH 1987/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.04631164437706367		[learning rate: 0.00010325]
	Learning Rate: 0.000103251
	LOSS [training: 0.04631164437706367 | validation: 0.041744578787431624]
	TIME [epoch: 9.5 sec]
EPOCH 1988/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05145868778361505		[learning rate: 0.000103]
	Learning Rate: 0.000103001
	LOSS [training: 0.05145868778361505 | validation: 0.03635717783099784]
	TIME [epoch: 9.51 sec]
EPOCH 1989/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053294977145802135		[learning rate: 0.00010275]
	Learning Rate: 0.000102752
	LOSS [training: 0.053294977145802135 | validation: 0.04373966757051664]
	TIME [epoch: 9.51 sec]
EPOCH 1990/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.052803188272485625		[learning rate: 0.0001025]
	Learning Rate: 0.000102503
	LOSS [training: 0.052803188272485625 | validation: 0.054659708505888895]
	TIME [epoch: 9.5 sec]
EPOCH 1991/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05531977964414603		[learning rate: 0.00010225]
	Learning Rate: 0.000102255
	LOSS [training: 0.05531977964414603 | validation: 0.050263259790471526]
	TIME [epoch: 9.5 sec]
EPOCH 1992/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05336822395670717		[learning rate: 0.00010201]
	Learning Rate: 0.000102007
	LOSS [training: 0.05336822395670717 | validation: 0.03989586786831091]
	TIME [epoch: 9.52 sec]
EPOCH 1993/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05217958626656285		[learning rate: 0.00010176]
	Learning Rate: 0.00010176
	LOSS [training: 0.05217958626656285 | validation: 0.05079523604444816]
	TIME [epoch: 9.5 sec]
EPOCH 1994/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.048202336763178		[learning rate: 0.00010151]
	Learning Rate: 0.000101514
	LOSS [training: 0.048202336763178 | validation: 0.053537731084023016]
	TIME [epoch: 9.5 sec]
EPOCH 1995/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.051968234159974716		[learning rate: 0.00010127]
	Learning Rate: 0.000101268
	LOSS [training: 0.051968234159974716 | validation: 0.059849043179934135]
	TIME [epoch: 9.51 sec]
EPOCH 1996/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.06303198991626349		[learning rate: 0.00010102]
	Learning Rate: 0.000101023
	LOSS [training: 0.06303198991626349 | validation: 0.05759923003251718]
	TIME [epoch: 9.5 sec]
EPOCH 1997/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.055320604569974584		[learning rate: 0.00010078]
	Learning Rate: 0.000100779
	LOSS [training: 0.055320604569974584 | validation: 0.04852578077950307]
	TIME [epoch: 9.5 sec]
EPOCH 1998/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.056724766581788		[learning rate: 0.00010053]
	Learning Rate: 0.000100535
	LOSS [training: 0.056724766581788 | validation: 0.05536714149798417]
	TIME [epoch: 9.5 sec]
EPOCH 1999/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.053684711843343745		[learning rate: 0.00010029]
	Learning Rate: 0.000100291
	LOSS [training: 0.053684711843343745 | validation: 0.05219495100627727]
	TIME [epoch: 9.51 sec]
EPOCH 2000/2000:
	Training over batches...
		[batch 5/5] avg loss: 0.05866988663366683		[learning rate: 0.00010005]
	Learning Rate: 0.000100048
	LOSS [training: 0.05866988663366683 | validation: 0.05172302332268178]
	TIME [epoch: 9.5 sec]
Finished training in 19162.857 seconds.
