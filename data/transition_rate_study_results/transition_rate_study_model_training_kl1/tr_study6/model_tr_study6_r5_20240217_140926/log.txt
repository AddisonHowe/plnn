Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r5', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2395782560

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.212500878886598		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.212500878886598 | validation: 8.456364219290007]
	TIME [epoch: 78.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.769282475647454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.769282475647454 | validation: 8.227098546601681]
	TIME [epoch: 9.59 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.238507120984508		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.238507120984508 | validation: 7.351000157789813]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.884693683475454		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.884693683475454 | validation: 7.647734336504838]
	TIME [epoch: 9.54 sec]
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.724370437608615		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.724370437608615 | validation: 8.962706881706222]
	TIME [epoch: 9.55 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.321320950417983		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.321320950417983 | validation: 7.248880090341045]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.62175253494492		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.62175253494492 | validation: 6.99997280666651]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.393245371429764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.393245371429764 | validation: 6.689515874206104]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.198081688951326		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.198081688951326 | validation: 6.460506435091579]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.0177683157589		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.0177683157589 | validation: 6.855412787647257]
	TIME [epoch: 9.53 sec]
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.1673468716271405		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.1673468716271405 | validation: 6.325670282284018]
	TIME [epoch: 9.56 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.465093554689297		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.465093554689297 | validation: 9.200337072731585]
	TIME [epoch: 9.52 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.369872972520005		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.369872972520005 | validation: 6.865079228864528]
	TIME [epoch: 9.53 sec]
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.9784046577940995		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9784046577940995 | validation: 5.764170325784037]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.6148198044157		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6148198044157 | validation: 7.090669649102038]
	TIME [epoch: 9.54 sec]
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.197265205524445		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.197265205524445 | validation: 6.014354220901814]
	TIME [epoch: 9.51 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.663854125476453		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.663854125476453 | validation: 6.072870356591821]
	TIME [epoch: 9.52 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.61761888430415		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.61761888430415 | validation: 6.345622290488231]
	TIME [epoch: 9.53 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.628281190897231		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.628281190897231 | validation: 6.120583339000156]
	TIME [epoch: 9.52 sec]
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.479532767938845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.479532767938845 | validation: 6.973649344444475]
	TIME [epoch: 9.52 sec]
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.258883022209567		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.258883022209567 | validation: 6.242083871625297]
	TIME [epoch: 9.52 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.581582326600987		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.581582326600987 | validation: 5.997556811356942]
	TIME [epoch: 9.54 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.48496225948121		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.48496225948121 | validation: 6.171980496705725]
	TIME [epoch: 9.52 sec]
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.726767270309051		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.726767270309051 | validation: 6.514892905112545]
	TIME [epoch: 9.52 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.69728751091408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.69728751091408 | validation: 6.005576574547181]
	TIME [epoch: 9.54 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.291102400922858		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.291102400922858 | validation: 5.8051504698115375]
	TIME [epoch: 9.52 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.431974739779328		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.431974739779328 | validation: 6.3911900695219686]
	TIME [epoch: 9.51 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.4797887024388015		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.4797887024388015 | validation: 5.7644158615107175]
	TIME [epoch: 9.51 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.231277419866764		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.231277419866764 | validation: 5.7092235924743635]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_29.pth
	Model improved!!!
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.171030673036053		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.171030673036053 | validation: 5.655121896059844]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.1941946638637395		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.1941946638637395 | validation: 6.002876085315156]
	TIME [epoch: 9.52 sec]
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.922356952484032		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.922356952484032 | validation: 6.289405629304299]
	TIME [epoch: 9.52 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.860669156030585		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.860669156030585 | validation: 6.032852586135489]
	TIME [epoch: 9.52 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.459916685736069		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.459916685736069 | validation: 6.205089049755468]
	TIME [epoch: 9.51 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.310900731519245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.310900731519245 | validation: 7.3448705764313695]
	TIME [epoch: 9.51 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.080581423128192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.080581423128192 | validation: 6.025321404009759]
	TIME [epoch: 9.54 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.168082530242493		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.168082530242493 | validation: 5.515464288382011]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_37.pth
	Model improved!!!
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.90929909364851		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.90929909364851 | validation: 5.572241221018703]
	TIME [epoch: 9.51 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.9230298844994955		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9230298844994955 | validation: 6.843876467231592]
	TIME [epoch: 9.54 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.415470367490979		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.415470367490979 | validation: 7.378682059499702]
	TIME [epoch: 9.5 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.398554431937439		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.398554431937439 | validation: 5.9927360414901205]
	TIME [epoch: 9.52 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.049338103554444		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.049338103554444 | validation: 5.56244831520085]
	TIME [epoch: 9.51 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.462236300717049		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.462236300717049 | validation: 6.382664739276346]
	TIME [epoch: 9.53 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.321032643973824		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.321032643973824 | validation: 5.477340015530024]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_44.pth
	Model improved!!!
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.114480675410748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.114480675410748 | validation: 6.659418527994298]
	TIME [epoch: 9.51 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.68566411006624		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.68566411006624 | validation: 6.0867586926120705]
	TIME [epoch: 9.52 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.153363873364191		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.153363873364191 | validation: 6.166830583498108]
	TIME [epoch: 9.5 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.9845356361585775		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9845356361585775 | validation: 5.5321763500320245]
	TIME [epoch: 9.5 sec]
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.952149320181631		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.952149320181631 | validation: 5.638363046714253]
	TIME [epoch: 9.5 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.12730298304748		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.12730298304748 | validation: 5.645343291995093]
	TIME [epoch: 9.51 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.673539455601639		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 5.673539455601639 | validation: 5.281113380344964]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_51.pth
	Model improved!!!
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.5088513464290045		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 6.5088513464290045 | validation: 7.021205270413487]
	TIME [epoch: 9.5 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.812393245628367		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 6.812393245628367 | validation: 5.105224276895423]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.557113342785698		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 5.557113342785698 | validation: 4.693164578942464]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_54.pth
	Model improved!!!
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.254719642785831		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 5.254719642785831 | validation: 4.641861510116638]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_55.pth
	Model improved!!!
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.159665508438961		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 5.159665508438961 | validation: 4.495696937381959]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.305858765450134		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 5.305858765450134 | validation: 5.233603562545828]
	TIME [epoch: 9.52 sec]
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.0875968023301015		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 5.0875968023301015 | validation: 4.525237265851372]
	TIME [epoch: 9.51 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.780061572677623		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 5.780061572677623 | validation: 5.864268585047165]
	TIME [epoch: 9.5 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.950345870712556		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 5.950345870712556 | validation: 6.513119458372546]
	TIME [epoch: 9.53 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.885861847603258		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 5.885861847603258 | validation: 4.775902498417288]
	TIME [epoch: 9.51 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.384389136830428		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 5.384389136830428 | validation: 5.161681765417693]
	TIME [epoch: 9.5 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.244022153911893		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 5.244022153911893 | validation: 4.841227967380367]
	TIME [epoch: 9.53 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.198812618061163		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 5.198812618061163 | validation: 4.435249540309605]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.874155141566201		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 4.874155141566201 | validation: 4.358190349280009]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_65.pth
	Model improved!!!
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.323304503994725		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 5.323304503994725 | validation: 4.637506453923331]
	TIME [epoch: 9.53 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.092693928080403		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 5.092693928080403 | validation: 4.629778595436034]
	TIME [epoch: 9.54 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.225281694287142		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 5.225281694287142 | validation: 6.310050249749386]
	TIME [epoch: 9.5 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.63593057445898		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 6.63593057445898 | validation: 5.708416300728715]
	TIME [epoch: 9.51 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.699562417196658		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 5.699562417196658 | validation: 5.60976649599723]
	TIME [epoch: 9.53 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.608055944759117		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 5.608055944759117 | validation: 4.722473114227842]
	TIME [epoch: 9.51 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.166611778598247		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 5.166611778598247 | validation: 4.971490818382139]
	TIME [epoch: 9.52 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.236208872919677		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 5.236208872919677 | validation: 4.485901475149396]
	TIME [epoch: 9.51 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.270837960293905		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 5.270837960293905 | validation: 6.546754897761039]
	TIME [epoch: 9.53 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.390579012629909		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 6.390579012629909 | validation: 5.584158428068248]
	TIME [epoch: 9.51 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.259079164939128		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 5.259079164939128 | validation: 3.783538084251525]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_76.pth
	Model improved!!!
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.414135650532662		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 4.414135650532662 | validation: 4.991078085985732]
	TIME [epoch: 9.53 sec]
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.9655746336006885		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 4.9655746336006885 | validation: 4.017632718480707]
	TIME [epoch: 9.51 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.306694956180796		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 4.306694956180796 | validation: 3.5927623935686506]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.677994254023124		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 4.677994254023124 | validation: 3.9426542257584027]
	TIME [epoch: 9.51 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.406008456922017		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 4.406008456922017 | validation: 3.69071124853514]
	TIME [epoch: 9.53 sec]
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.4889355712244505		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 4.4889355712244505 | validation: 4.196940983251397]
	TIME [epoch: 9.51 sec]
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.254485486027782		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 4.254485486027782 | validation: 3.399081905674448]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_83.pth
	Model improved!!!
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.160231851927429		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 4.160231851927429 | validation: 3.7680743065645483]
	TIME [epoch: 9.53 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.158097516354895		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 4.158097516354895 | validation: 3.4320728327798538]
	TIME [epoch: 9.52 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.097199166927159		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 4.097199166927159 | validation: 3.362716894812197]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_86.pth
	Model improved!!!
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.086116531140293		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 4.086116531140293 | validation: 3.317101081647163]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_87.pth
	Model improved!!!
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.103445413634736		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 4.103445413634736 | validation: 3.33853833130748]
	TIME [epoch: 9.54 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.136519493614776		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 4.136519493614776 | validation: 3.871378566369509]
	TIME [epoch: 9.5 sec]
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.166390918300851		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 4.166390918300851 | validation: 3.741251924032434]
	TIME [epoch: 9.51 sec]
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.34128952657274		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 4.34128952657274 | validation: 3.495102794082432]
	TIME [epoch: 9.54 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.010262921690982		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 4.010262921690982 | validation: 3.5432983491130585]
	TIME [epoch: 9.51 sec]
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9239918758820935		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 3.9239918758820935 | validation: 3.459044704418157]
	TIME [epoch: 9.51 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.137067223386121		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 4.137067223386121 | validation: 7.15122800267597]
	TIME [epoch: 9.52 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.743061464933453		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 4.743061464933453 | validation: 3.809357689285522]
	TIME [epoch: 9.54 sec]
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.522936537382882		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 4.522936537382882 | validation: 3.5597782655912846]
	TIME [epoch: 9.52 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.1008804852557175		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 4.1008804852557175 | validation: 3.417230755785979]
	TIME [epoch: 9.51 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.889081997496129		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 3.889081997496129 | validation: 4.558272455609993]
	TIME [epoch: 9.54 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.031367979160446		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 4.031367979160446 | validation: 3.4073969546431075]
	TIME [epoch: 9.51 sec]
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.058174313727342		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 4.058174313727342 | validation: 4.088165966378002]
	TIME [epoch: 9.5 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.016657194239096		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 4.016657194239096 | validation: 3.3554759590944543]
	TIME [epoch: 9.52 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8962183848139467		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 3.8962183848139467 | validation: 3.320351342656299]
	TIME [epoch: 9.53 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.076559494633877		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 4.076559494633877 | validation: 5.254751360702476]
	TIME [epoch: 9.51 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.174467722707595		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 4.174467722707595 | validation: 3.141471746187442]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_104.pth
	Model improved!!!
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9618725514286184		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 3.9618725514286184 | validation: 3.1713613040187285]
	TIME [epoch: 9.54 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.814474203002535		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 3.814474203002535 | validation: 3.115203342728429]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_106.pth
	Model improved!!!
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8660492217695372		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 3.8660492217695372 | validation: 3.397254207415127]
	TIME [epoch: 9.51 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.016154868614756		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 4.016154868614756 | validation: 3.2384917587613153]
	TIME [epoch: 9.52 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8512749417237444		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 3.8512749417237444 | validation: 3.133988493315944]
	TIME [epoch: 9.54 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8265670018735185		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 3.8265670018735185 | validation: 3.3044346933336977]
	TIME [epoch: 9.52 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8771872402362013		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 3.8771872402362013 | validation: 3.1027903382274857]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_111.pth
	Model improved!!!
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8345183334636253		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 3.8345183334636253 | validation: 3.3852280157710033]
	TIME [epoch: 9.54 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.847639138101529		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 3.847639138101529 | validation: 3.3319505365881894]
	TIME [epoch: 9.52 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8631430635213713		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 3.8631430635213713 | validation: 3.2916614071831156]
	TIME [epoch: 9.51 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.862327472327986		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 3.862327472327986 | validation: 3.287743828470998]
	TIME [epoch: 9.52 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8677472338581835		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 3.8677472338581835 | validation: 3.2412475644162937]
	TIME [epoch: 9.51 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.830670162843839		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 3.830670162843839 | validation: 3.293216404672005]
	TIME [epoch: 9.51 sec]
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8912298149148143		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 3.8912298149148143 | validation: 3.1655445615982134]
	TIME [epoch: 9.51 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.955892166236899		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 3.955892166236899 | validation: 3.2790435211789464]
	TIME [epoch: 9.54 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.836250749520692		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 3.836250749520692 | validation: 3.412828433233296]
	TIME [epoch: 9.5 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.90617718241563		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 3.90617718241563 | validation: 3.4644702646199717]
	TIME [epoch: 9.52 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9302022797372134		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 3.9302022797372134 | validation: 3.3570708092194823]
	TIME [epoch: 9.54 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.891054334893461		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 3.891054334893461 | validation: 3.1544370614656887]
	TIME [epoch: 9.52 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8989530832865684		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 3.8989530832865684 | validation: 3.294147754094717]
	TIME [epoch: 9.5 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.758762455419712		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 3.758762455419712 | validation: 3.2940269520557273]
	TIME [epoch: 9.51 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8110644489090917		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 3.8110644489090917 | validation: 3.3409894426625115]
	TIME [epoch: 9.54 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.852175073713256		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 3.852175073713256 | validation: 3.327485770192559]
	TIME [epoch: 9.51 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.747519404623877		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 3.747519404623877 | validation: 3.077432751263748]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_128.pth
	Model improved!!!
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.761941057651189		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 3.761941057651189 | validation: 3.1199118570626045]
	TIME [epoch: 9.52 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.540326487864215		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 4.540326487864215 | validation: 7.071170367191167]
	TIME [epoch: 9.53 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.844113233741071		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 4.844113233741071 | validation: 3.159034633978546]
	TIME [epoch: 9.53 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.796869898151347		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 3.796869898151347 | validation: 3.199591036705354]
	TIME [epoch: 9.51 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8385480985920695		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 3.8385480985920695 | validation: 3.1195036507411222]
	TIME [epoch: 9.54 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.780064914256478		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 3.780064914256478 | validation: 3.720273821689453]
	TIME [epoch: 9.53 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8903228401165357		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 3.8903228401165357 | validation: 3.2760387203790096]
	TIME [epoch: 9.52 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0626909830685545		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 4.0626909830685545 | validation: 3.206816177327015]
	TIME [epoch: 9.54 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7636849320402206		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 3.7636849320402206 | validation: 3.0605474230840417]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_137.pth
	Model improved!!!
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.727945241170759		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 3.727945241170759 | validation: 4.354588176863635]
	TIME [epoch: 9.52 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.881903678417254		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 3.881903678417254 | validation: 3.109617650113506]
	TIME [epoch: 9.52 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.752918738016349		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 3.752918738016349 | validation: 3.132597895614523]
	TIME [epoch: 9.54 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.76278044139512		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 3.76278044139512 | validation: 3.2258394062175393]
	TIME [epoch: 9.52 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8262934765969936		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 3.8262934765969936 | validation: 3.967518501004495]
	TIME [epoch: 9.51 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8666165052598855		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 3.8666165052598855 | validation: 3.0618618997762876]
	TIME [epoch: 9.53 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.690740502695357		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 3.690740502695357 | validation: 3.573098597925104]
	TIME [epoch: 9.52 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7873542972106846		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 3.7873542972106846 | validation: 3.2768736159985905]
	TIME [epoch: 9.51 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7330009421353565		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 3.7330009421353565 | validation: 3.160703278573927]
	TIME [epoch: 9.51 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.752672317124083		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 3.752672317124083 | validation: 3.7014488044964176]
	TIME [epoch: 9.54 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9083796132115163		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 3.9083796132115163 | validation: 3.051556856617635]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_148.pth
	Model improved!!!
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.559902316961724		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 3.559902316961724 | validation: 3.1288924545034735]
	TIME [epoch: 9.51 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.575178039215036		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 3.575178039215036 | validation: 3.057512524529437]
	TIME [epoch: 9.53 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.63330656364152		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 3.63330656364152 | validation: 3.048333589588616]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_151.pth
	Model improved!!!
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.133032006530556		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 4.133032006530556 | validation: 3.3127867027415756]
	TIME [epoch: 9.51 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6761611035176904		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 3.6761611035176904 | validation: 3.0475010711110544]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_153.pth
	Model improved!!!
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6920834472434074		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 3.6920834472434074 | validation: 3.3154156405861683]
	TIME [epoch: 9.55 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6414289720607584		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 3.6414289720607584 | validation: 3.1115492507714606]
	TIME [epoch: 9.52 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3944427375482653		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 3.3944427375482653 | validation: 3.3411651051012505]
	TIME [epoch: 9.51 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5588492824275617		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 3.5588492824275617 | validation: 3.940180042092303]
	TIME [epoch: 9.53 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.770172140518842		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 5.770172140518842 | validation: 5.413854127516578]
	TIME [epoch: 9.51 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.574342766622526		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 4.574342766622526 | validation: 3.1148203782346697]
	TIME [epoch: 9.52 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.656389192016916		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 3.656389192016916 | validation: 3.1216352949159387]
	TIME [epoch: 9.51 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7403248456385882		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 3.7403248456385882 | validation: 4.04658382908488]
	TIME [epoch: 9.55 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.803394438122844		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 4.803394438122844 | validation: 3.8907738130503304]
	TIME [epoch: 9.51 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.776276049083168		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 3.776276049083168 | validation: 3.1717237269382874]
	TIME [epoch: 9.52 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5072265157120013		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 3.5072265157120013 | validation: 3.4183260592726845]
	TIME [epoch: 9.54 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.273342555547328		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 4.273342555547328 | validation: 3.8915619135215924]
	TIME [epoch: 9.52 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.216388632472293		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 5.216388632472293 | validation: 4.880360291541296]
	TIME [epoch: 9.51 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.8199912602019666		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 5.8199912602019666 | validation: 4.172812022149672]
	TIME [epoch: 9.51 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.7166900243356435		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 4.7166900243356435 | validation: 3.8513511327985186]
	TIME [epoch: 9.53 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.186063260806955		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 4.186063260806955 | validation: 3.3594376288326613]
	TIME [epoch: 9.52 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9529683852679165		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 3.9529683852679165 | validation: 3.151412310285563]
	TIME [epoch: 9.52 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8066147450668915		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 3.8066147450668915 | validation: 4.09540642055099]
	TIME [epoch: 9.54 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.169476976717288		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 4.169476976717288 | validation: 3.327265161528782]
	TIME [epoch: 9.51 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7764415002555993		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 3.7764415002555993 | validation: 3.1816862401681156]
	TIME [epoch: 9.51 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5656058468336163		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 3.5656058468336163 | validation: 3.4575708666674165]
	TIME [epoch: 9.5 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7812416466079513		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 3.7812416466079513 | validation: 3.2817447508551245]
	TIME [epoch: 9.53 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.690334739356236		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 4.690334739356236 | validation: 5.796118816022507]
	TIME [epoch: 9.5 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.848881685730374		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 6.848881685730374 | validation: 6.234194460771472]
	TIME [epoch: 9.5 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.184564237170938		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 5.184564237170938 | validation: 3.9593623977329333]
	TIME [epoch: 9.53 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.222575084681702		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 4.222575084681702 | validation: 3.6481126047204397]
	TIME [epoch: 9.51 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.00133335841384		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 4.00133335841384 | validation: 3.287153701862158]
	TIME [epoch: 9.5 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.025015874428892		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 4.025015874428892 | validation: 3.2846679532285394]
	TIME [epoch: 9.51 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.958288496065279		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 3.958288496065279 | validation: 3.1806713153223916]
	TIME [epoch: 9.53 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.772180053649648		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 3.772180053649648 | validation: 3.253220964510674]
	TIME [epoch: 9.51 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.958764199692328		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 3.958764199692328 | validation: 3.3591829116486243]
	TIME [epoch: 9.51 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8047352931896015		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 3.8047352931896015 | validation: 3.0875126695672215]
	TIME [epoch: 9.53 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7837709931561436		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 3.7837709931561436 | validation: 3.3687454705312874]
	TIME [epoch: 9.51 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.840696072987787		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 3.840696072987787 | validation: 4.07931383780423]
	TIME [epoch: 9.5 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.95902451976194		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 4.95902451976194 | validation: 4.522623814544091]
	TIME [epoch: 9.5 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.041086864575488		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 5.041086864575488 | validation: 4.3134199545110485]
	TIME [epoch: 9.53 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.534020637410558		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 4.534020637410558 | validation: 3.636468585631939]
	TIME [epoch: 9.5 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9577703439541		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 3.9577703439541 | validation: 3.449525750148412]
	TIME [epoch: 9.51 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.926310934447224		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 3.926310934447224 | validation: 3.8221152869841455]
	TIME [epoch: 9.52 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8005984469422387		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 3.8005984469422387 | validation: 3.7334981627975545]
	TIME [epoch: 9.51 sec]
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.186608502565917		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 4.186608502565917 | validation: 3.628983576646923]
	TIME [epoch: 9.51 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.060030506323741		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 4.060030506323741 | validation: 3.4151049777307754]
	TIME [epoch: 9.52 sec]
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.1519164803503275		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 4.1519164803503275 | validation: 3.4969958849143405]
	TIME [epoch: 9.52 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.075800382278771		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 4.075800382278771 | validation: 3.527995729537431]
	TIME [epoch: 9.51 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9178197045529046		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 3.9178197045529046 | validation: 3.312073928251991]
	TIME [epoch: 9.51 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0064363724506915		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 4.0064363724506915 | validation: 4.265813378582273]
	TIME [epoch: 9.53 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.414063934616594		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 5.414063934616594 | validation: 5.577313089730987]
	TIME [epoch: 9.51 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.6818976008725555		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 5.6818976008725555 | validation: 4.542254340560355]
	TIME [epoch: 9.51 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.39690482673975		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 4.39690482673975 | validation: 3.3684989287702765]
	TIME [epoch: 9.52 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7893746239046755		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 3.7893746239046755 | validation: 3.3884458513331364]
	TIME [epoch: 9.52 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.680257908269957		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 3.680257908269957 | validation: 3.1760276543027555]
	TIME [epoch: 9.5 sec]
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6517125965461985		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 3.6517125965461985 | validation: 3.6841507783531844]
	TIME [epoch: 9.51 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.736024458132816		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 4.736024458132816 | validation: 3.726667402591896]
	TIME [epoch: 9.53 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.044239907541477		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 4.044239907541477 | validation: 3.2730784280618423]
	TIME [epoch: 9.51 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9735601818096535		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 3.9735601818096535 | validation: 3.30662939222791]
	TIME [epoch: 9.51 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9327930503434727		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 3.9327930503434727 | validation: 3.1979066201490167]
	TIME [epoch: 9.51 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9804067515488426		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 3.9804067515488426 | validation: 3.4135778776820263]
	TIME [epoch: 9.53 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8326291088654876		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 3.8326291088654876 | validation: 3.358869374457005]
	TIME [epoch: 9.51 sec]
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.776527059501209		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 3.776527059501209 | validation: 3.627751447256999]
	TIME [epoch: 9.5 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.018086054683563		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 4.018086054683563 | validation: 3.4030252932981013]
	TIME [epoch: 9.53 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9210251949458197		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 3.9210251949458197 | validation: 3.4407018910289184]
	TIME [epoch: 9.51 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8887292406934955		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 3.8887292406934955 | validation: 3.1795736227758447]
	TIME [epoch: 9.5 sec]
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.026951542514864		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 4.026951542514864 | validation: 3.2785177372946572]
	TIME [epoch: 9.51 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.058084300761118		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 4.058084300761118 | validation: 3.449555083860616]
	TIME [epoch: 9.52 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.000739567889616		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 4.000739567889616 | validation: 3.4226036566736586]
	TIME [epoch: 9.51 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.245204216264111		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 4.245204216264111 | validation: 3.498966322486939]
	TIME [epoch: 9.51 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.088835983521749		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 4.088835983521749 | validation: 3.4658621211040965]
	TIME [epoch: 9.54 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.191439219541374		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 4.191439219541374 | validation: 3.3585254205931263]
	TIME [epoch: 9.51 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0556353995362056		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 4.0556353995362056 | validation: 3.312936017508523]
	TIME [epoch: 9.5 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.012398112698249		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 4.012398112698249 | validation: 3.301338058239852]
	TIME [epoch: 9.52 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.021191427199184		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 4.021191427199184 | validation: 3.2566715370171595]
	TIME [epoch: 9.52 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.053762068548532		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 4.053762068548532 | validation: 3.4367656003708213]
	TIME [epoch: 9.51 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.689135231452553		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 4.689135231452553 | validation: 3.319285139100964]
	TIME [epoch: 9.51 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9415849572518056		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 3.9415849572518056 | validation: 3.2934695510727807]
	TIME [epoch: 9.53 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.019181018156766		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 4.019181018156766 | validation: 3.4838321595091153]
	TIME [epoch: 9.52 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.00049414652729		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 4.00049414652729 | validation: 3.2137875407345997]
	TIME [epoch: 9.51 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8953939406356737		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 3.8953939406356737 | validation: 3.4743775250910263]
	TIME [epoch: 9.51 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.956500493535026		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 3.956500493535026 | validation: 3.1772162040962817]
	TIME [epoch: 9.52 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.002939977559133		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 4.002939977559133 | validation: 3.457063217820273]
	TIME [epoch: 9.5 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9982502418980914		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 3.9982502418980914 | validation: 3.2380978652622274]
	TIME [epoch: 9.5 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.998141266776151		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 3.998141266776151 | validation: 3.159125522293952]
	TIME [epoch: 9.52 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9674916055008014		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 3.9674916055008014 | validation: 3.343717245179491]
	TIME [epoch: 9.51 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.993405426928144		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 3.993405426928144 | validation: 3.5101994346862133]
	TIME [epoch: 9.51 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.013991395007241		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 4.013991395007241 | validation: 3.230572370873651]
	TIME [epoch: 9.51 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9981556100844857		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 3.9981556100844857 | validation: 3.200862130295849]
	TIME [epoch: 9.52 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.1676356372004655		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 4.1676356372004655 | validation: 3.341473440550599]
	TIME [epoch: 9.5 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.004152501140092		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 4.004152501140092 | validation: 3.2850735320324373]
	TIME [epoch: 9.52 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.252973591747878		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 4.252973591747878 | validation: 3.872048465806753]
	TIME [epoch: 9.53 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.167358011872328		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 4.167358011872328 | validation: 3.3669238410352818]
	TIME [epoch: 9.51 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.946152330327614		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 3.946152330327614 | validation: 3.307216150839948]
	TIME [epoch: 9.49 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9483722283670653		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 3.9483722283670653 | validation: 3.244752942273142]
	TIME [epoch: 9.51 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9333997909792613		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 3.9333997909792613 | validation: 3.3267692264328788]
	TIME [epoch: 9.52 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.963396337557497		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 3.963396337557497 | validation: 3.2036971392848943]
	TIME [epoch: 9.51 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.990099387125672		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 3.990099387125672 | validation: 3.1859243931908856]
	TIME [epoch: 9.51 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9577316910538096		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 3.9577316910538096 | validation: 3.3033268651005536]
	TIME [epoch: 9.53 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.932210902074413		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 3.932210902074413 | validation: 3.5794053955761194]
	TIME [epoch: 9.5 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.022861470086705		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 4.022861470086705 | validation: 3.318418547663948]
	TIME [epoch: 9.51 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.969686985177303		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 3.969686985177303 | validation: 3.080372275004996]
	TIME [epoch: 9.53 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7142149964279456		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 3.7142149964279456 | validation: 2.946315111525521]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_252.pth
	Model improved!!!
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.666804625128472		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 3.666804625128472 | validation: 3.0115789944157307]
	TIME [epoch: 9.51 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.664683702579179		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 3.664683702579179 | validation: 2.9099330741544187]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_254.pth
	Model improved!!!
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5657154815022225		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 3.5657154815022225 | validation: 2.965650065568901]
	TIME [epoch: 9.54 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5878110822857168		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 3.5878110822857168 | validation: 2.9521370082504426]
	TIME [epoch: 9.51 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5350013972904533		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 3.5350013972904533 | validation: 3.0068556103733557]
	TIME [epoch: 9.51 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6297044499912374		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 3.6297044499912374 | validation: 3.216756650647624]
	TIME [epoch: 9.52 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.642740017083734		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 3.642740017083734 | validation: 3.3177285604745372]
	TIME [epoch: 9.53 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.317351249658799		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 4.317351249658799 | validation: 3.882707401919098]
	TIME [epoch: 9.52 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.762411980305442		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 4.762411980305442 | validation: 3.337890783561064]
	TIME [epoch: 9.5 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.928895527997709		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 3.928895527997709 | validation: 2.9980967434730723]
	TIME [epoch: 9.54 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.772846126425854		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 3.772846126425854 | validation: 3.371886526551255]
	TIME [epoch: 9.51 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.888443110411911		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 3.888443110411911 | validation: 2.9768081378958944]
	TIME [epoch: 9.51 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6514249799685485		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 3.6514249799685485 | validation: 2.8925686007787634]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_265.pth
	Model improved!!!
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.796118419969222		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 3.796118419969222 | validation: 3.125841578899401]
	TIME [epoch: 9.53 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6595874835411806		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 3.6595874835411806 | validation: 2.9736314753813575]
	TIME [epoch: 9.52 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4402380506585812		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 3.4402380506585812 | validation: 2.809706460826279]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_268.pth
	Model improved!!!
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.425117345751404		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 3.425117345751404 | validation: 3.11600874987626]
	TIME [epoch: 9.54 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6205177286595935		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 3.6205177286595935 | validation: 2.934743179152174]
	TIME [epoch: 9.5 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3432835107680807		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 3.3432835107680807 | validation: 2.794447524050899]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_271.pth
	Model improved!!!
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4732099494416224		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 3.4732099494416224 | validation: 2.8863494138615295]
	TIME [epoch: 9.84 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3982160715371066		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 3.3982160715371066 | validation: 2.9334412831187424]
	TIME [epoch: 9.51 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.326069076073444		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 3.326069076073444 | validation: 2.995131550668609]
	TIME [epoch: 9.51 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.218574281449535		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 3.218574281449535 | validation: 2.862811027002937]
	TIME [epoch: 9.5 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.820789105843631		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 3.820789105843631 | validation: 3.1807397416449983]
	TIME [epoch: 9.52 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8966430647526975		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 3.8966430647526975 | validation: 2.9925711117168676]
	TIME [epoch: 9.53 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.367969107539102		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 3.367969107539102 | validation: 3.1724729441992987]
	TIME [epoch: 9.5 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2403884620361523		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 3.2403884620361523 | validation: 2.7729300646438664]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_279.pth
	Model improved!!!
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3757566643759973		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 3.3757566643759973 | validation: 3.310280806533925]
	TIME [epoch: 9.51 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3525201598798704		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 3.3525201598798704 | validation: 3.0264518213797]
	TIME [epoch: 9.5 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.609444487695226		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 3.609444487695226 | validation: 3.6771454676989515]
	TIME [epoch: 9.5 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.696045072533115		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 3.696045072533115 | validation: 2.705048512788746]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_283.pth
	Model improved!!!
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.951945628825526		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 2.951945628825526 | validation: 2.729179098100651]
	TIME [epoch: 9.51 sec]
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9941665702617373		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 2.9941665702617373 | validation: 2.828679166743657]
	TIME [epoch: 9.5 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.112636660169997		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 3.112636660169997 | validation: 2.9810593616884717]
	TIME [epoch: 9.53 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4023352915077916		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 3.4023352915077916 | validation: 2.8109190086347016]
	TIME [epoch: 9.51 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3569754861071983		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 3.3569754861071983 | validation: 2.8626391923559686]
	TIME [epoch: 9.5 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1032431270614236		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 3.1032431270614236 | validation: 3.5246429096193688]
	TIME [epoch: 9.5 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.156141157288305		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 4.156141157288305 | validation: 3.1669742051662775]
	TIME [epoch: 9.53 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0644195170027873		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 3.0644195170027873 | validation: 2.5837877408438397]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_291.pth
	Model improved!!!
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9491166242744598		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 2.9491166242744598 | validation: 3.0111768509267494]
	TIME [epoch: 9.49 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.439090663808483		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 3.439090663808483 | validation: 3.5493786129231344]
	TIME [epoch: 9.52 sec]
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.533418988702607		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 3.533418988702607 | validation: 2.870412311535097]
	TIME [epoch: 9.51 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.92530037177702		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 2.92530037177702 | validation: 3.002692149814732]
	TIME [epoch: 9.5 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.137272520595915		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 3.137272520595915 | validation: 2.8465540991150284]
	TIME [epoch: 9.51 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.187959678025619		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 3.187959678025619 | validation: 3.3173592765457487]
	TIME [epoch: 9.53 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.638093573334119		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 3.638093573334119 | validation: 3.1142744266998976]
	TIME [epoch: 9.51 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.505923944671897		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 3.505923944671897 | validation: 2.8803309907757666]
	TIME [epoch: 9.5 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.268583314222107		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 3.268583314222107 | validation: 2.6966087400077208]
	TIME [epoch: 9.53 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0857070220260967		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 3.0857070220260967 | validation: 2.638770221416099]
	TIME [epoch: 9.51 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0777588035588406		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 3.0777588035588406 | validation: 2.6080443167118488]
	TIME [epoch: 9.5 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.991065416099424		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 2.991065416099424 | validation: 2.7157778115598545]
	TIME [epoch: 9.5 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.409129276261806		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 3.409129276261806 | validation: 2.9178819133754645]
	TIME [epoch: 9.52 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3046545004595793		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 3.3046545004595793 | validation: 2.8901923578492985]
	TIME [epoch: 9.5 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2492864607678826		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 3.2492864607678826 | validation: 2.7401200928859186]
	TIME [epoch: 9.5 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2872448951717717		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 3.2872448951717717 | validation: 2.7483175964823876]
	TIME [epoch: 9.53 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0851008125103023		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 3.0851008125103023 | validation: 2.7410491770494025]
	TIME [epoch: 9.51 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9496662064928634		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 2.9496662064928634 | validation: 2.58121692927601]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_309.pth
	Model improved!!!
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8874964962831173		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 2.8874964962831173 | validation: 2.984478094861909]
	TIME [epoch: 9.51 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1607458595938036		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 3.1607458595938036 | validation: 2.635365187099937]
	TIME [epoch: 9.52 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.870109154251268		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 2.870109154251268 | validation: 2.9110143876141197]
	TIME [epoch: 9.5 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.035784531470162		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 3.035784531470162 | validation: 2.6043802660842688]
	TIME [epoch: 9.5 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7884892774273644		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 2.7884892774273644 | validation: 2.8242047527492047]
	TIME [epoch: 9.52 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7608090311164393		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 2.7608090311164393 | validation: 2.585859912021767]
	TIME [epoch: 9.5 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0056986579312777		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 3.0056986579312777 | validation: 2.8153595371322884]
	TIME [epoch: 9.51 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1696503464223698		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 3.1696503464223698 | validation: 2.702285778567362]
	TIME [epoch: 9.51 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.000891435889739		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 3.000891435889739 | validation: 2.5495285425845142]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_318.pth
	Model improved!!!
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7015673644067513		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 2.7015673644067513 | validation: 2.4894399052053666]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_319.pth
	Model improved!!!
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.689364731292109		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 2.689364731292109 | validation: 2.3820782147269033]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_320.pth
	Model improved!!!
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5861276052010815		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 2.5861276052010815 | validation: 2.5835408781486797]
	TIME [epoch: 9.53 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5641940787520716		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 2.5641940787520716 | validation: 2.4068458924243665]
	TIME [epoch: 9.52 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.653026883846355		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 2.653026883846355 | validation: 2.5176429366732993]
	TIME [epoch: 9.51 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6183196736099807		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 2.6183196736099807 | validation: 2.2563501754477064]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_324.pth
	Model improved!!!
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4821919205227303		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 2.4821919205227303 | validation: 2.3917565461785797]
	TIME [epoch: 9.52 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.577567556704629		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 2.577567556704629 | validation: 2.612146873525335]
	TIME [epoch: 9.5 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.679297554635344		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 2.679297554635344 | validation: 2.4711588848927764]
	TIME [epoch: 9.5 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6975306559185084		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 2.6975306559185084 | validation: 2.7175905709678343]
	TIME [epoch: 9.54 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.457821120366927		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 2.457821120366927 | validation: 2.552565722852597]
	TIME [epoch: 9.51 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.472179517549074		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 2.472179517549074 | validation: 2.3654340258241224]
	TIME [epoch: 9.51 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2286030582475767		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 2.2286030582475767 | validation: 2.17338104783383]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_331.pth
	Model improved!!!
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.186148298684177		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 2.186148298684177 | validation: 2.06027696114302]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_332.pth
	Model improved!!!
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3635193540737767		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 2.3635193540737767 | validation: 2.353946490139783]
	TIME [epoch: 9.53 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.30200152438319		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 2.30200152438319 | validation: 2.0873492809430103]
	TIME [epoch: 9.51 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.1077910446791868		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 2.1077910446791868 | validation: 1.948718087889966]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_335.pth
	Model improved!!!
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.9820972325780477		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 1.9820972325780477 | validation: 1.9742675810049775]
	TIME [epoch: 9.52 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8935173025939942		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 1.8935173025939942 | validation: 1.9255018232167118]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_337.pth
	Model improved!!!
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7890003165415966		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 1.7890003165415966 | validation: 1.7442693441113364]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_338.pth
	Model improved!!!
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.8237372790047495		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 1.8237372790047495 | validation: 1.6885724482516213]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_339.pth
	Model improved!!!
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.82903185869849		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 1.82903185869849 | validation: 1.716838647416998]
	TIME [epoch: 9.52 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6524765319454187		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 1.6524765319454187 | validation: 1.57229112309196]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_341.pth
	Model improved!!!
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.6153319340044363		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 1.6153319340044363 | validation: 2.216847638289624]
	TIME [epoch: 9.54 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.7726080711761483		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 1.7726080711761483 | validation: 1.6740135147105324]
	TIME [epoch: 9.52 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5776908968699819		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 1.5776908968699819 | validation: 1.568534491201715]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_344.pth
	Model improved!!!
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.600107002780105		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 1.600107002780105 | validation: 1.7762421743514063]
	TIME [epoch: 9.54 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.5868469661624451		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 1.5868469661624451 | validation: 1.7075796724543149]
	TIME [epoch: 9.53 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.454608776292337		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 1.454608776292337 | validation: 1.4037416210782068]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_347.pth
	Model improved!!!
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4809470559874403		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 1.4809470559874403 | validation: 2.004340336057793]
	TIME [epoch: 9.52 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.550879915782183		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 1.550879915782183 | validation: 1.4033780870633894]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_349.pth
	Model improved!!!
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3670695635523904		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 1.3670695635523904 | validation: 1.4108039382921056]
	TIME [epoch: 9.51 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4674273606549988		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 1.4674273606549988 | validation: 1.373492782014936]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_351.pth
	Model improved!!!
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3873459903128793		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 1.3873459903128793 | validation: 1.8169800322313132]
	TIME [epoch: 9.53 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3526322171615326		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 1.3526322171615326 | validation: 1.340415703767199]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_353.pth
	Model improved!!!
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3832115129944935		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 1.3832115129944935 | validation: 1.4530681180137726]
	TIME [epoch: 9.5 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3770761039314119		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 1.3770761039314119 | validation: 1.418644537835189]
	TIME [epoch: 9.51 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2461739522185433		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 1.2461739522185433 | validation: 1.3069938538200392]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_356.pth
	Model improved!!!
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3749298994673687		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 1.3749298994673687 | validation: 1.3807737227257784]
	TIME [epoch: 9.51 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3124457155965792		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 1.3124457155965792 | validation: 1.3915676141315225]
	TIME [epoch: 9.51 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.299959668669768		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 1.299959668669768 | validation: 1.2192355663906755]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_359.pth
	Model improved!!!
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3055337185078544		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 1.3055337185078544 | validation: 1.4809688053779275]
	TIME [epoch: 9.52 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2568881053967682		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 1.2568881053967682 | validation: 1.4549428355356862]
	TIME [epoch: 9.51 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3087357804375732		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 1.3087357804375732 | validation: 1.5832854052661927]
	TIME [epoch: 9.53 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3101881741677353		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 1.3101881741677353 | validation: 1.4720335057715612]
	TIME [epoch: 9.52 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4173644542674495		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 1.4173644542674495 | validation: 1.439699287891354]
	TIME [epoch: 9.53 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3399999171845134		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 1.3399999171845134 | validation: 1.2578602359770679]
	TIME [epoch: 9.5 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3313589184995558		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 1.3313589184995558 | validation: 1.6807464720282792]
	TIME [epoch: 9.55 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.304285027491738		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 1.304285027491738 | validation: 1.3888145310559121]
	TIME [epoch: 9.52 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2640558299153082		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 1.2640558299153082 | validation: 1.420081864555791]
	TIME [epoch: 9.51 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2637535340579786		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 1.2637535340579786 | validation: 1.6322600508409124]
	TIME [epoch: 9.53 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.286285361868814		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 1.286285361868814 | validation: 1.6285663927467366]
	TIME [epoch: 9.51 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.589661862205372		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 1.589661862205372 | validation: 1.3784324533120225]
	TIME [epoch: 9.51 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1936486600030425		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 1.1936486600030425 | validation: 1.2314193125972688]
	TIME [epoch: 9.51 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2891222404516993		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 1.2891222404516993 | validation: 1.1906055981585772]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_373.pth
	Model improved!!!
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.268441960140586		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 1.268441960140586 | validation: 1.1875588832326274]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_374.pth
	Model improved!!!
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3317653888619634		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 1.3317653888619634 | validation: 1.183902583932846]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_375.pth
	Model improved!!!
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.222917029735984		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 1.222917029735984 | validation: 1.5134799402606944]
	TIME [epoch: 9.53 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2960759893322524		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 1.2960759893322524 | validation: 1.7394595532042645]
	TIME [epoch: 9.53 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3923483372440164		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 1.3923483372440164 | validation: 1.3881338568064354]
	TIME [epoch: 9.52 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2464684524911451		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 1.2464684524911451 | validation: 1.3888989429863292]
	TIME [epoch: 9.52 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2705985068717776		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 1.2705985068717776 | validation: 1.2023109614574838]
	TIME [epoch: 9.85 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2255617065490472		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 1.2255617065490472 | validation: 1.376441460140045]
	TIME [epoch: 9.51 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2169009400671702		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 1.2169009400671702 | validation: 1.836153409490775]
	TIME [epoch: 9.51 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3245370901009743		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 1.3245370901009743 | validation: 1.3539519804243316]
	TIME [epoch: 9.53 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.454913432114496		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 1.454913432114496 | validation: 1.5882302050118833]
	TIME [epoch: 9.51 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3544416121690144		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 1.3544416121690144 | validation: 1.3508665988328137]
	TIME [epoch: 9.51 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2395442430277708		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 1.2395442430277708 | validation: 1.2273864243008052]
	TIME [epoch: 9.51 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1212426146450323		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 1.1212426146450323 | validation: 1.627366067587708]
	TIME [epoch: 9.53 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3081033816995957		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 1.3081033816995957 | validation: 1.1591742534135452]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_388.pth
	Model improved!!!
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3229654577044276		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 1.3229654577044276 | validation: 1.263299623402732]
	TIME [epoch: 9.51 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3190330198566156		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 1.3190330198566156 | validation: 1.6631744825092023]
	TIME [epoch: 9.53 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2139761337917583		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 1.2139761337917583 | validation: 1.3885419688213156]
	TIME [epoch: 9.51 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.4089560934326706		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 1.4089560934326706 | validation: 1.4025916079707932]
	TIME [epoch: 9.51 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1789226992616475		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 1.1789226992616475 | validation: 1.37295665623281]
	TIME [epoch: 9.51 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3597664397714788		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 1.3597664397714788 | validation: 1.323745042313011]
	TIME [epoch: 9.53 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.303309772409611		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 1.303309772409611 | validation: 1.343972617727023]
	TIME [epoch: 9.51 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2422535400932126		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 1.2422535400932126 | validation: 1.51130610246801]
	TIME [epoch: 9.51 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2766204398456071		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 1.2766204398456071 | validation: 1.318921244547462]
	TIME [epoch: 9.53 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.134374069810358		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 1.134374069810358 | validation: 1.5707543050070223]
	TIME [epoch: 9.51 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.305446672579092		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 1.305446672579092 | validation: 1.7610001857812208]
	TIME [epoch: 9.51 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3653022247078659		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 1.3653022247078659 | validation: 1.1819706974320185]
	TIME [epoch: 9.51 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.231373508546076		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 1.231373508546076 | validation: 1.4415905313292319]
	TIME [epoch: 9.53 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1973368270647013		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 1.1973368270647013 | validation: 1.192691765847296]
	TIME [epoch: 9.51 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.20395512666106		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 1.20395512666106 | validation: 1.3116270278587336]
	TIME [epoch: 9.51 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2081399100608472		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 1.2081399100608472 | validation: 1.2139590745277007]
	TIME [epoch: 9.54 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1952440263159465		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 1.1952440263159465 | validation: 1.2882708843440418]
	TIME [epoch: 9.51 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1395570035530924		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 1.1395570035530924 | validation: 1.1246550764523289]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_406.pth
	Model improved!!!
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1046652852737018		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 1.1046652852737018 | validation: 1.3872294218410395]
	TIME [epoch: 9.52 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.20935183301361		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 1.20935183301361 | validation: 1.1021139428980025]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_408.pth
	Model improved!!!
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1101909628803186		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 1.1101909628803186 | validation: 1.282683095226705]
	TIME [epoch: 9.51 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2705645795047853		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 1.2705645795047853 | validation: 1.4770368347394982]
	TIME [epoch: 9.51 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.20608383246639		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 1.20608383246639 | validation: 1.178121860958928]
	TIME [epoch: 9.53 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0938829417588791		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 1.0938829417588791 | validation: 1.3073334911535164]
	TIME [epoch: 9.52 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.173105782243042		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 1.173105782243042 | validation: 1.3578601701310817]
	TIME [epoch: 9.52 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1595939831577982		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 1.1595939831577982 | validation: 1.2298661956023198]
	TIME [epoch: 9.51 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2178077594558723		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 1.2178077594558723 | validation: 1.3116629380292548]
	TIME [epoch: 9.53 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1462448874664672		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 1.1462448874664672 | validation: 1.316956293429285]
	TIME [epoch: 9.51 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1179442818958707		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 1.1179442818958707 | validation: 1.219792604631183]
	TIME [epoch: 9.51 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.201314400368227		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 1.201314400368227 | validation: 1.1736154072455798]
	TIME [epoch: 9.53 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1624408901406416		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 1.1624408901406416 | validation: 1.179785783208867]
	TIME [epoch: 9.51 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1506580686457162		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 1.1506580686457162 | validation: 1.225304239230691]
	TIME [epoch: 9.5 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2025185646768382		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 1.2025185646768382 | validation: 1.3079969495468537]
	TIME [epoch: 9.52 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.153699753064948		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 1.153699753064948 | validation: 1.2576413268010682]
	TIME [epoch: 9.52 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0936710810134693		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 1.0936710810134693 | validation: 1.2203673842362073]
	TIME [epoch: 9.51 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1947902248391202		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 1.1947902248391202 | validation: 1.5358153526084433]
	TIME [epoch: 9.51 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.195987488247319		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 1.195987488247319 | validation: 1.3855914742870976]
	TIME [epoch: 9.53 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1038163791762634		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 1.1038163791762634 | validation: 1.5331681961414105]
	TIME [epoch: 9.51 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1032204630057043		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 1.1032204630057043 | validation: 1.250577204301548]
	TIME [epoch: 9.51 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1452895927024567		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 1.1452895927024567 | validation: 1.311948685387511]
	TIME [epoch: 9.5 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1629612690361735		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 1.1629612690361735 | validation: 1.2118886711294157]
	TIME [epoch: 9.53 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.428348809646888		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 1.428348809646888 | validation: 1.2975397041158305]
	TIME [epoch: 9.51 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1356642796146925		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 1.1356642796146925 | validation: 1.288058498918258]
	TIME [epoch: 9.51 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.144781101406391		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 1.144781101406391 | validation: 1.2113946116210097]
	TIME [epoch: 9.54 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2288273239263274		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 1.2288273239263274 | validation: 1.0986724874722131]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_433.pth
	Model improved!!!
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2697936415628646		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 1.2697936415628646 | validation: 1.2374058394355099]
	TIME [epoch: 9.51 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1288053280294335		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 1.1288053280294335 | validation: 1.113042305194629]
	TIME [epoch: 9.51 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1665044428198512		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 1.1665044428198512 | validation: 1.1746978992804207]
	TIME [epoch: 9.52 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2321953053585035		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 1.2321953053585035 | validation: 1.3070482685681293]
	TIME [epoch: 9.5 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1279164459490574		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 1.1279164459490574 | validation: 1.1733877333592675]
	TIME [epoch: 9.51 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1682378312988528		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 1.1682378312988528 | validation: 1.129182149053168]
	TIME [epoch: 9.53 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1243227612851803		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 1.1243227612851803 | validation: 1.0727461586694902]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_440.pth
	Model improved!!!
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1014350975115303		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 1.1014350975115303 | validation: 1.102096691937883]
	TIME [epoch: 9.51 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.162918721310099		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 1.162918721310099 | validation: 1.1527880107801531]
	TIME [epoch: 9.52 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1125408946224087		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 1.1125408946224087 | validation: 1.107112172214016]
	TIME [epoch: 9.52 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2012284213740387		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 1.2012284213740387 | validation: 1.205581406775616]
	TIME [epoch: 9.52 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0613678069929628		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 1.0613678069929628 | validation: 1.1747112239026902]
	TIME [epoch: 9.5 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0612029907345133		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 1.0612029907345133 | validation: 1.2968881737366107]
	TIME [epoch: 9.54 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.3089641998264503		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 1.3089641998264503 | validation: 1.1897486025807877]
	TIME [epoch: 9.51 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.065093969500166		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 1.065093969500166 | validation: 1.4372799069605042]
	TIME [epoch: 9.51 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1821064759013273		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 1.1821064759013273 | validation: 1.1737401769995062]
	TIME [epoch: 9.52 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.038988170934571		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 1.038988170934571 | validation: 1.1332274422458546]
	TIME [epoch: 9.51 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0680336009065814		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 1.0680336009065814 | validation: 1.0869338842360932]
	TIME [epoch: 9.51 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.125229054813892		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 1.125229054813892 | validation: 1.1969255221944324]
	TIME [epoch: 9.5 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0933058971961065		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 1.0933058971961065 | validation: 1.0833720584178284]
	TIME [epoch: 9.53 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0744612164707281		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 1.0744612164707281 | validation: 1.4621040809916348]
	TIME [epoch: 9.51 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1839455198372553		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 1.1839455198372553 | validation: 1.677153875785745]
	TIME [epoch: 9.51 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.2626225207366126		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 1.2626225207366126 | validation: 1.2686448267071038]
	TIME [epoch: 9.52 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.203634144212063		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 1.203634144212063 | validation: 1.2463010274383886]
	TIME [epoch: 9.52 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0380424675221152		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 1.0380424675221152 | validation: 1.1073196381700374]
	TIME [epoch: 9.5 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0604594520281965		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 1.0604594520281965 | validation: 1.1504132180381696]
	TIME [epoch: 9.5 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0444759016837808		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 1.0444759016837808 | validation: 1.3777834788005863]
	TIME [epoch: 9.52 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1883508479917855		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 1.1883508479917855 | validation: 1.2091876654586766]
	TIME [epoch: 9.51 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0587921952130361		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 1.0587921952130361 | validation: 1.0860527178044819]
	TIME [epoch: 9.5 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.987634616329732		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 0.987634616329732 | validation: 1.2384321534913405]
	TIME [epoch: 9.52 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0864506291637148		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 1.0864506291637148 | validation: 1.273035699365618]
	TIME [epoch: 9.5 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0097218479774286		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 1.0097218479774286 | validation: 1.326767431011514]
	TIME [epoch: 9.5 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1574086778523731		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 1.1574086778523731 | validation: 1.1466407321673344]
	TIME [epoch: 9.5 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0376688272387864		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 1.0376688272387864 | validation: 1.1688276058449538]
	TIME [epoch: 9.52 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0472345346627505		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 1.0472345346627505 | validation: 1.086543091198717]
	TIME [epoch: 9.52 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1430567187514342		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 1.1430567187514342 | validation: 1.0799658777674208]
	TIME [epoch: 9.51 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.027916841533579		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 1.027916841533579 | validation: 1.2112259886940542]
	TIME [epoch: 9.53 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1390066356061939		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 1.1390066356061939 | validation: 1.2329221155221535]
	TIME [epoch: 9.51 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.05238655462817		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 1.05238655462817 | validation: 1.147947176492183]
	TIME [epoch: 9.52 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1897934506557277		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 1.1897934506557277 | validation: 1.0663082123367427]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_473.pth
	Model improved!!!
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1335923071039151		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 1.1335923071039151 | validation: 1.1187700170329598]
	TIME [epoch: 9.53 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0245062811596093		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 1.0245062811596093 | validation: 1.2228077334481788]
	TIME [epoch: 9.51 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0334444676386807		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 1.0334444676386807 | validation: 1.1626770142522593]
	TIME [epoch: 9.5 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1161743437116296		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 1.1161743437116296 | validation: 1.1630520364298396]
	TIME [epoch: 9.53 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.099484817650643		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 1.099484817650643 | validation: 1.150223652684497]
	TIME [epoch: 9.51 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0334561143244367		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 1.0334561143244367 | validation: 1.1787860056435815]
	TIME [epoch: 9.52 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1166110314338802		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 1.1166110314338802 | validation: 1.6031776442235173]
	TIME [epoch: 9.5 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.158233273916744		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 1.158233273916744 | validation: 1.0869913148770445]
	TIME [epoch: 9.53 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.041090656042428		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 1.041090656042428 | validation: 1.0767590771547852]
	TIME [epoch: 9.51 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0227636522379542		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 1.0227636522379542 | validation: 1.138538561705279]
	TIME [epoch: 9.5 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0466885682908895		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 1.0466885682908895 | validation: 1.1919903450283957]
	TIME [epoch: 9.52 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1060146285738566		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 1.1060146285738566 | validation: 1.6511720766419609]
	TIME [epoch: 9.51 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1785145646762278		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 1.1785145646762278 | validation: 1.104706238838172]
	TIME [epoch: 9.5 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0363307174515586		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 1.0363307174515586 | validation: 1.205504187618524]
	TIME [epoch: 9.51 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1035954776903767		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 1.1035954776903767 | validation: 1.3931565173772347]
	TIME [epoch: 9.53 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.017307350493661		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 1.017307350493661 | validation: 1.256658375830913]
	TIME [epoch: 9.51 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0953784341046775		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 1.0953784341046775 | validation: 1.1668101151439871]
	TIME [epoch: 9.51 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9965255549088414		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 0.9965255549088414 | validation: 1.154092086753046]
	TIME [epoch: 9.52 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.038536680882686		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 1.038536680882686 | validation: 1.1355512185035948]
	TIME [epoch: 9.51 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0519379963585755		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 1.0519379963585755 | validation: 1.1550977103111222]
	TIME [epoch: 9.51 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.036118934119985		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 1.036118934119985 | validation: 1.0331638143289885]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_494.pth
	Model improved!!!
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0204709903050393		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 1.0204709903050393 | validation: 1.171591694131086]
	TIME [epoch: 9.54 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0817686502453554		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 1.0817686502453554 | validation: 1.1736698201506324]
	TIME [epoch: 9.51 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0013094439552646		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 1.0013094439552646 | validation: 1.099265824662914]
	TIME [epoch: 9.51 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.200579725409781		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 1.200579725409781 | validation: 1.2925577512434703]
	TIME [epoch: 9.54 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1141268095662649		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 1.1141268095662649 | validation: 1.3033509137222246]
	TIME [epoch: 9.52 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.033096220600029		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 1.033096220600029 | validation: 1.0917796046075967]
	TIME [epoch: 9.51 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0015763303438159		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 1.0015763303438159 | validation: 1.0491168140805827]
	TIME [epoch: 9.51 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9785222585202721		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 0.9785222585202721 | validation: 1.14087322168294]
	TIME [epoch: 9.53 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.993875810958347		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 0.993875810958347 | validation: 1.243183297969255]
	TIME [epoch: 9.51 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.040822812522115		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 1.040822812522115 | validation: 1.093199966013539]
	TIME [epoch: 9.51 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9851596871140931		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 0.9851596871140931 | validation: 1.1936629928163252]
	TIME [epoch: 9.54 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0425597851208261		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 1.0425597851208261 | validation: 1.239181912402179]
	TIME [epoch: 9.52 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0837053065030822		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 1.0837053065030822 | validation: 1.02638996747545]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_507.pth
	Model improved!!!
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0175085726792736		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 1.0175085726792736 | validation: 1.2477710984978736]
	TIME [epoch: 9.51 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0329382930306263		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 1.0329382930306263 | validation: 1.1309105586489292]
	TIME [epoch: 9.55 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9895774147054464		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 0.9895774147054464 | validation: 1.1747026283977813]
	TIME [epoch: 9.52 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.009828332344124		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 1.009828332344124 | validation: 1.0227019235771702]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_511.pth
	Model improved!!!
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0422866525699246		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 1.0422866525699246 | validation: 1.1347865020250976]
	TIME [epoch: 9.55 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9941825233907876		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 0.9941825233907876 | validation: 1.4720568933135503]
	TIME [epoch: 9.53 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.1200180666779012		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 1.1200180666779012 | validation: 1.083720844421841]
	TIME [epoch: 9.52 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.979596459889281		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 0.979596459889281 | validation: 1.1426330943452467]
	TIME [epoch: 9.52 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0182516376619604		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 1.0182516376619604 | validation: 1.207620613693731]
	TIME [epoch: 9.53 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.047588750558956		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 1.047588750558956 | validation: 1.4472121375731848]
	TIME [epoch: 9.53 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.094024748483478		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 1.094024748483478 | validation: 1.0695069077871997]
	TIME [epoch: 9.51 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9770480039369172		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 0.9770480039369172 | validation: 1.262775431140315]
	TIME [epoch: 9.53 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0219083522008543		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 1.0219083522008543 | validation: 1.0384882659623966]
	TIME [epoch: 9.52 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0057510649695887		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 1.0057510649695887 | validation: 1.2292530843783647]
	TIME [epoch: 9.51 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9734809393010014		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 0.9734809393010014 | validation: 1.1364844984798577]
	TIME [epoch: 9.52 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9891482841993448		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 0.9891482841993448 | validation: 1.2358768070369726]
	TIME [epoch: 9.53 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0323983957593101		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 1.0323983957593101 | validation: 1.0053106325102432]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_524.pth
	Model improved!!!
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9382486046385301		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 0.9382486046385301 | validation: 1.0774116163376772]
	TIME [epoch: 9.52 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0042959596990597		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 1.0042959596990597 | validation: 1.0324526722026959]
	TIME [epoch: 9.54 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9991816074536974		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 0.9991816074536974 | validation: 1.0386670662414823]
	TIME [epoch: 9.51 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9512865640145087		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 0.9512865640145087 | validation: 1.1223152618794354]
	TIME [epoch: 9.5 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.043573210728241		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 1.043573210728241 | validation: 0.980870751393955]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_529.pth
	Model improved!!!
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.11215974979282		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 1.11215974979282 | validation: 1.5128130530513695]
	TIME [epoch: 9.53 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0956409713573094		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 1.0956409713573094 | validation: 1.0771810830845903]
	TIME [epoch: 9.51 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9875120822724253		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 0.9875120822724253 | validation: 1.3156712667435806]
	TIME [epoch: 9.51 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.998934395815956		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 0.998934395815956 | validation: 1.072365159964288]
	TIME [epoch: 9.53 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0501970005573893		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 1.0501970005573893 | validation: 1.0552266796115979]
	TIME [epoch: 9.51 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9368772460877886		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 0.9368772460877886 | validation: 1.0806388373817957]
	TIME [epoch: 9.51 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9643296465171286		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 0.9643296465171286 | validation: 1.0089985971223587]
	TIME [epoch: 9.51 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9603380340738173		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 0.9603380340738173 | validation: 1.1988797565648637]
	TIME [epoch: 9.53 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0167424126617188		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 1.0167424126617188 | validation: 1.0360263097152327]
	TIME [epoch: 9.52 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9370405380771383		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 0.9370405380771383 | validation: 1.078639915191366]
	TIME [epoch: 9.52 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9414351572209252		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 0.9414351572209252 | validation: 1.1558913426319983]
	TIME [epoch: 9.54 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9554682777550212		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 0.9554682777550212 | validation: 1.1626428887623181]
	TIME [epoch: 9.52 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9524865147507754		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 0.9524865147507754 | validation: 1.125507182555074]
	TIME [epoch: 9.51 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9655674688856981		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 0.9655674688856981 | validation: 1.0134710258193906]
	TIME [epoch: 9.52 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9353230255894737		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 0.9353230255894737 | validation: 1.0800798429268046]
	TIME [epoch: 9.53 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9470875130125511		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 0.9470875130125511 | validation: 1.1031152769645278]
	TIME [epoch: 9.52 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0029074393272772		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 1.0029074393272772 | validation: 0.9623716975841066]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_546.pth
	Model improved!!!
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9078447720798941		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 0.9078447720798941 | validation: 1.0030204727172045]
	TIME [epoch: 9.53 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.970783032080285		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 0.970783032080285 | validation: 1.052777970717393]
	TIME [epoch: 9.51 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9655584412776351		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 0.9655584412776351 | validation: 0.982888537746064]
	TIME [epoch: 9.51 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9451484112339003		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 0.9451484112339003 | validation: 1.1030535355056328]
	TIME [epoch: 9.52 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9950719623865947		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 0.9950719623865947 | validation: 1.0066208533674956]
	TIME [epoch: 9.53 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9355799011596003		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 0.9355799011596003 | validation: 1.0617602246843398]
	TIME [epoch: 9.52 sec]
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9290052256446891		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 0.9290052256446891 | validation: 1.1448835257020809]
	TIME [epoch: 9.51 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0642835538503619		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 1.0642835538503619 | validation: 1.2146854665594686]
	TIME [epoch: 9.54 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0249183562827895		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 1.0249183562827895 | validation: 1.0378843976651058]
	TIME [epoch: 9.52 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9117806659667025		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 0.9117806659667025 | validation: 1.0477744874660238]
	TIME [epoch: 9.52 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9476190451987522		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 0.9476190451987522 | validation: 1.0643377683350272]
	TIME [epoch: 9.53 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9257959296445566		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 0.9257959296445566 | validation: 1.0069505181441505]
	TIME [epoch: 9.53 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9375488769637039		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 0.9375488769637039 | validation: 1.0526617364153548]
	TIME [epoch: 9.51 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9529406184668845		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 0.9529406184668845 | validation: 1.1089737072808041]
	TIME [epoch: 9.52 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9514653570569191		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 0.9514653570569191 | validation: 1.2927408855576032]
	TIME [epoch: 9.54 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.013423345391734		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 1.013423345391734 | validation: 1.0571780474807364]
	TIME [epoch: 9.52 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9858071616688593		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 0.9858071616688593 | validation: 1.0896542274745096]
	TIME [epoch: 9.52 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0085843798969585		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 1.0085843798969585 | validation: 1.1552104085156674]
	TIME [epoch: 9.54 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.945904177819663		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 0.945904177819663 | validation: 1.0028682543514589]
	TIME [epoch: 9.53 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9347681006648049		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 0.9347681006648049 | validation: 0.9941456951861389]
	TIME [epoch: 9.51 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9560090302863271		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 0.9560090302863271 | validation: 1.1978804535410998]
	TIME [epoch: 9.52 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9579184872566889		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 0.9579184872566889 | validation: 1.1071814372136906]
	TIME [epoch: 9.53 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9473798734982767		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 0.9473798734982767 | validation: 1.0272172099755428]
	TIME [epoch: 9.51 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9367142526881646		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 0.9367142526881646 | validation: 1.15807152973809]
	TIME [epoch: 9.51 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9709016100872727		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 0.9709016100872727 | validation: 0.9913502346334994]
	TIME [epoch: 9.53 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8853903685715947		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 0.8853903685715947 | validation: 1.0511853419924555]
	TIME [epoch: 9.52 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9863352685074294		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 0.9863352685074294 | validation: 1.054941151217453]
	TIME [epoch: 9.51 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9166771200741503		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 0.9166771200741503 | validation: 1.0428718043195695]
	TIME [epoch: 9.51 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9640794140830058		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 0.9640794140830058 | validation: 1.119937938028152]
	TIME [epoch: 9.54 sec]
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9308805230630981		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 0.9308805230630981 | validation: 1.0644704234266666]
	TIME [epoch: 9.51 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9663774332195146		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 0.9663774332195146 | validation: 1.0101139435042357]
	TIME [epoch: 9.51 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0544990340946758		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 1.0544990340946758 | validation: 1.2788066224519126]
	TIME [epoch: 9.53 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.03387193454247		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 1.03387193454247 | validation: 0.9842987879760245]
	TIME [epoch: 9.52 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9187493458800653		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 0.9187493458800653 | validation: 0.9853010643734013]
	TIME [epoch: 9.51 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9135100571260117		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 0.9135100571260117 | validation: 1.2911537529124235]
	TIME [epoch: 9.51 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9600704148556648		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 0.9600704148556648 | validation: 1.0887320281773123]
	TIME [epoch: 9.54 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9430048277972393		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 0.9430048277972393 | validation: 0.9610249651602452]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_583.pth
	Model improved!!!
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9780162993881761		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 0.9780162993881761 | validation: 1.1415925795456257]
	TIME [epoch: 9.52 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9442778498059281		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 0.9442778498059281 | validation: 1.0411244182007784]
	TIME [epoch: 9.53 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9562681588765821		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 0.9562681588765821 | validation: 1.0729769920383971]
	TIME [epoch: 9.53 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9315765993021567		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 0.9315765993021567 | validation: 0.997224588958135]
	TIME [epoch: 9.51 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0179819458953194		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 1.0179819458953194 | validation: 1.0069379659748172]
	TIME [epoch: 9.5 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9070594901916122		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 0.9070594901916122 | validation: 1.0364983353120798]
	TIME [epoch: 9.53 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9911894088762695		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 0.9911894088762695 | validation: 1.0365646110081856]
	TIME [epoch: 9.51 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9561341404429122		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 0.9561341404429122 | validation: 1.0037707059526801]
	TIME [epoch: 9.52 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8988353411657759		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 0.8988353411657759 | validation: 1.0405999891655842]
	TIME [epoch: 9.53 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8988617811113079		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 0.8988617811113079 | validation: 1.1601251266748298]
	TIME [epoch: 9.52 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9674969986372843		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 0.9674969986372843 | validation: 0.9925261122230719]
	TIME [epoch: 9.51 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8984742590978719		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 0.8984742590978719 | validation: 1.2636322181390065]
	TIME [epoch: 9.51 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.982909709931444		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 0.982909709931444 | validation: 0.9949954842614271]
	TIME [epoch: 9.53 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9565959160137207		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 0.9565959160137207 | validation: 1.0073278148659484]
	TIME [epoch: 9.51 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.902250311696131		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 0.902250311696131 | validation: 0.9897633902215327]
	TIME [epoch: 9.51 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9273484232960074		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 0.9273484232960074 | validation: 0.980790200969089]
	TIME [epoch: 9.54 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9274691352891372		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 0.9274691352891372 | validation: 1.068823427521773]
	TIME [epoch: 9.52 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9293362877030669		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 0.9293362877030669 | validation: 1.0602297903415627]
	TIME [epoch: 9.52 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9177809631013878		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 0.9177809631013878 | validation: 1.065050503089593]
	TIME [epoch: 9.51 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9626691480586043		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 0.9626691480586043 | validation: 1.1104164766107265]
	TIME [epoch: 9.54 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8867574849099356		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 0.8867574849099356 | validation: 1.0560287490747273]
	TIME [epoch: 9.52 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.87748518935027		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 0.87748518935027 | validation: 1.0740350154948328]
	TIME [epoch: 9.52 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9760721624575677		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 0.9760721624575677 | validation: 1.0779222737188443]
	TIME [epoch: 9.54 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9138716386549353		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 0.9138716386549353 | validation: 1.0589702811506922]
	TIME [epoch: 9.52 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.89115987865584		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 0.89115987865584 | validation: 1.0003426124115282]
	TIME [epoch: 9.51 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9191023872758987		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 0.9191023872758987 | validation: 0.9356320018388994]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_609.pth
	Model improved!!!
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9819152660955023		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 0.9819152660955023 | validation: 0.9619281769790721]
	TIME [epoch: 9.53 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9024836727601571		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 0.9024836727601571 | validation: 1.0967441315872763]
	TIME [epoch: 9.51 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8924453714371492		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 0.8924453714371492 | validation: 1.0102103371000397]
	TIME [epoch: 9.51 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9765235646586076		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 0.9765235646586076 | validation: 1.0444033357513163]
	TIME [epoch: 9.53 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8809681997341864		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 0.8809681997341864 | validation: 0.9914123386760565]
	TIME [epoch: 9.51 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8889804046268737		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 0.8889804046268737 | validation: 1.1529398622739917]
	TIME [epoch: 9.5 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9062431490718547		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 0.9062431490718547 | validation: 1.0047713182137805]
	TIME [epoch: 9.51 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8835943787557883		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 0.8835943787557883 | validation: 0.9918174671892683]
	TIME [epoch: 9.54 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8995199068624558		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 0.8995199068624558 | validation: 0.94028458853964]
	TIME [epoch: 9.52 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.912502758308999		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 0.912502758308999 | validation: 0.9286782449716843]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_619.pth
	Model improved!!!
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8468946358193777		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 0.8468946358193777 | validation: 1.235778955281472]
	TIME [epoch: 9.54 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9602027792016337		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 0.9602027792016337 | validation: 0.9782740775446642]
	TIME [epoch: 9.52 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9186072213338639		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 0.9186072213338639 | validation: 1.2127089700791818]
	TIME [epoch: 9.51 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.0126700893864684		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 1.0126700893864684 | validation: 0.9371492123780327]
	TIME [epoch: 9.51 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8407666479826119		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 0.8407666479826119 | validation: 0.9584820265959277]
	TIME [epoch: 9.54 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8861295072182855		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 0.8861295072182855 | validation: 1.0256533473691898]
	TIME [epoch: 9.52 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8568316684994299		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 0.8568316684994299 | validation: 0.9247504030777194]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_626.pth
	Model improved!!!
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.898786778519197		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 0.898786778519197 | validation: 0.9312102327861567]
	TIME [epoch: 9.53 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8681189330204584		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 0.8681189330204584 | validation: 0.9416127531975237]
	TIME [epoch: 9.51 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8687877588997459		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 0.8687877588997459 | validation: 1.0066146935569382]
	TIME [epoch: 9.51 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9687821152586368		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 0.9687821152586368 | validation: 0.9791835855409187]
	TIME [epoch: 9.52 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.859753879491441		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 0.859753879491441 | validation: 1.102733614617807]
	TIME [epoch: 9.52 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8530326196870588		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 0.8530326196870588 | validation: 1.0662746872408486]
	TIME [epoch: 9.51 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8946239181466294		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 0.8946239181466294 | validation: 1.1178157146192313]
	TIME [epoch: 9.51 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9488523456853659		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 0.9488523456853659 | validation: 0.9630102500874719]
	TIME [epoch: 9.53 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8259451780265099		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 0.8259451780265099 | validation: 0.9990450293800092]
	TIME [epoch: 9.52 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8939405824836897		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 0.8939405824836897 | validation: 0.9502692921654357]
	TIME [epoch: 9.51 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8754074146302593		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 0.8754074146302593 | validation: 0.9707671667786417]
	TIME [epoch: 9.51 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8621436871895588		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 0.8621436871895588 | validation: 0.9612174308196808]
	TIME [epoch: 9.52 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8934931862709655		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 0.8934931862709655 | validation: 1.1180971700878974]
	TIME [epoch: 9.51 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9006468091773252		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 0.9006468091773252 | validation: 0.9570006945730802]
	TIME [epoch: 9.5 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8359726812950656		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 0.8359726812950656 | validation: 0.9551962393744244]
	TIME [epoch: 9.52 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8553469601780662		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 0.8553469601780662 | validation: 1.1058070862819498]
	TIME [epoch: 9.51 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8726071543040123		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 0.8726071543040123 | validation: 0.9509465091573537]
	TIME [epoch: 9.5 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8396918307772676		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 0.8396918307772676 | validation: 0.9921843932014233]
	TIME [epoch: 9.52 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8371113084861763		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 0.8371113084861763 | validation: 0.9577838517819379]
	TIME [epoch: 9.52 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.861005585205258		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 0.861005585205258 | validation: 1.0544257966088553]
	TIME [epoch: 9.51 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8589426608767206		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 0.8589426608767206 | validation: 0.9818455786599698]
	TIME [epoch: 9.5 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8518407400739723		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 0.8518407400739723 | validation: 0.9927792905561279]
	TIME [epoch: 9.53 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8329496829597905		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 0.8329496829597905 | validation: 0.9819645107395358]
	TIME [epoch: 9.51 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8527536332757846		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 0.8527536332757846 | validation: 0.9536494270363625]
	TIME [epoch: 9.51 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8695302128753631		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 0.8695302128753631 | validation: 1.0230612556639336]
	TIME [epoch: 9.52 sec]
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.855665379677338		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 0.855665379677338 | validation: 0.9834657812855565]
	TIME [epoch: 9.53 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8554870653177307		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 0.8554870653177307 | validation: 1.0459833410167807]
	TIME [epoch: 9.51 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9009083183726145		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 0.9009083183726145 | validation: 1.0510247139456268]
	TIME [epoch: 9.51 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8818950180976834		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 0.8818950180976834 | validation: 0.9666319599368515]
	TIME [epoch: 9.53 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8589824637019362		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 0.8589824637019362 | validation: 0.9991490377701935]
	TIME [epoch: 9.52 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9311318702827375		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 0.9311318702827375 | validation: 0.9929845652914948]
	TIME [epoch: 9.5 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8977867059954967		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 0.8977867059954967 | validation: 0.9238480858527693]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_658.pth
	Model improved!!!
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8402346715234629		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 0.8402346715234629 | validation: 0.934469874392472]
	TIME [epoch: 9.53 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8580374038332769		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 0.8580374038332769 | validation: 1.1405071350941973]
	TIME [epoch: 9.52 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8727937589385		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 0.8727937589385 | validation: 1.0359910603838953]
	TIME [epoch: 9.5 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8943495904222998		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 0.8943495904222998 | validation: 0.9669985929947612]
	TIME [epoch: 9.53 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9286827021322974		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 0.9286827021322974 | validation: 0.9813754793281599]
	TIME [epoch: 9.51 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8380112514051234		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 0.8380112514051234 | validation: 0.9608562845535187]
	TIME [epoch: 9.51 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8159583297581117		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 0.8159583297581117 | validation: 0.9976019915185496]
	TIME [epoch: 9.52 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8662482032676962		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 0.8662482032676962 | validation: 0.9481501164076507]
	TIME [epoch: 9.53 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8680264431301874		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 0.8680264431301874 | validation: 0.9249402735511385]
	TIME [epoch: 9.52 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8501115067014915		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 0.8501115067014915 | validation: 0.9444301295246489]
	TIME [epoch: 9.51 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8937776244455765		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 0.8937776244455765 | validation: 0.9144160777509054]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_669.pth
	Model improved!!!
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8320579223823433		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 0.8320579223823433 | validation: 0.9498517772816372]
	TIME [epoch: 9.51 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8508720396709236		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 0.8508720396709236 | validation: 0.9160991630029409]
	TIME [epoch: 9.51 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8082514873429298		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 0.8082514873429298 | validation: 0.9327843335288052]
	TIME [epoch: 9.53 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8221102428993138		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 0.8221102428993138 | validation: 0.9842549272943778]
	TIME [epoch: 9.51 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.890386546810398		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 0.890386546810398 | validation: 1.0001571500785857]
	TIME [epoch: 9.51 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8600638096507435		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 0.8600638096507435 | validation: 0.9112276652389456]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_675.pth
	Model improved!!!
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8593673780990196		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 0.8593673780990196 | validation: 0.9549633913838719]
	TIME [epoch: 9.54 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8557992403050114		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 0.8557992403050114 | validation: 1.03814104325437]
	TIME [epoch: 9.51 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.9228183436768399		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 0.9228183436768399 | validation: 1.0292298820903178]
	TIME [epoch: 9.52 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8689120832317141		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 0.8689120832317141 | validation: 1.0178542663011234]
	TIME [epoch: 9.52 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8378418087244057		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 0.8378418087244057 | validation: 0.9787898153575674]
	TIME [epoch: 9.52 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8490815938496098		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 0.8490815938496098 | validation: 0.8910042904940515]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_681.pth
	Model improved!!!
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8259676684101006		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 0.8259676684101006 | validation: 0.9130921313025024]
	TIME [epoch: 9.51 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8475005458286325		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 0.8475005458286325 | validation: 0.9602428752023844]
	TIME [epoch: 9.52 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8335576142078572		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 0.8335576142078572 | validation: 0.8959468999339211]
	TIME [epoch: 9.51 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.813268827877681		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 0.813268827877681 | validation: 0.9415497460492813]
	TIME [epoch: 9.5 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8498965178126783		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 0.8498965178126783 | validation: 1.1135067798589113]
	TIME [epoch: 9.52 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 1.002821024354515		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 1.002821024354515 | validation: 1.02136973287728]
	TIME [epoch: 9.52 sec]
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8465309503605332		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 0.8465309503605332 | validation: 0.9121899020195045]
	TIME [epoch: 9.51 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8190848762391785		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 0.8190848762391785 | validation: 0.9338573946850663]
	TIME [epoch: 9.51 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8418546212113256		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 0.8418546212113256 | validation: 0.9240664190451922]
	TIME [epoch: 9.52 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8512777050616929		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 0.8512777050616929 | validation: 0.8894810101753481]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_691.pth
	Model improved!!!
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8331886089365893		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 0.8331886089365893 | validation: 0.9464133123454582]
	TIME [epoch: 9.52 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.803247338624202		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 0.803247338624202 | validation: 0.9206268605212611]
	TIME [epoch: 9.52 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8208520375533384		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 0.8208520375533384 | validation: 0.9528326355240979]
	TIME [epoch: 9.52 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.817545044966623		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 0.817545044966623 | validation: 0.9233579643132191]
	TIME [epoch: 9.51 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8292641381750722		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 0.8292641381750722 | validation: 0.9806031410909156]
	TIME [epoch: 9.51 sec]
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8254406539611601		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 0.8254406539611601 | validation: 0.9729396618583631]
	TIME [epoch: 9.53 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8282752946694444		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 0.8282752946694444 | validation: 0.9558448831233233]
	TIME [epoch: 9.53 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8624650655194734		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 0.8624650655194734 | validation: 0.887674344255039]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_699.pth
	Model improved!!!
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8082654256571293		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 0.8082654256571293 | validation: 0.9672361219502904]
	TIME [epoch: 9.54 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.84671741289115		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 0.84671741289115 | validation: 0.9572336658377738]
	TIME [epoch: 9.5 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8124807329947339		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 0.8124807329947339 | validation: 0.915612958629991]
	TIME [epoch: 9.5 sec]
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.855687766737842		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 0.855687766737842 | validation: 0.9473429904630979]
	TIME [epoch: 9.5 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8331714424519856		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 0.8331714424519856 | validation: 0.9241367199072889]
	TIME [epoch: 9.52 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8156162286115208		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 0.8156162286115208 | validation: 0.8656923933637457]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_705.pth
	Model improved!!!
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7874007106416996		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 0.7874007106416996 | validation: 0.9653954532084938]
	TIME [epoch: 9.5 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8090197980519983		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 0.8090197980519983 | validation: 0.9381865171633849]
	TIME [epoch: 9.52 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8160237936102481		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 0.8160237936102481 | validation: 0.9146534191741775]
	TIME [epoch: 9.52 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7947852392265196		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 0.7947852392265196 | validation: 0.9038701880459921]
	TIME [epoch: 9.51 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8066476807227904		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 0.8066476807227904 | validation: 0.8815836601271648]
	TIME [epoch: 9.53 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8392936868598635		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 0.8392936868598635 | validation: 0.8515367465999046]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_711.pth
	Model improved!!!
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8111399452983911		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 0.8111399452983911 | validation: 0.9251100388682663]
	TIME [epoch: 9.51 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8576971483130114		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 0.8576971483130114 | validation: 0.9262593718401209]
	TIME [epoch: 9.5 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.847610426193169		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 0.847610426193169 | validation: 0.8705195672775918]
	TIME [epoch: 9.53 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8140827912711502		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 0.8140827912711502 | validation: 0.9774797611759677]
	TIME [epoch: 9.5 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8032427368452595		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 0.8032427368452595 | validation: 0.9240886637280032]
	TIME [epoch: 9.51 sec]
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8229298195868262		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 0.8229298195868262 | validation: 0.9353261143642267]
	TIME [epoch: 9.51 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8404895684723221		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 0.8404895684723221 | validation: 0.9880636744486256]
	TIME [epoch: 9.53 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.831088179939413		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 0.831088179939413 | validation: 0.9633734324000159]
	TIME [epoch: 9.5 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8102307988664524		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 0.8102307988664524 | validation: 0.9405980084371898]
	TIME [epoch: 9.5 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8347342949825715		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 0.8347342949825715 | validation: 1.0223928605250583]
	TIME [epoch: 9.54 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8259764596567049		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 0.8259764596567049 | validation: 0.9252096945971396]
	TIME [epoch: 9.52 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8119599072842478		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 0.8119599072842478 | validation: 0.9056066985639641]
	TIME [epoch: 9.51 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7978134810676154		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 0.7978134810676154 | validation: 0.8885039482066119]
	TIME [epoch: 9.51 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8413398135370118		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 0.8413398135370118 | validation: 0.9096471766349226]
	TIME [epoch: 9.52 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7961618279624612		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 0.7961618279624612 | validation: 0.8508064712989526]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_726.pth
	Model improved!!!
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8092109601889114		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 0.8092109601889114 | validation: 0.888417625894148]
	TIME [epoch: 9.5 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8657159630910474		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 0.8657159630910474 | validation: 1.0449792277469805]
	TIME [epoch: 9.53 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8350826515955656		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 0.8350826515955656 | validation: 1.0250845624445]
	TIME [epoch: 9.51 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8738570972083425		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 0.8738570972083425 | validation: 0.9629950872938763]
	TIME [epoch: 9.51 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8024002968266478		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 0.8024002968266478 | validation: 0.8939853174145145]
	TIME [epoch: 9.51 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8271248236489553		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 0.8271248236489553 | validation: 0.9821097978920159]
	TIME [epoch: 9.53 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.801070714029003		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 0.801070714029003 | validation: 1.0327140040350513]
	TIME [epoch: 9.51 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8660484149172667		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 0.8660484149172667 | validation: 0.8865124255525133]
	TIME [epoch: 9.5 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8327370687308818		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 0.8327370687308818 | validation: 0.9070353586757172]
	TIME [epoch: 9.54 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7684103945447579		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 0.7684103945447579 | validation: 0.9291578962506403]
	TIME [epoch: 9.52 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7874350390546925		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 0.7874350390546925 | validation: 0.8767464486344292]
	TIME [epoch: 9.5 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8002415526428368		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 0.8002415526428368 | validation: 0.9199545714523047]
	TIME [epoch: 9.52 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7950523463798247		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 0.7950523463798247 | validation: 0.8692156339146859]
	TIME [epoch: 9.53 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8165588509119937		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 0.8165588509119937 | validation: 0.9087123994238493]
	TIME [epoch: 9.52 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8012409896603409		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 0.8012409896603409 | validation: 0.8838128284113649]
	TIME [epoch: 9.51 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7880497554927468		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 0.7880497554927468 | validation: 0.8991171786811721]
	TIME [epoch: 9.53 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8032012559564837		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 0.8032012559564837 | validation: 0.880898219265811]
	TIME [epoch: 9.52 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7829248556953395		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 0.7829248556953395 | validation: 0.8787222225287112]
	TIME [epoch: 9.5 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8146293952250442		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 0.8146293952250442 | validation: 0.8874876854846386]
	TIME [epoch: 9.51 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.788093387778871		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 0.788093387778871 | validation: 0.8953273714285525]
	TIME [epoch: 9.54 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7995257263465233		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 0.7995257263465233 | validation: 0.8936698159121929]
	TIME [epoch: 9.52 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8048451247866305		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 0.8048451247866305 | validation: 0.9044278060948489]
	TIME [epoch: 9.51 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8262658320918883		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 0.8262658320918883 | validation: 0.9243589056078105]
	TIME [epoch: 9.53 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7826533820823903		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 0.7826533820823903 | validation: 0.8735500127604178]
	TIME [epoch: 9.52 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7800588719255879		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 0.7800588719255879 | validation: 0.956890760449215]
	TIME [epoch: 9.52 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8063401667471727		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 0.8063401667471727 | validation: 0.8449647908801221]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_752.pth
	Model improved!!!
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7764580167535066		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 0.7764580167535066 | validation: 0.8929206154202676]
	TIME [epoch: 9.52 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.828023635123176		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 0.828023635123176 | validation: 0.8439170079627908]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_754.pth
	Model improved!!!
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7849687723724932		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 0.7849687723724932 | validation: 0.8836336776962682]
	TIME [epoch: 9.51 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.795931711347337		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 0.795931711347337 | validation: 0.9198597116251097]
	TIME [epoch: 9.53 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8380506778474068		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 0.8380506778474068 | validation: 0.9064746181657956]
	TIME [epoch: 9.51 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8151572519772603		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 0.8151572519772603 | validation: 0.8628947904864717]
	TIME [epoch: 9.51 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7810194535995489		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 0.7810194535995489 | validation: 1.0008346413740332]
	TIME [epoch: 9.52 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.803380728700346		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 0.803380728700346 | validation: 0.8837503136677134]
	TIME [epoch: 9.52 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7645400335823449		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 0.7645400335823449 | validation: 0.9323185559600393]
	TIME [epoch: 9.51 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7989102274888115		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 0.7989102274888115 | validation: 0.8657585331812347]
	TIME [epoch: 9.5 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7934535613614442		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 0.7934535613614442 | validation: 0.924888955731445]
	TIME [epoch: 9.52 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7904248630161136		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 0.7904248630161136 | validation: 0.8880290603231096]
	TIME [epoch: 9.51 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7776981521569606		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 0.7776981521569606 | validation: 0.896227346478955]
	TIME [epoch: 9.51 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7537890764132558		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 0.7537890764132558 | validation: 0.8801260137489578]
	TIME [epoch: 9.52 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7737735688117472		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 0.7737735688117472 | validation: 0.8523406146092114]
	TIME [epoch: 9.52 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7943924063736794		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 0.7943924063736794 | validation: 0.8740731520672835]
	TIME [epoch: 9.51 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8068580239417509		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 0.8068580239417509 | validation: 0.9339976056475093]
	TIME [epoch: 9.51 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8224692694415815		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 0.8224692694415815 | validation: 0.899879467538731]
	TIME [epoch: 9.53 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8065148593645614		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 0.8065148593645614 | validation: 0.9524254318348223]
	TIME [epoch: 9.51 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8404359762223672		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 0.8404359762223672 | validation: 0.906019855829789]
	TIME [epoch: 9.52 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7855664547853142		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 0.7855664547853142 | validation: 0.8630709596942032]
	TIME [epoch: 9.58 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7960407401548301		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 0.7960407401548301 | validation: 0.8879572118465585]
	TIME [epoch: 9.55 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7501643320630488		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 0.7501643320630488 | validation: 0.8461846598001475]
	TIME [epoch: 9.54 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7582158291598107		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 0.7582158291598107 | validation: 0.9223386692418941]
	TIME [epoch: 9.52 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7681931820759256		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 0.7681931820759256 | validation: 0.9004044701224396]
	TIME [epoch: 9.56 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7798670374152056		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 0.7798670374152056 | validation: 0.9144411208123766]
	TIME [epoch: 9.54 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7862460725747523		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 0.7862460725747523 | validation: 0.8599550523107267]
	TIME [epoch: 9.53 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7700738586364919		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 0.7700738586364919 | validation: 0.8267092803359279]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_780.pth
	Model improved!!!
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.753872621753058		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 0.753872621753058 | validation: 0.9155079842135081]
	TIME [epoch: 9.53 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8005845928060239		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 0.8005845928060239 | validation: 0.9196037762865492]
	TIME [epoch: 9.52 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7668311129598484		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 0.7668311129598484 | validation: 0.8747730793162876]
	TIME [epoch: 9.52 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.77070387287922		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 0.77070387287922 | validation: 0.9015156983760753]
	TIME [epoch: 9.55 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7707166102737378		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 0.7707166102737378 | validation: 0.8217440067160712]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_785.pth
	Model improved!!!
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7465383645418731		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 0.7465383645418731 | validation: 0.8734840668107208]
	TIME [epoch: 9.52 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7683879412284318		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 0.7683879412284318 | validation: 0.8540074562569516]
	TIME [epoch: 9.54 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7650525336582036		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 0.7650525336582036 | validation: 0.9024266324447221]
	TIME [epoch: 9.53 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7588827334929291		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 0.7588827334929291 | validation: 0.8790188156399359]
	TIME [epoch: 9.52 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7739091674950831		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 0.7739091674950831 | validation: 0.8703320407276803]
	TIME [epoch: 9.52 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7681056773863337		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 0.7681056773863337 | validation: 0.8901270642699092]
	TIME [epoch: 9.54 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.774932764491673		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 0.774932764491673 | validation: 0.8514263739848582]
	TIME [epoch: 9.51 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.762878513897754		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 0.762878513897754 | validation: 0.8544434768453765]
	TIME [epoch: 9.52 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7867204677253195		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 0.7867204677253195 | validation: 0.8686300910389383]
	TIME [epoch: 9.55 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7629023960426886		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 0.7629023960426886 | validation: 0.8183190998900134]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_795.pth
	Model improved!!!
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7675623084582304		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 0.7675623084582304 | validation: 0.8348955234034737]
	TIME [epoch: 9.53 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7721315200920956		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 0.7721315200920956 | validation: 0.8090519339360108]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_797.pth
	Model improved!!!
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7452144952974145		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 0.7452144952974145 | validation: 0.845959916466854]
	TIME [epoch: 9.54 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.764997022511244		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 0.764997022511244 | validation: 0.8380010844380703]
	TIME [epoch: 9.53 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7778727963137464		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 0.7778727963137464 | validation: 0.802775320810255]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_800.pth
	Model improved!!!
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7599505148917817		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 0.7599505148917817 | validation: 0.8549736745175223]
	TIME [epoch: 9.55 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.771777067420333		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 0.771777067420333 | validation: 0.8827808066311491]
	TIME [epoch: 9.54 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8303175006593007		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 0.8303175006593007 | validation: 0.8698213143195049]
	TIME [epoch: 9.53 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7693680109125591		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 0.7693680109125591 | validation: 0.894511648902542]
	TIME [epoch: 9.53 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7993189156633013		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 0.7993189156633013 | validation: 0.893474198687807]
	TIME [epoch: 9.54 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7757665507597922		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 0.7757665507597922 | validation: 0.8624384627933631]
	TIME [epoch: 9.53 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7485759202975846		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 0.7485759202975846 | validation: 0.8800383674164656]
	TIME [epoch: 9.51 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7673073517122335		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 0.7673073517122335 | validation: 0.872812475835223]
	TIME [epoch: 9.55 sec]
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7583011014067863		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 0.7583011014067863 | validation: 0.8596328387523756]
	TIME [epoch: 9.52 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7665079918714117		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 0.7665079918714117 | validation: 0.9002665678024261]
	TIME [epoch: 9.52 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7583942567578238		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 0.7583942567578238 | validation: 0.8283574433682723]
	TIME [epoch: 9.53 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7497811896156362		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 0.7497811896156362 | validation: 0.8395303940282779]
	TIME [epoch: 9.54 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8233588832695553		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 0.8233588832695553 | validation: 0.8722505316716277]
	TIME [epoch: 9.52 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7490198391020562		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 0.7490198391020562 | validation: 0.8221172168274847]
	TIME [epoch: 9.52 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7535024381489376		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 0.7535024381489376 | validation: 0.8185389206155702]
	TIME [epoch: 9.53 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7930027192516256		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 0.7930027192516256 | validation: 0.8454791157453547]
	TIME [epoch: 9.52 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7547941623846743		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 0.7547941623846743 | validation: 0.8515020972110667]
	TIME [epoch: 9.52 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7342927509345157		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 0.7342927509345157 | validation: 0.8953300973722498]
	TIME [epoch: 9.53 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7685036019744587		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 0.7685036019744587 | validation: 0.8973091373005224]
	TIME [epoch: 9.55 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7650296369113475		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 0.7650296369113475 | validation: 0.8391102758382576]
	TIME [epoch: 9.53 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.760983672674725		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 0.760983672674725 | validation: 0.8563254853091153]
	TIME [epoch: 9.53 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7645131745789345		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 0.7645131745789345 | validation: 0.840318746469049]
	TIME [epoch: 9.54 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7638561495788374		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 0.7638561495788374 | validation: 0.8560588005054246]
	TIME [epoch: 9.54 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7375994239688499		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 0.7375994239688499 | validation: 0.8151094786902808]
	TIME [epoch: 9.52 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7314768776582622		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 0.7314768776582622 | validation: 0.9096686741878136]
	TIME [epoch: 9.54 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.785249509392928		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 0.785249509392928 | validation: 0.8747749174258382]
	TIME [epoch: 9.52 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7429642904272659		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 0.7429642904272659 | validation: 0.8852761551451468]
	TIME [epoch: 9.53 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7490708474891414		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 0.7490708474891414 | validation: 0.8265348933632257]
	TIME [epoch: 9.52 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7415787493882201		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 0.7415787493882201 | validation: 0.8183515667857924]
	TIME [epoch: 9.54 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7424844620963824		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 0.7424844620963824 | validation: 0.8291460941891695]
	TIME [epoch: 9.53 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7319870775446125		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 0.7319870775446125 | validation: 0.9101899361902411]
	TIME [epoch: 9.52 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7637385076596803		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 0.7637385076596803 | validation: 0.9178013285323303]
	TIME [epoch: 9.54 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.752310196282584		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 0.752310196282584 | validation: 0.8280504642998746]
	TIME [epoch: 9.53 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7354502241053489		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 0.7354502241053489 | validation: 0.814019960264049]
	TIME [epoch: 9.52 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7411054067180519		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 0.7411054067180519 | validation: 0.8340551654798588]
	TIME [epoch: 9.52 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7504267057086169		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 0.7504267057086169 | validation: 0.8123934191831635]
	TIME [epoch: 9.55 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7428156381228638		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 0.7428156381228638 | validation: 0.8696997087173282]
	TIME [epoch: 9.52 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7747836779217945		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 0.7747836779217945 | validation: 0.8456540060760969]
	TIME [epoch: 9.53 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7464781150506204		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 0.7464781150506204 | validation: 0.8642867936811522]
	TIME [epoch: 9.54 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7369025822335782		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 0.7369025822335782 | validation: 0.8123130911381179]
	TIME [epoch: 9.54 sec]
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.755715617146975		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 0.755715617146975 | validation: 0.8161810618490697]
	TIME [epoch: 9.51 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7377619650313715		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 0.7377619650313715 | validation: 0.8341047108781134]
	TIME [epoch: 9.53 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7425439513418534		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 0.7425439513418534 | validation: 0.8123407673505159]
	TIME [epoch: 9.54 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7540255190796835		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 0.7540255190796835 | validation: 0.8226724352247408]
	TIME [epoch: 9.52 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.743647898863429		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 0.743647898863429 | validation: 0.8250353927266763]
	TIME [epoch: 9.52 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7666973548699768		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 0.7666973548699768 | validation: 0.8118318206174878]
	TIME [epoch: 9.54 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7523015661929591		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 0.7523015661929591 | validation: 0.8351123556297212]
	TIME [epoch: 9.53 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.746835806662282		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 0.746835806662282 | validation: 0.8078155264974555]
	TIME [epoch: 9.54 sec]
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7559616976957901		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 0.7559616976957901 | validation: 0.8664768752362079]
	TIME [epoch: 9.52 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7504099047227807		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 0.7504099047227807 | validation: 0.8512795975164593]
	TIME [epoch: 9.56 sec]
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7525366886413871		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 0.7525366886413871 | validation: 0.8273676782761606]
	TIME [epoch: 9.52 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8103470189321149		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 0.8103470189321149 | validation: 0.9011933996191394]
	TIME [epoch: 9.54 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7572476473780906		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 0.7572476473780906 | validation: 0.8019195047042255]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_853.pth
	Model improved!!!
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7424397129386584		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 0.7424397129386584 | validation: 0.8888286417137472]
	TIME [epoch: 9.54 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.8311655610940949		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 0.8311655610940949 | validation: 0.8838319582852222]
	TIME [epoch: 9.52 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7690631762256721		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 0.7690631762256721 | validation: 0.84090047111815]
	TIME [epoch: 9.53 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7637173477633155		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 0.7637173477633155 | validation: 0.9044925101432517]
	TIME [epoch: 9.54 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7332986974326994		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 0.7332986974326994 | validation: 0.8391804978324262]
	TIME [epoch: 9.53 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7717743282451159		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 0.7717743282451159 | validation: 0.816423966080615]
	TIME [epoch: 9.53 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7507787297040647		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 0.7507787297040647 | validation: 0.8286641553603165]
	TIME [epoch: 9.55 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7334186524766524		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 0.7334186524766524 | validation: 0.8696488132973216]
	TIME [epoch: 9.54 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7240769375919609		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 0.7240769375919609 | validation: 0.8599928304053687]
	TIME [epoch: 9.54 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.737787005579823		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 0.737787005579823 | validation: 0.8697816695073933]
	TIME [epoch: 9.53 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.763134463196221		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 0.763134463196221 | validation: 0.8398023586279608]
	TIME [epoch: 9.56 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7334878281774312		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 0.7334878281774312 | validation: 0.8376481551338781]
	TIME [epoch: 9.52 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7405288654150711		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 0.7405288654150711 | validation: 0.812739612710208]
	TIME [epoch: 9.52 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7275808289721979		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 0.7275808289721979 | validation: 0.8273037215884768]
	TIME [epoch: 9.53 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7419335577977951		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 0.7419335577977951 | validation: 0.817122501278843]
	TIME [epoch: 9.52 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7426861503053113		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 0.7426861503053113 | validation: 0.7930483481658084]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_869.pth
	Model improved!!!
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7417252457859373		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 0.7417252457859373 | validation: 0.8582681402549668]
	TIME [epoch: 9.51 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7232361555878725		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 0.7232361555878725 | validation: 0.8095195443880003]
	TIME [epoch: 9.54 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7214060979187724		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 0.7214060979187724 | validation: 0.8106073921167106]
	TIME [epoch: 9.52 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7229539218663881		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 0.7229539218663881 | validation: 0.8237972483697431]
	TIME [epoch: 9.52 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7278459893276471		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 0.7278459893276471 | validation: 0.8623090777181828]
	TIME [epoch: 9.55 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7225222091472274		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 0.7225222091472274 | validation: 0.8161745256042224]
	TIME [epoch: 9.53 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7475478179186864		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 0.7475478179186864 | validation: 0.805488417836741]
	TIME [epoch: 9.53 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7562797349681839		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 0.7562797349681839 | validation: 0.8335867999684051]
	TIME [epoch: 9.52 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7179430579957672		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 0.7179430579957672 | validation: 0.860511411412314]
	TIME [epoch: 9.53 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7371368385138898		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 0.7371368385138898 | validation: 0.8029792605261168]
	TIME [epoch: 9.52 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7247180913723767		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 0.7247180913723767 | validation: 0.8687181726325459]
	TIME [epoch: 9.52 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7563277229876009		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 0.7563277229876009 | validation: 0.869097139850629]
	TIME [epoch: 9.54 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7370173889603581		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 0.7370173889603581 | validation: 0.909911152493122]
	TIME [epoch: 9.52 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7407235952220811		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 0.7407235952220811 | validation: 0.8528224037360884]
	TIME [epoch: 9.53 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7410909936627625		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 0.7410909936627625 | validation: 0.83898997462285]
	TIME [epoch: 9.52 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7297192836027303		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 0.7297192836027303 | validation: 0.8463339374018526]
	TIME [epoch: 9.55 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7531043740839409		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 0.7531043740839409 | validation: 0.8415966553909837]
	TIME [epoch: 9.52 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7400149487764724		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 0.7400149487764724 | validation: 0.8555929034264872]
	TIME [epoch: 9.52 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7328756692969851		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 0.7328756692969851 | validation: 0.7655519949373606]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_888.pth
	Model improved!!!
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7339331763702557		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 0.7339331763702557 | validation: 0.8351740823042676]
	TIME [epoch: 9.54 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.724925418808643		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 0.724925418808643 | validation: 0.8424013335551378]
	TIME [epoch: 9.52 sec]
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7200385089159853		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 0.7200385089159853 | validation: 0.8462929254150007]
	TIME [epoch: 9.54 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7076243728087288		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 0.7076243728087288 | validation: 0.7943662636146883]
	TIME [epoch: 9.54 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7440725458740827		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 0.7440725458740827 | validation: 0.7776163028331995]
	TIME [epoch: 9.52 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7351362860604073		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 0.7351362860604073 | validation: 0.816089272216503]
	TIME [epoch: 9.53 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7191147928492715		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 0.7191147928492715 | validation: 0.8079638952316316]
	TIME [epoch: 9.55 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7371227279576426		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 0.7371227279576426 | validation: 0.8175811277766484]
	TIME [epoch: 9.53 sec]
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7278115169919381		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 0.7278115169919381 | validation: 0.8156099572512185]
	TIME [epoch: 9.53 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7094007665256894		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 0.7094007665256894 | validation: 0.8855360786111781]
	TIME [epoch: 9.53 sec]
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.734430014130909		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 0.734430014130909 | validation: 0.8587967388268765]
	TIME [epoch: 9.54 sec]
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7311772914113314		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 0.7311772914113314 | validation: 0.829679787255783]
	TIME [epoch: 9.52 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7292237607485421		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 0.7292237607485421 | validation: 0.8136784739488665]
	TIME [epoch: 9.52 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7344055939657327		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 0.7344055939657327 | validation: 0.8306604669487788]
	TIME [epoch: 9.55 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7252465737066843		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 0.7252465737066843 | validation: 0.8009008323318912]
	TIME [epoch: 9.52 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7325195618034241		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 0.7325195618034241 | validation: 0.8709771814669034]
	TIME [epoch: 9.53 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7161458343074869		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 0.7161458343074869 | validation: 0.8138998062388265]
	TIME [epoch: 9.53 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7191016884683974		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 0.7191016884683974 | validation: 0.8424020797321714]
	TIME [epoch: 9.54 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.718824983905712		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 0.718824983905712 | validation: 0.8005877033795308]
	TIME [epoch: 9.52 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.735214572485291		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 0.735214572485291 | validation: 0.8319098482528764]
	TIME [epoch: 9.52 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7261124142120596		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 0.7261124142120596 | validation: 0.8112320056363634]
	TIME [epoch: 9.54 sec]
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7220713209793914		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 0.7220713209793914 | validation: 0.8341722886733299]
	TIME [epoch: 9.53 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7395766917148097		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 0.7395766917148097 | validation: 0.8021242927158204]
	TIME [epoch: 9.51 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7238552441966378		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 0.7238552441966378 | validation: 0.8188272933956253]
	TIME [epoch: 9.54 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7430982514022453		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 0.7430982514022453 | validation: 0.8239774285652848]
	TIME [epoch: 9.54 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7239304450252899		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 0.7239304450252899 | validation: 0.8035939173865353]
	TIME [epoch: 9.53 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.718587495602102		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 0.718587495602102 | validation: 0.8200688865676712]
	TIME [epoch: 9.52 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7149668268036207		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 0.7149668268036207 | validation: 0.8312785618892018]
	TIME [epoch: 9.55 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7170762846352163		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 0.7170762846352163 | validation: 0.7477260368618022]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240217_140926/states/model_tr_study6_917.pth
	Model improved!!!
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7163365994457017		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 0.7163365994457017 | validation: 0.7883713358160123]
	TIME [epoch: 9.52 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7128794188653524		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 0.7128794188653524 | validation: 0.7807146829147574]
	TIME [epoch: 9.54 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7181938860095463		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 0.7181938860095463 | validation: 0.78101699794535]
	TIME [epoch: 9.53 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7243912730115359		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 0.7243912730115359 | validation: 0.8048176896761358]
	TIME [epoch: 9.51 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7368562624598219		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 0.7368562624598219 | validation: 0.8153722687849891]
	TIME [epoch: 9.51 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.736571877117564		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 0.736571877117564 | validation: 0.7772324884527069]
	TIME [epoch: 9.55 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7326570230350146		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 0.7326570230350146 | validation: 0.8039935210687067]
	TIME [epoch: 9.52 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7160766584724702		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 0.7160766584724702 | validation: 0.7815716558946133]
	TIME [epoch: 9.52 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7093658153223689		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 0.7093658153223689 | validation: 0.8128194293270045]
	TIME [epoch: 9.54 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7179114908341894		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 0.7179114908341894 | validation: 0.7896148007877227]
	TIME [epoch: 9.52 sec]
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7111863745455251		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 0.7111863745455251 | validation: 0.8285331342316287]
	TIME [epoch: 9.51 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7395266650556691		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 0.7395266650556691 | validation: 0.7897878519005088]
	TIME [epoch: 9.52 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7141406330779752		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 0.7141406330779752 | validation: 0.8008258429727252]
	TIME [epoch: 9.54 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7114123869506676		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 0.7114123869506676 | validation: 0.7977051723656512]
	TIME [epoch: 9.52 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7279512505286296		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 0.7279512505286296 | validation: 0.7731160211663521]
	TIME [epoch: 9.52 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7254211385936712		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 0.7254211385936712 | validation: 0.7889571153024301]
	TIME [epoch: 9.53 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7150489994626593		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 0.7150489994626593 | validation: 0.8136680876596131]
	TIME [epoch: 9.52 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6966869059640859		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 0.6966869059640859 | validation: 0.7840411283171781]
	TIME [epoch: 9.52 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7158876685481614		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 0.7158876685481614 | validation: 0.8333081148802869]
	TIME [epoch: 9.52 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7259921573500969		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 0.7259921573500969 | validation: 0.777483936358469]
	TIME [epoch: 9.54 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7132930281324013		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 0.7132930281324013 | validation: 0.7972280622902826]
	TIME [epoch: 9.52 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7232664679164962		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 0.7232664679164962 | validation: 0.7926607928448124]
	TIME [epoch: 9.52 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7153540479881803		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 0.7153540479881803 | validation: 0.8183049482575584]
	TIME [epoch: 9.54 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7168926388120005		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 0.7168926388120005 | validation: 0.8238833913406219]
	TIME [epoch: 9.52 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.722096482610176		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 0.722096482610176 | validation: 0.8504765858867347]
	TIME [epoch: 9.52 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7092458730145574		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 0.7092458730145574 | validation: 0.8086824540412028]
	TIME [epoch: 9.51 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7240933051587063		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 0.7240933051587063 | validation: 0.7769688032765005]
	TIME [epoch: 9.54 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7102340533491258		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 0.7102340533491258 | validation: 0.7909425164439771]
	TIME [epoch: 9.51 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7114073377956814		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 0.7114073377956814 | validation: 0.7840786286625181]
	TIME [epoch: 9.52 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7054308561806254		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 0.7054308561806254 | validation: 0.8121180600523414]
	TIME [epoch: 9.54 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7023826734565635		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 0.7023826734565635 | validation: 0.8412677711894734]
	TIME [epoch: 9.52 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.716482517562387		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 0.716482517562387 | validation: 0.7677195284095205]
	TIME [epoch: 9.52 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7179276788644052		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 0.7179276788644052 | validation: 0.7829932192556281]
	TIME [epoch: 9.52 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.714034564606575		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 0.714034564606575 | validation: 0.7909260455735319]
	TIME [epoch: 9.56 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7138990328148036		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 0.7138990328148036 | validation: 0.8038863246282888]
	TIME [epoch: 9.51 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7025121089600643		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 0.7025121089600643 | validation: 0.7685981994173612]
	TIME [epoch: 9.52 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7161204008751633		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 0.7161204008751633 | validation: 0.7947217151530552]
	TIME [epoch: 9.54 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6976383183905849		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 0.6976383183905849 | validation: 0.8172751178344103]
	TIME [epoch: 9.52 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7185704109191697		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 0.7185704109191697 | validation: 0.7805565724626378]
	TIME [epoch: 9.51 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7038541264706892		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 0.7038541264706892 | validation: 0.8010196730856356]
	TIME [epoch: 9.5 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6958796638519391		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 0.6958796638519391 | validation: 0.8144761107752754]
	TIME [epoch: 9.55 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.69292876914847		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 0.69292876914847 | validation: 0.7856436398423604]
	TIME [epoch: 9.52 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7213079300539047		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 0.7213079300539047 | validation: 0.7743736622183619]
	TIME [epoch: 9.51 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7127943449746084		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 0.7127943449746084 | validation: 0.7581909396699914]
	TIME [epoch: 9.53 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7014040724655606		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 0.7014040724655606 | validation: 0.806772012621347]
	TIME [epoch: 9.52 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7290524056538769		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 0.7290524056538769 | validation: 0.7718758734225278]
	TIME [epoch: 9.52 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7004024885840143		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 0.7004024885840143 | validation: 0.8032204352956849]
	TIME [epoch: 9.51 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7158930384704935		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 0.7158930384704935 | validation: 0.8042636820172422]
	TIME [epoch: 9.53 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7012870576214889		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 0.7012870576214889 | validation: 0.7691343248753377]
	TIME [epoch: 9.51 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7075146866092771		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 0.7075146866092771 | validation: 0.8553623575252948]
	TIME [epoch: 9.53 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7143125395357257		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 0.7143125395357257 | validation: 0.7917958449829289]
	TIME [epoch: 9.56 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7170186530440024		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 0.7170186530440024 | validation: 0.8037937720460321]
	TIME [epoch: 9.52 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6907228771553215		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 0.6907228771553215 | validation: 0.7932658806079497]
	TIME [epoch: 9.52 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7075641804674346		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 0.7075641804674346 | validation: 0.7587418734799495]
	TIME [epoch: 9.52 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6891767161808292		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 0.6891767161808292 | validation: 0.7521641171573297]
	TIME [epoch: 9.54 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7031374845372171		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 0.7031374845372171 | validation: 0.7890962640562289]
	TIME [epoch: 9.52 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7089286840487168		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 0.7089286840487168 | validation: 0.7952428343329728]
	TIME [epoch: 9.52 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7123654930203672		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 0.7123654930203672 | validation: 0.7983507761314348]
	TIME [epoch: 9.55 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7176784896169421		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 0.7176784896169421 | validation: 0.8192079674954189]
	TIME [epoch: 9.53 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7069949178141384		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 0.7069949178141384 | validation: 0.7907798554051916]
	TIME [epoch: 9.52 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6928469944524516		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 0.6928469944524516 | validation: 0.8057235184539687]
	TIME [epoch: 9.52 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6879796295621189		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 0.6879796295621189 | validation: 0.7884324612710156]
	TIME [epoch: 9.53 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7103899684136377		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 0.7103899684136377 | validation: 0.8170562561099288]
	TIME [epoch: 9.51 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7006310493155162		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 0.7006310493155162 | validation: 0.7807052998220048]
	TIME [epoch: 9.52 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.694546896751229		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 0.694546896751229 | validation: 0.7902807052258533]
	TIME [epoch: 9.54 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6952465566048589		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 0.6952465566048589 | validation: 0.7867329446034781]
	TIME [epoch: 9.53 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.69809471262208		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 0.69809471262208 | validation: 0.8057022251937612]
	TIME [epoch: 9.52 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7107172991590162		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 0.7107172991590162 | validation: 0.8250485131478693]
	TIME [epoch: 9.52 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6994219278264238		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 0.6994219278264238 | validation: 0.7945676644278054]
	TIME [epoch: 9.56 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6994484768762512		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 0.6994484768762512 | validation: 0.8215107859802645]
	TIME [epoch: 9.52 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7099563434093612		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 0.7099563434093612 | validation: 0.8198140503732334]
	TIME [epoch: 9.52 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7088542847825708		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 0.7088542847825708 | validation: 0.8156832337200605]
	TIME [epoch: 9.53 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7040813220442285		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 0.7040813220442285 | validation: 0.7906488668788632]
	TIME [epoch: 9.53 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7139410493659883		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 0.7139410493659883 | validation: 0.7514495244069143]
	TIME [epoch: 9.52 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6991899858453368		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 0.6991899858453368 | validation: 0.8131223862179551]
	TIME [epoch: 9.52 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6937461446805839		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 0.6937461446805839 | validation: 0.7756708631851079]
	TIME [epoch: 9.54 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7004017682286013		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 0.7004017682286013 | validation: 0.7753754546896647]
	TIME [epoch: 9.52 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6925757496014552		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 0.6925757496014552 | validation: 0.773363308407456]
	TIME [epoch: 9.51 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7084734997379024		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 0.7084734997379024 | validation: 0.7865672977424443]
	TIME [epoch: 9.54 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6896106610366605		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 0.6896106610366605 | validation: 0.7807363677251488]
	TIME [epoch: 9.52 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.7137287955830762		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 0.7137287955830762 | validation: 0.7641084250578354]
	TIME [epoch: 9.52 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6866875376319256		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 0.6866875376319256 | validation: 0.748688000714698]
	TIME [epoch: 9.52 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 0.6913956813978219		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 0.6913956813978219 | validation: 0.7655576466758609]
	TIME [epoch: 9.54 sec]
Finished training in 9648.833 seconds.
