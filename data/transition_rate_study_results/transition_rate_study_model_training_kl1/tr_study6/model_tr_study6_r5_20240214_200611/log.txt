Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r5', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r5', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 2675578569

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 5/5] avg loss: 8.615742436080268		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.615742436080268 | validation: 10.4087325275242]
	TIME [epoch: 49.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 5/5] avg loss: 8.781642344471019		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.781642344471019 | validation: 6.7042854931968865]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 5/5] avg loss: 6.755762932716044		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.755762932716044 | validation: 6.544680997296432]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 5/5] avg loss: 6.488392471934112		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.488392471934112 | validation: 6.10491673350921]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/500:
	Training over batches...
		[batch 5/5] avg loss: 6.119230168531789		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.119230168531789 | validation: 5.740068041129649]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 5/5] avg loss: 6.221719776806484		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.221719776806484 | validation: 6.000678984054264]
	TIME [epoch: 10.2 sec]
EPOCH 7/500:
	Training over batches...
		[batch 5/5] avg loss: 5.955198823362047		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.955198823362047 | validation: 5.717735337989949]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 5/5] avg loss: 5.614843165242936		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.614843165242936 | validation: 5.094541889728762]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 5/5] avg loss: 5.488191442802222		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.488191442802222 | validation: 5.655088046208591]
	TIME [epoch: 10.2 sec]
EPOCH 10/500:
	Training over batches...
		[batch 5/5] avg loss: 5.620772433985511		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.620772433985511 | validation: 5.733332721000188]
	TIME [epoch: 10.3 sec]
EPOCH 11/500:
	Training over batches...
		[batch 5/5] avg loss: 5.27214196132377		[learning rate: 0.0099625]
	Learning Rate: 0.00996248
	LOSS [training: 5.27214196132377 | validation: 6.079059820527696]
	TIME [epoch: 10.2 sec]
EPOCH 12/500:
	Training over batches...
		[batch 5/5] avg loss: 5.3313544635805785		[learning rate: 0.0099158]
	Learning Rate: 0.00991577
	LOSS [training: 5.3313544635805785 | validation: 5.203986145700508]
	TIME [epoch: 10.3 sec]
EPOCH 13/500:
	Training over batches...
		[batch 5/5] avg loss: 5.375469209098396		[learning rate: 0.0098693]
	Learning Rate: 0.00986928
	LOSS [training: 5.375469209098396 | validation: 4.622453554281675]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 5/5] avg loss: 4.655237341584643		[learning rate: 0.009823]
	Learning Rate: 0.00982302
	LOSS [training: 4.655237341584643 | validation: 4.5037569002328075]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 5/5] avg loss: 4.4248271812770295		[learning rate: 0.009777]
	Learning Rate: 0.00977696
	LOSS [training: 4.4248271812770295 | validation: 4.293881033032862]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 5/5] avg loss: 4.241908313474403		[learning rate: 0.0097311]
	Learning Rate: 0.00973113
	LOSS [training: 4.241908313474403 | validation: 4.231483669754837]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 5/5] avg loss: 4.02693484488615		[learning rate: 0.0096855]
	Learning Rate: 0.00968551
	LOSS [training: 4.02693484488615 | validation: 4.385701089217315]
	TIME [epoch: 10.2 sec]
EPOCH 18/500:
	Training over batches...
		[batch 5/5] avg loss: 4.088936267586379		[learning rate: 0.0096401]
	Learning Rate: 0.0096401
	LOSS [training: 4.088936267586379 | validation: 4.085956740469943]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_18.pth
	Model improved!!!
EPOCH 19/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8769588690845658		[learning rate: 0.0095949]
	Learning Rate: 0.00959491
	LOSS [training: 3.8769588690845658 | validation: 4.037723882699291]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/500:
	Training over batches...
		[batch 5/5] avg loss: 3.690473666487801		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 3.690473666487801 | validation: 3.915569365859672]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5404512239764045		[learning rate: 0.0095052]
	Learning Rate: 0.00950515
	LOSS [training: 3.5404512239764045 | validation: 3.601824208149087]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 5/5] avg loss: 4.101662791677113		[learning rate: 0.0094606]
	Learning Rate: 0.00946059
	LOSS [training: 4.101662791677113 | validation: 4.0926286597816715]
	TIME [epoch: 10.2 sec]
EPOCH 23/500:
	Training over batches...
		[batch 5/5] avg loss: 5.109510804048694		[learning rate: 0.0094162]
	Learning Rate: 0.00941624
	LOSS [training: 5.109510804048694 | validation: 4.416480946069479]
	TIME [epoch: 10.2 sec]
EPOCH 24/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7403871458958933		[learning rate: 0.0093721]
	Learning Rate: 0.0093721
	LOSS [training: 3.7403871458958933 | validation: 3.505099890727319]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4996007234725313		[learning rate: 0.0093282]
	Learning Rate: 0.00932816
	LOSS [training: 3.4996007234725313 | validation: 3.446447158569415]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_25.pth
	Model improved!!!
EPOCH 26/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4719403271454623		[learning rate: 0.0092844]
	Learning Rate: 0.00928443
	LOSS [training: 3.4719403271454623 | validation: 3.462532490463703]
	TIME [epoch: 10.2 sec]
EPOCH 27/500:
	Training over batches...
		[batch 5/5] avg loss: 3.989759692710971		[learning rate: 0.0092409]
	Learning Rate: 0.0092409
	LOSS [training: 3.989759692710971 | validation: 3.576514904358773]
	TIME [epoch: 10.3 sec]
EPOCH 28/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4642221739710584		[learning rate: 0.0091976]
	Learning Rate: 0.00919758
	LOSS [training: 3.4642221739710584 | validation: 3.3072651507114514]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_28.pth
	Model improved!!!
EPOCH 29/500:
	Training over batches...
		[batch 5/5] avg loss: 3.296357762202523		[learning rate: 0.0091545]
	Learning Rate: 0.00915446
	LOSS [training: 3.296357762202523 | validation: 3.354990480227908]
	TIME [epoch: 10.3 sec]
EPOCH 30/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5046688583939245		[learning rate: 0.0091115]
	Learning Rate: 0.00911154
	LOSS [training: 3.5046688583939245 | validation: 3.2966047289338123]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 5/5] avg loss: 3.167467126671867		[learning rate: 0.0090688]
	Learning Rate: 0.00906882
	LOSS [training: 3.167467126671867 | validation: 3.0994158609233224]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_31.pth
	Model improved!!!
EPOCH 32/500:
	Training over batches...
		[batch 5/5] avg loss: 3.100459134920636		[learning rate: 0.0090263]
	Learning Rate: 0.00902631
	LOSS [training: 3.100459134920636 | validation: 2.871484960704239]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_32.pth
	Model improved!!!
EPOCH 33/500:
	Training over batches...
		[batch 5/5] avg loss: 3.147937619855605		[learning rate: 0.008984]
	Learning Rate: 0.00898399
	LOSS [training: 3.147937619855605 | validation: 2.823119350462532]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_33.pth
	Model improved!!!
EPOCH 34/500:
	Training over batches...
		[batch 5/5] avg loss: 2.843481154768455		[learning rate: 0.0089419]
	Learning Rate: 0.00894187
	LOSS [training: 2.843481154768455 | validation: 2.955405039439256]
	TIME [epoch: 10.2 sec]
EPOCH 35/500:
	Training over batches...
		[batch 5/5] avg loss: 2.988353830886518		[learning rate: 0.0089]
	Learning Rate: 0.00889995
	LOSS [training: 2.988353830886518 | validation: 2.993414247293633]
	TIME [epoch: 10.3 sec]
EPOCH 36/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3362547809966605		[learning rate: 0.0088582]
	Learning Rate: 0.00885823
	LOSS [training: 3.3362547809966605 | validation: 3.6037539769614613]
	TIME [epoch: 10.3 sec]
EPOCH 37/500:
	Training over batches...
		[batch 5/5] avg loss: 4.95755608271117		[learning rate: 0.0088167]
	Learning Rate: 0.0088167
	LOSS [training: 4.95755608271117 | validation: 4.04870169738135]
	TIME [epoch: 10.2 sec]
EPOCH 38/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6482424877039996		[learning rate: 0.0087754]
	Learning Rate: 0.00877537
	LOSS [training: 3.6482424877039996 | validation: 3.266950918689158]
	TIME [epoch: 10.3 sec]
EPOCH 39/500:
	Training over batches...
		[batch 5/5] avg loss: 2.915670600560799		[learning rate: 0.0087342]
	Learning Rate: 0.00873423
	LOSS [training: 2.915670600560799 | validation: 3.495204327143515]
	TIME [epoch: 10.3 sec]
EPOCH 40/500:
	Training over batches...
		[batch 5/5] avg loss: 3.227698744097391		[learning rate: 0.0086933]
	Learning Rate: 0.00869328
	LOSS [training: 3.227698744097391 | validation: 2.7874858970748013]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 5/5] avg loss: 2.877142975453027		[learning rate: 0.0086525]
	Learning Rate: 0.00865253
	LOSS [training: 2.877142975453027 | validation: 3.4819504854897003]
	TIME [epoch: 10.3 sec]
EPOCH 42/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6082106069981945		[learning rate: 0.008612]
	Learning Rate: 0.00861196
	LOSS [training: 3.6082106069981945 | validation: 2.6753040204354286]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_42.pth
	Model improved!!!
EPOCH 43/500:
	Training over batches...
		[batch 5/5] avg loss: 2.930118529042987		[learning rate: 0.0085716]
	Learning Rate: 0.00857159
	LOSS [training: 2.930118529042987 | validation: 2.652097757715051]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_43.pth
	Model improved!!!
EPOCH 44/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6481929417978494		[learning rate: 0.0085314]
	Learning Rate: 0.0085314
	LOSS [training: 2.6481929417978494 | validation: 2.682425583266854]
	TIME [epoch: 10.3 sec]
EPOCH 45/500:
	Training over batches...
		[batch 5/5] avg loss: 3.629115140336655		[learning rate: 0.0084914]
	Learning Rate: 0.00849141
	LOSS [training: 3.629115140336655 | validation: 2.7671369905793948]
	TIME [epoch: 10.2 sec]
EPOCH 46/500:
	Training over batches...
		[batch 5/5] avg loss: 3.122338177550371		[learning rate: 0.0084516]
	Learning Rate: 0.0084516
	LOSS [training: 3.122338177550371 | validation: 2.6259356638168003]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3165457117685486		[learning rate: 0.008412]
	Learning Rate: 0.00841197
	LOSS [training: 3.3165457117685486 | validation: 3.0556590244949517]
	TIME [epoch: 10.3 sec]
EPOCH 48/500:
	Training over batches...
		[batch 5/5] avg loss: 3.514849375253847		[learning rate: 0.0083725]
	Learning Rate: 0.00837254
	LOSS [training: 3.514849375253847 | validation: 2.807572560926898]
	TIME [epoch: 10.3 sec]
EPOCH 49/500:
	Training over batches...
		[batch 5/5] avg loss: 2.943957251716189		[learning rate: 0.0083333]
	Learning Rate: 0.00833329
	LOSS [training: 2.943957251716189 | validation: 2.88734985653457]
	TIME [epoch: 10.3 sec]
EPOCH 50/500:
	Training over batches...
		[batch 5/5] avg loss: 3.046131240073708		[learning rate: 0.0082942]
	Learning Rate: 0.00829422
	LOSS [training: 3.046131240073708 | validation: 2.6662340812080743]
	TIME [epoch: 10.3 sec]
EPOCH 51/500:
	Training over batches...
		[batch 5/5] avg loss: 3.341044344414488		[learning rate: 0.0082553]
	Learning Rate: 0.00825533
	LOSS [training: 3.341044344414488 | validation: 2.5194377994668793]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_51.pth
	Model improved!!!
EPOCH 52/500:
	Training over batches...
		[batch 5/5] avg loss: 3.072061441217735		[learning rate: 0.0082166]
	Learning Rate: 0.00821663
	LOSS [training: 3.072061441217735 | validation: 5.0134620481612]
	TIME [epoch: 10.3 sec]
EPOCH 53/500:
	Training over batches...
		[batch 5/5] avg loss: 4.385759517744669		[learning rate: 0.0081781]
	Learning Rate: 0.00817811
	LOSS [training: 4.385759517744669 | validation: 4.375654881828724]
	TIME [epoch: 10.3 sec]
EPOCH 54/500:
	Training over batches...
		[batch 5/5] avg loss: 4.20876871785214		[learning rate: 0.0081398]
	Learning Rate: 0.00813977
	LOSS [training: 4.20876871785214 | validation: 2.584400233244436]
	TIME [epoch: 10.3 sec]
EPOCH 55/500:
	Training over batches...
		[batch 5/5] avg loss: 3.179846564514377		[learning rate: 0.0081016]
	Learning Rate: 0.00810161
	LOSS [training: 3.179846564514377 | validation: 2.8458234264566262]
	TIME [epoch: 10.3 sec]
EPOCH 56/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2008679108105476		[learning rate: 0.0080636]
	Learning Rate: 0.00806363
	LOSS [training: 3.2008679108105476 | validation: 3.4080152092839655]
	TIME [epoch: 10.3 sec]
EPOCH 57/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6519413919346455		[learning rate: 0.0080258]
	Learning Rate: 0.00802583
	LOSS [training: 3.6519413919346455 | validation: 3.8698299564699505]
	TIME [epoch: 10.3 sec]
EPOCH 58/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8819653307522537		[learning rate: 0.0079882]
	Learning Rate: 0.0079882
	LOSS [training: 3.8819653307522537 | validation: 2.9545041463004877]
	TIME [epoch: 10.3 sec]
EPOCH 59/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7153614492248503		[learning rate: 0.0079508]
	Learning Rate: 0.00795075
	LOSS [training: 2.7153614492248503 | validation: 3.069168084402107]
	TIME [epoch: 10.3 sec]
EPOCH 60/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6672151553734693		[learning rate: 0.0079135]
	Learning Rate: 0.00791348
	LOSS [training: 2.6672151553734693 | validation: 2.34617415565362]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_60.pth
	Model improved!!!
EPOCH 61/500:
	Training over batches...
		[batch 5/5] avg loss: 3.385575866939355		[learning rate: 0.0078764]
	Learning Rate: 0.00787638
	LOSS [training: 3.385575866939355 | validation: 3.0693658815917217]
	TIME [epoch: 10.3 sec]
EPOCH 62/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8741823800509296		[learning rate: 0.0078395]
	Learning Rate: 0.00783945
	LOSS [training: 3.8741823800509296 | validation: 3.1341138818177146]
	TIME [epoch: 10.3 sec]
EPOCH 63/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4779651516485757		[learning rate: 0.0078027]
	Learning Rate: 0.0078027
	LOSS [training: 3.4779651516485757 | validation: 3.61849498191571]
	TIME [epoch: 10.3 sec]
EPOCH 64/500:
	Training over batches...
		[batch 5/5] avg loss: 4.065335627791585		[learning rate: 0.0077661]
	Learning Rate: 0.00776612
	LOSS [training: 4.065335627791585 | validation: 3.269236445707703]
	TIME [epoch: 10.3 sec]
EPOCH 65/500:
	Training over batches...
		[batch 5/5] avg loss: 4.166982269833161		[learning rate: 0.0077297]
	Learning Rate: 0.00772971
	LOSS [training: 4.166982269833161 | validation: 4.652392663783407]
	TIME [epoch: 10.3 sec]
EPOCH 66/500:
	Training over batches...
		[batch 5/5] avg loss: 4.573313878202781		[learning rate: 0.0076935]
	Learning Rate: 0.00769347
	LOSS [training: 4.573313878202781 | validation: 2.8986291414174317]
	TIME [epoch: 10.3 sec]
EPOCH 67/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9730451948702084		[learning rate: 0.0076574]
	Learning Rate: 0.0076574
	LOSS [training: 2.9730451948702084 | validation: 2.658769361631944]
	TIME [epoch: 10.3 sec]
EPOCH 68/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8172674877546102		[learning rate: 0.0076215]
	Learning Rate: 0.00762151
	LOSS [training: 2.8172674877546102 | validation: 2.845750138147295]
	TIME [epoch: 10.3 sec]
EPOCH 69/500:
	Training over batches...
		[batch 5/5] avg loss: 2.731617361858574		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 2.731617361858574 | validation: 2.8374921330312532]
	TIME [epoch: 10.3 sec]
EPOCH 70/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5247163966375163		[learning rate: 0.0075502]
	Learning Rate: 0.00755021
	LOSS [training: 2.5247163966375163 | validation: 2.513494727390748]
	TIME [epoch: 10.3 sec]
EPOCH 71/500:
	Training over batches...
		[batch 5/5] avg loss: 2.457666448386684		[learning rate: 0.0075148]
	Learning Rate: 0.00751482
	LOSS [training: 2.457666448386684 | validation: 2.1560702804508316]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_71.pth
	Model improved!!!
EPOCH 72/500:
	Training over batches...
		[batch 5/5] avg loss: 2.2812516623408268		[learning rate: 0.0074796]
	Learning Rate: 0.00747959
	LOSS [training: 2.2812516623408268 | validation: 2.0217072784066996]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_72.pth
	Model improved!!!
EPOCH 73/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3102685727539756		[learning rate: 0.0074445]
	Learning Rate: 0.00744452
	LOSS [training: 2.3102685727539756 | validation: 2.810669507596019]
	TIME [epoch: 10.3 sec]
EPOCH 74/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7525602058154393		[learning rate: 0.0074096]
	Learning Rate: 0.00740962
	LOSS [training: 2.7525602058154393 | validation: 2.1221160627641127]
	TIME [epoch: 10.3 sec]
EPOCH 75/500:
	Training over batches...
		[batch 5/5] avg loss: 2.2490090423393565		[learning rate: 0.0073749]
	Learning Rate: 0.00737488
	LOSS [training: 2.2490090423393565 | validation: 1.8566460311758104]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0954132757879167		[learning rate: 0.0073403]
	Learning Rate: 0.00734031
	LOSS [training: 2.0954132757879167 | validation: 1.8608070692437166]
	TIME [epoch: 10.2 sec]
EPOCH 77/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7545765080800202		[learning rate: 0.0073059]
	Learning Rate: 0.00730589
	LOSS [training: 1.7545765080800202 | validation: 2.214975389162644]
	TIME [epoch: 10.3 sec]
EPOCH 78/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1031477745918155		[learning rate: 0.0072716]
	Learning Rate: 0.00727164
	LOSS [training: 2.1031477745918155 | validation: 1.9501566884506445]
	TIME [epoch: 10.3 sec]
EPOCH 79/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8863631505725713		[learning rate: 0.0072376]
	Learning Rate: 0.00723755
	LOSS [training: 1.8863631505725713 | validation: 1.8087908801155859]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 5/5] avg loss: 2.035330621131727		[learning rate: 0.0072036]
	Learning Rate: 0.00720362
	LOSS [training: 2.035330621131727 | validation: 2.7440942648673836]
	TIME [epoch: 10.2 sec]
EPOCH 81/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8645072756755936		[learning rate: 0.0071699]
	Learning Rate: 0.00716985
	LOSS [training: 1.8645072756755936 | validation: 5.191487096975289]
	TIME [epoch: 10.3 sec]
EPOCH 82/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3136992395166014		[learning rate: 0.0071362]
	Learning Rate: 0.00713624
	LOSS [training: 2.3136992395166014 | validation: 1.3553376674731323]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6220945244593097		[learning rate: 0.0071028]
	Learning Rate: 0.00710278
	LOSS [training: 1.6220945244593097 | validation: 1.8620351031312254]
	TIME [epoch: 10.3 sec]
EPOCH 84/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6414046186599556		[learning rate: 0.0070695]
	Learning Rate: 0.00706948
	LOSS [training: 1.6414046186599556 | validation: 2.0530398165163115]
	TIME [epoch: 10.3 sec]
EPOCH 85/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5248007842814193		[learning rate: 0.0070363]
	Learning Rate: 0.00703634
	LOSS [training: 1.5248007842814193 | validation: 1.2682644443438205]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_85.pth
	Model improved!!!
EPOCH 86/500:
	Training over batches...
		[batch 5/5] avg loss: 1.262921820423447		[learning rate: 0.0070034]
	Learning Rate: 0.00700335
	LOSS [training: 1.262921820423447 | validation: 1.5045153331772851]
	TIME [epoch: 10.3 sec]
EPOCH 87/500:
	Training over batches...
		[batch 5/5] avg loss: 1.999380530068524		[learning rate: 0.0069705]
	Learning Rate: 0.00697052
	LOSS [training: 1.999380530068524 | validation: 4.155875469158864]
	TIME [epoch: 10.3 sec]
EPOCH 88/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8261052838810141		[learning rate: 0.0069378]
	Learning Rate: 0.00693784
	LOSS [training: 1.8261052838810141 | validation: 3.135325992282598]
	TIME [epoch: 10.2 sec]
EPOCH 89/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6112345518604243		[learning rate: 0.0069053]
	Learning Rate: 0.00690532
	LOSS [training: 1.6112345518604243 | validation: 3.2012644251736972]
	TIME [epoch: 10.3 sec]
EPOCH 90/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7466532569694317		[learning rate: 0.0068729]
	Learning Rate: 0.00687294
	LOSS [training: 3.7466532569694317 | validation: 6.0879782999707945]
	TIME [epoch: 10.3 sec]
EPOCH 91/500:
	Training over batches...
		[batch 5/5] avg loss: 4.415010430054312		[learning rate: 0.0068407]
	Learning Rate: 0.00684072
	LOSS [training: 4.415010430054312 | validation: 3.0391110906100347]
	TIME [epoch: 10.3 sec]
EPOCH 92/500:
	Training over batches...
		[batch 5/5] avg loss: 3.390827504473274		[learning rate: 0.0068087]
	Learning Rate: 0.00680865
	LOSS [training: 3.390827504473274 | validation: 2.384760528208712]
	TIME [epoch: 10.3 sec]
EPOCH 93/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0505710833938484		[learning rate: 0.0067767]
	Learning Rate: 0.00677673
	LOSS [training: 3.0505710833938484 | validation: 2.0870682094080775]
	TIME [epoch: 10.3 sec]
EPOCH 94/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6208409242884394		[learning rate: 0.006745]
	Learning Rate: 0.00674496
	LOSS [training: 2.6208409242884394 | validation: 2.0297626907468587]
	TIME [epoch: 10.3 sec]
EPOCH 95/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8087936121471686		[learning rate: 0.0067133]
	Learning Rate: 0.00671334
	LOSS [training: 1.8087936121471686 | validation: 1.2093682203432858]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_95.pth
	Model improved!!!
EPOCH 96/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2100673823660435		[learning rate: 0.0066819]
	Learning Rate: 0.00668187
	LOSS [training: 1.2100673823660435 | validation: 2.2241088380916465]
	TIME [epoch: 10.3 sec]
EPOCH 97/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4123256047144543		[learning rate: 0.0066505]
	Learning Rate: 0.00665054
	LOSS [training: 1.4123256047144543 | validation: 2.018190713213507]
	TIME [epoch: 10.3 sec]
EPOCH 98/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2097116895039695		[learning rate: 0.0066194]
	Learning Rate: 0.00661936
	LOSS [training: 1.2097116895039695 | validation: 1.1084075776003417]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5644674271433892		[learning rate: 0.0065883]
	Learning Rate: 0.00658833
	LOSS [training: 1.5644674271433892 | validation: 1.5406175321941207]
	TIME [epoch: 10.3 sec]
EPOCH 100/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7570636056083067		[learning rate: 0.0065574]
	Learning Rate: 0.00655745
	LOSS [training: 1.7570636056083067 | validation: 2.22215202556827]
	TIME [epoch: 10.3 sec]
EPOCH 101/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5606122589828877		[learning rate: 0.0065267]
	Learning Rate: 0.0065267
	LOSS [training: 1.5606122589828877 | validation: 1.0286345223751512]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_101.pth
	Model improved!!!
EPOCH 102/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2796467515913794		[learning rate: 0.0064961]
	Learning Rate: 0.0064961
	LOSS [training: 1.2796467515913794 | validation: 1.1688729619823945]
	TIME [epoch: 10.3 sec]
EPOCH 103/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1071517686476904		[learning rate: 0.0064657]
	Learning Rate: 0.00646565
	LOSS [training: 3.1071517686476904 | validation: 2.0842763581021977]
	TIME [epoch: 10.3 sec]
EPOCH 104/500:
	Training over batches...
		[batch 5/5] avg loss: 1.734825164688757		[learning rate: 0.0064353]
	Learning Rate: 0.00643534
	LOSS [training: 1.734825164688757 | validation: 1.4289093521127232]
	TIME [epoch: 10.3 sec]
EPOCH 105/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3065612082915103		[learning rate: 0.0064052]
	Learning Rate: 0.00640517
	LOSS [training: 1.3065612082915103 | validation: 0.8581263972249787]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_105.pth
	Model improved!!!
EPOCH 106/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0548787434330844		[learning rate: 0.0063751]
	Learning Rate: 0.00637514
	LOSS [training: 1.0548787434330844 | validation: 1.1649895602488258]
	TIME [epoch: 10.3 sec]
EPOCH 107/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8064172982414073		[learning rate: 0.0063453]
	Learning Rate: 0.00634525
	LOSS [training: 2.8064172982414073 | validation: 2.5693629443201433]
	TIME [epoch: 10.3 sec]
EPOCH 108/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1417968559753193		[learning rate: 0.0063155]
	Learning Rate: 0.00631551
	LOSS [training: 2.1417968559753193 | validation: 2.1602995196887775]
	TIME [epoch: 10.3 sec]
EPOCH 109/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3858382405536562		[learning rate: 0.0062859]
	Learning Rate: 0.0062859
	LOSS [training: 1.3858382405536562 | validation: 1.2360751970169426]
	TIME [epoch: 10.3 sec]
EPOCH 110/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0848158816048374		[learning rate: 0.0062564]
	Learning Rate: 0.00625643
	LOSS [training: 1.0848158816048374 | validation: 1.0956860678131373]
	TIME [epoch: 10.3 sec]
EPOCH 111/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2692586110099586		[learning rate: 0.0062271]
	Learning Rate: 0.0062271
	LOSS [training: 1.2692586110099586 | validation: 1.1110730782754752]
	TIME [epoch: 10.3 sec]
EPOCH 112/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2958237350940913		[learning rate: 0.0061979]
	Learning Rate: 0.0061979
	LOSS [training: 1.2958237350940913 | validation: 1.5991686471623319]
	TIME [epoch: 10.3 sec]
EPOCH 113/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3713022849377103		[learning rate: 0.0061688]
	Learning Rate: 0.00616885
	LOSS [training: 1.3713022849377103 | validation: 1.185526499312951]
	TIME [epoch: 10.3 sec]
EPOCH 114/500:
	Training over batches...
		[batch 5/5] avg loss: 0.958540419618062		[learning rate: 0.0061399]
	Learning Rate: 0.00613993
	LOSS [training: 0.958540419618062 | validation: 1.4314905992986877]
	TIME [epoch: 10.3 sec]
EPOCH 115/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0500025398535435		[learning rate: 0.0061111]
	Learning Rate: 0.00611114
	LOSS [training: 1.0500025398535435 | validation: 0.8713731466896658]
	TIME [epoch: 10.3 sec]
EPOCH 116/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9638223122815326		[learning rate: 0.0060825]
	Learning Rate: 0.00608249
	LOSS [training: 0.9638223122815326 | validation: 0.9555915650409409]
	TIME [epoch: 10.3 sec]
EPOCH 117/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1518379541709964		[learning rate: 0.006054]
	Learning Rate: 0.00605398
	LOSS [training: 1.1518379541709964 | validation: 1.117623848407636]
	TIME [epoch: 10.3 sec]
EPOCH 118/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9181996564192925		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 0.9181996564192925 | validation: 1.7541966775748814]
	TIME [epoch: 10.3 sec]
EPOCH 119/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6699487948747282		[learning rate: 0.0059973]
	Learning Rate: 0.00599735
	LOSS [training: 1.6699487948747282 | validation: 1.3038466213034428]
	TIME [epoch: 10.3 sec]
EPOCH 120/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8168359360891038		[learning rate: 0.0059692]
	Learning Rate: 0.00596923
	LOSS [training: 1.8168359360891038 | validation: 1.7242837153487767]
	TIME [epoch: 10.3 sec]
EPOCH 121/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5204858969769461		[learning rate: 0.0059412]
	Learning Rate: 0.00594125
	LOSS [training: 1.5204858969769461 | validation: 1.2636471492359636]
	TIME [epoch: 10.3 sec]
EPOCH 122/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1538918059048338		[learning rate: 0.0059134]
	Learning Rate: 0.00591339
	LOSS [training: 1.1538918059048338 | validation: 1.093548925021667]
	TIME [epoch: 10.3 sec]
EPOCH 123/500:
	Training over batches...
		[batch 5/5] avg loss: 0.935539994881838		[learning rate: 0.0058857]
	Learning Rate: 0.00588567
	LOSS [training: 0.935539994881838 | validation: 2.0551928426213575]
	TIME [epoch: 10.3 sec]
EPOCH 124/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2567001932999837		[learning rate: 0.0058581]
	Learning Rate: 0.00585808
	LOSS [training: 1.2567001932999837 | validation: 1.0673680893479545]
	TIME [epoch: 10.3 sec]
EPOCH 125/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9131294487430264		[learning rate: 0.0058306]
	Learning Rate: 0.00583061
	LOSS [training: 0.9131294487430264 | validation: 0.9021505292985731]
	TIME [epoch: 10.3 sec]
EPOCH 126/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8088242986498558		[learning rate: 0.0058033]
	Learning Rate: 0.00580328
	LOSS [training: 0.8088242986498558 | validation: 0.8221486222025043]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_126.pth
	Model improved!!!
EPOCH 127/500:
	Training over batches...
		[batch 5/5] avg loss: 0.971790769992819		[learning rate: 0.0057761]
	Learning Rate: 0.00577607
	LOSS [training: 0.971790769992819 | validation: 0.7741238989086844]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_127.pth
	Model improved!!!
EPOCH 128/500:
	Training over batches...
		[batch 5/5] avg loss: 1.274147706413368		[learning rate: 0.005749]
	Learning Rate: 0.00574899
	LOSS [training: 1.274147706413368 | validation: 1.348370873656006]
	TIME [epoch: 10.3 sec]
EPOCH 129/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0892004169828475		[learning rate: 0.005722]
	Learning Rate: 0.00572204
	LOSS [training: 1.0892004169828475 | validation: 1.0616600579687567]
	TIME [epoch: 10.3 sec]
EPOCH 130/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0111003928464464		[learning rate: 0.0056952]
	Learning Rate: 0.00569522
	LOSS [training: 1.0111003928464464 | validation: 1.0074113162613563]
	TIME [epoch: 10.3 sec]
EPOCH 131/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0247437219290387		[learning rate: 0.0056685]
	Learning Rate: 0.00566852
	LOSS [training: 1.0247437219290387 | validation: 2.0831330344633154]
	TIME [epoch: 10.3 sec]
EPOCH 132/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3488026002611417		[learning rate: 0.0056419]
	Learning Rate: 0.00564194
	LOSS [training: 1.3488026002611417 | validation: 1.0455397473578065]
	TIME [epoch: 10.2 sec]
EPOCH 133/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0133914391854735		[learning rate: 0.0056155]
	Learning Rate: 0.00561549
	LOSS [training: 1.0133914391854735 | validation: 0.9928653617367581]
	TIME [epoch: 10.2 sec]
EPOCH 134/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8068603242942867		[learning rate: 0.0055892]
	Learning Rate: 0.00558916
	LOSS [training: 0.8068603242942867 | validation: 1.0633976210956184]
	TIME [epoch: 10.2 sec]
EPOCH 135/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8554393827528429		[learning rate: 0.005563]
	Learning Rate: 0.00556296
	LOSS [training: 0.8554393827528429 | validation: 0.9907233583051945]
	TIME [epoch: 10.3 sec]
EPOCH 136/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9456799725953248		[learning rate: 0.0055369]
	Learning Rate: 0.00553688
	LOSS [training: 0.9456799725953248 | validation: 1.6655180934719769]
	TIME [epoch: 10.3 sec]
EPOCH 137/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1054641547280464		[learning rate: 0.0055109]
	Learning Rate: 0.00551092
	LOSS [training: 2.1054641547280464 | validation: 2.749837870040943]
	TIME [epoch: 10.3 sec]
EPOCH 138/500:
	Training over batches...
		[batch 5/5] avg loss: 3.715937403749833		[learning rate: 0.0054851]
	Learning Rate: 0.00548509
	LOSS [training: 3.715937403749833 | validation: 2.7847360242338834]
	TIME [epoch: 10.3 sec]
EPOCH 139/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5765408515488017		[learning rate: 0.0054594]
	Learning Rate: 0.00545937
	LOSS [training: 3.5765408515488017 | validation: 3.1262859234955123]
	TIME [epoch: 10.3 sec]
EPOCH 140/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6239325809433773		[learning rate: 0.0054338]
	Learning Rate: 0.00543378
	LOSS [training: 3.6239325809433773 | validation: 2.777684584690843]
	TIME [epoch: 10.3 sec]
EPOCH 141/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2089245972078366		[learning rate: 0.0054083]
	Learning Rate: 0.00540831
	LOSS [training: 3.2089245972078366 | validation: 2.4751416137295585]
	TIME [epoch: 10.3 sec]
EPOCH 142/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1060394357038317		[learning rate: 0.005383]
	Learning Rate: 0.00538295
	LOSS [training: 3.1060394357038317 | validation: 2.652069379896312]
	TIME [epoch: 10.3 sec]
EPOCH 143/500:
	Training over batches...
		[batch 5/5] avg loss: 4.032094738056312		[learning rate: 0.0053577]
	Learning Rate: 0.00535771
	LOSS [training: 4.032094738056312 | validation: 3.8084761080202045]
	TIME [epoch: 10.3 sec]
EPOCH 144/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3556136076485146		[learning rate: 0.0053326]
	Learning Rate: 0.0053326
	LOSS [training: 3.3556136076485146 | validation: 2.5253678729158753]
	TIME [epoch: 10.3 sec]
EPOCH 145/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0648870606120777		[learning rate: 0.0053076]
	Learning Rate: 0.0053076
	LOSS [training: 3.0648870606120777 | validation: 2.2796829298061865]
	TIME [epoch: 10.3 sec]
EPOCH 146/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8731952171492985		[learning rate: 0.0052827]
	Learning Rate: 0.00528271
	LOSS [training: 2.8731952171492985 | validation: 2.442994384719024]
	TIME [epoch: 10.2 sec]
EPOCH 147/500:
	Training over batches...
		[batch 5/5] avg loss: 3.146659018336063		[learning rate: 0.0052579]
	Learning Rate: 0.00525795
	LOSS [training: 3.146659018336063 | validation: 3.0820053320010823]
	TIME [epoch: 10.3 sec]
EPOCH 148/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4883747384841035		[learning rate: 0.0052333]
	Learning Rate: 0.0052333
	LOSS [training: 3.4883747384841035 | validation: 2.7054542146740412]
	TIME [epoch: 10.3 sec]
EPOCH 149/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2369803407385205		[learning rate: 0.0052088]
	Learning Rate: 0.00520876
	LOSS [training: 3.2369803407385205 | validation: 2.8279498290034613]
	TIME [epoch: 10.2 sec]
EPOCH 150/500:
	Training over batches...
		[batch 5/5] avg loss: 3.452794940308273		[learning rate: 0.0051843]
	Learning Rate: 0.00518434
	LOSS [training: 3.452794940308273 | validation: 2.5145840602840814]
	TIME [epoch: 10.3 sec]
EPOCH 151/500:
	Training over batches...
		[batch 5/5] avg loss: 3.107108147149135		[learning rate: 0.00516]
	Learning Rate: 0.00516004
	LOSS [training: 3.107108147149135 | validation: 2.447166463440772]
	TIME [epoch: 10.3 sec]
EPOCH 152/500:
	Training over batches...
		[batch 5/5] avg loss: 3.111584268915391		[learning rate: 0.0051358]
	Learning Rate: 0.00513585
	LOSS [training: 3.111584268915391 | validation: 2.493744287141387]
	TIME [epoch: 10.3 sec]
EPOCH 153/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9984976782899553		[learning rate: 0.0051118]
	Learning Rate: 0.00511177
	LOSS [training: 2.9984976782899553 | validation: 2.5345561143505164]
	TIME [epoch: 10.2 sec]
EPOCH 154/500:
	Training over batches...
		[batch 5/5] avg loss: 3.040740587928897		[learning rate: 0.0050878]
	Learning Rate: 0.00508781
	LOSS [training: 3.040740587928897 | validation: 2.2388918006183425]
	TIME [epoch: 10.3 sec]
EPOCH 155/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7688111564222866		[learning rate: 0.005064]
	Learning Rate: 0.00506395
	LOSS [training: 2.7688111564222866 | validation: 2.0854820581889375]
	TIME [epoch: 10.3 sec]
EPOCH 156/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8887092752465406		[learning rate: 0.0050402]
	Learning Rate: 0.00504021
	LOSS [training: 2.8887092752465406 | validation: 2.143219133934465]
	TIME [epoch: 10.3 sec]
EPOCH 157/500:
	Training over batches...
		[batch 5/5] avg loss: 3.012346155551735		[learning rate: 0.0050166]
	Learning Rate: 0.00501658
	LOSS [training: 3.012346155551735 | validation: 2.926818421845431]
	TIME [epoch: 10.3 sec]
EPOCH 158/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7361738059386633		[learning rate: 0.0049931]
	Learning Rate: 0.00499307
	LOSS [training: 3.7361738059386633 | validation: 3.2973102451956944]
	TIME [epoch: 10.2 sec]
EPOCH 159/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8663345072264503		[learning rate: 0.0049697]
	Learning Rate: 0.00496966
	LOSS [training: 3.8663345072264503 | validation: 3.177761502513359]
	TIME [epoch: 10.3 sec]
EPOCH 160/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3749659551646993		[learning rate: 0.0049464]
	Learning Rate: 0.00494636
	LOSS [training: 3.3749659551646993 | validation: 2.4621907038571313]
	TIME [epoch: 10.3 sec]
EPOCH 161/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1699974704711593		[learning rate: 0.0049232]
	Learning Rate: 0.00492317
	LOSS [training: 3.1699974704711593 | validation: 2.7123737628299374]
	TIME [epoch: 10.3 sec]
EPOCH 162/500:
	Training over batches...
		[batch 5/5] avg loss: 3.543218389924848		[learning rate: 0.0049001]
	Learning Rate: 0.00490009
	LOSS [training: 3.543218389924848 | validation: 2.9175457025522666]
	TIME [epoch: 10.3 sec]
EPOCH 163/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4416165479613716		[learning rate: 0.0048771]
	Learning Rate: 0.00487712
	LOSS [training: 3.4416165479613716 | validation: 2.63235293732546]
	TIME [epoch: 10.2 sec]
EPOCH 164/500:
	Training over batches...
		[batch 5/5] avg loss: 3.352547910961822		[learning rate: 0.0048543]
	Learning Rate: 0.00485425
	LOSS [training: 3.352547910961822 | validation: 3.140717293772448]
	TIME [epoch: 10.3 sec]
EPOCH 165/500:
	Training over batches...
		[batch 5/5] avg loss: 3.976601559179737		[learning rate: 0.0048315]
	Learning Rate: 0.0048315
	LOSS [training: 3.976601559179737 | validation: 3.05051656252767]
	TIME [epoch: 10.3 sec]
EPOCH 166/500:
	Training over batches...
		[batch 5/5] avg loss: 3.712814307077707		[learning rate: 0.0048088]
	Learning Rate: 0.00480885
	LOSS [training: 3.712814307077707 | validation: 3.1044249032151665]
	TIME [epoch: 10.3 sec]
EPOCH 167/500:
	Training over batches...
		[batch 5/5] avg loss: 3.479981019615898		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 3.479981019615898 | validation: 2.7482849837819994]
	TIME [epoch: 10.3 sec]
EPOCH 168/500:
	Training over batches...
		[batch 5/5] avg loss: 3.288188964921612		[learning rate: 0.0047639]
	Learning Rate: 0.00476386
	LOSS [training: 3.288188964921612 | validation: 2.417486921462404]
	TIME [epoch: 10.3 sec]
EPOCH 169/500:
	Training over batches...
		[batch 5/5] avg loss: 3.09826412598287		[learning rate: 0.0047415]
	Learning Rate: 0.00474153
	LOSS [training: 3.09826412598287 | validation: 2.4604398314005915]
	TIME [epoch: 10.2 sec]
EPOCH 170/500:
	Training over batches...
		[batch 5/5] avg loss: 3.260237669356323		[learning rate: 0.0047193]
	Learning Rate: 0.0047193
	LOSS [training: 3.260237669356323 | validation: 2.912703105268069]
	TIME [epoch: 10.2 sec]
EPOCH 171/500:
	Training over batches...
		[batch 5/5] avg loss: 3.5515697117379608		[learning rate: 0.0046972]
	Learning Rate: 0.00469718
	LOSS [training: 3.5515697117379608 | validation: 2.692855378169932]
	TIME [epoch: 10.3 sec]
EPOCH 172/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1695630787507127		[learning rate: 0.0046752]
	Learning Rate: 0.00467515
	LOSS [training: 3.1695630787507127 | validation: 2.5220861344643293]
	TIME [epoch: 10.3 sec]
EPOCH 173/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0849439378206194		[learning rate: 0.0046532]
	Learning Rate: 0.00465324
	LOSS [training: 3.0849439378206194 | validation: 3.2421672412850264]
	TIME [epoch: 10.3 sec]
EPOCH 174/500:
	Training over batches...
		[batch 5/5] avg loss: 3.529864399446761		[learning rate: 0.0046314]
	Learning Rate: 0.00463142
	LOSS [training: 3.529864399446761 | validation: 2.4685372955476192]
	TIME [epoch: 10.3 sec]
EPOCH 175/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9434189145671983		[learning rate: 0.0046097]
	Learning Rate: 0.00460971
	LOSS [training: 2.9434189145671983 | validation: 2.9539772267606423]
	TIME [epoch: 10.3 sec]
EPOCH 176/500:
	Training over batches...
		[batch 5/5] avg loss: 3.592950903967784		[learning rate: 0.0045881]
	Learning Rate: 0.0045881
	LOSS [training: 3.592950903967784 | validation: 3.0982670458736044]
	TIME [epoch: 10.3 sec]
EPOCH 177/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6651872391102343		[learning rate: 0.0045666]
	Learning Rate: 0.00456659
	LOSS [training: 3.6651872391102343 | validation: 3.2479113240021547]
	TIME [epoch: 10.2 sec]
EPOCH 178/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7988771032052773		[learning rate: 0.0045452]
	Learning Rate: 0.00454518
	LOSS [training: 3.7988771032052773 | validation: 3.471198321952227]
	TIME [epoch: 10.3 sec]
EPOCH 179/500:
	Training over batches...
		[batch 5/5] avg loss: 3.676132450659621		[learning rate: 0.0045239]
	Learning Rate: 0.00452387
	LOSS [training: 3.676132450659621 | validation: 2.7440626709360236]
	TIME [epoch: 10.3 sec]
EPOCH 180/500:
	Training over batches...
		[batch 5/5] avg loss: 3.036928681259544		[learning rate: 0.0045027]
	Learning Rate: 0.00450266
	LOSS [training: 3.036928681259544 | validation: 3.0127822879296695]
	TIME [epoch: 10.3 sec]
EPOCH 181/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0057602999786903		[learning rate: 0.0044816]
	Learning Rate: 0.00448155
	LOSS [training: 3.0057602999786903 | validation: 2.1989859425396703]
	TIME [epoch: 10.3 sec]
EPOCH 182/500:
	Training over batches...
		[batch 5/5] avg loss: 2.740870284581395		[learning rate: 0.0044605]
	Learning Rate: 0.00446054
	LOSS [training: 2.740870284581395 | validation: 2.2720820694740014]
	TIME [epoch: 10.3 sec]
EPOCH 183/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9848940423407613		[learning rate: 0.0044396]
	Learning Rate: 0.00443963
	LOSS [training: 2.9848940423407613 | validation: 2.7875721865097978]
	TIME [epoch: 10.3 sec]
EPOCH 184/500:
	Training over batches...
		[batch 5/5] avg loss: 3.130653803084594		[learning rate: 0.0044188]
	Learning Rate: 0.00441882
	LOSS [training: 3.130653803084594 | validation: 2.429515103881943]
	TIME [epoch: 10.3 sec]
EPOCH 185/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6518039693594555		[learning rate: 0.0043981]
	Learning Rate: 0.0043981
	LOSS [training: 2.6518039693594555 | validation: 2.1721309894226666]
	TIME [epoch: 10.3 sec]
EPOCH 186/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6516959925991133		[learning rate: 0.0043775]
	Learning Rate: 0.00437748
	LOSS [training: 2.6516959925991133 | validation: 2.144790181207472]
	TIME [epoch: 10.3 sec]
EPOCH 187/500:
	Training over batches...
		[batch 5/5] avg loss: 2.643548972692948		[learning rate: 0.004357]
	Learning Rate: 0.00435696
	LOSS [training: 2.643548972692948 | validation: 2.3299396938025443]
	TIME [epoch: 10.3 sec]
EPOCH 188/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6175098475547105		[learning rate: 0.0043365]
	Learning Rate: 0.00433654
	LOSS [training: 2.6175098475547105 | validation: 2.230960070343224]
	TIME [epoch: 10.3 sec]
EPOCH 189/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9777483906230025		[learning rate: 0.0043162]
	Learning Rate: 0.0043162
	LOSS [training: 2.9777483906230025 | validation: 2.9906030036942775]
	TIME [epoch: 10.2 sec]
EPOCH 190/500:
	Training over batches...
		[batch 5/5] avg loss: 3.667406332402229		[learning rate: 0.004296]
	Learning Rate: 0.00429597
	LOSS [training: 3.667406332402229 | validation: 2.851391326113577]
	TIME [epoch: 10.3 sec]
EPOCH 191/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4721255395776476		[learning rate: 0.0042758]
	Learning Rate: 0.00427583
	LOSS [training: 3.4721255395776476 | validation: 2.8250640461364664]
	TIME [epoch: 10.3 sec]
EPOCH 192/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3316913763786125		[learning rate: 0.0042558]
	Learning Rate: 0.00425578
	LOSS [training: 3.3316913763786125 | validation: 2.889106925994159]
	TIME [epoch: 10.3 sec]
EPOCH 193/500:
	Training over batches...
		[batch 5/5] avg loss: 3.311549309604847		[learning rate: 0.0042358]
	Learning Rate: 0.00423583
	LOSS [training: 3.311549309604847 | validation: 2.6270301758592707]
	TIME [epoch: 10.3 sec]
EPOCH 194/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2644021559862644		[learning rate: 0.004216]
	Learning Rate: 0.00421597
	LOSS [training: 3.2644021559862644 | validation: 2.7621555309664347]
	TIME [epoch: 10.2 sec]
EPOCH 195/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4343610619192377		[learning rate: 0.0041962]
	Learning Rate: 0.00419621
	LOSS [training: 3.4343610619192377 | validation: 2.7945903773177805]
	TIME [epoch: 10.3 sec]
EPOCH 196/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4262429904628937		[learning rate: 0.0041765]
	Learning Rate: 0.00417654
	LOSS [training: 3.4262429904628937 | validation: 2.675386777819523]
	TIME [epoch: 10.3 sec]
EPOCH 197/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1965121864107755		[learning rate: 0.004157]
	Learning Rate: 0.00415696
	LOSS [training: 3.1965121864107755 | validation: 2.8797277430590347]
	TIME [epoch: 10.3 sec]
EPOCH 198/500:
	Training over batches...
		[batch 5/5] avg loss: 3.318020808282366		[learning rate: 0.0041375]
	Learning Rate: 0.00413747
	LOSS [training: 3.318020808282366 | validation: 2.6185628094633935]
	TIME [epoch: 10.2 sec]
EPOCH 199/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1928612082211214		[learning rate: 0.0041181]
	Learning Rate: 0.00411807
	LOSS [training: 3.1928612082211214 | validation: 2.6119375751281204]
	TIME [epoch: 10.3 sec]
EPOCH 200/500:
	Training over batches...
		[batch 5/5] avg loss: 3.0629907827681984		[learning rate: 0.0040988]
	Learning Rate: 0.00409877
	LOSS [training: 3.0629907827681984 | validation: 2.4830037045908186]
	TIME [epoch: 10.3 sec]
EPOCH 201/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6459799014429035		[learning rate: 0.0040795]
	Learning Rate: 0.00407955
	LOSS [training: 2.6459799014429035 | validation: 2.071156428826407]
	TIME [epoch: 10.3 sec]
EPOCH 202/500:
	Training over batches...
		[batch 5/5] avg loss: 2.335938834714881		[learning rate: 0.0040604]
	Learning Rate: 0.00406042
	LOSS [training: 2.335938834714881 | validation: 2.0749797103620615]
	TIME [epoch: 10.3 sec]
EPOCH 203/500:
	Training over batches...
		[batch 5/5] avg loss: 2.277894092258143		[learning rate: 0.0040414]
	Learning Rate: 0.00404139
	LOSS [training: 2.277894092258143 | validation: 2.2685500510023684]
	TIME [epoch: 10.3 sec]
EPOCH 204/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3441538884144957		[learning rate: 0.0040224]
	Learning Rate: 0.00402244
	LOSS [training: 2.3441538884144957 | validation: 1.970992729268927]
	TIME [epoch: 10.3 sec]
EPOCH 205/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0811039387314074		[learning rate: 0.0040036]
	Learning Rate: 0.00400358
	LOSS [training: 2.0811039387314074 | validation: 1.7325716062957777]
	TIME [epoch: 10.3 sec]
EPOCH 206/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6629393106904176		[learning rate: 0.0039848]
	Learning Rate: 0.00398481
	LOSS [training: 1.6629393106904176 | validation: 1.5029981623609394]
	TIME [epoch: 10.2 sec]
EPOCH 207/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3235441030223605		[learning rate: 0.0039661]
	Learning Rate: 0.00396613
	LOSS [training: 1.3235441030223605 | validation: 1.19526865219705]
	TIME [epoch: 10.3 sec]
EPOCH 208/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2620059425703194		[learning rate: 0.0039475]
	Learning Rate: 0.00394754
	LOSS [training: 1.2620059425703194 | validation: 1.2211713049974595]
	TIME [epoch: 10.3 sec]
EPOCH 209/500:
	Training over batches...
		[batch 5/5] avg loss: 1.224446019031676		[learning rate: 0.003929]
	Learning Rate: 0.00392903
	LOSS [training: 1.224446019031676 | validation: 1.2868876688973447]
	TIME [epoch: 10.3 sec]
EPOCH 210/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1391962961252957		[learning rate: 0.0039106]
	Learning Rate: 0.00391061
	LOSS [training: 1.1391962961252957 | validation: 1.0553642904606482]
	TIME [epoch: 10.3 sec]
EPOCH 211/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9501842905334007		[learning rate: 0.0038923]
	Learning Rate: 0.00389228
	LOSS [training: 0.9501842905334007 | validation: 0.9903839991030249]
	TIME [epoch: 10.2 sec]
EPOCH 212/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8902208994840264		[learning rate: 0.003874]
	Learning Rate: 0.00387403
	LOSS [training: 0.8902208994840264 | validation: 0.9344424561161557]
	TIME [epoch: 10.3 sec]
EPOCH 213/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9886206467537477		[learning rate: 0.0038559]
	Learning Rate: 0.00385587
	LOSS [training: 0.9886206467537477 | validation: 2.0533679762144823]
	TIME [epoch: 10.3 sec]
EPOCH 214/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4988304310915068		[learning rate: 0.0038378]
	Learning Rate: 0.00383779
	LOSS [training: 1.4988304310915068 | validation: 1.133165752914721]
	TIME [epoch: 10.2 sec]
EPOCH 215/500:
	Training over batches...
		[batch 5/5] avg loss: 1.053146459295299		[learning rate: 0.0038198]
	Learning Rate: 0.0038198
	LOSS [training: 1.053146459295299 | validation: 1.0146172381506875]
	TIME [epoch: 10.3 sec]
EPOCH 216/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9484991219610382		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 0.9484991219610382 | validation: 0.9675683662230407]
	TIME [epoch: 10.3 sec]
EPOCH 217/500:
	Training over batches...
		[batch 5/5] avg loss: 0.806151564145767		[learning rate: 0.0037841]
	Learning Rate: 0.00378407
	LOSS [training: 0.806151564145767 | validation: 0.9120513733205389]
	TIME [epoch: 10.3 sec]
EPOCH 218/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8734651246395698		[learning rate: 0.0037663]
	Learning Rate: 0.00376633
	LOSS [training: 0.8734651246395698 | validation: 0.9055747713946104]
	TIME [epoch: 10.3 sec]
EPOCH 219/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8157414333084148		[learning rate: 0.0037487]
	Learning Rate: 0.00374867
	LOSS [training: 0.8157414333084148 | validation: 0.8772169358329973]
	TIME [epoch: 10.3 sec]
EPOCH 220/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8976243244951541		[learning rate: 0.0037311]
	Learning Rate: 0.0037311
	LOSS [training: 0.8976243244951541 | validation: 1.05789365854995]
	TIME [epoch: 10.3 sec]
EPOCH 221/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9602203631193914		[learning rate: 0.0037136]
	Learning Rate: 0.00371361
	LOSS [training: 0.9602203631193914 | validation: 1.2715142878156227]
	TIME [epoch: 10.2 sec]
EPOCH 222/500:
	Training over batches...
		[batch 5/5] avg loss: 1.209571679680572		[learning rate: 0.0036962]
	Learning Rate: 0.0036962
	LOSS [training: 1.209571679680572 | validation: 0.9014200187482174]
	TIME [epoch: 10.2 sec]
EPOCH 223/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7988287680068333		[learning rate: 0.0036789]
	Learning Rate: 0.00367887
	LOSS [training: 0.7988287680068333 | validation: 0.8498363793096049]
	TIME [epoch: 10.2 sec]
EPOCH 224/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7637823820579982		[learning rate: 0.0036616]
	Learning Rate: 0.00366162
	LOSS [training: 0.7637823820579982 | validation: 0.7924161532410713]
	TIME [epoch: 10.3 sec]
EPOCH 225/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1031594254325572		[learning rate: 0.0036445]
	Learning Rate: 0.00364446
	LOSS [training: 1.1031594254325572 | validation: 1.1033049525698593]
	TIME [epoch: 10.2 sec]
EPOCH 226/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9831426731310176		[learning rate: 0.0036274]
	Learning Rate: 0.00362737
	LOSS [training: 0.9831426731310176 | validation: 0.823645306105669]
	TIME [epoch: 10.2 sec]
EPOCH 227/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7565364677440785		[learning rate: 0.0036104]
	Learning Rate: 0.00361036
	LOSS [training: 0.7565364677440785 | validation: 0.8869278118786801]
	TIME [epoch: 10.3 sec]
EPOCH 228/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0020475485150313		[learning rate: 0.0035934]
	Learning Rate: 0.00359344
	LOSS [training: 1.0020475485150313 | validation: 0.974902072768655]
	TIME [epoch: 10.3 sec]
EPOCH 229/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8949687312703292		[learning rate: 0.0035766]
	Learning Rate: 0.00357659
	LOSS [training: 0.8949687312703292 | validation: 1.0324666418980613]
	TIME [epoch: 10.2 sec]
EPOCH 230/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8978269020208829		[learning rate: 0.0035598]
	Learning Rate: 0.00355982
	LOSS [training: 0.8978269020208829 | validation: 0.8145553306199099]
	TIME [epoch: 10.2 sec]
EPOCH 231/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7704835254365557		[learning rate: 0.0035431]
	Learning Rate: 0.00354314
	LOSS [training: 0.7704835254365557 | validation: 1.0142626275920708]
	TIME [epoch: 10.3 sec]
EPOCH 232/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8705095342877751		[learning rate: 0.0035265]
	Learning Rate: 0.00352652
	LOSS [training: 0.8705095342877751 | validation: 0.8746232390375264]
	TIME [epoch: 10.3 sec]
EPOCH 233/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8186064458297432		[learning rate: 0.00351]
	Learning Rate: 0.00350999
	LOSS [training: 0.8186064458297432 | validation: 0.9556054447158345]
	TIME [epoch: 10.2 sec]
EPOCH 234/500:
	Training over batches...
		[batch 5/5] avg loss: 0.939308902214767		[learning rate: 0.0034935]
	Learning Rate: 0.00349354
	LOSS [training: 0.939308902214767 | validation: 0.9680854061302282]
	TIME [epoch: 10.2 sec]
EPOCH 235/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8411848976062334		[learning rate: 0.0034772]
	Learning Rate: 0.00347716
	LOSS [training: 0.8411848976062334 | validation: 0.9110097851990971]
	TIME [epoch: 10.2 sec]
EPOCH 236/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8036482982947005		[learning rate: 0.0034609]
	Learning Rate: 0.00346086
	LOSS [training: 0.8036482982947005 | validation: 1.1433551342848043]
	TIME [epoch: 10.2 sec]
EPOCH 237/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8996296536182065		[learning rate: 0.0034446]
	Learning Rate: 0.00344463
	LOSS [training: 0.8996296536182065 | validation: 0.8913575982882432]
	TIME [epoch: 10.2 sec]
EPOCH 238/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7845819318906875		[learning rate: 0.0034285]
	Learning Rate: 0.00342848
	LOSS [training: 0.7845819318906875 | validation: 0.7836468339273535]
	TIME [epoch: 10.2 sec]
EPOCH 239/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9001518337173415		[learning rate: 0.0034124]
	Learning Rate: 0.00341241
	LOSS [training: 0.9001518337173415 | validation: 0.7066991712978039]
	TIME [epoch: 10.2 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_239.pth
	Model improved!!!
EPOCH 240/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7330036524015027		[learning rate: 0.0033964]
	Learning Rate: 0.00339641
	LOSS [training: 0.7330036524015027 | validation: 0.8905901778248303]
	TIME [epoch: 10.3 sec]
EPOCH 241/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0666461608122135		[learning rate: 0.0033805]
	Learning Rate: 0.00338049
	LOSS [training: 1.0666461608122135 | validation: 1.6362728444122001]
	TIME [epoch: 10.3 sec]
EPOCH 242/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2075737427782205		[learning rate: 0.0033646]
	Learning Rate: 0.00336464
	LOSS [training: 1.2075737427782205 | validation: 0.7522161911419697]
	TIME [epoch: 10.3 sec]
EPOCH 243/500:
	Training over batches...
		[batch 5/5] avg loss: 0.836547049784589		[learning rate: 0.0033489]
	Learning Rate: 0.00334887
	LOSS [training: 0.836547049784589 | validation: 1.9015158402191596]
	TIME [epoch: 10.2 sec]
EPOCH 244/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0050739773590838		[learning rate: 0.0033332]
	Learning Rate: 0.00333317
	LOSS [training: 1.0050739773590838 | validation: 0.8015223499895674]
	TIME [epoch: 10.3 sec]
EPOCH 245/500:
	Training over batches...
		[batch 5/5] avg loss: 0.854227451247192		[learning rate: 0.0033175]
	Learning Rate: 0.00331754
	LOSS [training: 0.854227451247192 | validation: 0.8234765555275902]
	TIME [epoch: 10.3 sec]
EPOCH 246/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7998241498116835		[learning rate: 0.003302]
	Learning Rate: 0.00330199
	LOSS [training: 0.7998241498116835 | validation: 0.8056947188222676]
	TIME [epoch: 10.2 sec]
EPOCH 247/500:
	Training over batches...
		[batch 5/5] avg loss: 0.728950876401288		[learning rate: 0.0032865]
	Learning Rate: 0.00328651
	LOSS [training: 0.728950876401288 | validation: 0.7846259045814471]
	TIME [epoch: 10.2 sec]
EPOCH 248/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8444854903127379		[learning rate: 0.0032711]
	Learning Rate: 0.0032711
	LOSS [training: 0.8444854903127379 | validation: 0.9315654599897774]
	TIME [epoch: 10.3 sec]
EPOCH 249/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8457122730065425		[learning rate: 0.0032558]
	Learning Rate: 0.00325576
	LOSS [training: 0.8457122730065425 | validation: 0.9526159740176229]
	TIME [epoch: 10.3 sec]
EPOCH 250/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8313264902209727		[learning rate: 0.0032405]
	Learning Rate: 0.0032405
	LOSS [training: 0.8313264902209727 | validation: 0.8035577294915146]
	TIME [epoch: 10.2 sec]
EPOCH 251/500:
	Training over batches...
		[batch 5/5] avg loss: 0.755297172679381		[learning rate: 0.0032253]
	Learning Rate: 0.00322531
	LOSS [training: 0.755297172679381 | validation: 0.7833403827152663]
	TIME [epoch: 10.3 sec]
EPOCH 252/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9598125514764899		[learning rate: 0.0032102]
	Learning Rate: 0.00321019
	LOSS [training: 0.9598125514764899 | validation: 0.8115310357134415]
	TIME [epoch: 10.2 sec]
EPOCH 253/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7833359375767873		[learning rate: 0.0031951]
	Learning Rate: 0.00319514
	LOSS [training: 0.7833359375767873 | validation: 0.8455674025696075]
	TIME [epoch: 10.3 sec]
EPOCH 254/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7976322312769353		[learning rate: 0.0031802]
	Learning Rate: 0.00318016
	LOSS [training: 0.7976322312769353 | validation: 0.8042396767706446]
	TIME [epoch: 10.3 sec]
EPOCH 255/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7206611578133865		[learning rate: 0.0031653]
	Learning Rate: 0.00316525
	LOSS [training: 0.7206611578133865 | validation: 0.7191224117398902]
	TIME [epoch: 10.3 sec]
EPOCH 256/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7126968063053989		[learning rate: 0.0031504]
	Learning Rate: 0.00315041
	LOSS [training: 0.7126968063053989 | validation: 0.9225964640210327]
	TIME [epoch: 10.2 sec]
EPOCH 257/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7403224414702769		[learning rate: 0.0031356]
	Learning Rate: 0.00313564
	LOSS [training: 0.7403224414702769 | validation: 0.7801276497169066]
	TIME [epoch: 10.3 sec]
EPOCH 258/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8171421172381473		[learning rate: 0.0031209]
	Learning Rate: 0.00312094
	LOSS [training: 0.8171421172381473 | validation: 1.1991453204012557]
	TIME [epoch: 10.3 sec]
EPOCH 259/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1276574450821093		[learning rate: 0.0031063]
	Learning Rate: 0.00310631
	LOSS [training: 1.1276574450821093 | validation: 0.7463041882978623]
	TIME [epoch: 10.3 sec]
EPOCH 260/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8058714862106013		[learning rate: 0.0030917]
	Learning Rate: 0.00309175
	LOSS [training: 0.8058714862106013 | validation: 0.79951505760684]
	TIME [epoch: 10.3 sec]
EPOCH 261/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7486119937858854		[learning rate: 0.0030773]
	Learning Rate: 0.00307725
	LOSS [training: 0.7486119937858854 | validation: 0.7195831816356477]
	TIME [epoch: 10.3 sec]
EPOCH 262/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7953440290400493		[learning rate: 0.0030628]
	Learning Rate: 0.00306283
	LOSS [training: 0.7953440290400493 | validation: 0.7504525567436358]
	TIME [epoch: 10.3 sec]
EPOCH 263/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7882648346696037		[learning rate: 0.0030485]
	Learning Rate: 0.00304847
	LOSS [training: 0.7882648346696037 | validation: 0.7391279529208664]
	TIME [epoch: 10.3 sec]
EPOCH 264/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7448602017004781		[learning rate: 0.0030342]
	Learning Rate: 0.00303418
	LOSS [training: 0.7448602017004781 | validation: 0.8232718777892651]
	TIME [epoch: 10.3 sec]
EPOCH 265/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7014831102117728		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.7014831102117728 | validation: 0.7803151182225111]
	TIME [epoch: 10.3 sec]
EPOCH 266/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9487407159783497		[learning rate: 0.0030058]
	Learning Rate: 0.00300579
	LOSS [training: 0.9487407159783497 | validation: 1.2764064511260351]
	TIME [epoch: 10.3 sec]
EPOCH 267/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8643803769886563		[learning rate: 0.0029917]
	Learning Rate: 0.0029917
	LOSS [training: 0.8643803769886563 | validation: 0.7668370368222798]
	TIME [epoch: 10.3 sec]
EPOCH 268/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7598820012556549		[learning rate: 0.0029777]
	Learning Rate: 0.00297768
	LOSS [training: 0.7598820012556549 | validation: 0.8598279491552332]
	TIME [epoch: 10.3 sec]
EPOCH 269/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7745811483784307		[learning rate: 0.0029637]
	Learning Rate: 0.00296372
	LOSS [training: 0.7745811483784307 | validation: 0.8805481603948218]
	TIME [epoch: 10.3 sec]
EPOCH 270/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7328373559988158		[learning rate: 0.0029498]
	Learning Rate: 0.00294982
	LOSS [training: 0.7328373559988158 | validation: 0.7220404342936345]
	TIME [epoch: 10.3 sec]
EPOCH 271/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7665023153931309		[learning rate: 0.002936]
	Learning Rate: 0.00293599
	LOSS [training: 0.7665023153931309 | validation: 0.9769280079419229]
	TIME [epoch: 10.2 sec]
EPOCH 272/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7451537483740355		[learning rate: 0.0029222]
	Learning Rate: 0.00292223
	LOSS [training: 0.7451537483740355 | validation: 0.9207810210206567]
	TIME [epoch: 10.2 sec]
EPOCH 273/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8113477799032554		[learning rate: 0.0029085]
	Learning Rate: 0.00290853
	LOSS [training: 0.8113477799032554 | validation: 0.7853359250266287]
	TIME [epoch: 10.3 sec]
EPOCH 274/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7301253423514769		[learning rate: 0.0028949]
	Learning Rate: 0.00289489
	LOSS [training: 0.7301253423514769 | validation: 0.8394566120237582]
	TIME [epoch: 10.3 sec]
EPOCH 275/500:
	Training over batches...
		[batch 5/5] avg loss: 0.736174687385811		[learning rate: 0.0028813]
	Learning Rate: 0.00288132
	LOSS [training: 0.736174687385811 | validation: 0.8132367519793732]
	TIME [epoch: 10.3 sec]
EPOCH 276/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6893515839475233		[learning rate: 0.0028678]
	Learning Rate: 0.00286781
	LOSS [training: 0.6893515839475233 | validation: 0.8620950702625713]
	TIME [epoch: 10.3 sec]
EPOCH 277/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8561531965197802		[learning rate: 0.0028544]
	Learning Rate: 0.00285437
	LOSS [training: 0.8561531965197802 | validation: 1.2817062570112574]
	TIME [epoch: 10.3 sec]
EPOCH 278/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8094736227465201		[learning rate: 0.002841]
	Learning Rate: 0.00284099
	LOSS [training: 0.8094736227465201 | validation: 0.6687958622147536]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_278.pth
	Model improved!!!
EPOCH 279/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8300899047237058		[learning rate: 0.0028277]
	Learning Rate: 0.00282767
	LOSS [training: 0.8300899047237058 | validation: 0.988461631074631]
	TIME [epoch: 10.3 sec]
EPOCH 280/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8059728935248808		[learning rate: 0.0028144]
	Learning Rate: 0.00281441
	LOSS [training: 0.8059728935248808 | validation: 0.7597125361437432]
	TIME [epoch: 10.3 sec]
EPOCH 281/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6283469688509735		[learning rate: 0.0028012]
	Learning Rate: 0.00280122
	LOSS [training: 0.6283469688509735 | validation: 0.7231266272423912]
	TIME [epoch: 10.3 sec]
EPOCH 282/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7740277887558764		[learning rate: 0.0027881]
	Learning Rate: 0.00278809
	LOSS [training: 0.7740277887558764 | validation: 0.8179330927805569]
	TIME [epoch: 10.3 sec]
EPOCH 283/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6423223663745246		[learning rate: 0.002775]
	Learning Rate: 0.00277501
	LOSS [training: 0.6423223663745246 | validation: 0.6681065806199679]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_283.pth
	Model improved!!!
EPOCH 284/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6997547502369161		[learning rate: 0.002762]
	Learning Rate: 0.002762
	LOSS [training: 0.6997547502369161 | validation: 0.8438191742803796]
	TIME [epoch: 10.3 sec]
EPOCH 285/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6949242912013398		[learning rate: 0.0027491]
	Learning Rate: 0.00274906
	LOSS [training: 0.6949242912013398 | validation: 0.8249550103169517]
	TIME [epoch: 10.3 sec]
EPOCH 286/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1538808726742018		[learning rate: 0.0027362]
	Learning Rate: 0.00273617
	LOSS [training: 1.1538808726742018 | validation: 0.7125775210027728]
	TIME [epoch: 10.3 sec]
EPOCH 287/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6311671848587468		[learning rate: 0.0027233]
	Learning Rate: 0.00272334
	LOSS [training: 0.6311671848587468 | validation: 0.6942573692157117]
	TIME [epoch: 10.3 sec]
EPOCH 288/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6414508593536146		[learning rate: 0.0027106]
	Learning Rate: 0.00271057
	LOSS [training: 0.6414508593536146 | validation: 0.7828970292678542]
	TIME [epoch: 10.3 sec]
EPOCH 289/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7649186191117429		[learning rate: 0.0026979]
	Learning Rate: 0.00269787
	LOSS [training: 0.7649186191117429 | validation: 0.7711865176532741]
	TIME [epoch: 10.3 sec]
EPOCH 290/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6907000813091255		[learning rate: 0.0026852]
	Learning Rate: 0.00268522
	LOSS [training: 0.6907000813091255 | validation: 0.6811266412287423]
	TIME [epoch: 10.3 sec]
EPOCH 291/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3409316424733104		[learning rate: 0.0026726]
	Learning Rate: 0.00267263
	LOSS [training: 1.3409316424733104 | validation: 0.8854297036944407]
	TIME [epoch: 10.3 sec]
EPOCH 292/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7765093447283175		[learning rate: 0.0026601]
	Learning Rate: 0.0026601
	LOSS [training: 0.7765093447283175 | validation: 0.8379535759156739]
	TIME [epoch: 10.3 sec]
EPOCH 293/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7069308441010986		[learning rate: 0.0026476]
	Learning Rate: 0.00264763
	LOSS [training: 0.7069308441010986 | validation: 0.7982852394757831]
	TIME [epoch: 10.3 sec]
EPOCH 294/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6966006995009811		[learning rate: 0.0026352]
	Learning Rate: 0.00263522
	LOSS [training: 0.6966006995009811 | validation: 0.834441368063269]
	TIME [epoch: 10.3 sec]
EPOCH 295/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7439761544394412		[learning rate: 0.0026229]
	Learning Rate: 0.00262286
	LOSS [training: 0.7439761544394412 | validation: 0.9076907087320354]
	TIME [epoch: 10.3 sec]
EPOCH 296/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7434106309835328		[learning rate: 0.0026106]
	Learning Rate: 0.00261057
	LOSS [training: 0.7434106309835328 | validation: 0.8899487144585129]
	TIME [epoch: 10.3 sec]
EPOCH 297/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6192952489464593		[learning rate: 0.0025983]
	Learning Rate: 0.00259833
	LOSS [training: 0.6192952489464593 | validation: 0.719435538295131]
	TIME [epoch: 10.3 sec]
EPOCH 298/500:
	Training over batches...
		[batch 5/5] avg loss: 0.583504914562278		[learning rate: 0.0025861]
	Learning Rate: 0.00258615
	LOSS [training: 0.583504914562278 | validation: 0.6917388631199768]
	TIME [epoch: 10.3 sec]
EPOCH 299/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8473726124771304		[learning rate: 0.002574]
	Learning Rate: 0.00257402
	LOSS [training: 0.8473726124771304 | validation: 0.8435329036495537]
	TIME [epoch: 10.3 sec]
EPOCH 300/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7815042511988468		[learning rate: 0.002562]
	Learning Rate: 0.00256195
	LOSS [training: 0.7815042511988468 | validation: 0.6858152608420207]
	TIME [epoch: 10.3 sec]
EPOCH 301/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8913758841898897		[learning rate: 0.0025499]
	Learning Rate: 0.00254994
	LOSS [training: 0.8913758841898897 | validation: 1.194867917696048]
	TIME [epoch: 10.3 sec]
EPOCH 302/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8323867387986601		[learning rate: 0.002538]
	Learning Rate: 0.00253799
	LOSS [training: 0.8323867387986601 | validation: 0.6719654460443383]
	TIME [epoch: 10.3 sec]
EPOCH 303/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6465736215156701		[learning rate: 0.0025261]
	Learning Rate: 0.00252609
	LOSS [training: 0.6465736215156701 | validation: 0.700448219350691]
	TIME [epoch: 10.3 sec]
EPOCH 304/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7546892582143512		[learning rate: 0.0025142]
	Learning Rate: 0.00251425
	LOSS [training: 0.7546892582143512 | validation: 0.855056809378462]
	TIME [epoch: 10.3 sec]
EPOCH 305/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6706840851530359		[learning rate: 0.0025025]
	Learning Rate: 0.00250246
	LOSS [training: 0.6706840851530359 | validation: 1.164959499990226]
	TIME [epoch: 10.3 sec]
EPOCH 306/500:
	Training over batches...
		[batch 5/5] avg loss: 0.996672619289036		[learning rate: 0.0024907]
	Learning Rate: 0.00249073
	LOSS [training: 0.996672619289036 | validation: 0.8048341246120978]
	TIME [epoch: 10.3 sec]
EPOCH 307/500:
	Training over batches...
		[batch 5/5] avg loss: 0.665104450873477		[learning rate: 0.0024791]
	Learning Rate: 0.00247905
	LOSS [training: 0.665104450873477 | validation: 0.5971204493835915]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_307.pth
	Model improved!!!
EPOCH 308/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5870319195776437		[learning rate: 0.0024674]
	Learning Rate: 0.00246743
	LOSS [training: 0.5870319195776437 | validation: 0.7984614183273534]
	TIME [epoch: 10.3 sec]
EPOCH 309/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6223936525800523		[learning rate: 0.0024559]
	Learning Rate: 0.00245586
	LOSS [training: 0.6223936525800523 | validation: 0.6156970093098628]
	TIME [epoch: 10.3 sec]
EPOCH 310/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5813215821040943		[learning rate: 0.0024443]
	Learning Rate: 0.00244435
	LOSS [training: 0.5813215821040943 | validation: 0.6131568277287573]
	TIME [epoch: 10.3 sec]
EPOCH 311/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5673713381052516		[learning rate: 0.0024329]
	Learning Rate: 0.00243289
	LOSS [training: 0.5673713381052516 | validation: 0.7276819747258559]
	TIME [epoch: 10.3 sec]
EPOCH 312/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6533206348290305		[learning rate: 0.0024215]
	Learning Rate: 0.00242148
	LOSS [training: 0.6533206348290305 | validation: 0.9230949655164824]
	TIME [epoch: 10.3 sec]
EPOCH 313/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6482089184873939		[learning rate: 0.0024101]
	Learning Rate: 0.00241013
	LOSS [training: 0.6482089184873939 | validation: 0.9179626173782509]
	TIME [epoch: 10.3 sec]
EPOCH 314/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7596878766822366		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.7596878766822366 | validation: 0.7857312996453226]
	TIME [epoch: 10.3 sec]
EPOCH 315/500:
	Training over batches...
		[batch 5/5] avg loss: 0.765117293406878		[learning rate: 0.0023876]
	Learning Rate: 0.00238759
	LOSS [training: 0.765117293406878 | validation: 0.6721615455553357]
	TIME [epoch: 10.3 sec]
EPOCH 316/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6220828514733009		[learning rate: 0.0023764]
	Learning Rate: 0.00237639
	LOSS [training: 0.6220828514733009 | validation: 0.6401603756192927]
	TIME [epoch: 10.3 sec]
EPOCH 317/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5472954536231492		[learning rate: 0.0023653]
	Learning Rate: 0.00236525
	LOSS [training: 0.5472954536231492 | validation: 0.6491763027734109]
	TIME [epoch: 10.3 sec]
EPOCH 318/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5676140168255838		[learning rate: 0.0023542]
	Learning Rate: 0.00235416
	LOSS [training: 0.5676140168255838 | validation: 0.71977471949809]
	TIME [epoch: 10.3 sec]
EPOCH 319/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6609903207195982		[learning rate: 0.0023431]
	Learning Rate: 0.00234313
	LOSS [training: 0.6609903207195982 | validation: 0.6759919706796299]
	TIME [epoch: 10.3 sec]
EPOCH 320/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5618093032697822		[learning rate: 0.0023321]
	Learning Rate: 0.00233214
	LOSS [training: 0.5618093032697822 | validation: 0.6513504863431954]
	TIME [epoch: 10.3 sec]
EPOCH 321/500:
	Training over batches...
		[batch 5/5] avg loss: 0.590284240611368		[learning rate: 0.0023212]
	Learning Rate: 0.00232121
	LOSS [training: 0.590284240611368 | validation: 0.6672699978861221]
	TIME [epoch: 10.3 sec]
EPOCH 322/500:
	Training over batches...
		[batch 5/5] avg loss: 0.661788884482846		[learning rate: 0.0023103]
	Learning Rate: 0.00231033
	LOSS [training: 0.661788884482846 | validation: 0.8957034172110976]
	TIME [epoch: 10.3 sec]
EPOCH 323/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7497425398041693		[learning rate: 0.0022995]
	Learning Rate: 0.0022995
	LOSS [training: 0.7497425398041693 | validation: 0.8238002800520924]
	TIME [epoch: 10.3 sec]
EPOCH 324/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7543532904518246		[learning rate: 0.0022887]
	Learning Rate: 0.00228872
	LOSS [training: 0.7543532904518246 | validation: 0.7686020249450063]
	TIME [epoch: 10.3 sec]
EPOCH 325/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6467537298523659		[learning rate: 0.002278]
	Learning Rate: 0.00227799
	LOSS [training: 0.6467537298523659 | validation: 0.65633139552693]
	TIME [epoch: 10.3 sec]
EPOCH 326/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6814702856596403		[learning rate: 0.0022673]
	Learning Rate: 0.00226731
	LOSS [training: 0.6814702856596403 | validation: 1.2948619316779857]
	TIME [epoch: 10.3 sec]
EPOCH 327/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8537152573710891		[learning rate: 0.0022567]
	Learning Rate: 0.00225668
	LOSS [training: 0.8537152573710891 | validation: 0.7499286138807456]
	TIME [epoch: 10.3 sec]
EPOCH 328/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6044575761511755		[learning rate: 0.0022461]
	Learning Rate: 0.0022461
	LOSS [training: 0.6044575761511755 | validation: 0.8677488558868182]
	TIME [epoch: 10.3 sec]
EPOCH 329/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6426190232811761		[learning rate: 0.0022356]
	Learning Rate: 0.00223557
	LOSS [training: 0.6426190232811761 | validation: 0.5949310076988322]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_329.pth
	Model improved!!!
EPOCH 330/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5595501543838829		[learning rate: 0.0022251]
	Learning Rate: 0.00222509
	LOSS [training: 0.5595501543838829 | validation: 0.8000167046519081]
	TIME [epoch: 10.3 sec]
EPOCH 331/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5772665094888174		[learning rate: 0.0022147]
	Learning Rate: 0.00221466
	LOSS [training: 0.5772665094888174 | validation: 0.6031254615727996]
	TIME [epoch: 10.3 sec]
EPOCH 332/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5228661842087895		[learning rate: 0.0022043]
	Learning Rate: 0.00220427
	LOSS [training: 0.5228661842087895 | validation: 0.6118356908302873]
	TIME [epoch: 10.3 sec]
EPOCH 333/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6987835832587809		[learning rate: 0.0021939]
	Learning Rate: 0.00219394
	LOSS [training: 0.6987835832587809 | validation: 0.679094369869353]
	TIME [epoch: 10.3 sec]
EPOCH 334/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5528281338404684		[learning rate: 0.0021837]
	Learning Rate: 0.00218365
	LOSS [training: 0.5528281338404684 | validation: 0.7561810819598616]
	TIME [epoch: 10.3 sec]
EPOCH 335/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6032484670078025		[learning rate: 0.0021734]
	Learning Rate: 0.00217342
	LOSS [training: 0.6032484670078025 | validation: 0.5780726484834416]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_335.pth
	Model improved!!!
EPOCH 336/500:
	Training over batches...
		[batch 5/5] avg loss: 0.726908432456744		[learning rate: 0.0021632]
	Learning Rate: 0.00216323
	LOSS [training: 0.726908432456744 | validation: 0.6528228772906641]
	TIME [epoch: 10.3 sec]
EPOCH 337/500:
	Training over batches...
		[batch 5/5] avg loss: 0.600785981051527		[learning rate: 0.0021531]
	Learning Rate: 0.00215309
	LOSS [training: 0.600785981051527 | validation: 0.6916125552226211]
	TIME [epoch: 10.3 sec]
EPOCH 338/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8312760753036749		[learning rate: 0.002143]
	Learning Rate: 0.00214299
	LOSS [training: 0.8312760753036749 | validation: 0.6460463409233834]
	TIME [epoch: 10.3 sec]
EPOCH 339/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6130960754507849		[learning rate: 0.0021329]
	Learning Rate: 0.00213294
	LOSS [training: 0.6130960754507849 | validation: 0.5932532674243746]
	TIME [epoch: 10.3 sec]
EPOCH 340/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5518687184811059		[learning rate: 0.0021229]
	Learning Rate: 0.00212294
	LOSS [training: 0.5518687184811059 | validation: 0.6181300486675386]
	TIME [epoch: 10.3 sec]
EPOCH 341/500:
	Training over batches...
		[batch 5/5] avg loss: 0.705438169888606		[learning rate: 0.002113]
	Learning Rate: 0.00211299
	LOSS [training: 0.705438169888606 | validation: 0.747928961400062]
	TIME [epoch: 10.3 sec]
EPOCH 342/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6163240283427994		[learning rate: 0.0021031]
	Learning Rate: 0.00210309
	LOSS [training: 0.6163240283427994 | validation: 0.6101015798309868]
	TIME [epoch: 10.3 sec]
EPOCH 343/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7346619611387205		[learning rate: 0.0020932]
	Learning Rate: 0.00209323
	LOSS [training: 0.7346619611387205 | validation: 0.8320812292645521]
	TIME [epoch: 10.3 sec]
EPOCH 344/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6122287280800283		[learning rate: 0.0020834]
	Learning Rate: 0.00208341
	LOSS [training: 0.6122287280800283 | validation: 0.6616950993443738]
	TIME [epoch: 10.3 sec]
EPOCH 345/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7006097747508775		[learning rate: 0.0020736]
	Learning Rate: 0.00207365
	LOSS [training: 0.7006097747508775 | validation: 0.5796214256027947]
	TIME [epoch: 10.3 sec]
EPOCH 346/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5709227417185962		[learning rate: 0.0020639]
	Learning Rate: 0.00206392
	LOSS [training: 0.5709227417185962 | validation: 0.6565094895342358]
	TIME [epoch: 10.3 sec]
EPOCH 347/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5724236213133942		[learning rate: 0.0020542]
	Learning Rate: 0.00205425
	LOSS [training: 0.5724236213133942 | validation: 0.6366315457243475]
	TIME [epoch: 10.3 sec]
EPOCH 348/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5868363044329201		[learning rate: 0.0020446]
	Learning Rate: 0.00204462
	LOSS [training: 0.5868363044329201 | validation: 1.220491983088122]
	TIME [epoch: 10.3 sec]
EPOCH 349/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0430430738920011		[learning rate: 0.002035]
	Learning Rate: 0.00203503
	LOSS [training: 1.0430430738920011 | validation: 0.7738238646976745]
	TIME [epoch: 10.3 sec]
EPOCH 350/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5767546076688459		[learning rate: 0.0020255]
	Learning Rate: 0.00202549
	LOSS [training: 0.5767546076688459 | validation: 0.5706080671977697]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_350.pth
	Model improved!!!
EPOCH 351/500:
	Training over batches...
		[batch 5/5] avg loss: 0.562975561218712		[learning rate: 0.002016]
	Learning Rate: 0.002016
	LOSS [training: 0.562975561218712 | validation: 0.8048133858464587]
	TIME [epoch: 10.3 sec]
EPOCH 352/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6554668863313177		[learning rate: 0.0020065]
	Learning Rate: 0.00200655
	LOSS [training: 0.6554668863313177 | validation: 0.6504651937342782]
	TIME [epoch: 10.3 sec]
EPOCH 353/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5875114038803423		[learning rate: 0.0019971]
	Learning Rate: 0.00199714
	LOSS [training: 0.5875114038803423 | validation: 0.7392873124814878]
	TIME [epoch: 10.3 sec]
EPOCH 354/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6487529371272596		[learning rate: 0.0019878]
	Learning Rate: 0.00198778
	LOSS [training: 0.6487529371272596 | validation: 0.6259864454697458]
	TIME [epoch: 10.3 sec]
EPOCH 355/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5319686610528684		[learning rate: 0.0019785]
	Learning Rate: 0.00197846
	LOSS [training: 0.5319686610528684 | validation: 0.6392606076839945]
	TIME [epoch: 10.3 sec]
EPOCH 356/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5781047191915206		[learning rate: 0.0019692]
	Learning Rate: 0.00196918
	LOSS [training: 0.5781047191915206 | validation: 0.8045318639270351]
	TIME [epoch: 10.3 sec]
EPOCH 357/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6191651077965776		[learning rate: 0.0019599]
	Learning Rate: 0.00195995
	LOSS [training: 0.6191651077965776 | validation: 0.7117394255138776]
	TIME [epoch: 10.3 sec]
EPOCH 358/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6971095067856272		[learning rate: 0.0019508]
	Learning Rate: 0.00195076
	LOSS [training: 0.6971095067856272 | validation: 1.0509130503012347]
	TIME [epoch: 10.3 sec]
EPOCH 359/500:
	Training over batches...
		[batch 5/5] avg loss: 0.648578575417016		[learning rate: 0.0019416]
	Learning Rate: 0.00194162
	LOSS [training: 0.648578575417016 | validation: 0.6128388492335393]
	TIME [epoch: 10.3 sec]
EPOCH 360/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5984784957999298		[learning rate: 0.0019325]
	Learning Rate: 0.00193251
	LOSS [training: 0.5984784957999298 | validation: 0.8290627593966176]
	TIME [epoch: 10.3 sec]
EPOCH 361/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5605903653217965		[learning rate: 0.0019235]
	Learning Rate: 0.00192345
	LOSS [training: 0.5605903653217965 | validation: 0.7195390564157828]
	TIME [epoch: 10.3 sec]
EPOCH 362/500:
	Training over batches...
		[batch 5/5] avg loss: 0.519162793147774		[learning rate: 0.0019144]
	Learning Rate: 0.00191444
	LOSS [training: 0.519162793147774 | validation: 0.5886882483292675]
	TIME [epoch: 10.3 sec]
EPOCH 363/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5060287207333781		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.5060287207333781 | validation: 0.5785444813671015]
	TIME [epoch: 10.3 sec]
EPOCH 364/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5565658541060825		[learning rate: 0.0018965]
	Learning Rate: 0.00189653
	LOSS [training: 0.5565658541060825 | validation: 0.5828296808221562]
	TIME [epoch: 10.3 sec]
EPOCH 365/500:
	Training over batches...
		[batch 5/5] avg loss: 0.575590041355839		[learning rate: 0.0018876]
	Learning Rate: 0.00188764
	LOSS [training: 0.575590041355839 | validation: 0.6292711327714793]
	TIME [epoch: 10.3 sec]
EPOCH 366/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5980412624356435		[learning rate: 0.0018788]
	Learning Rate: 0.00187879
	LOSS [training: 0.5980412624356435 | validation: 0.6843342533842796]
	TIME [epoch: 10.3 sec]
EPOCH 367/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5875699308283503		[learning rate: 0.00187]
	Learning Rate: 0.00186998
	LOSS [training: 0.5875699308283503 | validation: 0.6798406476227041]
	TIME [epoch: 10.3 sec]
EPOCH 368/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5117376780541764		[learning rate: 0.0018612]
	Learning Rate: 0.00186121
	LOSS [training: 0.5117376780541764 | validation: 0.611108483884005]
	TIME [epoch: 10.3 sec]
EPOCH 369/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5497744817821204		[learning rate: 0.0018525]
	Learning Rate: 0.00185249
	LOSS [training: 0.5497744817821204 | validation: 0.5917889754580968]
	TIME [epoch: 10.3 sec]
EPOCH 370/500:
	Training over batches...
		[batch 5/5] avg loss: 0.518927192436611		[learning rate: 0.0018438]
	Learning Rate: 0.0018438
	LOSS [training: 0.518927192436611 | validation: 0.6167791668083702]
	TIME [epoch: 10.3 sec]
EPOCH 371/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5316545785006136		[learning rate: 0.0018352]
	Learning Rate: 0.00183516
	LOSS [training: 0.5316545785006136 | validation: 0.5181768002208197]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_371.pth
	Model improved!!!
EPOCH 372/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48795982538704574		[learning rate: 0.0018266]
	Learning Rate: 0.00182655
	LOSS [training: 0.48795982538704574 | validation: 0.6215974291187211]
	TIME [epoch: 10.3 sec]
EPOCH 373/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5410530356218253		[learning rate: 0.001818]
	Learning Rate: 0.00181799
	LOSS [training: 0.5410530356218253 | validation: 0.6929474270735194]
	TIME [epoch: 10.3 sec]
EPOCH 374/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5977726761788225		[learning rate: 0.0018095]
	Learning Rate: 0.00180947
	LOSS [training: 0.5977726761788225 | validation: 0.5423755536425007]
	TIME [epoch: 10.3 sec]
EPOCH 375/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5849074658130581		[learning rate: 0.001801]
	Learning Rate: 0.00180099
	LOSS [training: 0.5849074658130581 | validation: 0.5848185117019428]
	TIME [epoch: 10.3 sec]
EPOCH 376/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5423891691994865		[learning rate: 0.0017925]
	Learning Rate: 0.00179254
	LOSS [training: 0.5423891691994865 | validation: 0.6552026807213511]
	TIME [epoch: 10.3 sec]
EPOCH 377/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5280761232780156		[learning rate: 0.0017841]
	Learning Rate: 0.00178414
	LOSS [training: 0.5280761232780156 | validation: 0.586211976851924]
	TIME [epoch: 10.3 sec]
EPOCH 378/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48252580146453694		[learning rate: 0.0017758]
	Learning Rate: 0.00177577
	LOSS [training: 0.48252580146453694 | validation: 0.5286112163733193]
	TIME [epoch: 10.3 sec]
EPOCH 379/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5021933308442544		[learning rate: 0.0017674]
	Learning Rate: 0.00176745
	LOSS [training: 0.5021933308442544 | validation: 0.5863928312227982]
	TIME [epoch: 10.3 sec]
EPOCH 380/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6507961739172311		[learning rate: 0.0017592]
	Learning Rate: 0.00175916
	LOSS [training: 0.6507961739172311 | validation: 0.5467640096399857]
	TIME [epoch: 10.3 sec]
EPOCH 381/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5415829088534029		[learning rate: 0.0017509]
	Learning Rate: 0.00175092
	LOSS [training: 0.5415829088534029 | validation: 0.6022066157473644]
	TIME [epoch: 10.3 sec]
EPOCH 382/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5096819584526682		[learning rate: 0.0017427]
	Learning Rate: 0.00174271
	LOSS [training: 0.5096819584526682 | validation: 0.6142732986245316]
	TIME [epoch: 10.3 sec]
EPOCH 383/500:
	Training over batches...
		[batch 5/5] avg loss: 0.696632794376854		[learning rate: 0.0017345]
	Learning Rate: 0.00173454
	LOSS [training: 0.696632794376854 | validation: 0.5813663264008244]
	TIME [epoch: 10.3 sec]
EPOCH 384/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6159430788889578		[learning rate: 0.0017264]
	Learning Rate: 0.00172641
	LOSS [training: 0.6159430788889578 | validation: 0.6671431176149031]
	TIME [epoch: 10.3 sec]
EPOCH 385/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5551603011620158		[learning rate: 0.0017183]
	Learning Rate: 0.00171831
	LOSS [training: 0.5551603011620158 | validation: 0.6663073982127939]
	TIME [epoch: 10.3 sec]
EPOCH 386/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5232411373488267		[learning rate: 0.0017103]
	Learning Rate: 0.00171026
	LOSS [training: 0.5232411373488267 | validation: 0.6396725964318271]
	TIME [epoch: 10.3 sec]
EPOCH 387/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5994382864525261		[learning rate: 0.0017022]
	Learning Rate: 0.00170224
	LOSS [training: 0.5994382864525261 | validation: 0.6715147924868728]
	TIME [epoch: 10.3 sec]
EPOCH 388/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6061856289056972		[learning rate: 0.0016943]
	Learning Rate: 0.00169426
	LOSS [training: 0.6061856289056972 | validation: 0.9858564924462414]
	TIME [epoch: 10.3 sec]
EPOCH 389/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7224124093512833		[learning rate: 0.0016863]
	Learning Rate: 0.00168632
	LOSS [training: 0.7224124093512833 | validation: 0.6569042402664428]
	TIME [epoch: 10.3 sec]
EPOCH 390/500:
	Training over batches...
		[batch 5/5] avg loss: 0.591166968589899		[learning rate: 0.0016784]
	Learning Rate: 0.00167841
	LOSS [training: 0.591166968589899 | validation: 0.6669880400976683]
	TIME [epoch: 10.3 sec]
EPOCH 391/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5235803762115747		[learning rate: 0.0016705]
	Learning Rate: 0.00167054
	LOSS [training: 0.5235803762115747 | validation: 0.6979443559461929]
	TIME [epoch: 10.3 sec]
EPOCH 392/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5743721143012742		[learning rate: 0.0016627]
	Learning Rate: 0.00166271
	LOSS [training: 0.5743721143012742 | validation: 0.5999394271112157]
	TIME [epoch: 10.3 sec]
EPOCH 393/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5303467296043546		[learning rate: 0.0016549]
	Learning Rate: 0.00165491
	LOSS [training: 0.5303467296043546 | validation: 0.5656331822956128]
	TIME [epoch: 10.3 sec]
EPOCH 394/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5864203861013165		[learning rate: 0.0016472]
	Learning Rate: 0.00164716
	LOSS [training: 0.5864203861013165 | validation: 0.640944918427185]
	TIME [epoch: 10.3 sec]
EPOCH 395/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4984458814977155		[learning rate: 0.0016394]
	Learning Rate: 0.00163943
	LOSS [training: 0.4984458814977155 | validation: 0.6238893532368419]
	TIME [epoch: 10.3 sec]
EPOCH 396/500:
	Training over batches...
		[batch 5/5] avg loss: 0.49510455983274076		[learning rate: 0.0016317]
	Learning Rate: 0.00163175
	LOSS [training: 0.49510455983274076 | validation: 0.6386609444496755]
	TIME [epoch: 10.3 sec]
EPOCH 397/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5156782485896064		[learning rate: 0.0016241]
	Learning Rate: 0.0016241
	LOSS [training: 0.5156782485896064 | validation: 0.5062261117332648]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_397.pth
	Model improved!!!
EPOCH 398/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5511645712459611		[learning rate: 0.0016165]
	Learning Rate: 0.00161648
	LOSS [training: 0.5511645712459611 | validation: 0.5270991263111675]
	TIME [epoch: 10.3 sec]
EPOCH 399/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5901604250957575		[learning rate: 0.0016089]
	Learning Rate: 0.00160891
	LOSS [training: 0.5901604250957575 | validation: 0.5456038790304337]
	TIME [epoch: 10.3 sec]
EPOCH 400/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4513281795959504		[learning rate: 0.0016014]
	Learning Rate: 0.00160136
	LOSS [training: 0.4513281795959504 | validation: 0.507013252385479]
	TIME [epoch: 10.3 sec]
EPOCH 401/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4497105497960698		[learning rate: 0.0015939]
	Learning Rate: 0.00159386
	LOSS [training: 0.4497105497960698 | validation: 0.5254769937677236]
	TIME [epoch: 10.3 sec]
EPOCH 402/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4488801100485145		[learning rate: 0.0015864]
	Learning Rate: 0.00158638
	LOSS [training: 0.4488801100485145 | validation: 0.5975427090625444]
	TIME [epoch: 10.3 sec]
EPOCH 403/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47749673677646365		[learning rate: 0.0015789]
	Learning Rate: 0.00157895
	LOSS [training: 0.47749673677646365 | validation: 0.5445473747766153]
	TIME [epoch: 10.3 sec]
EPOCH 404/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5452748032923271		[learning rate: 0.0015715]
	Learning Rate: 0.00157154
	LOSS [training: 0.5452748032923271 | validation: 0.7430115790154221]
	TIME [epoch: 10.3 sec]
EPOCH 405/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5916284154371347		[learning rate: 0.0015642]
	Learning Rate: 0.00156418
	LOSS [training: 0.5916284154371347 | validation: 0.8274548639602084]
	TIME [epoch: 10.3 sec]
EPOCH 406/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6029736462543814		[learning rate: 0.0015568]
	Learning Rate: 0.00155684
	LOSS [training: 0.6029736462543814 | validation: 0.5092985332574385]
	TIME [epoch: 10.3 sec]
EPOCH 407/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46102082784271425		[learning rate: 0.0015495]
	Learning Rate: 0.00154954
	LOSS [training: 0.46102082784271425 | validation: 1.0108047908319786]
	TIME [epoch: 10.3 sec]
EPOCH 408/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8041664425883237		[learning rate: 0.0015423]
	Learning Rate: 0.00154228
	LOSS [training: 0.8041664425883237 | validation: 0.5239064379905524]
	TIME [epoch: 10.3 sec]
EPOCH 409/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5204551272378486		[learning rate: 0.001535]
	Learning Rate: 0.00153505
	LOSS [training: 0.5204551272378486 | validation: 0.73742100257432]
	TIME [epoch: 10.3 sec]
EPOCH 410/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5379054337594356		[learning rate: 0.0015279]
	Learning Rate: 0.00152785
	LOSS [training: 0.5379054337594356 | validation: 0.5115552591832468]
	TIME [epoch: 10.3 sec]
EPOCH 411/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46181433402555194		[learning rate: 0.0015207]
	Learning Rate: 0.00152069
	LOSS [training: 0.46181433402555194 | validation: 0.4794216415519971]
	TIME [epoch: 10.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_411.pth
	Model improved!!!
EPOCH 412/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4458801058011076		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.4458801058011076 | validation: 0.7531151770256483]
	TIME [epoch: 10.1 sec]
EPOCH 413/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5481479468436694		[learning rate: 0.0015065]
	Learning Rate: 0.00150647
	LOSS [training: 0.5481479468436694 | validation: 0.4555399977394206]
	TIME [epoch: 10.1 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r5_20240214_200611/states/model_tr_study6_413.pth
	Model improved!!!
EPOCH 414/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4335330963386098		[learning rate: 0.0014994]
	Learning Rate: 0.0014994
	LOSS [training: 0.4335330963386098 | validation: 0.515879974624887]
	TIME [epoch: 10.2 sec]
EPOCH 415/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4980833100427633		[learning rate: 0.0014924]
	Learning Rate: 0.00149237
	LOSS [training: 0.4980833100427633 | validation: 0.48029485540878925]
	TIME [epoch: 10.2 sec]
EPOCH 416/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5196364600711185		[learning rate: 0.0014854]
	Learning Rate: 0.00148538
	LOSS [training: 0.5196364600711185 | validation: 0.5368939445189922]
	TIME [epoch: 10.2 sec]
EPOCH 417/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5072569610608456		[learning rate: 0.0014784]
	Learning Rate: 0.00147841
	LOSS [training: 0.5072569610608456 | validation: 0.5712839031775354]
	TIME [epoch: 10.2 sec]
EPOCH 418/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5494648479480103		[learning rate: 0.0014715]
	Learning Rate: 0.00147148
	LOSS [training: 0.5494648479480103 | validation: 0.5127082342004916]
	TIME [epoch: 10.2 sec]
EPOCH 419/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5057895407700908		[learning rate: 0.0014646]
	Learning Rate: 0.00146458
	LOSS [training: 0.5057895407700908 | validation: 0.5433134938254721]
	TIME [epoch: 10.3 sec]
EPOCH 420/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48818025996628667		[learning rate: 0.0014577]
	Learning Rate: 0.00145772
	LOSS [training: 0.48818025996628667 | validation: 0.6120028983676664]
	TIME [epoch: 10.3 sec]
EPOCH 421/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5409421661618877		[learning rate: 0.0014509]
	Learning Rate: 0.00145088
	LOSS [training: 0.5409421661618877 | validation: 0.5261079570863579]
	TIME [epoch: 10.2 sec]
EPOCH 422/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6093952618896079		[learning rate: 0.0014441]
	Learning Rate: 0.00144408
	LOSS [training: 0.6093952618896079 | validation: 1.0264583108779033]
	TIME [epoch: 10.3 sec]
EPOCH 423/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6984808224070378		[learning rate: 0.0014373]
	Learning Rate: 0.00143731
	LOSS [training: 0.6984808224070378 | validation: 0.5372458166699713]
	TIME [epoch: 10.2 sec]
EPOCH 424/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5545555912590818		[learning rate: 0.0014306]
	Learning Rate: 0.00143057
	LOSS [training: 0.5545555912590818 | validation: 0.6242179892049268]
	TIME [epoch: 10.1 sec]
EPOCH 425/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8334582917948575		[learning rate: 0.0014239]
	Learning Rate: 0.00142387
	LOSS [training: 0.8334582917948575 | validation: 0.594059438252847]
	TIME [epoch: 10.2 sec]
EPOCH 426/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5950895366808605		[learning rate: 0.0014172]
	Learning Rate: 0.00141719
	LOSS [training: 0.5950895366808605 | validation: 0.5261109149940784]
	TIME [epoch: 10.2 sec]
EPOCH 427/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4971354104613348		[learning rate: 0.0014105]
	Learning Rate: 0.00141055
	LOSS [training: 0.4971354104613348 | validation: 0.520878359622505]
	TIME [epoch: 10.3 sec]
EPOCH 428/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4945004014515687		[learning rate: 0.0014039]
	Learning Rate: 0.00140393
	LOSS [training: 0.4945004014515687 | validation: 0.5081219178826542]
	TIME [epoch: 10.2 sec]
EPOCH 429/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5257784928416998		[learning rate: 0.0013974]
	Learning Rate: 0.00139735
	LOSS [training: 0.5257784928416998 | validation: 0.7773756674920805]
	TIME [epoch: 10.2 sec]
EPOCH 430/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5163836341777073		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.5163836341777073 | validation: 0.5586032477934088]
	TIME [epoch: 10.2 sec]
EPOCH 431/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47849416440717196		[learning rate: 0.0013843]
	Learning Rate: 0.00138428
	LOSS [training: 0.47849416440717196 | validation: 0.5191923895797368]
	TIME [epoch: 10.3 sec]
EPOCH 432/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47926521115949994		[learning rate: 0.0013778]
	Learning Rate: 0.00137779
	LOSS [training: 0.47926521115949994 | validation: 0.5284180256657318]
	TIME [epoch: 10.2 sec]
EPOCH 433/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5372432621684641		[learning rate: 0.0013713]
	Learning Rate: 0.00137133
	LOSS [training: 0.5372432621684641 | validation: 0.5323097090239193]
	TIME [epoch: 10.2 sec]
EPOCH 434/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4833431510025795		[learning rate: 0.0013649]
	Learning Rate: 0.0013649
	LOSS [training: 0.4833431510025795 | validation: 0.5323900517144936]
	TIME [epoch: 10.3 sec]
EPOCH 435/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45121767308529465		[learning rate: 0.0013585]
	Learning Rate: 0.0013585
	LOSS [training: 0.45121767308529465 | validation: 0.5702613813482111]
	TIME [epoch: 10.3 sec]
EPOCH 436/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4569579285064366		[learning rate: 0.0013521]
	Learning Rate: 0.00135214
	LOSS [training: 0.4569579285064366 | validation: 0.5160211355274358]
	TIME [epoch: 10.3 sec]
EPOCH 437/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46123724242638947		[learning rate: 0.0013458]
	Learning Rate: 0.0013458
	LOSS [training: 0.46123724242638947 | validation: 0.5693132580476333]
	TIME [epoch: 10.2 sec]
EPOCH 438/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5241125338208015		[learning rate: 0.0013395]
	Learning Rate: 0.00133949
	LOSS [training: 0.5241125338208015 | validation: 0.5213290932656018]
	TIME [epoch: 10.3 sec]
EPOCH 439/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5987239567265179		[learning rate: 0.0013332]
	Learning Rate: 0.00133321
	LOSS [training: 0.5987239567265179 | validation: 0.6278163920253096]
	TIME [epoch: 10.3 sec]
EPOCH 440/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4854229246731913		[learning rate: 0.001327]
	Learning Rate: 0.00132696
	LOSS [training: 0.4854229246731913 | validation: 0.6714190384312508]
	TIME [epoch: 10.3 sec]
EPOCH 441/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5105804737035662		[learning rate: 0.0013207]
	Learning Rate: 0.00132074
	LOSS [training: 0.5105804737035662 | validation: 0.5073258510359088]
	TIME [epoch: 10.2 sec]
EPOCH 442/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4499747811632832		[learning rate: 0.0013145]
	Learning Rate: 0.00131454
	LOSS [training: 0.4499747811632832 | validation: 0.5327928782012283]
	TIME [epoch: 10.3 sec]
EPOCH 443/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5681835555901198		[learning rate: 0.0013084]
	Learning Rate: 0.00130838
	LOSS [training: 0.5681835555901198 | validation: 0.6302286815130739]
	TIME [epoch: 10.3 sec]
EPOCH 444/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4726592450903982		[learning rate: 0.0013022]
	Learning Rate: 0.00130225
	LOSS [training: 0.4726592450903982 | validation: 0.5363625273129773]
	TIME [epoch: 10.3 sec]
EPOCH 445/500:
	Training over batches...
		[batch 5/5] avg loss: 0.502264720947338		[learning rate: 0.0012961]
	Learning Rate: 0.00129614
	LOSS [training: 0.502264720947338 | validation: 0.4728939908708493]
	TIME [epoch: 10.3 sec]
EPOCH 446/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4580991910333056		[learning rate: 0.0012901]
	Learning Rate: 0.00129007
	LOSS [training: 0.4580991910333056 | validation: 0.48950372122294894]
	TIME [epoch: 10.3 sec]
EPOCH 447/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45782039231247856		[learning rate: 0.001284]
	Learning Rate: 0.00128402
	LOSS [training: 0.45782039231247856 | validation: 0.6294532809663584]
	TIME [epoch: 10.3 sec]
EPOCH 448/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47223903770926023		[learning rate: 0.001278]
	Learning Rate: 0.001278
	LOSS [training: 0.47223903770926023 | validation: 0.536984059219178]
	TIME [epoch: 10.3 sec]
EPOCH 449/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5465342391337542		[learning rate: 0.001272]
	Learning Rate: 0.00127201
	LOSS [training: 0.5465342391337542 | validation: 0.5818670764174677]
	TIME [epoch: 10.2 sec]
EPOCH 450/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4910092547529275		[learning rate: 0.001266]
	Learning Rate: 0.00126604
	LOSS [training: 0.4910092547529275 | validation: 0.5130290780509165]
	TIME [epoch: 10.3 sec]
EPOCH 451/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4787087807227241		[learning rate: 0.0012601]
	Learning Rate: 0.00126011
	LOSS [training: 0.4787087807227241 | validation: 0.5522541233151307]
	TIME [epoch: 10.3 sec]
EPOCH 452/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5135754947110511		[learning rate: 0.0012542]
	Learning Rate: 0.0012542
	LOSS [training: 0.5135754947110511 | validation: 0.5296973395155204]
	TIME [epoch: 10.3 sec]
EPOCH 453/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4421571808407817		[learning rate: 0.0012483]
	Learning Rate: 0.00124832
	LOSS [training: 0.4421571808407817 | validation: 0.5495674641239005]
	TIME [epoch: 10.3 sec]
EPOCH 454/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45645239446946134		[learning rate: 0.0012425]
	Learning Rate: 0.00124247
	LOSS [training: 0.45645239446946134 | validation: 0.5593212726085505]
	TIME [epoch: 10.2 sec]
EPOCH 455/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4816462004889763		[learning rate: 0.0012366]
	Learning Rate: 0.00123664
	LOSS [training: 0.4816462004889763 | validation: 0.6012914866418261]
	TIME [epoch: 10.3 sec]
EPOCH 456/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5796303465889556		[learning rate: 0.0012308]
	Learning Rate: 0.00123085
	LOSS [training: 0.5796303465889556 | validation: 0.593252584225472]
	TIME [epoch: 10.3 sec]
EPOCH 457/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46392079961401694		[learning rate: 0.0012251]
	Learning Rate: 0.00122508
	LOSS [training: 0.46392079961401694 | validation: 0.7426409847625516]
	TIME [epoch: 10.3 sec]
EPOCH 458/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6284362646268118		[learning rate: 0.0012193]
	Learning Rate: 0.00121933
	LOSS [training: 0.6284362646268118 | validation: 0.57357740613246]
	TIME [epoch: 10.3 sec]
EPOCH 459/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4779309429270994		[learning rate: 0.0012136]
	Learning Rate: 0.00121362
	LOSS [training: 0.4779309429270994 | validation: 0.6127437001539492]
	TIME [epoch: 10.3 sec]
EPOCH 460/500:
	Training over batches...
		[batch 5/5] avg loss: 0.502233455777324		[learning rate: 0.0012079]
	Learning Rate: 0.00120793
	LOSS [training: 0.502233455777324 | validation: 0.5928191054110561]
	TIME [epoch: 10.3 sec]
EPOCH 461/500:
	Training over batches...
		[batch 5/5] avg loss: 0.49723326430059067		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.49723326430059067 | validation: 0.865267442275706]
	TIME [epoch: 10.3 sec]
EPOCH 462/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5974698044206674		[learning rate: 0.0011966]
	Learning Rate: 0.00119663
	LOSS [training: 0.5974698044206674 | validation: 0.5620377338476417]
	TIME [epoch: 10.3 sec]
EPOCH 463/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5104945258147578		[learning rate: 0.001191]
	Learning Rate: 0.00119102
	LOSS [training: 0.5104945258147578 | validation: 0.5249743872651481]
	TIME [epoch: 10.3 sec]
EPOCH 464/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5953438956578949		[learning rate: 0.0011854]
	Learning Rate: 0.00118543
	LOSS [training: 0.5953438956578949 | validation: 0.5682902417732348]
	TIME [epoch: 10.3 sec]
EPOCH 465/500:
	Training over batches...
		[batch 5/5] avg loss: 0.47298569362627213		[learning rate: 0.0011799]
	Learning Rate: 0.00117988
	LOSS [training: 0.47298569362627213 | validation: 0.5069201913165101]
	TIME [epoch: 10.3 sec]
EPOCH 466/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4404545182115728		[learning rate: 0.0011743]
	Learning Rate: 0.00117435
	LOSS [training: 0.4404545182115728 | validation: 0.5998212548182101]
	TIME [epoch: 10.3 sec]
EPOCH 467/500:
	Training over batches...
		[batch 5/5] avg loss: 0.492094380784485		[learning rate: 0.0011688]
	Learning Rate: 0.00116884
	LOSS [training: 0.492094380784485 | validation: 0.5651217385536568]
	TIME [epoch: 10.3 sec]
EPOCH 468/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5101077203288449		[learning rate: 0.0011634]
	Learning Rate: 0.00116336
	LOSS [training: 0.5101077203288449 | validation: 0.6054319531251577]
	TIME [epoch: 10.3 sec]
EPOCH 469/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4776005681389077		[learning rate: 0.0011579]
	Learning Rate: 0.00115791
	LOSS [training: 0.4776005681389077 | validation: 0.6594610497153957]
	TIME [epoch: 10.3 sec]
EPOCH 470/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4914687494228248		[learning rate: 0.0011525]
	Learning Rate: 0.00115248
	LOSS [training: 0.4914687494228248 | validation: 0.5097888043649296]
	TIME [epoch: 10.3 sec]
EPOCH 471/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4457629942052529		[learning rate: 0.0011471]
	Learning Rate: 0.00114708
	LOSS [training: 0.4457629942052529 | validation: 0.5041949482237695]
	TIME [epoch: 10.3 sec]
EPOCH 472/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45728641236793005		[learning rate: 0.0011417]
	Learning Rate: 0.0011417
	LOSS [training: 0.45728641236793005 | validation: 0.5344348287959688]
	TIME [epoch: 10.3 sec]
EPOCH 473/500:
	Training over batches...
		[batch 5/5] avg loss: 0.44469238327905625		[learning rate: 0.0011363]
	Learning Rate: 0.00113635
	LOSS [training: 0.44469238327905625 | validation: 0.5035831590165818]
	TIME [epoch: 10.3 sec]
EPOCH 474/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5803806046610873		[learning rate: 0.001131]
	Learning Rate: 0.00113102
	LOSS [training: 0.5803806046610873 | validation: 0.5384847882206651]
	TIME [epoch: 10.3 sec]
EPOCH 475/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5259013466846947		[learning rate: 0.0011257]
	Learning Rate: 0.00112572
	LOSS [training: 0.5259013466846947 | validation: 0.5146149627460941]
	TIME [epoch: 10.3 sec]
EPOCH 476/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4571844131943287		[learning rate: 0.0011204]
	Learning Rate: 0.00112044
	LOSS [training: 0.4571844131943287 | validation: 0.5389285887168069]
	TIME [epoch: 10.3 sec]
EPOCH 477/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5467846692276559		[learning rate: 0.0011152]
	Learning Rate: 0.00111518
	LOSS [training: 0.5467846692276559 | validation: 0.5065815962227423]
	TIME [epoch: 10.3 sec]
EPOCH 478/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5994585107797854		[learning rate: 0.00111]
	Learning Rate: 0.00110996
	LOSS [training: 0.5994585107797854 | validation: 0.5529353644153615]
	TIME [epoch: 10.3 sec]
EPOCH 479/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5044438987925116		[learning rate: 0.0011048]
	Learning Rate: 0.00110475
	LOSS [training: 0.5044438987925116 | validation: 0.5949435192026402]
	TIME [epoch: 10.3 sec]
EPOCH 480/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5872415522740877		[learning rate: 0.0010996]
	Learning Rate: 0.00109957
	LOSS [training: 0.5872415522740877 | validation: 0.5763623305594672]
	TIME [epoch: 10.3 sec]
EPOCH 481/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5377454303774434		[learning rate: 0.0010944]
	Learning Rate: 0.00109442
	LOSS [training: 0.5377454303774434 | validation: 0.5824472488657314]
	TIME [epoch: 10.3 sec]
EPOCH 482/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5774420672590193		[learning rate: 0.0010893]
	Learning Rate: 0.00108929
	LOSS [training: 0.5774420672590193 | validation: 0.7075498468467945]
	TIME [epoch: 10.3 sec]
EPOCH 483/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5175726586668851		[learning rate: 0.0010842]
	Learning Rate: 0.00108418
	LOSS [training: 0.5175726586668851 | validation: 0.5898410831835471]
	TIME [epoch: 10.3 sec]
EPOCH 484/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5433571656721559		[learning rate: 0.0010791]
	Learning Rate: 0.0010791
	LOSS [training: 0.5433571656721559 | validation: 0.5047968299501245]
	TIME [epoch: 10.3 sec]
EPOCH 485/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4836514768587058		[learning rate: 0.001074]
	Learning Rate: 0.00107404
	LOSS [training: 0.4836514768587058 | validation: 0.5693910079384888]
	TIME [epoch: 10.3 sec]
EPOCH 486/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6473563675024815		[learning rate: 0.001069]
	Learning Rate: 0.001069
	LOSS [training: 0.6473563675024815 | validation: 0.546167769500589]
	TIME [epoch: 10.3 sec]
EPOCH 487/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6010310550716509		[learning rate: 0.001064]
	Learning Rate: 0.00106399
	LOSS [training: 0.6010310550716509 | validation: 0.6426747569491984]
	TIME [epoch: 10.3 sec]
EPOCH 488/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4710911109688277		[learning rate: 0.001059]
	Learning Rate: 0.001059
	LOSS [training: 0.4710911109688277 | validation: 0.5749528202967634]
	TIME [epoch: 10.3 sec]
EPOCH 489/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48305802820552224		[learning rate: 0.001054]
	Learning Rate: 0.00105404
	LOSS [training: 0.48305802820552224 | validation: 0.4890290086633051]
	TIME [epoch: 10.3 sec]
EPOCH 490/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4567717060904933		[learning rate: 0.0010491]
	Learning Rate: 0.0010491
	LOSS [training: 0.4567717060904933 | validation: 0.4947488341804009]
	TIME [epoch: 10.3 sec]
EPOCH 491/500:
	Training over batches...
		[batch 5/5] avg loss: 0.634092121913657		[learning rate: 0.0010442]
	Learning Rate: 0.00104418
	LOSS [training: 0.634092121913657 | validation: 0.6725970628982262]
	TIME [epoch: 10.3 sec]
EPOCH 492/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4785945772011345		[learning rate: 0.0010393]
	Learning Rate: 0.00103929
	LOSS [training: 0.4785945772011345 | validation: 0.5072499671788828]
	TIME [epoch: 10.3 sec]
EPOCH 493/500:
	Training over batches...
		[batch 5/5] avg loss: 0.655102807124031		[learning rate: 0.0010344]
	Learning Rate: 0.00103441
	LOSS [training: 0.655102807124031 | validation: 0.5332683290125071]
	TIME [epoch: 10.3 sec]
EPOCH 494/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4675500058619044		[learning rate: 0.0010296]
	Learning Rate: 0.00102956
	LOSS [training: 0.4675500058619044 | validation: 0.4844970353344482]
	TIME [epoch: 10.3 sec]
EPOCH 495/500:
	Training over batches...
		[batch 5/5] avg loss: 0.42887190134116154		[learning rate: 0.0010247]
	Learning Rate: 0.00102474
	LOSS [training: 0.42887190134116154 | validation: 0.5300941396387885]
	TIME [epoch: 10.3 sec]
EPOCH 496/500:
	Training over batches...
		[batch 5/5] avg loss: 0.49064784633150815		[learning rate: 0.0010199]
	Learning Rate: 0.00101993
	LOSS [training: 0.49064784633150815 | validation: 0.5086245108816412]
	TIME [epoch: 10.3 sec]
EPOCH 497/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48857992678577966		[learning rate: 0.0010152]
	Learning Rate: 0.00101515
	LOSS [training: 0.48857992678577966 | validation: 0.5429041872480239]
	TIME [epoch: 10.3 sec]
EPOCH 498/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5328836565578231		[learning rate: 0.0010104]
	Learning Rate: 0.00101039
	LOSS [training: 0.5328836565578231 | validation: 0.5241132565219128]
	TIME [epoch: 10.3 sec]
EPOCH 499/500:
	Training over batches...
		[batch 5/5] avg loss: 0.44805223333716065		[learning rate: 0.0010057]
	Learning Rate: 0.00100565
	LOSS [training: 0.44805223333716065 | validation: 0.543427736471299]
	TIME [epoch: 10.3 sec]
EPOCH 500/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5596957663046247		[learning rate: 0.0010009]
	Learning Rate: 0.00100094
	LOSS [training: 0.5596957663046247 | validation: 0.47569508791710613]
	TIME [epoch: 10.3 sec]
Finished training in 5199.325 seconds.
