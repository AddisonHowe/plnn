Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r3', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=500, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=10, nepochs_decay=-1, final_learning_rate=0.001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 14856729

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_0.pth
EPOCH 1/500:
	Training over batches...
		[batch 5/5] avg loss: 9.603524148438229		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.603524148438229 | validation: 9.822558240707863]
	TIME [epoch: 49.3 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/500:
	Training over batches...
		[batch 5/5] avg loss: 9.139545691911422		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.139545691911422 | validation: 9.061279077544633]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/500:
	Training over batches...
		[batch 5/5] avg loss: 8.5494907622524		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.5494907622524 | validation: 8.430441793074365]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/500:
	Training over batches...
		[batch 5/5] avg loss: 8.079082342550418		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.079082342550418 | validation: 8.843147974955972]
	TIME [epoch: 10.4 sec]
EPOCH 5/500:
	Training over batches...
		[batch 5/5] avg loss: 7.83011388008349		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.83011388008349 | validation: 7.811196310574173]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/500:
	Training over batches...
		[batch 5/5] avg loss: 7.404008748828045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.404008748828045 | validation: 7.691908530972272]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/500:
	Training over batches...
		[batch 5/5] avg loss: 7.142876460819915		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.142876460819915 | validation: 7.4390516587834465]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/500:
	Training over batches...
		[batch 5/5] avg loss: 6.947779057411681		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.947779057411681 | validation: 7.312644875301437]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/500:
	Training over batches...
		[batch 5/5] avg loss: 6.806939909679892		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.806939909679892 | validation: 7.237913094387568]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/500:
	Training over batches...
		[batch 5/5] avg loss: 6.697627715177717		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.697627715177717 | validation: 7.404864062172282]
	TIME [epoch: 10.5 sec]
EPOCH 11/500:
	Training over batches...
		[batch 5/5] avg loss: 6.879992264512154		[learning rate: 0.0099625]
	Learning Rate: 0.00996248
	LOSS [training: 6.879992264512154 | validation: 7.208362312662864]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_11.pth
	Model improved!!!
EPOCH 12/500:
	Training over batches...
		[batch 5/5] avg loss: 6.673437484295242		[learning rate: 0.0099158]
	Learning Rate: 0.00991577
	LOSS [training: 6.673437484295242 | validation: 7.067404604879587]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_12.pth
	Model improved!!!
EPOCH 13/500:
	Training over batches...
		[batch 5/5] avg loss: 6.577125119609503		[learning rate: 0.0098693]
	Learning Rate: 0.00986928
	LOSS [training: 6.577125119609503 | validation: 6.378482815701557]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/500:
	Training over batches...
		[batch 5/5] avg loss: 6.278884610567214		[learning rate: 0.009823]
	Learning Rate: 0.00982302
	LOSS [training: 6.278884610567214 | validation: 5.7123064407710125]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_14.pth
	Model improved!!!
EPOCH 15/500:
	Training over batches...
		[batch 5/5] avg loss: 5.40067521526579		[learning rate: 0.009777]
	Learning Rate: 0.00977696
	LOSS [training: 5.40067521526579 | validation: 5.0862351329341235]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/500:
	Training over batches...
		[batch 5/5] avg loss: 4.732330755202906		[learning rate: 0.0097311]
	Learning Rate: 0.00973113
	LOSS [training: 4.732330755202906 | validation: 3.8025266205261703]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/500:
	Training over batches...
		[batch 5/5] avg loss: 3.9539155240767108		[learning rate: 0.0096855]
	Learning Rate: 0.00968551
	LOSS [training: 3.9539155240767108 | validation: 3.245188323938944]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_17.pth
	Model improved!!!
EPOCH 18/500:
	Training over batches...
		[batch 5/5] avg loss: 3.6234680293178343		[learning rate: 0.0096401]
	Learning Rate: 0.0096401
	LOSS [training: 3.6234680293178343 | validation: 3.263192849182658]
	TIME [epoch: 10.4 sec]
EPOCH 19/500:
	Training over batches...
		[batch 5/5] avg loss: 4.04255899418138		[learning rate: 0.0095949]
	Learning Rate: 0.00959491
	LOSS [training: 4.04255899418138 | validation: 6.180760367357497]
	TIME [epoch: 10.4 sec]
EPOCH 20/500:
	Training over batches...
		[batch 5/5] avg loss: 5.185069790628447		[learning rate: 0.0095499]
	Learning Rate: 0.00954993
	LOSS [training: 5.185069790628447 | validation: 3.257304339146018]
	TIME [epoch: 10.4 sec]
EPOCH 21/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4979178165074125		[learning rate: 0.0095052]
	Learning Rate: 0.00950515
	LOSS [training: 3.4979178165074125 | validation: 2.7833072880329626]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_21.pth
	Model improved!!!
EPOCH 22/500:
	Training over batches...
		[batch 5/5] avg loss: 3.333084427213051		[learning rate: 0.0094606]
	Learning Rate: 0.00946059
	LOSS [training: 3.333084427213051 | validation: 2.8851193081987025]
	TIME [epoch: 10.4 sec]
EPOCH 23/500:
	Training over batches...
		[batch 5/5] avg loss: 3.8125193592246873		[learning rate: 0.0094162]
	Learning Rate: 0.00941624
	LOSS [training: 3.8125193592246873 | validation: 2.8695358516365785]
	TIME [epoch: 10.4 sec]
EPOCH 24/500:
	Training over batches...
		[batch 5/5] avg loss: 3.3283390156788677		[learning rate: 0.0093721]
	Learning Rate: 0.0093721
	LOSS [training: 3.3283390156788677 | validation: 2.851751667021595]
	TIME [epoch: 10.4 sec]
EPOCH 25/500:
	Training over batches...
		[batch 5/5] avg loss: 3.274699958326857		[learning rate: 0.0093282]
	Learning Rate: 0.00932816
	LOSS [training: 3.274699958326857 | validation: 3.093306368579606]
	TIME [epoch: 10.4 sec]
EPOCH 26/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1657111652359857		[learning rate: 0.0092844]
	Learning Rate: 0.00928443
	LOSS [training: 3.1657111652359857 | validation: 2.658235229181211]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_26.pth
	Model improved!!!
EPOCH 27/500:
	Training over batches...
		[batch 5/5] avg loss: 3.2405588982628353		[learning rate: 0.0092409]
	Learning Rate: 0.0092409
	LOSS [training: 3.2405588982628353 | validation: 3.046212995345336]
	TIME [epoch: 10.4 sec]
EPOCH 28/500:
	Training over batches...
		[batch 5/5] avg loss: 3.1326340605484093		[learning rate: 0.0091976]
	Learning Rate: 0.00919758
	LOSS [training: 3.1326340605484093 | validation: 2.9383192861030136]
	TIME [epoch: 10.4 sec]
EPOCH 29/500:
	Training over batches...
		[batch 5/5] avg loss: 4.238111692647168		[learning rate: 0.0091545]
	Learning Rate: 0.00915446
	LOSS [training: 4.238111692647168 | validation: 3.8781303036032955]
	TIME [epoch: 10.4 sec]
EPOCH 30/500:
	Training over batches...
		[batch 5/5] avg loss: 3.347031912692633		[learning rate: 0.0091115]
	Learning Rate: 0.00911154
	LOSS [training: 3.347031912692633 | validation: 2.6554443586919714]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/500:
	Training over batches...
		[batch 5/5] avg loss: 3.225908365304594		[learning rate: 0.0090688]
	Learning Rate: 0.00906882
	LOSS [training: 3.225908365304594 | validation: 2.778852325870762]
	TIME [epoch: 10.4 sec]
EPOCH 32/500:
	Training over batches...
		[batch 5/5] avg loss: 3.377710025539751		[learning rate: 0.0090263]
	Learning Rate: 0.00902631
	LOSS [training: 3.377710025539751 | validation: 3.621963911902119]
	TIME [epoch: 10.4 sec]
EPOCH 33/500:
	Training over batches...
		[batch 5/5] avg loss: 4.2356986501249505		[learning rate: 0.008984]
	Learning Rate: 0.00898399
	LOSS [training: 4.2356986501249505 | validation: 3.0640355257284315]
	TIME [epoch: 10.4 sec]
EPOCH 34/500:
	Training over batches...
		[batch 5/5] avg loss: 3.7874132260391336		[learning rate: 0.0089419]
	Learning Rate: 0.00894187
	LOSS [training: 3.7874132260391336 | validation: 4.0745970905888695]
	TIME [epoch: 10.4 sec]
EPOCH 35/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4412837189182546		[learning rate: 0.0089]
	Learning Rate: 0.00889995
	LOSS [training: 3.4412837189182546 | validation: 3.1115611994156396]
	TIME [epoch: 10.4 sec]
EPOCH 36/500:
	Training over batches...
		[batch 5/5] avg loss: 2.9884304352579583		[learning rate: 0.0088582]
	Learning Rate: 0.00885823
	LOSS [training: 2.9884304352579583 | validation: 3.075038134780592]
	TIME [epoch: 10.4 sec]
EPOCH 37/500:
	Training over batches...
		[batch 5/5] avg loss: 3.594726027066545		[learning rate: 0.0088167]
	Learning Rate: 0.0088167
	LOSS [training: 3.594726027066545 | validation: 2.9081756590711665]
	TIME [epoch: 10.4 sec]
EPOCH 38/500:
	Training over batches...
		[batch 5/5] avg loss: 2.827055246713895		[learning rate: 0.0087754]
	Learning Rate: 0.00877537
	LOSS [training: 2.827055246713895 | validation: 2.4603206297600044]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_38.pth
	Model improved!!!
EPOCH 39/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7557039223332973		[learning rate: 0.0087342]
	Learning Rate: 0.00873423
	LOSS [training: 2.7557039223332973 | validation: 4.910744806257045]
	TIME [epoch: 10.4 sec]
EPOCH 40/500:
	Training over batches...
		[batch 5/5] avg loss: 3.4853609865470587		[learning rate: 0.0086933]
	Learning Rate: 0.00869328
	LOSS [training: 3.4853609865470587 | validation: 2.2784728518561854]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_40.pth
	Model improved!!!
EPOCH 41/500:
	Training over batches...
		[batch 5/5] avg loss: 2.8139962873240387		[learning rate: 0.0086525]
	Learning Rate: 0.00865253
	LOSS [training: 2.8139962873240387 | validation: 2.4001581768583864]
	TIME [epoch: 10.5 sec]
EPOCH 42/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6863982045689054		[learning rate: 0.008612]
	Learning Rate: 0.00861196
	LOSS [training: 2.6863982045689054 | validation: 2.446484371837207]
	TIME [epoch: 10.4 sec]
EPOCH 43/500:
	Training over batches...
		[batch 5/5] avg loss: 2.435766726256037		[learning rate: 0.0085716]
	Learning Rate: 0.00857159
	LOSS [training: 2.435766726256037 | validation: 2.335390711789287]
	TIME [epoch: 10.4 sec]
EPOCH 44/500:
	Training over batches...
		[batch 5/5] avg loss: 2.5322738696115836		[learning rate: 0.0085314]
	Learning Rate: 0.0085314
	LOSS [training: 2.5322738696115836 | validation: 2.6552573735329954]
	TIME [epoch: 10.5 sec]
EPOCH 45/500:
	Training over batches...
		[batch 5/5] avg loss: 2.73748762872468		[learning rate: 0.0084914]
	Learning Rate: 0.00849141
	LOSS [training: 2.73748762872468 | validation: 2.7032836895458003]
	TIME [epoch: 10.5 sec]
EPOCH 46/500:
	Training over batches...
		[batch 5/5] avg loss: 2.570907259383106		[learning rate: 0.0084516]
	Learning Rate: 0.0084516
	LOSS [training: 2.570907259383106 | validation: 2.178274484102423]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_46.pth
	Model improved!!!
EPOCH 47/500:
	Training over batches...
		[batch 5/5] avg loss: 2.7379159171363887		[learning rate: 0.008412]
	Learning Rate: 0.00841197
	LOSS [training: 2.7379159171363887 | validation: 2.228427458434839]
	TIME [epoch: 10.4 sec]
EPOCH 48/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3236122299862503		[learning rate: 0.0083725]
	Learning Rate: 0.00837254
	LOSS [training: 2.3236122299862503 | validation: 2.2253763636042034]
	TIME [epoch: 10.4 sec]
EPOCH 49/500:
	Training over batches...
		[batch 5/5] avg loss: 2.342678033477097		[learning rate: 0.0083333]
	Learning Rate: 0.00833329
	LOSS [training: 2.342678033477097 | validation: 2.005025708765284]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_49.pth
	Model improved!!!
EPOCH 50/500:
	Training over batches...
		[batch 5/5] avg loss: 2.2447391504980247		[learning rate: 0.0082942]
	Learning Rate: 0.00829422
	LOSS [training: 2.2447391504980247 | validation: 2.1107619025083637]
	TIME [epoch: 10.4 sec]
EPOCH 51/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0915843476260823		[learning rate: 0.0082553]
	Learning Rate: 0.00825533
	LOSS [training: 2.0915843476260823 | validation: 2.5766462577383846]
	TIME [epoch: 10.4 sec]
EPOCH 52/500:
	Training over batches...
		[batch 5/5] avg loss: 2.6835205632531443		[learning rate: 0.0082166]
	Learning Rate: 0.00821663
	LOSS [training: 2.6835205632531443 | validation: 3.0947997527638407]
	TIME [epoch: 10.5 sec]
EPOCH 53/500:
	Training over batches...
		[batch 5/5] avg loss: 2.3930382266378407		[learning rate: 0.0081781]
	Learning Rate: 0.00817811
	LOSS [training: 2.3930382266378407 | validation: 2.268537428075745]
	TIME [epoch: 10.4 sec]
EPOCH 54/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0954614689752487		[learning rate: 0.0081398]
	Learning Rate: 0.00813977
	LOSS [training: 2.0954614689752487 | validation: 1.8236523306653953]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_54.pth
	Model improved!!!
EPOCH 55/500:
	Training over batches...
		[batch 5/5] avg loss: 2.177748286842528		[learning rate: 0.0081016]
	Learning Rate: 0.00810161
	LOSS [training: 2.177748286842528 | validation: 1.8988479122033228]
	TIME [epoch: 10.4 sec]
EPOCH 56/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8797130414328276		[learning rate: 0.0080636]
	Learning Rate: 0.00806363
	LOSS [training: 1.8797130414328276 | validation: 1.664824636676895]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_56.pth
	Model improved!!!
EPOCH 57/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8016762764371812		[learning rate: 0.0080258]
	Learning Rate: 0.00802583
	LOSS [training: 1.8016762764371812 | validation: 1.7530545632423167]
	TIME [epoch: 10.5 sec]
EPOCH 58/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6904081402185898		[learning rate: 0.0079882]
	Learning Rate: 0.0079882
	LOSS [training: 1.6904081402185898 | validation: 1.6053671522900317]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_58.pth
	Model improved!!!
EPOCH 59/500:
	Training over batches...
		[batch 5/5] avg loss: 1.93425999031097		[learning rate: 0.0079508]
	Learning Rate: 0.00795075
	LOSS [training: 1.93425999031097 | validation: 1.5276627430004412]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_59.pth
	Model improved!!!
EPOCH 60/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7830378370023845		[learning rate: 0.0079135]
	Learning Rate: 0.00791348
	LOSS [training: 1.7830378370023845 | validation: 2.323866444431229]
	TIME [epoch: 10.4 sec]
EPOCH 61/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7460891185854912		[learning rate: 0.0078764]
	Learning Rate: 0.00787638
	LOSS [training: 1.7460891185854912 | validation: 1.5358710815911725]
	TIME [epoch: 10.5 sec]
EPOCH 62/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6095161183777154		[learning rate: 0.0078395]
	Learning Rate: 0.00783945
	LOSS [training: 1.6095161183777154 | validation: 1.28833395656889]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_62.pth
	Model improved!!!
EPOCH 63/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4191820601763792		[learning rate: 0.0078027]
	Learning Rate: 0.0078027
	LOSS [training: 1.4191820601763792 | validation: 1.3474808752517522]
	TIME [epoch: 10.4 sec]
EPOCH 64/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7164293004125633		[learning rate: 0.0077661]
	Learning Rate: 0.00776612
	LOSS [training: 1.7164293004125633 | validation: 2.082061994239587]
	TIME [epoch: 10.5 sec]
EPOCH 65/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7493683352196012		[learning rate: 0.0077297]
	Learning Rate: 0.00772971
	LOSS [training: 1.7493683352196012 | validation: 1.556556637951675]
	TIME [epoch: 10.4 sec]
EPOCH 66/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5531351646005436		[learning rate: 0.0076935]
	Learning Rate: 0.00769347
	LOSS [training: 1.5531351646005436 | validation: 1.3684727611242204]
	TIME [epoch: 10.5 sec]
EPOCH 67/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3065672629870275		[learning rate: 0.0076574]
	Learning Rate: 0.0076574
	LOSS [training: 1.3065672629870275 | validation: 1.2504175432846536]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_67.pth
	Model improved!!!
EPOCH 68/500:
	Training over batches...
		[batch 5/5] avg loss: 1.6881576869143706		[learning rate: 0.0076215]
	Learning Rate: 0.00762151
	LOSS [training: 1.6881576869143706 | validation: 1.2529702736972204]
	TIME [epoch: 10.5 sec]
EPOCH 69/500:
	Training over batches...
		[batch 5/5] avg loss: 1.46484812832121		[learning rate: 0.0075858]
	Learning Rate: 0.00758578
	LOSS [training: 1.46484812832121 | validation: 1.2857965735370396]
	TIME [epoch: 10.5 sec]
EPOCH 70/500:
	Training over batches...
		[batch 5/5] avg loss: 1.4372627326810676		[learning rate: 0.0075502]
	Learning Rate: 0.00755021
	LOSS [training: 1.4372627326810676 | validation: 1.2235930994122595]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_70.pth
	Model improved!!!
EPOCH 71/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2983401495855298		[learning rate: 0.0075148]
	Learning Rate: 0.00751482
	LOSS [training: 1.2983401495855298 | validation: 1.2906711923269882]
	TIME [epoch: 10.5 sec]
EPOCH 72/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2310734802882475		[learning rate: 0.0074796]
	Learning Rate: 0.00747959
	LOSS [training: 1.2310734802882475 | validation: 1.0067919365420044]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_72.pth
	Model improved!!!
EPOCH 73/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1893683650177378		[learning rate: 0.0074445]
	Learning Rate: 0.00744452
	LOSS [training: 1.1893683650177378 | validation: 1.1876356601916225]
	TIME [epoch: 10.4 sec]
EPOCH 74/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2803440782807871		[learning rate: 0.0074096]
	Learning Rate: 0.00740962
	LOSS [training: 1.2803440782807871 | validation: 0.9493414180210071]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_74.pth
	Model improved!!!
EPOCH 75/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9147509114856568		[learning rate: 0.0073749]
	Learning Rate: 0.00737488
	LOSS [training: 0.9147509114856568 | validation: 0.8539112855522398]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_75.pth
	Model improved!!!
EPOCH 76/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0108379467923554		[learning rate: 0.0073403]
	Learning Rate: 0.00734031
	LOSS [training: 1.0108379467923554 | validation: 0.7971323797072191]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_76.pth
	Model improved!!!
EPOCH 77/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8591549150804163		[learning rate: 0.0073059]
	Learning Rate: 0.00730589
	LOSS [training: 0.8591549150804163 | validation: 0.8656639819796027]
	TIME [epoch: 10.4 sec]
EPOCH 78/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2192709878258239		[learning rate: 0.0072716]
	Learning Rate: 0.00727164
	LOSS [training: 1.2192709878258239 | validation: 0.8574522313209815]
	TIME [epoch: 10.5 sec]
EPOCH 79/500:
	Training over batches...
		[batch 5/5] avg loss: 1.432846335758032		[learning rate: 0.0072376]
	Learning Rate: 0.00723755
	LOSS [training: 1.432846335758032 | validation: 0.7615479387589392]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7545807645086017		[learning rate: 0.0072036]
	Learning Rate: 0.00720362
	LOSS [training: 0.7545807645086017 | validation: 0.6796766005613691]
	TIME [epoch: 10.4 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_80.pth
	Model improved!!!
EPOCH 81/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8350068406337066		[learning rate: 0.0071699]
	Learning Rate: 0.00716985
	LOSS [training: 1.8350068406337066 | validation: 0.908846374471062]
	TIME [epoch: 10.4 sec]
EPOCH 82/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9345882370843744		[learning rate: 0.0071362]
	Learning Rate: 0.00713624
	LOSS [training: 0.9345882370843744 | validation: 1.6002387855290539]
	TIME [epoch: 10.4 sec]
EPOCH 83/500:
	Training over batches...
		[batch 5/5] avg loss: 1.5207625336801456		[learning rate: 0.0071028]
	Learning Rate: 0.00710278
	LOSS [training: 1.5207625336801456 | validation: 1.0238481157870376]
	TIME [epoch: 10.4 sec]
EPOCH 84/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1411363833718033		[learning rate: 0.0070695]
	Learning Rate: 0.00706948
	LOSS [training: 1.1411363833718033 | validation: 0.7274901739545747]
	TIME [epoch: 10.4 sec]
EPOCH 85/500:
	Training over batches...
		[batch 5/5] avg loss: 0.890458456400572		[learning rate: 0.0070363]
	Learning Rate: 0.00703634
	LOSS [training: 0.890458456400572 | validation: 1.8688939900461006]
	TIME [epoch: 10.4 sec]
EPOCH 86/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3492015116289735		[learning rate: 0.0070034]
	Learning Rate: 0.00700335
	LOSS [training: 1.3492015116289735 | validation: 0.9414963580648521]
	TIME [epoch: 10.4 sec]
EPOCH 87/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9424459347635133		[learning rate: 0.0069705]
	Learning Rate: 0.00697052
	LOSS [training: 0.9424459347635133 | validation: 0.9470203290234577]
	TIME [epoch: 10.4 sec]
EPOCH 88/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9235897875465753		[learning rate: 0.0069378]
	Learning Rate: 0.00693784
	LOSS [training: 0.9235897875465753 | validation: 0.8004876345224119]
	TIME [epoch: 10.4 sec]
EPOCH 89/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8974280489058195		[learning rate: 0.0069053]
	Learning Rate: 0.00690532
	LOSS [training: 0.8974280489058195 | validation: 0.8333229052381352]
	TIME [epoch: 10.5 sec]
EPOCH 90/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3039676040990067		[learning rate: 0.0068729]
	Learning Rate: 0.00687294
	LOSS [training: 1.3039676040990067 | validation: 1.0170435457224989]
	TIME [epoch: 10.4 sec]
EPOCH 91/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8867004269330151		[learning rate: 0.0068407]
	Learning Rate: 0.00684072
	LOSS [training: 0.8867004269330151 | validation: 0.7529915534929896]
	TIME [epoch: 10.4 sec]
EPOCH 92/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7433755826390709		[learning rate: 0.0068087]
	Learning Rate: 0.00680865
	LOSS [training: 0.7433755826390709 | validation: 0.807469819594877]
	TIME [epoch: 10.4 sec]
EPOCH 93/500:
	Training over batches...
		[batch 5/5] avg loss: 0.959071611288441		[learning rate: 0.0067767]
	Learning Rate: 0.00677673
	LOSS [training: 0.959071611288441 | validation: 0.943797873700507]
	TIME [epoch: 10.5 sec]
EPOCH 94/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8855544827189903		[learning rate: 0.006745]
	Learning Rate: 0.00674496
	LOSS [training: 0.8855544827189903 | validation: 0.9183845429935927]
	TIME [epoch: 10.4 sec]
EPOCH 95/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9244458780576128		[learning rate: 0.0067133]
	Learning Rate: 0.00671334
	LOSS [training: 0.9244458780576128 | validation: 0.7694500988515671]
	TIME [epoch: 10.4 sec]
EPOCH 96/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0127672289994725		[learning rate: 0.0066819]
	Learning Rate: 0.00668187
	LOSS [training: 1.0127672289994725 | validation: 2.8811822818301698]
	TIME [epoch: 10.4 sec]
EPOCH 97/500:
	Training over batches...
		[batch 5/5] avg loss: 2.0871978493546792		[learning rate: 0.0066505]
	Learning Rate: 0.00665054
	LOSS [training: 2.0871978493546792 | validation: 1.0544259910854488]
	TIME [epoch: 10.5 sec]
EPOCH 98/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8565925289800465		[learning rate: 0.0066194]
	Learning Rate: 0.00661936
	LOSS [training: 0.8565925289800465 | validation: 0.8043997889612675]
	TIME [epoch: 10.5 sec]
EPOCH 99/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7873626385196673		[learning rate: 0.0065883]
	Learning Rate: 0.00658833
	LOSS [training: 0.7873626385196673 | validation: 1.0081430476546784]
	TIME [epoch: 10.4 sec]
EPOCH 100/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8918569085370317		[learning rate: 0.0065574]
	Learning Rate: 0.00655745
	LOSS [training: 0.8918569085370317 | validation: 0.6584413824350669]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_100.pth
	Model improved!!!
EPOCH 101/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7238902827979505		[learning rate: 0.0065267]
	Learning Rate: 0.0065267
	LOSS [training: 0.7238902827979505 | validation: 1.4293508164896063]
	TIME [epoch: 10.5 sec]
EPOCH 102/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9694441527087478		[learning rate: 0.0064961]
	Learning Rate: 0.0064961
	LOSS [training: 0.9694441527087478 | validation: 0.9381819074343086]
	TIME [epoch: 10.5 sec]
EPOCH 103/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9506623140833332		[learning rate: 0.0064657]
	Learning Rate: 0.00646565
	LOSS [training: 0.9506623140833332 | validation: 0.9593223089676137]
	TIME [epoch: 10.5 sec]
EPOCH 104/500:
	Training over batches...
		[batch 5/5] avg loss: 1.8359702195528904		[learning rate: 0.0064353]
	Learning Rate: 0.00643534
	LOSS [training: 1.8359702195528904 | validation: 1.2256990578320817]
	TIME [epoch: 10.5 sec]
EPOCH 105/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0746962230419514		[learning rate: 0.0064052]
	Learning Rate: 0.00640517
	LOSS [training: 1.0746962230419514 | validation: 0.7326106884290999]
	TIME [epoch: 10.5 sec]
EPOCH 106/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8941670398473125		[learning rate: 0.0063751]
	Learning Rate: 0.00637514
	LOSS [training: 0.8941670398473125 | validation: 0.7874625787254276]
	TIME [epoch: 10.5 sec]
EPOCH 107/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7790975041270303		[learning rate: 0.0063453]
	Learning Rate: 0.00634525
	LOSS [training: 0.7790975041270303 | validation: 0.8975561090222136]
	TIME [epoch: 10.5 sec]
EPOCH 108/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8931810210240781		[learning rate: 0.0063155]
	Learning Rate: 0.00631551
	LOSS [training: 0.8931810210240781 | validation: 0.6828312047571413]
	TIME [epoch: 10.5 sec]
EPOCH 109/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7561222833457438		[learning rate: 0.0062859]
	Learning Rate: 0.0062859
	LOSS [training: 0.7561222833457438 | validation: 0.9645353770174973]
	TIME [epoch: 10.5 sec]
EPOCH 110/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8866753322509862		[learning rate: 0.0062564]
	Learning Rate: 0.00625643
	LOSS [training: 0.8866753322509862 | validation: 0.6479504750621047]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_110.pth
	Model improved!!!
EPOCH 111/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9144541017377328		[learning rate: 0.0062271]
	Learning Rate: 0.0062271
	LOSS [training: 0.9144541017377328 | validation: 0.6238591421245637]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_111.pth
	Model improved!!!
EPOCH 112/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0063967451210085		[learning rate: 0.0061979]
	Learning Rate: 0.0061979
	LOSS [training: 1.0063967451210085 | validation: 0.9914003081757946]
	TIME [epoch: 10.5 sec]
EPOCH 113/500:
	Training over batches...
		[batch 5/5] avg loss: 0.730335889459563		[learning rate: 0.0061688]
	Learning Rate: 0.00616885
	LOSS [training: 0.730335889459563 | validation: 1.3014252325322335]
	TIME [epoch: 10.5 sec]
EPOCH 114/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9869035388042559		[learning rate: 0.0061399]
	Learning Rate: 0.00613993
	LOSS [training: 0.9869035388042559 | validation: 0.9051698663757004]
	TIME [epoch: 10.5 sec]
EPOCH 115/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8969838782710431		[learning rate: 0.0061111]
	Learning Rate: 0.00611114
	LOSS [training: 0.8969838782710431 | validation: 0.7165039591260959]
	TIME [epoch: 10.4 sec]
EPOCH 116/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7723350378956464		[learning rate: 0.0060825]
	Learning Rate: 0.00608249
	LOSS [training: 0.7723350378956464 | validation: 0.7250661646145916]
	TIME [epoch: 10.5 sec]
EPOCH 117/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8256592996201558		[learning rate: 0.006054]
	Learning Rate: 0.00605398
	LOSS [training: 0.8256592996201558 | validation: 1.2612018937282643]
	TIME [epoch: 10.5 sec]
EPOCH 118/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0558128967647966		[learning rate: 0.0060256]
	Learning Rate: 0.0060256
	LOSS [training: 1.0558128967647966 | validation: 0.7510193674835073]
	TIME [epoch: 10.5 sec]
EPOCH 119/500:
	Training over batches...
		[batch 5/5] avg loss: 0.781003085906123		[learning rate: 0.0059973]
	Learning Rate: 0.00599735
	LOSS [training: 0.781003085906123 | validation: 0.9676827513236882]
	TIME [epoch: 10.5 sec]
EPOCH 120/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8559442101629443		[learning rate: 0.0059692]
	Learning Rate: 0.00596923
	LOSS [training: 0.8559442101629443 | validation: 0.8247699061147118]
	TIME [epoch: 10.5 sec]
EPOCH 121/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8327294327093016		[learning rate: 0.0059412]
	Learning Rate: 0.00594125
	LOSS [training: 0.8327294327093016 | validation: 0.6858506697172381]
	TIME [epoch: 10.5 sec]
EPOCH 122/500:
	Training over batches...
		[batch 5/5] avg loss: 2.1755707868656757		[learning rate: 0.0059134]
	Learning Rate: 0.00591339
	LOSS [training: 2.1755707868656757 | validation: 2.8543716858413166]
	TIME [epoch: 10.5 sec]
EPOCH 123/500:
	Training over batches...
		[batch 5/5] avg loss: 2.907505129922856		[learning rate: 0.0058857]
	Learning Rate: 0.00588567
	LOSS [training: 2.907505129922856 | validation: 2.1783102332371946]
	TIME [epoch: 10.5 sec]
EPOCH 124/500:
	Training over batches...
		[batch 5/5] avg loss: 1.3583320216151595		[learning rate: 0.0058581]
	Learning Rate: 0.00585808
	LOSS [training: 1.3583320216151595 | validation: 0.9189726000479848]
	TIME [epoch: 10.5 sec]
EPOCH 125/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1380397640053885		[learning rate: 0.0058306]
	Learning Rate: 0.00583061
	LOSS [training: 1.1380397640053885 | validation: 1.070586875398251]
	TIME [epoch: 10.5 sec]
EPOCH 126/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8072137869290318		[learning rate: 0.0058033]
	Learning Rate: 0.00580328
	LOSS [training: 0.8072137869290318 | validation: 0.7487646875042785]
	TIME [epoch: 10.5 sec]
EPOCH 127/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7916612566802421		[learning rate: 0.0057761]
	Learning Rate: 0.00577607
	LOSS [training: 0.7916612566802421 | validation: 0.9216542453345232]
	TIME [epoch: 10.5 sec]
EPOCH 128/500:
	Training over batches...
		[batch 5/5] avg loss: 1.048324639849561		[learning rate: 0.005749]
	Learning Rate: 0.00574899
	LOSS [training: 1.048324639849561 | validation: 0.7809875415909207]
	TIME [epoch: 10.5 sec]
EPOCH 129/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9674210772951769		[learning rate: 0.005722]
	Learning Rate: 0.00572204
	LOSS [training: 0.9674210772951769 | validation: 0.6991908946858147]
	TIME [epoch: 10.5 sec]
EPOCH 130/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6852330594643464		[learning rate: 0.0056952]
	Learning Rate: 0.00569522
	LOSS [training: 0.6852330594643464 | validation: 0.9212387832567805]
	TIME [epoch: 10.5 sec]
EPOCH 131/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8052036549904065		[learning rate: 0.0056685]
	Learning Rate: 0.00566852
	LOSS [training: 0.8052036549904065 | validation: 1.0819436086647778]
	TIME [epoch: 10.5 sec]
EPOCH 132/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0990928671081899		[learning rate: 0.0056419]
	Learning Rate: 0.00564194
	LOSS [training: 1.0990928671081899 | validation: 0.6881928104923165]
	TIME [epoch: 10.5 sec]
EPOCH 133/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6891715591317971		[learning rate: 0.0056155]
	Learning Rate: 0.00561549
	LOSS [training: 0.6891715591317971 | validation: 0.8284193194981587]
	TIME [epoch: 10.5 sec]
EPOCH 134/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8742821899154389		[learning rate: 0.0055892]
	Learning Rate: 0.00558916
	LOSS [training: 0.8742821899154389 | validation: 1.016986174345867]
	TIME [epoch: 10.5 sec]
EPOCH 135/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8223955943133723		[learning rate: 0.005563]
	Learning Rate: 0.00556296
	LOSS [training: 0.8223955943133723 | validation: 0.8607072107680804]
	TIME [epoch: 10.5 sec]
EPOCH 136/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7275429461952609		[learning rate: 0.0055369]
	Learning Rate: 0.00553688
	LOSS [training: 0.7275429461952609 | validation: 0.6312834810521862]
	TIME [epoch: 10.5 sec]
EPOCH 137/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6557541100004062		[learning rate: 0.0055109]
	Learning Rate: 0.00551092
	LOSS [training: 0.6557541100004062 | validation: 0.7365378257674127]
	TIME [epoch: 10.5 sec]
EPOCH 138/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6750799201039709		[learning rate: 0.0054851]
	Learning Rate: 0.00548509
	LOSS [training: 0.6750799201039709 | validation: 0.6679417287299212]
	TIME [epoch: 10.5 sec]
EPOCH 139/500:
	Training over batches...
		[batch 5/5] avg loss: 0.650357328637112		[learning rate: 0.0054594]
	Learning Rate: 0.00545937
	LOSS [training: 0.650357328637112 | validation: 0.6319359870960521]
	TIME [epoch: 10.5 sec]
EPOCH 140/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6181447221363883		[learning rate: 0.0054338]
	Learning Rate: 0.00543378
	LOSS [training: 0.6181447221363883 | validation: 0.6109393724715116]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_140.pth
	Model improved!!!
EPOCH 141/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6385974471947944		[learning rate: 0.0054083]
	Learning Rate: 0.00540831
	LOSS [training: 0.6385974471947944 | validation: 0.6481768641979676]
	TIME [epoch: 10.5 sec]
EPOCH 142/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7079088565518294		[learning rate: 0.005383]
	Learning Rate: 0.00538295
	LOSS [training: 0.7079088565518294 | validation: 0.7974137477270551]
	TIME [epoch: 10.5 sec]
EPOCH 143/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8686091892334928		[learning rate: 0.0053577]
	Learning Rate: 0.00535771
	LOSS [training: 0.8686091892334928 | validation: 1.0793381909320858]
	TIME [epoch: 10.5 sec]
EPOCH 144/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8896633369642389		[learning rate: 0.0053326]
	Learning Rate: 0.0053326
	LOSS [training: 0.8896633369642389 | validation: 1.0561561823112517]
	TIME [epoch: 10.5 sec]
EPOCH 145/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0157045116141112		[learning rate: 0.0053076]
	Learning Rate: 0.0053076
	LOSS [training: 1.0157045116141112 | validation: 0.6602596814194]
	TIME [epoch: 10.5 sec]
EPOCH 146/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9466188245203255		[learning rate: 0.0052827]
	Learning Rate: 0.00528271
	LOSS [training: 0.9466188245203255 | validation: 1.0216914528784198]
	TIME [epoch: 10.5 sec]
EPOCH 147/500:
	Training over batches...
		[batch 5/5] avg loss: 0.891445246357297		[learning rate: 0.0052579]
	Learning Rate: 0.00525795
	LOSS [training: 0.891445246357297 | validation: 0.6416044069799588]
	TIME [epoch: 10.5 sec]
EPOCH 148/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7741317063220009		[learning rate: 0.0052333]
	Learning Rate: 0.0052333
	LOSS [training: 0.7741317063220009 | validation: 0.729023184083932]
	TIME [epoch: 10.5 sec]
EPOCH 149/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7464450587637949		[learning rate: 0.0052088]
	Learning Rate: 0.00520876
	LOSS [training: 0.7464450587637949 | validation: 0.6832683265105535]
	TIME [epoch: 10.5 sec]
EPOCH 150/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6761174746975612		[learning rate: 0.0051843]
	Learning Rate: 0.00518434
	LOSS [training: 0.6761174746975612 | validation: 0.8497426950799445]
	TIME [epoch: 10.5 sec]
EPOCH 151/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7606877057069938		[learning rate: 0.00516]
	Learning Rate: 0.00516004
	LOSS [training: 0.7606877057069938 | validation: 0.733421569207448]
	TIME [epoch: 10.5 sec]
EPOCH 152/500:
	Training over batches...
		[batch 5/5] avg loss: 1.7820050280372068		[learning rate: 0.0051358]
	Learning Rate: 0.00513585
	LOSS [training: 1.7820050280372068 | validation: 0.570894596053559]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_152.pth
	Model improved!!!
EPOCH 153/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6912334530438651		[learning rate: 0.0051118]
	Learning Rate: 0.00511177
	LOSS [training: 0.6912334530438651 | validation: 0.9157710562000013]
	TIME [epoch: 10.5 sec]
EPOCH 154/500:
	Training over batches...
		[batch 5/5] avg loss: 0.860842171766534		[learning rate: 0.0050878]
	Learning Rate: 0.00508781
	LOSS [training: 0.860842171766534 | validation: 0.6574023112692594]
	TIME [epoch: 10.5 sec]
EPOCH 155/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6066216070187849		[learning rate: 0.005064]
	Learning Rate: 0.00506395
	LOSS [training: 0.6066216070187849 | validation: 0.5456220161891622]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_155.pth
	Model improved!!!
EPOCH 156/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9615909906799625		[learning rate: 0.0050402]
	Learning Rate: 0.00504021
	LOSS [training: 0.9615909906799625 | validation: 0.6826418153830064]
	TIME [epoch: 10.5 sec]
EPOCH 157/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6715239455781234		[learning rate: 0.0050166]
	Learning Rate: 0.00501658
	LOSS [training: 0.6715239455781234 | validation: 1.6468133215907268]
	TIME [epoch: 10.5 sec]
EPOCH 158/500:
	Training over batches...
		[batch 5/5] avg loss: 1.224456636533827		[learning rate: 0.0049931]
	Learning Rate: 0.00499307
	LOSS [training: 1.224456636533827 | validation: 0.8922500914393249]
	TIME [epoch: 10.5 sec]
EPOCH 159/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6626914529733225		[learning rate: 0.0049697]
	Learning Rate: 0.00496966
	LOSS [training: 0.6626914529733225 | validation: 0.633620013396037]
	TIME [epoch: 10.5 sec]
EPOCH 160/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7586219811414335		[learning rate: 0.0049464]
	Learning Rate: 0.00494636
	LOSS [training: 0.7586219811414335 | validation: 0.6533927258726212]
	TIME [epoch: 10.5 sec]
EPOCH 161/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7789952178415346		[learning rate: 0.0049232]
	Learning Rate: 0.00492317
	LOSS [training: 0.7789952178415346 | validation: 0.7883405487032125]
	TIME [epoch: 10.5 sec]
EPOCH 162/500:
	Training over batches...
		[batch 5/5] avg loss: 1.0533120942125727		[learning rate: 0.0049001]
	Learning Rate: 0.00490009
	LOSS [training: 1.0533120942125727 | validation: 1.1588390050665571]
	TIME [epoch: 10.5 sec]
EPOCH 163/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9710339610778507		[learning rate: 0.0048771]
	Learning Rate: 0.00487712
	LOSS [training: 0.9710339610778507 | validation: 0.7221635260010542]
	TIME [epoch: 10.5 sec]
EPOCH 164/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8226694107111637		[learning rate: 0.0048543]
	Learning Rate: 0.00485425
	LOSS [training: 0.8226694107111637 | validation: 0.7691603441831052]
	TIME [epoch: 10.5 sec]
EPOCH 165/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7916673713842678		[learning rate: 0.0048315]
	Learning Rate: 0.0048315
	LOSS [training: 0.7916673713842678 | validation: 1.2228612799358756]
	TIME [epoch: 10.5 sec]
EPOCH 166/500:
	Training over batches...
		[batch 5/5] avg loss: 0.9868788456158505		[learning rate: 0.0048088]
	Learning Rate: 0.00480885
	LOSS [training: 0.9868788456158505 | validation: 0.877632903272218]
	TIME [epoch: 10.5 sec]
EPOCH 167/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8220559626829971		[learning rate: 0.0047863]
	Learning Rate: 0.0047863
	LOSS [training: 0.8220559626829971 | validation: 1.1135371972355927]
	TIME [epoch: 10.5 sec]
EPOCH 168/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8784317626497582		[learning rate: 0.0047639]
	Learning Rate: 0.00476386
	LOSS [training: 0.8784317626497582 | validation: 0.627082776334618]
	TIME [epoch: 10.5 sec]
EPOCH 169/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7166366044153556		[learning rate: 0.0047415]
	Learning Rate: 0.00474153
	LOSS [training: 0.7166366044153556 | validation: 0.6685863084972317]
	TIME [epoch: 10.5 sec]
EPOCH 170/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7218001923331572		[learning rate: 0.0047193]
	Learning Rate: 0.0047193
	LOSS [training: 0.7218001923331572 | validation: 0.6490067617075994]
	TIME [epoch: 10.5 sec]
EPOCH 171/500:
	Training over batches...
		[batch 5/5] avg loss: 0.711132280591514		[learning rate: 0.0046972]
	Learning Rate: 0.00469718
	LOSS [training: 0.711132280591514 | validation: 0.8409943407785868]
	TIME [epoch: 10.5 sec]
EPOCH 172/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7808018872812683		[learning rate: 0.0046752]
	Learning Rate: 0.00467515
	LOSS [training: 0.7808018872812683 | validation: 0.6496724099548449]
	TIME [epoch: 10.5 sec]
EPOCH 173/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6895037284250511		[learning rate: 0.0046532]
	Learning Rate: 0.00465324
	LOSS [training: 0.6895037284250511 | validation: 0.6780503541786936]
	TIME [epoch: 10.5 sec]
EPOCH 174/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6602724784865615		[learning rate: 0.0046314]
	Learning Rate: 0.00463142
	LOSS [training: 0.6602724784865615 | validation: 0.9690303445768007]
	TIME [epoch: 10.5 sec]
EPOCH 175/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7607131199895852		[learning rate: 0.0046097]
	Learning Rate: 0.00460971
	LOSS [training: 0.7607131199895852 | validation: 0.7001841997526055]
	TIME [epoch: 10.5 sec]
EPOCH 176/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6808039508860434		[learning rate: 0.0045881]
	Learning Rate: 0.0045881
	LOSS [training: 0.6808039508860434 | validation: 1.3968960184679935]
	TIME [epoch: 10.5 sec]
EPOCH 177/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2263675405205703		[learning rate: 0.0045666]
	Learning Rate: 0.00456659
	LOSS [training: 1.2263675405205703 | validation: 0.7659076603969784]
	TIME [epoch: 10.5 sec]
EPOCH 178/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7673251688941883		[learning rate: 0.0045452]
	Learning Rate: 0.00454518
	LOSS [training: 0.7673251688941883 | validation: 0.7078693872565746]
	TIME [epoch: 10.5 sec]
EPOCH 179/500:
	Training over batches...
		[batch 5/5] avg loss: 0.86367689951969		[learning rate: 0.0045239]
	Learning Rate: 0.00452387
	LOSS [training: 0.86367689951969 | validation: 0.7041443597887564]
	TIME [epoch: 10.5 sec]
EPOCH 180/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6719584458977558		[learning rate: 0.0045027]
	Learning Rate: 0.00450266
	LOSS [training: 0.6719584458977558 | validation: 0.8977566569114237]
	TIME [epoch: 10.5 sec]
EPOCH 181/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8285842689057821		[learning rate: 0.0044816]
	Learning Rate: 0.00448155
	LOSS [training: 0.8285842689057821 | validation: 0.802234319014614]
	TIME [epoch: 10.5 sec]
EPOCH 182/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8964709248604192		[learning rate: 0.0044605]
	Learning Rate: 0.00446054
	LOSS [training: 0.8964709248604192 | validation: 1.1951535730252925]
	TIME [epoch: 10.5 sec]
EPOCH 183/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8670176612152563		[learning rate: 0.0044396]
	Learning Rate: 0.00443963
	LOSS [training: 0.8670176612152563 | validation: 0.7381166842034378]
	TIME [epoch: 10.5 sec]
EPOCH 184/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6018111669481747		[learning rate: 0.0044188]
	Learning Rate: 0.00441882
	LOSS [training: 0.6018111669481747 | validation: 0.6847083696514309]
	TIME [epoch: 10.5 sec]
EPOCH 185/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6303065902232226		[learning rate: 0.0043981]
	Learning Rate: 0.0043981
	LOSS [training: 0.6303065902232226 | validation: 0.71628698007531]
	TIME [epoch: 10.5 sec]
EPOCH 186/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6815765063061482		[learning rate: 0.0043775]
	Learning Rate: 0.00437748
	LOSS [training: 0.6815765063061482 | validation: 1.0228050656442833]
	TIME [epoch: 10.5 sec]
EPOCH 187/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8896540713895341		[learning rate: 0.004357]
	Learning Rate: 0.00435696
	LOSS [training: 0.8896540713895341 | validation: 0.9229494791258182]
	TIME [epoch: 10.5 sec]
EPOCH 188/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8419339254197201		[learning rate: 0.0043365]
	Learning Rate: 0.00433654
	LOSS [training: 0.8419339254197201 | validation: 0.9553307287251834]
	TIME [epoch: 10.5 sec]
EPOCH 189/500:
	Training over batches...
		[batch 5/5] avg loss: 0.798892292558809		[learning rate: 0.0043162]
	Learning Rate: 0.0043162
	LOSS [training: 0.798892292558809 | validation: 0.6187264898705174]
	TIME [epoch: 10.5 sec]
EPOCH 190/500:
	Training over batches...
		[batch 5/5] avg loss: 0.77296472824137		[learning rate: 0.004296]
	Learning Rate: 0.00429597
	LOSS [training: 0.77296472824137 | validation: 0.6532319625825386]
	TIME [epoch: 10.5 sec]
EPOCH 191/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5957366550609328		[learning rate: 0.0042758]
	Learning Rate: 0.00427583
	LOSS [training: 0.5957366550609328 | validation: 0.7580948791608695]
	TIME [epoch: 10.5 sec]
EPOCH 192/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6109339174292453		[learning rate: 0.0042558]
	Learning Rate: 0.00425578
	LOSS [training: 0.6109339174292453 | validation: 0.532530190722049]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_192.pth
	Model improved!!!
EPOCH 193/500:
	Training over batches...
		[batch 5/5] avg loss: 1.238523367671067		[learning rate: 0.0042358]
	Learning Rate: 0.00423583
	LOSS [training: 1.238523367671067 | validation: 1.0408695895420788]
	TIME [epoch: 10.5 sec]
EPOCH 194/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7561030785802217		[learning rate: 0.004216]
	Learning Rate: 0.00421597
	LOSS [training: 0.7561030785802217 | validation: 0.6967893818037214]
	TIME [epoch: 10.5 sec]
EPOCH 195/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6279171579303953		[learning rate: 0.0041962]
	Learning Rate: 0.00419621
	LOSS [training: 0.6279171579303953 | validation: 0.6224002297904989]
	TIME [epoch: 10.4 sec]
EPOCH 196/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8326071863883661		[learning rate: 0.0041765]
	Learning Rate: 0.00417654
	LOSS [training: 0.8326071863883661 | validation: 0.6262119981718626]
	TIME [epoch: 10.4 sec]
EPOCH 197/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5960129351749248		[learning rate: 0.004157]
	Learning Rate: 0.00415696
	LOSS [training: 0.5960129351749248 | validation: 0.609779746852258]
	TIME [epoch: 10.4 sec]
EPOCH 198/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5423887101620524		[learning rate: 0.0041375]
	Learning Rate: 0.00413747
	LOSS [training: 0.5423887101620524 | validation: 0.5634105890249953]
	TIME [epoch: 10.5 sec]
EPOCH 199/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8768463062036584		[learning rate: 0.0041181]
	Learning Rate: 0.00411807
	LOSS [training: 0.8768463062036584 | validation: 0.7746481209410709]
	TIME [epoch: 10.5 sec]
EPOCH 200/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6574223950974488		[learning rate: 0.0040988]
	Learning Rate: 0.00409877
	LOSS [training: 0.6574223950974488 | validation: 0.6418864422693764]
	TIME [epoch: 10.5 sec]
EPOCH 201/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6948056557503328		[learning rate: 0.0040795]
	Learning Rate: 0.00407955
	LOSS [training: 0.6948056557503328 | validation: 0.8190165297538028]
	TIME [epoch: 10.4 sec]
EPOCH 202/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7731255451949717		[learning rate: 0.0040604]
	Learning Rate: 0.00406042
	LOSS [training: 0.7731255451949717 | validation: 0.6396059488880896]
	TIME [epoch: 10.5 sec]
EPOCH 203/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5387187805317185		[learning rate: 0.0040414]
	Learning Rate: 0.00404139
	LOSS [training: 0.5387187805317185 | validation: 0.5150632348164972]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_203.pth
	Model improved!!!
EPOCH 204/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6044663006991263		[learning rate: 0.0040224]
	Learning Rate: 0.00402244
	LOSS [training: 0.6044663006991263 | validation: 0.726696709552814]
	TIME [epoch: 10.4 sec]
EPOCH 205/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7136002627984654		[learning rate: 0.0040036]
	Learning Rate: 0.00400358
	LOSS [training: 0.7136002627984654 | validation: 0.5123669217628225]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_205.pth
	Model improved!!!
EPOCH 206/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5510506810012117		[learning rate: 0.0039848]
	Learning Rate: 0.00398481
	LOSS [training: 0.5510506810012117 | validation: 0.6280106671948608]
	TIME [epoch: 10.5 sec]
EPOCH 207/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6734321731090634		[learning rate: 0.0039661]
	Learning Rate: 0.00396613
	LOSS [training: 0.6734321731090634 | validation: 1.2057188719779393]
	TIME [epoch: 10.5 sec]
EPOCH 208/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8632734247985159		[learning rate: 0.0039475]
	Learning Rate: 0.00394754
	LOSS [training: 0.8632734247985159 | validation: 0.6757772399835639]
	TIME [epoch: 10.5 sec]
EPOCH 209/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5927843223949558		[learning rate: 0.003929]
	Learning Rate: 0.00392903
	LOSS [training: 0.5927843223949558 | validation: 0.47464707075349405]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_209.pth
	Model improved!!!
EPOCH 210/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6084151809158606		[learning rate: 0.0039106]
	Learning Rate: 0.00391061
	LOSS [training: 0.6084151809158606 | validation: 0.5655230055648166]
	TIME [epoch: 10.5 sec]
EPOCH 211/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4824757559061622		[learning rate: 0.0038923]
	Learning Rate: 0.00389228
	LOSS [training: 0.4824757559061622 | validation: 0.48412624458731596]
	TIME [epoch: 10.5 sec]
EPOCH 212/500:
	Training over batches...
		[batch 5/5] avg loss: 0.491174877156176		[learning rate: 0.003874]
	Learning Rate: 0.00387403
	LOSS [training: 0.491174877156176 | validation: 0.432567646403094]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_212.pth
	Model improved!!!
EPOCH 213/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5290201783754533		[learning rate: 0.0038559]
	Learning Rate: 0.00385587
	LOSS [training: 0.5290201783754533 | validation: 0.4388078988072403]
	TIME [epoch: 10.5 sec]
EPOCH 214/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6611392748049518		[learning rate: 0.0038378]
	Learning Rate: 0.00383779
	LOSS [training: 0.6611392748049518 | validation: 0.8906407111534267]
	TIME [epoch: 10.5 sec]
EPOCH 215/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6752558777080933		[learning rate: 0.0038198]
	Learning Rate: 0.0038198
	LOSS [training: 0.6752558777080933 | validation: 0.7858788592906941]
	TIME [epoch: 10.5 sec]
EPOCH 216/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6612575703797742		[learning rate: 0.0038019]
	Learning Rate: 0.00380189
	LOSS [training: 0.6612575703797742 | validation: 0.5769279600315051]
	TIME [epoch: 10.5 sec]
EPOCH 217/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7214482673199291		[learning rate: 0.0037841]
	Learning Rate: 0.00378407
	LOSS [training: 0.7214482673199291 | validation: 0.7867398603695136]
	TIME [epoch: 10.5 sec]
EPOCH 218/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7400637518990397		[learning rate: 0.0037663]
	Learning Rate: 0.00376633
	LOSS [training: 0.7400637518990397 | validation: 0.6814439677874015]
	TIME [epoch: 10.5 sec]
EPOCH 219/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6535415922495564		[learning rate: 0.0037487]
	Learning Rate: 0.00374867
	LOSS [training: 0.6535415922495564 | validation: 0.8964551763302844]
	TIME [epoch: 10.5 sec]
EPOCH 220/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8534777192641455		[learning rate: 0.0037311]
	Learning Rate: 0.0037311
	LOSS [training: 0.8534777192641455 | validation: 0.5035005783287843]
	TIME [epoch: 10.5 sec]
EPOCH 221/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5537808685860287		[learning rate: 0.0037136]
	Learning Rate: 0.00371361
	LOSS [training: 0.5537808685860287 | validation: 0.5522244511886838]
	TIME [epoch: 10.5 sec]
EPOCH 222/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5329933741369957		[learning rate: 0.0036962]
	Learning Rate: 0.0036962
	LOSS [training: 0.5329933741369957 | validation: 0.44632643738335104]
	TIME [epoch: 10.5 sec]
EPOCH 223/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5349572988978546		[learning rate: 0.0036789]
	Learning Rate: 0.00367887
	LOSS [training: 0.5349572988978546 | validation: 0.4541469812915576]
	TIME [epoch: 10.5 sec]
EPOCH 224/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5723326288323629		[learning rate: 0.0036616]
	Learning Rate: 0.00366162
	LOSS [training: 0.5723326288323629 | validation: 1.038258534938646]
	TIME [epoch: 10.5 sec]
EPOCH 225/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7749285684838785		[learning rate: 0.0036445]
	Learning Rate: 0.00364446
	LOSS [training: 0.7749285684838785 | validation: 0.6740018097537671]
	TIME [epoch: 10.5 sec]
EPOCH 226/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6097546571919715		[learning rate: 0.0036274]
	Learning Rate: 0.00362737
	LOSS [training: 0.6097546571919715 | validation: 0.4375499440179242]
	TIME [epoch: 10.5 sec]
EPOCH 227/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5067142329170011		[learning rate: 0.0036104]
	Learning Rate: 0.00361036
	LOSS [training: 0.5067142329170011 | validation: 0.5410642669065249]
	TIME [epoch: 10.5 sec]
EPOCH 228/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8363783515099446		[learning rate: 0.0035934]
	Learning Rate: 0.00359344
	LOSS [training: 0.8363783515099446 | validation: 0.9309302376577372]
	TIME [epoch: 10.5 sec]
EPOCH 229/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7981937788350569		[learning rate: 0.0035766]
	Learning Rate: 0.00357659
	LOSS [training: 0.7981937788350569 | validation: 0.6771249416662445]
	TIME [epoch: 10.5 sec]
EPOCH 230/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6256190763581861		[learning rate: 0.0035598]
	Learning Rate: 0.00355982
	LOSS [training: 0.6256190763581861 | validation: 0.5667136241476322]
	TIME [epoch: 10.5 sec]
EPOCH 231/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5295431432145845		[learning rate: 0.0035431]
	Learning Rate: 0.00354314
	LOSS [training: 0.5295431432145845 | validation: 0.5802468676898205]
	TIME [epoch: 10.5 sec]
EPOCH 232/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5217933308741721		[learning rate: 0.0035265]
	Learning Rate: 0.00352652
	LOSS [training: 0.5217933308741721 | validation: 0.5081865433569394]
	TIME [epoch: 10.5 sec]
EPOCH 233/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5608895314885705		[learning rate: 0.00351]
	Learning Rate: 0.00350999
	LOSS [training: 0.5608895314885705 | validation: 0.6030312053521228]
	TIME [epoch: 10.5 sec]
EPOCH 234/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5151989330376928		[learning rate: 0.0034935]
	Learning Rate: 0.00349354
	LOSS [training: 0.5151989330376928 | validation: 0.599343578468259]
	TIME [epoch: 10.5 sec]
EPOCH 235/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6344678641755105		[learning rate: 0.0034772]
	Learning Rate: 0.00347716
	LOSS [training: 0.6344678641755105 | validation: 0.6952881570105724]
	TIME [epoch: 10.5 sec]
EPOCH 236/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5520910055648367		[learning rate: 0.0034609]
	Learning Rate: 0.00346086
	LOSS [training: 0.5520910055648367 | validation: 0.4718669601115911]
	TIME [epoch: 10.5 sec]
EPOCH 237/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5109088915639497		[learning rate: 0.0034446]
	Learning Rate: 0.00344463
	LOSS [training: 0.5109088915639497 | validation: 0.5899108959101131]
	TIME [epoch: 10.5 sec]
EPOCH 238/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5861403131380051		[learning rate: 0.0034285]
	Learning Rate: 0.00342848
	LOSS [training: 0.5861403131380051 | validation: 0.48047122077434906]
	TIME [epoch: 10.5 sec]
EPOCH 239/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6836445420653352		[learning rate: 0.0034124]
	Learning Rate: 0.00341241
	LOSS [training: 0.6836445420653352 | validation: 0.6327344269926127]
	TIME [epoch: 10.5 sec]
EPOCH 240/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5236934965088275		[learning rate: 0.0033964]
	Learning Rate: 0.00339641
	LOSS [training: 0.5236934965088275 | validation: 0.4508040776850546]
	TIME [epoch: 10.5 sec]
EPOCH 241/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7142885475214218		[learning rate: 0.0033805]
	Learning Rate: 0.00338049
	LOSS [training: 0.7142885475214218 | validation: 0.8971522060232269]
	TIME [epoch: 10.5 sec]
EPOCH 242/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5944856704126446		[learning rate: 0.0033646]
	Learning Rate: 0.00336464
	LOSS [training: 0.5944856704126446 | validation: 0.48069930419826956]
	TIME [epoch: 10.5 sec]
EPOCH 243/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5050757857542304		[learning rate: 0.0033489]
	Learning Rate: 0.00334887
	LOSS [training: 0.5050757857542304 | validation: 0.5212831121003785]
	TIME [epoch: 10.5 sec]
EPOCH 244/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5498018454535836		[learning rate: 0.0033332]
	Learning Rate: 0.00333317
	LOSS [training: 0.5498018454535836 | validation: 0.6034555475343001]
	TIME [epoch: 10.5 sec]
EPOCH 245/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5364402709460172		[learning rate: 0.0033175]
	Learning Rate: 0.00331754
	LOSS [training: 0.5364402709460172 | validation: 0.6654315619127248]
	TIME [epoch: 10.5 sec]
EPOCH 246/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6782712676003178		[learning rate: 0.003302]
	Learning Rate: 0.00330199
	LOSS [training: 0.6782712676003178 | validation: 0.8909504471925215]
	TIME [epoch: 10.5 sec]
EPOCH 247/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6493636017684332		[learning rate: 0.0032865]
	Learning Rate: 0.00328651
	LOSS [training: 0.6493636017684332 | validation: 0.5401148862565515]
	TIME [epoch: 10.5 sec]
EPOCH 248/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5151100521477858		[learning rate: 0.0032711]
	Learning Rate: 0.0032711
	LOSS [training: 0.5151100521477858 | validation: 0.579573850669534]
	TIME [epoch: 10.5 sec]
EPOCH 249/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5404717517273248		[learning rate: 0.0032558]
	Learning Rate: 0.00325576
	LOSS [training: 0.5404717517273248 | validation: 0.5654859202801447]
	TIME [epoch: 10.5 sec]
EPOCH 250/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6047262405323546		[learning rate: 0.0032405]
	Learning Rate: 0.0032405
	LOSS [training: 0.6047262405323546 | validation: 0.6094692715169288]
	TIME [epoch: 10.5 sec]
EPOCH 251/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6033222682137143		[learning rate: 0.0032253]
	Learning Rate: 0.00322531
	LOSS [training: 0.6033222682137143 | validation: 0.5926977801814508]
	TIME [epoch: 10.5 sec]
EPOCH 252/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5179532283561785		[learning rate: 0.0032102]
	Learning Rate: 0.00321019
	LOSS [training: 0.5179532283561785 | validation: 0.7164995448326724]
	TIME [epoch: 10.5 sec]
EPOCH 253/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5824077017887633		[learning rate: 0.0031951]
	Learning Rate: 0.00319514
	LOSS [training: 0.5824077017887633 | validation: 0.5843680704990194]
	TIME [epoch: 10.5 sec]
EPOCH 254/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5098992206039157		[learning rate: 0.0031802]
	Learning Rate: 0.00318016
	LOSS [training: 0.5098992206039157 | validation: 0.5320684253706898]
	TIME [epoch: 10.5 sec]
EPOCH 255/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46882147528005313		[learning rate: 0.0031653]
	Learning Rate: 0.00316525
	LOSS [training: 0.46882147528005313 | validation: 0.44764271557367197]
	TIME [epoch: 10.5 sec]
EPOCH 256/500:
	Training over batches...
		[batch 5/5] avg loss: 0.43792828243959		[learning rate: 0.0031504]
	Learning Rate: 0.00315041
	LOSS [training: 0.43792828243959 | validation: 0.4788065099513257]
	TIME [epoch: 10.4 sec]
EPOCH 257/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4685391867910811		[learning rate: 0.0031356]
	Learning Rate: 0.00313564
	LOSS [training: 0.4685391867910811 | validation: 0.6079203072662032]
	TIME [epoch: 10.5 sec]
EPOCH 258/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5195347813755371		[learning rate: 0.0031209]
	Learning Rate: 0.00312094
	LOSS [training: 0.5195347813755371 | validation: 0.5203494694391853]
	TIME [epoch: 10.5 sec]
EPOCH 259/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5900415068871743		[learning rate: 0.0031063]
	Learning Rate: 0.00310631
	LOSS [training: 0.5900415068871743 | validation: 0.4367623245836312]
	TIME [epoch: 10.5 sec]
EPOCH 260/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45542693737954404		[learning rate: 0.0030917]
	Learning Rate: 0.00309175
	LOSS [training: 0.45542693737954404 | validation: 0.5461955642115752]
	TIME [epoch: 10.5 sec]
EPOCH 261/500:
	Training over batches...
		[batch 5/5] avg loss: 1.1656895879271958		[learning rate: 0.0030773]
	Learning Rate: 0.00307725
	LOSS [training: 1.1656895879271958 | validation: 0.7737736153043911]
	TIME [epoch: 10.5 sec]
EPOCH 262/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6217127750788681		[learning rate: 0.0030628]
	Learning Rate: 0.00306283
	LOSS [training: 0.6217127750788681 | validation: 0.5240425083674393]
	TIME [epoch: 10.5 sec]
EPOCH 263/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5323741092592128		[learning rate: 0.0030485]
	Learning Rate: 0.00304847
	LOSS [training: 0.5323741092592128 | validation: 0.4704097825091479]
	TIME [epoch: 10.5 sec]
EPOCH 264/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7843980345344349		[learning rate: 0.0030342]
	Learning Rate: 0.00303418
	LOSS [training: 0.7843980345344349 | validation: 1.0327609225161896]
	TIME [epoch: 10.5 sec]
EPOCH 265/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6946996525008984		[learning rate: 0.00302]
	Learning Rate: 0.00301995
	LOSS [training: 0.6946996525008984 | validation: 0.4777390774927855]
	TIME [epoch: 10.5 sec]
EPOCH 266/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5703012481733893		[learning rate: 0.0030058]
	Learning Rate: 0.00300579
	LOSS [training: 0.5703012481733893 | validation: 0.5341167145151167]
	TIME [epoch: 10.5 sec]
EPOCH 267/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5162981163874806		[learning rate: 0.0029917]
	Learning Rate: 0.0029917
	LOSS [training: 0.5162981163874806 | validation: 0.4632183753519259]
	TIME [epoch: 10.5 sec]
EPOCH 268/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4935153153999104		[learning rate: 0.0029777]
	Learning Rate: 0.00297768
	LOSS [training: 0.4935153153999104 | validation: 0.5898014745207277]
	TIME [epoch: 10.5 sec]
EPOCH 269/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7870792008600134		[learning rate: 0.0029637]
	Learning Rate: 0.00296372
	LOSS [training: 0.7870792008600134 | validation: 0.9248208527127278]
	TIME [epoch: 10.5 sec]
EPOCH 270/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6811423573438278		[learning rate: 0.0029498]
	Learning Rate: 0.00294982
	LOSS [training: 0.6811423573438278 | validation: 0.549956491840837]
	TIME [epoch: 10.5 sec]
EPOCH 271/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6084846560879712		[learning rate: 0.002936]
	Learning Rate: 0.00293599
	LOSS [training: 0.6084846560879712 | validation: 0.7278441746425784]
	TIME [epoch: 10.4 sec]
EPOCH 272/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5568484264429072		[learning rate: 0.0029222]
	Learning Rate: 0.00292223
	LOSS [training: 0.5568484264429072 | validation: 0.445915358302509]
	TIME [epoch: 10.5 sec]
EPOCH 273/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48507880857706187		[learning rate: 0.0029085]
	Learning Rate: 0.00290853
	LOSS [training: 0.48507880857706187 | validation: 0.4914527544816846]
	TIME [epoch: 10.4 sec]
EPOCH 274/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6083321873625123		[learning rate: 0.0028949]
	Learning Rate: 0.00289489
	LOSS [training: 0.6083321873625123 | validation: 0.4243259840323313]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_274.pth
	Model improved!!!
EPOCH 275/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5330170385370475		[learning rate: 0.0028813]
	Learning Rate: 0.00288132
	LOSS [training: 0.5330170385370475 | validation: 0.5225453096489951]
	TIME [epoch: 10.5 sec]
EPOCH 276/500:
	Training over batches...
		[batch 5/5] avg loss: 0.440945790404105		[learning rate: 0.0028678]
	Learning Rate: 0.00286781
	LOSS [training: 0.440945790404105 | validation: 0.5111536096033673]
	TIME [epoch: 10.5 sec]
EPOCH 277/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4469689161601263		[learning rate: 0.0028544]
	Learning Rate: 0.00285437
	LOSS [training: 0.4469689161601263 | validation: 0.5381451789262482]
	TIME [epoch: 10.5 sec]
EPOCH 278/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6120677131796215		[learning rate: 0.002841]
	Learning Rate: 0.00284099
	LOSS [training: 0.6120677131796215 | validation: 0.7474339032762589]
	TIME [epoch: 10.5 sec]
EPOCH 279/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7460379630389777		[learning rate: 0.0028277]
	Learning Rate: 0.00282767
	LOSS [training: 0.7460379630389777 | validation: 0.7167939375664905]
	TIME [epoch: 10.5 sec]
EPOCH 280/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6437016257597273		[learning rate: 0.0028144]
	Learning Rate: 0.00281441
	LOSS [training: 0.6437016257597273 | validation: 0.6816618923601828]
	TIME [epoch: 10.5 sec]
EPOCH 281/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7750643967978568		[learning rate: 0.0028012]
	Learning Rate: 0.00280122
	LOSS [training: 0.7750643967978568 | validation: 0.7160225815663137]
	TIME [epoch: 10.4 sec]
EPOCH 282/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7220189583078107		[learning rate: 0.0027881]
	Learning Rate: 0.00278809
	LOSS [training: 0.7220189583078107 | validation: 0.7173964956177106]
	TIME [epoch: 10.5 sec]
EPOCH 283/500:
	Training over batches...
		[batch 5/5] avg loss: 0.8018146044015915		[learning rate: 0.002775]
	Learning Rate: 0.00277501
	LOSS [training: 0.8018146044015915 | validation: 0.8270871177611642]
	TIME [epoch: 10.5 sec]
EPOCH 284/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6889642679977575		[learning rate: 0.002762]
	Learning Rate: 0.002762
	LOSS [training: 0.6889642679977575 | validation: 0.5804762406103632]
	TIME [epoch: 10.5 sec]
EPOCH 285/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5320833586253146		[learning rate: 0.0027491]
	Learning Rate: 0.00274906
	LOSS [training: 0.5320833586253146 | validation: 0.49467822213252405]
	TIME [epoch: 10.5 sec]
EPOCH 286/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4793362586391726		[learning rate: 0.0027362]
	Learning Rate: 0.00273617
	LOSS [training: 0.4793362586391726 | validation: 0.4581771798737978]
	TIME [epoch: 10.5 sec]
EPOCH 287/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5090105548458909		[learning rate: 0.0027233]
	Learning Rate: 0.00272334
	LOSS [training: 0.5090105548458909 | validation: 0.6685463324514361]
	TIME [epoch: 10.5 sec]
EPOCH 288/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6648641811898517		[learning rate: 0.0027106]
	Learning Rate: 0.00271057
	LOSS [training: 0.6648641811898517 | validation: 0.6809639617343247]
	TIME [epoch: 10.5 sec]
EPOCH 289/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6122072235669743		[learning rate: 0.0026979]
	Learning Rate: 0.00269787
	LOSS [training: 0.6122072235669743 | validation: 0.4314102321639722]
	TIME [epoch: 10.5 sec]
EPOCH 290/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4694964351786683		[learning rate: 0.0026852]
	Learning Rate: 0.00268522
	LOSS [training: 0.4694964351786683 | validation: 0.6666721892612923]
	TIME [epoch: 10.5 sec]
EPOCH 291/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5796940948040668		[learning rate: 0.0026726]
	Learning Rate: 0.00267263
	LOSS [training: 0.5796940948040668 | validation: 0.5807564477813346]
	TIME [epoch: 10.5 sec]
EPOCH 292/500:
	Training over batches...
		[batch 5/5] avg loss: 0.610830994715176		[learning rate: 0.0026601]
	Learning Rate: 0.0026601
	LOSS [training: 0.610830994715176 | validation: 0.56371304725239]
	TIME [epoch: 10.5 sec]
EPOCH 293/500:
	Training over batches...
		[batch 5/5] avg loss: 0.574041778826351		[learning rate: 0.0026476]
	Learning Rate: 0.00264763
	LOSS [training: 0.574041778826351 | validation: 0.49268103899246696]
	TIME [epoch: 10.5 sec]
EPOCH 294/500:
	Training over batches...
		[batch 5/5] avg loss: 0.455751045582931		[learning rate: 0.0026352]
	Learning Rate: 0.00263522
	LOSS [training: 0.455751045582931 | validation: 0.4793339428312305]
	TIME [epoch: 10.5 sec]
EPOCH 295/500:
	Training over batches...
		[batch 5/5] avg loss: 0.525941443906643		[learning rate: 0.0026229]
	Learning Rate: 0.00262286
	LOSS [training: 0.525941443906643 | validation: 0.6085458848987036]
	TIME [epoch: 10.5 sec]
EPOCH 296/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5488035374577646		[learning rate: 0.0026106]
	Learning Rate: 0.00261057
	LOSS [training: 0.5488035374577646 | validation: 0.4989811788608098]
	TIME [epoch: 10.5 sec]
EPOCH 297/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5606037430430538		[learning rate: 0.0025983]
	Learning Rate: 0.00259833
	LOSS [training: 0.5606037430430538 | validation: 0.5951473650656567]
	TIME [epoch: 10.5 sec]
EPOCH 298/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6777179010665547		[learning rate: 0.0025861]
	Learning Rate: 0.00258615
	LOSS [training: 0.6777179010665547 | validation: 0.5533249744494321]
	TIME [epoch: 10.5 sec]
EPOCH 299/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5651133257916238		[learning rate: 0.002574]
	Learning Rate: 0.00257402
	LOSS [training: 0.5651133257916238 | validation: 0.5123578109882556]
	TIME [epoch: 10.5 sec]
EPOCH 300/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45725327949325606		[learning rate: 0.002562]
	Learning Rate: 0.00256195
	LOSS [training: 0.45725327949325606 | validation: 0.4290518138692162]
	TIME [epoch: 10.5 sec]
EPOCH 301/500:
	Training over batches...
		[batch 5/5] avg loss: 0.42282851872369837		[learning rate: 0.0025499]
	Learning Rate: 0.00254994
	LOSS [training: 0.42282851872369837 | validation: 0.3758138072025771]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_301.pth
	Model improved!!!
EPOCH 302/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46475468316996515		[learning rate: 0.002538]
	Learning Rate: 0.00253799
	LOSS [training: 0.46475468316996515 | validation: 0.5505919520792277]
	TIME [epoch: 10.5 sec]
EPOCH 303/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5480956151048986		[learning rate: 0.0025261]
	Learning Rate: 0.00252609
	LOSS [training: 0.5480956151048986 | validation: 0.39925521608586273]
	TIME [epoch: 10.5 sec]
EPOCH 304/500:
	Training over batches...
		[batch 5/5] avg loss: 0.412984474091485		[learning rate: 0.0025142]
	Learning Rate: 0.00251425
	LOSS [training: 0.412984474091485 | validation: 0.5465367015241608]
	TIME [epoch: 10.5 sec]
EPOCH 305/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5994119186004723		[learning rate: 0.0025025]
	Learning Rate: 0.00250246
	LOSS [training: 0.5994119186004723 | validation: 0.7141300433799848]
	TIME [epoch: 10.5 sec]
EPOCH 306/500:
	Training over batches...
		[batch 5/5] avg loss: 0.474922962783796		[learning rate: 0.0024907]
	Learning Rate: 0.00249073
	LOSS [training: 0.474922962783796 | validation: 0.4785011279011542]
	TIME [epoch: 10.5 sec]
EPOCH 307/500:
	Training over batches...
		[batch 5/5] avg loss: 0.616098489615293		[learning rate: 0.0024791]
	Learning Rate: 0.00247905
	LOSS [training: 0.616098489615293 | validation: 0.7224428180916936]
	TIME [epoch: 10.5 sec]
EPOCH 308/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5708609132851399		[learning rate: 0.0024674]
	Learning Rate: 0.00246743
	LOSS [training: 0.5708609132851399 | validation: 0.3826687460671597]
	TIME [epoch: 10.5 sec]
EPOCH 309/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5135745948228554		[learning rate: 0.0024559]
	Learning Rate: 0.00245586
	LOSS [training: 0.5135745948228554 | validation: 0.5152213566755016]
	TIME [epoch: 10.5 sec]
EPOCH 310/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4932481546347791		[learning rate: 0.0024443]
	Learning Rate: 0.00244435
	LOSS [training: 0.4932481546347791 | validation: 0.5020488377236552]
	TIME [epoch: 10.5 sec]
EPOCH 311/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3850031697290279		[learning rate: 0.0024329]
	Learning Rate: 0.00243289
	LOSS [training: 0.3850031697290279 | validation: 0.3434797890404353]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_311.pth
	Model improved!!!
EPOCH 312/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4002750093222165		[learning rate: 0.0024215]
	Learning Rate: 0.00242148
	LOSS [training: 0.4002750093222165 | validation: 0.6068661638673366]
	TIME [epoch: 10.5 sec]
EPOCH 313/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4717160006501556		[learning rate: 0.0024101]
	Learning Rate: 0.00241013
	LOSS [training: 0.4717160006501556 | validation: 0.38644729357518165]
	TIME [epoch: 10.5 sec]
EPOCH 314/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3596090730328661		[learning rate: 0.0023988]
	Learning Rate: 0.00239883
	LOSS [training: 0.3596090730328661 | validation: 0.3221467691366627]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_314.pth
	Model improved!!!
EPOCH 315/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3415402164426801		[learning rate: 0.0023876]
	Learning Rate: 0.00238759
	LOSS [training: 0.3415402164426801 | validation: 0.32088752866096715]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_315.pth
	Model improved!!!
EPOCH 316/500:
	Training over batches...
		[batch 5/5] avg loss: 0.36074375545557913		[learning rate: 0.0023764]
	Learning Rate: 0.00237639
	LOSS [training: 0.36074375545557913 | validation: 0.3668894604751371]
	TIME [epoch: 10.5 sec]
EPOCH 317/500:
	Training over batches...
		[batch 5/5] avg loss: 0.34494824357901105		[learning rate: 0.0023653]
	Learning Rate: 0.00236525
	LOSS [training: 0.34494824357901105 | validation: 0.3329977112846838]
	TIME [epoch: 10.5 sec]
EPOCH 318/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3910413907987477		[learning rate: 0.0023542]
	Learning Rate: 0.00235416
	LOSS [training: 0.3910413907987477 | validation: 0.3233532519365152]
	TIME [epoch: 10.5 sec]
EPOCH 319/500:
	Training over batches...
		[batch 5/5] avg loss: 0.40736102795099327		[learning rate: 0.0023431]
	Learning Rate: 0.00234313
	LOSS [training: 0.40736102795099327 | validation: 0.6373115722326099]
	TIME [epoch: 10.5 sec]
EPOCH 320/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6595573747691347		[learning rate: 0.0023321]
	Learning Rate: 0.00233214
	LOSS [training: 0.6595573747691347 | validation: 0.7145157804683759]
	TIME [epoch: 10.5 sec]
EPOCH 321/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6513212634201822		[learning rate: 0.0023212]
	Learning Rate: 0.00232121
	LOSS [training: 0.6513212634201822 | validation: 0.6100640182035751]
	TIME [epoch: 10.5 sec]
EPOCH 322/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4783255128899442		[learning rate: 0.0023103]
	Learning Rate: 0.00231033
	LOSS [training: 0.4783255128899442 | validation: 0.35615849778069225]
	TIME [epoch: 10.5 sec]
EPOCH 323/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4035022244165605		[learning rate: 0.0022995]
	Learning Rate: 0.0022995
	LOSS [training: 0.4035022244165605 | validation: 0.5272005835869592]
	TIME [epoch: 10.5 sec]
EPOCH 324/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5517103826396246		[learning rate: 0.0022887]
	Learning Rate: 0.00228872
	LOSS [training: 0.5517103826396246 | validation: 0.6751008176713728]
	TIME [epoch: 10.5 sec]
EPOCH 325/500:
	Training over batches...
		[batch 5/5] avg loss: 0.6437265504363369		[learning rate: 0.002278]
	Learning Rate: 0.00227799
	LOSS [training: 0.6437265504363369 | validation: 0.6543743842787859]
	TIME [epoch: 10.5 sec]
EPOCH 326/500:
	Training over batches...
		[batch 5/5] avg loss: 0.655575319192055		[learning rate: 0.0022673]
	Learning Rate: 0.00226731
	LOSS [training: 0.655575319192055 | validation: 0.6437066106801619]
	TIME [epoch: 10.5 sec]
EPOCH 327/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5067529964191423		[learning rate: 0.0022567]
	Learning Rate: 0.00225668
	LOSS [training: 0.5067529964191423 | validation: 0.4882606052153225]
	TIME [epoch: 10.5 sec]
EPOCH 328/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4630375886766995		[learning rate: 0.0022461]
	Learning Rate: 0.0022461
	LOSS [training: 0.4630375886766995 | validation: 0.47952283515159755]
	TIME [epoch: 10.5 sec]
EPOCH 329/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5236755462856755		[learning rate: 0.0022356]
	Learning Rate: 0.00223557
	LOSS [training: 0.5236755462856755 | validation: 0.5449108049709273]
	TIME [epoch: 10.5 sec]
EPOCH 330/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48568168926459077		[learning rate: 0.0022251]
	Learning Rate: 0.00222509
	LOSS [training: 0.48568168926459077 | validation: 0.41022414035395816]
	TIME [epoch: 10.5 sec]
EPOCH 331/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5263891381370078		[learning rate: 0.0022147]
	Learning Rate: 0.00221466
	LOSS [training: 0.5263891381370078 | validation: 1.6060414687975155]
	TIME [epoch: 10.5 sec]
EPOCH 332/500:
	Training over batches...
		[batch 5/5] avg loss: 1.2817614325663684		[learning rate: 0.0022043]
	Learning Rate: 0.00220427
	LOSS [training: 1.2817614325663684 | validation: 0.5883686942708612]
	TIME [epoch: 10.5 sec]
EPOCH 333/500:
	Training over batches...
		[batch 5/5] avg loss: 0.7249132658471901		[learning rate: 0.0021939]
	Learning Rate: 0.00219394
	LOSS [training: 0.7249132658471901 | validation: 0.5727855811331947]
	TIME [epoch: 10.5 sec]
EPOCH 334/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5417453782024803		[learning rate: 0.0021837]
	Learning Rate: 0.00218365
	LOSS [training: 0.5417453782024803 | validation: 0.4296713939743693]
	TIME [epoch: 10.5 sec]
EPOCH 335/500:
	Training over batches...
		[batch 5/5] avg loss: 0.38035664449872886		[learning rate: 0.0021734]
	Learning Rate: 0.00217342
	LOSS [training: 0.38035664449872886 | validation: 0.46712284724391695]
	TIME [epoch: 10.5 sec]
EPOCH 336/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4944416117085841		[learning rate: 0.0021632]
	Learning Rate: 0.00216323
	LOSS [training: 0.4944416117085841 | validation: 0.47783390334332515]
	TIME [epoch: 10.5 sec]
EPOCH 337/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5621992973887423		[learning rate: 0.0021531]
	Learning Rate: 0.00215309
	LOSS [training: 0.5621992973887423 | validation: 0.6882357738395141]
	TIME [epoch: 10.5 sec]
EPOCH 338/500:
	Training over batches...
		[batch 5/5] avg loss: 0.706378364127646		[learning rate: 0.002143]
	Learning Rate: 0.00214299
	LOSS [training: 0.706378364127646 | validation: 0.688348167655947]
	TIME [epoch: 10.5 sec]
EPOCH 339/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5467297428300129		[learning rate: 0.0021329]
	Learning Rate: 0.00213294
	LOSS [training: 0.5467297428300129 | validation: 0.47667785062700246]
	TIME [epoch: 10.5 sec]
EPOCH 340/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4263944770832125		[learning rate: 0.0021229]
	Learning Rate: 0.00212294
	LOSS [training: 0.4263944770832125 | validation: 0.4294038785435421]
	TIME [epoch: 10.5 sec]
EPOCH 341/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4367050476417651		[learning rate: 0.002113]
	Learning Rate: 0.00211299
	LOSS [training: 0.4367050476417651 | validation: 0.49125715440500783]
	TIME [epoch: 10.5 sec]
EPOCH 342/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5101386884537581		[learning rate: 0.0021031]
	Learning Rate: 0.00210309
	LOSS [training: 0.5101386884537581 | validation: 0.4650332168276279]
	TIME [epoch: 10.5 sec]
EPOCH 343/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4176912875381925		[learning rate: 0.0020932]
	Learning Rate: 0.00209323
	LOSS [training: 0.4176912875381925 | validation: 0.3248085444575732]
	TIME [epoch: 10.5 sec]
EPOCH 344/500:
	Training over batches...
		[batch 5/5] avg loss: 0.30292303835537565		[learning rate: 0.0020834]
	Learning Rate: 0.00208341
	LOSS [training: 0.30292303835537565 | validation: 0.3184590075552216]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_344.pth
	Model improved!!!
EPOCH 345/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3078426395683544		[learning rate: 0.0020736]
	Learning Rate: 0.00207365
	LOSS [training: 0.3078426395683544 | validation: 0.29147572593116744]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_345.pth
	Model improved!!!
EPOCH 346/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4902879320670671		[learning rate: 0.0020639]
	Learning Rate: 0.00206392
	LOSS [training: 0.4902879320670671 | validation: 0.31677110344749076]
	TIME [epoch: 10.5 sec]
EPOCH 347/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2822466145303912		[learning rate: 0.0020542]
	Learning Rate: 0.00205425
	LOSS [training: 0.2822466145303912 | validation: 0.28431319077864076]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_347.pth
	Model improved!!!
EPOCH 348/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3104984836919351		[learning rate: 0.0020446]
	Learning Rate: 0.00204462
	LOSS [training: 0.3104984836919351 | validation: 0.4621773049794199]
	TIME [epoch: 10.5 sec]
EPOCH 349/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5256207562307254		[learning rate: 0.002035]
	Learning Rate: 0.00203503
	LOSS [training: 0.5256207562307254 | validation: 0.4051269140567302]
	TIME [epoch: 10.5 sec]
EPOCH 350/500:
	Training over batches...
		[batch 5/5] avg loss: 0.45294600337530727		[learning rate: 0.0020255]
	Learning Rate: 0.00202549
	LOSS [training: 0.45294600337530727 | validation: 0.3603162412529591]
	TIME [epoch: 10.5 sec]
EPOCH 351/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3679851915388312		[learning rate: 0.002016]
	Learning Rate: 0.002016
	LOSS [training: 0.3679851915388312 | validation: 0.36208837294446544]
	TIME [epoch: 10.5 sec]
EPOCH 352/500:
	Training over batches...
		[batch 5/5] avg loss: 0.32290376336088905		[learning rate: 0.0020065]
	Learning Rate: 0.00200655
	LOSS [training: 0.32290376336088905 | validation: 0.40257897091199696]
	TIME [epoch: 10.5 sec]
EPOCH 353/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48294841171530856		[learning rate: 0.0019971]
	Learning Rate: 0.00199714
	LOSS [training: 0.48294841171530856 | validation: 0.6000009927956308]
	TIME [epoch: 10.5 sec]
EPOCH 354/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4665273945012915		[learning rate: 0.0019878]
	Learning Rate: 0.00198778
	LOSS [training: 0.4665273945012915 | validation: 0.37969326790108576]
	TIME [epoch: 10.5 sec]
EPOCH 355/500:
	Training over batches...
		[batch 5/5] avg loss: 0.35978623850770014		[learning rate: 0.0019785]
	Learning Rate: 0.00197846
	LOSS [training: 0.35978623850770014 | validation: 0.29694804215749543]
	TIME [epoch: 10.5 sec]
EPOCH 356/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2719387949408043		[learning rate: 0.0019692]
	Learning Rate: 0.00196918
	LOSS [training: 0.2719387949408043 | validation: 0.24519300457662177]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_356.pth
	Model improved!!!
EPOCH 357/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2657860245477774		[learning rate: 0.0019599]
	Learning Rate: 0.00195995
	LOSS [training: 0.2657860245477774 | validation: 0.4028864341671161]
	TIME [epoch: 10.5 sec]
EPOCH 358/500:
	Training over batches...
		[batch 5/5] avg loss: 0.34427477113262006		[learning rate: 0.0019508]
	Learning Rate: 0.00195076
	LOSS [training: 0.34427477113262006 | validation: 0.30114463230547667]
	TIME [epoch: 10.5 sec]
EPOCH 359/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24526931815191846		[learning rate: 0.0019416]
	Learning Rate: 0.00194162
	LOSS [training: 0.24526931815191846 | validation: 0.2787956976638605]
	TIME [epoch: 10.5 sec]
EPOCH 360/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4843381677994344		[learning rate: 0.0019325]
	Learning Rate: 0.00193251
	LOSS [training: 0.4843381677994344 | validation: 0.4842897421520252]
	TIME [epoch: 10.5 sec]
EPOCH 361/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3796136004954225		[learning rate: 0.0019235]
	Learning Rate: 0.00192345
	LOSS [training: 0.3796136004954225 | validation: 0.38294597785817386]
	TIME [epoch: 10.5 sec]
EPOCH 362/500:
	Training over batches...
		[batch 5/5] avg loss: 0.40205445855319777		[learning rate: 0.0019144]
	Learning Rate: 0.00191444
	LOSS [training: 0.40205445855319777 | validation: 0.29185594070708726]
	TIME [epoch: 10.5 sec]
EPOCH 363/500:
	Training over batches...
		[batch 5/5] avg loss: 0.27306963221386404		[learning rate: 0.0019055]
	Learning Rate: 0.00190546
	LOSS [training: 0.27306963221386404 | validation: 0.3248165717690552]
	TIME [epoch: 10.5 sec]
EPOCH 364/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2577962856793208		[learning rate: 0.0018965]
	Learning Rate: 0.00189653
	LOSS [training: 0.2577962856793208 | validation: 0.2332807005700158]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_364.pth
	Model improved!!!
EPOCH 365/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2556874220950671		[learning rate: 0.0018876]
	Learning Rate: 0.00188764
	LOSS [training: 0.2556874220950671 | validation: 0.28617641906252633]
	TIME [epoch: 10.5 sec]
EPOCH 366/500:
	Training over batches...
		[batch 5/5] avg loss: 0.27413302907142334		[learning rate: 0.0018788]
	Learning Rate: 0.00187879
	LOSS [training: 0.27413302907142334 | validation: 0.33987735062760693]
	TIME [epoch: 10.5 sec]
EPOCH 367/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2829999474720516		[learning rate: 0.00187]
	Learning Rate: 0.00186998
	LOSS [training: 0.2829999474720516 | validation: 0.2641689393782762]
	TIME [epoch: 10.5 sec]
EPOCH 368/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46594702090217177		[learning rate: 0.0018612]
	Learning Rate: 0.00186121
	LOSS [training: 0.46594702090217177 | validation: 0.7462943946043353]
	TIME [epoch: 10.5 sec]
EPOCH 369/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5012224662964819		[learning rate: 0.0018525]
	Learning Rate: 0.00185249
	LOSS [training: 0.5012224662964819 | validation: 0.3046698950589344]
	TIME [epoch: 10.5 sec]
EPOCH 370/500:
	Training over batches...
		[batch 5/5] avg loss: 0.36049492604166244		[learning rate: 0.0018438]
	Learning Rate: 0.0018438
	LOSS [training: 0.36049492604166244 | validation: 0.3367422626536766]
	TIME [epoch: 10.5 sec]
EPOCH 371/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3015970319246604		[learning rate: 0.0018352]
	Learning Rate: 0.00183516
	LOSS [training: 0.3015970319246604 | validation: 0.3122957986535741]
	TIME [epoch: 10.5 sec]
EPOCH 372/500:
	Training over batches...
		[batch 5/5] avg loss: 0.42989436484153076		[learning rate: 0.0018266]
	Learning Rate: 0.00182655
	LOSS [training: 0.42989436484153076 | validation: 0.4301435252413716]
	TIME [epoch: 10.5 sec]
EPOCH 373/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3394170025745862		[learning rate: 0.001818]
	Learning Rate: 0.00181799
	LOSS [training: 0.3394170025745862 | validation: 0.24835024631351282]
	TIME [epoch: 10.5 sec]
EPOCH 374/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2663000051896387		[learning rate: 0.0018095]
	Learning Rate: 0.00180947
	LOSS [training: 0.2663000051896387 | validation: 0.3205989553096707]
	TIME [epoch: 10.5 sec]
EPOCH 375/500:
	Training over batches...
		[batch 5/5] avg loss: 0.29490717513109477		[learning rate: 0.001801]
	Learning Rate: 0.00180099
	LOSS [training: 0.29490717513109477 | validation: 0.27204299859782743]
	TIME [epoch: 10.5 sec]
EPOCH 376/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24858974473323087		[learning rate: 0.0017925]
	Learning Rate: 0.00179254
	LOSS [training: 0.24858974473323087 | validation: 0.23842188528035557]
	TIME [epoch: 10.5 sec]
EPOCH 377/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3707888185686641		[learning rate: 0.0017841]
	Learning Rate: 0.00178414
	LOSS [training: 0.3707888185686641 | validation: 0.6208019387277774]
	TIME [epoch: 10.5 sec]
EPOCH 378/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48674406590806363		[learning rate: 0.0017758]
	Learning Rate: 0.00177577
	LOSS [training: 0.48674406590806363 | validation: 0.3889196753635897]
	TIME [epoch: 10.5 sec]
EPOCH 379/500:
	Training over batches...
		[batch 5/5] avg loss: 0.46789967545974287		[learning rate: 0.0017674]
	Learning Rate: 0.00176745
	LOSS [training: 0.46789967545974287 | validation: 0.5003045024601407]
	TIME [epoch: 10.5 sec]
EPOCH 380/500:
	Training over batches...
		[batch 5/5] avg loss: 0.36947279352874496		[learning rate: 0.0017592]
	Learning Rate: 0.00175916
	LOSS [training: 0.36947279352874496 | validation: 0.2997713000426745]
	TIME [epoch: 10.5 sec]
EPOCH 381/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2367287165108424		[learning rate: 0.0017509]
	Learning Rate: 0.00175092
	LOSS [training: 0.2367287165108424 | validation: 0.2460189590177301]
	TIME [epoch: 10.5 sec]
EPOCH 382/500:
	Training over batches...
		[batch 5/5] avg loss: 0.26840175009757955		[learning rate: 0.0017427]
	Learning Rate: 0.00174271
	LOSS [training: 0.26840175009757955 | validation: 0.2940159896000604]
	TIME [epoch: 10.5 sec]
EPOCH 383/500:
	Training over batches...
		[batch 5/5] avg loss: 0.35884355887773334		[learning rate: 0.0017345]
	Learning Rate: 0.00173454
	LOSS [training: 0.35884355887773334 | validation: 0.5061068038222493]
	TIME [epoch: 10.5 sec]
EPOCH 384/500:
	Training over batches...
		[batch 5/5] avg loss: 0.5523593970761771		[learning rate: 0.0017264]
	Learning Rate: 0.00172641
	LOSS [training: 0.5523593970761771 | validation: 0.6200063228909172]
	TIME [epoch: 10.5 sec]
EPOCH 385/500:
	Training over batches...
		[batch 5/5] avg loss: 0.4580284818266354		[learning rate: 0.0017183]
	Learning Rate: 0.00171831
	LOSS [training: 0.4580284818266354 | validation: 0.35587902986997594]
	TIME [epoch: 10.5 sec]
EPOCH 386/500:
	Training over batches...
		[batch 5/5] avg loss: 0.31948938981804265		[learning rate: 0.0017103]
	Learning Rate: 0.00171026
	LOSS [training: 0.31948938981804265 | validation: 0.32811186201559067]
	TIME [epoch: 10.5 sec]
EPOCH 387/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2375430542593114		[learning rate: 0.0017022]
	Learning Rate: 0.00170224
	LOSS [training: 0.2375430542593114 | validation: 0.25846603408244206]
	TIME [epoch: 10.5 sec]
EPOCH 388/500:
	Training over batches...
		[batch 5/5] avg loss: 0.30165025383464417		[learning rate: 0.0016943]
	Learning Rate: 0.00169426
	LOSS [training: 0.30165025383464417 | validation: 0.428385435577162]
	TIME [epoch: 10.5 sec]
EPOCH 389/500:
	Training over batches...
		[batch 5/5] avg loss: 0.559379777196427		[learning rate: 0.0016863]
	Learning Rate: 0.00168632
	LOSS [training: 0.559379777196427 | validation: 0.400458142964395]
	TIME [epoch: 10.4 sec]
EPOCH 390/500:
	Training over batches...
		[batch 5/5] avg loss: 0.34047728142405415		[learning rate: 0.0016784]
	Learning Rate: 0.00167841
	LOSS [training: 0.34047728142405415 | validation: 0.25354743808654756]
	TIME [epoch: 10.5 sec]
EPOCH 391/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21513988628319664		[learning rate: 0.0016705]
	Learning Rate: 0.00167054
	LOSS [training: 0.21513988628319664 | validation: 0.243368112014086]
	TIME [epoch: 10.5 sec]
EPOCH 392/500:
	Training over batches...
		[batch 5/5] avg loss: 0.26726639099485605		[learning rate: 0.0016627]
	Learning Rate: 0.00166271
	LOSS [training: 0.26726639099485605 | validation: 0.27531064998683263]
	TIME [epoch: 10.5 sec]
EPOCH 393/500:
	Training over batches...
		[batch 5/5] avg loss: 0.26775636517435036		[learning rate: 0.0016549]
	Learning Rate: 0.00165491
	LOSS [training: 0.26775636517435036 | validation: 0.22505524047443945]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_393.pth
	Model improved!!!
EPOCH 394/500:
	Training over batches...
		[batch 5/5] avg loss: 0.23969979006729894		[learning rate: 0.0016472]
	Learning Rate: 0.00164716
	LOSS [training: 0.23969979006729894 | validation: 0.24823206944711682]
	TIME [epoch: 10.5 sec]
EPOCH 395/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21717861940813182		[learning rate: 0.0016394]
	Learning Rate: 0.00163943
	LOSS [training: 0.21717861940813182 | validation: 0.1952985317808112]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_395.pth
	Model improved!!!
EPOCH 396/500:
	Training over batches...
		[batch 5/5] avg loss: 0.23007225033678927		[learning rate: 0.0016317]
	Learning Rate: 0.00163175
	LOSS [training: 0.23007225033678927 | validation: 0.3276779329882237]
	TIME [epoch: 10.5 sec]
EPOCH 397/500:
	Training over batches...
		[batch 5/5] avg loss: 0.26382815448489894		[learning rate: 0.0016241]
	Learning Rate: 0.0016241
	LOSS [training: 0.26382815448489894 | validation: 0.27826648486818045]
	TIME [epoch: 10.5 sec]
EPOCH 398/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21982215228444132		[learning rate: 0.0016165]
	Learning Rate: 0.00161648
	LOSS [training: 0.21982215228444132 | validation: 0.18775610906515902]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_398.pth
	Model improved!!!
EPOCH 399/500:
	Training over batches...
		[batch 5/5] avg loss: 0.30311532461761		[learning rate: 0.0016089]
	Learning Rate: 0.00160891
	LOSS [training: 0.30311532461761 | validation: 0.2768666443057424]
	TIME [epoch: 10.5 sec]
EPOCH 400/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24392034614895702		[learning rate: 0.0016014]
	Learning Rate: 0.00160136
	LOSS [training: 0.24392034614895702 | validation: 0.39438214118782944]
	TIME [epoch: 10.5 sec]
EPOCH 401/500:
	Training over batches...
		[batch 5/5] avg loss: 0.32711040687451587		[learning rate: 0.0015939]
	Learning Rate: 0.00159386
	LOSS [training: 0.32711040687451587 | validation: 0.390281036932837]
	TIME [epoch: 10.5 sec]
EPOCH 402/500:
	Training over batches...
		[batch 5/5] avg loss: 0.30226239448877157		[learning rate: 0.0015864]
	Learning Rate: 0.00158638
	LOSS [training: 0.30226239448877157 | validation: 0.313124680498852]
	TIME [epoch: 10.5 sec]
EPOCH 403/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22880009627275405		[learning rate: 0.0015789]
	Learning Rate: 0.00157895
	LOSS [training: 0.22880009627275405 | validation: 0.26357982942529856]
	TIME [epoch: 10.5 sec]
EPOCH 404/500:
	Training over batches...
		[batch 5/5] avg loss: 0.222095489823578		[learning rate: 0.0015715]
	Learning Rate: 0.00157154
	LOSS [training: 0.222095489823578 | validation: 0.23111361859772608]
	TIME [epoch: 10.5 sec]
EPOCH 405/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17586833453600084		[learning rate: 0.0015642]
	Learning Rate: 0.00156418
	LOSS [training: 0.17586833453600084 | validation: 0.16450136082612676]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_405.pth
	Model improved!!!
EPOCH 406/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2671381080597783		[learning rate: 0.0015568]
	Learning Rate: 0.00155684
	LOSS [training: 0.2671381080597783 | validation: 0.3811291412067548]
	TIME [epoch: 10.5 sec]
EPOCH 407/500:
	Training over batches...
		[batch 5/5] avg loss: 0.275648778524797		[learning rate: 0.0015495]
	Learning Rate: 0.00154954
	LOSS [training: 0.275648778524797 | validation: 0.2238167675225371]
	TIME [epoch: 10.5 sec]
EPOCH 408/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1800474690194816		[learning rate: 0.0015423]
	Learning Rate: 0.00154228
	LOSS [training: 0.1800474690194816 | validation: 0.16583228665378508]
	TIME [epoch: 10.5 sec]
EPOCH 409/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20280955916795113		[learning rate: 0.001535]
	Learning Rate: 0.00153505
	LOSS [training: 0.20280955916795113 | validation: 0.21497793494523046]
	TIME [epoch: 10.5 sec]
EPOCH 410/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19163996576127587		[learning rate: 0.0015279]
	Learning Rate: 0.00152785
	LOSS [training: 0.19163996576127587 | validation: 0.20779253868204067]
	TIME [epoch: 10.5 sec]
EPOCH 411/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24023554202867609		[learning rate: 0.0015207]
	Learning Rate: 0.00152069
	LOSS [training: 0.24023554202867609 | validation: 0.2381457280694301]
	TIME [epoch: 10.5 sec]
EPOCH 412/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22235714725159883		[learning rate: 0.0015136]
	Learning Rate: 0.00151356
	LOSS [training: 0.22235714725159883 | validation: 0.22103274938815454]
	TIME [epoch: 10.5 sec]
EPOCH 413/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2011354382718825		[learning rate: 0.0015065]
	Learning Rate: 0.00150647
	LOSS [training: 0.2011354382718825 | validation: 0.1480876171913534]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_413.pth
	Model improved!!!
EPOCH 414/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18664003595472894		[learning rate: 0.0014994]
	Learning Rate: 0.0014994
	LOSS [training: 0.18664003595472894 | validation: 0.17120810174761972]
	TIME [epoch: 10.5 sec]
EPOCH 415/500:
	Training over batches...
		[batch 5/5] avg loss: 0.16937994351869518		[learning rate: 0.0014924]
	Learning Rate: 0.00149237
	LOSS [training: 0.16937994351869518 | validation: 0.26778260904749185]
	TIME [epoch: 10.5 sec]
EPOCH 416/500:
	Training over batches...
		[batch 5/5] avg loss: 0.26716556327339414		[learning rate: 0.0014854]
	Learning Rate: 0.00148538
	LOSS [training: 0.26716556327339414 | validation: 0.28488814925808414]
	TIME [epoch: 10.5 sec]
EPOCH 417/500:
	Training over batches...
		[batch 5/5] avg loss: 0.25097860787074866		[learning rate: 0.0014784]
	Learning Rate: 0.00147841
	LOSS [training: 0.25097860787074866 | validation: 0.20679489931916265]
	TIME [epoch: 10.5 sec]
EPOCH 418/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15399621137954403		[learning rate: 0.0014715]
	Learning Rate: 0.00147148
	LOSS [training: 0.15399621137954403 | validation: 0.17400786581862246]
	TIME [epoch: 10.5 sec]
EPOCH 419/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18008047187067414		[learning rate: 0.0014646]
	Learning Rate: 0.00146458
	LOSS [training: 0.18008047187067414 | validation: 0.2698192863576318]
	TIME [epoch: 10.5 sec]
EPOCH 420/500:
	Training over batches...
		[batch 5/5] avg loss: 0.31478754819450294		[learning rate: 0.0014577]
	Learning Rate: 0.00145772
	LOSS [training: 0.31478754819450294 | validation: 0.3094250726834452]
	TIME [epoch: 10.5 sec]
EPOCH 421/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3461145689225321		[learning rate: 0.0014509]
	Learning Rate: 0.00145088
	LOSS [training: 0.3461145689225321 | validation: 0.38351808428174705]
	TIME [epoch: 10.5 sec]
EPOCH 422/500:
	Training over batches...
		[batch 5/5] avg loss: 0.33388375882254556		[learning rate: 0.0014441]
	Learning Rate: 0.00144408
	LOSS [training: 0.33388375882254556 | validation: 0.29533002140185505]
	TIME [epoch: 10.5 sec]
EPOCH 423/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24267904131817314		[learning rate: 0.0014373]
	Learning Rate: 0.00143731
	LOSS [training: 0.24267904131817314 | validation: 0.3169017740275753]
	TIME [epoch: 10.5 sec]
EPOCH 424/500:
	Training over batches...
		[batch 5/5] avg loss: 0.26649847349629796		[learning rate: 0.0014306]
	Learning Rate: 0.00143057
	LOSS [training: 0.26649847349629796 | validation: 0.2718980058566476]
	TIME [epoch: 10.5 sec]
EPOCH 425/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22980128471389136		[learning rate: 0.0014239]
	Learning Rate: 0.00142387
	LOSS [training: 0.22980128471389136 | validation: 0.17269800977715669]
	TIME [epoch: 10.5 sec]
EPOCH 426/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20410079522386884		[learning rate: 0.0014172]
	Learning Rate: 0.00141719
	LOSS [training: 0.20410079522386884 | validation: 0.25392701471667534]
	TIME [epoch: 10.5 sec]
EPOCH 427/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2868099988677949		[learning rate: 0.0014105]
	Learning Rate: 0.00141055
	LOSS [training: 0.2868099988677949 | validation: 0.3153543014804793]
	TIME [epoch: 10.5 sec]
EPOCH 428/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24765652480837402		[learning rate: 0.0014039]
	Learning Rate: 0.00140393
	LOSS [training: 0.24765652480837402 | validation: 0.25580350847739325]
	TIME [epoch: 10.5 sec]
EPOCH 429/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2670342859777862		[learning rate: 0.0013974]
	Learning Rate: 0.00139735
	LOSS [training: 0.2670342859777862 | validation: 0.24508563136339426]
	TIME [epoch: 10.5 sec]
EPOCH 430/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2438843727606705		[learning rate: 0.0013908]
	Learning Rate: 0.0013908
	LOSS [training: 0.2438843727606705 | validation: 0.23271172720223768]
	TIME [epoch: 10.5 sec]
EPOCH 431/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19322497086541718		[learning rate: 0.0013843]
	Learning Rate: 0.00138428
	LOSS [training: 0.19322497086541718 | validation: 0.18462828942966028]
	TIME [epoch: 10.5 sec]
EPOCH 432/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1722029742764783		[learning rate: 0.0013778]
	Learning Rate: 0.00137779
	LOSS [training: 0.1722029742764783 | validation: 0.21181302676437813]
	TIME [epoch: 10.5 sec]
EPOCH 433/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17145724135560703		[learning rate: 0.0013713]
	Learning Rate: 0.00137133
	LOSS [training: 0.17145724135560703 | validation: 0.1981242721365984]
	TIME [epoch: 10.5 sec]
EPOCH 434/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15307643705452403		[learning rate: 0.0013649]
	Learning Rate: 0.0013649
	LOSS [training: 0.15307643705452403 | validation: 0.14960353076087465]
	TIME [epoch: 10.5 sec]
EPOCH 435/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15279220763196175		[learning rate: 0.0013585]
	Learning Rate: 0.0013585
	LOSS [training: 0.15279220763196175 | validation: 0.12905342861241925]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_435.pth
	Model improved!!!
EPOCH 436/500:
	Training over batches...
		[batch 5/5] avg loss: 0.12689616228793218		[learning rate: 0.0013521]
	Learning Rate: 0.00135214
	LOSS [training: 0.12689616228793218 | validation: 0.22034292500993097]
	TIME [epoch: 10.5 sec]
EPOCH 437/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22320994280665798		[learning rate: 0.0013458]
	Learning Rate: 0.0013458
	LOSS [training: 0.22320994280665798 | validation: 0.2658606816972037]
	TIME [epoch: 10.5 sec]
EPOCH 438/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19602606373766066		[learning rate: 0.0013395]
	Learning Rate: 0.00133949
	LOSS [training: 0.19602606373766066 | validation: 0.14666378258509277]
	TIME [epoch: 10.5 sec]
EPOCH 439/500:
	Training over batches...
		[batch 5/5] avg loss: 0.16474475649083137		[learning rate: 0.0013332]
	Learning Rate: 0.00133321
	LOSS [training: 0.16474475649083137 | validation: 0.1292775929823709]
	TIME [epoch: 10.5 sec]
EPOCH 440/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15474647723080304		[learning rate: 0.001327]
	Learning Rate: 0.00132696
	LOSS [training: 0.15474647723080304 | validation: 0.16770944731015913]
	TIME [epoch: 10.5 sec]
EPOCH 441/500:
	Training over batches...
		[batch 5/5] avg loss: 0.13163956974832136		[learning rate: 0.0013207]
	Learning Rate: 0.00132074
	LOSS [training: 0.13163956974832136 | validation: 0.16349281271966595]
	TIME [epoch: 10.5 sec]
EPOCH 442/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17853526760568889		[learning rate: 0.0013145]
	Learning Rate: 0.00131454
	LOSS [training: 0.17853526760568889 | validation: 0.12341776526809482]
	TIME [epoch: 10.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240214_195103/states/model_tr_study6_442.pth
	Model improved!!!
EPOCH 443/500:
	Training over batches...
		[batch 5/5] avg loss: 0.14780495911605315		[learning rate: 0.0013084]
	Learning Rate: 0.00130838
	LOSS [training: 0.14780495911605315 | validation: 0.14565374974772555]
	TIME [epoch: 10.5 sec]
EPOCH 444/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1340220747177177		[learning rate: 0.0013022]
	Learning Rate: 0.00130225
	LOSS [training: 0.1340220747177177 | validation: 0.16604041400132807]
	TIME [epoch: 10.5 sec]
EPOCH 445/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15665198067205394		[learning rate: 0.0012961]
	Learning Rate: 0.00129614
	LOSS [training: 0.15665198067205394 | validation: 0.3396914610848112]
	TIME [epoch: 10.5 sec]
EPOCH 446/500:
	Training over batches...
		[batch 5/5] avg loss: 0.23107983489048042		[learning rate: 0.0012901]
	Learning Rate: 0.00129007
	LOSS [training: 0.23107983489048042 | validation: 0.17844193027230262]
	TIME [epoch: 10.5 sec]
EPOCH 447/500:
	Training over batches...
		[batch 5/5] avg loss: 0.16722957464937319		[learning rate: 0.001284]
	Learning Rate: 0.00128402
	LOSS [training: 0.16722957464937319 | validation: 0.17208259673037318]
	TIME [epoch: 10.5 sec]
EPOCH 448/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17646952654453732		[learning rate: 0.001278]
	Learning Rate: 0.001278
	LOSS [training: 0.17646952654453732 | validation: 0.19295321452419018]
	TIME [epoch: 10.5 sec]
EPOCH 449/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21356218963598678		[learning rate: 0.001272]
	Learning Rate: 0.00127201
	LOSS [training: 0.21356218963598678 | validation: 0.23896786629620906]
	TIME [epoch: 10.5 sec]
EPOCH 450/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20529825846683353		[learning rate: 0.001266]
	Learning Rate: 0.00126604
	LOSS [training: 0.20529825846683353 | validation: 0.2163750370397299]
	TIME [epoch: 10.5 sec]
EPOCH 451/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1877592045939333		[learning rate: 0.0012601]
	Learning Rate: 0.00126011
	LOSS [training: 0.1877592045939333 | validation: 0.19938650645114564]
	TIME [epoch: 10.5 sec]
EPOCH 452/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20508284873136237		[learning rate: 0.0012542]
	Learning Rate: 0.0012542
	LOSS [training: 0.20508284873136237 | validation: 0.2123812232243143]
	TIME [epoch: 10.5 sec]
EPOCH 453/500:
	Training over batches...
		[batch 5/5] avg loss: 0.23168117226524534		[learning rate: 0.0012483]
	Learning Rate: 0.00124832
	LOSS [training: 0.23168117226524534 | validation: 0.18149763370049962]
	TIME [epoch: 10.5 sec]
EPOCH 454/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20118092342591246		[learning rate: 0.0012425]
	Learning Rate: 0.00124247
	LOSS [training: 0.20118092342591246 | validation: 0.2552410795920115]
	TIME [epoch: 10.5 sec]
EPOCH 455/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2394089484150089		[learning rate: 0.0012366]
	Learning Rate: 0.00123664
	LOSS [training: 0.2394089484150089 | validation: 0.2017376830463844]
	TIME [epoch: 10.5 sec]
EPOCH 456/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1945465561196675		[learning rate: 0.0012308]
	Learning Rate: 0.00123085
	LOSS [training: 0.1945465561196675 | validation: 0.19050495637258869]
	TIME [epoch: 10.5 sec]
EPOCH 457/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18824402847925867		[learning rate: 0.0012251]
	Learning Rate: 0.00122508
	LOSS [training: 0.18824402847925867 | validation: 0.17855048072174232]
	TIME [epoch: 10.5 sec]
EPOCH 458/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1945954758680212		[learning rate: 0.0012193]
	Learning Rate: 0.00121933
	LOSS [training: 0.1945954758680212 | validation: 0.18100528509681588]
	TIME [epoch: 10.5 sec]
EPOCH 459/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2157653721973789		[learning rate: 0.0012136]
	Learning Rate: 0.00121362
	LOSS [training: 0.2157653721973789 | validation: 0.253488667402778]
	TIME [epoch: 10.5 sec]
EPOCH 460/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1731008715023969		[learning rate: 0.0012079]
	Learning Rate: 0.00120793
	LOSS [training: 0.1731008715023969 | validation: 0.2061981886345422]
	TIME [epoch: 10.5 sec]
EPOCH 461/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20706842079096827		[learning rate: 0.0012023]
	Learning Rate: 0.00120226
	LOSS [training: 0.20706842079096827 | validation: 0.23246129299695015]
	TIME [epoch: 10.5 sec]
EPOCH 462/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22189226682169724		[learning rate: 0.0011966]
	Learning Rate: 0.00119663
	LOSS [training: 0.22189226682169724 | validation: 0.17652816622617326]
	TIME [epoch: 10.5 sec]
EPOCH 463/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15381704411677713		[learning rate: 0.001191]
	Learning Rate: 0.00119102
	LOSS [training: 0.15381704411677713 | validation: 0.15097327453613255]
	TIME [epoch: 10.5 sec]
EPOCH 464/500:
	Training over batches...
		[batch 5/5] avg loss: 0.11881281567406062		[learning rate: 0.0011854]
	Learning Rate: 0.00118543
	LOSS [training: 0.11881281567406062 | validation: 0.15620829253591317]
	TIME [epoch: 10.5 sec]
EPOCH 465/500:
	Training over batches...
		[batch 5/5] avg loss: 0.22546120476687728		[learning rate: 0.0011799]
	Learning Rate: 0.00117988
	LOSS [training: 0.22546120476687728 | validation: 0.21424622488690517]
	TIME [epoch: 10.5 sec]
EPOCH 466/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19145174119065173		[learning rate: 0.0011743]
	Learning Rate: 0.00117435
	LOSS [training: 0.19145174119065173 | validation: 0.20660680297448128]
	TIME [epoch: 10.5 sec]
EPOCH 467/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17193123252850334		[learning rate: 0.0011688]
	Learning Rate: 0.00116884
	LOSS [training: 0.17193123252850334 | validation: 0.18251074730241232]
	TIME [epoch: 10.5 sec]
EPOCH 468/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3124459711137183		[learning rate: 0.0011634]
	Learning Rate: 0.00116336
	LOSS [training: 0.3124459711137183 | validation: 0.4571127636954054]
	TIME [epoch: 10.5 sec]
EPOCH 469/500:
	Training over batches...
		[batch 5/5] avg loss: 0.48956956394378837		[learning rate: 0.0011579]
	Learning Rate: 0.00115791
	LOSS [training: 0.48956956394378837 | validation: 0.27534880804471923]
	TIME [epoch: 10.5 sec]
EPOCH 470/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2087108847603988		[learning rate: 0.0011525]
	Learning Rate: 0.00115248
	LOSS [training: 0.2087108847603988 | validation: 0.21390739668587594]
	TIME [epoch: 10.5 sec]
EPOCH 471/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24917267930628628		[learning rate: 0.0011471]
	Learning Rate: 0.00114708
	LOSS [training: 0.24917267930628628 | validation: 0.18435926605766156]
	TIME [epoch: 10.5 sec]
EPOCH 472/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18974561945694424		[learning rate: 0.0011417]
	Learning Rate: 0.0011417
	LOSS [training: 0.18974561945694424 | validation: 0.1590816603115399]
	TIME [epoch: 10.5 sec]
EPOCH 473/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1564155674189775		[learning rate: 0.0011363]
	Learning Rate: 0.00113635
	LOSS [training: 0.1564155674189775 | validation: 0.15332176572221978]
	TIME [epoch: 10.5 sec]
EPOCH 474/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15791885332169397		[learning rate: 0.001131]
	Learning Rate: 0.00113102
	LOSS [training: 0.15791885332169397 | validation: 0.16336004859954392]
	TIME [epoch: 10.5 sec]
EPOCH 475/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18675095753653517		[learning rate: 0.0011257]
	Learning Rate: 0.00112572
	LOSS [training: 0.18675095753653517 | validation: 0.338766426135278]
	TIME [epoch: 10.5 sec]
EPOCH 476/500:
	Training over batches...
		[batch 5/5] avg loss: 0.25959350016187915		[learning rate: 0.0011204]
	Learning Rate: 0.00112044
	LOSS [training: 0.25959350016187915 | validation: 0.19026443502959278]
	TIME [epoch: 10.5 sec]
EPOCH 477/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18475712006974462		[learning rate: 0.0011152]
	Learning Rate: 0.00111518
	LOSS [training: 0.18475712006974462 | validation: 0.2233702780818615]
	TIME [epoch: 10.5 sec]
EPOCH 478/500:
	Training over batches...
		[batch 5/5] avg loss: 0.20176880319140517		[learning rate: 0.00111]
	Learning Rate: 0.00110996
	LOSS [training: 0.20176880319140517 | validation: 0.2847621846621968]
	TIME [epoch: 10.5 sec]
EPOCH 479/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2643246927825587		[learning rate: 0.0011048]
	Learning Rate: 0.00110475
	LOSS [training: 0.2643246927825587 | validation: 0.20014300108584526]
	TIME [epoch: 10.5 sec]
EPOCH 480/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15017140799331644		[learning rate: 0.0010996]
	Learning Rate: 0.00109957
	LOSS [training: 0.15017140799331644 | validation: 0.19408051326301576]
	TIME [epoch: 10.5 sec]
EPOCH 481/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19792164760746878		[learning rate: 0.0010944]
	Learning Rate: 0.00109442
	LOSS [training: 0.19792164760746878 | validation: 0.23205092004425631]
	TIME [epoch: 10.5 sec]
EPOCH 482/500:
	Training over batches...
		[batch 5/5] avg loss: 0.24351331610674257		[learning rate: 0.0010893]
	Learning Rate: 0.00108929
	LOSS [training: 0.24351331610674257 | validation: 0.1671940862734558]
	TIME [epoch: 10.5 sec]
EPOCH 483/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17858507944728105		[learning rate: 0.0010842]
	Learning Rate: 0.00108418
	LOSS [training: 0.17858507944728105 | validation: 0.2111047096410617]
	TIME [epoch: 10.5 sec]
EPOCH 484/500:
	Training over batches...
		[batch 5/5] avg loss: 0.206095827556695		[learning rate: 0.0010791]
	Learning Rate: 0.0010791
	LOSS [training: 0.206095827556695 | validation: 0.20876594808916435]
	TIME [epoch: 10.5 sec]
EPOCH 485/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21890177724617405		[learning rate: 0.001074]
	Learning Rate: 0.00107404
	LOSS [training: 0.21890177724617405 | validation: 0.23185898584965395]
	TIME [epoch: 10.5 sec]
EPOCH 486/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1826014516347304		[learning rate: 0.001069]
	Learning Rate: 0.001069
	LOSS [training: 0.1826014516347304 | validation: 0.17017954768588908]
	TIME [epoch: 10.5 sec]
EPOCH 487/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21698169926009805		[learning rate: 0.001064]
	Learning Rate: 0.00106399
	LOSS [training: 0.21698169926009805 | validation: 0.19791430181308337]
	TIME [epoch: 10.5 sec]
EPOCH 488/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2499670383443909		[learning rate: 0.001059]
	Learning Rate: 0.001059
	LOSS [training: 0.2499670383443909 | validation: 0.18513766386246563]
	TIME [epoch: 10.5 sec]
EPOCH 489/500:
	Training over batches...
		[batch 5/5] avg loss: 0.17397686634227177		[learning rate: 0.001054]
	Learning Rate: 0.00105404
	LOSS [training: 0.17397686634227177 | validation: 0.15799841551470253]
	TIME [epoch: 10.5 sec]
EPOCH 490/500:
	Training over batches...
		[batch 5/5] avg loss: 0.18044138857785377		[learning rate: 0.0010491]
	Learning Rate: 0.0010491
	LOSS [training: 0.18044138857785377 | validation: 0.22308638672109316]
	TIME [epoch: 10.5 sec]
EPOCH 491/500:
	Training over batches...
		[batch 5/5] avg loss: 0.21296603649927123		[learning rate: 0.0010442]
	Learning Rate: 0.00104418
	LOSS [training: 0.21296603649927123 | validation: 0.17875685886843432]
	TIME [epoch: 10.4 sec]
EPOCH 492/500:
	Training over batches...
		[batch 5/5] avg loss: 0.15850741561282589		[learning rate: 0.0010393]
	Learning Rate: 0.00103929
	LOSS [training: 0.15850741561282589 | validation: 0.1404930367109505]
	TIME [epoch: 10.5 sec]
EPOCH 493/500:
	Training over batches...
		[batch 5/5] avg loss: 0.13467074909798846		[learning rate: 0.0010344]
	Learning Rate: 0.00103441
	LOSS [training: 0.13467074909798846 | validation: 0.13709779516173007]
	TIME [epoch: 10.5 sec]
EPOCH 494/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19475481681294526		[learning rate: 0.0010296]
	Learning Rate: 0.00102956
	LOSS [training: 0.19475481681294526 | validation: 0.3092206338182479]
	TIME [epoch: 10.5 sec]
EPOCH 495/500:
	Training over batches...
		[batch 5/5] avg loss: 0.3382097887072489		[learning rate: 0.0010247]
	Learning Rate: 0.00102474
	LOSS [training: 0.3382097887072489 | validation: 0.2880214282324668]
	TIME [epoch: 10.5 sec]
EPOCH 496/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2888050149882798		[learning rate: 0.0010199]
	Learning Rate: 0.00101993
	LOSS [training: 0.2888050149882798 | validation: 0.3692537008630611]
	TIME [epoch: 10.5 sec]
EPOCH 497/500:
	Training over batches...
		[batch 5/5] avg loss: 0.2998508175908357		[learning rate: 0.0010152]
	Learning Rate: 0.00101515
	LOSS [training: 0.2998508175908357 | validation: 0.21379598850151396]
	TIME [epoch: 10.5 sec]
EPOCH 498/500:
	Training over batches...
		[batch 5/5] avg loss: 0.19165974462060692		[learning rate: 0.0010104]
	Learning Rate: 0.00101039
	LOSS [training: 0.19165974462060692 | validation: 0.13677298829771434]
	TIME [epoch: 10.5 sec]
EPOCH 499/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1488153107432413		[learning rate: 0.0010057]
	Learning Rate: 0.00100565
	LOSS [training: 0.1488153107432413 | validation: 0.12501397346620993]
	TIME [epoch: 10.5 sec]
EPOCH 500/500:
	Training over batches...
		[batch 5/5] avg loss: 0.1279653779265737		[learning rate: 0.0010009]
	Learning Rate: 0.00100094
	LOSS [training: 0.1279653779265737 | validation: 0.1402433751077463]
	TIME [epoch: 10.5 sec]
Finished training in 5304.706 seconds.
