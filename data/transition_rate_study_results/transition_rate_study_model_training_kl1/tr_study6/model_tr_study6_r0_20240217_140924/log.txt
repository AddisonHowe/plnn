Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r0', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r0', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=1000, batch_size=100, report_every=10, ndims=2, nparams=2, nsigs=2, ncells=200, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=True, sigma=0.05, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=0.0001, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 4149548047

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_0.pth
EPOCH 1/1000:
	Training over batches...
		[batch 5/5] avg loss: 9.059161149051501		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 9.059161149051501 | validation: 8.700125714413241]
	TIME [epoch: 81 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.606801416083467		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.606801416083467 | validation: 8.39609369177839]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.500493204385558		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.500493204385558 | validation: 7.732956275724176]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/1000:
	Training over batches...
		[batch 5/5] avg loss: 8.113260069921408		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.113260069921408 | validation: 7.60617719393592]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.909615917429965		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.909615917429965 | validation: 7.7860311832529465]
	TIME [epoch: 9.52 sec]
EPOCH 6/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.970199732991387		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.970199732991387 | validation: 7.228210339689938]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.588723062134234		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.588723062134234 | validation: 7.305507634007581]
	TIME [epoch: 9.54 sec]
EPOCH 8/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.646115815829819		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.646115815829819 | validation: 6.91705944019187]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.513003448175664		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.513003448175664 | validation: 6.856554293350067]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.3895160013129		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.3895160013129 | validation: 6.6134387210939884]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_10.pth
	Model improved!!!
EPOCH 11/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.003082359030256		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.003082359030256 | validation: 7.387252586413794]
	TIME [epoch: 9.52 sec]
EPOCH 12/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.204324819248976		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.204324819248976 | validation: 6.9680015204269194]
	TIME [epoch: 9.51 sec]
EPOCH 13/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.010627682032914		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.010627682032914 | validation: 6.563253927529579]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_13.pth
	Model improved!!!
EPOCH 14/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.877830385424329		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.877830385424329 | validation: 6.806385542923924]
	TIME [epoch: 9.53 sec]
EPOCH 15/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.929168645742361		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.929168645742361 | validation: 6.410715251701775]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_15.pth
	Model improved!!!
EPOCH 16/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.935767135649972		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.935767135649972 | validation: 6.642116225748555]
	TIME [epoch: 9.52 sec]
EPOCH 17/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.846989345880251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.846989345880251 | validation: 7.08064332967718]
	TIME [epoch: 9.54 sec]
EPOCH 18/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.0147166474302		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.0147166474302 | validation: 6.442450504615755]
	TIME [epoch: 9.52 sec]
EPOCH 19/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.835906787660404		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.835906787660404 | validation: 6.407872783102869]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_19.pth
	Model improved!!!
EPOCH 20/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.955949114181342		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.955949114181342 | validation: 6.342638941416624]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_20.pth
	Model improved!!!
EPOCH 21/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.85710318161275		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.85710318161275 | validation: 6.625125552231367]
	TIME [epoch: 9.52 sec]
EPOCH 22/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.857796978898305		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.857796978898305 | validation: 6.414614702437726]
	TIME [epoch: 9.51 sec]
EPOCH 23/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.7845780109192		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7845780109192 | validation: 6.286396321173465]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_23.pth
	Model improved!!!
EPOCH 24/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.164724723376315		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.164724723376315 | validation: 6.383952694232505]
	TIME [epoch: 9.53 sec]
EPOCH 25/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.916477025182182		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.916477025182182 | validation: 6.500437182570222]
	TIME [epoch: 9.51 sec]
EPOCH 26/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.075616430337637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.075616430337637 | validation: 6.475473340345953]
	TIME [epoch: 9.52 sec]
EPOCH 27/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.831186869512796		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.831186869512796 | validation: 6.380171990510357]
	TIME [epoch: 9.54 sec]
EPOCH 28/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.134040763589299		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.134040763589299 | validation: 6.719925151308599]
	TIME [epoch: 9.53 sec]
EPOCH 29/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.803481107397099		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.803481107397099 | validation: 6.566125958041696]
	TIME [epoch: 9.52 sec]
EPOCH 30/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.840223657037724		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.840223657037724 | validation: 6.279011530799343]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_30.pth
	Model improved!!!
EPOCH 31/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.705135260480146		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.705135260480146 | validation: 6.1691627930670645]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_31.pth
	Model improved!!!
EPOCH 32/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.6287949656878		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.6287949656878 | validation: 6.460879037052909]
	TIME [epoch: 9.52 sec]
EPOCH 33/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.8861312595913535		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.8861312595913535 | validation: 6.435716920975671]
	TIME [epoch: 9.51 sec]
EPOCH 34/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.827614132148197		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.827614132148197 | validation: 6.518616412074334]
	TIME [epoch: 9.54 sec]
EPOCH 35/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.815777911852497		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.815777911852497 | validation: 6.4195630161559505]
	TIME [epoch: 9.52 sec]
EPOCH 36/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.825084847627634		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.825084847627634 | validation: 6.347210025453883]
	TIME [epoch: 9.51 sec]
EPOCH 37/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.755756472055898		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.755756472055898 | validation: 7.015707890348181]
	TIME [epoch: 9.52 sec]
EPOCH 38/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.931369592469491		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.931369592469491 | validation: 6.621608502305816]
	TIME [epoch: 9.53 sec]
EPOCH 39/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.849781557909236		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.849781557909236 | validation: 6.279653940823603]
	TIME [epoch: 9.52 sec]
EPOCH 40/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.76374337587026		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.76374337587026 | validation: 6.318048985258838]
	TIME [epoch: 9.51 sec]
EPOCH 41/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.911909168469204		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.911909168469204 | validation: 6.336945687194466]
	TIME [epoch: 9.54 sec]
EPOCH 42/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.821118938096843		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.821118938096843 | validation: 6.290120878287983]
	TIME [epoch: 9.52 sec]
EPOCH 43/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.816617203084602		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.816617203084602 | validation: 6.321264465762943]
	TIME [epoch: 9.51 sec]
EPOCH 44/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.7789720319488875		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.7789720319488875 | validation: 6.482256567072277]
	TIME [epoch: 9.52 sec]
EPOCH 45/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.790865109043921		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.790865109043921 | validation: 6.318490222667959]
	TIME [epoch: 9.53 sec]
EPOCH 46/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.739050967254515		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.739050967254515 | validation: 6.305813872177694]
	TIME [epoch: 9.51 sec]
EPOCH 47/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.943875784313637		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.943875784313637 | validation: 6.546099750275507]
	TIME [epoch: 9.52 sec]
EPOCH 48/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.805483674624739		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.805483674624739 | validation: 6.118697934699846]
	TIME [epoch: 9.54 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_48.pth
	Model improved!!!
EPOCH 49/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.322019269890187		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.322019269890187 | validation: 6.6685752361617485]
	TIME [epoch: 9.52 sec]
EPOCH 50/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.9246085548918845		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.9246085548918845 | validation: 6.355056560203496]
	TIME [epoch: 9.52 sec]
EPOCH 51/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.734196648080368		[learning rate: 0.0099613]
	Learning Rate: 0.00996129
	LOSS [training: 6.734196648080368 | validation: 6.4239710100357845]
	TIME [epoch: 9.52 sec]
EPOCH 52/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.765741910449128		[learning rate: 0.0099131]
	Learning Rate: 0.00991312
	LOSS [training: 6.765741910449128 | validation: 6.469488465815241]
	TIME [epoch: 9.53 sec]
EPOCH 53/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.736261059406448		[learning rate: 0.0098652]
	Learning Rate: 0.00986519
	LOSS [training: 6.736261059406448 | validation: 6.110060005770463]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_53.pth
	Model improved!!!
EPOCH 54/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.543836452486336		[learning rate: 0.0098175]
	Learning Rate: 0.00981748
	LOSS [training: 6.543836452486336 | validation: 6.1423702262233615]
	TIME [epoch: 9.53 sec]
EPOCH 55/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.39154979234668		[learning rate: 0.00977]
	Learning Rate: 0.00977
	LOSS [training: 6.39154979234668 | validation: 6.121240505467019]
	TIME [epoch: 9.54 sec]
EPOCH 56/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.453724290180121		[learning rate: 0.0097228]
	Learning Rate: 0.00972276
	LOSS [training: 6.453724290180121 | validation: 6.028756037995972]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_56.pth
	Model improved!!!
EPOCH 57/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.7349762662693875		[learning rate: 0.0096757]
	Learning Rate: 0.00967574
	LOSS [training: 6.7349762662693875 | validation: 5.968477067043781]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_57.pth
	Model improved!!!
EPOCH 58/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.92021911227189		[learning rate: 0.009629]
	Learning Rate: 0.00962895
	LOSS [training: 6.92021911227189 | validation: 7.110996492876718]
	TIME [epoch: 9.53 sec]
EPOCH 59/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.178740731519495		[learning rate: 0.0095824]
	Learning Rate: 0.00958239
	LOSS [training: 7.178740731519495 | validation: 6.299981717720572]
	TIME [epoch: 9.52 sec]
EPOCH 60/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.614652793137159		[learning rate: 0.009536]
	Learning Rate: 0.00953605
	LOSS [training: 6.614652793137159 | validation: 5.993457674334491]
	TIME [epoch: 9.5 sec]
EPOCH 61/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.449667992004102		[learning rate: 0.0094899]
	Learning Rate: 0.00948993
	LOSS [training: 7.449667992004102 | validation: 7.408395498731798]
	TIME [epoch: 9.5 sec]
EPOCH 62/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.339636145533343		[learning rate: 0.009444]
	Learning Rate: 0.00944404
	LOSS [training: 7.339636145533343 | validation: 6.0628992203272025]
	TIME [epoch: 9.53 sec]
EPOCH 63/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.68998719368188		[learning rate: 0.0093984]
	Learning Rate: 0.00939837
	LOSS [training: 6.68998719368188 | validation: 6.343054270961914]
	TIME [epoch: 9.51 sec]
EPOCH 64/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.602308368008911		[learning rate: 0.0093529]
	Learning Rate: 0.00935292
	LOSS [training: 6.602308368008911 | validation: 5.9463671750640446]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_64.pth
	Model improved!!!
EPOCH 65/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.611179777453789		[learning rate: 0.0093077]
	Learning Rate: 0.00930769
	LOSS [training: 6.611179777453789 | validation: 6.317421360034735]
	TIME [epoch: 9.53 sec]
EPOCH 66/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.9347268064463155		[learning rate: 0.0092627]
	Learning Rate: 0.00926268
	LOSS [training: 6.9347268064463155 | validation: 6.141150830963623]
	TIME [epoch: 9.51 sec]
EPOCH 67/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.567929685002591		[learning rate: 0.0092179]
	Learning Rate: 0.00921789
	LOSS [training: 6.567929685002591 | validation: 6.471142309035977]
	TIME [epoch: 9.51 sec]
EPOCH 68/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.791490529147995		[learning rate: 0.0091733]
	Learning Rate: 0.00917332
	LOSS [training: 6.791490529147995 | validation: 6.806794848458333]
	TIME [epoch: 9.5 sec]
EPOCH 69/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.670036496790203		[learning rate: 0.009129]
	Learning Rate: 0.00912895
	LOSS [training: 6.670036496790203 | validation: 6.430139948929933]
	TIME [epoch: 9.53 sec]
EPOCH 70/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.566191524540062		[learning rate: 0.0090848]
	Learning Rate: 0.00908481
	LOSS [training: 6.566191524540062 | validation: 6.984829204377647]
	TIME [epoch: 9.5 sec]
EPOCH 71/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.880125415142041		[learning rate: 0.0090409]
	Learning Rate: 0.00904088
	LOSS [training: 6.880125415142041 | validation: 6.777206823559188]
	TIME [epoch: 9.52 sec]
EPOCH 72/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.030705210219631		[learning rate: 0.0089972]
	Learning Rate: 0.00899716
	LOSS [training: 7.030705210219631 | validation: 6.3880502188567885]
	TIME [epoch: 9.52 sec]
EPOCH 73/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.405204663360676		[learning rate: 0.0089536]
	Learning Rate: 0.00895365
	LOSS [training: 7.405204663360676 | validation: 7.616692293181195]
	TIME [epoch: 9.5 sec]
EPOCH 74/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.550660563335927		[learning rate: 0.0089103]
	Learning Rate: 0.00891035
	LOSS [training: 7.550660563335927 | validation: 6.197748850275905]
	TIME [epoch: 9.5 sec]
EPOCH 75/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.642413107220645		[learning rate: 0.0088673]
	Learning Rate: 0.00886726
	LOSS [training: 6.642413107220645 | validation: 7.125253090625258]
	TIME [epoch: 9.51 sec]
EPOCH 76/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.937642696147708		[learning rate: 0.0088244]
	Learning Rate: 0.00882438
	LOSS [training: 6.937642696147708 | validation: 6.110505477024718]
	TIME [epoch: 9.52 sec]
EPOCH 77/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.560716274504669		[learning rate: 0.0087817]
	Learning Rate: 0.00878171
	LOSS [training: 6.560716274504669 | validation: 5.889440918709049]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_77.pth
	Model improved!!!
EPOCH 78/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.574097909190746		[learning rate: 0.0087392]
	Learning Rate: 0.00873924
	LOSS [training: 6.574097909190746 | validation: 5.963496535131565]
	TIME [epoch: 9.5 sec]
EPOCH 79/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.3458441326782795		[learning rate: 0.008697]
	Learning Rate: 0.00869698
	LOSS [training: 6.3458441326782795 | validation: 5.788924217661294]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_79.pth
	Model improved!!!
EPOCH 80/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.643361572596457		[learning rate: 0.0086549]
	Learning Rate: 0.00865492
	LOSS [training: 6.643361572596457 | validation: 6.251737398144419]
	TIME [epoch: 9.51 sec]
EPOCH 81/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.302880513986851		[learning rate: 0.0086131]
	Learning Rate: 0.00861307
	LOSS [training: 6.302880513986851 | validation: 5.748267855121327]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_81.pth
	Model improved!!!
EPOCH 82/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.63797150276125		[learning rate: 0.0085714]
	Learning Rate: 0.00857142
	LOSS [training: 5.63797150276125 | validation: 5.000530421066901]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_82.pth
	Model improved!!!
EPOCH 83/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.030488543833084		[learning rate: 0.00853]
	Learning Rate: 0.00852997
	LOSS [training: 5.030488543833084 | validation: 4.594701182394743]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_83.pth
	Model improved!!!
EPOCH 84/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.7768108340374		[learning rate: 0.0084887]
	Learning Rate: 0.00848872
	LOSS [training: 4.7768108340374 | validation: 4.716694899800159]
	TIME [epoch: 9.5 sec]
EPOCH 85/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.689602271235364		[learning rate: 0.0084477]
	Learning Rate: 0.00844767
	LOSS [training: 4.689602271235364 | validation: 5.210381308804106]
	TIME [epoch: 9.51 sec]
EPOCH 86/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.581965416276008		[learning rate: 0.0084068]
	Learning Rate: 0.00840682
	LOSS [training: 4.581965416276008 | validation: 4.267405989335908]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_86.pth
	Model improved!!!
EPOCH 87/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.260162425653565		[learning rate: 0.0083662]
	Learning Rate: 0.00836616
	LOSS [training: 4.260162425653565 | validation: 4.170226349686836]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_87.pth
	Model improved!!!
EPOCH 88/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.426369760137772		[learning rate: 0.0083257]
	Learning Rate: 0.00832571
	LOSS [training: 4.426369760137772 | validation: 4.218737087122409]
	TIME [epoch: 9.5 sec]
EPOCH 89/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.073938169841176		[learning rate: 0.0082854]
	Learning Rate: 0.00828544
	LOSS [training: 4.073938169841176 | validation: 4.070313930989238]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_89.pth
	Model improved!!!
EPOCH 90/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0586715356827305		[learning rate: 0.0082454]
	Learning Rate: 0.00824538
	LOSS [training: 4.0586715356827305 | validation: 3.6894685305337203]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_90.pth
	Model improved!!!
EPOCH 91/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6777855953909233		[learning rate: 0.0082055]
	Learning Rate: 0.0082055
	LOSS [training: 3.6777855953909233 | validation: 4.598680553581911]
	TIME [epoch: 9.51 sec]
EPOCH 92/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.778770820689463		[learning rate: 0.0081658]
	Learning Rate: 0.00816582
	LOSS [training: 3.778770820689463 | validation: 3.402466229956291]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_92.pth
	Model improved!!!
EPOCH 93/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5939339808439796		[learning rate: 0.0081263]
	Learning Rate: 0.00812634
	LOSS [training: 3.5939339808439796 | validation: 3.5817274533523507]
	TIME [epoch: 9.53 sec]
EPOCH 94/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5666263929666258		[learning rate: 0.008087]
	Learning Rate: 0.00808704
	LOSS [training: 3.5666263929666258 | validation: 3.7134580588072597]
	TIME [epoch: 9.5 sec]
EPOCH 95/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4608181584855466		[learning rate: 0.0080479]
	Learning Rate: 0.00804793
	LOSS [training: 3.4608181584855466 | validation: 3.3639073118420293]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_95.pth
	Model improved!!!
EPOCH 96/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4334025066492146		[learning rate: 0.008009]
	Learning Rate: 0.00800901
	LOSS [training: 3.4334025066492146 | validation: 3.716423220700396]
	TIME [epoch: 9.52 sec]
EPOCH 97/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4806270088448543		[learning rate: 0.0079703]
	Learning Rate: 0.00797028
	LOSS [training: 3.4806270088448543 | validation: 3.4897172534363166]
	TIME [epoch: 9.51 sec]
EPOCH 98/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.918562220720704		[learning rate: 0.0079317]
	Learning Rate: 0.00793174
	LOSS [training: 3.918562220720704 | validation: 3.67566691940747]
	TIME [epoch: 9.51 sec]
EPOCH 99/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2894497263132507		[learning rate: 0.0078934]
	Learning Rate: 0.00789338
	LOSS [training: 3.2894497263132507 | validation: 3.234219034656738]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_99.pth
	Model improved!!!
EPOCH 100/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.243458570752419		[learning rate: 0.0078552]
	Learning Rate: 0.00785521
	LOSS [training: 3.243458570752419 | validation: 3.3239337925795143]
	TIME [epoch: 9.53 sec]
EPOCH 101/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2529223985226636		[learning rate: 0.0078172]
	Learning Rate: 0.00781722
	LOSS [training: 3.2529223985226636 | validation: 3.831466779604725]
	TIME [epoch: 9.5 sec]
EPOCH 102/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6005830537294656		[learning rate: 0.0077794]
	Learning Rate: 0.00777942
	LOSS [training: 3.6005830537294656 | validation: 3.8384204101099484]
	TIME [epoch: 9.5 sec]
EPOCH 103/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7377270809540746		[learning rate: 0.0077418]
	Learning Rate: 0.0077418
	LOSS [training: 3.7377270809540746 | validation: 3.8102726297267044]
	TIME [epoch: 9.53 sec]
EPOCH 104/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.46683689286792		[learning rate: 0.0077044]
	Learning Rate: 0.00770437
	LOSS [training: 3.46683689286792 | validation: 3.9368216249678993]
	TIME [epoch: 9.51 sec]
EPOCH 105/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5986695921161784		[learning rate: 0.0076671]
	Learning Rate: 0.00766711
	LOSS [training: 3.5986695921161784 | validation: 3.3238047203187024]
	TIME [epoch: 9.51 sec]
EPOCH 106/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.405384067537996		[learning rate: 0.00763]
	Learning Rate: 0.00763003
	LOSS [training: 3.405384067537996 | validation: 3.678768974517626]
	TIME [epoch: 9.5 sec]
EPOCH 107/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3106584024293495		[learning rate: 0.0075931]
	Learning Rate: 0.00759313
	LOSS [training: 3.3106584024293495 | validation: 4.2605183358252665]
	TIME [epoch: 9.53 sec]
EPOCH 108/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5864032290598225		[learning rate: 0.0075564]
	Learning Rate: 0.00755642
	LOSS [training: 3.5864032290598225 | validation: 3.4723053058329323]
	TIME [epoch: 9.5 sec]
EPOCH 109/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4880377459215097		[learning rate: 0.0075199]
	Learning Rate: 0.00751987
	LOSS [training: 3.4880377459215097 | validation: 3.3634931392414145]
	TIME [epoch: 9.5 sec]
EPOCH 110/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5602033764482477		[learning rate: 0.0074835]
	Learning Rate: 0.00748351
	LOSS [training: 3.5602033764482477 | validation: 6.553691698734924]
	TIME [epoch: 9.52 sec]
EPOCH 111/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.1516041187709005		[learning rate: 0.0074473]
	Learning Rate: 0.00744732
	LOSS [training: 6.1516041187709005 | validation: 5.33830349091164]
	TIME [epoch: 9.51 sec]
EPOCH 112/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.357151684530189		[learning rate: 0.0074113]
	Learning Rate: 0.00741131
	LOSS [training: 5.357151684530189 | validation: 4.9445198432173045]
	TIME [epoch: 9.5 sec]
EPOCH 113/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.841726539063515		[learning rate: 0.0073755]
	Learning Rate: 0.00737547
	LOSS [training: 4.841726539063515 | validation: 4.767973621790717]
	TIME [epoch: 9.5 sec]
EPOCH 114/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.176733541574339		[learning rate: 0.0073398]
	Learning Rate: 0.0073398
	LOSS [training: 4.176733541574339 | validation: 3.6697309520097154]
	TIME [epoch: 9.52 sec]
EPOCH 115/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5098385047332634		[learning rate: 0.0073043]
	Learning Rate: 0.00730431
	LOSS [training: 3.5098385047332634 | validation: 4.44257138844289]
	TIME [epoch: 9.51 sec]
EPOCH 116/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7921737052493882		[learning rate: 0.007269]
	Learning Rate: 0.00726898
	LOSS [training: 3.7921737052493882 | validation: 3.4969989128075167]
	TIME [epoch: 9.5 sec]
EPOCH 117/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.378199651932244		[learning rate: 0.0072338]
	Learning Rate: 0.00723383
	LOSS [training: 3.378199651932244 | validation: 3.17576963401521]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_117.pth
	Model improved!!!
EPOCH 118/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5632843687484743		[learning rate: 0.0071989]
	Learning Rate: 0.00719885
	LOSS [training: 3.5632843687484743 | validation: 4.5750665226096485]
	TIME [epoch: 9.51 sec]
EPOCH 119/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.500567264670113		[learning rate: 0.007164]
	Learning Rate: 0.00716404
	LOSS [training: 4.500567264670113 | validation: 3.972056568709372]
	TIME [epoch: 9.5 sec]
EPOCH 120/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5055735041234444		[learning rate: 0.0071294]
	Learning Rate: 0.00712939
	LOSS [training: 3.5055735041234444 | validation: 4.700309108314557]
	TIME [epoch: 9.51 sec]
EPOCH 121/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.658461464301316		[learning rate: 0.0070949]
	Learning Rate: 0.00709492
	LOSS [training: 4.658461464301316 | validation: 5.412177435586081]
	TIME [epoch: 9.53 sec]
EPOCH 122/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.813438547377172		[learning rate: 0.0070606]
	Learning Rate: 0.00706061
	LOSS [training: 4.813438547377172 | validation: 4.461385071831787]
	TIME [epoch: 9.5 sec]
EPOCH 123/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.094515327518707		[learning rate: 0.0070265]
	Learning Rate: 0.00702646
	LOSS [training: 4.094515327518707 | validation: 3.5544070063194306]
	TIME [epoch: 9.5 sec]
EPOCH 124/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9077058759646635		[learning rate: 0.0069925]
	Learning Rate: 0.00699248
	LOSS [training: 3.9077058759646635 | validation: 4.700653096741467]
	TIME [epoch: 9.52 sec]
EPOCH 125/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.367321711963735		[learning rate: 0.0069587]
	Learning Rate: 0.00695867
	LOSS [training: 4.367321711963735 | validation: 3.989029850620456]
	TIME [epoch: 9.51 sec]
EPOCH 126/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.465313058982683		[learning rate: 0.006925]
	Learning Rate: 0.00692502
	LOSS [training: 3.465313058982683 | validation: 4.253874560958438]
	TIME [epoch: 9.5 sec]
EPOCH 127/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.517918986060846		[learning rate: 0.0068915]
	Learning Rate: 0.00689153
	LOSS [training: 5.517918986060846 | validation: 5.465062716272334]
	TIME [epoch: 9.51 sec]
EPOCH 128/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.239171614113735		[learning rate: 0.0068582]
	Learning Rate: 0.00685821
	LOSS [training: 4.239171614113735 | validation: 5.808162204469106]
	TIME [epoch: 9.52 sec]
EPOCH 129/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.55073612245576		[learning rate: 0.006825]
	Learning Rate: 0.00682504
	LOSS [training: 6.55073612245576 | validation: 7.395415780184707]
	TIME [epoch: 9.5 sec]
EPOCH 130/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.756555344729051		[learning rate: 0.006792]
	Learning Rate: 0.00679204
	LOSS [training: 6.756555344729051 | validation: 6.6014969331251265]
	TIME [epoch: 9.5 sec]
EPOCH 131/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.814607687038738		[learning rate: 0.0067592]
	Learning Rate: 0.00675919
	LOSS [training: 4.814607687038738 | validation: 3.534511948975604]
	TIME [epoch: 9.52 sec]
EPOCH 132/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5384943049561697		[learning rate: 0.0067265]
	Learning Rate: 0.00672651
	LOSS [training: 3.5384943049561697 | validation: 3.4612122825656555]
	TIME [epoch: 9.5 sec]
EPOCH 133/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0355089673779565		[learning rate: 0.006694]
	Learning Rate: 0.00669398
	LOSS [training: 4.0355089673779565 | validation: 4.277534218480649]
	TIME [epoch: 9.5 sec]
EPOCH 134/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.758613695128593		[learning rate: 0.0066616]
	Learning Rate: 0.00666161
	LOSS [training: 3.758613695128593 | validation: 3.4967564048617215]
	TIME [epoch: 9.51 sec]
EPOCH 135/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.486759795879931		[learning rate: 0.0066294]
	Learning Rate: 0.00662939
	LOSS [training: 3.486759795879931 | validation: 4.894183093484775]
	TIME [epoch: 9.52 sec]
EPOCH 136/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.189429194320049		[learning rate: 0.0065973]
	Learning Rate: 0.00659733
	LOSS [training: 5.189429194320049 | validation: 4.918923953445584]
	TIME [epoch: 9.51 sec]
EPOCH 137/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.209499872788478		[learning rate: 0.0065654]
	Learning Rate: 0.00656543
	LOSS [training: 4.209499872788478 | validation: 3.881815779170812]
	TIME [epoch: 9.51 sec]
EPOCH 138/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6428477562811388		[learning rate: 0.0065337]
	Learning Rate: 0.00653368
	LOSS [training: 3.6428477562811388 | validation: 3.907646142906204]
	TIME [epoch: 9.53 sec]
EPOCH 139/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.538330039958173		[learning rate: 0.0065021]
	Learning Rate: 0.00650208
	LOSS [training: 3.538330039958173 | validation: 4.166086219898688]
	TIME [epoch: 9.51 sec]
EPOCH 140/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.851347716205346		[learning rate: 0.0064706]
	Learning Rate: 0.00647064
	LOSS [training: 3.851347716205346 | validation: 5.342089622765362]
	TIME [epoch: 9.51 sec]
EPOCH 141/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.042848368342891		[learning rate: 0.0064394]
	Learning Rate: 0.00643935
	LOSS [training: 5.042848368342891 | validation: 3.9461505290082455]
	TIME [epoch: 9.51 sec]
EPOCH 142/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7289133729831248		[learning rate: 0.0064082]
	Learning Rate: 0.00640821
	LOSS [training: 3.7289133729831248 | validation: 3.3458856907541263]
	TIME [epoch: 9.52 sec]
EPOCH 143/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3080547033508245		[learning rate: 0.0063772]
	Learning Rate: 0.00637722
	LOSS [training: 3.3080547033508245 | validation: 3.642465745084402]
	TIME [epoch: 9.51 sec]
EPOCH 144/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.577658801935545		[learning rate: 0.0063464]
	Learning Rate: 0.00634638
	LOSS [training: 3.577658801935545 | validation: 4.356902264794294]
	TIME [epoch: 9.51 sec]
EPOCH 145/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.294741075746982		[learning rate: 0.0063157]
	Learning Rate: 0.00631569
	LOSS [training: 4.294741075746982 | validation: 4.428264056805723]
	TIME [epoch: 9.53 sec]
EPOCH 146/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.090626633247188		[learning rate: 0.0062852]
	Learning Rate: 0.00628515
	LOSS [training: 4.090626633247188 | validation: 5.196655415069199]
	TIME [epoch: 9.51 sec]
EPOCH 147/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.430867346314967		[learning rate: 0.0062548]
	Learning Rate: 0.00625476
	LOSS [training: 5.430867346314967 | validation: 5.485991555703925]
	TIME [epoch: 9.51 sec]
EPOCH 148/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.621508982367461		[learning rate: 0.0062245]
	Learning Rate: 0.00622451
	LOSS [training: 4.621508982367461 | validation: 3.6624146659848016]
	TIME [epoch: 9.51 sec]
EPOCH 149/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.384076717807966		[learning rate: 0.0061944]
	Learning Rate: 0.00619441
	LOSS [training: 3.384076717807966 | validation: 3.3658509547257522]
	TIME [epoch: 9.52 sec]
EPOCH 150/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6591160834963974		[learning rate: 0.0061645]
	Learning Rate: 0.00616446
	LOSS [training: 3.6591160834963974 | validation: 4.6400457812384195]
	TIME [epoch: 9.51 sec]
EPOCH 151/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.515446517907385		[learning rate: 0.0061346]
	Learning Rate: 0.00613465
	LOSS [training: 4.515446517907385 | validation: 3.573503608085467]
	TIME [epoch: 9.51 sec]
EPOCH 152/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.109604971889505		[learning rate: 0.006105]
	Learning Rate: 0.00610498
	LOSS [training: 4.109604971889505 | validation: 4.021124357085872]
	TIME [epoch: 9.53 sec]
EPOCH 153/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.889513392105509		[learning rate: 0.0060755]
	Learning Rate: 0.00607546
	LOSS [training: 3.889513392105509 | validation: 3.5419854266629365]
	TIME [epoch: 9.51 sec]
EPOCH 154/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4335025170505817		[learning rate: 0.0060461]
	Learning Rate: 0.00604608
	LOSS [training: 3.4335025170505817 | validation: 3.799547979754093]
	TIME [epoch: 9.5 sec]
EPOCH 155/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.252549415136275		[learning rate: 0.0060168]
	Learning Rate: 0.00601684
	LOSS [training: 5.252549415136275 | validation: 6.668327114474321]
	TIME [epoch: 9.52 sec]
EPOCH 156/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.379084106880539		[learning rate: 0.0059877]
	Learning Rate: 0.00598774
	LOSS [training: 5.379084106880539 | validation: 4.306708189143469]
	TIME [epoch: 9.53 sec]
EPOCH 157/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.5320197372238		[learning rate: 0.0059588]
	Learning Rate: 0.00595879
	LOSS [training: 4.5320197372238 | validation: 4.662693387158193]
	TIME [epoch: 9.51 sec]
EPOCH 158/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.4917140856102415		[learning rate: 0.00593]
	Learning Rate: 0.00592997
	LOSS [training: 4.4917140856102415 | validation: 3.924902225028753]
	TIME [epoch: 9.5 sec]
EPOCH 159/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.193861976451144		[learning rate: 0.0059013]
	Learning Rate: 0.0059013
	LOSS [training: 4.193861976451144 | validation: 6.0794227508622045]
	TIME [epoch: 9.54 sec]
EPOCH 160/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.662086897104674		[learning rate: 0.0058728]
	Learning Rate: 0.00587276
	LOSS [training: 6.662086897104674 | validation: 7.349413779476212]
	TIME [epoch: 9.51 sec]
EPOCH 161/1000:
	Training over batches...
		[batch 5/5] avg loss: 7.532860264433016		[learning rate: 0.0058444]
	Learning Rate: 0.00584436
	LOSS [training: 7.532860264433016 | validation: 6.500682542545626]
	TIME [epoch: 9.5 sec]
EPOCH 162/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.033522011314043		[learning rate: 0.0058161]
	Learning Rate: 0.0058161
	LOSS [training: 6.033522011314043 | validation: 5.361300140823166]
	TIME [epoch: 9.52 sec]
EPOCH 163/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.719357287472494		[learning rate: 0.005788]
	Learning Rate: 0.00578797
	LOSS [training: 4.719357287472494 | validation: 4.654030167652366]
	TIME [epoch: 9.52 sec]
EPOCH 164/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.924025789481445		[learning rate: 0.00576]
	Learning Rate: 0.00575998
	LOSS [training: 5.924025789481445 | validation: 6.575461846736602]
	TIME [epoch: 9.5 sec]
EPOCH 165/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.809761956457637		[learning rate: 0.0057321]
	Learning Rate: 0.00573213
	LOSS [training: 5.809761956457637 | validation: 5.459259866987813]
	TIME [epoch: 9.51 sec]
EPOCH 166/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.334085474360907		[learning rate: 0.0057044]
	Learning Rate: 0.00570441
	LOSS [training: 4.334085474360907 | validation: 3.861145023456768]
	TIME [epoch: 9.53 sec]
EPOCH 167/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7509309982036605		[learning rate: 0.0056768]
	Learning Rate: 0.00567682
	LOSS [training: 3.7509309982036605 | validation: 3.6230853762582798]
	TIME [epoch: 9.51 sec]
EPOCH 168/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.461673154362792		[learning rate: 0.0056494]
	Learning Rate: 0.00564937
	LOSS [training: 3.461673154362792 | validation: 3.6003356961053736]
	TIME [epoch: 9.5 sec]
EPOCH 169/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5286354052830107		[learning rate: 0.0056221]
	Learning Rate: 0.00562205
	LOSS [training: 3.5286354052830107 | validation: 4.152274744936109]
	TIME [epoch: 9.51 sec]
EPOCH 170/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7781643533676474		[learning rate: 0.0055949]
	Learning Rate: 0.00559486
	LOSS [training: 3.7781643533676474 | validation: 3.4908775007618944]
	TIME [epoch: 9.53 sec]
EPOCH 171/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.117780368156085		[learning rate: 0.0055678]
	Learning Rate: 0.00556781
	LOSS [training: 4.117780368156085 | validation: 5.621995853331491]
	TIME [epoch: 9.52 sec]
EPOCH 172/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.2523228301571345		[learning rate: 0.0055409]
	Learning Rate: 0.00554088
	LOSS [training: 5.2523228301571345 | validation: 4.828025474151716]
	TIME [epoch: 9.5 sec]
EPOCH 173/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.055773429844274		[learning rate: 0.0055141]
	Learning Rate: 0.00551409
	LOSS [training: 5.055773429844274 | validation: 4.360778049844676]
	TIME [epoch: 9.52 sec]
EPOCH 174/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.889806085125491		[learning rate: 0.0054874]
	Learning Rate: 0.00548742
	LOSS [training: 3.889806085125491 | validation: 3.67708154820801]
	TIME [epoch: 9.51 sec]
EPOCH 175/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7286520082146		[learning rate: 0.0054609]
	Learning Rate: 0.00546089
	LOSS [training: 3.7286520082146 | validation: 3.653952096555356]
	TIME [epoch: 9.51 sec]
EPOCH 176/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7082244056398777		[learning rate: 0.0054345]
	Learning Rate: 0.00543448
	LOSS [training: 3.7082244056398777 | validation: 3.6005618499662053]
	TIME [epoch: 9.53 sec]
EPOCH 177/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6909521330845365		[learning rate: 0.0054082]
	Learning Rate: 0.0054082
	LOSS [training: 3.6909521330845365 | validation: 4.725858286168403]
	TIME [epoch: 9.51 sec]
EPOCH 178/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.099990586102555		[learning rate: 0.005382]
	Learning Rate: 0.00538205
	LOSS [training: 4.099990586102555 | validation: 3.654650532164566]
	TIME [epoch: 9.51 sec]
EPOCH 179/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5555159091031037		[learning rate: 0.005356]
	Learning Rate: 0.00535602
	LOSS [training: 3.5555159091031037 | validation: 3.5789473609590403]
	TIME [epoch: 9.51 sec]
EPOCH 180/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.431012954701669		[learning rate: 0.0053301]
	Learning Rate: 0.00533012
	LOSS [training: 3.431012954701669 | validation: 3.722681943875273]
	TIME [epoch: 9.53 sec]
EPOCH 181/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4474805415789276		[learning rate: 0.0053043]
	Learning Rate: 0.00530434
	LOSS [training: 3.4474805415789276 | validation: 4.149488710809737]
	TIME [epoch: 9.51 sec]
EPOCH 182/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4322843519986557		[learning rate: 0.0052787]
	Learning Rate: 0.00527869
	LOSS [training: 3.4322843519986557 | validation: 3.4192300920639447]
	TIME [epoch: 9.51 sec]
EPOCH 183/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.263043548690587		[learning rate: 0.0052532]
	Learning Rate: 0.00525316
	LOSS [training: 3.263043548690587 | validation: 3.5688305317387803]
	TIME [epoch: 9.52 sec]
EPOCH 184/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2922844391269535		[learning rate: 0.0052278]
	Learning Rate: 0.00522776
	LOSS [training: 3.2922844391269535 | validation: 3.4408800300914617]
	TIME [epoch: 9.52 sec]
EPOCH 185/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.129625358036178		[learning rate: 0.0052025]
	Learning Rate: 0.00520248
	LOSS [training: 3.129625358036178 | validation: 3.3456694412862715]
	TIME [epoch: 9.5 sec]
EPOCH 186/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.116852027739993		[learning rate: 0.0051773]
	Learning Rate: 0.00517732
	LOSS [training: 3.116852027739993 | validation: 3.318601765979235]
	TIME [epoch: 9.5 sec]
EPOCH 187/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1129801433798496		[learning rate: 0.0051523]
	Learning Rate: 0.00515229
	LOSS [training: 3.1129801433798496 | validation: 4.3247909649608465]
	TIME [epoch: 9.52 sec]
EPOCH 188/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.107283018804187		[learning rate: 0.0051274]
	Learning Rate: 0.00512737
	LOSS [training: 4.107283018804187 | validation: 4.203541556554102]
	TIME [epoch: 9.5 sec]
EPOCH 189/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8480072384829214		[learning rate: 0.0051026]
	Learning Rate: 0.00510258
	LOSS [training: 3.8480072384829214 | validation: 3.4796774053237254]
	TIME [epoch: 9.51 sec]
EPOCH 190/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1824749677205295		[learning rate: 0.0050779]
	Learning Rate: 0.0050779
	LOSS [training: 3.1824749677205295 | validation: 3.531397672974129]
	TIME [epoch: 9.52 sec]
EPOCH 191/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1714987886797195		[learning rate: 0.0050533]
	Learning Rate: 0.00505334
	LOSS [training: 3.1714987886797195 | validation: 3.329853436300553]
	TIME [epoch: 9.51 sec]
EPOCH 192/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0731476453146427		[learning rate: 0.0050289]
	Learning Rate: 0.00502891
	LOSS [training: 3.0731476453146427 | validation: 3.3772612688510932]
	TIME [epoch: 9.5 sec]
EPOCH 193/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1183002490932137		[learning rate: 0.0050046]
	Learning Rate: 0.00500459
	LOSS [training: 3.1183002490932137 | validation: 3.150006511184332]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_193.pth
	Model improved!!!
EPOCH 194/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.144722583026366		[learning rate: 0.0049804]
	Learning Rate: 0.00498039
	LOSS [training: 3.144722583026366 | validation: 3.420939452986959]
	TIME [epoch: 9.53 sec]
EPOCH 195/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.086255766657198		[learning rate: 0.0049563]
	Learning Rate: 0.0049563
	LOSS [training: 3.086255766657198 | validation: 3.109963503547424]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_195.pth
	Model improved!!!
EPOCH 196/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0234048313469915		[learning rate: 0.0049323]
	Learning Rate: 0.00493234
	LOSS [training: 3.0234048313469915 | validation: 3.288442543096064]
	TIME [epoch: 9.5 sec]
EPOCH 197/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.001264162154472		[learning rate: 0.0049085]
	Learning Rate: 0.00490848
	LOSS [training: 3.001264162154472 | validation: 3.354668967302487]
	TIME [epoch: 9.52 sec]
EPOCH 198/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0209192962884344		[learning rate: 0.0048847]
	Learning Rate: 0.00488475
	LOSS [training: 3.0209192962884344 | validation: 3.3430393428529532]
	TIME [epoch: 9.51 sec]
EPOCH 199/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.289586731168624		[learning rate: 0.0048611]
	Learning Rate: 0.00486113
	LOSS [training: 4.289586731168624 | validation: 5.114753321110449]
	TIME [epoch: 9.5 sec]
EPOCH 200/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.198343741259757		[learning rate: 0.0048376]
	Learning Rate: 0.00483762
	LOSS [training: 4.198343741259757 | validation: 3.716909541513487]
	TIME [epoch: 9.51 sec]
EPOCH 201/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7380671202117597		[learning rate: 0.0048142]
	Learning Rate: 0.00481422
	LOSS [training: 3.7380671202117597 | validation: 4.071209167170392]
	TIME [epoch: 9.53 sec]
EPOCH 202/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2510034520603583		[learning rate: 0.0047909]
	Learning Rate: 0.00479094
	LOSS [training: 3.2510034520603583 | validation: 3.3380761462791266]
	TIME [epoch: 9.5 sec]
EPOCH 203/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1166587553228773		[learning rate: 0.0047678]
	Learning Rate: 0.00476778
	LOSS [training: 3.1166587553228773 | validation: 3.1201197981764266]
	TIME [epoch: 9.49 sec]
EPOCH 204/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.002246036131787		[learning rate: 0.0047447]
	Learning Rate: 0.00474472
	LOSS [training: 3.002246036131787 | validation: 3.1086396039116604]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_204.pth
	Model improved!!!
EPOCH 205/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0117369727442806		[learning rate: 0.0047218]
	Learning Rate: 0.00472177
	LOSS [training: 3.0117369727442806 | validation: 3.164429003236744]
	TIME [epoch: 9.51 sec]
EPOCH 206/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.10349576359702		[learning rate: 0.0046989]
	Learning Rate: 0.00469894
	LOSS [training: 3.10349576359702 | validation: 3.493439759731168]
	TIME [epoch: 9.5 sec]
EPOCH 207/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.184860414732473		[learning rate: 0.0046762]
	Learning Rate: 0.00467622
	LOSS [training: 3.184860414732473 | validation: 3.2459903598490043]
	TIME [epoch: 9.5 sec]
EPOCH 208/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1963793609759437		[learning rate: 0.0046536]
	Learning Rate: 0.0046536
	LOSS [training: 3.1963793609759437 | validation: 3.3667979429953925]
	TIME [epoch: 9.52 sec]
EPOCH 209/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1218452246541544		[learning rate: 0.0046311]
	Learning Rate: 0.0046311
	LOSS [training: 3.1218452246541544 | validation: 3.1351670166326064]
	TIME [epoch: 9.5 sec]
EPOCH 210/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1393247323874798		[learning rate: 0.0046087]
	Learning Rate: 0.00460871
	LOSS [training: 3.1393247323874798 | validation: 3.340038355933844]
	TIME [epoch: 9.5 sec]
EPOCH 211/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1585855425469154		[learning rate: 0.0045864]
	Learning Rate: 0.00458642
	LOSS [training: 3.1585855425469154 | validation: 3.0772718404894825]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_211.pth
	Model improved!!!
EPOCH 212/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.279282558076653		[learning rate: 0.0045642]
	Learning Rate: 0.00456424
	LOSS [training: 3.279282558076653 | validation: 3.7252211794857595]
	TIME [epoch: 9.51 sec]
EPOCH 213/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2525792366064388		[learning rate: 0.0045422]
	Learning Rate: 0.00454217
	LOSS [training: 3.2525792366064388 | validation: 3.203005763348118]
	TIME [epoch: 9.5 sec]
EPOCH 214/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.170729518160904		[learning rate: 0.0045202]
	Learning Rate: 0.0045202
	LOSS [training: 3.170729518160904 | validation: 3.466382511845921]
	TIME [epoch: 9.52 sec]
EPOCH 215/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0153530785097495		[learning rate: 0.0044983]
	Learning Rate: 0.00449834
	LOSS [training: 3.0153530785097495 | validation: 3.073891589737781]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_215.pth
	Model improved!!!
EPOCH 216/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9240111384482725		[learning rate: 0.0044766]
	Learning Rate: 0.00447659
	LOSS [training: 2.9240111384482725 | validation: 3.151278582185733]
	TIME [epoch: 9.5 sec]
EPOCH 217/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2391418397558676		[learning rate: 0.0044549]
	Learning Rate: 0.00445494
	LOSS [training: 3.2391418397558676 | validation: 4.543246121477663]
	TIME [epoch: 9.8 sec]
EPOCH 218/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.525459247140686		[learning rate: 0.0044334]
	Learning Rate: 0.0044334
	LOSS [training: 4.525459247140686 | validation: 4.505041080169458]
	TIME [epoch: 9.54 sec]
EPOCH 219/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.416188224085991		[learning rate: 0.004412]
	Learning Rate: 0.00441196
	LOSS [training: 3.416188224085991 | validation: 3.3332397775901157]
	TIME [epoch: 9.52 sec]
EPOCH 220/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2623801691807244		[learning rate: 0.0043906]
	Learning Rate: 0.00439062
	LOSS [training: 3.2623801691807244 | validation: 3.2843100498834925]
	TIME [epoch: 9.52 sec]
EPOCH 221/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.213439520909276		[learning rate: 0.0043694]
	Learning Rate: 0.00436939
	LOSS [training: 3.213439520909276 | validation: 3.39702170498168]
	TIME [epoch: 9.53 sec]
EPOCH 222/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5988079571558815		[learning rate: 0.0043483]
	Learning Rate: 0.00434826
	LOSS [training: 3.5988079571558815 | validation: 4.385330078333987]
	TIME [epoch: 9.53 sec]
EPOCH 223/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.718724795448276		[learning rate: 0.0043272]
	Learning Rate: 0.00432724
	LOSS [training: 4.718724795448276 | validation: 5.593567809540537]
	TIME [epoch: 9.52 sec]
EPOCH 224/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.833592388458906		[learning rate: 0.0043063]
	Learning Rate: 0.00430631
	LOSS [training: 4.833592388458906 | validation: 4.4106486953548885]
	TIME [epoch: 9.51 sec]
EPOCH 225/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.999770534560566		[learning rate: 0.0042855]
	Learning Rate: 0.00428549
	LOSS [training: 3.999770534560566 | validation: 4.0602362353077055]
	TIME [epoch: 9.54 sec]
EPOCH 226/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6687585429697087		[learning rate: 0.0042648]
	Learning Rate: 0.00426476
	LOSS [training: 3.6687585429697087 | validation: 3.7142356003081423]
	TIME [epoch: 9.52 sec]
EPOCH 227/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.467498229456755		[learning rate: 0.0042441]
	Learning Rate: 0.00424414
	LOSS [training: 3.467498229456755 | validation: 3.6976254008935174]
	TIME [epoch: 9.51 sec]
EPOCH 228/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3207451858471466		[learning rate: 0.0042236]
	Learning Rate: 0.00422361
	LOSS [training: 3.3207451858471466 | validation: 3.3558934786636785]
	TIME [epoch: 9.52 sec]
EPOCH 229/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2676673967598893		[learning rate: 0.0042032]
	Learning Rate: 0.00420319
	LOSS [training: 3.2676673967598893 | validation: 4.158167713260065]
	TIME [epoch: 9.53 sec]
EPOCH 230/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6300635252606215		[learning rate: 0.0041829]
	Learning Rate: 0.00418286
	LOSS [training: 3.6300635252606215 | validation: 3.3491073383208674]
	TIME [epoch: 9.51 sec]
EPOCH 231/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.33676925343564		[learning rate: 0.0041626]
	Learning Rate: 0.00416264
	LOSS [training: 3.33676925343564 | validation: 3.4074054609641826]
	TIME [epoch: 9.51 sec]
EPOCH 232/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2039463486269653		[learning rate: 0.0041425]
	Learning Rate: 0.00414251
	LOSS [training: 3.2039463486269653 | validation: 3.3292548575354197]
	TIME [epoch: 9.53 sec]
EPOCH 233/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.399757450954252		[learning rate: 0.0041225]
	Learning Rate: 0.00412247
	LOSS [training: 3.399757450954252 | validation: 3.5070171822508667]
	TIME [epoch: 9.51 sec]
EPOCH 234/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2250075735804877		[learning rate: 0.0041025]
	Learning Rate: 0.00410254
	LOSS [training: 3.2250075735804877 | validation: 3.2619024331202082]
	TIME [epoch: 9.51 sec]
EPOCH 235/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.408205527896031		[learning rate: 0.0040827]
	Learning Rate: 0.0040827
	LOSS [training: 3.408205527896031 | validation: 5.377857373214716]
	TIME [epoch: 9.52 sec]
EPOCH 236/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.3067376502050205		[learning rate: 0.004063]
	Learning Rate: 0.00406296
	LOSS [training: 6.3067376502050205 | validation: 6.29153788407725]
	TIME [epoch: 9.53 sec]
EPOCH 237/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.320537807455584		[learning rate: 0.0040433]
	Learning Rate: 0.00404331
	LOSS [training: 5.320537807455584 | validation: 5.196287192299425]
	TIME [epoch: 9.51 sec]
EPOCH 238/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.593339203842624		[learning rate: 0.0040238]
	Learning Rate: 0.00402375
	LOSS [training: 4.593339203842624 | validation: 3.895233853956928]
	TIME [epoch: 9.51 sec]
EPOCH 239/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6331142074161646		[learning rate: 0.0040043]
	Learning Rate: 0.0040043
	LOSS [training: 3.6331142074161646 | validation: 3.4820322481331347]
	TIME [epoch: 9.54 sec]
EPOCH 240/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.1437494298671345		[learning rate: 0.0039849]
	Learning Rate: 0.00398493
	LOSS [training: 4.1437494298671345 | validation: 4.842320666461053]
	TIME [epoch: 9.51 sec]
EPOCH 241/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.580143427314211		[learning rate: 0.0039657]
	Learning Rate: 0.00396566
	LOSS [training: 4.580143427314211 | validation: 4.265955943560295]
	TIME [epoch: 9.51 sec]
EPOCH 242/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.477752775465022		[learning rate: 0.0039465]
	Learning Rate: 0.00394649
	LOSS [training: 3.477752775465022 | validation: 3.769725688603983]
	TIME [epoch: 9.52 sec]
EPOCH 243/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4425902004918627		[learning rate: 0.0039274]
	Learning Rate: 0.0039274
	LOSS [training: 3.4425902004918627 | validation: 3.8321778019980424]
	TIME [epoch: 9.52 sec]
EPOCH 244/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.360112378255264		[learning rate: 0.0039084]
	Learning Rate: 0.00390841
	LOSS [training: 3.360112378255264 | validation: 3.855091851546918]
	TIME [epoch: 9.51 sec]
EPOCH 245/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3338574999715016		[learning rate: 0.0038895]
	Learning Rate: 0.00388951
	LOSS [training: 3.3338574999715016 | validation: 3.167686366162769]
	TIME [epoch: 9.51 sec]
EPOCH 246/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.070705465024372		[learning rate: 0.0038707]
	Learning Rate: 0.0038707
	LOSS [training: 3.070705465024372 | validation: 3.3809903832139185]
	TIME [epoch: 9.54 sec]
EPOCH 247/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.05498048984633		[learning rate: 0.003852]
	Learning Rate: 0.00385198
	LOSS [training: 3.05498048984633 | validation: 3.130959892518975]
	TIME [epoch: 9.51 sec]
EPOCH 248/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.07892830672197		[learning rate: 0.0038334]
	Learning Rate: 0.00383335
	LOSS [training: 3.07892830672197 | validation: 3.1019861522867846]
	TIME [epoch: 9.51 sec]
EPOCH 249/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1173104150396016		[learning rate: 0.0038148]
	Learning Rate: 0.00381482
	LOSS [training: 3.1173104150396016 | validation: 3.2763863023492354]
	TIME [epoch: 9.52 sec]
EPOCH 250/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6242042181214806		[learning rate: 0.0037964]
	Learning Rate: 0.00379637
	LOSS [training: 3.6242042181214806 | validation: 3.9582001675699985]
	TIME [epoch: 9.52 sec]
EPOCH 251/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.259554227963937		[learning rate: 0.003778]
	Learning Rate: 0.00377801
	LOSS [training: 4.259554227963937 | validation: 5.549063345334191]
	TIME [epoch: 9.51 sec]
EPOCH 252/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.190470638594055		[learning rate: 0.0037597]
	Learning Rate: 0.00375974
	LOSS [training: 5.190470638594055 | validation: 4.692946453525695]
	TIME [epoch: 9.51 sec]
EPOCH 253/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.18291611241591		[learning rate: 0.0037416]
	Learning Rate: 0.00374156
	LOSS [training: 4.18291611241591 | validation: 4.024893241700876]
	TIME [epoch: 9.54 sec]
EPOCH 254/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.502891795901415		[learning rate: 0.0037235]
	Learning Rate: 0.00372347
	LOSS [training: 3.502891795901415 | validation: 3.418310335069857]
	TIME [epoch: 9.51 sec]
EPOCH 255/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.414530832686684		[learning rate: 0.0037055]
	Learning Rate: 0.00370546
	LOSS [training: 3.414530832686684 | validation: 3.5506646375040023]
	TIME [epoch: 9.51 sec]
EPOCH 256/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2545620815012724		[learning rate: 0.0036875]
	Learning Rate: 0.00368754
	LOSS [training: 3.2545620815012724 | validation: 3.2442496537948844]
	TIME [epoch: 9.53 sec]
EPOCH 257/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4320806151618655		[learning rate: 0.0036697]
	Learning Rate: 0.00366971
	LOSS [training: 3.4320806151618655 | validation: 3.3973706645346455]
	TIME [epoch: 9.52 sec]
EPOCH 258/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4254657274078513		[learning rate: 0.003652]
	Learning Rate: 0.00365196
	LOSS [training: 3.4254657274078513 | validation: 3.6295889883173094]
	TIME [epoch: 9.52 sec]
EPOCH 259/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2775255419561886		[learning rate: 0.0036343]
	Learning Rate: 0.0036343
	LOSS [training: 3.2775255419561886 | validation: 3.3064229479886587]
	TIME [epoch: 9.51 sec]
EPOCH 260/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0916246967027035		[learning rate: 0.0036167]
	Learning Rate: 0.00361673
	LOSS [training: 3.0916246967027035 | validation: 3.2216695546609526]
	TIME [epoch: 9.54 sec]
EPOCH 261/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.728387942134689		[learning rate: 0.0035992]
	Learning Rate: 0.00359924
	LOSS [training: 3.728387942134689 | validation: 3.234488856492803]
	TIME [epoch: 9.51 sec]
EPOCH 262/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3886705370745096		[learning rate: 0.0035818]
	Learning Rate: 0.00358183
	LOSS [training: 3.3886705370745096 | validation: 3.9091470674189415]
	TIME [epoch: 9.52 sec]
EPOCH 263/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6670928285168465		[learning rate: 0.0035645]
	Learning Rate: 0.00356451
	LOSS [training: 3.6670928285168465 | validation: 3.2374540989145792]
	TIME [epoch: 9.53 sec]
EPOCH 264/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0629724049130322		[learning rate: 0.0035473]
	Learning Rate: 0.00354727
	LOSS [training: 3.0629724049130322 | validation: 3.103691779144335]
	TIME [epoch: 9.51 sec]
EPOCH 265/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.83826910220509		[learning rate: 0.0035301]
	Learning Rate: 0.00353012
	LOSS [training: 2.83826910220509 | validation: 3.2900649038767438]
	TIME [epoch: 9.51 sec]
EPOCH 266/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1576463884562638		[learning rate: 0.003513]
	Learning Rate: 0.00351305
	LOSS [training: 3.1576463884562638 | validation: 3.270101045254004]
	TIME [epoch: 9.51 sec]
EPOCH 267/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0958525793508365		[learning rate: 0.0034961]
	Learning Rate: 0.00349606
	LOSS [training: 3.0958525793508365 | validation: 3.2392493320100915]
	TIME [epoch: 9.54 sec]
EPOCH 268/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0256858250418674		[learning rate: 0.0034792]
	Learning Rate: 0.00347915
	LOSS [training: 3.0256858250418674 | validation: 4.015271615084494]
	TIME [epoch: 9.51 sec]
EPOCH 269/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.083728204401707		[learning rate: 0.0034623]
	Learning Rate: 0.00346233
	LOSS [training: 4.083728204401707 | validation: 4.2317350043115765]
	TIME [epoch: 9.51 sec]
EPOCH 270/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.051228911162661		[learning rate: 0.0034456]
	Learning Rate: 0.00344559
	LOSS [training: 5.051228911162661 | validation: 6.240795773291514]
	TIME [epoch: 9.53 sec]
EPOCH 271/1000:
	Training over batches...
		[batch 5/5] avg loss: 6.093092290649464		[learning rate: 0.0034289]
	Learning Rate: 0.00342892
	LOSS [training: 6.093092290649464 | validation: 6.064624221683954]
	TIME [epoch: 9.52 sec]
EPOCH 272/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.0054204538038904		[learning rate: 0.0034123]
	Learning Rate: 0.00341234
	LOSS [training: 5.0054204538038904 | validation: 4.037614487824113]
	TIME [epoch: 9.52 sec]
EPOCH 273/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2814010234643356		[learning rate: 0.0033958]
	Learning Rate: 0.00339584
	LOSS [training: 3.2814010234643356 | validation: 3.233847148751442]
	TIME [epoch: 9.51 sec]
EPOCH 274/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0635725928294253		[learning rate: 0.0033794]
	Learning Rate: 0.00337942
	LOSS [training: 3.0635725928294253 | validation: 3.3026802421766]
	TIME [epoch: 9.54 sec]
EPOCH 275/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.41568197615165		[learning rate: 0.0033631]
	Learning Rate: 0.00336308
	LOSS [training: 4.41568197615165 | validation: 4.342817952654197]
	TIME [epoch: 9.52 sec]
EPOCH 276/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6526331376716046		[learning rate: 0.0033468]
	Learning Rate: 0.00334681
	LOSS [training: 3.6526331376716046 | validation: 3.747872475102188]
	TIME [epoch: 9.51 sec]
EPOCH 277/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6491669433386553		[learning rate: 0.0033306]
	Learning Rate: 0.00333063
	LOSS [training: 3.6491669433386553 | validation: 3.352730250556431]
	TIME [epoch: 9.54 sec]
EPOCH 278/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1315331967591526		[learning rate: 0.0033145]
	Learning Rate: 0.00331452
	LOSS [training: 3.1315331967591526 | validation: 3.1068882411656853]
	TIME [epoch: 9.52 sec]
EPOCH 279/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.383634897673344		[learning rate: 0.0032985]
	Learning Rate: 0.00329849
	LOSS [training: 3.383634897673344 | validation: 3.0079587774715173]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_279.pth
	Model improved!!!
EPOCH 280/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.028947005750779		[learning rate: 0.0032825]
	Learning Rate: 0.00328254
	LOSS [training: 3.028947005750779 | validation: 3.485682034632078]
	TIME [epoch: 9.51 sec]
EPOCH 281/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1154916524481573		[learning rate: 0.0032667]
	Learning Rate: 0.00326667
	LOSS [training: 3.1154916524481573 | validation: 3.5537800051296684]
	TIME [epoch: 9.53 sec]
EPOCH 282/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9252832437454415		[learning rate: 0.0032509]
	Learning Rate: 0.00325087
	LOSS [training: 3.9252832437454415 | validation: 3.6837442092209685]
	TIME [epoch: 9.51 sec]
EPOCH 283/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.311254578262555		[learning rate: 0.0032352]
	Learning Rate: 0.00323515
	LOSS [training: 3.311254578262555 | validation: 3.1298186145399995]
	TIME [epoch: 9.51 sec]
EPOCH 284/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0673041741557876		[learning rate: 0.0032195]
	Learning Rate: 0.00321951
	LOSS [training: 3.0673041741557876 | validation: 2.9813319250005077]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_284.pth
	Model improved!!!
EPOCH 285/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9468166075192426		[learning rate: 0.0032039]
	Learning Rate: 0.00320394
	LOSS [training: 2.9468166075192426 | validation: 3.8172347737112227]
	TIME [epoch: 9.51 sec]
EPOCH 286/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.657409697890902		[learning rate: 0.0031884]
	Learning Rate: 0.00318845
	LOSS [training: 3.657409697890902 | validation: 4.605568415323314]
	TIME [epoch: 9.51 sec]
EPOCH 287/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.834215389711189		[learning rate: 0.003173]
	Learning Rate: 0.00317303
	LOSS [training: 3.834215389711189 | validation: 3.142599968522916]
	TIME [epoch: 9.51 sec]
EPOCH 288/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8873142773205442		[learning rate: 0.0031577]
	Learning Rate: 0.00315768
	LOSS [training: 2.8873142773205442 | validation: 3.1071486670814377]
	TIME [epoch: 9.53 sec]
EPOCH 289/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9168464707864876		[learning rate: 0.0031424]
	Learning Rate: 0.00314241
	LOSS [training: 2.9168464707864876 | validation: 3.0079341245277895]
	TIME [epoch: 9.51 sec]
EPOCH 290/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.170642045715021		[learning rate: 0.0031272]
	Learning Rate: 0.00312722
	LOSS [training: 3.170642045715021 | validation: 3.3167443882711813]
	TIME [epoch: 9.52 sec]
EPOCH 291/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0870728707466304		[learning rate: 0.0031121]
	Learning Rate: 0.00311209
	LOSS [training: 3.0870728707466304 | validation: 3.039027026117966]
	TIME [epoch: 9.53 sec]
EPOCH 292/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1352727763475006		[learning rate: 0.003097]
	Learning Rate: 0.00309704
	LOSS [training: 3.1352727763475006 | validation: 3.763334882797982]
	TIME [epoch: 9.51 sec]
EPOCH 293/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3549420514298207		[learning rate: 0.0030821]
	Learning Rate: 0.00308207
	LOSS [training: 3.3549420514298207 | validation: 2.913093231914]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_293.pth
	Model improved!!!
EPOCH 294/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9858824546712475		[learning rate: 0.0030672]
	Learning Rate: 0.00306716
	LOSS [training: 2.9858824546712475 | validation: 3.564720807836032]
	TIME [epoch: 9.52 sec]
EPOCH 295/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.415938296211594		[learning rate: 0.0030523]
	Learning Rate: 0.00305233
	LOSS [training: 3.415938296211594 | validation: 3.156262758186776]
	TIME [epoch: 9.52 sec]
EPOCH 296/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.36131652308604		[learning rate: 0.0030376]
	Learning Rate: 0.00303757
	LOSS [training: 3.36131652308604 | validation: 4.06389605639489]
	TIME [epoch: 9.5 sec]
EPOCH 297/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.623419760028996		[learning rate: 0.0030229]
	Learning Rate: 0.00302288
	LOSS [training: 3.623419760028996 | validation: 3.3487771409032328]
	TIME [epoch: 9.5 sec]
EPOCH 298/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1676309026524616		[learning rate: 0.0030083]
	Learning Rate: 0.00300826
	LOSS [training: 3.1676309026524616 | validation: 3.226601600126098]
	TIME [epoch: 9.52 sec]
EPOCH 299/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.959308471354416		[learning rate: 0.0029937]
	Learning Rate: 0.00299372
	LOSS [training: 2.959308471354416 | validation: 3.0114383734967727]
	TIME [epoch: 9.51 sec]
EPOCH 300/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0751105538569825		[learning rate: 0.0029792]
	Learning Rate: 0.00297924
	LOSS [training: 3.0751105538569825 | validation: 3.3427446053388854]
	TIME [epoch: 9.51 sec]
EPOCH 301/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.27960870429971		[learning rate: 0.0029648]
	Learning Rate: 0.00296483
	LOSS [training: 3.27960870429971 | validation: 3.42246912015406]
	TIME [epoch: 9.51 sec]
EPOCH 302/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5383464580268615		[learning rate: 0.0029505]
	Learning Rate: 0.00295049
	LOSS [training: 3.5383464580268615 | validation: 4.952624838436846]
	TIME [epoch: 9.53 sec]
EPOCH 303/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.374179508370422		[learning rate: 0.0029362]
	Learning Rate: 0.00293623
	LOSS [training: 5.374179508370422 | validation: 5.83588598696708]
	TIME [epoch: 9.51 sec]
EPOCH 304/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.465692966452613		[learning rate: 0.002922]
	Learning Rate: 0.00292203
	LOSS [training: 5.465692966452613 | validation: 5.911971674847402]
	TIME [epoch: 9.5 sec]
EPOCH 305/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.530204585626001		[learning rate: 0.0029079]
	Learning Rate: 0.0029079
	LOSS [training: 5.530204585626001 | validation: 5.267294640269301]
	TIME [epoch: 9.53 sec]
EPOCH 306/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.319652686534365		[learning rate: 0.0028938]
	Learning Rate: 0.00289383
	LOSS [training: 4.319652686534365 | validation: 4.040428935284133]
	TIME [epoch: 9.51 sec]
EPOCH 307/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.688135076329197		[learning rate: 0.0028798]
	Learning Rate: 0.00287984
	LOSS [training: 3.688135076329197 | validation: 3.682876816937918]
	TIME [epoch: 9.51 sec]
EPOCH 308/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4239196777597947		[learning rate: 0.0028659]
	Learning Rate: 0.00286591
	LOSS [training: 3.4239196777597947 | validation: 3.345381128305645]
	TIME [epoch: 9.51 sec]
EPOCH 309/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2390260716543287		[learning rate: 0.0028521]
	Learning Rate: 0.00285205
	LOSS [training: 3.2390260716543287 | validation: 3.3171952057356853]
	TIME [epoch: 9.53 sec]
EPOCH 310/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1418988661139715		[learning rate: 0.0028383]
	Learning Rate: 0.00283826
	LOSS [training: 3.1418988661139715 | validation: 3.19286317327255]
	TIME [epoch: 9.52 sec]
EPOCH 311/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1594134684396225		[learning rate: 0.0028245]
	Learning Rate: 0.00282454
	LOSS [training: 3.1594134684396225 | validation: 3.503188264407396]
	TIME [epoch: 9.51 sec]
EPOCH 312/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.413669819852933		[learning rate: 0.0028109]
	Learning Rate: 0.00281088
	LOSS [training: 3.413669819852933 | validation: 4.118180975371632]
	TIME [epoch: 9.53 sec]
EPOCH 313/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.16168466715929		[learning rate: 0.0027973]
	Learning Rate: 0.00279729
	LOSS [training: 4.16168466715929 | validation: 4.483908915581828]
	TIME [epoch: 9.52 sec]
EPOCH 314/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.510471753165649		[learning rate: 0.0027838]
	Learning Rate: 0.00278376
	LOSS [training: 4.510471753165649 | validation: 4.621904494572937]
	TIME [epoch: 9.51 sec]
EPOCH 315/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.2329272975516945		[learning rate: 0.0027703]
	Learning Rate: 0.0027703
	LOSS [training: 4.2329272975516945 | validation: 3.8187694636924867]
	TIME [epoch: 9.52 sec]
EPOCH 316/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3449888840032456		[learning rate: 0.0027569]
	Learning Rate: 0.0027569
	LOSS [training: 3.3449888840032456 | validation: 3.5677941662941146]
	TIME [epoch: 9.53 sec]
EPOCH 317/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.253481300247367		[learning rate: 0.0027436]
	Learning Rate: 0.00274357
	LOSS [training: 4.253481300247367 | validation: 5.020491244545122]
	TIME [epoch: 9.51 sec]
EPOCH 318/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.432663291712249		[learning rate: 0.0027303]
	Learning Rate: 0.0027303
	LOSS [training: 4.432663291712249 | validation: 3.7381828933505576]
	TIME [epoch: 9.51 sec]
EPOCH 319/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3659991293914073		[learning rate: 0.0027171]
	Learning Rate: 0.0027171
	LOSS [training: 3.3659991293914073 | validation: 3.640500091898256]
	TIME [epoch: 9.53 sec]
EPOCH 320/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.679049932248097		[learning rate: 0.002704]
	Learning Rate: 0.00270396
	LOSS [training: 3.679049932248097 | validation: 3.355119453822734]
	TIME [epoch: 9.51 sec]
EPOCH 321/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.173214959165251		[learning rate: 0.0026909]
	Learning Rate: 0.00269088
	LOSS [training: 3.173214959165251 | validation: 3.1937844152519936]
	TIME [epoch: 9.51 sec]
EPOCH 322/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8214359322190297		[learning rate: 0.0026779]
	Learning Rate: 0.00267787
	LOSS [training: 3.8214359322190297 | validation: 3.9143335996116035]
	TIME [epoch: 9.52 sec]
EPOCH 323/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0404865985225005		[learning rate: 0.0026649]
	Learning Rate: 0.00266492
	LOSS [training: 4.0404865985225005 | validation: 3.6816808316407794]
	TIME [epoch: 9.52 sec]
EPOCH 324/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3267942330729063		[learning rate: 0.002652]
	Learning Rate: 0.00265203
	LOSS [training: 3.3267942330729063 | validation: 3.1486087404144225]
	TIME [epoch: 9.51 sec]
EPOCH 325/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.122520718181181		[learning rate: 0.0026392]
	Learning Rate: 0.00263921
	LOSS [training: 3.122520718181181 | validation: 3.2197001860514693]
	TIME [epoch: 9.5 sec]
EPOCH 326/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.016088982440656		[learning rate: 0.0026264]
	Learning Rate: 0.00262645
	LOSS [training: 3.016088982440656 | validation: 2.9312789802440613]
	TIME [epoch: 9.54 sec]
EPOCH 327/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8967089220409736		[learning rate: 0.0026137]
	Learning Rate: 0.00261374
	LOSS [training: 2.8967089220409736 | validation: 3.000196629743381]
	TIME [epoch: 9.51 sec]
EPOCH 328/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0751584477626865		[learning rate: 0.0026011]
	Learning Rate: 0.00260111
	LOSS [training: 3.0751584477626865 | validation: 3.26733677333463]
	TIME [epoch: 9.5 sec]
EPOCH 329/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.073902345120873		[learning rate: 0.0025885]
	Learning Rate: 0.00258853
	LOSS [training: 3.073902345120873 | validation: 2.9748679354504395]
	TIME [epoch: 9.52 sec]
EPOCH 330/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.003016099963939		[learning rate: 0.002576]
	Learning Rate: 0.00257601
	LOSS [training: 3.003016099963939 | validation: 3.00806558286268]
	TIME [epoch: 9.52 sec]
EPOCH 331/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9086053262745235		[learning rate: 0.0025636]
	Learning Rate: 0.00256355
	LOSS [training: 2.9086053262745235 | validation: 3.169388538245255]
	TIME [epoch: 9.51 sec]
EPOCH 332/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.023903192998641		[learning rate: 0.0025512]
	Learning Rate: 0.00255115
	LOSS [training: 3.023903192998641 | validation: 3.225724094781065]
	TIME [epoch: 9.51 sec]
EPOCH 333/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.132559828874716		[learning rate: 0.0025388]
	Learning Rate: 0.00253882
	LOSS [training: 3.132559828874716 | validation: 3.2676592649986267]
	TIME [epoch: 9.53 sec]
EPOCH 334/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0255585009432178		[learning rate: 0.0025265]
	Learning Rate: 0.00252654
	LOSS [training: 3.0255585009432178 | validation: 2.962770043592292]
	TIME [epoch: 9.51 sec]
EPOCH 335/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.904181278334766		[learning rate: 0.0025143]
	Learning Rate: 0.00251432
	LOSS [training: 2.904181278334766 | validation: 3.0699570871539983]
	TIME [epoch: 9.51 sec]
EPOCH 336/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9390377140215733		[learning rate: 0.0025022]
	Learning Rate: 0.00250216
	LOSS [training: 2.9390377140215733 | validation: 3.1098511216254336]
	TIME [epoch: 9.52 sec]
EPOCH 337/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3900308759072075		[learning rate: 0.0024901]
	Learning Rate: 0.00249006
	LOSS [training: 3.3900308759072075 | validation: 4.213979666770423]
	TIME [epoch: 9.52 sec]
EPOCH 338/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.911715502927607		[learning rate: 0.002478]
	Learning Rate: 0.00247802
	LOSS [training: 3.911715502927607 | validation: 4.016684244649296]
	TIME [epoch: 9.5 sec]
EPOCH 339/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7194570782558616		[learning rate: 0.002466]
	Learning Rate: 0.00246604
	LOSS [training: 3.7194570782558616 | validation: 4.1960407825125206]
	TIME [epoch: 9.5 sec]
EPOCH 340/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.827269984954807		[learning rate: 0.0024541]
	Learning Rate: 0.00245411
	LOSS [training: 3.827269984954807 | validation: 4.953387251075133]
	TIME [epoch: 9.53 sec]
EPOCH 341/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.700416690278687		[learning rate: 0.0024422]
	Learning Rate: 0.00244225
	LOSS [training: 4.700416690278687 | validation: 4.777420621044796]
	TIME [epoch: 9.5 sec]
EPOCH 342/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.343066962731976		[learning rate: 0.0024304]
	Learning Rate: 0.00243044
	LOSS [training: 4.343066962731976 | validation: 4.184922191212882]
	TIME [epoch: 9.5 sec]
EPOCH 343/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.752669491894239		[learning rate: 0.0024187]
	Learning Rate: 0.00241868
	LOSS [training: 3.752669491894239 | validation: 3.875915177739843]
	TIME [epoch: 9.52 sec]
EPOCH 344/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.422463765577767		[learning rate: 0.002407]
	Learning Rate: 0.00240699
	LOSS [training: 3.422463765577767 | validation: 3.564968190174688]
	TIME [epoch: 9.51 sec]
EPOCH 345/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3287484692748763		[learning rate: 0.0023953]
	Learning Rate: 0.00239535
	LOSS [training: 3.3287484692748763 | validation: 3.449702271197438]
	TIME [epoch: 9.51 sec]
EPOCH 346/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1508631268308895		[learning rate: 0.0023838]
	Learning Rate: 0.00238376
	LOSS [training: 3.1508631268308895 | validation: 3.268511483798365]
	TIME [epoch: 9.51 sec]
EPOCH 347/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0917160424077332		[learning rate: 0.0023722]
	Learning Rate: 0.00237224
	LOSS [training: 3.0917160424077332 | validation: 3.264319494303876]
	TIME [epoch: 9.53 sec]
EPOCH 348/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0709693270489424		[learning rate: 0.0023608]
	Learning Rate: 0.00236076
	LOSS [training: 3.0709693270489424 | validation: 3.6417275624075263]
	TIME [epoch: 9.51 sec]
EPOCH 349/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3797996003204176		[learning rate: 0.0023493]
	Learning Rate: 0.00234935
	LOSS [training: 3.3797996003204176 | validation: 3.4346755618600424]
	TIME [epoch: 9.51 sec]
EPOCH 350/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2363964169489456		[learning rate: 0.002338]
	Learning Rate: 0.00233799
	LOSS [training: 3.2363964169489456 | validation: 3.5934918374292546]
	TIME [epoch: 9.53 sec]
EPOCH 351/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2377705736422913		[learning rate: 0.0023267]
	Learning Rate: 0.00232668
	LOSS [training: 3.2377705736422913 | validation: 3.3417717587967037]
	TIME [epoch: 9.51 sec]
EPOCH 352/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1087556054060568		[learning rate: 0.0023154]
	Learning Rate: 0.00231543
	LOSS [training: 3.1087556054060568 | validation: 3.3385101717995553]
	TIME [epoch: 9.51 sec]
EPOCH 353/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.006886542566858		[learning rate: 0.0023042]
	Learning Rate: 0.00230423
	LOSS [training: 3.006886542566858 | validation: 3.2433695350021203]
	TIME [epoch: 9.51 sec]
EPOCH 354/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.968477787065951		[learning rate: 0.0022931]
	Learning Rate: 0.00229309
	LOSS [training: 2.968477787065951 | validation: 3.1555238074424916]
	TIME [epoch: 9.53 sec]
EPOCH 355/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.933655568631817		[learning rate: 0.002282]
	Learning Rate: 0.002282
	LOSS [training: 2.933655568631817 | validation: 3.323316182077308]
	TIME [epoch: 9.5 sec]
EPOCH 356/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.994555382059405		[learning rate: 0.002271]
	Learning Rate: 0.00227097
	LOSS [training: 2.994555382059405 | validation: 3.3011505056347246]
	TIME [epoch: 9.51 sec]
EPOCH 357/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3285168997335477		[learning rate: 0.00226]
	Learning Rate: 0.00225998
	LOSS [training: 3.3285168997335477 | validation: 3.522757406438121]
	TIME [epoch: 9.52 sec]
EPOCH 358/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2196482266502797		[learning rate: 0.0022491]
	Learning Rate: 0.00224905
	LOSS [training: 3.2196482266502797 | validation: 3.3509341923776548]
	TIME [epoch: 9.52 sec]
EPOCH 359/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.01276367810893		[learning rate: 0.0022382]
	Learning Rate: 0.00223818
	LOSS [training: 3.01276367810893 | validation: 3.2542572139360613]
	TIME [epoch: 9.51 sec]
EPOCH 360/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1032596616024284		[learning rate: 0.0022274]
	Learning Rate: 0.00222736
	LOSS [training: 3.1032596616024284 | validation: 3.26240980903896]
	TIME [epoch: 9.51 sec]
EPOCH 361/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0526719660707125		[learning rate: 0.0022166]
	Learning Rate: 0.00221658
	LOSS [training: 3.0526719660707125 | validation: 3.201945370083969]
	TIME [epoch: 9.53 sec]
EPOCH 362/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9575079891367446		[learning rate: 0.0022059]
	Learning Rate: 0.00220586
	LOSS [training: 2.9575079891367446 | validation: 3.2160829914640385]
	TIME [epoch: 9.51 sec]
EPOCH 363/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9801555223227734		[learning rate: 0.0021952]
	Learning Rate: 0.0021952
	LOSS [training: 2.9801555223227734 | validation: 3.2099643221200838]
	TIME [epoch: 9.51 sec]
EPOCH 364/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.94861001000966		[learning rate: 0.0021846]
	Learning Rate: 0.00218458
	LOSS [training: 2.94861001000966 | validation: 3.3755032418322344]
	TIME [epoch: 9.53 sec]
EPOCH 365/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9944574522763796		[learning rate: 0.002174]
	Learning Rate: 0.00217402
	LOSS [training: 2.9944574522763796 | validation: 3.322393703013519]
	TIME [epoch: 9.51 sec]
EPOCH 366/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1941556854377895		[learning rate: 0.0021635]
	Learning Rate: 0.0021635
	LOSS [training: 3.1941556854377895 | validation: 3.5784119752761843]
	TIME [epoch: 9.5 sec]
EPOCH 367/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2081519208518983		[learning rate: 0.002153]
	Learning Rate: 0.00215304
	LOSS [training: 3.2081519208518983 | validation: 3.445647777595561]
	TIME [epoch: 9.51 sec]
EPOCH 368/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0450606540014507		[learning rate: 0.0021426]
	Learning Rate: 0.00214263
	LOSS [training: 3.0450606540014507 | validation: 3.1779637890642434]
	TIME [epoch: 9.53 sec]
EPOCH 369/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.045580974867008		[learning rate: 0.0021323]
	Learning Rate: 0.00213227
	LOSS [training: 3.045580974867008 | validation: 3.430758934288532]
	TIME [epoch: 9.51 sec]
EPOCH 370/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1806390425620967		[learning rate: 0.002122]
	Learning Rate: 0.00212196
	LOSS [training: 3.1806390425620967 | validation: 3.358713007103465]
	TIME [epoch: 9.51 sec]
EPOCH 371/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0708703660629846		[learning rate: 0.0021117]
	Learning Rate: 0.0021117
	LOSS [training: 3.0708703660629846 | validation: 3.338079513840154]
	TIME [epoch: 9.53 sec]
EPOCH 372/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0167468665007813		[learning rate: 0.0021015]
	Learning Rate: 0.00210149
	LOSS [training: 3.0167468665007813 | validation: 3.2792300027437857]
	TIME [epoch: 9.52 sec]
EPOCH 373/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0881530269633037		[learning rate: 0.0020913]
	Learning Rate: 0.00209132
	LOSS [training: 3.0881530269633037 | validation: 3.331413788346489]
	TIME [epoch: 9.51 sec]
EPOCH 374/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0889908674968933		[learning rate: 0.0020812]
	Learning Rate: 0.00208121
	LOSS [training: 3.0889908674968933 | validation: 3.281082792662417]
	TIME [epoch: 9.51 sec]
EPOCH 375/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.041297853206635		[learning rate: 0.0020711]
	Learning Rate: 0.00207115
	LOSS [training: 3.041297853206635 | validation: 3.515435431213206]
	TIME [epoch: 9.53 sec]
EPOCH 376/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0751426032132714		[learning rate: 0.0020611]
	Learning Rate: 0.00206113
	LOSS [training: 3.0751426032132714 | validation: 3.2282876822854747]
	TIME [epoch: 9.51 sec]
EPOCH 377/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.980180686891526		[learning rate: 0.0020512]
	Learning Rate: 0.00205116
	LOSS [training: 2.980180686891526 | validation: 3.3050100762650847]
	TIME [epoch: 9.51 sec]
EPOCH 378/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.147669929056206		[learning rate: 0.0020412]
	Learning Rate: 0.00204124
	LOSS [training: 3.147669929056206 | validation: 3.233375714906221]
	TIME [epoch: 9.53 sec]
EPOCH 379/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9360133217569766		[learning rate: 0.0020314]
	Learning Rate: 0.00203137
	LOSS [training: 2.9360133217569766 | validation: 3.096600791722911]
	TIME [epoch: 9.52 sec]
EPOCH 380/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.861937472059922		[learning rate: 0.0020215]
	Learning Rate: 0.00202155
	LOSS [training: 2.861937472059922 | validation: 3.1948189935600806]
	TIME [epoch: 9.5 sec]
EPOCH 381/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8315271001113116		[learning rate: 0.0020118]
	Learning Rate: 0.00201177
	LOSS [training: 2.8315271001113116 | validation: 3.193412963066784]
	TIME [epoch: 9.51 sec]
EPOCH 382/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.914694931793309		[learning rate: 0.002002]
	Learning Rate: 0.00200204
	LOSS [training: 2.914694931793309 | validation: 3.3218203053894126]
	TIME [epoch: 9.52 sec]
EPOCH 383/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0827961757771667		[learning rate: 0.0019924]
	Learning Rate: 0.00199236
	LOSS [training: 3.0827961757771667 | validation: 3.1930333669296616]
	TIME [epoch: 9.5 sec]
EPOCH 384/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.851002355333915		[learning rate: 0.0019827]
	Learning Rate: 0.00198273
	LOSS [training: 2.851002355333915 | validation: 3.193243459938028]
	TIME [epoch: 9.5 sec]
EPOCH 385/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.950200846120362		[learning rate: 0.0019731]
	Learning Rate: 0.00197314
	LOSS [training: 2.950200846120362 | validation: 3.724588367826015]
	TIME [epoch: 9.54 sec]
EPOCH 386/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.400129925666647		[learning rate: 0.0019636]
	Learning Rate: 0.0019636
	LOSS [training: 3.400129925666647 | validation: 3.8428016377258287]
	TIME [epoch: 9.52 sec]
EPOCH 387/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.823683297707144		[learning rate: 0.0019541]
	Learning Rate: 0.0019541
	LOSS [training: 3.823683297707144 | validation: 4.2244954234679435]
	TIME [epoch: 9.51 sec]
EPOCH 388/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0149481623668235		[learning rate: 0.0019447]
	Learning Rate: 0.00194465
	LOSS [training: 4.0149481623668235 | validation: 3.9680843196205684]
	TIME [epoch: 9.51 sec]
EPOCH 389/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.8207353148505256		[learning rate: 0.0019352]
	Learning Rate: 0.00193525
	LOSS [training: 3.8207353148505256 | validation: 3.516741642430146]
	TIME [epoch: 9.53 sec]
EPOCH 390/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.289429013173782		[learning rate: 0.0019259]
	Learning Rate: 0.00192589
	LOSS [training: 3.289429013173782 | validation: 3.170552999662608]
	TIME [epoch: 9.5 sec]
EPOCH 391/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9653040414748184		[learning rate: 0.0019166]
	Learning Rate: 0.00191658
	LOSS [training: 2.9653040414748184 | validation: 3.1206591251220925]
	TIME [epoch: 9.5 sec]
EPOCH 392/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.876492128344476		[learning rate: 0.0019073]
	Learning Rate: 0.00190731
	LOSS [training: 2.876492128344476 | validation: 3.250866563822532]
	TIME [epoch: 9.53 sec]
EPOCH 393/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9244045648385173		[learning rate: 0.0018981]
	Learning Rate: 0.00189809
	LOSS [training: 2.9244045648385173 | validation: 3.1849601475562817]
	TIME [epoch: 9.5 sec]
EPOCH 394/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1064837465325748		[learning rate: 0.0018889]
	Learning Rate: 0.00188891
	LOSS [training: 3.1064837465325748 | validation: 4.269937208155908]
	TIME [epoch: 9.51 sec]
EPOCH 395/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9663140539625266		[learning rate: 0.0018798]
	Learning Rate: 0.00187977
	LOSS [training: 3.9663140539625266 | validation: 3.888911742151685]
	TIME [epoch: 9.51 sec]
EPOCH 396/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2848784789140275		[learning rate: 0.0018707]
	Learning Rate: 0.00187068
	LOSS [training: 3.2848784789140275 | validation: 3.532256276216523]
	TIME [epoch: 9.52 sec]
EPOCH 397/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0110275233138024		[learning rate: 0.0018616]
	Learning Rate: 0.00186164
	LOSS [training: 3.0110275233138024 | validation: 3.518632937399334]
	TIME [epoch: 9.51 sec]
EPOCH 398/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.299907050259924		[learning rate: 0.0018526]
	Learning Rate: 0.00185263
	LOSS [training: 3.299907050259924 | validation: 3.2477522577411633]
	TIME [epoch: 9.5 sec]
EPOCH 399/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0540389812744997		[learning rate: 0.0018437]
	Learning Rate: 0.00184367
	LOSS [training: 3.0540389812744997 | validation: 3.5796181821139115]
	TIME [epoch: 9.53 sec]
EPOCH 400/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.6520848667190675		[learning rate: 0.0018348]
	Learning Rate: 0.00183476
	LOSS [training: 3.6520848667190675 | validation: 4.375046292979587]
	TIME [epoch: 9.51 sec]
EPOCH 401/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.672964557284634		[learning rate: 0.0018259]
	Learning Rate: 0.00182589
	LOSS [training: 3.672964557284634 | validation: 3.4952883734786155]
	TIME [epoch: 9.51 sec]
EPOCH 402/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2267178013912945		[learning rate: 0.0018171]
	Learning Rate: 0.00181706
	LOSS [training: 3.2267178013912945 | validation: 3.353386362948587]
	TIME [epoch: 9.51 sec]
EPOCH 403/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0258311856348334		[learning rate: 0.0018083]
	Learning Rate: 0.00180827
	LOSS [training: 3.0258311856348334 | validation: 3.2685562457690187]
	TIME [epoch: 9.53 sec]
EPOCH 404/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0520788923471587		[learning rate: 0.0017995]
	Learning Rate: 0.00179952
	LOSS [training: 3.0520788923471587 | validation: 3.3257926805498044]
	TIME [epoch: 9.51 sec]
EPOCH 405/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1091346020495183		[learning rate: 0.0017908]
	Learning Rate: 0.00179082
	LOSS [training: 3.1091346020495183 | validation: 3.387965233796063]
	TIME [epoch: 9.51 sec]
EPOCH 406/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0292423033162343		[learning rate: 0.0017822]
	Learning Rate: 0.00178216
	LOSS [training: 3.0292423033162343 | validation: 3.200835332660894]
	TIME [epoch: 9.53 sec]
EPOCH 407/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.995749287288105		[learning rate: 0.0017735]
	Learning Rate: 0.00177354
	LOSS [training: 2.995749287288105 | validation: 3.373472466695255]
	TIME [epoch: 9.51 sec]
EPOCH 408/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2407628064928367		[learning rate: 0.001765]
	Learning Rate: 0.00176497
	LOSS [training: 3.2407628064928367 | validation: 3.3200869561724504]
	TIME [epoch: 9.5 sec]
EPOCH 409/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.132185720503942		[learning rate: 0.0017564]
	Learning Rate: 0.00175643
	LOSS [training: 3.132185720503942 | validation: 3.3926580950863277]
	TIME [epoch: 9.51 sec]
EPOCH 410/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.233139615859847		[learning rate: 0.0017479]
	Learning Rate: 0.00174794
	LOSS [training: 3.233139615859847 | validation: 3.4957432543636195]
	TIME [epoch: 9.53 sec]
EPOCH 411/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2457029143026785		[learning rate: 0.0017395]
	Learning Rate: 0.00173949
	LOSS [training: 3.2457029143026785 | validation: 3.5039726190514093]
	TIME [epoch: 9.51 sec]
EPOCH 412/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2152521198232145		[learning rate: 0.0017311]
	Learning Rate: 0.00173107
	LOSS [training: 3.2152521198232145 | validation: 3.6115450556473947]
	TIME [epoch: 9.52 sec]
EPOCH 413/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2117498802402467		[learning rate: 0.0017227]
	Learning Rate: 0.0017227
	LOSS [training: 3.2117498802402467 | validation: 3.3235393381618463]
	TIME [epoch: 9.53 sec]
EPOCH 414/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.072218454076434		[learning rate: 0.0017144]
	Learning Rate: 0.00171437
	LOSS [training: 3.072218454076434 | validation: 3.292874484593316]
	TIME [epoch: 9.5 sec]
EPOCH 415/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.020072841123255		[learning rate: 0.0017061]
	Learning Rate: 0.00170608
	LOSS [training: 3.020072841123255 | validation: 3.344695300018678]
	TIME [epoch: 9.51 sec]
EPOCH 416/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5314103894143636		[learning rate: 0.0016978]
	Learning Rate: 0.00169783
	LOSS [training: 3.5314103894143636 | validation: 3.797586852470405]
	TIME [epoch: 9.51 sec]
EPOCH 417/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2340510816342105		[learning rate: 0.0016896]
	Learning Rate: 0.00168962
	LOSS [training: 3.2340510816342105 | validation: 3.3194329427448683]
	TIME [epoch: 9.52 sec]
EPOCH 418/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0023895432850214		[learning rate: 0.0016815]
	Learning Rate: 0.00168145
	LOSS [training: 3.0023895432850214 | validation: 3.3841929451238753]
	TIME [epoch: 9.51 sec]
EPOCH 419/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.124088697388169		[learning rate: 0.0016733]
	Learning Rate: 0.00167332
	LOSS [training: 3.124088697388169 | validation: 3.788605686055123]
	TIME [epoch: 9.5 sec]
EPOCH 420/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.709335184266549		[learning rate: 0.0016652]
	Learning Rate: 0.00166523
	LOSS [training: 3.709335184266549 | validation: 3.995934933371454]
	TIME [epoch: 9.53 sec]
EPOCH 421/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.523188707969775		[learning rate: 0.0016572]
	Learning Rate: 0.00165718
	LOSS [training: 3.523188707969775 | validation: 3.487186596641428]
	TIME [epoch: 9.5 sec]
EPOCH 422/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.097224937726164		[learning rate: 0.0016492]
	Learning Rate: 0.00164916
	LOSS [training: 3.097224937726164 | validation: 3.3731754890471373]
	TIME [epoch: 9.51 sec]
EPOCH 423/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.060207883097035		[learning rate: 0.0016412]
	Learning Rate: 0.00164119
	LOSS [training: 3.060207883097035 | validation: 3.5769781503444738]
	TIME [epoch: 9.51 sec]
EPOCH 424/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2186748529945417		[learning rate: 0.0016332]
	Learning Rate: 0.00163325
	LOSS [training: 3.2186748529945417 | validation: 3.481265968337799]
	TIME [epoch: 9.51 sec]
EPOCH 425/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1804627830487524		[learning rate: 0.0016254]
	Learning Rate: 0.00162535
	LOSS [training: 3.1804627830487524 | validation: 3.3938667829837255]
	TIME [epoch: 9.51 sec]
EPOCH 426/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0204029803841004		[learning rate: 0.0016175]
	Learning Rate: 0.00161749
	LOSS [training: 3.0204029803841004 | validation: 3.4167663776965833]
	TIME [epoch: 9.51 sec]
EPOCH 427/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0928887701065726		[learning rate: 0.0016097]
	Learning Rate: 0.00160967
	LOSS [training: 3.0928887701065726 | validation: 3.456851952757312]
	TIME [epoch: 9.53 sec]
EPOCH 428/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.136696845565198		[learning rate: 0.0016019]
	Learning Rate: 0.00160189
	LOSS [training: 3.136696845565198 | validation: 3.3331052935767342]
	TIME [epoch: 9.51 sec]
EPOCH 429/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.048235545010383		[learning rate: 0.0015941]
	Learning Rate: 0.00159414
	LOSS [training: 3.048235545010383 | validation: 3.26399234286108]
	TIME [epoch: 9.5 sec]
EPOCH 430/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0082300052331736		[learning rate: 0.0015864]
	Learning Rate: 0.00158643
	LOSS [training: 3.0082300052331736 | validation: 3.1890263831590757]
	TIME [epoch: 9.52 sec]
EPOCH 431/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.995801451737054		[learning rate: 0.0015788]
	Learning Rate: 0.00157876
	LOSS [training: 2.995801451737054 | validation: 3.3179382172160343]
	TIME [epoch: 9.52 sec]
EPOCH 432/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1173202139581155		[learning rate: 0.0015711]
	Learning Rate: 0.00157112
	LOSS [training: 3.1173202139581155 | validation: 3.379662848831299]
	TIME [epoch: 9.51 sec]
EPOCH 433/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.045218009066505		[learning rate: 0.0015635]
	Learning Rate: 0.00156353
	LOSS [training: 3.045218009066505 | validation: 3.2550673166549666]
	TIME [epoch: 9.51 sec]
EPOCH 434/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9758250354282354		[learning rate: 0.001556]
	Learning Rate: 0.00155597
	LOSS [training: 2.9758250354282354 | validation: 3.2198586578560695]
	TIME [epoch: 9.53 sec]
EPOCH 435/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9436278889029857		[learning rate: 0.0015484]
	Learning Rate: 0.00154844
	LOSS [training: 2.9436278889029857 | validation: 3.204696058265639]
	TIME [epoch: 9.51 sec]
EPOCH 436/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.957862272709213		[learning rate: 0.001541]
	Learning Rate: 0.00154095
	LOSS [training: 2.957862272709213 | validation: 3.431077856004631]
	TIME [epoch: 9.51 sec]
EPOCH 437/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.292094506270666		[learning rate: 0.0015335]
	Learning Rate: 0.0015335
	LOSS [training: 3.292094506270666 | validation: 3.663335851437512]
	TIME [epoch: 9.52 sec]
EPOCH 438/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2303238165732253		[learning rate: 0.0015261]
	Learning Rate: 0.00152609
	LOSS [training: 3.2303238165732253 | validation: 3.4003425137764154]
	TIME [epoch: 9.52 sec]
EPOCH 439/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0949530687583455		[learning rate: 0.0015187]
	Learning Rate: 0.00151871
	LOSS [training: 3.0949530687583455 | validation: 3.433727165371859]
	TIME [epoch: 9.51 sec]
EPOCH 440/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1337100461515		[learning rate: 0.0015114]
	Learning Rate: 0.00151136
	LOSS [training: 3.1337100461515 | validation: 3.458171853873246]
	TIME [epoch: 9.51 sec]
EPOCH 441/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.205962857764716		[learning rate: 0.0015041]
	Learning Rate: 0.00150405
	LOSS [training: 3.205962857764716 | validation: 3.503254682314392]
	TIME [epoch: 9.53 sec]
EPOCH 442/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1008792980968947		[learning rate: 0.0014968]
	Learning Rate: 0.00149678
	LOSS [training: 3.1008792980968947 | validation: 3.302942568543138]
	TIME [epoch: 9.51 sec]
EPOCH 443/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1759479779377697		[learning rate: 0.0014895]
	Learning Rate: 0.00148954
	LOSS [training: 3.1759479779377697 | validation: 3.912006339706869]
	TIME [epoch: 9.51 sec]
EPOCH 444/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9581606387353014		[learning rate: 0.0014823]
	Learning Rate: 0.00148234
	LOSS [training: 3.9581606387353014 | validation: 3.9092690452030627]
	TIME [epoch: 9.53 sec]
EPOCH 445/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.7533096902744867		[learning rate: 0.0014752]
	Learning Rate: 0.00147517
	LOSS [training: 3.7533096902744867 | validation: 3.8282840528776276]
	TIME [epoch: 9.51 sec]
EPOCH 446/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.805438182564939		[learning rate: 0.001468]
	Learning Rate: 0.00146804
	LOSS [training: 3.805438182564939 | validation: 4.322004487883475]
	TIME [epoch: 9.51 sec]
EPOCH 447/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9479533372040843		[learning rate: 0.0014609]
	Learning Rate: 0.00146094
	LOSS [training: 3.9479533372040843 | validation: 4.183402139744674]
	TIME [epoch: 9.51 sec]
EPOCH 448/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.838251451939654		[learning rate: 0.0014539]
	Learning Rate: 0.00145387
	LOSS [training: 3.838251451939654 | validation: 4.038728793878146]
	TIME [epoch: 9.53 sec]
EPOCH 449/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.71986312581051		[learning rate: 0.0014468]
	Learning Rate: 0.00144684
	LOSS [training: 3.71986312581051 | validation: 3.7350405270925]
	TIME [epoch: 9.51 sec]
EPOCH 450/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3671240628426675		[learning rate: 0.0014398]
	Learning Rate: 0.00143985
	LOSS [training: 3.3671240628426675 | validation: 3.4541295039099826]
	TIME [epoch: 9.51 sec]
EPOCH 451/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1690966077780156		[learning rate: 0.0014329]
	Learning Rate: 0.00143288
	LOSS [training: 3.1690966077780156 | validation: 3.5104237416598654]
	TIME [epoch: 9.53 sec]
EPOCH 452/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.130831824036263		[learning rate: 0.001426]
	Learning Rate: 0.00142595
	LOSS [training: 3.130831824036263 | validation: 3.172899587577589]
	TIME [epoch: 9.51 sec]
EPOCH 453/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3014565757176917		[learning rate: 0.0014191]
	Learning Rate: 0.00141906
	LOSS [training: 3.3014565757176917 | validation: 4.1059473584339194]
	TIME [epoch: 9.51 sec]
EPOCH 454/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.9103324106646924		[learning rate: 0.0014122]
	Learning Rate: 0.0014122
	LOSS [training: 3.9103324106646924 | validation: 4.27414052486828]
	TIME [epoch: 9.52 sec]
EPOCH 455/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.372750818636885		[learning rate: 0.0014054]
	Learning Rate: 0.00140537
	LOSS [training: 4.372750818636885 | validation: 4.697785898411418]
	TIME [epoch: 9.53 sec]
EPOCH 456/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.829632630866475		[learning rate: 0.0013986]
	Learning Rate: 0.00139857
	LOSS [training: 4.829632630866475 | validation: 5.08718028895292]
	TIME [epoch: 9.51 sec]
EPOCH 457/1000:
	Training over batches...
		[batch 5/5] avg loss: 5.028042293770897		[learning rate: 0.0013918]
	Learning Rate: 0.00139181
	LOSS [training: 5.028042293770897 | validation: 4.760634904362739]
	TIME [epoch: 9.51 sec]
EPOCH 458/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.327031158245541		[learning rate: 0.0013851]
	Learning Rate: 0.00138508
	LOSS [training: 4.327031158245541 | validation: 4.222516506298486]
	TIME [epoch: 9.53 sec]
EPOCH 459/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.888670265663991		[learning rate: 0.0013784]
	Learning Rate: 0.00137838
	LOSS [training: 3.888670265663991 | validation: 3.9026765770794967]
	TIME [epoch: 9.52 sec]
EPOCH 460/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.828505736598892		[learning rate: 0.0013717]
	Learning Rate: 0.00137171
	LOSS [training: 3.828505736598892 | validation: 4.393366776631449]
	TIME [epoch: 9.51 sec]
EPOCH 461/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.439982984145611		[learning rate: 0.0013651]
	Learning Rate: 0.00136508
	LOSS [training: 4.439982984145611 | validation: 4.357022102580487]
	TIME [epoch: 9.51 sec]
EPOCH 462/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.0837650077350185		[learning rate: 0.0013585]
	Learning Rate: 0.00135848
	LOSS [training: 4.0837650077350185 | validation: 4.294509429658633]
	TIME [epoch: 9.54 sec]
EPOCH 463/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.229856788970487		[learning rate: 0.0013519]
	Learning Rate: 0.00135191
	LOSS [training: 4.229856788970487 | validation: 4.72047583143302]
	TIME [epoch: 9.51 sec]
EPOCH 464/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.654960169266788		[learning rate: 0.0013454]
	Learning Rate: 0.00134537
	LOSS [training: 4.654960169266788 | validation: 4.784989144732975]
	TIME [epoch: 9.51 sec]
EPOCH 465/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.379253953028498		[learning rate: 0.0013389]
	Learning Rate: 0.00133887
	LOSS [training: 4.379253953028498 | validation: 4.523253095097285]
	TIME [epoch: 9.53 sec]
EPOCH 466/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.054369934403601		[learning rate: 0.0013324]
	Learning Rate: 0.00133239
	LOSS [training: 4.054369934403601 | validation: 3.6712837361744777]
	TIME [epoch: 9.52 sec]
EPOCH 467/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.442988692903623		[learning rate: 0.0013259]
	Learning Rate: 0.00132595
	LOSS [training: 3.442988692903623 | validation: 3.3261401988942687]
	TIME [epoch: 9.51 sec]
EPOCH 468/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1268871991596687		[learning rate: 0.0013195]
	Learning Rate: 0.00131954
	LOSS [training: 3.1268871991596687 | validation: 3.208532698342295]
	TIME [epoch: 9.51 sec]
EPOCH 469/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.927659343632541		[learning rate: 0.0013132]
	Learning Rate: 0.00131315
	LOSS [training: 2.927659343632541 | validation: 3.0221216982439443]
	TIME [epoch: 9.54 sec]
EPOCH 470/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.797349037346861		[learning rate: 0.0013068]
	Learning Rate: 0.0013068
	LOSS [training: 2.797349037346861 | validation: 3.227458562872968]
	TIME [epoch: 9.51 sec]
EPOCH 471/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.515717250744399		[learning rate: 0.0013005]
	Learning Rate: 0.00130048
	LOSS [training: 3.515717250744399 | validation: 4.000910497671107]
	TIME [epoch: 9.52 sec]
EPOCH 472/1000:
	Training over batches...
		[batch 5/5] avg loss: 4.069713875325755		[learning rate: 0.0012942]
	Learning Rate: 0.0012942
	LOSS [training: 4.069713875325755 | validation: 4.24247038418422]
	TIME [epoch: 9.53 sec]
EPOCH 473/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.966000557196648		[learning rate: 0.0012879]
	Learning Rate: 0.00128794
	LOSS [training: 3.966000557196648 | validation: 3.9990527931148074]
	TIME [epoch: 9.52 sec]
EPOCH 474/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.629957263982625		[learning rate: 0.0012817]
	Learning Rate: 0.00128171
	LOSS [training: 3.629957263982625 | validation: 3.2861858206201897]
	TIME [epoch: 9.51 sec]
EPOCH 475/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.960295948416616		[learning rate: 0.0012755]
	Learning Rate: 0.00127551
	LOSS [training: 2.960295948416616 | validation: 3.159288243724289]
	TIME [epoch: 9.51 sec]
EPOCH 476/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9874526677598308		[learning rate: 0.0012693]
	Learning Rate: 0.00126934
	LOSS [training: 2.9874526677598308 | validation: 3.126129877385724]
	TIME [epoch: 9.53 sec]
EPOCH 477/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.081718412088583		[learning rate: 0.0012632]
	Learning Rate: 0.0012632
	LOSS [training: 3.081718412088583 | validation: 3.5805736210851]
	TIME [epoch: 9.51 sec]
EPOCH 478/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2427876232220116		[learning rate: 0.0012571]
	Learning Rate: 0.0012571
	LOSS [training: 3.2427876232220116 | validation: 3.4323069810419162]
	TIME [epoch: 9.52 sec]
EPOCH 479/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.12386454891023		[learning rate: 0.001251]
	Learning Rate: 0.00125102
	LOSS [training: 3.12386454891023 | validation: 3.732263307199661]
	TIME [epoch: 9.52 sec]
EPOCH 480/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3770929006158803		[learning rate: 0.001245]
	Learning Rate: 0.00124497
	LOSS [training: 3.3770929006158803 | validation: 3.6520362926873036]
	TIME [epoch: 9.51 sec]
EPOCH 481/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1914614334098674		[learning rate: 0.0012389]
	Learning Rate: 0.00123895
	LOSS [training: 3.1914614334098674 | validation: 3.6688518348835224]
	TIME [epoch: 9.5 sec]
EPOCH 482/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.569024296314524		[learning rate: 0.001233]
	Learning Rate: 0.00123296
	LOSS [training: 3.569024296314524 | validation: 3.683957473900456]
	TIME [epoch: 9.51 sec]
EPOCH 483/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2676159132497204		[learning rate: 0.001227]
	Learning Rate: 0.00122699
	LOSS [training: 3.2676159132497204 | validation: 3.39173853994273]
	TIME [epoch: 9.53 sec]
EPOCH 484/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1218425453848524		[learning rate: 0.0012211]
	Learning Rate: 0.00122106
	LOSS [training: 3.1218425453848524 | validation: 3.4316846669175693]
	TIME [epoch: 9.5 sec]
EPOCH 485/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1995521179384916		[learning rate: 0.0012152]
	Learning Rate: 0.00121515
	LOSS [training: 3.1995521179384916 | validation: 3.3656142637100475]
	TIME [epoch: 9.5 sec]
EPOCH 486/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1849698538105216		[learning rate: 0.0012093]
	Learning Rate: 0.00120928
	LOSS [training: 3.1849698538105216 | validation: 3.4897506309904562]
	TIME [epoch: 9.52 sec]
EPOCH 487/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1161827398942825		[learning rate: 0.0012034]
	Learning Rate: 0.00120343
	LOSS [training: 3.1161827398942825 | validation: 3.3723989133614998]
	TIME [epoch: 9.51 sec]
EPOCH 488/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.055866778744819		[learning rate: 0.0011976]
	Learning Rate: 0.00119761
	LOSS [training: 3.055866778744819 | validation: 3.2124175170354548]
	TIME [epoch: 9.5 sec]
EPOCH 489/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.186473458177697		[learning rate: 0.0011918]
	Learning Rate: 0.00119182
	LOSS [training: 3.186473458177697 | validation: 3.4754551451710056]
	TIME [epoch: 9.51 sec]
EPOCH 490/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.074564811746721		[learning rate: 0.0011861]
	Learning Rate: 0.00118606
	LOSS [training: 3.074564811746721 | validation: 3.243743457067923]
	TIME [epoch: 9.52 sec]
EPOCH 491/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9025264983321715		[learning rate: 0.0011803]
	Learning Rate: 0.00118032
	LOSS [training: 2.9025264983321715 | validation: 3.1419971559212336]
	TIME [epoch: 9.51 sec]
EPOCH 492/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8708621638687477		[learning rate: 0.0011746]
	Learning Rate: 0.00117461
	LOSS [training: 2.8708621638687477 | validation: 3.127772065059586]
	TIME [epoch: 9.5 sec]
EPOCH 493/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.910868664005725		[learning rate: 0.0011689]
	Learning Rate: 0.00116893
	LOSS [training: 2.910868664005725 | validation: 3.1604194687043345]
	TIME [epoch: 9.52 sec]
EPOCH 494/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.85616235761886		[learning rate: 0.0011633]
	Learning Rate: 0.00116328
	LOSS [training: 2.85616235761886 | validation: 3.145872937348829]
	TIME [epoch: 9.5 sec]
EPOCH 495/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8807509886977405		[learning rate: 0.0011577]
	Learning Rate: 0.00115765
	LOSS [training: 2.8807509886977405 | validation: 3.133776329036428]
	TIME [epoch: 9.5 sec]
EPOCH 496/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.957489341933846		[learning rate: 0.0011521]
	Learning Rate: 0.00115206
	LOSS [training: 2.957489341933846 | validation: 3.2473247784228603]
	TIME [epoch: 9.51 sec]
EPOCH 497/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9757689450476397		[learning rate: 0.0011465]
	Learning Rate: 0.00114648
	LOSS [training: 2.9757689450476397 | validation: 3.073385837056622]
	TIME [epoch: 9.52 sec]
EPOCH 498/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.846605223826594		[learning rate: 0.0011409]
	Learning Rate: 0.00114094
	LOSS [training: 2.846605223826594 | validation: 3.1542236712991962]
	TIME [epoch: 9.5 sec]
EPOCH 499/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9301207151179876		[learning rate: 0.0011354]
	Learning Rate: 0.00113542
	LOSS [training: 2.9301207151179876 | validation: 3.3361755189446605]
	TIME [epoch: 9.5 sec]
EPOCH 500/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1259993900580314		[learning rate: 0.0011299]
	Learning Rate: 0.00112993
	LOSS [training: 3.1259993900580314 | validation: 3.3753707697811057]
	TIME [epoch: 9.53 sec]
EPOCH 501/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1062647760209305		[learning rate: 0.0011245]
	Learning Rate: 0.00112447
	LOSS [training: 3.1062647760209305 | validation: 3.3291619566649433]
	TIME [epoch: 9.5 sec]
EPOCH 502/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0151261374183305		[learning rate: 0.001119]
	Learning Rate: 0.00111903
	LOSS [training: 3.0151261374183305 | validation: 3.149558975206665]
	TIME [epoch: 9.5 sec]
EPOCH 503/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.88503412188034		[learning rate: 0.0011136]
	Learning Rate: 0.00111362
	LOSS [training: 2.88503412188034 | validation: 3.1508082306782494]
	TIME [epoch: 9.51 sec]
EPOCH 504/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.942513458402601		[learning rate: 0.0011082]
	Learning Rate: 0.00110823
	LOSS [training: 2.942513458402601 | validation: 3.2523180395624833]
	TIME [epoch: 9.53 sec]
EPOCH 505/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0187511829042935		[learning rate: 0.0011029]
	Learning Rate: 0.00110287
	LOSS [training: 3.0187511829042935 | validation: 3.45063193733229]
	TIME [epoch: 9.51 sec]
EPOCH 506/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0833450421271236		[learning rate: 0.0010975]
	Learning Rate: 0.00109754
	LOSS [training: 3.0833450421271236 | validation: 3.3243534158439023]
	TIME [epoch: 9.5 sec]
EPOCH 507/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0034286729432855		[learning rate: 0.0010922]
	Learning Rate: 0.00109223
	LOSS [training: 3.0034286729432855 | validation: 3.23814977038365]
	TIME [epoch: 9.53 sec]
EPOCH 508/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.981524880088905		[learning rate: 0.001087]
	Learning Rate: 0.00108695
	LOSS [training: 2.981524880088905 | validation: 3.2583190644673734]
	TIME [epoch: 9.5 sec]
EPOCH 509/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0036996214817235		[learning rate: 0.0010817]
	Learning Rate: 0.0010817
	LOSS [training: 3.0036996214817235 | validation: 3.310557493518104]
	TIME [epoch: 9.5 sec]
EPOCH 510/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0956468700547473		[learning rate: 0.0010765]
	Learning Rate: 0.00107647
	LOSS [training: 3.0956468700547473 | validation: 3.45758235001335]
	TIME [epoch: 9.5 sec]
EPOCH 511/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.068322772940105		[learning rate: 0.0010713]
	Learning Rate: 0.00107126
	LOSS [training: 3.068322772940105 | validation: 3.366446495544002]
	TIME [epoch: 9.52 sec]
EPOCH 512/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.043439400298722		[learning rate: 0.0010661]
	Learning Rate: 0.00106608
	LOSS [training: 3.043439400298722 | validation: 3.196151974630429]
	TIME [epoch: 9.5 sec]
EPOCH 513/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8975133653989533		[learning rate: 0.0010609]
	Learning Rate: 0.00106092
	LOSS [training: 2.8975133653989533 | validation: 3.1455720835055807]
	TIME [epoch: 9.5 sec]
EPOCH 514/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.88549199342637		[learning rate: 0.0010558]
	Learning Rate: 0.00105579
	LOSS [training: 2.88549199342637 | validation: 3.15743504209901]
	TIME [epoch: 9.53 sec]
EPOCH 515/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9471874395057593		[learning rate: 0.0010507]
	Learning Rate: 0.00105069
	LOSS [training: 2.9471874395057593 | validation: 3.410187303263731]
	TIME [epoch: 9.5 sec]
EPOCH 516/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.031217091632569		[learning rate: 0.0010456]
	Learning Rate: 0.00104561
	LOSS [training: 3.031217091632569 | validation: 3.144843809082062]
	TIME [epoch: 9.5 sec]
EPOCH 517/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0085835278139283		[learning rate: 0.0010406]
	Learning Rate: 0.00104055
	LOSS [training: 3.0085835278139283 | validation: 3.1685802483163044]
	TIME [epoch: 9.51 sec]
EPOCH 518/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9768004931951233		[learning rate: 0.0010355]
	Learning Rate: 0.00103552
	LOSS [training: 2.9768004931951233 | validation: 3.3203105337607757]
	TIME [epoch: 9.51 sec]
EPOCH 519/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0144191847695163		[learning rate: 0.0010305]
	Learning Rate: 0.00103051
	LOSS [training: 3.0144191847695163 | validation: 3.397585475712516]
	TIME [epoch: 9.5 sec]
EPOCH 520/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.045892207456342		[learning rate: 0.0010255]
	Learning Rate: 0.00102553
	LOSS [training: 3.045892207456342 | validation: 3.3138962006876955]
	TIME [epoch: 9.5 sec]
EPOCH 521/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.045116047245152		[learning rate: 0.0010206]
	Learning Rate: 0.00102057
	LOSS [training: 3.045116047245152 | validation: 3.364287665098477]
	TIME [epoch: 9.52 sec]
EPOCH 522/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.07565392019614		[learning rate: 0.0010156]
	Learning Rate: 0.00101563
	LOSS [training: 3.07565392019614 | validation: 3.311132483706097]
	TIME [epoch: 9.5 sec]
EPOCH 523/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0427752069823564		[learning rate: 0.0010107]
	Learning Rate: 0.00101072
	LOSS [training: 3.0427752069823564 | validation: 3.281906023649099]
	TIME [epoch: 9.5 sec]
EPOCH 524/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9732703082211858		[learning rate: 0.0010058]
	Learning Rate: 0.00100583
	LOSS [training: 2.9732703082211858 | validation: 3.113187793289501]
	TIME [epoch: 9.51 sec]
EPOCH 525/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8943823169150713		[learning rate: 0.001001]
	Learning Rate: 0.00100097
	LOSS [training: 2.8943823169150713 | validation: 3.1580050300893845]
	TIME [epoch: 9.51 sec]
EPOCH 526/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8878188264623574		[learning rate: 0.00099613]
	Learning Rate: 0.000996129
	LOSS [training: 2.8878188264623574 | validation: 3.148525507982683]
	TIME [epoch: 9.5 sec]
EPOCH 527/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9384223717239295		[learning rate: 0.00099131]
	Learning Rate: 0.000991312
	LOSS [training: 2.9384223717239295 | validation: 3.094302393326343]
	TIME [epoch: 9.5 sec]
EPOCH 528/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9177528379568582		[learning rate: 0.00098652]
	Learning Rate: 0.000986519
	LOSS [training: 2.9177528379568582 | validation: 3.199719007369586]
	TIME [epoch: 9.53 sec]
EPOCH 529/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9265145189373776		[learning rate: 0.00098175]
	Learning Rate: 0.000981748
	LOSS [training: 2.9265145189373776 | validation: 3.1381269949671684]
	TIME [epoch: 9.5 sec]
EPOCH 530/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8832570070725314		[learning rate: 0.000977]
	Learning Rate: 0.000977
	LOSS [training: 2.8832570070725314 | validation: 3.1351096014937583]
	TIME [epoch: 9.5 sec]
EPOCH 531/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.831241940098431		[learning rate: 0.00097228]
	Learning Rate: 0.000972276
	LOSS [training: 2.831241940098431 | validation: 3.060204927957972]
	TIME [epoch: 9.51 sec]
EPOCH 532/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8635428031875128		[learning rate: 0.00096757]
	Learning Rate: 0.000967574
	LOSS [training: 2.8635428031875128 | validation: 3.23018922429888]
	TIME [epoch: 9.51 sec]
EPOCH 533/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8737215778780807		[learning rate: 0.00096289]
	Learning Rate: 0.000962895
	LOSS [training: 2.8737215778780807 | validation: 3.1923508235956666]
	TIME [epoch: 9.49 sec]
EPOCH 534/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.914770867523091		[learning rate: 0.00095824]
	Learning Rate: 0.000958239
	LOSS [training: 2.914770867523091 | validation: 3.159371707091896]
	TIME [epoch: 9.49 sec]
EPOCH 535/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8850421187037183		[learning rate: 0.0009536]
	Learning Rate: 0.000953605
	LOSS [training: 2.8850421187037183 | validation: 3.1587058951188967]
	TIME [epoch: 9.52 sec]
EPOCH 536/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8797806083660213		[learning rate: 0.00094899]
	Learning Rate: 0.000948993
	LOSS [training: 2.8797806083660213 | validation: 3.082828502927579]
	TIME [epoch: 9.49 sec]
EPOCH 537/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.79499430229422		[learning rate: 0.0009444]
	Learning Rate: 0.000944404
	LOSS [training: 2.79499430229422 | validation: 2.984029097821613]
	TIME [epoch: 9.5 sec]
EPOCH 538/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7268155009127892		[learning rate: 0.00093984]
	Learning Rate: 0.000939837
	LOSS [training: 2.7268155009127892 | validation: 2.975547428247434]
	TIME [epoch: 9.51 sec]
EPOCH 539/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.745745698423525		[learning rate: 0.00093529]
	Learning Rate: 0.000935292
	LOSS [training: 2.745745698423525 | validation: 3.01282150188024]
	TIME [epoch: 9.5 sec]
EPOCH 540/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7782348399868306		[learning rate: 0.00093077]
	Learning Rate: 0.000930769
	LOSS [training: 2.7782348399868306 | validation: 3.163007189939315]
	TIME [epoch: 9.5 sec]
EPOCH 541/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8809468740655144		[learning rate: 0.00092627]
	Learning Rate: 0.000926268
	LOSS [training: 2.8809468740655144 | validation: 3.0288428103354534]
	TIME [epoch: 9.5 sec]
EPOCH 542/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.801390214069964		[learning rate: 0.00092179]
	Learning Rate: 0.000921789
	LOSS [training: 2.801390214069964 | validation: 2.9975216628389534]
	TIME [epoch: 9.53 sec]
EPOCH 543/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.829042337640938		[learning rate: 0.00091733]
	Learning Rate: 0.000917331
	LOSS [training: 2.829042337640938 | validation: 3.2071614686958254]
	TIME [epoch: 9.5 sec]
EPOCH 544/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.209198906129491		[learning rate: 0.0009129]
	Learning Rate: 0.000912895
	LOSS [training: 3.209198906129491 | validation: 3.2883880863896593]
	TIME [epoch: 9.5 sec]
EPOCH 545/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.03547199352832		[learning rate: 0.00090848]
	Learning Rate: 0.000908481
	LOSS [training: 3.03547199352832 | validation: 3.1936601776747677]
	TIME [epoch: 9.52 sec]
EPOCH 546/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0103054107806106		[learning rate: 0.00090409]
	Learning Rate: 0.000904088
	LOSS [training: 3.0103054107806106 | validation: 3.057339352544729]
	TIME [epoch: 9.51 sec]
EPOCH 547/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.969815398679573		[learning rate: 0.00089972]
	Learning Rate: 0.000899716
	LOSS [training: 2.969815398679573 | validation: 3.3899331954080587]
	TIME [epoch: 9.5 sec]
EPOCH 548/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4956037205155908		[learning rate: 0.00089536]
	Learning Rate: 0.000895365
	LOSS [training: 3.4956037205155908 | validation: 3.444350611290073]
	TIME [epoch: 9.51 sec]
EPOCH 549/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3692174579162533		[learning rate: 0.00089104]
	Learning Rate: 0.000891035
	LOSS [training: 3.3692174579162533 | validation: 3.3597004810849804]
	TIME [epoch: 9.53 sec]
EPOCH 550/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.120276078000652		[learning rate: 0.00088673]
	Learning Rate: 0.000886726
	LOSS [training: 3.120276078000652 | validation: 2.9452530643968253]
	TIME [epoch: 9.5 sec]
EPOCH 551/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.818150310474073		[learning rate: 0.00088244]
	Learning Rate: 0.000882438
	LOSS [training: 2.818150310474073 | validation: 2.928170761169509]
	TIME [epoch: 9.5 sec]
EPOCH 552/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.685138995795053		[learning rate: 0.00087817]
	Learning Rate: 0.000878171
	LOSS [training: 2.685138995795053 | validation: 2.7844678552598228]
	TIME [epoch: 9.55 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_552.pth
	Model improved!!!
EPOCH 553/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.701397360936614		[learning rate: 0.00087392]
	Learning Rate: 0.000873924
	LOSS [training: 2.701397360936614 | validation: 2.997627935668351]
	TIME [epoch: 9.51 sec]
EPOCH 554/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.164224643823169		[learning rate: 0.0008697]
	Learning Rate: 0.000869698
	LOSS [training: 3.164224643823169 | validation: 3.688670714276375]
	TIME [epoch: 9.51 sec]
EPOCH 555/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4988777893012033		[learning rate: 0.00086549]
	Learning Rate: 0.000865492
	LOSS [training: 3.4988777893012033 | validation: 3.411581946945305]
	TIME [epoch: 9.5 sec]
EPOCH 556/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1743021811210665		[learning rate: 0.00086131]
	Learning Rate: 0.000861307
	LOSS [training: 3.1743021811210665 | validation: 3.2227731730772122]
	TIME [epoch: 9.53 sec]
EPOCH 557/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.913653546965606		[learning rate: 0.00085714]
	Learning Rate: 0.000857142
	LOSS [training: 2.913653546965606 | validation: 2.94768871569079]
	TIME [epoch: 9.5 sec]
EPOCH 558/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.740947460846921		[learning rate: 0.000853]
	Learning Rate: 0.000852997
	LOSS [training: 2.740947460846921 | validation: 2.9152386326737862]
	TIME [epoch: 9.5 sec]
EPOCH 559/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7416753801290645		[learning rate: 0.00084887]
	Learning Rate: 0.000848872
	LOSS [training: 2.7416753801290645 | validation: 2.8975298589192953]
	TIME [epoch: 9.53 sec]
EPOCH 560/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6920283374326988		[learning rate: 0.00084477]
	Learning Rate: 0.000844767
	LOSS [training: 2.6920283374326988 | validation: 2.8990548098859477]
	TIME [epoch: 9.5 sec]
EPOCH 561/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7385696098610475		[learning rate: 0.00084068]
	Learning Rate: 0.000840682
	LOSS [training: 2.7385696098610475 | validation: 3.2040670003167646]
	TIME [epoch: 9.5 sec]
EPOCH 562/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.854839624114766		[learning rate: 0.00083662]
	Learning Rate: 0.000836616
	LOSS [training: 2.854839624114766 | validation: 3.0713453687962122]
	TIME [epoch: 9.5 sec]
EPOCH 563/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7621010808882573		[learning rate: 0.00083257]
	Learning Rate: 0.000832571
	LOSS [training: 2.7621010808882573 | validation: 2.930462918709694]
	TIME [epoch: 9.53 sec]
EPOCH 564/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8324660006122473		[learning rate: 0.00082854]
	Learning Rate: 0.000828544
	LOSS [training: 2.8324660006122473 | validation: 3.1569538915933113]
	TIME [epoch: 9.5 sec]
EPOCH 565/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8905765692318686		[learning rate: 0.00082454]
	Learning Rate: 0.000824538
	LOSS [training: 2.8905765692318686 | validation: 3.203785966512421]
	TIME [epoch: 9.5 sec]
EPOCH 566/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9131339125405438		[learning rate: 0.00082055]
	Learning Rate: 0.00082055
	LOSS [training: 2.9131339125405438 | validation: 3.1861115419193715]
	TIME [epoch: 9.52 sec]
EPOCH 567/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.832254510189398		[learning rate: 0.00081658]
	Learning Rate: 0.000816582
	LOSS [training: 2.832254510189398 | validation: 3.0211732904332633]
	TIME [epoch: 9.51 sec]
EPOCH 568/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.838835985595155		[learning rate: 0.00081263]
	Learning Rate: 0.000812633
	LOSS [training: 2.838835985595155 | validation: 3.2019779519279417]
	TIME [epoch: 9.51 sec]
EPOCH 569/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9123578086733155		[learning rate: 0.0008087]
	Learning Rate: 0.000808704
	LOSS [training: 2.9123578086733155 | validation: 3.3667502088227104]
	TIME [epoch: 9.51 sec]
EPOCH 570/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.990193878801075		[learning rate: 0.00080479]
	Learning Rate: 0.000804793
	LOSS [training: 2.990193878801075 | validation: 3.2476975886451966]
	TIME [epoch: 9.52 sec]
EPOCH 571/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8488910577960023		[learning rate: 0.0008009]
	Learning Rate: 0.000800901
	LOSS [training: 2.8488910577960023 | validation: 2.9733620902786537]
	TIME [epoch: 9.5 sec]
EPOCH 572/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7462513688221333		[learning rate: 0.00079703]
	Learning Rate: 0.000797028
	LOSS [training: 2.7462513688221333 | validation: 2.946286169670134]
	TIME [epoch: 9.5 sec]
EPOCH 573/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.654915978249155		[learning rate: 0.00079317]
	Learning Rate: 0.000793174
	LOSS [training: 2.654915978249155 | validation: 2.879116131410907]
	TIME [epoch: 9.52 sec]
EPOCH 574/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6303122642093877		[learning rate: 0.00078934]
	Learning Rate: 0.000789338
	LOSS [training: 2.6303122642093877 | validation: 3.008764450611825]
	TIME [epoch: 9.5 sec]
EPOCH 575/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6898226846110598		[learning rate: 0.00078552]
	Learning Rate: 0.000785521
	LOSS [training: 2.6898226846110598 | validation: 2.7644262187223285]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_575.pth
	Model improved!!!
EPOCH 576/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6052763226165703		[learning rate: 0.00078172]
	Learning Rate: 0.000781723
	LOSS [training: 2.6052763226165703 | validation: 2.7995419690610768]
	TIME [epoch: 9.51 sec]
EPOCH 577/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6950455435331158		[learning rate: 0.00077794]
	Learning Rate: 0.000777942
	LOSS [training: 2.6950455435331158 | validation: 3.051785518929531]
	TIME [epoch: 9.52 sec]
EPOCH 578/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.1247612442374075		[learning rate: 0.00077418]
	Learning Rate: 0.00077418
	LOSS [training: 3.1247612442374075 | validation: 3.2232383543664254]
	TIME [epoch: 9.5 sec]
EPOCH 579/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.485847735613555		[learning rate: 0.00077044]
	Learning Rate: 0.000770436
	LOSS [training: 3.485847735613555 | validation: 3.7756433650642602]
	TIME [epoch: 9.5 sec]
EPOCH 580/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.5275177531255806		[learning rate: 0.00076671]
	Learning Rate: 0.000766711
	LOSS [training: 3.5275177531255806 | validation: 3.458928998202152]
	TIME [epoch: 9.51 sec]
EPOCH 581/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3602101917962925		[learning rate: 0.000763]
	Learning Rate: 0.000763003
	LOSS [training: 3.3602101917962925 | validation: 3.2761140201852177]
	TIME [epoch: 9.51 sec]
EPOCH 582/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0159666110708985		[learning rate: 0.00075931]
	Learning Rate: 0.000759313
	LOSS [training: 3.0159666110708985 | validation: 3.0260230723658528]
	TIME [epoch: 9.5 sec]
EPOCH 583/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8572185857599672		[learning rate: 0.00075564]
	Learning Rate: 0.000755641
	LOSS [training: 2.8572185857599672 | validation: 2.977953838714971]
	TIME [epoch: 9.51 sec]
EPOCH 584/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8312226266623055		[learning rate: 0.00075199]
	Learning Rate: 0.000751987
	LOSS [training: 2.8312226266623055 | validation: 3.1482690403961384]
	TIME [epoch: 9.52 sec]
EPOCH 585/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9335799209646587		[learning rate: 0.00074835]
	Learning Rate: 0.000748351
	LOSS [training: 2.9335799209646587 | validation: 2.961411802792266]
	TIME [epoch: 9.51 sec]
EPOCH 586/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8067945783440855		[learning rate: 0.00074473]
	Learning Rate: 0.000744732
	LOSS [training: 2.8067945783440855 | validation: 3.046933243228851]
	TIME [epoch: 9.5 sec]
EPOCH 587/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7002800520260544		[learning rate: 0.00074113]
	Learning Rate: 0.000741131
	LOSS [training: 2.7002800520260544 | validation: 2.795607011593537]
	TIME [epoch: 9.53 sec]
EPOCH 588/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.680512708667787		[learning rate: 0.00073755]
	Learning Rate: 0.000737547
	LOSS [training: 2.680512708667787 | validation: 2.834099729151434]
	TIME [epoch: 9.51 sec]
EPOCH 589/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6599919200289994		[learning rate: 0.00073398]
	Learning Rate: 0.00073398
	LOSS [training: 2.6599919200289994 | validation: 2.887915207209361]
	TIME [epoch: 9.5 sec]
EPOCH 590/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.783908819486411		[learning rate: 0.00073043]
	Learning Rate: 0.00073043
	LOSS [training: 2.783908819486411 | validation: 2.9029494680001653]
	TIME [epoch: 9.51 sec]
EPOCH 591/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7429046415424536		[learning rate: 0.0007269]
	Learning Rate: 0.000726898
	LOSS [training: 2.7429046415424536 | validation: 2.871502924146229]
	TIME [epoch: 9.52 sec]
EPOCH 592/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7312267918385666		[learning rate: 0.00072338]
	Learning Rate: 0.000723383
	LOSS [training: 2.7312267918385666 | validation: 2.897348611563365]
	TIME [epoch: 9.5 sec]
EPOCH 593/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.75621584190048		[learning rate: 0.00071989]
	Learning Rate: 0.000719885
	LOSS [training: 2.75621584190048 | validation: 2.8331950065409424]
	TIME [epoch: 9.52 sec]
EPOCH 594/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6935306752608277		[learning rate: 0.0007164]
	Learning Rate: 0.000716404
	LOSS [training: 2.6935306752608277 | validation: 2.8706144894786885]
	TIME [epoch: 9.52 sec]
EPOCH 595/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6944908000425754		[learning rate: 0.00071294]
	Learning Rate: 0.000712939
	LOSS [training: 2.6944908000425754 | validation: 2.9027159486214966]
	TIME [epoch: 9.51 sec]
EPOCH 596/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7469352353819354		[learning rate: 0.00070949]
	Learning Rate: 0.000709492
	LOSS [training: 2.7469352353819354 | validation: 2.9171897398579194]
	TIME [epoch: 9.5 sec]
EPOCH 597/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8398040407203173		[learning rate: 0.00070606]
	Learning Rate: 0.000706061
	LOSS [training: 2.8398040407203173 | validation: 3.1323443044626744]
	TIME [epoch: 9.5 sec]
EPOCH 598/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.071790707717604		[learning rate: 0.00070265]
	Learning Rate: 0.000702647
	LOSS [training: 3.071790707717604 | validation: 3.464378395777477]
	TIME [epoch: 9.51 sec]
EPOCH 599/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.2647163651109414		[learning rate: 0.00069925]
	Learning Rate: 0.000699248
	LOSS [training: 3.2647163651109414 | validation: 3.362615007068512]
	TIME [epoch: 9.5 sec]
EPOCH 600/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.3073530788463104		[learning rate: 0.00069587]
	Learning Rate: 0.000695867
	LOSS [training: 3.3073530788463104 | validation: 3.51804797403748]
	TIME [epoch: 9.5 sec]
EPOCH 601/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.4806702606611637		[learning rate: 0.0006925]
	Learning Rate: 0.000692502
	LOSS [training: 3.4806702606611637 | validation: 3.7529399616269816]
	TIME [epoch: 9.52 sec]
EPOCH 602/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.488463621176501		[learning rate: 0.00068915]
	Learning Rate: 0.000689153
	LOSS [training: 3.488463621176501 | validation: 3.343633895662068]
	TIME [epoch: 9.5 sec]
EPOCH 603/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.047706778746916		[learning rate: 0.00068582]
	Learning Rate: 0.000685821
	LOSS [training: 3.047706778746916 | validation: 2.9990005520571392]
	TIME [epoch: 9.5 sec]
EPOCH 604/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.916385249854786		[learning rate: 0.0006825]
	Learning Rate: 0.000682504
	LOSS [training: 2.916385249854786 | validation: 3.1563058176781738]
	TIME [epoch: 9.51 sec]
EPOCH 605/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.014056130153423		[learning rate: 0.0006792]
	Learning Rate: 0.000679204
	LOSS [training: 3.014056130153423 | validation: 3.013328924746285]
	TIME [epoch: 9.52 sec]
EPOCH 606/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0376918477768893		[learning rate: 0.00067592]
	Learning Rate: 0.000675919
	LOSS [training: 3.0376918477768893 | validation: 3.153373992669337]
	TIME [epoch: 9.51 sec]
EPOCH 607/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.9765170934744734		[learning rate: 0.00067265]
	Learning Rate: 0.000672651
	LOSS [training: 2.9765170934744734 | validation: 3.0350252870061127]
	TIME [epoch: 9.5 sec]
EPOCH 608/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8859771835241665		[learning rate: 0.0006694]
	Learning Rate: 0.000669398
	LOSS [training: 2.8859771835241665 | validation: 3.024504254408403]
	TIME [epoch: 9.52 sec]
EPOCH 609/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8968993028887624		[learning rate: 0.00066616]
	Learning Rate: 0.000666161
	LOSS [training: 2.8968993028887624 | validation: 3.2040539170520383]
	TIME [epoch: 9.5 sec]
EPOCH 610/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0801044547146814		[learning rate: 0.00066294]
	Learning Rate: 0.000662939
	LOSS [training: 3.0801044547146814 | validation: 3.2050751524192345]
	TIME [epoch: 9.5 sec]
EPOCH 611/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0574423736593035		[learning rate: 0.00065973]
	Learning Rate: 0.000659733
	LOSS [training: 3.0574423736593035 | validation: 3.2206695601846596]
	TIME [epoch: 9.5 sec]
EPOCH 612/1000:
	Training over batches...
		[batch 5/5] avg loss: 3.0498683822161254		[learning rate: 0.00065654]
	Learning Rate: 0.000656543
	LOSS [training: 3.0498683822161254 | validation: 3.1859373602222587]
	TIME [epoch: 9.52 sec]
EPOCH 613/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.992025246859977		[learning rate: 0.00065337]
	Learning Rate: 0.000653368
	LOSS [training: 2.992025246859977 | validation: 3.101435848520749]
	TIME [epoch: 9.5 sec]
EPOCH 614/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.955087880761552		[learning rate: 0.00065021]
	Learning Rate: 0.000650209
	LOSS [training: 2.955087880761552 | validation: 3.044590981277305]
	TIME [epoch: 9.5 sec]
EPOCH 615/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.89650267105164		[learning rate: 0.00064706]
	Learning Rate: 0.000647064
	LOSS [training: 2.89650267105164 | validation: 3.0470797120848054]
	TIME [epoch: 9.52 sec]
EPOCH 616/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.872976395121524		[learning rate: 0.00064394]
	Learning Rate: 0.000643935
	LOSS [training: 2.872976395121524 | validation: 3.0403280428947865]
	TIME [epoch: 9.5 sec]
EPOCH 617/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.864492529043908		[learning rate: 0.00064082]
	Learning Rate: 0.000640821
	LOSS [training: 2.864492529043908 | validation: 3.001236818020546]
	TIME [epoch: 9.5 sec]
EPOCH 618/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.803658730176495		[learning rate: 0.00063772]
	Learning Rate: 0.000637722
	LOSS [training: 2.803658730176495 | validation: 2.9871059496221535]
	TIME [epoch: 9.51 sec]
EPOCH 619/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7736820277842478		[learning rate: 0.00063464]
	Learning Rate: 0.000634638
	LOSS [training: 2.7736820277842478 | validation: 2.932603634695072]
	TIME [epoch: 9.51 sec]
EPOCH 620/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8189238144802933		[learning rate: 0.00063157]
	Learning Rate: 0.000631569
	LOSS [training: 2.8189238144802933 | validation: 3.0382541909747363]
	TIME [epoch: 9.5 sec]
EPOCH 621/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.817154792546126		[learning rate: 0.00062852]
	Learning Rate: 0.000628515
	LOSS [training: 2.817154792546126 | validation: 2.982480333849691]
	TIME [epoch: 9.5 sec]
EPOCH 622/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7919035885197263		[learning rate: 0.00062548]
	Learning Rate: 0.000625476
	LOSS [training: 2.7919035885197263 | validation: 2.9326290791589673]
	TIME [epoch: 9.52 sec]
EPOCH 623/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7588928962396624		[learning rate: 0.00062245]
	Learning Rate: 0.000622451
	LOSS [training: 2.7588928962396624 | validation: 2.968777368279627]
	TIME [epoch: 9.5 sec]
EPOCH 624/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7678245206181167		[learning rate: 0.00061944]
	Learning Rate: 0.000619441
	LOSS [training: 2.7678245206181167 | validation: 2.9277633255091007]
	TIME [epoch: 9.5 sec]
EPOCH 625/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.770786804286314		[learning rate: 0.00061645]
	Learning Rate: 0.000616445
	LOSS [training: 2.770786804286314 | validation: 2.969516344279408]
	TIME [epoch: 9.51 sec]
EPOCH 626/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8125796126560614		[learning rate: 0.00061346]
	Learning Rate: 0.000613465
	LOSS [training: 2.8125796126560614 | validation: 3.0430501895014426]
	TIME [epoch: 9.51 sec]
EPOCH 627/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8389129624125755		[learning rate: 0.0006105]
	Learning Rate: 0.000610498
	LOSS [training: 2.8389129624125755 | validation: 3.0729737398146804]
	TIME [epoch: 9.5 sec]
EPOCH 628/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.822461883091248		[learning rate: 0.00060755]
	Learning Rate: 0.000607546
	LOSS [training: 2.822461883091248 | validation: 2.991970192470277]
	TIME [epoch: 9.51 sec]
EPOCH 629/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.8323191585335543		[learning rate: 0.00060461]
	Learning Rate: 0.000604608
	LOSS [training: 2.8323191585335543 | validation: 2.924529091101876]
	TIME [epoch: 9.52 sec]
EPOCH 630/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.712867621191321		[learning rate: 0.00060168]
	Learning Rate: 0.000601684
	LOSS [training: 2.712867621191321 | validation: 2.911162020891037]
	TIME [epoch: 9.5 sec]
EPOCH 631/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.714209575709556		[learning rate: 0.00059877]
	Learning Rate: 0.000598774
	LOSS [training: 2.714209575709556 | validation: 2.9433524286712593]
	TIME [epoch: 9.5 sec]
EPOCH 632/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.729178802449316		[learning rate: 0.00059588]
	Learning Rate: 0.000595879
	LOSS [training: 2.729178802449316 | validation: 2.905042384777299]
	TIME [epoch: 9.51 sec]
EPOCH 633/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7199794956526544		[learning rate: 0.000593]
	Learning Rate: 0.000592997
	LOSS [training: 2.7199794956526544 | validation: 2.906302416412535]
	TIME [epoch: 9.52 sec]
EPOCH 634/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6974956683207285		[learning rate: 0.00059013]
	Learning Rate: 0.000590129
	LOSS [training: 2.6974956683207285 | validation: 2.8885261077759483]
	TIME [epoch: 9.51 sec]
EPOCH 635/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6824899800737443		[learning rate: 0.00058728]
	Learning Rate: 0.000587276
	LOSS [training: 2.6824899800737443 | validation: 2.89207620615916]
	TIME [epoch: 9.51 sec]
EPOCH 636/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.694121748848069		[learning rate: 0.00058444]
	Learning Rate: 0.000584436
	LOSS [training: 2.694121748848069 | validation: 2.8450620358531116]
	TIME [epoch: 9.52 sec]
EPOCH 637/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.669180303645013		[learning rate: 0.00058161]
	Learning Rate: 0.00058161
	LOSS [training: 2.669180303645013 | validation: 2.883701774466067]
	TIME [epoch: 9.5 sec]
EPOCH 638/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7148113615930987		[learning rate: 0.0005788]
	Learning Rate: 0.000578797
	LOSS [training: 2.7148113615930987 | validation: 2.917720807487155]
	TIME [epoch: 9.5 sec]
EPOCH 639/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6841439961223577		[learning rate: 0.000576]
	Learning Rate: 0.000575998
	LOSS [training: 2.6841439961223577 | validation: 2.883325853733073]
	TIME [epoch: 9.52 sec]
EPOCH 640/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6823530375696634		[learning rate: 0.00057321]
	Learning Rate: 0.000573213
	LOSS [training: 2.6823530375696634 | validation: 2.829342396997912]
	TIME [epoch: 9.5 sec]
EPOCH 641/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.674455757503599		[learning rate: 0.00057044]
	Learning Rate: 0.000570441
	LOSS [training: 2.674455757503599 | validation: 2.8382869650004046]
	TIME [epoch: 9.5 sec]
EPOCH 642/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6605988857708893		[learning rate: 0.00056768]
	Learning Rate: 0.000567682
	LOSS [training: 2.6605988857708893 | validation: 2.9107139253267427]
	TIME [epoch: 9.5 sec]
EPOCH 643/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7396484210498473		[learning rate: 0.00056494]
	Learning Rate: 0.000564937
	LOSS [training: 2.7396484210498473 | validation: 2.904125157563651]
	TIME [epoch: 9.53 sec]
EPOCH 644/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.729556874907568		[learning rate: 0.0005622]
	Learning Rate: 0.000562205
	LOSS [training: 2.729556874907568 | validation: 2.985098066847413]
	TIME [epoch: 9.5 sec]
EPOCH 645/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.738750423000858		[learning rate: 0.00055949]
	Learning Rate: 0.000559486
	LOSS [training: 2.738750423000858 | validation: 3.001490646096369]
	TIME [epoch: 9.5 sec]
EPOCH 646/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6971160776794703		[learning rate: 0.00055678]
	Learning Rate: 0.000556781
	LOSS [training: 2.6971160776794703 | validation: 2.898339241027935]
	TIME [epoch: 9.52 sec]
EPOCH 647/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7198343635705142		[learning rate: 0.00055409]
	Learning Rate: 0.000554088
	LOSS [training: 2.7198343635705142 | validation: 3.1915595971614996]
	TIME [epoch: 9.51 sec]
EPOCH 648/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.827987336501137		[learning rate: 0.00055141]
	Learning Rate: 0.000551409
	LOSS [training: 2.827987336501137 | validation: 3.0552974068988594]
	TIME [epoch: 9.51 sec]
EPOCH 649/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7542544149119346		[learning rate: 0.00054874]
	Learning Rate: 0.000548742
	LOSS [training: 2.7542544149119346 | validation: 3.012480681564129]
	TIME [epoch: 9.51 sec]
EPOCH 650/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.675699835381404		[learning rate: 0.00054609]
	Learning Rate: 0.000546089
	LOSS [training: 2.675699835381404 | validation: 2.8555356183270773]
	TIME [epoch: 9.52 sec]
EPOCH 651/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5796027747172854		[learning rate: 0.00054345]
	Learning Rate: 0.000543448
	LOSS [training: 2.5796027747172854 | validation: 2.6477860806242792]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_651.pth
	Model improved!!!
EPOCH 652/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5147233908152797		[learning rate: 0.00054082]
	Learning Rate: 0.00054082
	LOSS [training: 2.5147233908152797 | validation: 2.8049834638466282]
	TIME [epoch: 9.5 sec]
EPOCH 653/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.560217563081972		[learning rate: 0.0005382]
	Learning Rate: 0.000538205
	LOSS [training: 2.560217563081972 | validation: 2.802526567397075]
	TIME [epoch: 9.52 sec]
EPOCH 654/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.570799582007747		[learning rate: 0.0005356]
	Learning Rate: 0.000535602
	LOSS [training: 2.570799582007747 | validation: 2.737411104760771]
	TIME [epoch: 9.5 sec]
EPOCH 655/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5011273872820103		[learning rate: 0.00053301]
	Learning Rate: 0.000533012
	LOSS [training: 2.5011273872820103 | validation: 2.7011786353398115]
	TIME [epoch: 9.5 sec]
EPOCH 656/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.580120698746165		[learning rate: 0.00053043]
	Learning Rate: 0.000530434
	LOSS [training: 2.580120698746165 | validation: 2.8510642621762052]
	TIME [epoch: 9.51 sec]
EPOCH 657/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.532728418868585		[learning rate: 0.00052787]
	Learning Rate: 0.000527869
	LOSS [training: 2.532728418868585 | validation: 2.843635267786697]
	TIME [epoch: 9.53 sec]
EPOCH 658/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.60157644109944		[learning rate: 0.00052532]
	Learning Rate: 0.000525317
	LOSS [training: 2.60157644109944 | validation: 2.9047634227668535]
	TIME [epoch: 9.51 sec]
EPOCH 659/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5972284595030657		[learning rate: 0.00052278]
	Learning Rate: 0.000522776
	LOSS [training: 2.5972284595030657 | validation: 2.8557587757708593]
	TIME [epoch: 9.5 sec]
EPOCH 660/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6024862350596383		[learning rate: 0.00052025]
	Learning Rate: 0.000520248
	LOSS [training: 2.6024862350596383 | validation: 2.90538978478551]
	TIME [epoch: 9.52 sec]
EPOCH 661/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.598591267400817		[learning rate: 0.00051773]
	Learning Rate: 0.000517732
	LOSS [training: 2.598591267400817 | validation: 2.831836021201218]
	TIME [epoch: 9.51 sec]
EPOCH 662/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5530211641364353		[learning rate: 0.00051523]
	Learning Rate: 0.000515229
	LOSS [training: 2.5530211641364353 | validation: 2.825206172599103]
	TIME [epoch: 9.5 sec]
EPOCH 663/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6018505653978607		[learning rate: 0.00051274]
	Learning Rate: 0.000512737
	LOSS [training: 2.6018505653978607 | validation: 2.8000621924777316]
	TIME [epoch: 9.5 sec]
EPOCH 664/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.64349094142891		[learning rate: 0.00051026]
	Learning Rate: 0.000510258
	LOSS [training: 2.64349094142891 | validation: 2.7966291063522215]
	TIME [epoch: 9.52 sec]
EPOCH 665/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.552101764990283		[learning rate: 0.00050779]
	Learning Rate: 0.00050779
	LOSS [training: 2.552101764990283 | validation: 2.7912871324895856]
	TIME [epoch: 9.5 sec]
EPOCH 666/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5774997775072643		[learning rate: 0.00050533]
	Learning Rate: 0.000505334
	LOSS [training: 2.5774997775072643 | validation: 2.9108593267595952]
	TIME [epoch: 9.5 sec]
EPOCH 667/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6123963179821446		[learning rate: 0.00050289]
	Learning Rate: 0.000502891
	LOSS [training: 2.6123963179821446 | validation: 2.7807262530870727]
	TIME [epoch: 9.52 sec]
EPOCH 668/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5420538602511344		[learning rate: 0.00050046]
	Learning Rate: 0.000500459
	LOSS [training: 2.5420538602511344 | validation: 2.795355638555219]
	TIME [epoch: 9.5 sec]
EPOCH 669/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.581115402620482		[learning rate: 0.00049804]
	Learning Rate: 0.000498039
	LOSS [training: 2.581115402620482 | validation: 2.7968985533301445]
	TIME [epoch: 9.5 sec]
EPOCH 670/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.542177782542992		[learning rate: 0.00049563]
	Learning Rate: 0.00049563
	LOSS [training: 2.542177782542992 | validation: 2.7600621466424413]
	TIME [epoch: 9.5 sec]
EPOCH 671/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5683966234587476		[learning rate: 0.00049323]
	Learning Rate: 0.000493234
	LOSS [training: 2.5683966234587476 | validation: 2.77110363093672]
	TIME [epoch: 9.52 sec]
EPOCH 672/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.538997169107356		[learning rate: 0.00049085]
	Learning Rate: 0.000490848
	LOSS [training: 2.538997169107356 | validation: 2.9247445567027435]
	TIME [epoch: 9.5 sec]
EPOCH 673/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5921924087083483		[learning rate: 0.00048847]
	Learning Rate: 0.000488475
	LOSS [training: 2.5921924087083483 | validation: 2.875822240537764]
	TIME [epoch: 9.5 sec]
EPOCH 674/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.594422839920622		[learning rate: 0.00048611]
	Learning Rate: 0.000486113
	LOSS [training: 2.594422839920622 | validation: 2.7893403623600714]
	TIME [epoch: 9.52 sec]
EPOCH 675/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.649068000837242		[learning rate: 0.00048376]
	Learning Rate: 0.000483762
	LOSS [training: 2.649068000837242 | validation: 2.8732511912466796]
	TIME [epoch: 9.51 sec]
EPOCH 676/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.662206110043124		[learning rate: 0.00048142]
	Learning Rate: 0.000481422
	LOSS [training: 2.662206110043124 | validation: 2.9260850447579223]
	TIME [epoch: 9.5 sec]
EPOCH 677/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6237374215000573		[learning rate: 0.00047909]
	Learning Rate: 0.000479094
	LOSS [training: 2.6237374215000573 | validation: 2.952353435115148]
	TIME [epoch: 9.51 sec]
EPOCH 678/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6129094843331444		[learning rate: 0.00047678]
	Learning Rate: 0.000476777
	LOSS [training: 2.6129094843331444 | validation: 2.9245428992608082]
	TIME [epoch: 9.52 sec]
EPOCH 679/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.692448727283254		[learning rate: 0.00047447]
	Learning Rate: 0.000474472
	LOSS [training: 2.692448727283254 | validation: 2.8362166587829996]
	TIME [epoch: 9.5 sec]
EPOCH 680/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.585583983561476		[learning rate: 0.00047218]
	Learning Rate: 0.000472177
	LOSS [training: 2.585583983561476 | validation: 2.7403220705092974]
	TIME [epoch: 9.5 sec]
EPOCH 681/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4942381865352288		[learning rate: 0.00046989]
	Learning Rate: 0.000469894
	LOSS [training: 2.4942381865352288 | validation: 2.689860053947805]
	TIME [epoch: 9.52 sec]
EPOCH 682/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5260669376886042		[learning rate: 0.00046762]
	Learning Rate: 0.000467622
	LOSS [training: 2.5260669376886042 | validation: 2.781277969687285]
	TIME [epoch: 9.51 sec]
EPOCH 683/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5342501329683214		[learning rate: 0.00046536]
	Learning Rate: 0.00046536
	LOSS [training: 2.5342501329683214 | validation: 2.749726118823753]
	TIME [epoch: 9.51 sec]
EPOCH 684/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.521527513995517		[learning rate: 0.00046311]
	Learning Rate: 0.00046311
	LOSS [training: 2.521527513995517 | validation: 2.7772354113369797]
	TIME [epoch: 9.51 sec]
EPOCH 685/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.500687435612013		[learning rate: 0.00046087]
	Learning Rate: 0.000460871
	LOSS [training: 2.500687435612013 | validation: 2.788298396313217]
	TIME [epoch: 9.52 sec]
EPOCH 686/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5957482726090384		[learning rate: 0.00045864]
	Learning Rate: 0.000458642
	LOSS [training: 2.5957482726090384 | validation: 2.717492038524558]
	TIME [epoch: 9.5 sec]
EPOCH 687/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.48129534787375		[learning rate: 0.00045642]
	Learning Rate: 0.000456424
	LOSS [training: 2.48129534787375 | validation: 2.6045001282537736]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_687.pth
	Model improved!!!
EPOCH 688/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.551066528050714		[learning rate: 0.00045422]
	Learning Rate: 0.000454217
	LOSS [training: 2.551066528050714 | validation: 2.6536532179533237]
	TIME [epoch: 9.53 sec]
EPOCH 689/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.566930148899945		[learning rate: 0.00045202]
	Learning Rate: 0.00045202
	LOSS [training: 2.566930148899945 | validation: 2.8363092834810755]
	TIME [epoch: 9.51 sec]
EPOCH 690/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6324275479896495		[learning rate: 0.00044983]
	Learning Rate: 0.000449834
	LOSS [training: 2.6324275479896495 | validation: 2.7917995044797626]
	TIME [epoch: 9.5 sec]
EPOCH 691/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.617889850182987		[learning rate: 0.00044766]
	Learning Rate: 0.000447659
	LOSS [training: 2.617889850182987 | validation: 2.797836835879317]
	TIME [epoch: 9.51 sec]
EPOCH 692/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.765720011911381		[learning rate: 0.00044549]
	Learning Rate: 0.000445494
	LOSS [training: 2.765720011911381 | validation: 2.909614958160611]
	TIME [epoch: 9.52 sec]
EPOCH 693/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.802255334009133		[learning rate: 0.00044334]
	Learning Rate: 0.00044334
	LOSS [training: 2.802255334009133 | validation: 2.7916994519965015]
	TIME [epoch: 9.5 sec]
EPOCH 694/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.642367802065788		[learning rate: 0.0004412]
	Learning Rate: 0.000441196
	LOSS [training: 2.642367802065788 | validation: 2.7816728540998485]
	TIME [epoch: 9.5 sec]
EPOCH 695/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6186992690061386		[learning rate: 0.00043906]
	Learning Rate: 0.000439063
	LOSS [training: 2.6186992690061386 | validation: 2.6544589840259274]
	TIME [epoch: 9.52 sec]
EPOCH 696/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5250659347243345		[learning rate: 0.00043694]
	Learning Rate: 0.000436939
	LOSS [training: 2.5250659347243345 | validation: 2.6044113898530776]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_696.pth
	Model improved!!!
EPOCH 697/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.548057493319327		[learning rate: 0.00043483]
	Learning Rate: 0.000434826
	LOSS [training: 2.548057493319327 | validation: 2.692589423294633]
	TIME [epoch: 9.5 sec]
EPOCH 698/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5463367709800533		[learning rate: 0.00043272]
	Learning Rate: 0.000432724
	LOSS [training: 2.5463367709800533 | validation: 2.706793733933133]
	TIME [epoch: 9.51 sec]
EPOCH 699/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5002524681804594		[learning rate: 0.00043063]
	Learning Rate: 0.000430631
	LOSS [training: 2.5002524681804594 | validation: 2.6386223049466246]
	TIME [epoch: 9.5 sec]
EPOCH 700/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.449826633848196		[learning rate: 0.00042855]
	Learning Rate: 0.000428548
	LOSS [training: 2.449826633848196 | validation: 2.6275088854509887]
	TIME [epoch: 9.5 sec]
EPOCH 701/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.428954086851175		[learning rate: 0.00042648]
	Learning Rate: 0.000426476
	LOSS [training: 2.428954086851175 | validation: 2.7287071169111834]
	TIME [epoch: 9.49 sec]
EPOCH 702/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.493075900028314		[learning rate: 0.00042441]
	Learning Rate: 0.000424414
	LOSS [training: 2.493075900028314 | validation: 2.57256978754697]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_702.pth
	Model improved!!!
EPOCH 703/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4641379445301776		[learning rate: 0.00042236]
	Learning Rate: 0.000422361
	LOSS [training: 2.4641379445301776 | validation: 2.8078180164411344]
	TIME [epoch: 9.5 sec]
EPOCH 704/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4554108685420126		[learning rate: 0.00042032]
	Learning Rate: 0.000420319
	LOSS [training: 2.4554108685420126 | validation: 2.681228823286401]
	TIME [epoch: 9.5 sec]
EPOCH 705/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4535595773297922		[learning rate: 0.00041829]
	Learning Rate: 0.000418286
	LOSS [training: 2.4535595773297922 | validation: 2.777543575716783]
	TIME [epoch: 9.51 sec]
EPOCH 706/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4329514862142387		[learning rate: 0.00041626]
	Learning Rate: 0.000416264
	LOSS [training: 2.4329514862142387 | validation: 2.646201052857868]
	TIME [epoch: 9.5 sec]
EPOCH 707/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4257137724238698		[learning rate: 0.00041425]
	Learning Rate: 0.000414251
	LOSS [training: 2.4257137724238698 | validation: 2.6945996643766086]
	TIME [epoch: 9.5 sec]
EPOCH 708/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5248070673893777		[learning rate: 0.00041225]
	Learning Rate: 0.000412247
	LOSS [training: 2.5248070673893777 | validation: 2.7202480758437733]
	TIME [epoch: 9.5 sec]
EPOCH 709/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5475420265477835		[learning rate: 0.00041025]
	Learning Rate: 0.000410254
	LOSS [training: 2.5475420265477835 | validation: 2.621233861884734]
	TIME [epoch: 9.52 sec]
EPOCH 710/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5191245008217913		[learning rate: 0.00040827]
	Learning Rate: 0.00040827
	LOSS [training: 2.5191245008217913 | validation: 2.6715426237591475]
	TIME [epoch: 9.5 sec]
EPOCH 711/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.436483713430776		[learning rate: 0.0004063]
	Learning Rate: 0.000406296
	LOSS [training: 2.436483713430776 | validation: 2.6756888406952966]
	TIME [epoch: 9.5 sec]
EPOCH 712/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4273731003293126		[learning rate: 0.00040433]
	Learning Rate: 0.000404331
	LOSS [training: 2.4273731003293126 | validation: 2.629154971946117]
	TIME [epoch: 9.51 sec]
EPOCH 713/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.451012399897157		[learning rate: 0.00040238]
	Learning Rate: 0.000402376
	LOSS [training: 2.451012399897157 | validation: 2.6232727138248304]
	TIME [epoch: 9.51 sec]
EPOCH 714/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.451066598626363		[learning rate: 0.00040043]
	Learning Rate: 0.00040043
	LOSS [training: 2.451066598626363 | validation: 2.589990550931135]
	TIME [epoch: 9.5 sec]
EPOCH 715/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4186792968697657		[learning rate: 0.00039849]
	Learning Rate: 0.000398493
	LOSS [training: 2.4186792968697657 | validation: 2.709907713053914]
	TIME [epoch: 9.5 sec]
EPOCH 716/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4078930979400606		[learning rate: 0.00039657]
	Learning Rate: 0.000396566
	LOSS [training: 2.4078930979400606 | validation: 2.5645211366077625]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_716.pth
	Model improved!!!
EPOCH 717/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4178094831470016		[learning rate: 0.00039465]
	Learning Rate: 0.000394649
	LOSS [training: 2.4178094831470016 | validation: 2.67347311960393]
	TIME [epoch: 9.5 sec]
EPOCH 718/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4443100066080428		[learning rate: 0.00039274]
	Learning Rate: 0.00039274
	LOSS [training: 2.4443100066080428 | validation: 2.568275141196756]
	TIME [epoch: 9.49 sec]
EPOCH 719/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.458640418423827		[learning rate: 0.00039084]
	Learning Rate: 0.000390841
	LOSS [training: 2.458640418423827 | validation: 2.597251152267263]
	TIME [epoch: 9.51 sec]
EPOCH 720/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4143011783503434		[learning rate: 0.00038895]
	Learning Rate: 0.000388951
	LOSS [training: 2.4143011783503434 | validation: 2.65146027953963]
	TIME [epoch: 9.5 sec]
EPOCH 721/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4800141384764354		[learning rate: 0.00038707]
	Learning Rate: 0.00038707
	LOSS [training: 2.4800141384764354 | validation: 2.7538524006786442]
	TIME [epoch: 9.49 sec]
EPOCH 722/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4819704642838083		[learning rate: 0.0003852]
	Learning Rate: 0.000385198
	LOSS [training: 2.4819704642838083 | validation: 2.783901352357792]
	TIME [epoch: 9.49 sec]
EPOCH 723/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4824060248319575		[learning rate: 0.00038334]
	Learning Rate: 0.000383335
	LOSS [training: 2.4824060248319575 | validation: 2.726295399828607]
	TIME [epoch: 9.51 sec]
EPOCH 724/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.473281803967785		[learning rate: 0.00038148]
	Learning Rate: 0.000381482
	LOSS [training: 2.473281803967785 | validation: 2.6616297981609147]
	TIME [epoch: 9.5 sec]
EPOCH 725/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.429105671313085		[learning rate: 0.00037964]
	Learning Rate: 0.000379637
	LOSS [training: 2.429105671313085 | validation: 2.63344010123703]
	TIME [epoch: 9.5 sec]
EPOCH 726/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.435558956901903		[learning rate: 0.0003778]
	Learning Rate: 0.000377801
	LOSS [training: 2.435558956901903 | validation: 2.6230258377348497]
	TIME [epoch: 9.51 sec]
EPOCH 727/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4581704460579696		[learning rate: 0.00037597]
	Learning Rate: 0.000375974
	LOSS [training: 2.4581704460579696 | validation: 2.6394162807323394]
	TIME [epoch: 9.5 sec]
EPOCH 728/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4437093681235984		[learning rate: 0.00037416]
	Learning Rate: 0.000374156
	LOSS [training: 2.4437093681235984 | validation: 2.729459671514071]
	TIME [epoch: 9.5 sec]
EPOCH 729/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4514056894771485		[learning rate: 0.00037235]
	Learning Rate: 0.000372347
	LOSS [training: 2.4514056894771485 | validation: 2.6738686324204113]
	TIME [epoch: 9.5 sec]
EPOCH 730/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4404343285934984		[learning rate: 0.00037055]
	Learning Rate: 0.000370546
	LOSS [training: 2.4404343285934984 | validation: 2.716644743492875]
	TIME [epoch: 9.53 sec]
EPOCH 731/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.508974325623309		[learning rate: 0.00036875]
	Learning Rate: 0.000368754
	LOSS [training: 2.508974325623309 | validation: 2.7452172351229853]
	TIME [epoch: 9.5 sec]
EPOCH 732/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4659910300281114		[learning rate: 0.00036697]
	Learning Rate: 0.000366971
	LOSS [training: 2.4659910300281114 | validation: 2.7271704571666886]
	TIME [epoch: 9.5 sec]
EPOCH 733/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.478673118382803		[learning rate: 0.0003652]
	Learning Rate: 0.000365196
	LOSS [training: 2.478673118382803 | validation: 2.7700999078980613]
	TIME [epoch: 9.53 sec]
EPOCH 734/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5133305341186785		[learning rate: 0.00036343]
	Learning Rate: 0.00036343
	LOSS [training: 2.5133305341186785 | validation: 2.931855533666402]
	TIME [epoch: 9.51 sec]
EPOCH 735/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6373107359751513		[learning rate: 0.00036167]
	Learning Rate: 0.000361673
	LOSS [training: 2.6373107359751513 | validation: 2.8261317665582424]
	TIME [epoch: 9.51 sec]
EPOCH 736/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5498729709932895		[learning rate: 0.00035992]
	Learning Rate: 0.000359924
	LOSS [training: 2.5498729709932895 | validation: 2.7558457307043644]
	TIME [epoch: 9.51 sec]
EPOCH 737/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5623815336654188		[learning rate: 0.00035818]
	Learning Rate: 0.000358183
	LOSS [training: 2.5623815336654188 | validation: 2.8303795937691736]
	TIME [epoch: 9.53 sec]
EPOCH 738/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6018949506471896		[learning rate: 0.00035645]
	Learning Rate: 0.000356451
	LOSS [training: 2.6018949506471896 | validation: 2.8987057994856276]
	TIME [epoch: 9.51 sec]
EPOCH 739/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.7462950142269356		[learning rate: 0.00035473]
	Learning Rate: 0.000354727
	LOSS [training: 2.7462950142269356 | validation: 3.0554752202672297]
	TIME [epoch: 9.5 sec]
EPOCH 740/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.718367225604319		[learning rate: 0.00035301]
	Learning Rate: 0.000353012
	LOSS [training: 2.718367225604319 | validation: 3.006941413381586]
	TIME [epoch: 9.52 sec]
EPOCH 741/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.670982664462257		[learning rate: 0.0003513]
	Learning Rate: 0.000351305
	LOSS [training: 2.670982664462257 | validation: 3.098176987403016]
	TIME [epoch: 9.51 sec]
EPOCH 742/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.638196833315324		[learning rate: 0.00034961]
	Learning Rate: 0.000349606
	LOSS [training: 2.638196833315324 | validation: 3.046218412197512]
	TIME [epoch: 9.5 sec]
EPOCH 743/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.707882438812402		[learning rate: 0.00034792]
	Learning Rate: 0.000347915
	LOSS [training: 2.707882438812402 | validation: 3.0500856373022796]
	TIME [epoch: 9.5 sec]
EPOCH 744/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6616871695966795		[learning rate: 0.00034623]
	Learning Rate: 0.000346233
	LOSS [training: 2.6616871695966795 | validation: 2.995169860501626]
	TIME [epoch: 9.52 sec]
EPOCH 745/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.663039250790992		[learning rate: 0.00034456]
	Learning Rate: 0.000344559
	LOSS [training: 2.663039250790992 | validation: 3.0549869645855727]
	TIME [epoch: 9.51 sec]
EPOCH 746/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6871629459446096		[learning rate: 0.00034289]
	Learning Rate: 0.000342892
	LOSS [training: 2.6871629459446096 | validation: 3.036017638987632]
	TIME [epoch: 9.5 sec]
EPOCH 747/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6642296155782343		[learning rate: 0.00034123]
	Learning Rate: 0.000341234
	LOSS [training: 2.6642296155782343 | validation: 2.9568217761615965]
	TIME [epoch: 9.53 sec]
EPOCH 748/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.6263107932948198		[learning rate: 0.00033958]
	Learning Rate: 0.000339584
	LOSS [training: 2.6263107932948198 | validation: 2.7822667533816117]
	TIME [epoch: 9.51 sec]
EPOCH 749/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5524105378864204		[learning rate: 0.00033794]
	Learning Rate: 0.000337942
	LOSS [training: 2.5524105378864204 | validation: 2.7860606037511593]
	TIME [epoch: 9.5 sec]
EPOCH 750/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.521743214786755		[learning rate: 0.00033631]
	Learning Rate: 0.000336308
	LOSS [training: 2.521743214786755 | validation: 2.78660336398898]
	TIME [epoch: 9.51 sec]
EPOCH 751/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5289462457266807		[learning rate: 0.00033468]
	Learning Rate: 0.000334681
	LOSS [training: 2.5289462457266807 | validation: 2.8162868128179195]
	TIME [epoch: 9.52 sec]
EPOCH 752/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.54780409907844		[learning rate: 0.00033306]
	Learning Rate: 0.000333063
	LOSS [training: 2.54780409907844 | validation: 2.828444354925776]
	TIME [epoch: 9.49 sec]
EPOCH 753/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.560803983174161		[learning rate: 0.00033145]
	Learning Rate: 0.000331452
	LOSS [training: 2.560803983174161 | validation: 2.921057583933814]
	TIME [epoch: 9.5 sec]
EPOCH 754/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.631342761763701		[learning rate: 0.00032985]
	Learning Rate: 0.000329849
	LOSS [training: 2.631342761763701 | validation: 2.977183473511193]
	TIME [epoch: 9.52 sec]
EPOCH 755/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5897196932972326		[learning rate: 0.00032825]
	Learning Rate: 0.000328254
	LOSS [training: 2.5897196932972326 | validation: 2.759706775461982]
	TIME [epoch: 9.51 sec]
EPOCH 756/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.532953061114829		[learning rate: 0.00032667]
	Learning Rate: 0.000326667
	LOSS [training: 2.532953061114829 | validation: 2.763566515211356]
	TIME [epoch: 9.51 sec]
EPOCH 757/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5121778388983835		[learning rate: 0.00032509]
	Learning Rate: 0.000325087
	LOSS [training: 2.5121778388983835 | validation: 2.7945873736492515]
	TIME [epoch: 9.51 sec]
EPOCH 758/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5199028464569944		[learning rate: 0.00032352]
	Learning Rate: 0.000323515
	LOSS [training: 2.5199028464569944 | validation: 2.7017942150866645]
	TIME [epoch: 9.51 sec]
EPOCH 759/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4509207756699474		[learning rate: 0.00032195]
	Learning Rate: 0.000321951
	LOSS [training: 2.4509207756699474 | validation: 2.7499824151231724]
	TIME [epoch: 9.5 sec]
EPOCH 760/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5096609947952424		[learning rate: 0.00032039]
	Learning Rate: 0.000320394
	LOSS [training: 2.5096609947952424 | validation: 2.929072575772669]
	TIME [epoch: 9.5 sec]
EPOCH 761/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5366370159542404		[learning rate: 0.00031884]
	Learning Rate: 0.000318845
	LOSS [training: 2.5366370159542404 | validation: 2.787492702526698]
	TIME [epoch: 9.52 sec]
EPOCH 762/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5834594570108846		[learning rate: 0.0003173]
	Learning Rate: 0.000317303
	LOSS [training: 2.5834594570108846 | validation: 2.90173043735456]
	TIME [epoch: 9.51 sec]
EPOCH 763/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5934590070563113		[learning rate: 0.00031577]
	Learning Rate: 0.000315768
	LOSS [training: 2.5934590070563113 | validation: 2.817881190434539]
	TIME [epoch: 9.51 sec]
EPOCH 764/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5487482058095154		[learning rate: 0.00031424]
	Learning Rate: 0.000314241
	LOSS [training: 2.5487482058095154 | validation: 2.7596785154344627]
	TIME [epoch: 9.51 sec]
EPOCH 765/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5209370327317013		[learning rate: 0.00031272]
	Learning Rate: 0.000312722
	LOSS [training: 2.5209370327317013 | validation: 2.739753103385806]
	TIME [epoch: 9.52 sec]
EPOCH 766/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5042868703720096		[learning rate: 0.00031121]
	Learning Rate: 0.000311209
	LOSS [training: 2.5042868703720096 | validation: 2.7655267759427744]
	TIME [epoch: 9.5 sec]
EPOCH 767/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.506838603808572		[learning rate: 0.0003097]
	Learning Rate: 0.000309704
	LOSS [training: 2.506838603808572 | validation: 2.6462416647654745]
	TIME [epoch: 9.5 sec]
EPOCH 768/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4804496609428712		[learning rate: 0.00030821]
	Learning Rate: 0.000308207
	LOSS [training: 2.4804496609428712 | validation: 2.6787324334544467]
	TIME [epoch: 9.54 sec]
EPOCH 769/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.465573237635179		[learning rate: 0.00030672]
	Learning Rate: 0.000306716
	LOSS [training: 2.465573237635179 | validation: 2.702412106679387]
	TIME [epoch: 9.5 sec]
EPOCH 770/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4532428608049486		[learning rate: 0.00030523]
	Learning Rate: 0.000305233
	LOSS [training: 2.4532428608049486 | validation: 2.8024507101563074]
	TIME [epoch: 9.5 sec]
EPOCH 771/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4917397810095796		[learning rate: 0.00030376]
	Learning Rate: 0.000303757
	LOSS [training: 2.4917397810095796 | validation: 2.714882395497517]
	TIME [epoch: 9.51 sec]
EPOCH 772/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5186013259717095		[learning rate: 0.00030229]
	Learning Rate: 0.000302288
	LOSS [training: 2.5186013259717095 | validation: 2.900580306757862]
	TIME [epoch: 9.52 sec]
EPOCH 773/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5175085356413662		[learning rate: 0.00030083]
	Learning Rate: 0.000300826
	LOSS [training: 2.5175085356413662 | validation: 2.707305605255513]
	TIME [epoch: 9.5 sec]
EPOCH 774/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4516190860959446		[learning rate: 0.00029937]
	Learning Rate: 0.000299372
	LOSS [training: 2.4516190860959446 | validation: 2.6242399064181585]
	TIME [epoch: 9.5 sec]
EPOCH 775/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4788475265406262		[learning rate: 0.00029792]
	Learning Rate: 0.000297924
	LOSS [training: 2.4788475265406262 | validation: 2.6681166867566506]
	TIME [epoch: 9.54 sec]
EPOCH 776/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.508751757268048		[learning rate: 0.00029648]
	Learning Rate: 0.000296483
	LOSS [training: 2.508751757268048 | validation: 2.6997584770294862]
	TIME [epoch: 9.53 sec]
EPOCH 777/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.472001402520222		[learning rate: 0.00029505]
	Learning Rate: 0.000295049
	LOSS [training: 2.472001402520222 | validation: 2.6790678133963963]
	TIME [epoch: 9.52 sec]
EPOCH 778/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4393757097991715		[learning rate: 0.00029362]
	Learning Rate: 0.000293623
	LOSS [training: 2.4393757097991715 | validation: 2.7523001229695248]
	TIME [epoch: 9.52 sec]
EPOCH 779/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.454064597030834		[learning rate: 0.0002922]
	Learning Rate: 0.000292203
	LOSS [training: 2.454064597030834 | validation: 2.8125063081918165]
	TIME [epoch: 9.53 sec]
EPOCH 780/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5508099025202324		[learning rate: 0.00029079]
	Learning Rate: 0.00029079
	LOSS [training: 2.5508099025202324 | validation: 2.837795927405632]
	TIME [epoch: 9.52 sec]
EPOCH 781/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.538375236697036		[learning rate: 0.00028938]
	Learning Rate: 0.000289383
	LOSS [training: 2.538375236697036 | validation: 2.8201610090061466]
	TIME [epoch: 9.52 sec]
EPOCH 782/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.453606931424609		[learning rate: 0.00028798]
	Learning Rate: 0.000287984
	LOSS [training: 2.453606931424609 | validation: 2.7899014257434254]
	TIME [epoch: 9.53 sec]
EPOCH 783/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4986024572886367		[learning rate: 0.00028659]
	Learning Rate: 0.000286591
	LOSS [training: 2.4986024572886367 | validation: 2.807064011847308]
	TIME [epoch: 9.51 sec]
EPOCH 784/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5169363427317784		[learning rate: 0.00028521]
	Learning Rate: 0.000285205
	LOSS [training: 2.5169363427317784 | validation: 2.8657280449534928]
	TIME [epoch: 9.51 sec]
EPOCH 785/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5227335234396033		[learning rate: 0.00028383]
	Learning Rate: 0.000283826
	LOSS [training: 2.5227335234396033 | validation: 2.875744046879237]
	TIME [epoch: 9.53 sec]
EPOCH 786/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.530909703557706		[learning rate: 0.00028245]
	Learning Rate: 0.000282454
	LOSS [training: 2.530909703557706 | validation: 2.916936709545471]
	TIME [epoch: 9.51 sec]
EPOCH 787/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5301335954417814		[learning rate: 0.00028109]
	Learning Rate: 0.000281088
	LOSS [training: 2.5301335954417814 | validation: 2.806057754124822]
	TIME [epoch: 9.51 sec]
EPOCH 788/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.5653657516330624		[learning rate: 0.00027973]
	Learning Rate: 0.000279729
	LOSS [training: 2.5653657516330624 | validation: 2.808169627447824]
	TIME [epoch: 9.51 sec]
EPOCH 789/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.553344054984719		[learning rate: 0.00027838]
	Learning Rate: 0.000278376
	LOSS [training: 2.553344054984719 | validation: 2.786986332073409]
	TIME [epoch: 9.53 sec]
EPOCH 790/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.501888244215376		[learning rate: 0.00027703]
	Learning Rate: 0.00027703
	LOSS [training: 2.501888244215376 | validation: 2.7757121631689596]
	TIME [epoch: 9.52 sec]
EPOCH 791/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.497587551553749		[learning rate: 0.00027569]
	Learning Rate: 0.00027569
	LOSS [training: 2.497587551553749 | validation: 2.8562350398918217]
	TIME [epoch: 9.52 sec]
EPOCH 792/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.51574187810085		[learning rate: 0.00027436]
	Learning Rate: 0.000274357
	LOSS [training: 2.51574187810085 | validation: 2.857129771219306]
	TIME [epoch: 9.52 sec]
EPOCH 793/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4880938936936667		[learning rate: 0.00027303]
	Learning Rate: 0.00027303
	LOSS [training: 2.4880938936936667 | validation: 2.7903499894375976]
	TIME [epoch: 9.52 sec]
EPOCH 794/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4615963247345922		[learning rate: 0.00027171]
	Learning Rate: 0.00027171
	LOSS [training: 2.4615963247345922 | validation: 2.7424233113759886]
	TIME [epoch: 9.51 sec]
EPOCH 795/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.453312786028367		[learning rate: 0.0002704]
	Learning Rate: 0.000270396
	LOSS [training: 2.453312786028367 | validation: 2.631558725844528]
	TIME [epoch: 9.51 sec]
EPOCH 796/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4187030952710606		[learning rate: 0.00026909]
	Learning Rate: 0.000269088
	LOSS [training: 2.4187030952710606 | validation: 2.751048955220664]
	TIME [epoch: 9.53 sec]
EPOCH 797/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4139634105620305		[learning rate: 0.00026779]
	Learning Rate: 0.000267787
	LOSS [training: 2.4139634105620305 | validation: 2.6536713291606193]
	TIME [epoch: 9.51 sec]
EPOCH 798/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.436170552131218		[learning rate: 0.00026649]
	Learning Rate: 0.000266492
	LOSS [training: 2.436170552131218 | validation: 2.6924696755140722]
	TIME [epoch: 9.52 sec]
EPOCH 799/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4570076066405577		[learning rate: 0.0002652]
	Learning Rate: 0.000265203
	LOSS [training: 2.4570076066405577 | validation: 2.7081279317267595]
	TIME [epoch: 9.52 sec]
EPOCH 800/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4037496661072617		[learning rate: 0.00026392]
	Learning Rate: 0.000263921
	LOSS [training: 2.4037496661072617 | validation: 2.6178265473581144]
	TIME [epoch: 9.52 sec]
EPOCH 801/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4039785845419246		[learning rate: 0.00026264]
	Learning Rate: 0.000262645
	LOSS [training: 2.4039785845419246 | validation: 2.6776380864256657]
	TIME [epoch: 9.51 sec]
EPOCH 802/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4092127345200787		[learning rate: 0.00026137]
	Learning Rate: 0.000261374
	LOSS [training: 2.4092127345200787 | validation: 2.7203828697494163]
	TIME [epoch: 9.51 sec]
EPOCH 803/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3825974319925747		[learning rate: 0.00026011]
	Learning Rate: 0.00026011
	LOSS [training: 2.3825974319925747 | validation: 2.649572868213614]
	TIME [epoch: 9.54 sec]
EPOCH 804/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.393772253930186		[learning rate: 0.00025885]
	Learning Rate: 0.000258853
	LOSS [training: 2.393772253930186 | validation: 2.675500990270842]
	TIME [epoch: 9.51 sec]
EPOCH 805/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.378480365042642		[learning rate: 0.0002576]
	Learning Rate: 0.000257601
	LOSS [training: 2.378480365042642 | validation: 2.65447262721261]
	TIME [epoch: 9.51 sec]
EPOCH 806/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.405983246447395		[learning rate: 0.00025636]
	Learning Rate: 0.000256355
	LOSS [training: 2.405983246447395 | validation: 2.6364005502601593]
	TIME [epoch: 9.53 sec]
EPOCH 807/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3957095935179167		[learning rate: 0.00025512]
	Learning Rate: 0.000255115
	LOSS [training: 2.3957095935179167 | validation: 2.6405325090344536]
	TIME [epoch: 9.51 sec]
EPOCH 808/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3964204637580173		[learning rate: 0.00025388]
	Learning Rate: 0.000253882
	LOSS [training: 2.3964204637580173 | validation: 2.5509347773064053]
	TIME [epoch: 9.52 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_808.pth
	Model improved!!!
EPOCH 809/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4089658896757387		[learning rate: 0.00025265]
	Learning Rate: 0.000252654
	LOSS [training: 2.4089658896757387 | validation: 2.639837349340833]
	TIME [epoch: 9.51 sec]
EPOCH 810/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.390057121772931		[learning rate: 0.00025143]
	Learning Rate: 0.000251432
	LOSS [training: 2.390057121772931 | validation: 2.5936238294457215]
	TIME [epoch: 9.53 sec]
EPOCH 811/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3889260244266883		[learning rate: 0.00025022]
	Learning Rate: 0.000250216
	LOSS [training: 2.3889260244266883 | validation: 2.655092775910979]
	TIME [epoch: 9.51 sec]
EPOCH 812/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.421504168095363		[learning rate: 0.00024901]
	Learning Rate: 0.000249006
	LOSS [training: 2.421504168095363 | validation: 2.697553327872847]
	TIME [epoch: 9.51 sec]
EPOCH 813/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3973370412908728		[learning rate: 0.0002478]
	Learning Rate: 0.000247802
	LOSS [training: 2.3973370412908728 | validation: 2.6443117333556594]
	TIME [epoch: 9.53 sec]
EPOCH 814/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.410635698437043		[learning rate: 0.0002466]
	Learning Rate: 0.000246604
	LOSS [training: 2.410635698437043 | validation: 2.6424549641069093]
	TIME [epoch: 9.52 sec]
EPOCH 815/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4098732636805735		[learning rate: 0.00024541]
	Learning Rate: 0.000245411
	LOSS [training: 2.4098732636805735 | validation: 2.654485340367017]
	TIME [epoch: 9.5 sec]
EPOCH 816/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3774199268436966		[learning rate: 0.00024422]
	Learning Rate: 0.000244225
	LOSS [training: 2.3774199268436966 | validation: 2.5888277913321507]
	TIME [epoch: 9.5 sec]
EPOCH 817/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.379138111155611		[learning rate: 0.00024304]
	Learning Rate: 0.000243044
	LOSS [training: 2.379138111155611 | validation: 2.558294495283239]
	TIME [epoch: 9.52 sec]
EPOCH 818/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.397676485850151		[learning rate: 0.00024187]
	Learning Rate: 0.000241868
	LOSS [training: 2.397676485850151 | validation: 2.689769884741576]
	TIME [epoch: 9.5 sec]
EPOCH 819/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.420372886062463		[learning rate: 0.0002407]
	Learning Rate: 0.000240699
	LOSS [training: 2.420372886062463 | validation: 2.61707808616361]
	TIME [epoch: 9.51 sec]
EPOCH 820/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.408053730636735		[learning rate: 0.00023953]
	Learning Rate: 0.000239535
	LOSS [training: 2.408053730636735 | validation: 2.620798418427498]
	TIME [epoch: 9.53 sec]
EPOCH 821/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4179705369008695		[learning rate: 0.00023838]
	Learning Rate: 0.000238376
	LOSS [training: 2.4179705369008695 | validation: 2.6503941322722997]
	TIME [epoch: 9.51 sec]
EPOCH 822/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4391568460667727		[learning rate: 0.00023722]
	Learning Rate: 0.000237224
	LOSS [training: 2.4391568460667727 | validation: 2.5627110893451652]
	TIME [epoch: 9.51 sec]
EPOCH 823/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3950214093144675		[learning rate: 0.00023608]
	Learning Rate: 0.000236076
	LOSS [training: 2.3950214093144675 | validation: 2.6305826482168073]
	TIME [epoch: 9.51 sec]
EPOCH 824/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.399535032881171		[learning rate: 0.00023493]
	Learning Rate: 0.000234935
	LOSS [training: 2.399535032881171 | validation: 2.6644111888009196]
	TIME [epoch: 9.52 sec]
EPOCH 825/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4009377612547764		[learning rate: 0.0002338]
	Learning Rate: 0.000233799
	LOSS [training: 2.4009377612547764 | validation: 2.620337182285145]
	TIME [epoch: 9.51 sec]
EPOCH 826/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3621226554384838		[learning rate: 0.00023267]
	Learning Rate: 0.000232668
	LOSS [training: 2.3621226554384838 | validation: 2.5743172489783155]
	TIME [epoch: 9.51 sec]
EPOCH 827/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3562181191549705		[learning rate: 0.00023154]
	Learning Rate: 0.000231543
	LOSS [training: 2.3562181191549705 | validation: 2.5913259896665655]
	TIME [epoch: 9.52 sec]
EPOCH 828/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3506046782449816		[learning rate: 0.00023042]
	Learning Rate: 0.000230423
	LOSS [training: 2.3506046782449816 | validation: 2.5985962060147654]
	TIME [epoch: 9.51 sec]
EPOCH 829/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.36273913016011		[learning rate: 0.00022931]
	Learning Rate: 0.000229309
	LOSS [training: 2.36273913016011 | validation: 2.62095538005019]
	TIME [epoch: 9.52 sec]
EPOCH 830/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.320580455746274		[learning rate: 0.0002282]
	Learning Rate: 0.0002282
	LOSS [training: 2.320580455746274 | validation: 2.6030211882381242]
	TIME [epoch: 9.52 sec]
EPOCH 831/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.317728495751989		[learning rate: 0.0002271]
	Learning Rate: 0.000227097
	LOSS [training: 2.317728495751989 | validation: 2.619252103191982]
	TIME [epoch: 9.52 sec]
EPOCH 832/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.347281955268493		[learning rate: 0.000226]
	Learning Rate: 0.000225998
	LOSS [training: 2.347281955268493 | validation: 2.6025837972062082]
	TIME [epoch: 9.51 sec]
EPOCH 833/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.360405071463948		[learning rate: 0.00022491]
	Learning Rate: 0.000224905
	LOSS [training: 2.360405071463948 | validation: 2.594092892104551]
	TIME [epoch: 9.5 sec]
EPOCH 834/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3552910964916824		[learning rate: 0.00022382]
	Learning Rate: 0.000223818
	LOSS [training: 2.3552910964916824 | validation: 2.6473779241180013]
	TIME [epoch: 9.53 sec]
EPOCH 835/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3698347408801936		[learning rate: 0.00022274]
	Learning Rate: 0.000222736
	LOSS [training: 2.3698347408801936 | validation: 2.598731076176092]
	TIME [epoch: 9.51 sec]
EPOCH 836/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3780915607713746		[learning rate: 0.00022166]
	Learning Rate: 0.000221658
	LOSS [training: 2.3780915607713746 | validation: 2.5809674049111404]
	TIME [epoch: 9.51 sec]
EPOCH 837/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3321510257216684		[learning rate: 0.00022059]
	Learning Rate: 0.000220587
	LOSS [training: 2.3321510257216684 | validation: 2.660474163555615]
	TIME [epoch: 9.51 sec]
EPOCH 838/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.349989324514834		[learning rate: 0.00021952]
	Learning Rate: 0.00021952
	LOSS [training: 2.349989324514834 | validation: 2.640255586410357]
	TIME [epoch: 9.52 sec]
EPOCH 839/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3826446896040165		[learning rate: 0.00021846]
	Learning Rate: 0.000218458
	LOSS [training: 2.3826446896040165 | validation: 2.5706327672183558]
	TIME [epoch: 9.51 sec]
EPOCH 840/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.347502888359171		[learning rate: 0.0002174]
	Learning Rate: 0.000217402
	LOSS [training: 2.347502888359171 | validation: 2.5171242072714266]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_840.pth
	Model improved!!!
EPOCH 841/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3554759087620876		[learning rate: 0.00021635]
	Learning Rate: 0.00021635
	LOSS [training: 2.3554759087620876 | validation: 2.564194604982769]
	TIME [epoch: 9.53 sec]
EPOCH 842/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.338459121184172		[learning rate: 0.0002153]
	Learning Rate: 0.000215304
	LOSS [training: 2.338459121184172 | validation: 2.562494175036769]
	TIME [epoch: 9.51 sec]
EPOCH 843/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.347516303002611		[learning rate: 0.00021426]
	Learning Rate: 0.000214263
	LOSS [training: 2.347516303002611 | validation: 2.7128590699608446]
	TIME [epoch: 9.5 sec]
EPOCH 844/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3346332196631203		[learning rate: 0.00021323]
	Learning Rate: 0.000213227
	LOSS [training: 2.3346332196631203 | validation: 2.670892995551776]
	TIME [epoch: 9.51 sec]
EPOCH 845/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.338296926005302		[learning rate: 0.0002122]
	Learning Rate: 0.000212196
	LOSS [training: 2.338296926005302 | validation: 2.544131138219887]
	TIME [epoch: 9.52 sec]
EPOCH 846/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.334061121854043		[learning rate: 0.00021117]
	Learning Rate: 0.00021117
	LOSS [training: 2.334061121854043 | validation: 2.5452703472900122]
	TIME [epoch: 9.51 sec]
EPOCH 847/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.336845195458703		[learning rate: 0.00021015]
	Learning Rate: 0.000210149
	LOSS [training: 2.336845195458703 | validation: 2.549802803693704]
	TIME [epoch: 9.51 sec]
EPOCH 848/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.336318068604933		[learning rate: 0.00020913]
	Learning Rate: 0.000209132
	LOSS [training: 2.336318068604933 | validation: 2.508395988125292]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_848.pth
	Model improved!!!
EPOCH 849/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.33144739732587		[learning rate: 0.00020812]
	Learning Rate: 0.000208121
	LOSS [training: 2.33144739732587 | validation: 2.5153964499542747]
	TIME [epoch: 9.51 sec]
EPOCH 850/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.346737977422774		[learning rate: 0.00020711]
	Learning Rate: 0.000207114
	LOSS [training: 2.346737977422774 | validation: 2.4971931545128934]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_850.pth
	Model improved!!!
EPOCH 851/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3078767144994727		[learning rate: 0.00020611]
	Learning Rate: 0.000206113
	LOSS [training: 2.3078767144994727 | validation: 2.5315483801586254]
	TIME [epoch: 9.52 sec]
EPOCH 852/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.32325764643314		[learning rate: 0.00020512]
	Learning Rate: 0.000205116
	LOSS [training: 2.32325764643314 | validation: 2.561418337501544]
	TIME [epoch: 9.52 sec]
EPOCH 853/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.327581221821073		[learning rate: 0.00020412]
	Learning Rate: 0.000204124
	LOSS [training: 2.327581221821073 | validation: 2.6498277661767164]
	TIME [epoch: 9.5 sec]
EPOCH 854/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3181504893719893		[learning rate: 0.00020314]
	Learning Rate: 0.000203137
	LOSS [training: 2.3181504893719893 | validation: 2.519748234946164]
	TIME [epoch: 9.51 sec]
EPOCH 855/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.314430820161035		[learning rate: 0.00020215]
	Learning Rate: 0.000202155
	LOSS [training: 2.314430820161035 | validation: 2.575260909779449]
	TIME [epoch: 9.53 sec]
EPOCH 856/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3226138377450853		[learning rate: 0.00020118]
	Learning Rate: 0.000201177
	LOSS [training: 2.3226138377450853 | validation: 2.628279565171048]
	TIME [epoch: 9.52 sec]
EPOCH 857/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3477793006269865		[learning rate: 0.0002002]
	Learning Rate: 0.000200204
	LOSS [training: 2.3477793006269865 | validation: 2.5371671088415257]
	TIME [epoch: 9.51 sec]
EPOCH 858/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.374500488473788		[learning rate: 0.00019924]
	Learning Rate: 0.000199236
	LOSS [training: 2.374500488473788 | validation: 2.5513410142317747]
	TIME [epoch: 9.52 sec]
EPOCH 859/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3426406395431583		[learning rate: 0.00019827]
	Learning Rate: 0.000198273
	LOSS [training: 2.3426406395431583 | validation: 2.6234361094793766]
	TIME [epoch: 9.52 sec]
EPOCH 860/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3240217942987758		[learning rate: 0.00019731]
	Learning Rate: 0.000197314
	LOSS [training: 2.3240217942987758 | validation: 2.5935467502468197]
	TIME [epoch: 9.51 sec]
EPOCH 861/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3516432756974788		[learning rate: 0.00019636]
	Learning Rate: 0.00019636
	LOSS [training: 2.3516432756974788 | validation: 2.5362479108390965]
	TIME [epoch: 9.51 sec]
EPOCH 862/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.36588510916276		[learning rate: 0.00019541]
	Learning Rate: 0.00019541
	LOSS [training: 2.36588510916276 | validation: 2.68663508210538]
	TIME [epoch: 9.52 sec]
EPOCH 863/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.383323427943657		[learning rate: 0.00019447]
	Learning Rate: 0.000194465
	LOSS [training: 2.383323427943657 | validation: 2.665692359846617]
	TIME [epoch: 9.51 sec]
EPOCH 864/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.356355728066804		[learning rate: 0.00019352]
	Learning Rate: 0.000193525
	LOSS [training: 2.356355728066804 | validation: 2.6110059693981986]
	TIME [epoch: 9.51 sec]
EPOCH 865/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.324555186787746		[learning rate: 0.00019259]
	Learning Rate: 0.000192589
	LOSS [training: 2.324555186787746 | validation: 2.6005350677437264]
	TIME [epoch: 9.53 sec]
EPOCH 866/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3665212872823678		[learning rate: 0.00019166]
	Learning Rate: 0.000191658
	LOSS [training: 2.3665212872823678 | validation: 2.6157145334055554]
	TIME [epoch: 9.52 sec]
EPOCH 867/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.315074743764254		[learning rate: 0.00019073]
	Learning Rate: 0.000190731
	LOSS [training: 2.315074743764254 | validation: 2.6081771164570298]
	TIME [epoch: 9.5 sec]
EPOCH 868/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3204114367196467		[learning rate: 0.00018981]
	Learning Rate: 0.000189809
	LOSS [training: 2.3204114367196467 | validation: 2.5498525719915173]
	TIME [epoch: 9.52 sec]
EPOCH 869/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.348528079736912		[learning rate: 0.00018889]
	Learning Rate: 0.000188891
	LOSS [training: 2.348528079736912 | validation: 2.617158913797211]
	TIME [epoch: 9.52 sec]
EPOCH 870/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3576519009471895		[learning rate: 0.00018798]
	Learning Rate: 0.000187977
	LOSS [training: 2.3576519009471895 | validation: 2.505638490303287]
	TIME [epoch: 9.51 sec]
EPOCH 871/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.339363092691356		[learning rate: 0.00018707]
	Learning Rate: 0.000187068
	LOSS [training: 2.339363092691356 | validation: 2.675524681489651]
	TIME [epoch: 9.51 sec]
EPOCH 872/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.37505455182114		[learning rate: 0.00018616]
	Learning Rate: 0.000186164
	LOSS [training: 2.37505455182114 | validation: 2.657095020535445]
	TIME [epoch: 9.53 sec]
EPOCH 873/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.349595011759811		[learning rate: 0.00018526]
	Learning Rate: 0.000185263
	LOSS [training: 2.349595011759811 | validation: 2.622422502699169]
	TIME [epoch: 9.51 sec]
EPOCH 874/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.338373064664105		[learning rate: 0.00018437]
	Learning Rate: 0.000184367
	LOSS [training: 2.338373064664105 | validation: 2.586248002582679]
	TIME [epoch: 9.51 sec]
EPOCH 875/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3838162041272475		[learning rate: 0.00018348]
	Learning Rate: 0.000183476
	LOSS [training: 2.3838162041272475 | validation: 2.694473608358494]
	TIME [epoch: 9.51 sec]
EPOCH 876/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3668691786273213		[learning rate: 0.00018259]
	Learning Rate: 0.000182589
	LOSS [training: 2.3668691786273213 | validation: 2.616830524689126]
	TIME [epoch: 9.53 sec]
EPOCH 877/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3447501024054924		[learning rate: 0.00018171]
	Learning Rate: 0.000181706
	LOSS [training: 2.3447501024054924 | validation: 2.6373485982684826]
	TIME [epoch: 9.51 sec]
EPOCH 878/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3706402614444757		[learning rate: 0.00018083]
	Learning Rate: 0.000180827
	LOSS [training: 2.3706402614444757 | validation: 2.69676996066455]
	TIME [epoch: 9.51 sec]
EPOCH 879/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3453869728550956		[learning rate: 0.00017995]
	Learning Rate: 0.000179953
	LOSS [training: 2.3453869728550956 | validation: 2.7097351489202857]
	TIME [epoch: 9.53 sec]
EPOCH 880/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3418411284135034		[learning rate: 0.00017908]
	Learning Rate: 0.000179082
	LOSS [training: 2.3418411284135034 | validation: 2.6293815140901393]
	TIME [epoch: 9.51 sec]
EPOCH 881/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3180988675963787		[learning rate: 0.00017822]
	Learning Rate: 0.000178216
	LOSS [training: 2.3180988675963787 | validation: 2.5825952333445366]
	TIME [epoch: 9.51 sec]
EPOCH 882/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2983159538544884		[learning rate: 0.00017735]
	Learning Rate: 0.000177354
	LOSS [training: 2.2983159538544884 | validation: 2.5076368938353073]
	TIME [epoch: 9.52 sec]
EPOCH 883/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3072742190272537		[learning rate: 0.0001765]
	Learning Rate: 0.000176497
	LOSS [training: 2.3072742190272537 | validation: 2.522971233251096]
	TIME [epoch: 9.54 sec]
EPOCH 884/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.31243407181428		[learning rate: 0.00017564]
	Learning Rate: 0.000175643
	LOSS [training: 2.31243407181428 | validation: 2.604030925583736]
	TIME [epoch: 9.51 sec]
EPOCH 885/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.298470081561444		[learning rate: 0.00017479]
	Learning Rate: 0.000174794
	LOSS [training: 2.298470081561444 | validation: 2.594822009597258]
	TIME [epoch: 9.51 sec]
EPOCH 886/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3204842347070924		[learning rate: 0.00017395]
	Learning Rate: 0.000173949
	LOSS [training: 2.3204842347070924 | validation: 2.562844570653686]
	TIME [epoch: 9.53 sec]
EPOCH 887/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3353337839219073		[learning rate: 0.00017311]
	Learning Rate: 0.000173107
	LOSS [training: 2.3353337839219073 | validation: 2.6172734925384815]
	TIME [epoch: 9.51 sec]
EPOCH 888/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.307616261984678		[learning rate: 0.00017227]
	Learning Rate: 0.00017227
	LOSS [training: 2.307616261984678 | validation: 2.621555396885255]
	TIME [epoch: 9.5 sec]
EPOCH 889/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3377785922933056		[learning rate: 0.00017144]
	Learning Rate: 0.000171437
	LOSS [training: 2.3377785922933056 | validation: 2.5229517806557307]
	TIME [epoch: 9.5 sec]
EPOCH 890/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3283916699018476		[learning rate: 0.00017061]
	Learning Rate: 0.000170608
	LOSS [training: 2.3283916699018476 | validation: 2.48963858241696]
	TIME [epoch: 9.53 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_890.pth
	Model improved!!!
EPOCH 891/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.296011139022919		[learning rate: 0.00016978]
	Learning Rate: 0.000169783
	LOSS [training: 2.296011139022919 | validation: 2.564654926827657]
	TIME [epoch: 9.5 sec]
EPOCH 892/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3396529552100302		[learning rate: 0.00016896]
	Learning Rate: 0.000168962
	LOSS [training: 2.3396529552100302 | validation: 2.585451603839398]
	TIME [epoch: 9.5 sec]
EPOCH 893/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.280860099963051		[learning rate: 0.00016815]
	Learning Rate: 0.000168145
	LOSS [training: 2.280860099963051 | validation: 2.494700203549744]
	TIME [epoch: 9.52 sec]
EPOCH 894/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3141014504608073		[learning rate: 0.00016733]
	Learning Rate: 0.000167332
	LOSS [training: 2.3141014504608073 | validation: 2.5626234623393964]
	TIME [epoch: 9.5 sec]
EPOCH 895/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.320819047891806		[learning rate: 0.00016652]
	Learning Rate: 0.000166523
	LOSS [training: 2.320819047891806 | validation: 2.5295085361913663]
	TIME [epoch: 9.5 sec]
EPOCH 896/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2741363116236		[learning rate: 0.00016572]
	Learning Rate: 0.000165718
	LOSS [training: 2.2741363116236 | validation: 2.486640933385142]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_896.pth
	Model improved!!!
EPOCH 897/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.28022404371223		[learning rate: 0.00016492]
	Learning Rate: 0.000164916
	LOSS [training: 2.28022404371223 | validation: 2.517365878051621]
	TIME [epoch: 9.52 sec]
EPOCH 898/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3050377062089007		[learning rate: 0.00016412]
	Learning Rate: 0.000164119
	LOSS [training: 2.3050377062089007 | validation: 2.464664937378903]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_898.pth
	Model improved!!!
EPOCH 899/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2873257346173395		[learning rate: 0.00016332]
	Learning Rate: 0.000163325
	LOSS [training: 2.2873257346173395 | validation: 2.450971110101857]
	TIME [epoch: 9.51 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_899.pth
	Model improved!!!
EPOCH 900/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.277488271136201		[learning rate: 0.00016254]
	Learning Rate: 0.000162535
	LOSS [training: 2.277488271136201 | validation: 2.5532845793702914]
	TIME [epoch: 9.53 sec]
EPOCH 901/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2856453526790936		[learning rate: 0.00016175]
	Learning Rate: 0.000161749
	LOSS [training: 2.2856453526790936 | validation: 2.515058425357252]
	TIME [epoch: 9.5 sec]
EPOCH 902/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2707522784620355		[learning rate: 0.00016097]
	Learning Rate: 0.000160967
	LOSS [training: 2.2707522784620355 | validation: 2.496025214773634]
	TIME [epoch: 9.5 sec]
EPOCH 903/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2929898184451285		[learning rate: 0.00016019]
	Learning Rate: 0.000160189
	LOSS [training: 2.2929898184451285 | validation: 2.494850496032922]
	TIME [epoch: 9.51 sec]
EPOCH 904/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2680267080008956		[learning rate: 0.00015941]
	Learning Rate: 0.000159414
	LOSS [training: 2.2680267080008956 | validation: 2.4848291007607117]
	TIME [epoch: 9.53 sec]
EPOCH 905/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2882964085939914		[learning rate: 0.00015864]
	Learning Rate: 0.000158643
	LOSS [training: 2.2882964085939914 | validation: 2.496084561678473]
	TIME [epoch: 9.51 sec]
EPOCH 906/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3119224401025207		[learning rate: 0.00015788]
	Learning Rate: 0.000157876
	LOSS [training: 2.3119224401025207 | validation: 2.475629874058514]
	TIME [epoch: 9.5 sec]
EPOCH 907/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.316259892202482		[learning rate: 0.00015711]
	Learning Rate: 0.000157112
	LOSS [training: 2.316259892202482 | validation: 2.5598452625712302]
	TIME [epoch: 9.52 sec]
EPOCH 908/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.328428596786258		[learning rate: 0.00015635]
	Learning Rate: 0.000156353
	LOSS [training: 2.328428596786258 | validation: 2.569632532713039]
	TIME [epoch: 9.5 sec]
EPOCH 909/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.316279066135402		[learning rate: 0.0001556]
	Learning Rate: 0.000155597
	LOSS [training: 2.316279066135402 | validation: 2.4271209051271234]
	TIME [epoch: 9.5 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_909.pth
	Model improved!!!
EPOCH 910/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2769152448181473		[learning rate: 0.00015484]
	Learning Rate: 0.000154844
	LOSS [training: 2.2769152448181473 | validation: 2.47815378731904]
	TIME [epoch: 9.51 sec]
EPOCH 911/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2775878907042038		[learning rate: 0.0001541]
	Learning Rate: 0.000154095
	LOSS [training: 2.2775878907042038 | validation: 2.4861813221947604]
	TIME [epoch: 9.51 sec]
EPOCH 912/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2753166269496936		[learning rate: 0.00015335]
	Learning Rate: 0.00015335
	LOSS [training: 2.2753166269496936 | validation: 2.51865995001832]
	TIME [epoch: 9.5 sec]
EPOCH 913/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2626038793517775		[learning rate: 0.00015261]
	Learning Rate: 0.000152609
	LOSS [training: 2.2626038793517775 | validation: 2.4855508967736375]
	TIME [epoch: 9.49 sec]
EPOCH 914/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2671312481631736		[learning rate: 0.00015187]
	Learning Rate: 0.000151871
	LOSS [training: 2.2671312481631736 | validation: 2.5314669294841137]
	TIME [epoch: 9.52 sec]
EPOCH 915/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2648726710727765		[learning rate: 0.00015114]
	Learning Rate: 0.000151136
	LOSS [training: 2.2648726710727765 | validation: 2.465635997892068]
	TIME [epoch: 9.49 sec]
EPOCH 916/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.249815741829643		[learning rate: 0.00015041]
	Learning Rate: 0.000150405
	LOSS [training: 2.249815741829643 | validation: 2.487291825773235]
	TIME [epoch: 9.5 sec]
EPOCH 917/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2406272075772202		[learning rate: 0.00014968]
	Learning Rate: 0.000149678
	LOSS [training: 2.2406272075772202 | validation: 2.4872892223068366]
	TIME [epoch: 9.52 sec]
EPOCH 918/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2462942813571583		[learning rate: 0.00014895]
	Learning Rate: 0.000148954
	LOSS [training: 2.2462942813571583 | validation: 2.428287586818783]
	TIME [epoch: 9.51 sec]
EPOCH 919/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.280380287712033		[learning rate: 0.00014823]
	Learning Rate: 0.000148234
	LOSS [training: 2.280380287712033 | validation: 2.5301189415586403]
	TIME [epoch: 9.49 sec]
EPOCH 920/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.263019837780875		[learning rate: 0.00014752]
	Learning Rate: 0.000147517
	LOSS [training: 2.263019837780875 | validation: 2.494494482227863]
	TIME [epoch: 9.49 sec]
EPOCH 921/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.251982207600629		[learning rate: 0.0001468]
	Learning Rate: 0.000146804
	LOSS [training: 2.251982207600629 | validation: 2.472500624258134]
	TIME [epoch: 9.51 sec]
EPOCH 922/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.251354905428046		[learning rate: 0.00014609]
	Learning Rate: 0.000146094
	LOSS [training: 2.251354905428046 | validation: 2.4398334640238266]
	TIME [epoch: 9.5 sec]
EPOCH 923/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.23170274794209		[learning rate: 0.00014539]
	Learning Rate: 0.000145387
	LOSS [training: 2.23170274794209 | validation: 2.541854139134072]
	TIME [epoch: 9.49 sec]
EPOCH 924/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2376160726150722		[learning rate: 0.00014468]
	Learning Rate: 0.000144684
	LOSS [training: 2.2376160726150722 | validation: 2.492005962614096]
	TIME [epoch: 9.51 sec]
EPOCH 925/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.254592470399864		[learning rate: 0.00014398]
	Learning Rate: 0.000143985
	LOSS [training: 2.254592470399864 | validation: 2.48274562855309]
	TIME [epoch: 9.5 sec]
EPOCH 926/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.245044815487611		[learning rate: 0.00014329]
	Learning Rate: 0.000143288
	LOSS [training: 2.245044815487611 | validation: 2.504952510987461]
	TIME [epoch: 9.5 sec]
EPOCH 927/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2514027192381323		[learning rate: 0.0001426]
	Learning Rate: 0.000142595
	LOSS [training: 2.2514027192381323 | validation: 2.3924772274917125]
	TIME [epoch: 9.49 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r0_20240217_140924/states/model_tr_study6_927.pth
	Model improved!!!
EPOCH 928/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3212418648799336		[learning rate: 0.00014191]
	Learning Rate: 0.000141906
	LOSS [training: 2.3212418648799336 | validation: 2.4730171104403285]
	TIME [epoch: 9.53 sec]
EPOCH 929/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.231571374015471		[learning rate: 0.00014122]
	Learning Rate: 0.000141219
	LOSS [training: 2.231571374015471 | validation: 2.467866409389369]
	TIME [epoch: 9.51 sec]
EPOCH 930/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2532441739954194		[learning rate: 0.00014054]
	Learning Rate: 0.000140537
	LOSS [training: 2.2532441739954194 | validation: 2.516463956202808]
	TIME [epoch: 9.5 sec]
EPOCH 931/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.25166212737978		[learning rate: 0.00013986]
	Learning Rate: 0.000139857
	LOSS [training: 2.25166212737978 | validation: 2.5718553271863303]
	TIME [epoch: 9.51 sec]
EPOCH 932/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.226637746282054		[learning rate: 0.00013918]
	Learning Rate: 0.000139181
	LOSS [training: 2.226637746282054 | validation: 2.5276288583017283]
	TIME [epoch: 9.49 sec]
EPOCH 933/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2506994888854854		[learning rate: 0.00013851]
	Learning Rate: 0.000138508
	LOSS [training: 2.2506994888854854 | validation: 2.5042727275180034]
	TIME [epoch: 9.5 sec]
EPOCH 934/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2330110214830468		[learning rate: 0.00013784]
	Learning Rate: 0.000137838
	LOSS [training: 2.2330110214830468 | validation: 2.464775175093233]
	TIME [epoch: 9.49 sec]
EPOCH 935/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.243010638593328		[learning rate: 0.00013717]
	Learning Rate: 0.000137171
	LOSS [training: 2.243010638593328 | validation: 2.521378053087055]
	TIME [epoch: 9.52 sec]
EPOCH 936/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2710776021195165		[learning rate: 0.00013651]
	Learning Rate: 0.000136508
	LOSS [training: 2.2710776021195165 | validation: 2.631254406861409]
	TIME [epoch: 9.5 sec]
EPOCH 937/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.263200970648292		[learning rate: 0.00013585]
	Learning Rate: 0.000135848
	LOSS [training: 2.263200970648292 | validation: 2.514150170197127]
	TIME [epoch: 9.5 sec]
EPOCH 938/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2229659480042754		[learning rate: 0.00013519]
	Learning Rate: 0.000135191
	LOSS [training: 2.2229659480042754 | validation: 2.557513155547648]
	TIME [epoch: 9.52 sec]
EPOCH 939/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.27885711514199		[learning rate: 0.00013454]
	Learning Rate: 0.000134537
	LOSS [training: 2.27885711514199 | validation: 2.5839328116525895]
	TIME [epoch: 9.49 sec]
EPOCH 940/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.226663427868917		[learning rate: 0.00013389]
	Learning Rate: 0.000133887
	LOSS [training: 2.226663427868917 | validation: 2.6041831868307894]
	TIME [epoch: 9.5 sec]
EPOCH 941/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2479181111554354		[learning rate: 0.00013324]
	Learning Rate: 0.000133239
	LOSS [training: 2.2479181111554354 | validation: 2.5774570714334004]
	TIME [epoch: 9.5 sec]
EPOCH 942/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.244091489503064		[learning rate: 0.00013259]
	Learning Rate: 0.000132595
	LOSS [training: 2.244091489503064 | validation: 2.4895648450006784]
	TIME [epoch: 9.52 sec]
EPOCH 943/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.290671586098488		[learning rate: 0.00013195]
	Learning Rate: 0.000131954
	LOSS [training: 2.290671586098488 | validation: 2.6154940214309863]
	TIME [epoch: 9.49 sec]
EPOCH 944/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2970001322707945		[learning rate: 0.00013132]
	Learning Rate: 0.000131315
	LOSS [training: 2.2970001322707945 | validation: 2.4842806480512305]
	TIME [epoch: 9.5 sec]
EPOCH 945/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.311694162403249		[learning rate: 0.00013068]
	Learning Rate: 0.00013068
	LOSS [training: 2.311694162403249 | validation: 2.5608825794789336]
	TIME [epoch: 9.51 sec]
EPOCH 946/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.34231931992311		[learning rate: 0.00013005]
	Learning Rate: 0.000130048
	LOSS [training: 2.34231931992311 | validation: 2.5774546902646795]
	TIME [epoch: 9.5 sec]
EPOCH 947/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.342825341930431		[learning rate: 0.00012942]
	Learning Rate: 0.00012942
	LOSS [training: 2.342825341930431 | validation: 2.6778681909517843]
	TIME [epoch: 9.51 sec]
EPOCH 948/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.366567307120129		[learning rate: 0.00012879]
	Learning Rate: 0.000128794
	LOSS [training: 2.366567307120129 | validation: 2.6962414366002325]
	TIME [epoch: 9.49 sec]
EPOCH 949/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.342728453505202		[learning rate: 0.00012817]
	Learning Rate: 0.000128171
	LOSS [training: 2.342728453505202 | validation: 2.713334622546761]
	TIME [epoch: 9.51 sec]
EPOCH 950/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.321552440373428		[learning rate: 0.00012755]
	Learning Rate: 0.000127551
	LOSS [training: 2.321552440373428 | validation: 2.6495093437476034]
	TIME [epoch: 9.49 sec]
EPOCH 951/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3335999126330877		[learning rate: 0.00012693]
	Learning Rate: 0.000126934
	LOSS [training: 2.3335999126330877 | validation: 2.640619615385032]
	TIME [epoch: 9.49 sec]
EPOCH 952/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.351524456447346		[learning rate: 0.00012632]
	Learning Rate: 0.00012632
	LOSS [training: 2.351524456447346 | validation: 2.4923093024879606]
	TIME [epoch: 9.54 sec]
EPOCH 953/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.393264023358282		[learning rate: 0.00012571]
	Learning Rate: 0.00012571
	LOSS [training: 2.393264023358282 | validation: 2.689002552031507]
	TIME [epoch: 9.49 sec]
EPOCH 954/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3731819277837367		[learning rate: 0.0001251]
	Learning Rate: 0.000125102
	LOSS [training: 2.3731819277837367 | validation: 2.6532311111683358]
	TIME [epoch: 9.5 sec]
EPOCH 955/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3720250312199544		[learning rate: 0.0001245]
	Learning Rate: 0.000124497
	LOSS [training: 2.3720250312199544 | validation: 2.6330373653889536]
	TIME [epoch: 9.49 sec]
EPOCH 956/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4384707207334877		[learning rate: 0.00012389]
	Learning Rate: 0.000123895
	LOSS [training: 2.4384707207334877 | validation: 2.7275048099872072]
	TIME [epoch: 9.52 sec]
EPOCH 957/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.418833911108812		[learning rate: 0.0001233]
	Learning Rate: 0.000123296
	LOSS [training: 2.418833911108812 | validation: 2.6539933862941654]
	TIME [epoch: 9.49 sec]
EPOCH 958/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4447793840915315		[learning rate: 0.0001227]
	Learning Rate: 0.000122699
	LOSS [training: 2.4447793840915315 | validation: 2.697288243377217]
	TIME [epoch: 9.49 sec]
EPOCH 959/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4558583095640993		[learning rate: 0.00012211]
	Learning Rate: 0.000122106
	LOSS [training: 2.4558583095640993 | validation: 2.7036239553848067]
	TIME [epoch: 9.51 sec]
EPOCH 960/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.421425377435849		[learning rate: 0.00012152]
	Learning Rate: 0.000121515
	LOSS [training: 2.421425377435849 | validation: 2.7202514121530714]
	TIME [epoch: 9.49 sec]
EPOCH 961/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.417478123468955		[learning rate: 0.00012093]
	Learning Rate: 0.000120928
	LOSS [training: 2.417478123468955 | validation: 2.7993463179462377]
	TIME [epoch: 9.5 sec]
EPOCH 962/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.462912864059056		[learning rate: 0.00012034]
	Learning Rate: 0.000120343
	LOSS [training: 2.462912864059056 | validation: 2.790109152184401]
	TIME [epoch: 9.49 sec]
EPOCH 963/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.457244588691599		[learning rate: 0.00011976]
	Learning Rate: 0.000119761
	LOSS [training: 2.457244588691599 | validation: 2.8745899806742017]
	TIME [epoch: 9.51 sec]
EPOCH 964/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4668563190431145		[learning rate: 0.00011918]
	Learning Rate: 0.000119182
	LOSS [training: 2.4668563190431145 | validation: 2.848569168008296]
	TIME [epoch: 9.49 sec]
EPOCH 965/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4632577152673916		[learning rate: 0.00011861]
	Learning Rate: 0.000118606
	LOSS [training: 2.4632577152673916 | validation: 2.7866251640972584]
	TIME [epoch: 9.5 sec]
EPOCH 966/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4643269627871858		[learning rate: 0.00011803]
	Learning Rate: 0.000118032
	LOSS [training: 2.4643269627871858 | validation: 2.808113341454131]
	TIME [epoch: 9.51 sec]
EPOCH 967/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4880988466415976		[learning rate: 0.00011746]
	Learning Rate: 0.000117461
	LOSS [training: 2.4880988466415976 | validation: 2.86311595444015]
	TIME [epoch: 9.49 sec]
EPOCH 968/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4791266998583374		[learning rate: 0.00011689]
	Learning Rate: 0.000116893
	LOSS [training: 2.4791266998583374 | validation: 2.8066042811292404]
	TIME [epoch: 9.49 sec]
EPOCH 969/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4515661086918192		[learning rate: 0.00011633]
	Learning Rate: 0.000116328
	LOSS [training: 2.4515661086918192 | validation: 2.78120266174534]
	TIME [epoch: 9.49 sec]
EPOCH 970/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4229418704960457		[learning rate: 0.00011577]
	Learning Rate: 0.000115765
	LOSS [training: 2.4229418704960457 | validation: 2.764109673271383]
	TIME [epoch: 9.51 sec]
EPOCH 971/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.413381493141715		[learning rate: 0.00011521]
	Learning Rate: 0.000115206
	LOSS [training: 2.413381493141715 | validation: 2.6511063458667974]
	TIME [epoch: 9.49 sec]
EPOCH 972/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.4006651827629444		[learning rate: 0.00011465]
	Learning Rate: 0.000114649
	LOSS [training: 2.4006651827629444 | validation: 2.709259169224066]
	TIME [epoch: 9.5 sec]
EPOCH 973/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.432418512166599		[learning rate: 0.00011409]
	Learning Rate: 0.000114094
	LOSS [training: 2.432418512166599 | validation: 2.6120752253849844]
	TIME [epoch: 9.51 sec]
EPOCH 974/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3985092712134604		[learning rate: 0.00011354]
	Learning Rate: 0.000113542
	LOSS [training: 2.3985092712134604 | validation: 2.656259651773491]
	TIME [epoch: 9.5 sec]
EPOCH 975/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.382633099896472		[learning rate: 0.00011299]
	Learning Rate: 0.000112993
	LOSS [training: 2.382633099896472 | validation: 2.5823719658533184]
	TIME [epoch: 9.49 sec]
EPOCH 976/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3622125801828204		[learning rate: 0.00011245]
	Learning Rate: 0.000112447
	LOSS [training: 2.3622125801828204 | validation: 2.5822940617009085]
	TIME [epoch: 9.49 sec]
EPOCH 977/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.324256002346747		[learning rate: 0.0001119]
	Learning Rate: 0.000111903
	LOSS [training: 2.324256002346747 | validation: 2.4997539424735598]
	TIME [epoch: 9.5 sec]
EPOCH 978/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3035030255922058		[learning rate: 0.00011136]
	Learning Rate: 0.000111362
	LOSS [training: 2.3035030255922058 | validation: 2.5751123075802878]
	TIME [epoch: 9.5 sec]
EPOCH 979/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3013989907338077		[learning rate: 0.00011082]
	Learning Rate: 0.000110823
	LOSS [training: 2.3013989907338077 | validation: 2.5398554142653875]
	TIME [epoch: 9.49 sec]
EPOCH 980/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3126405482566468		[learning rate: 0.00011029]
	Learning Rate: 0.000110288
	LOSS [training: 2.3126405482566468 | validation: 2.4741238080650607]
	TIME [epoch: 9.51 sec]
EPOCH 981/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2910658901015997		[learning rate: 0.00010975]
	Learning Rate: 0.000109754
	LOSS [training: 2.2910658901015997 | validation: 2.507175530194552]
	TIME [epoch: 9.5 sec]
EPOCH 982/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.2696648649933673		[learning rate: 0.00010922]
	Learning Rate: 0.000109223
	LOSS [training: 2.2696648649933673 | validation: 2.6068087869668144]
	TIME [epoch: 9.5 sec]
EPOCH 983/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3430610106098197		[learning rate: 0.0001087]
	Learning Rate: 0.000108695
	LOSS [training: 2.3430610106098197 | validation: 2.598259065116269]
	TIME [epoch: 9.49 sec]
EPOCH 984/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.358832748092451		[learning rate: 0.00010817]
	Learning Rate: 0.00010817
	LOSS [training: 2.358832748092451 | validation: 2.6537661803392223]
	TIME [epoch: 9.51 sec]
EPOCH 985/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.322906635401989		[learning rate: 0.00010765]
	Learning Rate: 0.000107647
	LOSS [training: 2.322906635401989 | validation: 2.638031604487484]
	TIME [epoch: 9.49 sec]
EPOCH 986/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3142438319601504		[learning rate: 0.00010713]
	Learning Rate: 0.000107126
	LOSS [training: 2.3142438319601504 | validation: 2.5612642006903616]
	TIME [epoch: 9.49 sec]
EPOCH 987/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3372615258379192		[learning rate: 0.00010661]
	Learning Rate: 0.000106608
	LOSS [training: 2.3372615258379192 | validation: 2.560720941481185]
	TIME [epoch: 9.52 sec]
EPOCH 988/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3617267326692084		[learning rate: 0.00010609]
	Learning Rate: 0.000106092
	LOSS [training: 2.3617267326692084 | validation: 2.6001824086981675]
	TIME [epoch: 9.49 sec]
EPOCH 989/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.39080001478019		[learning rate: 0.00010558]
	Learning Rate: 0.000105579
	LOSS [training: 2.39080001478019 | validation: 2.6403298979727867]
	TIME [epoch: 9.48 sec]
EPOCH 990/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.371256616554979		[learning rate: 0.00010507]
	Learning Rate: 0.000105069
	LOSS [training: 2.371256616554979 | validation: 2.676997832454647]
	TIME [epoch: 9.49 sec]
EPOCH 991/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3485886159641067		[learning rate: 0.00010456]
	Learning Rate: 0.000104561
	LOSS [training: 2.3485886159641067 | validation: 2.647344093663635]
	TIME [epoch: 9.52 sec]
EPOCH 992/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.317054620571926		[learning rate: 0.00010406]
	Learning Rate: 0.000104055
	LOSS [training: 2.317054620571926 | validation: 2.5806321802395455]
	TIME [epoch: 9.49 sec]
EPOCH 993/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3409776998344176		[learning rate: 0.00010355]
	Learning Rate: 0.000103552
	LOSS [training: 2.3409776998344176 | validation: 2.6329040877335452]
	TIME [epoch: 9.49 sec]
EPOCH 994/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.345195780111946		[learning rate: 0.00010305]
	Learning Rate: 0.000103051
	LOSS [training: 2.345195780111946 | validation: 2.5707488364295137]
	TIME [epoch: 9.5 sec]
EPOCH 995/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3378152771365577		[learning rate: 0.00010255]
	Learning Rate: 0.000102553
	LOSS [training: 2.3378152771365577 | validation: 2.538480712194375]
	TIME [epoch: 9.5 sec]
EPOCH 996/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3404229883046015		[learning rate: 0.00010206]
	Learning Rate: 0.000102057
	LOSS [training: 2.3404229883046015 | validation: 2.709670900879621]
	TIME [epoch: 9.5 sec]
EPOCH 997/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.356107571802405		[learning rate: 0.00010156]
	Learning Rate: 0.000101563
	LOSS [training: 2.356107571802405 | validation: 2.5874680432914263]
	TIME [epoch: 9.51 sec]
EPOCH 998/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.348296425188809		[learning rate: 0.00010107]
	Learning Rate: 0.000101072
	LOSS [training: 2.348296425188809 | validation: 2.657750826416469]
	TIME [epoch: 9.51 sec]
EPOCH 999/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.3545320642881262		[learning rate: 0.00010058]
	Learning Rate: 0.000100583
	LOSS [training: 2.3545320642881262 | validation: 2.662811205645585]
	TIME [epoch: 9.49 sec]
EPOCH 1000/1000:
	Training over batches...
		[batch 5/5] avg loss: 2.387023310294149		[learning rate: 0.0001001]
	Learning Rate: 0.000100097
	LOSS [training: 2.387023310294149 | validation: 2.725864536235139]
	TIME [epoch: 9.49 sec]
Finished training in 9619.560 seconds.
