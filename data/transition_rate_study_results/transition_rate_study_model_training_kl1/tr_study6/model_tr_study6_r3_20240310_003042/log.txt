Args:
Namespace(name='model_tr_study6', outdir='out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3', training_data='data/transition_rate_studies/tr_study6/tr_study6_training/r3', validation_data='data/transition_rate_studies/tr_study6/tr_study6_validation/r3', model_type='deep_phi', nsims_training=None, nsims_validation=None, num_epochs=2000, batch_size=250, report_every=10, reduce_dt_on_nan=False, dt_reduction_factor=0.5, reduce_cf_on_nan=True, cf_reduction_factor=0.5, nan_max_attempts=4, ndims=2, nparams=2, nsigs=2, ncells=500, dt=0.1, signal_function='sigmoid', solver='heun', confine=True, confinement_factor=0.1, phi_hidden_dims=[16, 32, 32, 16], phi_hidden_acts=['softplus'], phi_final_act='None', phi_layer_normalize=False, tilt_hidden_dims=[0], tilt_hidden_acts=['None'], tilt_final_act='None', tilt_layer_normalize=False, infer_metric=False, metric_hidden_dims=[8, 8, 8, 8], metric_hidden_acts=['softplus', 'softplus', 'softplus', 'softplus'], metric_final_act=None, metric_layer_normalize=False, fix_noise=False, sigma=0.2, init_phi_weights_method='xavier_uniform', init_phi_weights_args=[], init_phi_bias_method='constant', init_phi_bias_args=[0.01], init_tilt_weights_method='xavier_uniform', init_tilt_weights_args=[], init_tilt_bias_method='constant', init_tilt_bias_args=[0.01], init_metric_weights_method='xavier_uniform', init_metric_weights_args=[], init_metric_bias_method=None, init_metric_bias_args=None, loss='kl', optimizer='rms', momentum=0.5, weight_decay=0.9, clip=1.0, lr_schedule='exponential_decay', learning_rate=0.01, nepochs_warmup=50, nepochs_decay=-1, final_learning_rate=1e-05, peak_learning_rate=0.02, warmup_cosine_decay_exponent=1.0, plot=True, dtype='float64', seed=0, timestamp=True, save_all=False, enforce_gpu=True, continuation=None)

Using seed: 3659079104

Training model...

Saving initial model state to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_0.pth
EPOCH 1/2000:
	Training over batches...
		[batch 4/4] avg loss: 8.594297365084643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 8.594297365084643 | validation: 8.124228201441838]
	TIME [epoch: 106 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_1.pth
	Model improved!!!
EPOCH 2/2000:
	Training over batches...
		[batch 4/4] avg loss: 7.2237738473182365		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 7.2237738473182365 | validation: 7.191280521409265]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_2.pth
	Model improved!!!
EPOCH 3/2000:
	Training over batches...
		[batch 4/4] avg loss: 6.366318667521603		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 6.366318667521603 | validation: 6.169180376296185]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_3.pth
	Model improved!!!
EPOCH 4/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.802649357639251		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.802649357639251 | validation: 5.610159483295465]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_4.pth
	Model improved!!!
EPOCH 5/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.17009814235608		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.17009814235608 | validation: 5.033514614908369]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_5.pth
	Model improved!!!
EPOCH 6/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.939798225442029		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.939798225442029 | validation: 4.561827840731454]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_6.pth
	Model improved!!!
EPOCH 7/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.03212768510894		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.03212768510894 | validation: 4.144133575733876]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_7.pth
	Model improved!!!
EPOCH 8/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.067593716814483		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.067593716814483 | validation: 4.083607928213846]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_8.pth
	Model improved!!!
EPOCH 9/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.844897479772656		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.844897479772656 | validation: 3.269258429376474]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_9.pth
	Model improved!!!
EPOCH 10/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.706949315096213		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.706949315096213 | validation: 3.928532419682813]
	TIME [epoch: 27.8 sec]
EPOCH 11/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.565690798990905		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.565690798990905 | validation: 3.6596120730134953]
	TIME [epoch: 27.8 sec]
EPOCH 12/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7570413760686887		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.7570413760686887 | validation: 3.280556760697026]
	TIME [epoch: 27.8 sec]
EPOCH 13/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.035258244917509		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.035258244917509 | validation: 4.725889373178208]
	TIME [epoch: 27.7 sec]
EPOCH 14/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.918972969862961		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.918972969862961 | validation: 3.4939087441466756]
	TIME [epoch: 27.7 sec]
EPOCH 15/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5546490579719827		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5546490579719827 | validation: 3.5213531764145323]
	TIME [epoch: 27.8 sec]
EPOCH 16/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4959515062168873		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4959515062168873 | validation: 3.20178821203774]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_16.pth
	Model improved!!!
EPOCH 17/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6347169191465114		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.6347169191465114 | validation: 3.7635481314547645]
	TIME [epoch: 27.7 sec]
EPOCH 18/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5765761047945643		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.5765761047945643 | validation: 3.3772055617671946]
	TIME [epoch: 27.7 sec]
EPOCH 19/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.329231770633045		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.329231770633045 | validation: 3.4882487116567074]
	TIME [epoch: 27.7 sec]
EPOCH 20/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4851068491345885		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4851068491345885 | validation: 3.420166387017841]
	TIME [epoch: 27.7 sec]
EPOCH 21/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8071927752474815		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8071927752474815 | validation: 3.479216514636505]
	TIME [epoch: 27.7 sec]
EPOCH 22/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3578175011804703		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3578175011804703 | validation: 3.1010497816257225]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_22.pth
	Model improved!!!
EPOCH 23/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.241031842777242		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.241031842777242 | validation: 3.1273623022326125]
	TIME [epoch: 27.7 sec]
EPOCH 24/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.250009286341		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.250009286341 | validation: 3.0931126373353504]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_24.pth
	Model improved!!!
EPOCH 25/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2062972953444007		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2062972953444007 | validation: 3.9138937985380644]
	TIME [epoch: 27.7 sec]
EPOCH 26/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2962209542614893		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2962209542614893 | validation: 2.980718230557169]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_26.pth
	Model improved!!!
EPOCH 27/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2879451571368037		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.2879451571368037 | validation: 3.409733765527455]
	TIME [epoch: 27.7 sec]
EPOCH 28/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0278123440460507		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.0278123440460507 | validation: 3.44037397647957]
	TIME [epoch: 27.7 sec]
EPOCH 29/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.414459443133583		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.414459443133583 | validation: 3.460167656435566]
	TIME [epoch: 27.8 sec]
EPOCH 30/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.076321846107134		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.076321846107134 | validation: 3.1676941574040147]
	TIME [epoch: 27.8 sec]
EPOCH 31/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.938604158027952		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.938604158027952 | validation: 2.641137342681864]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_31.pth
	Model improved!!!
EPOCH 32/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7239925647794867		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7239925647794867 | validation: 2.868626531582263]
	TIME [epoch: 27.7 sec]
EPOCH 33/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.759835680964744		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.759835680964744 | validation: 3.5437542777060305]
	TIME [epoch: 27.7 sec]
EPOCH 34/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.342179897284735		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.342179897284735 | validation: 3.1624717022406488]
	TIME [epoch: 27.7 sec]
EPOCH 35/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8511674418771578		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.8511674418771578 | validation: 3.840077861413764]
	TIME [epoch: 27.7 sec]
EPOCH 36/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.022479237353924		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.022479237353924 | validation: 2.930908096492633]
	TIME [epoch: 27.7 sec]
EPOCH 37/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8229665114049425		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.8229665114049425 | validation: 2.564162173790284]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_37.pth
	Model improved!!!
EPOCH 38/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7502253648832813		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.7502253648832813 | validation: 3.3900484358363956]
	TIME [epoch: 27.8 sec]
EPOCH 39/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4825255844548035		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4825255844548035 | validation: 3.5889220341479096]
	TIME [epoch: 27.8 sec]
EPOCH 40/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.9132673811897245		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 5.9132673811897245 | validation: 4.910676317128264]
	TIME [epoch: 27.8 sec]
EPOCH 41/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.666299028377605		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 4.666299028377605 | validation: 3.0749085613006644]
	TIME [epoch: 27.8 sec]
EPOCH 42/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.947831396683183		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.947831396683183 | validation: 2.9579423842358152]
	TIME [epoch: 27.8 sec]
EPOCH 43/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.770606157226436		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.770606157226436 | validation: 2.6534964511532304]
	TIME [epoch: 27.8 sec]
EPOCH 44/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4592847411622474		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4592847411622474 | validation: 2.9411167319021865]
	TIME [epoch: 27.8 sec]
EPOCH 45/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.154900555116262		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.154900555116262 | validation: 3.0164304873631114]
	TIME [epoch: 27.8 sec]
EPOCH 46/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.686729548550506		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.686729548550506 | validation: 3.283802276434829]
	TIME [epoch: 27.8 sec]
EPOCH 47/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4014432494434463		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.4014432494434463 | validation: 2.5288481038702155]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_47.pth
	Model improved!!!
EPOCH 48/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1257458890321947		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.1257458890321947 | validation: 3.0824880805452928]
	TIME [epoch: 27.7 sec]
EPOCH 49/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.673797469374471		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 2.673797469374471 | validation: 3.4458720710161845]
	TIME [epoch: 27.7 sec]
EPOCH 50/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3562898802962526		[learning rate: 0.01]
	Learning Rate: 0.01
	LOSS [training: 3.3562898802962526 | validation: 6.323590113575441]
	TIME [epoch: 27.8 sec]
EPOCH 51/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.6897566686455905		[learning rate: 0.0099735]
	Learning Rate: 0.00997347
	LOSS [training: 5.6897566686455905 | validation: 3.3125323417920196]
	TIME [epoch: 27.7 sec]
EPOCH 52/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.097633481055998		[learning rate: 0.0099382]
	Learning Rate: 0.0099382
	LOSS [training: 3.097633481055998 | validation: 2.98971291505261]
	TIME [epoch: 27.8 sec]
EPOCH 53/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8625577408459293		[learning rate: 0.0099031]
	Learning Rate: 0.00990306
	LOSS [training: 2.8625577408459293 | validation: 2.6814937190732038]
	TIME [epoch: 27.8 sec]
EPOCH 54/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2895112637909896		[learning rate: 0.009868]
	Learning Rate: 0.00986804
	LOSS [training: 3.2895112637909896 | validation: 3.730164873842583]
	TIME [epoch: 27.8 sec]
EPOCH 55/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.935488876516159		[learning rate: 0.0098331]
	Learning Rate: 0.00983314
	LOSS [training: 3.935488876516159 | validation: 3.5437950747171842]
	TIME [epoch: 27.8 sec]
EPOCH 56/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8567902343847154		[learning rate: 0.0097984]
	Learning Rate: 0.00979837
	LOSS [training: 3.8567902343847154 | validation: 2.8043601094168187]
	TIME [epoch: 27.8 sec]
EPOCH 57/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.892379366541555		[learning rate: 0.0097637]
	Learning Rate: 0.00976372
	LOSS [training: 2.892379366541555 | validation: 3.023149358092808]
	TIME [epoch: 27.8 sec]
EPOCH 58/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5571102968060044		[learning rate: 0.0097292]
	Learning Rate: 0.0097292
	LOSS [training: 3.5571102968060044 | validation: 2.7803278448426285]
	TIME [epoch: 27.8 sec]
EPOCH 59/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.505729013517797		[learning rate: 0.0096948]
	Learning Rate: 0.00969479
	LOSS [training: 3.505729013517797 | validation: 3.8222722893887346]
	TIME [epoch: 27.8 sec]
EPOCH 60/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.387402683507577		[learning rate: 0.0096605]
	Learning Rate: 0.00966051
	LOSS [training: 3.387402683507577 | validation: 2.901827835146887]
	TIME [epoch: 27.8 sec]
EPOCH 61/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9658768199926184		[learning rate: 0.0096263]
	Learning Rate: 0.00962635
	LOSS [training: 2.9658768199926184 | validation: 2.5705883866222443]
	TIME [epoch: 27.7 sec]
EPOCH 62/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.621539803828284		[learning rate: 0.0095923]
	Learning Rate: 0.00959231
	LOSS [training: 2.621539803828284 | validation: 2.816583623599767]
	TIME [epoch: 27.9 sec]
EPOCH 63/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7850212029326		[learning rate: 0.0095584]
	Learning Rate: 0.00955839
	LOSS [training: 2.7850212029326 | validation: 2.6122110059625867]
	TIME [epoch: 27.7 sec]
EPOCH 64/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7296980091110647		[learning rate: 0.0095246]
	Learning Rate: 0.00952459
	LOSS [training: 2.7296980091110647 | validation: 2.9489644950629477]
	TIME [epoch: 27.8 sec]
EPOCH 65/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2120379924250466		[learning rate: 0.0094909]
	Learning Rate: 0.00949091
	LOSS [training: 3.2120379924250466 | validation: 5.338914474033158]
	TIME [epoch: 27.7 sec]
EPOCH 66/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.064602469278858		[learning rate: 0.0094573]
	Learning Rate: 0.00945734
	LOSS [training: 5.064602469278858 | validation: 3.855033852760793]
	TIME [epoch: 27.7 sec]
EPOCH 67/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.602169505815824		[learning rate: 0.0094239]
	Learning Rate: 0.0094239
	LOSS [training: 4.602169505815824 | validation: 4.4917301541930374]
	TIME [epoch: 27.6 sec]
EPOCH 68/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9933929132926957		[learning rate: 0.0093906]
	Learning Rate: 0.00939058
	LOSS [training: 3.9933929132926957 | validation: 3.7721424863011332]
	TIME [epoch: 27.7 sec]
EPOCH 69/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.713640892149892		[learning rate: 0.0093574]
	Learning Rate: 0.00935737
	LOSS [training: 4.713640892149892 | validation: 4.029103377040976]
	TIME [epoch: 27.7 sec]
EPOCH 70/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.48862290314168		[learning rate: 0.0093243]
	Learning Rate: 0.00932428
	LOSS [training: 3.48862290314168 | validation: 2.76315022314417]
	TIME [epoch: 27.8 sec]
EPOCH 71/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0471941234878717		[learning rate: 0.0092913]
	Learning Rate: 0.00929131
	LOSS [training: 3.0471941234878717 | validation: 3.6707022363850474]
	TIME [epoch: 27.7 sec]
EPOCH 72/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.289711405850788		[learning rate: 0.0092585]
	Learning Rate: 0.00925845
	LOSS [training: 3.289711405850788 | validation: 2.735550320455924]
	TIME [epoch: 27.8 sec]
EPOCH 73/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7716872309356773		[learning rate: 0.0092257]
	Learning Rate: 0.00922571
	LOSS [training: 2.7716872309356773 | validation: 3.189243557999124]
	TIME [epoch: 27.7 sec]
EPOCH 74/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.537966519696975		[learning rate: 0.0091931]
	Learning Rate: 0.00919309
	LOSS [training: 3.537966519696975 | validation: 2.797944524025332]
	TIME [epoch: 27.7 sec]
EPOCH 75/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7697003246004335		[learning rate: 0.0091606]
	Learning Rate: 0.00916058
	LOSS [training: 2.7697003246004335 | validation: 2.5496334260906757]
	TIME [epoch: 27.7 sec]
EPOCH 76/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8914305551787063		[learning rate: 0.0091282]
	Learning Rate: 0.00912819
	LOSS [training: 2.8914305551787063 | validation: 3.8250687873760416]
	TIME [epoch: 27.7 sec]
EPOCH 77/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.895090411108993		[learning rate: 0.0090959]
	Learning Rate: 0.00909591
	LOSS [training: 3.895090411108993 | validation: 3.1627848873488937]
	TIME [epoch: 27.8 sec]
EPOCH 78/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3709650265193916		[learning rate: 0.0090637]
	Learning Rate: 0.00906374
	LOSS [training: 3.3709650265193916 | validation: 2.9595650671514204]
	TIME [epoch: 27.7 sec]
EPOCH 79/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.850045933644892		[learning rate: 0.0090317]
	Learning Rate: 0.00903169
	LOSS [training: 2.850045933644892 | validation: 2.852217932961865]
	TIME [epoch: 27.7 sec]
EPOCH 80/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8730308653210974		[learning rate: 0.0089998]
	Learning Rate: 0.00899976
	LOSS [training: 2.8730308653210974 | validation: 3.224635396842294]
	TIME [epoch: 27.8 sec]
EPOCH 81/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.041445398678955		[learning rate: 0.0089679]
	Learning Rate: 0.00896793
	LOSS [training: 3.041445398678955 | validation: 2.850972881255915]
	TIME [epoch: 27.7 sec]
EPOCH 82/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2139181655416342		[learning rate: 0.0089362]
	Learning Rate: 0.00893622
	LOSS [training: 3.2139181655416342 | validation: 3.3915139426508314]
	TIME [epoch: 27.8 sec]
EPOCH 83/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.9999979920337365		[learning rate: 0.0089046]
	Learning Rate: 0.00890462
	LOSS [training: 4.9999979920337365 | validation: 4.409342146252548]
	TIME [epoch: 27.7 sec]
EPOCH 84/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8315861134971487		[learning rate: 0.0088731]
	Learning Rate: 0.00887313
	LOSS [training: 3.8315861134971487 | validation: 2.9216561177153433]
	TIME [epoch: 27.8 sec]
EPOCH 85/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9441210924226744		[learning rate: 0.0088418]
	Learning Rate: 0.00884175
	LOSS [training: 2.9441210924226744 | validation: 2.9372028063318703]
	TIME [epoch: 27.8 sec]
EPOCH 86/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2594625828309276		[learning rate: 0.0088105]
	Learning Rate: 0.00881049
	LOSS [training: 3.2594625828309276 | validation: 3.2834377748531707]
	TIME [epoch: 27.7 sec]
EPOCH 87/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.457351033614072		[learning rate: 0.0087793]
	Learning Rate: 0.00877933
	LOSS [training: 3.457351033614072 | validation: 2.939887864266475]
	TIME [epoch: 27.7 sec]
EPOCH 88/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.934331480732668		[learning rate: 0.0087483]
	Learning Rate: 0.00874829
	LOSS [training: 2.934331480732668 | validation: 2.6101119026574686]
	TIME [epoch: 27.7 sec]
EPOCH 89/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6753082671238095		[learning rate: 0.0087174]
	Learning Rate: 0.00871735
	LOSS [training: 2.6753082671238095 | validation: 2.5040870856016357]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_89.pth
	Model improved!!!
EPOCH 90/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.258981812546356		[learning rate: 0.0086865]
	Learning Rate: 0.00868653
	LOSS [training: 3.258981812546356 | validation: 4.161691980611995]
	TIME [epoch: 27.8 sec]
EPOCH 91/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.63972348070652		[learning rate: 0.0086558]
	Learning Rate: 0.00865581
	LOSS [training: 4.63972348070652 | validation: 3.204392142208931]
	TIME [epoch: 27.6 sec]
EPOCH 92/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2274512946357894		[learning rate: 0.0086252]
	Learning Rate: 0.0086252
	LOSS [training: 3.2274512946357894 | validation: 3.1710204910336293]
	TIME [epoch: 27.8 sec]
EPOCH 93/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9353014169570257		[learning rate: 0.0085947]
	Learning Rate: 0.0085947
	LOSS [training: 2.9353014169570257 | validation: 2.6687823290014365]
	TIME [epoch: 27.8 sec]
EPOCH 94/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.644275823220121		[learning rate: 0.0085643]
	Learning Rate: 0.00856431
	LOSS [training: 3.644275823220121 | validation: 4.6787586573153]
	TIME [epoch: 27.7 sec]
EPOCH 95/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.284120266491165		[learning rate: 0.008534]
	Learning Rate: 0.00853402
	LOSS [training: 4.284120266491165 | validation: 2.8547381625716786]
	TIME [epoch: 27.6 sec]
EPOCH 96/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8027977624759064		[learning rate: 0.0085038]
	Learning Rate: 0.00850385
	LOSS [training: 2.8027977624759064 | validation: 2.4620955624618537]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_96.pth
	Model improved!!!
EPOCH 97/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.629852998720763		[learning rate: 0.0084738]
	Learning Rate: 0.00847377
	LOSS [training: 2.629852998720763 | validation: 2.4125596831920295]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_97.pth
	Model improved!!!
EPOCH 98/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5830664267984274		[learning rate: 0.0084438]
	Learning Rate: 0.00844381
	LOSS [training: 2.5830664267984274 | validation: 2.3787882336352983]
	TIME [epoch: 27.6 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_98.pth
	Model improved!!!
EPOCH 99/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.7511461241518154		[learning rate: 0.008414]
	Learning Rate: 0.00841395
	LOSS [training: 2.7511461241518154 | validation: 2.4298525418000216]
	TIME [epoch: 27.7 sec]
EPOCH 100/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.431566197327835		[learning rate: 0.0083842]
	Learning Rate: 0.0083842
	LOSS [training: 2.431566197327835 | validation: 2.400632572013043]
	TIME [epoch: 27.7 sec]
EPOCH 101/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.46111529972615		[learning rate: 0.0083546]
	Learning Rate: 0.00835455
	LOSS [training: 2.46111529972615 | validation: 2.1096213125718517]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_101.pth
	Model improved!!!
EPOCH 102/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.402979981330666		[learning rate: 0.008325]
	Learning Rate: 0.00832501
	LOSS [training: 2.402979981330666 | validation: 2.5360722514043466]
	TIME [epoch: 27.7 sec]
EPOCH 103/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.981897674760228		[learning rate: 0.0082956]
	Learning Rate: 0.00829557
	LOSS [training: 2.981897674760228 | validation: 3.121538491483716]
	TIME [epoch: 27.7 sec]
EPOCH 104/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.696006295168017		[learning rate: 0.0082662]
	Learning Rate: 0.00826623
	LOSS [training: 2.696006295168017 | validation: 2.6414865452179526]
	TIME [epoch: 27.8 sec]
EPOCH 105/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4015369613463253		[learning rate: 0.008237]
	Learning Rate: 0.008237
	LOSS [training: 2.4015369613463253 | validation: 2.3551298633070274]
	TIME [epoch: 27.8 sec]
EPOCH 106/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.281624168364732		[learning rate: 0.0082079]
	Learning Rate: 0.00820788
	LOSS [training: 2.281624168364732 | validation: 2.2134325704036506]
	TIME [epoch: 27.8 sec]
EPOCH 107/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.8053406116278543		[learning rate: 0.0081789]
	Learning Rate: 0.00817885
	LOSS [training: 2.8053406116278543 | validation: 2.2325956630996266]
	TIME [epoch: 27.8 sec]
EPOCH 108/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2099426643776905		[learning rate: 0.0081499]
	Learning Rate: 0.00814993
	LOSS [training: 2.2099426643776905 | validation: 2.087804464133045]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_108.pth
	Model improved!!!
EPOCH 109/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1683959822101837		[learning rate: 0.0081211]
	Learning Rate: 0.00812111
	LOSS [training: 2.1683959822101837 | validation: 2.142337588269947]
	TIME [epoch: 27.8 sec]
EPOCH 110/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.193470817268875		[learning rate: 0.0080924]
	Learning Rate: 0.00809239
	LOSS [training: 2.193470817268875 | validation: 1.8970323784261411]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_110.pth
	Model improved!!!
EPOCH 111/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9115959734654484		[learning rate: 0.0080638]
	Learning Rate: 0.00806378
	LOSS [training: 1.9115959734654484 | validation: 1.6377397791813135]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_111.pth
	Model improved!!!
EPOCH 112/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.273002423704972		[learning rate: 0.0080353]
	Learning Rate: 0.00803526
	LOSS [training: 2.273002423704972 | validation: 2.301077501038549]
	TIME [epoch: 27.8 sec]
EPOCH 113/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.878590374024306		[learning rate: 0.0080068]
	Learning Rate: 0.00800685
	LOSS [training: 1.878590374024306 | validation: 1.7177383220790643]
	TIME [epoch: 27.8 sec]
EPOCH 114/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.633559006317394		[learning rate: 0.0079785]
	Learning Rate: 0.00797853
	LOSS [training: 1.633559006317394 | validation: 2.317262963426312]
	TIME [epoch: 27.8 sec]
EPOCH 115/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4555005036153235		[learning rate: 0.0079503]
	Learning Rate: 0.00795032
	LOSS [training: 2.4555005036153235 | validation: 1.5474981560169705]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_115.pth
	Model improved!!!
EPOCH 116/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.042413778498932		[learning rate: 0.0079222]
	Learning Rate: 0.00792221
	LOSS [training: 2.042413778498932 | validation: 1.3743529554872382]
	TIME [epoch: 27.7 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_116.pth
	Model improved!!!
EPOCH 117/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5256639603004074		[learning rate: 0.0078942]
	Learning Rate: 0.00789419
	LOSS [training: 1.5256639603004074 | validation: 1.298943624126951]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_117.pth
	Model improved!!!
EPOCH 118/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3957690178296167		[learning rate: 0.0078663]
	Learning Rate: 0.00786628
	LOSS [training: 1.3957690178296167 | validation: 2.241358884437718]
	TIME [epoch: 27.9 sec]
EPOCH 119/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.200501709690258		[learning rate: 0.0078385]
	Learning Rate: 0.00783846
	LOSS [training: 4.200501709690258 | validation: 2.704502960232209]
	TIME [epoch: 27.8 sec]
EPOCH 120/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.643006575251922		[learning rate: 0.0078107]
	Learning Rate: 0.00781074
	LOSS [training: 3.643006575251922 | validation: 3.7981735955915674]
	TIME [epoch: 27.9 sec]
EPOCH 121/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7229473418946855		[learning rate: 0.0077831]
	Learning Rate: 0.00778312
	LOSS [training: 3.7229473418946855 | validation: 2.9754543556357764]
	TIME [epoch: 27.8 sec]
EPOCH 122/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4411568861425104		[learning rate: 0.0077556]
	Learning Rate: 0.0077556
	LOSS [training: 3.4411568861425104 | validation: 2.8861701859853794]
	TIME [epoch: 27.9 sec]
EPOCH 123/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.310044625953578		[learning rate: 0.0077282]
	Learning Rate: 0.00772817
	LOSS [training: 3.310044625953578 | validation: 2.862541838487088]
	TIME [epoch: 27.9 sec]
EPOCH 124/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2302078499311575		[learning rate: 0.0077008]
	Learning Rate: 0.00770085
	LOSS [training: 3.2302078499311575 | validation: 2.839335781087403]
	TIME [epoch: 27.8 sec]
EPOCH 125/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3979014855860505		[learning rate: 0.0076736]
	Learning Rate: 0.00767362
	LOSS [training: 3.3979014855860505 | validation: 4.8273079118622455]
	TIME [epoch: 27.9 sec]
EPOCH 126/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.579651053992248		[learning rate: 0.0076465]
	Learning Rate: 0.00764648
	LOSS [training: 5.579651053992248 | validation: 5.150520622999234]
	TIME [epoch: 27.8 sec]
EPOCH 127/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.725183108220797		[learning rate: 0.0076194]
	Learning Rate: 0.00761944
	LOSS [training: 4.725183108220797 | validation: 5.851219785044439]
	TIME [epoch: 27.8 sec]
EPOCH 128/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.946054228656546		[learning rate: 0.0075925]
	Learning Rate: 0.0075925
	LOSS [training: 5.946054228656546 | validation: 3.2644185650651183]
	TIME [epoch: 27.8 sec]
EPOCH 129/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.014093479365378		[learning rate: 0.0075656]
	Learning Rate: 0.00756565
	LOSS [training: 4.014093479365378 | validation: 3.5197483015983653]
	TIME [epoch: 27.8 sec]
EPOCH 130/2000:
	Training over batches...
		[batch 4/4] avg loss: 5.344307606537345		[learning rate: 0.0075389]
	Learning Rate: 0.00753889
	LOSS [training: 5.344307606537345 | validation: 3.849080566869994]
	TIME [epoch: 27.8 sec]
EPOCH 131/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.606225554879315		[learning rate: 0.0075122]
	Learning Rate: 0.00751224
	LOSS [training: 4.606225554879315 | validation: 3.6846699297805334]
	TIME [epoch: 27.8 sec]
EPOCH 132/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.944077268984675		[learning rate: 0.0074857]
	Learning Rate: 0.00748567
	LOSS [training: 3.944077268984675 | validation: 2.7255760842081678]
	TIME [epoch: 27.8 sec]
EPOCH 133/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2687115563632263		[learning rate: 0.0074592]
	Learning Rate: 0.0074592
	LOSS [training: 3.2687115563632263 | validation: 4.629901421053911]
	TIME [epoch: 27.8 sec]
EPOCH 134/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.549397270139264		[learning rate: 0.0074328]
	Learning Rate: 0.00743282
	LOSS [training: 4.549397270139264 | validation: 3.376371099679825]
	TIME [epoch: 27.8 sec]
EPOCH 135/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5511894451099764		[learning rate: 0.0074065]
	Learning Rate: 0.00740654
	LOSS [training: 3.5511894451099764 | validation: 3.4777753207770434]
	TIME [epoch: 27.8 sec]
EPOCH 136/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5911616496760637		[learning rate: 0.0073803]
	Learning Rate: 0.00738035
	LOSS [training: 3.5911616496760637 | validation: 3.340897045284182]
	TIME [epoch: 27.7 sec]
EPOCH 137/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9971401897129146		[learning rate: 0.0073543]
	Learning Rate: 0.00735425
	LOSS [training: 3.9971401897129146 | validation: 4.084859599607353]
	TIME [epoch: 27.8 sec]
EPOCH 138/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5910329539375483		[learning rate: 0.0073282]
	Learning Rate: 0.00732825
	LOSS [training: 3.5910329539375483 | validation: 2.8898720568642062]
	TIME [epoch: 27.8 sec]
EPOCH 139/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.42889198847236		[learning rate: 0.0073023]
	Learning Rate: 0.00730233
	LOSS [training: 3.42889198847236 | validation: 3.6386173655710077]
	TIME [epoch: 27.9 sec]
EPOCH 140/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7927422112069547		[learning rate: 0.0072765]
	Learning Rate: 0.00727651
	LOSS [training: 3.7927422112069547 | validation: 3.0952919894271633]
	TIME [epoch: 27.8 sec]
EPOCH 141/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2388161191993134		[learning rate: 0.0072508]
	Learning Rate: 0.00725078
	LOSS [training: 3.2388161191993134 | validation: 2.6615214543250882]
	TIME [epoch: 27.8 sec]
EPOCH 142/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.310458506149575		[learning rate: 0.0072251]
	Learning Rate: 0.00722514
	LOSS [training: 3.310458506149575 | validation: 2.831143987454835]
	TIME [epoch: 27.8 sec]
EPOCH 143/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9453370425923184		[learning rate: 0.0071996]
	Learning Rate: 0.00719959
	LOSS [training: 2.9453370425923184 | validation: 2.851357973787575]
	TIME [epoch: 27.9 sec]
EPOCH 144/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.78623880733832		[learning rate: 0.0071741]
	Learning Rate: 0.00717413
	LOSS [training: 2.78623880733832 | validation: 2.6025013899287006]
	TIME [epoch: 27.7 sec]
EPOCH 145/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3294641174880732		[learning rate: 0.0071488]
	Learning Rate: 0.00714876
	LOSS [training: 3.3294641174880732 | validation: 2.8551495164610223]
	TIME [epoch: 27.9 sec]
EPOCH 146/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.880225871997707		[learning rate: 0.0071235]
	Learning Rate: 0.00712348
	LOSS [training: 2.880225871997707 | validation: 2.5580200254948493]
	TIME [epoch: 27.8 sec]
EPOCH 147/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.864403147654648		[learning rate: 0.0070983]
	Learning Rate: 0.00709829
	LOSS [training: 2.864403147654648 | validation: 2.6491924971586105]
	TIME [epoch: 27.8 sec]
EPOCH 148/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6161728253034786		[learning rate: 0.0070732]
	Learning Rate: 0.00707319
	LOSS [training: 2.6161728253034786 | validation: 3.071982526274889]
	TIME [epoch: 27.9 sec]
EPOCH 149/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4382660644397065		[learning rate: 0.0070482]
	Learning Rate: 0.00704818
	LOSS [training: 3.4382660644397065 | validation: 2.2327030749260173]
	TIME [epoch: 27.7 sec]
EPOCH 150/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6532012498989896		[learning rate: 0.0070233]
	Learning Rate: 0.00702325
	LOSS [training: 2.6532012498989896 | validation: 2.1119444808882575]
	TIME [epoch: 27.7 sec]
EPOCH 151/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2862016118974546		[learning rate: 0.0069984]
	Learning Rate: 0.00699842
	LOSS [training: 2.2862016118974546 | validation: 2.663003092170833]
	TIME [epoch: 27.7 sec]
EPOCH 152/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1612411819490718		[learning rate: 0.0069737]
	Learning Rate: 0.00697367
	LOSS [training: 3.1612411819490718 | validation: 2.1919946853697927]
	TIME [epoch: 27.7 sec]
EPOCH 153/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.343510492408373		[learning rate: 0.006949]
	Learning Rate: 0.00694901
	LOSS [training: 2.343510492408373 | validation: 2.0758786188186464]
	TIME [epoch: 27.8 sec]
EPOCH 154/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.406159383279963		[learning rate: 0.0069244]
	Learning Rate: 0.00692444
	LOSS [training: 2.406159383279963 | validation: 2.4709046172155382]
	TIME [epoch: 27.9 sec]
EPOCH 155/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.262638055132804		[learning rate: 0.0069]
	Learning Rate: 0.00689995
	LOSS [training: 2.262638055132804 | validation: 2.133218925367755]
	TIME [epoch: 27.9 sec]
EPOCH 156/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5415398272077314		[learning rate: 0.0068756]
	Learning Rate: 0.00687555
	LOSS [training: 2.5415398272077314 | validation: 2.341851468344785]
	TIME [epoch: 27.9 sec]
EPOCH 157/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.241065870523519		[learning rate: 0.0068512]
	Learning Rate: 0.00685124
	LOSS [training: 2.241065870523519 | validation: 1.8552490345259898]
	TIME [epoch: 27.9 sec]
EPOCH 158/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.019645806397705		[learning rate: 0.006827]
	Learning Rate: 0.00682701
	LOSS [training: 2.019645806397705 | validation: 1.792267812972144]
	TIME [epoch: 27.9 sec]
EPOCH 159/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1076095537942203		[learning rate: 0.0068029]
	Learning Rate: 0.00680287
	LOSS [training: 2.1076095537942203 | validation: 1.796250434445755]
	TIME [epoch: 27.8 sec]
EPOCH 160/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9587878565694332		[learning rate: 0.0067788]
	Learning Rate: 0.00677882
	LOSS [training: 1.9587878565694332 | validation: 1.995586026478042]
	TIME [epoch: 27.9 sec]
EPOCH 161/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.0473261143423906		[learning rate: 0.0067548]
	Learning Rate: 0.00675485
	LOSS [training: 2.0473261143423906 | validation: 1.665501796553596]
	TIME [epoch: 27.8 sec]
EPOCH 162/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7588660908006455		[learning rate: 0.006731]
	Learning Rate: 0.00673096
	LOSS [training: 1.7588660908006455 | validation: 1.5816146681658638]
	TIME [epoch: 27.9 sec]
EPOCH 163/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9895820329803302		[learning rate: 0.0067072]
	Learning Rate: 0.00670716
	LOSS [training: 1.9895820329803302 | validation: 1.5053087363708857]
	TIME [epoch: 27.9 sec]
EPOCH 164/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.2226022165397947		[learning rate: 0.0066834]
	Learning Rate: 0.00668344
	LOSS [training: 2.2226022165397947 | validation: 3.3964545015150227]
	TIME [epoch: 27.8 sec]
EPOCH 165/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8096374327322797		[learning rate: 0.0066598]
	Learning Rate: 0.0066598
	LOSS [training: 3.8096374327322797 | validation: 4.021979121269725]
	TIME [epoch: 27.7 sec]
EPOCH 166/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.561478311460809		[learning rate: 0.0066363]
	Learning Rate: 0.00663625
	LOSS [training: 3.561478311460809 | validation: 2.441703212254389]
	TIME [epoch: 27.7 sec]
EPOCH 167/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8992366229148376		[learning rate: 0.0066128]
	Learning Rate: 0.00661279
	LOSS [training: 1.8992366229148376 | validation: 1.5454593133204657]
	TIME [epoch: 27.7 sec]
EPOCH 168/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4909421222932293		[learning rate: 0.0065894]
	Learning Rate: 0.0065894
	LOSS [training: 1.4909421222932293 | validation: 1.7140654585324628]
	TIME [epoch: 27.7 sec]
EPOCH 169/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5117517062592567		[learning rate: 0.0065661]
	Learning Rate: 0.0065661
	LOSS [training: 1.5117517062592567 | validation: 2.2436573302373968]
	TIME [epoch: 27.7 sec]
EPOCH 170/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9280717332432178		[learning rate: 0.0065429]
	Learning Rate: 0.00654288
	LOSS [training: 1.9280717332432178 | validation: 2.0084747740639743]
	TIME [epoch: 27.8 sec]
EPOCH 171/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.149667903514505		[learning rate: 0.0065197]
	Learning Rate: 0.00651975
	LOSS [training: 2.149667903514505 | validation: 1.4003583772604657]
	TIME [epoch: 27.8 sec]
EPOCH 172/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.561364843632717		[learning rate: 0.0064967]
	Learning Rate: 0.00649669
	LOSS [training: 1.561364843632717 | validation: 1.2218181473021161]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_172.pth
	Model improved!!!
EPOCH 173/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2600654657109098		[learning rate: 0.0064737]
	Learning Rate: 0.00647372
	LOSS [training: 1.2600654657109098 | validation: 1.4408010632121535]
	TIME [epoch: 27.9 sec]
EPOCH 174/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3578085668399384		[learning rate: 0.0064508]
	Learning Rate: 0.00645083
	LOSS [training: 1.3578085668399384 | validation: 1.3470483379079334]
	TIME [epoch: 27.9 sec]
EPOCH 175/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.502304788884682		[learning rate: 0.006428]
	Learning Rate: 0.00642801
	LOSS [training: 1.502304788884682 | validation: 1.1149059000552017]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_175.pth
	Model improved!!!
EPOCH 176/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.403460910485172		[learning rate: 0.0064053]
	Learning Rate: 0.00640529
	LOSS [training: 2.403460910485172 | validation: 1.7088304236091765]
	TIME [epoch: 27.8 sec]
EPOCH 177/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.392331000952141		[learning rate: 0.0063826]
	Learning Rate: 0.00638263
	LOSS [training: 1.392331000952141 | validation: 1.0324150506786172]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_177.pth
	Model improved!!!
EPOCH 178/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.8615931382902446		[learning rate: 0.0063601]
	Learning Rate: 0.00636006
	LOSS [training: 1.8615931382902446 | validation: 1.809547287333475]
	TIME [epoch: 27.9 sec]
EPOCH 179/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.384326142262608		[learning rate: 0.0063376]
	Learning Rate: 0.00633757
	LOSS [training: 1.384326142262608 | validation: 0.9477643031988826]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_179.pth
	Model improved!!!
EPOCH 180/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0603224169904215		[learning rate: 0.0063152]
	Learning Rate: 0.00631516
	LOSS [training: 1.0603224169904215 | validation: 0.9109174555381152]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_180.pth
	Model improved!!!
EPOCH 181/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.900016219987343		[learning rate: 0.0062928]
	Learning Rate: 0.00629283
	LOSS [training: 0.900016219987343 | validation: 0.8435361740406309]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_181.pth
	Model improved!!!
EPOCH 182/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1313778232866378		[learning rate: 0.0062706]
	Learning Rate: 0.00627058
	LOSS [training: 1.1313778232866378 | validation: 2.2914560244558326]
	TIME [epoch: 27.8 sec]
EPOCH 183/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2873282065501586		[learning rate: 0.0062484]
	Learning Rate: 0.00624841
	LOSS [training: 1.2873282065501586 | validation: 1.3464115402132921]
	TIME [epoch: 27.9 sec]
EPOCH 184/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2850897459843043		[learning rate: 0.0062263]
	Learning Rate: 0.00622631
	LOSS [training: 1.2850897459843043 | validation: 1.4452957501946047]
	TIME [epoch: 27.9 sec]
EPOCH 185/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1224688916557097		[learning rate: 0.0062043]
	Learning Rate: 0.00620429
	LOSS [training: 1.1224688916557097 | validation: 0.9976672916323819]
	TIME [epoch: 27.9 sec]
EPOCH 186/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.567280922581196		[learning rate: 0.0061824]
	Learning Rate: 0.00618235
	LOSS [training: 3.567280922581196 | validation: 4.023252477879038]
	TIME [epoch: 27.8 sec]
EPOCH 187/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.110300562383945		[learning rate: 0.0061605]
	Learning Rate: 0.00616049
	LOSS [training: 4.110300562383945 | validation: 2.878742351248103]
	TIME [epoch: 27.8 sec]
EPOCH 188/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1808913418394478		[learning rate: 0.0061387]
	Learning Rate: 0.00613871
	LOSS [training: 3.1808913418394478 | validation: 2.6536989536135036]
	TIME [epoch: 27.8 sec]
EPOCH 189/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5813953590697007		[learning rate: 0.006117]
	Learning Rate: 0.006117
	LOSS [training: 2.5813953590697007 | validation: 1.791817796120335]
	TIME [epoch: 27.8 sec]
EPOCH 190/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5886178783301113		[learning rate: 0.0060954]
	Learning Rate: 0.00609537
	LOSS [training: 1.5886178783301113 | validation: 1.2475121655892298]
	TIME [epoch: 27.8 sec]
EPOCH 191/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.342743532409326		[learning rate: 0.0060738]
	Learning Rate: 0.00607382
	LOSS [training: 1.342743532409326 | validation: 1.4883171845031709]
	TIME [epoch: 27.8 sec]
EPOCH 192/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1547644624432996		[learning rate: 0.0060523]
	Learning Rate: 0.00605234
	LOSS [training: 1.1547644624432996 | validation: 0.8742796460929843]
	TIME [epoch: 27.8 sec]
EPOCH 193/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0904942692459092		[learning rate: 0.0060309]
	Learning Rate: 0.00603093
	LOSS [training: 1.0904942692459092 | validation: 0.829980287221547]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_193.pth
	Model improved!!!
EPOCH 194/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0580518141406767		[learning rate: 0.0060096]
	Learning Rate: 0.00600961
	LOSS [training: 1.0580518141406767 | validation: 1.0336472162658166]
	TIME [epoch: 27.8 sec]
EPOCH 195/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1567910121144696		[learning rate: 0.0059884]
	Learning Rate: 0.00598836
	LOSS [training: 1.1567910121144696 | validation: 0.7472150762047737]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_195.pth
	Model improved!!!
EPOCH 196/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7722259976059797		[learning rate: 0.0059672]
	Learning Rate: 0.00596718
	LOSS [training: 0.7722259976059797 | validation: 1.085384433618589]
	TIME [epoch: 27.9 sec]
EPOCH 197/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9243948384622762		[learning rate: 0.0059461]
	Learning Rate: 0.00594608
	LOSS [training: 0.9243948384622762 | validation: 0.7877144807781936]
	TIME [epoch: 27.9 sec]
EPOCH 198/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9909948105898526		[learning rate: 0.0059251]
	Learning Rate: 0.00592505
	LOSS [training: 0.9909948105898526 | validation: 0.9590841106242743]
	TIME [epoch: 27.9 sec]
EPOCH 199/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9212282589104225		[learning rate: 0.0059041]
	Learning Rate: 0.0059041
	LOSS [training: 0.9212282589104225 | validation: 1.0061723230311186]
	TIME [epoch: 27.9 sec]
EPOCH 200/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.006748081778762		[learning rate: 0.0058832]
	Learning Rate: 0.00588322
	LOSS [training: 1.006748081778762 | validation: 0.7005541142055344]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_200.pth
	Model improved!!!
EPOCH 201/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0696070822084394		[learning rate: 0.0058624]
	Learning Rate: 0.00586242
	LOSS [training: 1.0696070822084394 | validation: 0.7653169372305385]
	TIME [epoch: 27.9 sec]
EPOCH 202/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8164252572606268		[learning rate: 0.0058417]
	Learning Rate: 0.00584169
	LOSS [training: 0.8164252572606268 | validation: 1.7131205975509227]
	TIME [epoch: 27.9 sec]
EPOCH 203/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1250618954949043		[learning rate: 0.005821]
	Learning Rate: 0.00582103
	LOSS [training: 1.1250618954949043 | validation: 0.6998765540958266]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_203.pth
	Model improved!!!
EPOCH 204/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7529174258295921		[learning rate: 0.0058004]
	Learning Rate: 0.00580045
	LOSS [training: 0.7529174258295921 | validation: 0.5777843091276498]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_204.pth
	Model improved!!!
EPOCH 205/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6399688365801045		[learning rate: 0.0057799]
	Learning Rate: 0.00577994
	LOSS [training: 0.6399688365801045 | validation: 1.6351807654036963]
	TIME [epoch: 27.8 sec]
EPOCH 206/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.165263625534633		[learning rate: 0.0057595]
	Learning Rate: 0.0057595
	LOSS [training: 1.165263625534633 | validation: 0.8822392651674126]
	TIME [epoch: 27.7 sec]
EPOCH 207/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.5008833825993113		[learning rate: 0.0057391]
	Learning Rate: 0.00573913
	LOSS [training: 1.5008833825993113 | validation: 1.2931216932144014]
	TIME [epoch: 27.7 sec]
EPOCH 208/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9986596218288282		[learning rate: 0.0057188]
	Learning Rate: 0.00571884
	LOSS [training: 0.9986596218288282 | validation: 0.8740854316693845]
	TIME [epoch: 27.8 sec]
EPOCH 209/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7715347332964082		[learning rate: 0.0056986]
	Learning Rate: 0.00569861
	LOSS [training: 0.7715347332964082 | validation: 1.3175148028144756]
	TIME [epoch: 27.8 sec]
EPOCH 210/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8826040051962174		[learning rate: 0.0056785]
	Learning Rate: 0.00567846
	LOSS [training: 0.8826040051962174 | validation: 0.7034131559808499]
	TIME [epoch: 27.9 sec]
EPOCH 211/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6741294647207988		[learning rate: 0.0056584]
	Learning Rate: 0.00565838
	LOSS [training: 0.6741294647207988 | validation: 0.6607398342949743]
	TIME [epoch: 27.9 sec]
EPOCH 212/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6789365588517577		[learning rate: 0.0056384]
	Learning Rate: 0.00563837
	LOSS [training: 0.6789365588517577 | validation: 0.9834554739199516]
	TIME [epoch: 27.9 sec]
EPOCH 213/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8450791962065195		[learning rate: 0.0056184]
	Learning Rate: 0.00561843
	LOSS [training: 0.8450791962065195 | validation: 1.1097699541032802]
	TIME [epoch: 27.9 sec]
EPOCH 214/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0241537112230534		[learning rate: 0.0055986]
	Learning Rate: 0.00559857
	LOSS [training: 1.0241537112230534 | validation: 0.811389332694356]
	TIME [epoch: 27.9 sec]
EPOCH 215/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9056255270882471		[learning rate: 0.0055788]
	Learning Rate: 0.00557877
	LOSS [training: 0.9056255270882471 | validation: 0.6704374021722025]
	TIME [epoch: 27.9 sec]
EPOCH 216/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2898508251129892		[learning rate: 0.005559]
	Learning Rate: 0.00555904
	LOSS [training: 1.2898508251129892 | validation: 0.8696246159572829]
	TIME [epoch: 27.9 sec]
EPOCH 217/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7571293055002128		[learning rate: 0.0055394]
	Learning Rate: 0.00553939
	LOSS [training: 0.7571293055002128 | validation: 1.2451223332945822]
	TIME [epoch: 27.9 sec]
EPOCH 218/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.909216395093337		[learning rate: 0.0055198]
	Learning Rate: 0.0055198
	LOSS [training: 0.909216395093337 | validation: 0.7491621518295386]
	TIME [epoch: 27.9 sec]
EPOCH 219/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.268616924236689		[learning rate: 0.0055003]
	Learning Rate: 0.00550028
	LOSS [training: 1.268616924236689 | validation: 1.1035705036812653]
	TIME [epoch: 27.9 sec]
EPOCH 220/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9878710210168679		[learning rate: 0.0054808]
	Learning Rate: 0.00548083
	LOSS [training: 0.9878710210168679 | validation: 0.6096313915583688]
	TIME [epoch: 27.8 sec]
EPOCH 221/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.255580252891956		[learning rate: 0.0054614]
	Learning Rate: 0.00546145
	LOSS [training: 1.255580252891956 | validation: 1.360272148854772]
	TIME [epoch: 27.9 sec]
EPOCH 222/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.059820494160388		[learning rate: 0.0054421]
	Learning Rate: 0.00544213
	LOSS [training: 1.059820494160388 | validation: 1.1577051313112117]
	TIME [epoch: 27.9 sec]
EPOCH 223/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2636264580080978		[learning rate: 0.0054229]
	Learning Rate: 0.00542289
	LOSS [training: 1.2636264580080978 | validation: 1.252898171094275]
	TIME [epoch: 27.9 sec]
EPOCH 224/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9702781000022086		[learning rate: 0.0054037]
	Learning Rate: 0.00540371
	LOSS [training: 0.9702781000022086 | validation: 1.5926059418250527]
	TIME [epoch: 27.9 sec]
EPOCH 225/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7134267073061833		[learning rate: 0.0053846]
	Learning Rate: 0.0053846
	LOSS [training: 1.7134267073061833 | validation: 2.4371234789745615]
	TIME [epoch: 27.8 sec]
EPOCH 226/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6329644090082085		[learning rate: 0.0053656]
	Learning Rate: 0.00536556
	LOSS [training: 1.6329644090082085 | validation: 0.6053290788475206]
	TIME [epoch: 27.9 sec]
EPOCH 227/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7868904906721093		[learning rate: 0.0053466]
	Learning Rate: 0.00534659
	LOSS [training: 0.7868904906721093 | validation: 1.2241675106822134]
	TIME [epoch: 27.9 sec]
EPOCH 228/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8995386572829399		[learning rate: 0.0053277]
	Learning Rate: 0.00532768
	LOSS [training: 0.8995386572829399 | validation: 0.8812105065679208]
	TIME [epoch: 27.9 sec]
EPOCH 229/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8606168533074794		[learning rate: 0.0053088]
	Learning Rate: 0.00530885
	LOSS [training: 0.8606168533074794 | validation: 0.8510059729266436]
	TIME [epoch: 27.9 sec]
EPOCH 230/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0213067419149844		[learning rate: 0.0052901]
	Learning Rate: 0.00529007
	LOSS [training: 1.0213067419149844 | validation: 0.9175003468733434]
	TIME [epoch: 27.9 sec]
EPOCH 231/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9463261595300294		[learning rate: 0.0052714]
	Learning Rate: 0.00527136
	LOSS [training: 0.9463261595300294 | validation: 0.993030779355187]
	TIME [epoch: 27.9 sec]
EPOCH 232/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9472013820423103		[learning rate: 0.0052527]
	Learning Rate: 0.00525272
	LOSS [training: 0.9472013820423103 | validation: 0.7143446767699578]
	TIME [epoch: 27.9 sec]
EPOCH 233/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.832422104689591		[learning rate: 0.0052341]
	Learning Rate: 0.00523415
	LOSS [training: 0.832422104689591 | validation: 0.7543201929248926]
	TIME [epoch: 27.9 sec]
EPOCH 234/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8757097790500503		[learning rate: 0.0052156]
	Learning Rate: 0.00521564
	LOSS [training: 0.8757097790500503 | validation: 0.7443860439348648]
	TIME [epoch: 27.9 sec]
EPOCH 235/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6957688588075233		[learning rate: 0.0051972]
	Learning Rate: 0.0051972
	LOSS [training: 0.6957688588075233 | validation: 0.7208749923364819]
	TIME [epoch: 27.9 sec]
EPOCH 236/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9684448110389037		[learning rate: 0.0051788]
	Learning Rate: 0.00517882
	LOSS [training: 0.9684448110389037 | validation: 0.7248353386657698]
	TIME [epoch: 27.9 sec]
EPOCH 237/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0240904907220667		[learning rate: 0.0051605]
	Learning Rate: 0.00516051
	LOSS [training: 1.0240904907220667 | validation: 0.7126134846017965]
	TIME [epoch: 27.9 sec]
EPOCH 238/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6661107623850904		[learning rate: 0.0051423]
	Learning Rate: 0.00514226
	LOSS [training: 0.6661107623850904 | validation: 0.6235855898320936]
	TIME [epoch: 27.9 sec]
EPOCH 239/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.695762265000694		[learning rate: 0.0051241]
	Learning Rate: 0.00512407
	LOSS [training: 0.695762265000694 | validation: 0.6878513707868747]
	TIME [epoch: 27.9 sec]
EPOCH 240/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.870227702942834		[learning rate: 0.005106]
	Learning Rate: 0.00510596
	LOSS [training: 0.870227702942834 | validation: 2.279257798862078]
	TIME [epoch: 27.9 sec]
EPOCH 241/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7335508538498559		[learning rate: 0.0050879]
	Learning Rate: 0.0050879
	LOSS [training: 1.7335508538498559 | validation: 1.1587786488927116]
	TIME [epoch: 27.9 sec]
EPOCH 242/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8685750129799953		[learning rate: 0.0050699]
	Learning Rate: 0.00506991
	LOSS [training: 0.8685750129799953 | validation: 1.0709395277051372]
	TIME [epoch: 27.9 sec]
EPOCH 243/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1090077032041405		[learning rate: 0.005052]
	Learning Rate: 0.00505198
	LOSS [training: 1.1090077032041405 | validation: 0.6760110496220665]
	TIME [epoch: 27.9 sec]
EPOCH 244/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7764340745221876		[learning rate: 0.0050341]
	Learning Rate: 0.00503411
	LOSS [training: 0.7764340745221876 | validation: 0.6760199786338197]
	TIME [epoch: 27.9 sec]
EPOCH 245/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.687250602333877		[learning rate: 0.0050163]
	Learning Rate: 0.00501631
	LOSS [training: 0.687250602333877 | validation: 0.670045801957104]
	TIME [epoch: 27.8 sec]
EPOCH 246/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7999053387428251		[learning rate: 0.0049986]
	Learning Rate: 0.00499857
	LOSS [training: 0.7999053387428251 | validation: 0.8878335871015318]
	TIME [epoch: 27.8 sec]
EPOCH 247/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7704949849001642		[learning rate: 0.0049809]
	Learning Rate: 0.0049809
	LOSS [training: 0.7704949849001642 | validation: 0.7951924398153224]
	TIME [epoch: 27.8 sec]
EPOCH 248/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7807134553739234		[learning rate: 0.0049633]
	Learning Rate: 0.00496329
	LOSS [training: 0.7807134553739234 | validation: 0.7601836354646156]
	TIME [epoch: 27.8 sec]
EPOCH 249/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8714556355717165		[learning rate: 0.0049457]
	Learning Rate: 0.00494573
	LOSS [training: 0.8714556355717165 | validation: 0.9302739056647724]
	TIME [epoch: 27.9 sec]
EPOCH 250/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9784936054698345		[learning rate: 0.0049282]
	Learning Rate: 0.00492824
	LOSS [training: 0.9784936054698345 | validation: 0.706261883761284]
	TIME [epoch: 27.9 sec]
EPOCH 251/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.762113884302298		[learning rate: 0.0049108]
	Learning Rate: 0.00491082
	LOSS [training: 0.762113884302298 | validation: 0.6633815343232464]
	TIME [epoch: 27.9 sec]
EPOCH 252/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6703512199840505		[learning rate: 0.0048935]
	Learning Rate: 0.00489345
	LOSS [training: 0.6703512199840505 | validation: 0.6306889659533096]
	TIME [epoch: 27.9 sec]
EPOCH 253/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9014911589844723		[learning rate: 0.0048761]
	Learning Rate: 0.00487615
	LOSS [training: 0.9014911589844723 | validation: 1.332586526639927]
	TIME [epoch: 27.9 sec]
EPOCH 254/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9913754254089919		[learning rate: 0.0048589]
	Learning Rate: 0.00485891
	LOSS [training: 0.9913754254089919 | validation: 0.6552840870450275]
	TIME [epoch: 27.9 sec]
EPOCH 255/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.744472872747463		[learning rate: 0.0048417]
	Learning Rate: 0.00484172
	LOSS [training: 0.744472872747463 | validation: 0.6977904568088299]
	TIME [epoch: 27.9 sec]
EPOCH 256/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7634896992837533		[learning rate: 0.0048246]
	Learning Rate: 0.0048246
	LOSS [training: 0.7634896992837533 | validation: 0.8451512149146885]
	TIME [epoch: 27.9 sec]
EPOCH 257/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9203046833031274		[learning rate: 0.0048075]
	Learning Rate: 0.00480754
	LOSS [training: 0.9203046833031274 | validation: 1.109461607017304]
	TIME [epoch: 27.9 sec]
EPOCH 258/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9540008894988105		[learning rate: 0.0047905]
	Learning Rate: 0.00479054
	LOSS [training: 0.9540008894988105 | validation: 0.6915897917025275]
	TIME [epoch: 27.9 sec]
EPOCH 259/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8324139750766033		[learning rate: 0.0047736]
	Learning Rate: 0.0047736
	LOSS [training: 0.8324139750766033 | validation: 1.8020394435912772]
	TIME [epoch: 27.9 sec]
EPOCH 260/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.309329246442181		[learning rate: 0.0047567]
	Learning Rate: 0.00475672
	LOSS [training: 1.309329246442181 | validation: 0.9171926987907231]
	TIME [epoch: 27.8 sec]
EPOCH 261/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9926368886180432		[learning rate: 0.0047399]
	Learning Rate: 0.0047399
	LOSS [training: 0.9926368886180432 | validation: 0.8231971255479771]
	TIME [epoch: 27.9 sec]
EPOCH 262/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7899736782850307		[learning rate: 0.0047231]
	Learning Rate: 0.00472314
	LOSS [training: 0.7899736782850307 | validation: 1.0243183610296966]
	TIME [epoch: 27.9 sec]
EPOCH 263/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.858364631653225		[learning rate: 0.0047064]
	Learning Rate: 0.00470644
	LOSS [training: 0.858364631653225 | validation: 1.3446772002225265]
	TIME [epoch: 27.8 sec]
EPOCH 264/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1507622474552242		[learning rate: 0.0046898]
	Learning Rate: 0.00468979
	LOSS [training: 1.1507622474552242 | validation: 0.8386192697255745]
	TIME [epoch: 27.9 sec]
EPOCH 265/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8971216422212817		[learning rate: 0.0046732]
	Learning Rate: 0.00467321
	LOSS [training: 0.8971216422212817 | validation: 0.8014254488249489]
	TIME [epoch: 27.9 sec]
EPOCH 266/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8732114594999649		[learning rate: 0.0046567]
	Learning Rate: 0.00465669
	LOSS [training: 0.8732114594999649 | validation: 1.1202071953801742]
	TIME [epoch: 27.9 sec]
EPOCH 267/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0453778510836087		[learning rate: 0.0046402]
	Learning Rate: 0.00464022
	LOSS [training: 1.0453778510836087 | validation: 0.6582529976431432]
	TIME [epoch: 27.8 sec]
EPOCH 268/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7049231963841551		[learning rate: 0.0046238]
	Learning Rate: 0.00462381
	LOSS [training: 0.7049231963841551 | validation: 0.7292645630121746]
	TIME [epoch: 27.8 sec]
EPOCH 269/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.852902110886114		[learning rate: 0.0046075]
	Learning Rate: 0.00460746
	LOSS [training: 0.852902110886114 | validation: 0.7231940222296109]
	TIME [epoch: 27.8 sec]
EPOCH 270/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8834194987371724		[learning rate: 0.0045912]
	Learning Rate: 0.00459117
	LOSS [training: 0.8834194987371724 | validation: 1.149164372420552]
	TIME [epoch: 27.8 sec]
EPOCH 271/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9424282482087414		[learning rate: 0.0045749]
	Learning Rate: 0.00457493
	LOSS [training: 0.9424282482087414 | validation: 0.6942038094073385]
	TIME [epoch: 27.9 sec]
EPOCH 272/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7576341217288589		[learning rate: 0.0045588]
	Learning Rate: 0.00455875
	LOSS [training: 0.7576341217288589 | validation: 0.6587061433764153]
	TIME [epoch: 27.9 sec]
EPOCH 273/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6586697469331719		[learning rate: 0.0045426]
	Learning Rate: 0.00454263
	LOSS [training: 0.6586697469331719 | validation: 1.0303678575580508]
	TIME [epoch: 27.9 sec]
EPOCH 274/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9525328452591907		[learning rate: 0.0045266]
	Learning Rate: 0.00452657
	LOSS [training: 0.9525328452591907 | validation: 0.8412579113672567]
	TIME [epoch: 27.9 sec]
EPOCH 275/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7927977136498023		[learning rate: 0.0045106]
	Learning Rate: 0.00451056
	LOSS [training: 0.7927977136498023 | validation: 0.9439541073305354]
	TIME [epoch: 27.9 sec]
EPOCH 276/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1983654345016275		[learning rate: 0.0044946]
	Learning Rate: 0.00449461
	LOSS [training: 1.1983654345016275 | validation: 1.5962751059608957]
	TIME [epoch: 27.9 sec]
EPOCH 277/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0804195643970733		[learning rate: 0.0044787]
	Learning Rate: 0.00447872
	LOSS [training: 1.0804195643970733 | validation: 0.9928629662124313]
	TIME [epoch: 27.9 sec]
EPOCH 278/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7170205682023127		[learning rate: 0.0044629]
	Learning Rate: 0.00446288
	LOSS [training: 0.7170205682023127 | validation: 0.7723286882309097]
	TIME [epoch: 27.9 sec]
EPOCH 279/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7952634076551875		[learning rate: 0.0044471]
	Learning Rate: 0.0044471
	LOSS [training: 0.7952634076551875 | validation: 0.7267448932895036]
	TIME [epoch: 27.9 sec]
EPOCH 280/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6773434502849939		[learning rate: 0.0044314]
	Learning Rate: 0.00443137
	LOSS [training: 0.6773434502849939 | validation: 1.2001096891165224]
	TIME [epoch: 27.8 sec]
EPOCH 281/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.323996846451929		[learning rate: 0.0044157]
	Learning Rate: 0.0044157
	LOSS [training: 1.323996846451929 | validation: 1.1358064022149064]
	TIME [epoch: 27.8 sec]
EPOCH 282/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0190907488295224		[learning rate: 0.0044001]
	Learning Rate: 0.00440009
	LOSS [training: 1.0190907488295224 | validation: 1.0489466280414927]
	TIME [epoch: 27.8 sec]
EPOCH 283/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8813679697345811		[learning rate: 0.0043845]
	Learning Rate: 0.00438453
	LOSS [training: 0.8813679697345811 | validation: 0.7259672788122765]
	TIME [epoch: 27.8 sec]
EPOCH 284/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9874934047929176		[learning rate: 0.004369]
	Learning Rate: 0.00436903
	LOSS [training: 0.9874934047929176 | validation: 1.4276276640327348]
	TIME [epoch: 27.9 sec]
EPOCH 285/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9346084273478825		[learning rate: 0.0043536]
	Learning Rate: 0.00435358
	LOSS [training: 0.9346084273478825 | validation: 0.7478638531394387]
	TIME [epoch: 27.8 sec]
EPOCH 286/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0380916347942488		[learning rate: 0.0043382]
	Learning Rate: 0.00433818
	LOSS [training: 1.0380916347942488 | validation: 1.1595659966449963]
	TIME [epoch: 27.9 sec]
EPOCH 287/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0353229874031602		[learning rate: 0.0043228]
	Learning Rate: 0.00432284
	LOSS [training: 1.0353229874031602 | validation: 0.7749278299738418]
	TIME [epoch: 27.9 sec]
EPOCH 288/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6910125106220142		[learning rate: 0.0043076]
	Learning Rate: 0.00430755
	LOSS [training: 0.6910125106220142 | validation: 1.194889338988422]
	TIME [epoch: 27.9 sec]
EPOCH 289/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.958247754361551		[learning rate: 0.0042923]
	Learning Rate: 0.00429232
	LOSS [training: 0.958247754361551 | validation: 2.0313116757294853]
	TIME [epoch: 27.9 sec]
EPOCH 290/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7630251129084193		[learning rate: 0.0042771]
	Learning Rate: 0.00427714
	LOSS [training: 1.7630251129084193 | validation: 1.8621346988675853]
	TIME [epoch: 27.9 sec]
EPOCH 291/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1982683967247572		[learning rate: 0.004262]
	Learning Rate: 0.00426202
	LOSS [training: 1.1982683967247572 | validation: 0.6450458556475794]
	TIME [epoch: 27.9 sec]
EPOCH 292/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7821559720208522		[learning rate: 0.0042469]
	Learning Rate: 0.00424695
	LOSS [training: 0.7821559720208522 | validation: 2.1143117494918204]
	TIME [epoch: 27.8 sec]
EPOCH 293/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2952397978549959		[learning rate: 0.0042319]
	Learning Rate: 0.00423193
	LOSS [training: 1.2952397978549959 | validation: 0.5880209150691363]
	TIME [epoch: 27.7 sec]
EPOCH 294/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6541419636986909		[learning rate: 0.004217]
	Learning Rate: 0.00421696
	LOSS [training: 0.6541419636986909 | validation: 0.589811215571249]
	TIME [epoch: 27.8 sec]
EPOCH 295/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8932336390116309		[learning rate: 0.0042021]
	Learning Rate: 0.00420205
	LOSS [training: 0.8932336390116309 | validation: 0.798595218894626]
	TIME [epoch: 27.8 sec]
EPOCH 296/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7236973367519356		[learning rate: 0.0041872]
	Learning Rate: 0.00418719
	LOSS [training: 0.7236973367519356 | validation: 0.7945019733420208]
	TIME [epoch: 27.9 sec]
EPOCH 297/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7111231465713176		[learning rate: 0.0041724]
	Learning Rate: 0.00417239
	LOSS [training: 0.7111231465713176 | validation: 0.589346321299168]
	TIME [epoch: 27.9 sec]
EPOCH 298/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7299384290611387		[learning rate: 0.0041576]
	Learning Rate: 0.00415763
	LOSS [training: 0.7299384290611387 | validation: 0.6338823631982287]
	TIME [epoch: 27.9 sec]
EPOCH 299/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8239744681481581		[learning rate: 0.0041429]
	Learning Rate: 0.00414293
	LOSS [training: 0.8239744681481581 | validation: 0.8711069478669465]
	TIME [epoch: 27.8 sec]
EPOCH 300/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8187536189461062		[learning rate: 0.0041283]
	Learning Rate: 0.00412828
	LOSS [training: 0.8187536189461062 | validation: 0.6754228542398542]
	TIME [epoch: 27.7 sec]
EPOCH 301/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7575421614358437		[learning rate: 0.0041137]
	Learning Rate: 0.00411368
	LOSS [training: 0.7575421614358437 | validation: 0.6425041274004084]
	TIME [epoch: 27.8 sec]
EPOCH 302/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6745119378833678		[learning rate: 0.0040991]
	Learning Rate: 0.00409914
	LOSS [training: 0.6745119378833678 | validation: 0.7361115169045727]
	TIME [epoch: 27.8 sec]
EPOCH 303/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8545557158797307		[learning rate: 0.0040846]
	Learning Rate: 0.00408464
	LOSS [training: 0.8545557158797307 | validation: 0.733271551308476]
	TIME [epoch: 27.8 sec]
EPOCH 304/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9896606035779393		[learning rate: 0.0040702]
	Learning Rate: 0.0040702
	LOSS [training: 0.9896606035779393 | validation: 0.7050972059014484]
	TIME [epoch: 27.9 sec]
EPOCH 305/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6315416886347561		[learning rate: 0.0040558]
	Learning Rate: 0.0040558
	LOSS [training: 0.6315416886347561 | validation: 0.6042341938953478]
	TIME [epoch: 27.9 sec]
EPOCH 306/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6775608027027991		[learning rate: 0.0040415]
	Learning Rate: 0.00404146
	LOSS [training: 0.6775608027027991 | validation: 0.6000370191319598]
	TIME [epoch: 27.9 sec]
EPOCH 307/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6694505671676491		[learning rate: 0.0040272]
	Learning Rate: 0.00402717
	LOSS [training: 0.6694505671676491 | validation: 0.8140808425210664]
	TIME [epoch: 27.9 sec]
EPOCH 308/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8235660299119989		[learning rate: 0.0040129]
	Learning Rate: 0.00401293
	LOSS [training: 0.8235660299119989 | validation: 0.6515557765587932]
	TIME [epoch: 27.9 sec]
EPOCH 309/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7402428383414323		[learning rate: 0.0039987]
	Learning Rate: 0.00399874
	LOSS [training: 0.7402428383414323 | validation: 1.0234654144064588]
	TIME [epoch: 27.9 sec]
EPOCH 310/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8705164754327143		[learning rate: 0.0039846]
	Learning Rate: 0.0039846
	LOSS [training: 0.8705164754327143 | validation: 0.6390085393193624]
	TIME [epoch: 27.9 sec]
EPOCH 311/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2706189632664626		[learning rate: 0.0039705]
	Learning Rate: 0.00397051
	LOSS [training: 1.2706189632664626 | validation: 1.045308030152598]
	TIME [epoch: 27.8 sec]
EPOCH 312/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.269277888587663		[learning rate: 0.0039565]
	Learning Rate: 0.00395647
	LOSS [training: 1.269277888587663 | validation: 0.7109936552897145]
	TIME [epoch: 27.9 sec]
EPOCH 313/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8488202911798548		[learning rate: 0.0039425]
	Learning Rate: 0.00394248
	LOSS [training: 0.8488202911798548 | validation: 0.7007506126458257]
	TIME [epoch: 27.8 sec]
EPOCH 314/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7961978315499285		[learning rate: 0.0039285]
	Learning Rate: 0.00392854
	LOSS [training: 0.7961978315499285 | validation: 0.8076793717140109]
	TIME [epoch: 27.9 sec]
EPOCH 315/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7837644824052745		[learning rate: 0.0039146]
	Learning Rate: 0.00391464
	LOSS [training: 0.7837644824052745 | validation: 0.6508060713846966]
	TIME [epoch: 27.9 sec]
EPOCH 316/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.498029521369163		[learning rate: 0.0039008]
	Learning Rate: 0.0039008
	LOSS [training: 2.498029521369163 | validation: 0.8759715134209998]
	TIME [epoch: 27.8 sec]
EPOCH 317/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.101909624126824		[learning rate: 0.003887]
	Learning Rate: 0.00388701
	LOSS [training: 1.101909624126824 | validation: 0.7021484728307676]
	TIME [epoch: 27.9 sec]
EPOCH 318/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.672970285614003		[learning rate: 0.0038733]
	Learning Rate: 0.00387326
	LOSS [training: 0.672970285614003 | validation: 0.6248671502970529]
	TIME [epoch: 27.9 sec]
EPOCH 319/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.812320256139071		[learning rate: 0.0038596]
	Learning Rate: 0.00385957
	LOSS [training: 0.812320256139071 | validation: 0.8797916813572436]
	TIME [epoch: 27.9 sec]
EPOCH 320/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9458414272178597		[learning rate: 0.0038459]
	Learning Rate: 0.00384592
	LOSS [training: 0.9458414272178597 | validation: 1.0431476598713159]
	TIME [epoch: 27.9 sec]
EPOCH 321/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8297267349122228		[learning rate: 0.0038323]
	Learning Rate: 0.00383232
	LOSS [training: 0.8297267349122228 | validation: 0.9088044821091329]
	TIME [epoch: 27.9 sec]
EPOCH 322/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6876680474631489		[learning rate: 0.0038188]
	Learning Rate: 0.00381877
	LOSS [training: 0.6876680474631489 | validation: 0.6384030025062406]
	TIME [epoch: 27.9 sec]
EPOCH 323/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6696275245337058		[learning rate: 0.0038053]
	Learning Rate: 0.00380526
	LOSS [training: 0.6696275245337058 | validation: 0.8404002914138741]
	TIME [epoch: 27.9 sec]
EPOCH 324/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8690591266115391		[learning rate: 0.0037918]
	Learning Rate: 0.00379181
	LOSS [training: 0.8690591266115391 | validation: 0.5679625058274114]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_324.pth
	Model improved!!!
EPOCH 325/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8088233228952271		[learning rate: 0.0037784]
	Learning Rate: 0.0037784
	LOSS [training: 0.8088233228952271 | validation: 0.719745494290608]
	TIME [epoch: 27.9 sec]
EPOCH 326/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6482508065578234		[learning rate: 0.003765]
	Learning Rate: 0.00376504
	LOSS [training: 0.6482508065578234 | validation: 0.7954161866170872]
	TIME [epoch: 27.9 sec]
EPOCH 327/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.791875753201798		[learning rate: 0.0037517]
	Learning Rate: 0.00375172
	LOSS [training: 0.791875753201798 | validation: 0.864407596153327]
	TIME [epoch: 27.9 sec]
EPOCH 328/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9166602737763854		[learning rate: 0.0037385]
	Learning Rate: 0.00373846
	LOSS [training: 0.9166602737763854 | validation: 0.7372231921129204]
	TIME [epoch: 27.9 sec]
EPOCH 329/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7263266010644593		[learning rate: 0.0037252]
	Learning Rate: 0.00372524
	LOSS [training: 0.7263266010644593 | validation: 1.0774215160061718]
	TIME [epoch: 27.9 sec]
EPOCH 330/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9863969415825217		[learning rate: 0.0037121]
	Learning Rate: 0.00371206
	LOSS [training: 0.9863969415825217 | validation: 0.7870084074742425]
	TIME [epoch: 27.9 sec]
EPOCH 331/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6691290977880986		[learning rate: 0.0036989]
	Learning Rate: 0.00369894
	LOSS [training: 0.6691290977880986 | validation: 0.9289056304129051]
	TIME [epoch: 27.8 sec]
EPOCH 332/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8852524391471713		[learning rate: 0.0036859]
	Learning Rate: 0.00368586
	LOSS [training: 0.8852524391471713 | validation: 0.9504801900365851]
	TIME [epoch: 27.8 sec]
EPOCH 333/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8803774337181509		[learning rate: 0.0036728]
	Learning Rate: 0.00367282
	LOSS [training: 0.8803774337181509 | validation: 0.768938481819454]
	TIME [epoch: 27.8 sec]
EPOCH 334/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.703073116084161		[learning rate: 0.0036598]
	Learning Rate: 0.00365984
	LOSS [training: 0.703073116084161 | validation: 1.238322536934234]
	TIME [epoch: 27.8 sec]
EPOCH 335/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.216743397782435		[learning rate: 0.0036469]
	Learning Rate: 0.00364689
	LOSS [training: 1.216743397782435 | validation: 1.2278926324456132]
	TIME [epoch: 27.9 sec]
EPOCH 336/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9432251043324488		[learning rate: 0.003634]
	Learning Rate: 0.003634
	LOSS [training: 0.9432251043324488 | validation: 0.7383151805481029]
	TIME [epoch: 27.8 sec]
EPOCH 337/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7475644060876534		[learning rate: 0.0036211]
	Learning Rate: 0.00362115
	LOSS [training: 0.7475644060876534 | validation: 0.7502945864507031]
	TIME [epoch: 27.9 sec]
EPOCH 338/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7665913702967208		[learning rate: 0.0036083]
	Learning Rate: 0.00360834
	LOSS [training: 0.7665913702967208 | validation: 0.805168853622242]
	TIME [epoch: 27.9 sec]
EPOCH 339/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.7803413368632575		[learning rate: 0.0035956]
	Learning Rate: 0.00359558
	LOSS [training: 1.7803413368632575 | validation: 0.7995337233373556]
	TIME [epoch: 27.8 sec]
EPOCH 340/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9346128560834193		[learning rate: 0.0035829]
	Learning Rate: 0.00358287
	LOSS [training: 0.9346128560834193 | validation: 1.2508083522059505]
	TIME [epoch: 27.8 sec]
EPOCH 341/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8877221390592391		[learning rate: 0.0035702]
	Learning Rate: 0.0035702
	LOSS [training: 0.8877221390592391 | validation: 1.2954460726548507]
	TIME [epoch: 27.7 sec]
EPOCH 342/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9875895096790765		[learning rate: 0.0035576]
	Learning Rate: 0.00355757
	LOSS [training: 0.9875895096790765 | validation: 0.6238304896780144]
	TIME [epoch: 27.8 sec]
EPOCH 343/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.869341103840731		[learning rate: 0.003545]
	Learning Rate: 0.00354499
	LOSS [training: 0.869341103840731 | validation: 1.9478293518534755]
	TIME [epoch: 27.8 sec]
EPOCH 344/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2197263697232963		[learning rate: 0.0035325]
	Learning Rate: 0.00353246
	LOSS [training: 1.2197263697232963 | validation: 0.636451141045781]
	TIME [epoch: 27.9 sec]
EPOCH 345/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.722058494641248		[learning rate: 0.00352]
	Learning Rate: 0.00351997
	LOSS [training: 0.722058494641248 | validation: 1.0896888804808678]
	TIME [epoch: 27.9 sec]
EPOCH 346/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8502191867613814		[learning rate: 0.0035075]
	Learning Rate: 0.00350752
	LOSS [training: 0.8502191867613814 | validation: 0.9071634289285407]
	TIME [epoch: 27.9 sec]
EPOCH 347/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8601267053966163		[learning rate: 0.0034951]
	Learning Rate: 0.00349512
	LOSS [training: 0.8601267053966163 | validation: 1.493675713006091]
	TIME [epoch: 27.9 sec]
EPOCH 348/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0426147034875455		[learning rate: 0.0034828]
	Learning Rate: 0.00348276
	LOSS [training: 1.0426147034875455 | validation: 0.9451377986997178]
	TIME [epoch: 27.9 sec]
EPOCH 349/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.122388140555311		[learning rate: 0.0034704]
	Learning Rate: 0.00347044
	LOSS [training: 1.122388140555311 | validation: 1.0121633294804644]
	TIME [epoch: 27.9 sec]
EPOCH 350/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8186253135826758		[learning rate: 0.0034582]
	Learning Rate: 0.00345817
	LOSS [training: 0.8186253135826758 | validation: 1.0939426386753242]
	TIME [epoch: 27.9 sec]
EPOCH 351/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1244637804102535		[learning rate: 0.0034459]
	Learning Rate: 0.00344594
	LOSS [training: 1.1244637804102535 | validation: 0.845898102565718]
	TIME [epoch: 27.9 sec]
EPOCH 352/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.2042295525054105		[learning rate: 0.0034338]
	Learning Rate: 0.00343375
	LOSS [training: 1.2042295525054105 | validation: 0.6878727135731325]
	TIME [epoch: 27.9 sec]
EPOCH 353/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.1961010999781694		[learning rate: 0.0034216]
	Learning Rate: 0.00342161
	LOSS [training: 2.1961010999781694 | validation: 0.9445116447887134]
	TIME [epoch: 27.9 sec]
EPOCH 354/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9118637179955548		[learning rate: 0.0034095]
	Learning Rate: 0.00340951
	LOSS [training: 0.9118637179955548 | validation: 1.0467936683108146]
	TIME [epoch: 27.9 sec]
EPOCH 355/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3539772337264622		[learning rate: 0.0033975]
	Learning Rate: 0.00339746
	LOSS [training: 1.3539772337264622 | validation: 1.0733827270243106]
	TIME [epoch: 27.9 sec]
EPOCH 356/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.262381560705636		[learning rate: 0.0033854]
	Learning Rate: 0.00338544
	LOSS [training: 1.262381560705636 | validation: 0.90620142993093]
	TIME [epoch: 27.9 sec]
EPOCH 357/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7966416990269899		[learning rate: 0.0033735]
	Learning Rate: 0.00337347
	LOSS [training: 0.7966416990269899 | validation: 0.6876983758101203]
	TIME [epoch: 27.9 sec]
EPOCH 358/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8217778442322252		[learning rate: 0.0033615]
	Learning Rate: 0.00336154
	LOSS [training: 0.8217778442322252 | validation: 1.0464162314884369]
	TIME [epoch: 27.9 sec]
EPOCH 359/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8984018254810733		[learning rate: 0.0033497]
	Learning Rate: 0.00334965
	LOSS [training: 0.8984018254810733 | validation: 0.8811147963724686]
	TIME [epoch: 27.9 sec]
EPOCH 360/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8062844661689375		[learning rate: 0.0033378]
	Learning Rate: 0.00333781
	LOSS [training: 0.8062844661689375 | validation: 1.155151031105699]
	TIME [epoch: 27.9 sec]
EPOCH 361/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.328620830225712		[learning rate: 0.003326]
	Learning Rate: 0.00332601
	LOSS [training: 3.328620830225712 | validation: 3.4606386894960828]
	TIME [epoch: 27.8 sec]
EPOCH 362/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.486983654726142		[learning rate: 0.0033142]
	Learning Rate: 0.00331425
	LOSS [training: 3.486983654726142 | validation: 2.843105254410617]
	TIME [epoch: 27.8 sec]
EPOCH 363/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2666521932976216		[learning rate: 0.0033025]
	Learning Rate: 0.00330253
	LOSS [training: 3.2666521932976216 | validation: 2.678231733499462]
	TIME [epoch: 27.8 sec]
EPOCH 364/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2522988278454767		[learning rate: 0.0032908]
	Learning Rate: 0.00329085
	LOSS [training: 3.2522988278454767 | validation: 2.735272035228909]
	TIME [epoch: 27.8 sec]
EPOCH 365/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1967932400992445		[learning rate: 0.0032792]
	Learning Rate: 0.00327921
	LOSS [training: 3.1967932400992445 | validation: 2.766306414578141]
	TIME [epoch: 27.9 sec]
EPOCH 366/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2324001350373135		[learning rate: 0.0032676]
	Learning Rate: 0.00326761
	LOSS [training: 3.2324001350373135 | validation: 2.8234474021493488]
	TIME [epoch: 27.8 sec]
EPOCH 367/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3094757148036704		[learning rate: 0.0032561]
	Learning Rate: 0.00325606
	LOSS [training: 3.3094757148036704 | validation: 2.736327134829512]
	TIME [epoch: 27.8 sec]
EPOCH 368/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.202680239531844		[learning rate: 0.0032445]
	Learning Rate: 0.00324455
	LOSS [training: 3.202680239531844 | validation: 2.729850577079758]
	TIME [epoch: 27.8 sec]
EPOCH 369/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.168501588914711		[learning rate: 0.0032331]
	Learning Rate: 0.00323307
	LOSS [training: 3.168501588914711 | validation: 2.7352934503395363]
	TIME [epoch: 27.8 sec]
EPOCH 370/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.217163508568366		[learning rate: 0.0032216]
	Learning Rate: 0.00322164
	LOSS [training: 3.217163508568366 | validation: 2.897295476650833]
	TIME [epoch: 27.8 sec]
EPOCH 371/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.003930784425213		[learning rate: 0.0032102]
	Learning Rate: 0.00321025
	LOSS [training: 4.003930784425213 | validation: 4.118479865649853]
	TIME [epoch: 27.7 sec]
EPOCH 372/2000:
	Training over batches...
		[batch 4/4] avg loss: 4.534203239271795		[learning rate: 0.0031989]
	Learning Rate: 0.0031989
	LOSS [training: 4.534203239271795 | validation: 3.715744410665238]
	TIME [epoch: 27.7 sec]
EPOCH 373/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.8813719305572225		[learning rate: 0.0031876]
	Learning Rate: 0.00318758
	LOSS [training: 3.8813719305572225 | validation: 2.9348115072523724]
	TIME [epoch: 27.8 sec]
EPOCH 374/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.391627112669947		[learning rate: 0.0031763]
	Learning Rate: 0.00317631
	LOSS [training: 3.391627112669947 | validation: 2.9490986927917486]
	TIME [epoch: 27.8 sec]
EPOCH 375/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6663041006809216		[learning rate: 0.0031651]
	Learning Rate: 0.00316508
	LOSS [training: 3.6663041006809216 | validation: 3.2349313865308917]
	TIME [epoch: 27.8 sec]
EPOCH 376/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.9156558073777834		[learning rate: 0.0031539]
	Learning Rate: 0.00315389
	LOSS [training: 3.9156558073777834 | validation: 3.3683083517139973]
	TIME [epoch: 27.7 sec]
EPOCH 377/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.819073708587916		[learning rate: 0.0031427]
	Learning Rate: 0.00314273
	LOSS [training: 3.819073708587916 | validation: 2.9788410161712893]
	TIME [epoch: 27.8 sec]
EPOCH 378/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5354837606279172		[learning rate: 0.0031316]
	Learning Rate: 0.00313162
	LOSS [training: 3.5354837606279172 | validation: 2.879267028672276]
	TIME [epoch: 27.8 sec]
EPOCH 379/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.363310003075518		[learning rate: 0.0031205]
	Learning Rate: 0.00312055
	LOSS [training: 3.363310003075518 | validation: 2.7947649049323533]
	TIME [epoch: 27.8 sec]
EPOCH 380/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5200870991791358		[learning rate: 0.0031095]
	Learning Rate: 0.00310951
	LOSS [training: 3.5200870991791358 | validation: 3.2031383695701448]
	TIME [epoch: 27.8 sec]
EPOCH 381/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7861579691703904		[learning rate: 0.0030985]
	Learning Rate: 0.00309852
	LOSS [training: 3.7861579691703904 | validation: 2.8880017398282014]
	TIME [epoch: 27.7 sec]
EPOCH 382/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3220475449733424		[learning rate: 0.0030876]
	Learning Rate: 0.00308756
	LOSS [training: 3.3220475449733424 | validation: 2.770640299424116]
	TIME [epoch: 27.8 sec]
EPOCH 383/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.344705280974099		[learning rate: 0.0030766]
	Learning Rate: 0.00307664
	LOSS [training: 3.344705280974099 | validation: 2.807936105940308]
	TIME [epoch: 27.8 sec]
EPOCH 384/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2386369694155563		[learning rate: 0.0030658]
	Learning Rate: 0.00306576
	LOSS [training: 3.2386369694155563 | validation: 2.7686773472386506]
	TIME [epoch: 27.8 sec]
EPOCH 385/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.221590925861765		[learning rate: 0.0030549]
	Learning Rate: 0.00305492
	LOSS [training: 3.221590925861765 | validation: 2.7066217882591936]
	TIME [epoch: 27.8 sec]
EPOCH 386/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.186804927106735		[learning rate: 0.0030441]
	Learning Rate: 0.00304412
	LOSS [training: 3.186804927106735 | validation: 2.691098055717025]
	TIME [epoch: 27.8 sec]
EPOCH 387/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.173968520513398		[learning rate: 0.0030334]
	Learning Rate: 0.00303335
	LOSS [training: 3.173968520513398 | validation: 2.686524951885977]
	TIME [epoch: 27.8 sec]
EPOCH 388/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.166078202578956		[learning rate: 0.0030226]
	Learning Rate: 0.00302263
	LOSS [training: 3.166078202578956 | validation: 2.782140795399373]
	TIME [epoch: 27.8 sec]
EPOCH 389/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.650449547887902		[learning rate: 0.0030119]
	Learning Rate: 0.00301194
	LOSS [training: 3.650449547887902 | validation: 3.4038689475600066]
	TIME [epoch: 27.7 sec]
EPOCH 390/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.719520381911448		[learning rate: 0.0030013]
	Learning Rate: 0.00300129
	LOSS [training: 3.719520381911448 | validation: 2.8969086319335156]
	TIME [epoch: 27.8 sec]
EPOCH 391/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.382419541444571		[learning rate: 0.0029907]
	Learning Rate: 0.00299068
	LOSS [training: 3.382419541444571 | validation: 2.8892713038316957]
	TIME [epoch: 27.8 sec]
EPOCH 392/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.5514920763148967		[learning rate: 0.0029801]
	Learning Rate: 0.0029801
	LOSS [training: 3.5514920763148967 | validation: 3.2155110992803886]
	TIME [epoch: 27.8 sec]
EPOCH 393/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.7582514003398937		[learning rate: 0.0029696]
	Learning Rate: 0.00296956
	LOSS [training: 3.7582514003398937 | validation: 3.209080876721162]
	TIME [epoch: 27.7 sec]
EPOCH 394/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6056766722775153		[learning rate: 0.0029591]
	Learning Rate: 0.00295906
	LOSS [training: 3.6056766722775153 | validation: 2.961410483376475]
	TIME [epoch: 27.8 sec]
EPOCH 395/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.4730839008799066		[learning rate: 0.0029486]
	Learning Rate: 0.0029486
	LOSS [training: 3.4730839008799066 | validation: 2.896288980108073]
	TIME [epoch: 27.8 sec]
EPOCH 396/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.398356885050976		[learning rate: 0.0029382]
	Learning Rate: 0.00293817
	LOSS [training: 3.398356885050976 | validation: 2.8209903083883923]
	TIME [epoch: 27.8 sec]
EPOCH 397/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.405777601566036		[learning rate: 0.0029278]
	Learning Rate: 0.00292778
	LOSS [training: 3.405777601566036 | validation: 2.7859830747210994]
	TIME [epoch: 27.8 sec]
EPOCH 398/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.30641891632162		[learning rate: 0.0029174]
	Learning Rate: 0.00291743
	LOSS [training: 3.30641891632162 | validation: 2.7406094018812563]
	TIME [epoch: 27.9 sec]
EPOCH 399/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3759360113103556		[learning rate: 0.0029071]
	Learning Rate: 0.00290711
	LOSS [training: 3.3759360113103556 | validation: 2.6596652849421445]
	TIME [epoch: 27.8 sec]
EPOCH 400/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.145669947467333		[learning rate: 0.0028968]
	Learning Rate: 0.00289683
	LOSS [training: 3.145669947467333 | validation: 2.635352061192521]
	TIME [epoch: 27.8 sec]
EPOCH 401/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.230795802573427		[learning rate: 0.0028866]
	Learning Rate: 0.00288659
	LOSS [training: 3.230795802573427 | validation: 2.630973904640549]
	TIME [epoch: 27.8 sec]
EPOCH 402/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0740648859776916		[learning rate: 0.0028764]
	Learning Rate: 0.00287638
	LOSS [training: 3.0740648859776916 | validation: 3.041971502272271]
	TIME [epoch: 27.8 sec]
EPOCH 403/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3489667801254304		[learning rate: 0.0028662]
	Learning Rate: 0.00286621
	LOSS [training: 3.3489667801254304 | validation: 2.6820782527903777]
	TIME [epoch: 27.8 sec]
EPOCH 404/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.302377679763652		[learning rate: 0.0028561]
	Learning Rate: 0.00285607
	LOSS [training: 3.302377679763652 | validation: 2.931157762590973]
	TIME [epoch: 27.8 sec]
EPOCH 405/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2700288294779147		[learning rate: 0.002846]
	Learning Rate: 0.00284597
	LOSS [training: 3.2700288294779147 | validation: 2.643266794268202]
	TIME [epoch: 27.8 sec]
EPOCH 406/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2124732281374433		[learning rate: 0.0028359]
	Learning Rate: 0.00283591
	LOSS [training: 3.2124732281374433 | validation: 2.609647040304069]
	TIME [epoch: 27.8 sec]
EPOCH 407/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.453969262584679		[learning rate: 0.0028259]
	Learning Rate: 0.00282588
	LOSS [training: 3.453969262584679 | validation: 2.6642921642472404]
	TIME [epoch: 27.8 sec]
EPOCH 408/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1600746502094226		[learning rate: 0.0028159]
	Learning Rate: 0.00281589
	LOSS [training: 3.1600746502094226 | validation: 2.6426735211092076]
	TIME [epoch: 27.8 sec]
EPOCH 409/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.151926404355255		[learning rate: 0.0028059]
	Learning Rate: 0.00280593
	LOSS [training: 3.151926404355255 | validation: 2.831503740349877]
	TIME [epoch: 27.8 sec]
EPOCH 410/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.6601302612517337		[learning rate: 0.002796]
	Learning Rate: 0.00279601
	LOSS [training: 3.6601302612517337 | validation: 3.364138856251608]
	TIME [epoch: 27.8 sec]
EPOCH 411/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.537039335226342		[learning rate: 0.0027861]
	Learning Rate: 0.00278612
	LOSS [training: 3.537039335226342 | validation: 2.728295393530045]
	TIME [epoch: 27.8 sec]
EPOCH 412/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.159973642819187		[learning rate: 0.0027763]
	Learning Rate: 0.00277627
	LOSS [training: 3.159973642819187 | validation: 3.1059304487325825]
	TIME [epoch: 27.7 sec]
EPOCH 413/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3197081193980367		[learning rate: 0.0027665]
	Learning Rate: 0.00276645
	LOSS [training: 3.3197081193980367 | validation: 2.69526513801065]
	TIME [epoch: 27.8 sec]
EPOCH 414/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2351352379312575		[learning rate: 0.0027567]
	Learning Rate: 0.00275667
	LOSS [training: 3.2351352379312575 | validation: 2.628142777445429]
	TIME [epoch: 27.7 sec]
EPOCH 415/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2226712140161102		[learning rate: 0.0027469]
	Learning Rate: 0.00274692
	LOSS [training: 3.2226712140161102 | validation: 2.550498195871366]
	TIME [epoch: 27.8 sec]
EPOCH 416/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0735464823579113		[learning rate: 0.0027372]
	Learning Rate: 0.00273721
	LOSS [training: 3.0735464823579113 | validation: 2.986709085578346]
	TIME [epoch: 27.8 sec]
EPOCH 417/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.265153354733881		[learning rate: 0.0027275]
	Learning Rate: 0.00272753
	LOSS [training: 3.265153354733881 | validation: 2.8991362603259745]
	TIME [epoch: 27.8 sec]
EPOCH 418/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1496754912758966		[learning rate: 0.0027179]
	Learning Rate: 0.00271788
	LOSS [training: 3.1496754912758966 | validation: 2.6504438443138993]
	TIME [epoch: 27.8 sec]
EPOCH 419/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.135998699128252		[learning rate: 0.0027083]
	Learning Rate: 0.00270827
	LOSS [training: 3.135998699128252 | validation: 2.856758958024468]
	TIME [epoch: 27.7 sec]
EPOCH 420/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.303026295468772		[learning rate: 0.0026987]
	Learning Rate: 0.0026987
	LOSS [training: 3.303026295468772 | validation: 2.7265862697753493]
	TIME [epoch: 27.8 sec]
EPOCH 421/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.409485733827724		[learning rate: 0.0026892]
	Learning Rate: 0.00268915
	LOSS [training: 3.409485733827724 | validation: 2.67384306024533]
	TIME [epoch: 27.8 sec]
EPOCH 422/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0502779460060507		[learning rate: 0.0026796]
	Learning Rate: 0.00267964
	LOSS [training: 3.0502779460060507 | validation: 2.591091980006656]
	TIME [epoch: 27.8 sec]
EPOCH 423/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.3483533362109092		[learning rate: 0.0026702]
	Learning Rate: 0.00267017
	LOSS [training: 3.3483533362109092 | validation: 2.7871019827131165]
	TIME [epoch: 27.8 sec]
EPOCH 424/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.081574168854633		[learning rate: 0.0026607]
	Learning Rate: 0.00266073
	LOSS [training: 3.081574168854633 | validation: 2.562654000355569]
	TIME [epoch: 27.7 sec]
EPOCH 425/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9471605822726996		[learning rate: 0.0026513]
	Learning Rate: 0.00265132
	LOSS [training: 2.9471605822726996 | validation: 2.5431099423646732]
	TIME [epoch: 27.8 sec]
EPOCH 426/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9736265176714927		[learning rate: 0.0026419]
	Learning Rate: 0.00264194
	LOSS [training: 2.9736265176714927 | validation: 2.7703881763288845]
	TIME [epoch: 27.7 sec]
EPOCH 427/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.219966171138409		[learning rate: 0.0026326]
	Learning Rate: 0.0026326
	LOSS [training: 3.219966171138409 | validation: 3.0415600867439077]
	TIME [epoch: 27.8 sec]
EPOCH 428/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.66271848129402		[learning rate: 0.0026233]
	Learning Rate: 0.00262329
	LOSS [training: 3.66271848129402 | validation: 3.0300147944469487]
	TIME [epoch: 27.8 sec]
EPOCH 429/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2821267690093228		[learning rate: 0.002614]
	Learning Rate: 0.00261401
	LOSS [training: 3.2821267690093228 | validation: 2.5539625826331123]
	TIME [epoch: 27.8 sec]
EPOCH 430/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.925358489624913		[learning rate: 0.0026048]
	Learning Rate: 0.00260477
	LOSS [training: 2.925358489624913 | validation: 2.686418804271512]
	TIME [epoch: 27.8 sec]
EPOCH 431/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.949278461670758		[learning rate: 0.0025956]
	Learning Rate: 0.00259556
	LOSS [training: 2.949278461670758 | validation: 2.5190491958704584]
	TIME [epoch: 27.7 sec]
EPOCH 432/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.833547378953432		[learning rate: 0.0025864]
	Learning Rate: 0.00258638
	LOSS [training: 2.833547378953432 | validation: 2.4785417477457403]
	TIME [epoch: 27.8 sec]
EPOCH 433/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.002140226078464		[learning rate: 0.0025772]
	Learning Rate: 0.00257723
	LOSS [training: 3.002140226078464 | validation: 2.5058759799065764]
	TIME [epoch: 27.8 sec]
EPOCH 434/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9662747093307162		[learning rate: 0.0025681]
	Learning Rate: 0.00256812
	LOSS [training: 2.9662747093307162 | validation: 2.4845959351799864]
	TIME [epoch: 27.8 sec]
EPOCH 435/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.2458579882054757		[learning rate: 0.002559]
	Learning Rate: 0.00255904
	LOSS [training: 3.2458579882054757 | validation: 2.5511332561842908]
	TIME [epoch: 27.8 sec]
EPOCH 436/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.1593497441484257		[learning rate: 0.00255]
	Learning Rate: 0.00254999
	LOSS [training: 3.1593497441484257 | validation: 2.516250886620708]
	TIME [epoch: 27.8 sec]
EPOCH 437/2000:
	Training over batches...
		[batch 4/4] avg loss: 3.0327795249051217		[learning rate: 0.002541]
	Learning Rate: 0.00254097
	LOSS [training: 3.0327795249051217 | validation: 2.46438014014126]
	TIME [epoch: 27.8 sec]
EPOCH 438/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.9577725485298654		[learning rate: 0.002532]
	Learning Rate: 0.00253199
	LOSS [training: 2.9577725485298654 | validation: 2.566575309846066]
	TIME [epoch: 27.8 sec]
EPOCH 439/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.816112283871966		[learning rate: 0.002523]
	Learning Rate: 0.00252303
	LOSS [training: 2.816112283871966 | validation: 2.377156274838357]
	TIME [epoch: 27.8 sec]
EPOCH 440/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6293956409749066		[learning rate: 0.0025141]
	Learning Rate: 0.00251411
	LOSS [training: 2.6293956409749066 | validation: 2.1857365521664587]
	TIME [epoch: 27.8 sec]
EPOCH 441/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.5321715502280027		[learning rate: 0.0025052]
	Learning Rate: 0.00250522
	LOSS [training: 2.5321715502280027 | validation: 2.3395746206475745]
	TIME [epoch: 27.9 sec]
EPOCH 442/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.681010250441392		[learning rate: 0.0024964]
	Learning Rate: 0.00249636
	LOSS [training: 2.681010250441392 | validation: 2.4286469437718057]
	TIME [epoch: 27.8 sec]
EPOCH 443/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.6812051515735473		[learning rate: 0.0024875]
	Learning Rate: 0.00248754
	LOSS [training: 2.6812051515735473 | validation: 2.2373695136401652]
	TIME [epoch: 27.8 sec]
EPOCH 444/2000:
	Training over batches...
		[batch 4/4] avg loss: 2.4572635749976808		[learning rate: 0.0024787]
	Learning Rate: 0.00247874
	LOSS [training: 2.4572635749976808 | validation: 1.819701740527006]
	TIME [epoch: 27.8 sec]
EPOCH 445/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.9792387505722089		[learning rate: 0.00247]
	Learning Rate: 0.00246997
	LOSS [training: 1.9792387505722089 | validation: 1.5346802570195979]
	TIME [epoch: 27.8 sec]
EPOCH 446/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.6473289114150746		[learning rate: 0.0024612]
	Learning Rate: 0.00246124
	LOSS [training: 1.6473289114150746 | validation: 1.5866617690599412]
	TIME [epoch: 27.9 sec]
EPOCH 447/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4874241405970645		[learning rate: 0.0024525]
	Learning Rate: 0.00245254
	LOSS [training: 1.4874241405970645 | validation: 1.516785399589531]
	TIME [epoch: 27.8 sec]
EPOCH 448/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4046645192611682		[learning rate: 0.0024439]
	Learning Rate: 0.00244386
	LOSS [training: 1.4046645192611682 | validation: 1.1921053155886365]
	TIME [epoch: 27.9 sec]
EPOCH 449/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.152553078986506		[learning rate: 0.0024352]
	Learning Rate: 0.00243522
	LOSS [training: 1.152553078986506 | validation: 1.0106534451967202]
	TIME [epoch: 27.8 sec]
EPOCH 450/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1253706037511313		[learning rate: 0.0024266]
	Learning Rate: 0.00242661
	LOSS [training: 1.1253706037511313 | validation: 1.0164233312388278]
	TIME [epoch: 27.9 sec]
EPOCH 451/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8918569770767398		[learning rate: 0.002418]
	Learning Rate: 0.00241803
	LOSS [training: 0.8918569770767398 | validation: 0.8903624874305968]
	TIME [epoch: 27.9 sec]
EPOCH 452/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9390357735229327		[learning rate: 0.0024095]
	Learning Rate: 0.00240948
	LOSS [training: 0.9390357735229327 | validation: 0.7996364299816493]
	TIME [epoch: 27.8 sec]
EPOCH 453/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8273927153405327		[learning rate: 0.002401]
	Learning Rate: 0.00240096
	LOSS [training: 0.8273927153405327 | validation: 2.1267344912593233]
	TIME [epoch: 27.9 sec]
EPOCH 454/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.4473290997817858		[learning rate: 0.0023925]
	Learning Rate: 0.00239247
	LOSS [training: 1.4473290997817858 | validation: 0.851568550639078]
	TIME [epoch: 27.8 sec]
EPOCH 455/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9861889443467011		[learning rate: 0.002384]
	Learning Rate: 0.00238401
	LOSS [training: 0.9861889443467011 | validation: 0.8858237355617974]
	TIME [epoch: 27.9 sec]
EPOCH 456/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7688021325666228		[learning rate: 0.0023756]
	Learning Rate: 0.00237558
	LOSS [training: 0.7688021325666228 | validation: 0.7129974317142387]
	TIME [epoch: 27.9 sec]
EPOCH 457/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7237644900740358		[learning rate: 0.0023672]
	Learning Rate: 0.00236718
	LOSS [training: 0.7237644900740358 | validation: 0.718157248782031]
	TIME [epoch: 27.9 sec]
EPOCH 458/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7205102769743473		[learning rate: 0.0023588]
	Learning Rate: 0.00235881
	LOSS [training: 0.7205102769743473 | validation: 0.6938968876138699]
	TIME [epoch: 27.9 sec]
EPOCH 459/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.693709274208648		[learning rate: 0.0023505]
	Learning Rate: 0.00235047
	LOSS [training: 0.693709274208648 | validation: 0.7185717495291642]
	TIME [epoch: 27.9 sec]
EPOCH 460/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.840538704744565		[learning rate: 0.0023422]
	Learning Rate: 0.00234215
	LOSS [training: 0.840538704744565 | validation: 0.7451913486873646]
	TIME [epoch: 27.9 sec]
EPOCH 461/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6968751334240532		[learning rate: 0.0023339]
	Learning Rate: 0.00233387
	LOSS [training: 0.6968751334240532 | validation: 0.655809929688303]
	TIME [epoch: 27.9 sec]
EPOCH 462/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6640297413182474		[learning rate: 0.0023256]
	Learning Rate: 0.00232562
	LOSS [training: 0.6640297413182474 | validation: 0.6343976201682487]
	TIME [epoch: 27.9 sec]
EPOCH 463/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7109743144121077		[learning rate: 0.0023174]
	Learning Rate: 0.00231739
	LOSS [training: 0.7109743144121077 | validation: 0.6755998623711256]
	TIME [epoch: 27.9 sec]
EPOCH 464/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7517378488580699		[learning rate: 0.0023092]
	Learning Rate: 0.0023092
	LOSS [training: 0.7517378488580699 | validation: 0.6375781287544937]
	TIME [epoch: 27.9 sec]
EPOCH 465/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7176282514575327		[learning rate: 0.002301]
	Learning Rate: 0.00230103
	LOSS [training: 0.7176282514575327 | validation: 0.745253671452144]
	TIME [epoch: 27.9 sec]
EPOCH 466/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8187933045288811		[learning rate: 0.0022929]
	Learning Rate: 0.0022929
	LOSS [training: 0.8187933045288811 | validation: 0.6224588882296249]
	TIME [epoch: 27.9 sec]
EPOCH 467/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7476843626967009		[learning rate: 0.0022848]
	Learning Rate: 0.00228479
	LOSS [training: 0.7476843626967009 | validation: 0.8365184748355518]
	TIME [epoch: 27.9 sec]
EPOCH 468/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6487968473764029		[learning rate: 0.0022767]
	Learning Rate: 0.00227671
	LOSS [training: 0.6487968473764029 | validation: 0.6069565768935506]
	TIME [epoch: 27.9 sec]
EPOCH 469/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7015551435593808		[learning rate: 0.0022687]
	Learning Rate: 0.00226866
	LOSS [training: 0.7015551435593808 | validation: 0.6816361789345543]
	TIME [epoch: 27.9 sec]
EPOCH 470/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6189812763635552		[learning rate: 0.0022606]
	Learning Rate: 0.00226064
	LOSS [training: 0.6189812763635552 | validation: 0.8811628924653652]
	TIME [epoch: 27.9 sec]
EPOCH 471/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.035668694534681		[learning rate: 0.0022526]
	Learning Rate: 0.00225264
	LOSS [training: 1.035668694534681 | validation: 0.7557320233634375]
	TIME [epoch: 27.9 sec]
EPOCH 472/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9226664696266921		[learning rate: 0.0022447]
	Learning Rate: 0.00224468
	LOSS [training: 0.9226664696266921 | validation: 0.960207723889501]
	TIME [epoch: 27.9 sec]
EPOCH 473/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7424233921908394		[learning rate: 0.0022367]
	Learning Rate: 0.00223674
	LOSS [training: 0.7424233921908394 | validation: 0.7252499935023582]
	TIME [epoch: 27.9 sec]
EPOCH 474/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6792014092154938		[learning rate: 0.0022288]
	Learning Rate: 0.00222883
	LOSS [training: 0.6792014092154938 | validation: 0.7653436155782624]
	TIME [epoch: 27.9 sec]
EPOCH 475/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.662407656456947		[learning rate: 0.0022209]
	Learning Rate: 0.00222095
	LOSS [training: 0.662407656456947 | validation: 0.8387810454037853]
	TIME [epoch: 28 sec]
EPOCH 476/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7039474131733917		[learning rate: 0.0022131]
	Learning Rate: 0.00221309
	LOSS [training: 0.7039474131733917 | validation: 0.6376311241368525]
	TIME [epoch: 27.9 sec]
EPOCH 477/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6201072679221595		[learning rate: 0.0022053]
	Learning Rate: 0.00220527
	LOSS [training: 0.6201072679221595 | validation: 0.8699250565283728]
	TIME [epoch: 28 sec]
EPOCH 478/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6668702452003443		[learning rate: 0.0021975]
	Learning Rate: 0.00219747
	LOSS [training: 0.6668702452003443 | validation: 0.8717521792356709]
	TIME [epoch: 28 sec]
EPOCH 479/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7507476154475183		[learning rate: 0.0021897]
	Learning Rate: 0.0021897
	LOSS [training: 0.7507476154475183 | validation: 0.6261219335121191]
	TIME [epoch: 27.9 sec]
EPOCH 480/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6433072641623785		[learning rate: 0.002182]
	Learning Rate: 0.00218196
	LOSS [training: 0.6433072641623785 | validation: 0.7607367479440674]
	TIME [epoch: 27.9 sec]
EPOCH 481/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5944249911656131		[learning rate: 0.0021742]
	Learning Rate: 0.00217424
	LOSS [training: 0.5944249911656131 | validation: 0.6149821245660023]
	TIME [epoch: 27.8 sec]
EPOCH 482/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5830561523492693		[learning rate: 0.0021666]
	Learning Rate: 0.00216655
	LOSS [training: 0.5830561523492693 | validation: 0.6217754813111779]
	TIME [epoch: 27.8 sec]
EPOCH 483/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5399394195314591		[learning rate: 0.0021589]
	Learning Rate: 0.00215889
	LOSS [training: 0.5399394195314591 | validation: 0.7329753638877042]
	TIME [epoch: 27.9 sec]
EPOCH 484/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6811264713173014		[learning rate: 0.0021513]
	Learning Rate: 0.00215126
	LOSS [training: 0.6811264713173014 | validation: 0.6162950903967855]
	TIME [epoch: 27.9 sec]
EPOCH 485/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7348638967198976		[learning rate: 0.0021436]
	Learning Rate: 0.00214365
	LOSS [training: 0.7348638967198976 | validation: 0.7132050591618778]
	TIME [epoch: 28 sec]
EPOCH 486/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6988890829573355		[learning rate: 0.0021361]
	Learning Rate: 0.00213607
	LOSS [training: 0.6988890829573355 | validation: 0.584427074139934]
	TIME [epoch: 27.9 sec]
EPOCH 487/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6557535220271127		[learning rate: 0.0021285]
	Learning Rate: 0.00212852
	LOSS [training: 0.6557535220271127 | validation: 0.5962402442246527]
	TIME [epoch: 27.9 sec]
EPOCH 488/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6685990542678044		[learning rate: 0.002121]
	Learning Rate: 0.00212099
	LOSS [training: 0.6685990542678044 | validation: 0.7653127335257515]
	TIME [epoch: 28 sec]
EPOCH 489/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6412129569870065		[learning rate: 0.0021135]
	Learning Rate: 0.00211349
	LOSS [training: 0.6412129569870065 | validation: 0.6494152572183294]
	TIME [epoch: 28 sec]
EPOCH 490/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7747128133551249		[learning rate: 0.002106]
	Learning Rate: 0.00210602
	LOSS [training: 0.7747128133551249 | validation: 0.653638672018611]
	TIME [epoch: 28 sec]
EPOCH 491/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7313954944358718		[learning rate: 0.0020986]
	Learning Rate: 0.00209857
	LOSS [training: 0.7313954944358718 | validation: 0.9096710523312485]
	TIME [epoch: 28 sec]
EPOCH 492/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7045525856934375		[learning rate: 0.0020911]
	Learning Rate: 0.00209115
	LOSS [training: 0.7045525856934375 | validation: 0.6685919154278535]
	TIME [epoch: 27.9 sec]
EPOCH 493/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6008824268772953		[learning rate: 0.0020838]
	Learning Rate: 0.00208375
	LOSS [training: 0.6008824268772953 | validation: 0.7086099217419738]
	TIME [epoch: 28 sec]
EPOCH 494/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1198808457960352		[learning rate: 0.0020764]
	Learning Rate: 0.00207638
	LOSS [training: 1.1198808457960352 | validation: 0.5855648396493719]
	TIME [epoch: 27.9 sec]
EPOCH 495/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6594679137086549		[learning rate: 0.002069]
	Learning Rate: 0.00206904
	LOSS [training: 0.6594679137086549 | validation: 0.8912579557325255]
	TIME [epoch: 28 sec]
EPOCH 496/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7102068616955022		[learning rate: 0.0020617]
	Learning Rate: 0.00206173
	LOSS [training: 0.7102068616955022 | validation: 0.6520144874513869]
	TIME [epoch: 27.9 sec]
EPOCH 497/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5920477906347457		[learning rate: 0.0020544]
	Learning Rate: 0.00205443
	LOSS [training: 0.5920477906347457 | validation: 0.5532205499944935]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_497.pth
	Model improved!!!
EPOCH 498/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5760320005998181		[learning rate: 0.0020472]
	Learning Rate: 0.00204717
	LOSS [training: 0.5760320005998181 | validation: 0.8683324109793961]
	TIME [epoch: 27.9 sec]
EPOCH 499/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6826803082799076		[learning rate: 0.0020399]
	Learning Rate: 0.00203993
	LOSS [training: 0.6826803082799076 | validation: 0.65821891234162]
	TIME [epoch: 28 sec]
EPOCH 500/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6521012269252038		[learning rate: 0.0020327]
	Learning Rate: 0.00203272
	LOSS [training: 0.6521012269252038 | validation: 0.5839749218313199]
	TIME [epoch: 27.9 sec]
EPOCH 501/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6438339620112427		[learning rate: 0.0020255]
	Learning Rate: 0.00202553
	LOSS [training: 0.6438339620112427 | validation: 0.6392970667360673]
	TIME [epoch: 28 sec]
EPOCH 502/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5909559871674948		[learning rate: 0.0020184]
	Learning Rate: 0.00201837
	LOSS [training: 0.5909559871674948 | validation: 0.8276980588676619]
	TIME [epoch: 27.9 sec]
EPOCH 503/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6134843935156642		[learning rate: 0.0020112]
	Learning Rate: 0.00201123
	LOSS [training: 0.6134843935156642 | validation: 0.5563917836766118]
	TIME [epoch: 27.9 sec]
EPOCH 504/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6024848020605879		[learning rate: 0.0020041]
	Learning Rate: 0.00200412
	LOSS [training: 0.6024848020605879 | validation: 0.6090292967094222]
	TIME [epoch: 28 sec]
EPOCH 505/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6268587172154323		[learning rate: 0.001997]
	Learning Rate: 0.00199703
	LOSS [training: 0.6268587172154323 | validation: 0.6540536078535938]
	TIME [epoch: 27.9 sec]
EPOCH 506/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6464384447301226		[learning rate: 0.00199]
	Learning Rate: 0.00198997
	LOSS [training: 0.6464384447301226 | validation: 1.2446852419133958]
	TIME [epoch: 28 sec]
EPOCH 507/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.3098556320492718		[learning rate: 0.0019829]
	Learning Rate: 0.00198293
	LOSS [training: 1.3098556320492718 | validation: 0.9283069804090553]
	TIME [epoch: 27.9 sec]
EPOCH 508/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7815713452887251		[learning rate: 0.0019759]
	Learning Rate: 0.00197592
	LOSS [training: 0.7815713452887251 | validation: 0.7750739472031333]
	TIME [epoch: 28 sec]
EPOCH 509/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6515447822554563		[learning rate: 0.0019689]
	Learning Rate: 0.00196893
	LOSS [training: 0.6515447822554563 | validation: 0.5428272301510666]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_509.pth
	Model improved!!!
EPOCH 510/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344681824466335		[learning rate: 0.001962]
	Learning Rate: 0.00196197
	LOSS [training: 0.6344681824466335 | validation: 0.5874357072417414]
	TIME [epoch: 27.9 sec]
EPOCH 511/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.552655504789828		[learning rate: 0.001955]
	Learning Rate: 0.00195503
	LOSS [training: 0.552655504789828 | validation: 0.5477120999215827]
	TIME [epoch: 28 sec]
EPOCH 512/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5755506016759068		[learning rate: 0.0019481]
	Learning Rate: 0.00194812
	LOSS [training: 0.5755506016759068 | validation: 0.6783851393975858]
	TIME [epoch: 28 sec]
EPOCH 513/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5581733529262289		[learning rate: 0.0019412]
	Learning Rate: 0.00194123
	LOSS [training: 0.5581733529262289 | validation: 0.7085266240308167]
	TIME [epoch: 27.9 sec]
EPOCH 514/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5900219193238296		[learning rate: 0.0019344]
	Learning Rate: 0.00193437
	LOSS [training: 0.5900219193238296 | validation: 0.535170734403789]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_514.pth
	Model improved!!!
EPOCH 515/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5633999181143874		[learning rate: 0.0019275]
	Learning Rate: 0.00192752
	LOSS [training: 0.5633999181143874 | validation: 0.5550822158020284]
	TIME [epoch: 27.8 sec]
EPOCH 516/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5317240271505908		[learning rate: 0.0019207]
	Learning Rate: 0.00192071
	LOSS [training: 0.5317240271505908 | validation: 0.5542931547563532]
	TIME [epoch: 28 sec]
EPOCH 517/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5677854723824755		[learning rate: 0.0019139]
	Learning Rate: 0.00191392
	LOSS [training: 0.5677854723824755 | validation: 1.0541409081436894]
	TIME [epoch: 27.9 sec]
EPOCH 518/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7748360441801103		[learning rate: 0.0019071]
	Learning Rate: 0.00190715
	LOSS [training: 0.7748360441801103 | validation: 0.5776250848131809]
	TIME [epoch: 27.9 sec]
EPOCH 519/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6085822255896529		[learning rate: 0.0019004]
	Learning Rate: 0.0019004
	LOSS [training: 0.6085822255896529 | validation: 0.6989878157847613]
	TIME [epoch: 28 sec]
EPOCH 520/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5974618786287614		[learning rate: 0.0018937]
	Learning Rate: 0.00189368
	LOSS [training: 0.5974618786287614 | validation: 0.5496468907626393]
	TIME [epoch: 27.9 sec]
EPOCH 521/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5657065357540203		[learning rate: 0.001887]
	Learning Rate: 0.00188699
	LOSS [training: 0.5657065357540203 | validation: 0.5651972821934086]
	TIME [epoch: 28 sec]
EPOCH 522/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5851542120033852		[learning rate: 0.0018803]
	Learning Rate: 0.00188032
	LOSS [training: 0.5851542120033852 | validation: 0.5889883555362063]
	TIME [epoch: 28 sec]
EPOCH 523/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6039146929644703		[learning rate: 0.0018737]
	Learning Rate: 0.00187367
	LOSS [training: 0.6039146929644703 | validation: 0.6747953728669864]
	TIME [epoch: 27.9 sec]
EPOCH 524/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6757438533944536		[learning rate: 0.001867]
	Learning Rate: 0.00186704
	LOSS [training: 0.6757438533944536 | validation: 0.6496586545472987]
	TIME [epoch: 27.9 sec]
EPOCH 525/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6200955564884294		[learning rate: 0.0018604]
	Learning Rate: 0.00186044
	LOSS [training: 0.6200955564884294 | validation: 0.7022321274578197]
	TIME [epoch: 27.9 sec]
EPOCH 526/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.1478553153140862		[learning rate: 0.0018539]
	Learning Rate: 0.00185386
	LOSS [training: 1.1478553153140862 | validation: 0.5811007674817724]
	TIME [epoch: 27.9 sec]
EPOCH 527/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5653963013413509		[learning rate: 0.0018473]
	Learning Rate: 0.0018473
	LOSS [training: 0.5653963013413509 | validation: 0.5780544841158167]
	TIME [epoch: 28 sec]
EPOCH 528/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.571744094332073		[learning rate: 0.0018408]
	Learning Rate: 0.00184077
	LOSS [training: 0.571744094332073 | validation: 0.5997248898164885]
	TIME [epoch: 27.9 sec]
EPOCH 529/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5486166298128634		[learning rate: 0.0018343]
	Learning Rate: 0.00183426
	LOSS [training: 0.5486166298128634 | validation: 0.7391973682232355]
	TIME [epoch: 28 sec]
EPOCH 530/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.627692572585884		[learning rate: 0.0018278]
	Learning Rate: 0.00182778
	LOSS [training: 0.627692572585884 | validation: 0.6510213263235832]
	TIME [epoch: 27.9 sec]
EPOCH 531/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6993090379863479		[learning rate: 0.0018213]
	Learning Rate: 0.00182131
	LOSS [training: 0.6993090379863479 | validation: 0.9902581855490192]
	TIME [epoch: 28 sec]
EPOCH 532/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.697854052167545		[learning rate: 0.0018149]
	Learning Rate: 0.00181487
	LOSS [training: 0.697854052167545 | validation: 0.5644472203933657]
	TIME [epoch: 28 sec]
EPOCH 533/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6037485508360659		[learning rate: 0.0018085]
	Learning Rate: 0.00180845
	LOSS [training: 0.6037485508360659 | validation: 0.5463854324255023]
	TIME [epoch: 27.9 sec]
EPOCH 534/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5322896160831376		[learning rate: 0.0018021]
	Learning Rate: 0.00180206
	LOSS [training: 0.5322896160831376 | validation: 1.0511425073984766]
	TIME [epoch: 28 sec]
EPOCH 535/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7677426314314071		[learning rate: 0.0017957]
	Learning Rate: 0.00179569
	LOSS [training: 0.7677426314314071 | validation: 0.7844266146710479]
	TIME [epoch: 28 sec]
EPOCH 536/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7923248865449045		[learning rate: 0.0017893]
	Learning Rate: 0.00178934
	LOSS [training: 0.7923248865449045 | validation: 0.6977817389938786]
	TIME [epoch: 27.9 sec]
EPOCH 537/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6537229808207046		[learning rate: 0.001783]
	Learning Rate: 0.00178301
	LOSS [training: 0.6537229808207046 | validation: 0.6213624920229872]
	TIME [epoch: 27.8 sec]
EPOCH 538/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6019926935903124		[learning rate: 0.0017767]
	Learning Rate: 0.00177671
	LOSS [training: 0.6019926935903124 | validation: 0.7356587899947504]
	TIME [epoch: 27.9 sec]
EPOCH 539/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6461384954746869		[learning rate: 0.0017704]
	Learning Rate: 0.00177042
	LOSS [training: 0.6461384954746869 | validation: 0.6433300812595593]
	TIME [epoch: 27.8 sec]
EPOCH 540/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.846888585848715		[learning rate: 0.0017642]
	Learning Rate: 0.00176416
	LOSS [training: 0.846888585848715 | validation: 0.9596457069701966]
	TIME [epoch: 27.9 sec]
EPOCH 541/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7295333314550722		[learning rate: 0.0017579]
	Learning Rate: 0.00175792
	LOSS [training: 0.7295333314550722 | validation: 0.5584198489251062]
	TIME [epoch: 27.9 sec]
EPOCH 542/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5800782750089076		[learning rate: 0.0017517]
	Learning Rate: 0.00175171
	LOSS [training: 0.5800782750089076 | validation: 0.654727386897087]
	TIME [epoch: 27.9 sec]
EPOCH 543/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6828730769062761		[learning rate: 0.0017455]
	Learning Rate: 0.00174551
	LOSS [training: 0.6828730769062761 | validation: 0.6408090474628853]
	TIME [epoch: 27.9 sec]
EPOCH 544/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6961561985052971		[learning rate: 0.0017393]
	Learning Rate: 0.00173934
	LOSS [training: 0.6961561985052971 | validation: 0.8867527503677303]
	TIME [epoch: 27.9 sec]
EPOCH 545/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6801397596750645		[learning rate: 0.0017332]
	Learning Rate: 0.00173319
	LOSS [training: 0.6801397596750645 | validation: 0.5921240965524295]
	TIME [epoch: 27.9 sec]
EPOCH 546/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6070541033088656		[learning rate: 0.0017271]
	Learning Rate: 0.00172706
	LOSS [training: 0.6070541033088656 | validation: 0.6171433153286842]
	TIME [epoch: 27.9 sec]
EPOCH 547/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6524091916901992		[learning rate: 0.001721]
	Learning Rate: 0.00172095
	LOSS [training: 0.6524091916901992 | validation: 0.7835344675823501]
	TIME [epoch: 28 sec]
EPOCH 548/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5884513502673941		[learning rate: 0.0017149]
	Learning Rate: 0.00171487
	LOSS [training: 0.5884513502673941 | validation: 0.5728504482203893]
	TIME [epoch: 28 sec]
EPOCH 549/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676614452360851		[learning rate: 0.0017088]
	Learning Rate: 0.0017088
	LOSS [training: 0.5676614452360851 | validation: 0.6015940162808702]
	TIME [epoch: 28 sec]
EPOCH 550/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6258598561407409		[learning rate: 0.0017028]
	Learning Rate: 0.00170276
	LOSS [training: 0.6258598561407409 | validation: 0.6738373634906085]
	TIME [epoch: 27.9 sec]
EPOCH 551/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5531468223831142		[learning rate: 0.0016967]
	Learning Rate: 0.00169674
	LOSS [training: 0.5531468223831142 | validation: 0.669886412535844]
	TIME [epoch: 27.9 sec]
EPOCH 552/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6944511563217213		[learning rate: 0.0016907]
	Learning Rate: 0.00169074
	LOSS [training: 0.6944511563217213 | validation: 0.9195422029542515]
	TIME [epoch: 27.9 sec]
EPOCH 553/2000:
	Training over batches...
		[batch 4/4] avg loss: 1.0640122216424075		[learning rate: 0.0016848]
	Learning Rate: 0.00168476
	LOSS [training: 1.0640122216424075 | validation: 0.6251434231759768]
	TIME [epoch: 27.9 sec]
EPOCH 554/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7081707690478332		[learning rate: 0.0016788]
	Learning Rate: 0.0016788
	LOSS [training: 0.7081707690478332 | validation: 0.5791740374206833]
	TIME [epoch: 27.9 sec]
EPOCH 555/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5369452949599947		[learning rate: 0.0016729]
	Learning Rate: 0.00167287
	LOSS [training: 0.5369452949599947 | validation: 0.7830946811330639]
	TIME [epoch: 27.9 sec]
EPOCH 556/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6226910659542725		[learning rate: 0.001667]
	Learning Rate: 0.00166695
	LOSS [training: 0.6226910659542725 | validation: 0.5648448582749737]
	TIME [epoch: 27.9 sec]
EPOCH 557/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5576858100188926		[learning rate: 0.0016611]
	Learning Rate: 0.00166106
	LOSS [training: 0.5576858100188926 | validation: 0.5827908657274239]
	TIME [epoch: 28 sec]
EPOCH 558/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.615338198872955		[learning rate: 0.0016552]
	Learning Rate: 0.00165518
	LOSS [training: 0.615338198872955 | validation: 0.6003955621459182]
	TIME [epoch: 27.9 sec]
EPOCH 559/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.640542316997953		[learning rate: 0.0016493]
	Learning Rate: 0.00164933
	LOSS [training: 0.640542316997953 | validation: 0.6826453061539435]
	TIME [epoch: 27.9 sec]
EPOCH 560/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6839343264189266		[learning rate: 0.0016435]
	Learning Rate: 0.0016435
	LOSS [training: 0.6839343264189266 | validation: 0.5984542123926688]
	TIME [epoch: 27.9 sec]
EPOCH 561/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5987104217186534		[learning rate: 0.0016377]
	Learning Rate: 0.00163769
	LOSS [training: 0.5987104217186534 | validation: 0.5568462946429638]
	TIME [epoch: 27.9 sec]
EPOCH 562/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5272454099649522		[learning rate: 0.0016319]
	Learning Rate: 0.0016319
	LOSS [training: 0.5272454099649522 | validation: 0.5363504071434811]
	TIME [epoch: 27.9 sec]
EPOCH 563/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5293588189761139		[learning rate: 0.0016261]
	Learning Rate: 0.00162612
	LOSS [training: 0.5293588189761139 | validation: 0.5576734218549784]
	TIME [epoch: 27.9 sec]
EPOCH 564/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5697237780508735		[learning rate: 0.0016204]
	Learning Rate: 0.00162037
	LOSS [training: 0.5697237780508735 | validation: 0.6886769942801272]
	TIME [epoch: 27.9 sec]
EPOCH 565/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7374934890526518		[learning rate: 0.0016146]
	Learning Rate: 0.00161464
	LOSS [training: 0.7374934890526518 | validation: 0.988971289586527]
	TIME [epoch: 27.9 sec]
EPOCH 566/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7523007225637648		[learning rate: 0.0016089]
	Learning Rate: 0.00160893
	LOSS [training: 0.7523007225637648 | validation: 0.6365374308502283]
	TIME [epoch: 27.9 sec]
EPOCH 567/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5512650696303802		[learning rate: 0.0016032]
	Learning Rate: 0.00160325
	LOSS [training: 0.5512650696303802 | validation: 0.5781066772783383]
	TIME [epoch: 27.9 sec]
EPOCH 568/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5511010940236519		[learning rate: 0.0015976]
	Learning Rate: 0.00159758
	LOSS [training: 0.5511010940236519 | validation: 0.9934046824107924]
	TIME [epoch: 27.9 sec]
EPOCH 569/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7831515895466741		[learning rate: 0.0015919]
	Learning Rate: 0.00159193
	LOSS [training: 0.7831515895466741 | validation: 0.763373846770266]
	TIME [epoch: 27.9 sec]
EPOCH 570/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6171750928475251		[learning rate: 0.0015863]
	Learning Rate: 0.0015863
	LOSS [training: 0.6171750928475251 | validation: 0.5647651526068462]
	TIME [epoch: 27.9 sec]
EPOCH 571/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5874652326679998		[learning rate: 0.0015807]
	Learning Rate: 0.00158069
	LOSS [training: 0.5874652326679998 | validation: 0.587511028757267]
	TIME [epoch: 27.9 sec]
EPOCH 572/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5798881619138853		[learning rate: 0.0015751]
	Learning Rate: 0.0015751
	LOSS [training: 0.5798881619138853 | validation: 0.6550068512421764]
	TIME [epoch: 27.9 sec]
EPOCH 573/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6778542916169721		[learning rate: 0.0015695]
	Learning Rate: 0.00156953
	LOSS [training: 0.6778542916169721 | validation: 0.557438874532092]
	TIME [epoch: 27.9 sec]
EPOCH 574/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5446018310682272		[learning rate: 0.001564]
	Learning Rate: 0.00156398
	LOSS [training: 0.5446018310682272 | validation: 0.653206190117551]
	TIME [epoch: 27.9 sec]
EPOCH 575/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.561449088255592		[learning rate: 0.0015584]
	Learning Rate: 0.00155845
	LOSS [training: 0.561449088255592 | validation: 0.6674251635187295]
	TIME [epoch: 27.9 sec]
EPOCH 576/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7586108213762117		[learning rate: 0.0015529]
	Learning Rate: 0.00155294
	LOSS [training: 0.7586108213762117 | validation: 0.7605796498452362]
	TIME [epoch: 27.9 sec]
EPOCH 577/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6999676707048669		[learning rate: 0.0015474]
	Learning Rate: 0.00154745
	LOSS [training: 0.6999676707048669 | validation: 0.5267315724865411]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_577.pth
	Model improved!!!
EPOCH 578/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6123322863558871		[learning rate: 0.001542]
	Learning Rate: 0.00154197
	LOSS [training: 0.6123322863558871 | validation: 0.6866471536592502]
	TIME [epoch: 27.9 sec]
EPOCH 579/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5905960617989863		[learning rate: 0.0015365]
	Learning Rate: 0.00153652
	LOSS [training: 0.5905960617989863 | validation: 0.5560484769186518]
	TIME [epoch: 27.9 sec]
EPOCH 580/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5388716448943842		[learning rate: 0.0015311]
	Learning Rate: 0.00153109
	LOSS [training: 0.5388716448943842 | validation: 0.5821042413573422]
	TIME [epoch: 28 sec]
EPOCH 581/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6026408349885652		[learning rate: 0.0015257]
	Learning Rate: 0.00152567
	LOSS [training: 0.6026408349885652 | validation: 0.5309508123494437]
	TIME [epoch: 27.9 sec]
EPOCH 582/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.609265596405432		[learning rate: 0.0015203]
	Learning Rate: 0.00152028
	LOSS [training: 0.609265596405432 | validation: 0.6471926592981754]
	TIME [epoch: 28 sec]
EPOCH 583/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6346617880231366		[learning rate: 0.0015149]
	Learning Rate: 0.0015149
	LOSS [training: 0.6346617880231366 | validation: 0.5869592505340573]
	TIME [epoch: 27.9 sec]
EPOCH 584/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5950180951239357		[learning rate: 0.0015095]
	Learning Rate: 0.00150955
	LOSS [training: 0.5950180951239357 | validation: 0.6960253461337346]
	TIME [epoch: 27.9 sec]
EPOCH 585/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6654929833266966		[learning rate: 0.0015042]
	Learning Rate: 0.00150421
	LOSS [training: 0.6654929833266966 | validation: 0.6372941548700665]
	TIME [epoch: 27.9 sec]
EPOCH 586/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6642770002470584		[learning rate: 0.0014989]
	Learning Rate: 0.00149889
	LOSS [training: 0.6642770002470584 | validation: 0.7798218799607338]
	TIME [epoch: 27.9 sec]
EPOCH 587/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6190722801809421		[learning rate: 0.0014936]
	Learning Rate: 0.00149359
	LOSS [training: 0.6190722801809421 | validation: 0.656254759857659]
	TIME [epoch: 28 sec]
EPOCH 588/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5457592812085197		[learning rate: 0.0014883]
	Learning Rate: 0.00148831
	LOSS [training: 0.5457592812085197 | validation: 0.5623387175997995]
	TIME [epoch: 27.9 sec]
EPOCH 589/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5168043660574931		[learning rate: 0.001483]
	Learning Rate: 0.00148304
	LOSS [training: 0.5168043660574931 | validation: 0.5885297567312707]
	TIME [epoch: 27.9 sec]
EPOCH 590/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5993922183879726		[learning rate: 0.0014778]
	Learning Rate: 0.0014778
	LOSS [training: 0.5993922183879726 | validation: 0.8981935587374673]
	TIME [epoch: 27.9 sec]
EPOCH 591/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6465299181954112		[learning rate: 0.0014726]
	Learning Rate: 0.00147257
	LOSS [training: 0.6465299181954112 | validation: 0.5339795075452272]
	TIME [epoch: 27.9 sec]
EPOCH 592/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5771490516692227		[learning rate: 0.0014674]
	Learning Rate: 0.00146737
	LOSS [training: 0.5771490516692227 | validation: 0.6070511535133799]
	TIME [epoch: 27.9 sec]
EPOCH 593/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6445611963983292		[learning rate: 0.0014622]
	Learning Rate: 0.00146218
	LOSS [training: 0.6445611963983292 | validation: 0.5291079383861278]
	TIME [epoch: 27.9 sec]
EPOCH 594/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6494324807939544		[learning rate: 0.001457]
	Learning Rate: 0.00145701
	LOSS [training: 0.6494324807939544 | validation: 0.5753149626761926]
	TIME [epoch: 27.9 sec]
EPOCH 595/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5469108967346353		[learning rate: 0.0014519]
	Learning Rate: 0.00145185
	LOSS [training: 0.5469108967346353 | validation: 0.6357170460867678]
	TIME [epoch: 27.9 sec]
EPOCH 596/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5667778239060755		[learning rate: 0.0014467]
	Learning Rate: 0.00144672
	LOSS [training: 0.5667778239060755 | validation: 0.5909517815948104]
	TIME [epoch: 27.9 sec]
EPOCH 597/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5631410179217935		[learning rate: 0.0014416]
	Learning Rate: 0.0014416
	LOSS [training: 0.5631410179217935 | validation: 0.5910906365808094]
	TIME [epoch: 27.9 sec]
EPOCH 598/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.606900587603905		[learning rate: 0.0014365]
	Learning Rate: 0.00143651
	LOSS [training: 0.606900587603905 | validation: 0.5795882673523738]
	TIME [epoch: 27.8 sec]
EPOCH 599/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5676903978222658		[learning rate: 0.0014314]
	Learning Rate: 0.00143143
	LOSS [training: 0.5676903978222658 | validation: 0.5606399684937772]
	TIME [epoch: 27.8 sec]
EPOCH 600/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5447715408848484		[learning rate: 0.0014264]
	Learning Rate: 0.00142637
	LOSS [training: 0.5447715408848484 | validation: 0.5844738165140045]
	TIME [epoch: 27.8 sec]
EPOCH 601/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5644438198556041		[learning rate: 0.0014213]
	Learning Rate: 0.00142132
	LOSS [training: 0.5644438198556041 | validation: 0.5702812034003352]
	TIME [epoch: 27.8 sec]
EPOCH 602/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6889730090884029		[learning rate: 0.0014163]
	Learning Rate: 0.0014163
	LOSS [training: 0.6889730090884029 | validation: 0.5124816834462724]
	TIME [epoch: 27.8 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_602.pth
	Model improved!!!
EPOCH 603/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6503931427421191		[learning rate: 0.0014113]
	Learning Rate: 0.00141129
	LOSS [training: 0.6503931427421191 | validation: 0.848159481949478]
	TIME [epoch: 27.8 sec]
EPOCH 604/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6771835378411558		[learning rate: 0.0014063]
	Learning Rate: 0.0014063
	LOSS [training: 0.6771835378411558 | validation: 0.8759083548098093]
	TIME [epoch: 27.9 sec]
EPOCH 605/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6941045279082896		[learning rate: 0.0014013]
	Learning Rate: 0.00140132
	LOSS [training: 0.6941045279082896 | validation: 1.0331740664206093]
	TIME [epoch: 28 sec]
EPOCH 606/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8493155588501015		[learning rate: 0.0013964]
	Learning Rate: 0.00139637
	LOSS [training: 0.8493155588501015 | validation: 0.5479300882427695]
	TIME [epoch: 27.9 sec]
EPOCH 607/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5419460454030862		[learning rate: 0.0013914]
	Learning Rate: 0.00139143
	LOSS [training: 0.5419460454030862 | validation: 0.6938990914844084]
	TIME [epoch: 28 sec]
EPOCH 608/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.577599884451626		[learning rate: 0.0013865]
	Learning Rate: 0.00138651
	LOSS [training: 0.577599884451626 | validation: 0.9981571055528831]
	TIME [epoch: 28 sec]
EPOCH 609/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7702159792188463		[learning rate: 0.0013816]
	Learning Rate: 0.00138161
	LOSS [training: 0.7702159792188463 | validation: 1.3371586046252792]
	TIME [epoch: 27.9 sec]
EPOCH 610/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.9542383444635031		[learning rate: 0.0013767]
	Learning Rate: 0.00137672
	LOSS [training: 0.9542383444635031 | validation: 0.652444189591883]
	TIME [epoch: 27.9 sec]
EPOCH 611/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6505166170488612		[learning rate: 0.0013719]
	Learning Rate: 0.00137185
	LOSS [training: 0.6505166170488612 | validation: 0.5556372205351058]
	TIME [epoch: 27.9 sec]
EPOCH 612/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5287283313502866		[learning rate: 0.001367]
	Learning Rate: 0.001367
	LOSS [training: 0.5287283313502866 | validation: 0.6734080696543358]
	TIME [epoch: 27.9 sec]
EPOCH 613/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6155885801694577		[learning rate: 0.0013622]
	Learning Rate: 0.00136217
	LOSS [training: 0.6155885801694577 | validation: 0.9664989194797765]
	TIME [epoch: 27.9 sec]
EPOCH 614/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7812752606361912		[learning rate: 0.0013574]
	Learning Rate: 0.00135735
	LOSS [training: 0.7812752606361912 | validation: 0.7303389254447986]
	TIME [epoch: 27.8 sec]
EPOCH 615/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6205048865288978		[learning rate: 0.0013526]
	Learning Rate: 0.00135255
	LOSS [training: 0.6205048865288978 | validation: 0.7124185803345681]
	TIME [epoch: 27.7 sec]
EPOCH 616/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6030090125297558		[learning rate: 0.0013478]
	Learning Rate: 0.00134777
	LOSS [training: 0.6030090125297558 | validation: 0.6382727958620094]
	TIME [epoch: 27.7 sec]
EPOCH 617/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5322038975963996		[learning rate: 0.001343]
	Learning Rate: 0.001343
	LOSS [training: 0.5322038975963996 | validation: 0.5954638907220847]
	TIME [epoch: 27.8 sec]
EPOCH 618/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511208299326966		[learning rate: 0.0013383]
	Learning Rate: 0.00133825
	LOSS [training: 0.511208299326966 | validation: 0.5176843167903331]
	TIME [epoch: 27.8 sec]
EPOCH 619/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5330991444576767		[learning rate: 0.0013335]
	Learning Rate: 0.00133352
	LOSS [training: 0.5330991444576767 | validation: 0.570174391747264]
	TIME [epoch: 27.8 sec]
EPOCH 620/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5514077783901041		[learning rate: 0.0013288]
	Learning Rate: 0.00132881
	LOSS [training: 0.5514077783901041 | validation: 0.5407917603518265]
	TIME [epoch: 27.9 sec]
EPOCH 621/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5630724714704345		[learning rate: 0.0013241]
	Learning Rate: 0.00132411
	LOSS [training: 0.5630724714704345 | validation: 0.6142679749978835]
	TIME [epoch: 27.9 sec]
EPOCH 622/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5456508378103436		[learning rate: 0.0013194]
	Learning Rate: 0.00131942
	LOSS [training: 0.5456508378103436 | validation: 0.6228957016303527]
	TIME [epoch: 27.9 sec]
EPOCH 623/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5792127036949517		[learning rate: 0.0013148]
	Learning Rate: 0.00131476
	LOSS [training: 0.5792127036949517 | validation: 0.5666329139615647]
	TIME [epoch: 27.9 sec]
EPOCH 624/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5271530751817577		[learning rate: 0.0013101]
	Learning Rate: 0.00131011
	LOSS [training: 0.5271530751817577 | validation: 0.6004513981564911]
	TIME [epoch: 27.9 sec]
EPOCH 625/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5875206169652073		[learning rate: 0.0013055]
	Learning Rate: 0.00130548
	LOSS [training: 0.5875206169652073 | validation: 0.8564734920149845]
	TIME [epoch: 27.9 sec]
EPOCH 626/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7715308889596769		[learning rate: 0.0013009]
	Learning Rate: 0.00130086
	LOSS [training: 0.7715308889596769 | validation: 0.565473568699122]
	TIME [epoch: 27.9 sec]
EPOCH 627/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7351429713571174		[learning rate: 0.0012963]
	Learning Rate: 0.00129626
	LOSS [training: 0.7351429713571174 | validation: 0.547203089117103]
	TIME [epoch: 27.9 sec]
EPOCH 628/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5478113539272645		[learning rate: 0.0012917]
	Learning Rate: 0.00129168
	LOSS [training: 0.5478113539272645 | validation: 0.5409484530361376]
	TIME [epoch: 27.9 sec]
EPOCH 629/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6375285620349834		[learning rate: 0.0012871]
	Learning Rate: 0.00128711
	LOSS [training: 0.6375285620349834 | validation: 0.5555421346092467]
	TIME [epoch: 27.8 sec]
EPOCH 630/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5186695105828178		[learning rate: 0.0012826]
	Learning Rate: 0.00128256
	LOSS [training: 0.5186695105828178 | validation: 0.5509412539338654]
	TIME [epoch: 27.9 sec]
EPOCH 631/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5596780839877904		[learning rate: 0.001278]
	Learning Rate: 0.00127802
	LOSS [training: 0.5596780839877904 | validation: 0.6107989832500771]
	TIME [epoch: 27.8 sec]
EPOCH 632/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7597980206916745		[learning rate: 0.0012735]
	Learning Rate: 0.0012735
	LOSS [training: 0.7597980206916745 | validation: 0.7923348377330416]
	TIME [epoch: 28 sec]
EPOCH 633/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6729245575024789		[learning rate: 0.001269]
	Learning Rate: 0.001269
	LOSS [training: 0.6729245575024789 | validation: 0.5367621908772636]
	TIME [epoch: 27.9 sec]
EPOCH 634/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5352474256485598		[learning rate: 0.0012645]
	Learning Rate: 0.00126451
	LOSS [training: 0.5352474256485598 | validation: 0.5879668347300244]
	TIME [epoch: 28 sec]
EPOCH 635/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49485787433257616		[learning rate: 0.00126]
	Learning Rate: 0.00126004
	LOSS [training: 0.49485787433257616 | validation: 0.512529660072999]
	TIME [epoch: 28 sec]
EPOCH 636/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5107019104506212		[learning rate: 0.0012556]
	Learning Rate: 0.00125559
	LOSS [training: 0.5107019104506212 | validation: 0.577432877132884]
	TIME [epoch: 28 sec]
EPOCH 637/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5087381582933067		[learning rate: 0.0012511]
	Learning Rate: 0.00125115
	LOSS [training: 0.5087381582933067 | validation: 0.6096278682859816]
	TIME [epoch: 27.9 sec]
EPOCH 638/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.763396913941173		[learning rate: 0.0012467]
	Learning Rate: 0.00124672
	LOSS [training: 0.763396913941173 | validation: 0.5942860534602283]
	TIME [epoch: 28 sec]
EPOCH 639/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5270984110777882		[learning rate: 0.0012423]
	Learning Rate: 0.00124231
	LOSS [training: 0.5270984110777882 | validation: 0.5324308658389231]
	TIME [epoch: 28 sec]
EPOCH 640/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.713792636553291		[learning rate: 0.0012379]
	Learning Rate: 0.00123792
	LOSS [training: 0.713792636553291 | validation: 0.5690191064895775]
	TIME [epoch: 27.9 sec]
EPOCH 641/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.526866083123866		[learning rate: 0.0012335]
	Learning Rate: 0.00123354
	LOSS [training: 0.526866083123866 | validation: 0.49749995126559987]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_641.pth
	Model improved!!!
EPOCH 642/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5379996099741318		[learning rate: 0.0012292]
	Learning Rate: 0.00122918
	LOSS [training: 0.5379996099741318 | validation: 0.4987414315813446]
	TIME [epoch: 27.8 sec]
EPOCH 643/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49981225230019577		[learning rate: 0.0012248]
	Learning Rate: 0.00122483
	LOSS [training: 0.49981225230019577 | validation: 0.5838708896137643]
	TIME [epoch: 27.9 sec]
EPOCH 644/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6514388642600116		[learning rate: 0.0012205]
	Learning Rate: 0.0012205
	LOSS [training: 0.6514388642600116 | validation: 0.5326736917661107]
	TIME [epoch: 27.9 sec]
EPOCH 645/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5462514184031607		[learning rate: 0.0012162]
	Learning Rate: 0.00121619
	LOSS [training: 0.5462514184031607 | validation: 0.5472485137574765]
	TIME [epoch: 28 sec]
EPOCH 646/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5590125294855196		[learning rate: 0.0012119]
	Learning Rate: 0.00121189
	LOSS [training: 0.5590125294855196 | validation: 0.7509534926295632]
	TIME [epoch: 28 sec]
EPOCH 647/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.70308020703104		[learning rate: 0.0012076]
	Learning Rate: 0.0012076
	LOSS [training: 0.70308020703104 | validation: 0.530770850512954]
	TIME [epoch: 27.9 sec]
EPOCH 648/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4781199835304302		[learning rate: 0.0012033]
	Learning Rate: 0.00120333
	LOSS [training: 0.4781199835304302 | validation: 0.6069046346851963]
	TIME [epoch: 28 sec]
EPOCH 649/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6049757969890313		[learning rate: 0.0011991]
	Learning Rate: 0.00119907
	LOSS [training: 0.6049757969890313 | validation: 0.5027221921402381]
	TIME [epoch: 28 sec]
EPOCH 650/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6396071407325603		[learning rate: 0.0011948]
	Learning Rate: 0.00119483
	LOSS [training: 0.6396071407325603 | validation: 0.656896218975764]
	TIME [epoch: 28 sec]
EPOCH 651/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5204543858308603		[learning rate: 0.0011906]
	Learning Rate: 0.00119061
	LOSS [training: 0.5204543858308603 | validation: 0.6795278101050225]
	TIME [epoch: 28 sec]
EPOCH 652/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5494728977847483		[learning rate: 0.0011864]
	Learning Rate: 0.0011864
	LOSS [training: 0.5494728977847483 | validation: 0.6949609964382708]
	TIME [epoch: 27.9 sec]
EPOCH 653/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7424050968191831		[learning rate: 0.0011822]
	Learning Rate: 0.0011822
	LOSS [training: 0.7424050968191831 | validation: 0.5668323449479985]
	TIME [epoch: 28 sec]
EPOCH 654/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5543399833198523		[learning rate: 0.001178]
	Learning Rate: 0.00117802
	LOSS [training: 0.5543399833198523 | validation: 0.6059074937979629]
	TIME [epoch: 27.9 sec]
EPOCH 655/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5552542607577199		[learning rate: 0.0011739]
	Learning Rate: 0.00117386
	LOSS [training: 0.5552542607577199 | validation: 0.5385304939249805]
	TIME [epoch: 27.9 sec]
EPOCH 656/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5633551790188254		[learning rate: 0.0011697]
	Learning Rate: 0.00116971
	LOSS [training: 0.5633551790188254 | validation: 0.5839290462982026]
	TIME [epoch: 28 sec]
EPOCH 657/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5913178014550413		[learning rate: 0.0011656]
	Learning Rate: 0.00116557
	LOSS [training: 0.5913178014550413 | validation: 0.8316067891261609]
	TIME [epoch: 27.9 sec]
EPOCH 658/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6267834933484602		[learning rate: 0.0011614]
	Learning Rate: 0.00116145
	LOSS [training: 0.6267834933484602 | validation: 0.5178440303924539]
	TIME [epoch: 28 sec]
EPOCH 659/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.531443255529624		[learning rate: 0.0011573]
	Learning Rate: 0.00115734
	LOSS [training: 0.531443255529624 | validation: 0.613714784125419]
	TIME [epoch: 28 sec]
EPOCH 660/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5600323135893468		[learning rate: 0.0011532]
	Learning Rate: 0.00115325
	LOSS [training: 0.5600323135893468 | validation: 0.5201947830246003]
	TIME [epoch: 28 sec]
EPOCH 661/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5028216969733448		[learning rate: 0.0011492]
	Learning Rate: 0.00114917
	LOSS [training: 0.5028216969733448 | validation: 0.564493333968504]
	TIME [epoch: 27.9 sec]
EPOCH 662/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5165135296869108		[learning rate: 0.0011451]
	Learning Rate: 0.00114511
	LOSS [training: 0.5165135296869108 | validation: 0.5348711388103778]
	TIME [epoch: 28 sec]
EPOCH 663/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4720756822660953		[learning rate: 0.0011411]
	Learning Rate: 0.00114106
	LOSS [training: 0.4720756822660953 | validation: 0.4644913258517184]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_663.pth
	Model improved!!!
EPOCH 664/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4511209218006872		[learning rate: 0.001137]
	Learning Rate: 0.00113702
	LOSS [training: 0.4511209218006872 | validation: 0.48697173131680416]
	TIME [epoch: 28 sec]
EPOCH 665/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4483985288223187		[learning rate: 0.001133]
	Learning Rate: 0.001133
	LOSS [training: 0.4483985288223187 | validation: 0.6943594129122999]
	TIME [epoch: 27.9 sec]
EPOCH 666/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5962195297466643		[learning rate: 0.001129]
	Learning Rate: 0.001129
	LOSS [training: 0.5962195297466643 | validation: 0.5210418714276176]
	TIME [epoch: 27.9 sec]
EPOCH 667/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4720181650311		[learning rate: 0.001125]
	Learning Rate: 0.001125
	LOSS [training: 0.4720181650311 | validation: 0.537742381937183]
	TIME [epoch: 27.9 sec]
EPOCH 668/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5469539394739372		[learning rate: 0.001121]
	Learning Rate: 0.00112103
	LOSS [training: 0.5469539394739372 | validation: 0.5569054290410793]
	TIME [epoch: 28 sec]
EPOCH 669/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5381251395464415		[learning rate: 0.0011171]
	Learning Rate: 0.00111706
	LOSS [training: 0.5381251395464415 | validation: 0.49962983991578996]
	TIME [epoch: 28 sec]
EPOCH 670/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5326645405927116		[learning rate: 0.0011131]
	Learning Rate: 0.00111311
	LOSS [training: 0.5326645405927116 | validation: 0.516469435810245]
	TIME [epoch: 27.9 sec]
EPOCH 671/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6212180163847734		[learning rate: 0.0011092]
	Learning Rate: 0.00110917
	LOSS [training: 0.6212180163847734 | validation: 0.5191287309665792]
	TIME [epoch: 27.9 sec]
EPOCH 672/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.559734265387591		[learning rate: 0.0011053]
	Learning Rate: 0.00110525
	LOSS [training: 0.559734265387591 | validation: 0.7994539212083188]
	TIME [epoch: 27.9 sec]
EPOCH 673/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5658195105194304		[learning rate: 0.0011013]
	Learning Rate: 0.00110134
	LOSS [training: 0.5658195105194304 | validation: 0.5724056800577918]
	TIME [epoch: 28 sec]
EPOCH 674/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5478569655095392		[learning rate: 0.0010974]
	Learning Rate: 0.00109745
	LOSS [training: 0.5478569655095392 | validation: 0.6440880067710828]
	TIME [epoch: 28 sec]
EPOCH 675/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5617948693864165		[learning rate: 0.0010936]
	Learning Rate: 0.00109357
	LOSS [training: 0.5617948693864165 | validation: 0.6205401121099431]
	TIME [epoch: 27.9 sec]
EPOCH 676/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.8134206335837063		[learning rate: 0.0010897]
	Learning Rate: 0.0010897
	LOSS [training: 0.8134206335837063 | validation: 0.5327327418981238]
	TIME [epoch: 27.9 sec]
EPOCH 677/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4896987871578856		[learning rate: 0.0010858]
	Learning Rate: 0.00108585
	LOSS [training: 0.4896987871578856 | validation: 0.5353337646953946]
	TIME [epoch: 27.9 sec]
EPOCH 678/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5200001830774174		[learning rate: 0.001082]
	Learning Rate: 0.00108201
	LOSS [training: 0.5200001830774174 | validation: 0.6067841757864522]
	TIME [epoch: 27.9 sec]
EPOCH 679/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5436122549628036		[learning rate: 0.0010782]
	Learning Rate: 0.00107818
	LOSS [training: 0.5436122549628036 | validation: 0.5279592116609628]
	TIME [epoch: 27.8 sec]
EPOCH 680/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47726085113984695		[learning rate: 0.0010744]
	Learning Rate: 0.00107437
	LOSS [training: 0.47726085113984695 | validation: 0.47983163480529284]
	TIME [epoch: 27.7 sec]
EPOCH 681/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4657704259894018		[learning rate: 0.0010706]
	Learning Rate: 0.00107057
	LOSS [training: 0.4657704259894018 | validation: 0.4848124292147454]
	TIME [epoch: 27.7 sec]
EPOCH 682/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4934780318462591		[learning rate: 0.0010668]
	Learning Rate: 0.00106679
	LOSS [training: 0.4934780318462591 | validation: 0.5051981847547615]
	TIME [epoch: 27.7 sec]
EPOCH 683/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5106533395017074		[learning rate: 0.001063]
	Learning Rate: 0.00106301
	LOSS [training: 0.5106533395017074 | validation: 0.4933998971634387]
	TIME [epoch: 27.9 sec]
EPOCH 684/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49996614779085186		[learning rate: 0.0010593]
	Learning Rate: 0.00105925
	LOSS [training: 0.49996614779085186 | validation: 0.6655887248284017]
	TIME [epoch: 28 sec]
EPOCH 685/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5369491896137409		[learning rate: 0.0010555]
	Learning Rate: 0.00105551
	LOSS [training: 0.5369491896137409 | validation: 0.5014109618063736]
	TIME [epoch: 28 sec]
EPOCH 686/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5158863805339893		[learning rate: 0.0010518]
	Learning Rate: 0.00105178
	LOSS [training: 0.5158863805339893 | validation: 0.5315300982098693]
	TIME [epoch: 27.9 sec]
EPOCH 687/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5457298312635946		[learning rate: 0.0010481]
	Learning Rate: 0.00104806
	LOSS [training: 0.5457298312635946 | validation: 0.6069198823126111]
	TIME [epoch: 27.9 sec]
EPOCH 688/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5454279380194006		[learning rate: 0.0010444]
	Learning Rate: 0.00104435
	LOSS [training: 0.5454279380194006 | validation: 0.5590406864972411]
	TIME [epoch: 27.9 sec]
EPOCH 689/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5443702935353552		[learning rate: 0.0010407]
	Learning Rate: 0.00104066
	LOSS [training: 0.5443702935353552 | validation: 0.5362059011917918]
	TIME [epoch: 27.9 sec]
EPOCH 690/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5006269947487593		[learning rate: 0.001037]
	Learning Rate: 0.00103698
	LOSS [training: 0.5006269947487593 | validation: 0.6194194480651793]
	TIME [epoch: 28 sec]
EPOCH 691/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6121469938590369		[learning rate: 0.0010333]
	Learning Rate: 0.00103331
	LOSS [training: 0.6121469938590369 | validation: 0.5752105313704894]
	TIME [epoch: 27.9 sec]
EPOCH 692/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6059733081395938		[learning rate: 0.0010297]
	Learning Rate: 0.00102966
	LOSS [training: 0.6059733081395938 | validation: 0.564438674813906]
	TIME [epoch: 28 sec]
EPOCH 693/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5748093423075592		[learning rate: 0.001026]
	Learning Rate: 0.00102602
	LOSS [training: 0.5748093423075592 | validation: 0.5529063384987176]
	TIME [epoch: 27.9 sec]
EPOCH 694/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48330121939662685		[learning rate: 0.0010224]
	Learning Rate: 0.00102239
	LOSS [training: 0.48330121939662685 | validation: 0.47855554054656246]
	TIME [epoch: 28 sec]
EPOCH 695/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5085038106620037		[learning rate: 0.0010188]
	Learning Rate: 0.00101877
	LOSS [training: 0.5085038106620037 | validation: 0.5339910465585161]
	TIME [epoch: 27.9 sec]
EPOCH 696/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5064406883183642		[learning rate: 0.0010152]
	Learning Rate: 0.00101517
	LOSS [training: 0.5064406883183642 | validation: 0.4781631577948191]
	TIME [epoch: 27.9 sec]
EPOCH 697/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49807152993697146		[learning rate: 0.0010116]
	Learning Rate: 0.00101158
	LOSS [training: 0.49807152993697146 | validation: 0.5699526588656194]
	TIME [epoch: 27.8 sec]
EPOCH 698/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.523690397085841		[learning rate: 0.001008]
	Learning Rate: 0.001008
	LOSS [training: 0.523690397085841 | validation: 0.555918826844099]
	TIME [epoch: 27.8 sec]
EPOCH 699/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6344820407436084		[learning rate: 0.0010044]
	Learning Rate: 0.00100444
	LOSS [training: 0.6344820407436084 | validation: 0.5138700863143422]
	TIME [epoch: 27.8 sec]
EPOCH 700/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49872386530805257		[learning rate: 0.0010009]
	Learning Rate: 0.00100089
	LOSS [training: 0.49872386530805257 | validation: 0.6930431651118941]
	TIME [epoch: 27.8 sec]
EPOCH 701/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5574088531990339		[learning rate: 0.00099735]
	Learning Rate: 0.000997347
	LOSS [training: 0.5574088531990339 | validation: 0.4823548867720933]
	TIME [epoch: 27.8 sec]
EPOCH 702/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5770797411795007		[learning rate: 0.00099382]
	Learning Rate: 0.00099382
	LOSS [training: 0.5770797411795007 | validation: 0.48541121881269234]
	TIME [epoch: 27.9 sec]
EPOCH 703/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48981923422880536		[learning rate: 0.00099031]
	Learning Rate: 0.000990306
	LOSS [training: 0.48981923422880536 | validation: 0.4839319211726955]
	TIME [epoch: 27.9 sec]
EPOCH 704/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5214789364046097		[learning rate: 0.0009868]
	Learning Rate: 0.000986804
	LOSS [training: 0.5214789364046097 | validation: 0.5318639216783282]
	TIME [epoch: 28 sec]
EPOCH 705/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.581014383550538		[learning rate: 0.00098331]
	Learning Rate: 0.000983314
	LOSS [training: 0.581014383550538 | validation: 0.5102403936453215]
	TIME [epoch: 28 sec]
EPOCH 706/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48676364542248196		[learning rate: 0.00097984]
	Learning Rate: 0.000979837
	LOSS [training: 0.48676364542248196 | validation: 0.6285792642289925]
	TIME [epoch: 27.9 sec]
EPOCH 707/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.578910970869671		[learning rate: 0.00097637]
	Learning Rate: 0.000976372
	LOSS [training: 0.578910970869671 | validation: 0.6314243161298861]
	TIME [epoch: 28 sec]
EPOCH 708/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5265181885350814		[learning rate: 0.00097292]
	Learning Rate: 0.00097292
	LOSS [training: 0.5265181885350814 | validation: 0.5288407069340335]
	TIME [epoch: 27.9 sec]
EPOCH 709/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5596230562358528		[learning rate: 0.00096948]
	Learning Rate: 0.000969479
	LOSS [training: 0.5596230562358528 | validation: 0.5594387905422852]
	TIME [epoch: 28 sec]
EPOCH 710/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5248355863090612		[learning rate: 0.00096605]
	Learning Rate: 0.000966051
	LOSS [training: 0.5248355863090612 | validation: 0.4622033294787058]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_710.pth
	Model improved!!!
EPOCH 711/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47711047777354604		[learning rate: 0.00096263]
	Learning Rate: 0.000962635
	LOSS [training: 0.47711047777354604 | validation: 0.5004516302460005]
	TIME [epoch: 28 sec]
EPOCH 712/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4833946467690704		[learning rate: 0.00095923]
	Learning Rate: 0.000959231
	LOSS [training: 0.4833946467690704 | validation: 0.6424195389165839]
	TIME [epoch: 28 sec]
EPOCH 713/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5443026217842831		[learning rate: 0.00095584]
	Learning Rate: 0.000955839
	LOSS [training: 0.5443026217842831 | validation: 0.6564242771592904]
	TIME [epoch: 27.9 sec]
EPOCH 714/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5859961923420257		[learning rate: 0.00095246]
	Learning Rate: 0.000952459
	LOSS [training: 0.5859961923420257 | validation: 0.49342636714786625]
	TIME [epoch: 28 sec]
EPOCH 715/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4745271036640086		[learning rate: 0.00094909]
	Learning Rate: 0.000949091
	LOSS [training: 0.4745271036640086 | validation: 0.4950680880879896]
	TIME [epoch: 27.8 sec]
EPOCH 716/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47183692407731054		[learning rate: 0.00094573]
	Learning Rate: 0.000945735
	LOSS [training: 0.47183692407731054 | validation: 0.48847356681817033]
	TIME [epoch: 27.9 sec]
EPOCH 717/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5714433809166951		[learning rate: 0.00094239]
	Learning Rate: 0.00094239
	LOSS [training: 0.5714433809166951 | validation: 0.742975595198867]
	TIME [epoch: 27.9 sec]
EPOCH 718/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5384107618751781		[learning rate: 0.00093906]
	Learning Rate: 0.000939058
	LOSS [training: 0.5384107618751781 | validation: 0.5082918966579549]
	TIME [epoch: 27.9 sec]
EPOCH 719/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4776626947216729		[learning rate: 0.00093574]
	Learning Rate: 0.000935737
	LOSS [training: 0.4776626947216729 | validation: 0.547260416634431]
	TIME [epoch: 27.9 sec]
EPOCH 720/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4727246843439852		[learning rate: 0.00093243]
	Learning Rate: 0.000932428
	LOSS [training: 0.4727246843439852 | validation: 0.501540191041628]
	TIME [epoch: 27.9 sec]
EPOCH 721/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49512616703246376		[learning rate: 0.00092913]
	Learning Rate: 0.000929131
	LOSS [training: 0.49512616703246376 | validation: 0.48378066511778317]
	TIME [epoch: 28 sec]
EPOCH 722/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4923411303029719		[learning rate: 0.00092585]
	Learning Rate: 0.000925845
	LOSS [training: 0.4923411303029719 | validation: 0.4878969122745366]
	TIME [epoch: 27.9 sec]
EPOCH 723/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48030153004311865		[learning rate: 0.00092257]
	Learning Rate: 0.000922571
	LOSS [training: 0.48030153004311865 | validation: 0.4803284055238898]
	TIME [epoch: 27.9 sec]
EPOCH 724/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4542777553219037		[learning rate: 0.00091931]
	Learning Rate: 0.000919309
	LOSS [training: 0.4542777553219037 | validation: 0.5112668456721849]
	TIME [epoch: 28 sec]
EPOCH 725/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6163293165778008		[learning rate: 0.00091606]
	Learning Rate: 0.000916058
	LOSS [training: 0.6163293165778008 | validation: 0.5913345080698875]
	TIME [epoch: 27.9 sec]
EPOCH 726/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5053798175988122		[learning rate: 0.00091282]
	Learning Rate: 0.000912819
	LOSS [training: 0.5053798175988122 | validation: 0.5824994052228404]
	TIME [epoch: 27.9 sec]
EPOCH 727/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5551198986444055		[learning rate: 0.00090959]
	Learning Rate: 0.000909591
	LOSS [training: 0.5551198986444055 | validation: 0.54647492967137]
	TIME [epoch: 27.9 sec]
EPOCH 728/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5231679818800421		[learning rate: 0.00090637]
	Learning Rate: 0.000906374
	LOSS [training: 0.5231679818800421 | validation: 0.7705041841812166]
	TIME [epoch: 27.8 sec]
EPOCH 729/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6042393606349832		[learning rate: 0.00090317]
	Learning Rate: 0.00090317
	LOSS [training: 0.6042393606349832 | validation: 0.49455130983950724]
	TIME [epoch: 27.8 sec]
EPOCH 730/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4808043949369452		[learning rate: 0.00089998]
	Learning Rate: 0.000899976
	LOSS [training: 0.4808043949369452 | validation: 0.576336156666415]
	TIME [epoch: 27.8 sec]
EPOCH 731/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4986936601450993		[learning rate: 0.00089679]
	Learning Rate: 0.000896793
	LOSS [training: 0.4986936601450993 | validation: 0.48171130860233136]
	TIME [epoch: 27.9 sec]
EPOCH 732/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4598411570451616		[learning rate: 0.00089362]
	Learning Rate: 0.000893622
	LOSS [training: 0.4598411570451616 | validation: 0.5718356581570915]
	TIME [epoch: 28 sec]
EPOCH 733/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4977903745351932		[learning rate: 0.00089046]
	Learning Rate: 0.000890462
	LOSS [training: 0.4977903745351932 | validation: 0.5416133425328117]
	TIME [epoch: 27.9 sec]
EPOCH 734/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6085106172625983		[learning rate: 0.00088731]
	Learning Rate: 0.000887313
	LOSS [training: 0.6085106172625983 | validation: 0.613977021324501]
	TIME [epoch: 27.9 sec]
EPOCH 735/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6416197684328879		[learning rate: 0.00088418]
	Learning Rate: 0.000884176
	LOSS [training: 0.6416197684328879 | validation: 0.46950304238696944]
	TIME [epoch: 28 sec]
EPOCH 736/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4573074575028359		[learning rate: 0.00088105]
	Learning Rate: 0.000881049
	LOSS [training: 0.4573074575028359 | validation: 0.5280411776130104]
	TIME [epoch: 27.9 sec]
EPOCH 737/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.511998269308296		[learning rate: 0.00087793]
	Learning Rate: 0.000877933
	LOSS [training: 0.511998269308296 | validation: 0.7148961800434952]
	TIME [epoch: 27.9 sec]
EPOCH 738/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5726930140909122		[learning rate: 0.00087483]
	Learning Rate: 0.000874829
	LOSS [training: 0.5726930140909122 | validation: 0.4870308152365241]
	TIME [epoch: 27.9 sec]
EPOCH 739/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5243233652148974		[learning rate: 0.00087174]
	Learning Rate: 0.000871735
	LOSS [training: 0.5243233652148974 | validation: 0.4929674410815216]
	TIME [epoch: 28 sec]
EPOCH 740/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4722690722902911		[learning rate: 0.00086865]
	Learning Rate: 0.000868653
	LOSS [training: 0.4722690722902911 | validation: 0.6217985080959915]
	TIME [epoch: 27.9 sec]
EPOCH 741/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.550213406915694		[learning rate: 0.00086558]
	Learning Rate: 0.000865581
	LOSS [training: 0.550213406915694 | validation: 0.53157528409388]
	TIME [epoch: 28 sec]
EPOCH 742/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44877572393247867		[learning rate: 0.00086252]
	Learning Rate: 0.00086252
	LOSS [training: 0.44877572393247867 | validation: 0.46189564685049134]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_742.pth
	Model improved!!!
EPOCH 743/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4904549047455628		[learning rate: 0.00085947]
	Learning Rate: 0.00085947
	LOSS [training: 0.4904549047455628 | validation: 0.534681325078203]
	TIME [epoch: 27.9 sec]
EPOCH 744/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4810619020322222		[learning rate: 0.00085643]
	Learning Rate: 0.000856431
	LOSS [training: 0.4810619020322222 | validation: 0.4751486685873495]
	TIME [epoch: 27.9 sec]
EPOCH 745/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5137590762755663		[learning rate: 0.0008534]
	Learning Rate: 0.000853403
	LOSS [training: 0.5137590762755663 | validation: 0.5666623357476896]
	TIME [epoch: 28 sec]
EPOCH 746/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6077964076695466		[learning rate: 0.00085038]
	Learning Rate: 0.000850385
	LOSS [training: 0.6077964076695466 | validation: 0.6433730971630597]
	TIME [epoch: 27.9 sec]
EPOCH 747/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5838056798609262		[learning rate: 0.00084738]
	Learning Rate: 0.000847378
	LOSS [training: 0.5838056798609262 | validation: 0.6727290620153903]
	TIME [epoch: 27.9 sec]
EPOCH 748/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5527733800269552		[learning rate: 0.00084438]
	Learning Rate: 0.000844381
	LOSS [training: 0.5527733800269552 | validation: 0.4978678025814843]
	TIME [epoch: 27.8 sec]
EPOCH 749/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5939436945472738		[learning rate: 0.0008414]
	Learning Rate: 0.000841395
	LOSS [training: 0.5939436945472738 | validation: 0.6063910570664678]
	TIME [epoch: 27.9 sec]
EPOCH 750/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49884875659850586		[learning rate: 0.00083842]
	Learning Rate: 0.00083842
	LOSS [training: 0.49884875659850586 | validation: 0.49209826768001225]
	TIME [epoch: 27.9 sec]
EPOCH 751/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4642217939901006		[learning rate: 0.00083546]
	Learning Rate: 0.000835455
	LOSS [training: 0.4642217939901006 | validation: 0.4725323556997094]
	TIME [epoch: 28 sec]
EPOCH 752/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46839077820879965		[learning rate: 0.0008325]
	Learning Rate: 0.000832501
	LOSS [training: 0.46839077820879965 | validation: 0.4863035209663727]
	TIME [epoch: 27.8 sec]
EPOCH 753/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.501141171554936		[learning rate: 0.00082956]
	Learning Rate: 0.000829557
	LOSS [training: 0.501141171554936 | validation: 0.6247811648273508]
	TIME [epoch: 27.8 sec]
EPOCH 754/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5809127135000655		[learning rate: 0.00082662]
	Learning Rate: 0.000826623
	LOSS [training: 0.5809127135000655 | validation: 0.4557291529980735]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_754.pth
	Model improved!!!
EPOCH 755/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4449709924206512		[learning rate: 0.0008237]
	Learning Rate: 0.000823701
	LOSS [training: 0.4449709924206512 | validation: 0.5114615014293593]
	TIME [epoch: 27.8 sec]
EPOCH 756/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46598894825465886		[learning rate: 0.00082079]
	Learning Rate: 0.000820788
	LOSS [training: 0.46598894825465886 | validation: 0.45218782955182435]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_756.pth
	Model improved!!!
EPOCH 757/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5081418295707664		[learning rate: 0.00081789]
	Learning Rate: 0.000817885
	LOSS [training: 0.5081418295707664 | validation: 0.6047875189671242]
	TIME [epoch: 27.9 sec]
EPOCH 758/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5100384575359547		[learning rate: 0.00081499]
	Learning Rate: 0.000814993
	LOSS [training: 0.5100384575359547 | validation: 0.5258051191255271]
	TIME [epoch: 28 sec]
EPOCH 759/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4782676693187959		[learning rate: 0.00081211]
	Learning Rate: 0.000812111
	LOSS [training: 0.4782676693187959 | validation: 0.47847039107833084]
	TIME [epoch: 28 sec]
EPOCH 760/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47358814961937096		[learning rate: 0.00080924]
	Learning Rate: 0.000809239
	LOSS [training: 0.47358814961937096 | validation: 0.462463602076443]
	TIME [epoch: 28 sec]
EPOCH 761/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5763111431411071		[learning rate: 0.00080638]
	Learning Rate: 0.000806378
	LOSS [training: 0.5763111431411071 | validation: 0.4651421915919221]
	TIME [epoch: 28 sec]
EPOCH 762/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47030648691659527		[learning rate: 0.00080353]
	Learning Rate: 0.000803526
	LOSS [training: 0.47030648691659527 | validation: 0.4718570965912274]
	TIME [epoch: 28.1 sec]
EPOCH 763/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4895749439504191		[learning rate: 0.00080068]
	Learning Rate: 0.000800685
	LOSS [training: 0.4895749439504191 | validation: 0.4840315198744945]
	TIME [epoch: 28 sec]
EPOCH 764/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46483474151270676		[learning rate: 0.00079785]
	Learning Rate: 0.000797853
	LOSS [training: 0.46483474151270676 | validation: 0.4975005919709798]
	TIME [epoch: 28 sec]
EPOCH 765/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5678571165455923		[learning rate: 0.00079503]
	Learning Rate: 0.000795032
	LOSS [training: 0.5678571165455923 | validation: 0.4821451572817751]
	TIME [epoch: 28 sec]
EPOCH 766/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6184899024132098		[learning rate: 0.00079222]
	Learning Rate: 0.000792221
	LOSS [training: 0.6184899024132098 | validation: 0.46828112886330403]
	TIME [epoch: 27.9 sec]
EPOCH 767/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5181484873426172		[learning rate: 0.00078942]
	Learning Rate: 0.000789419
	LOSS [training: 0.5181484873426172 | validation: 0.6016777829788377]
	TIME [epoch: 28 sec]
EPOCH 768/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4906198378999854		[learning rate: 0.00078663]
	Learning Rate: 0.000786628
	LOSS [training: 0.4906198378999854 | validation: 0.4824348365906164]
	TIME [epoch: 27.9 sec]
EPOCH 769/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4777625879043986		[learning rate: 0.00078385]
	Learning Rate: 0.000783846
	LOSS [training: 0.4777625879043986 | validation: 0.4947789137096524]
	TIME [epoch: 27.9 sec]
EPOCH 770/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4460238800950135		[learning rate: 0.00078107]
	Learning Rate: 0.000781074
	LOSS [training: 0.4460238800950135 | validation: 0.4715596910424418]
	TIME [epoch: 27.9 sec]
EPOCH 771/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404547858326414		[learning rate: 0.00077831]
	Learning Rate: 0.000778312
	LOSS [training: 0.4404547858326414 | validation: 0.4527160889317122]
	TIME [epoch: 27.9 sec]
EPOCH 772/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43483083325470573		[learning rate: 0.00077556]
	Learning Rate: 0.00077556
	LOSS [training: 0.43483083325470573 | validation: 0.4798834599652876]
	TIME [epoch: 27.9 sec]
EPOCH 773/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4555082332779527		[learning rate: 0.00077282]
	Learning Rate: 0.000772817
	LOSS [training: 0.4555082332779527 | validation: 0.4614180193339055]
	TIME [epoch: 27.9 sec]
EPOCH 774/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4875398865915114		[learning rate: 0.00077008]
	Learning Rate: 0.000770085
	LOSS [training: 0.4875398865915114 | validation: 0.5485876612678505]
	TIME [epoch: 27.8 sec]
EPOCH 775/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5793011096537681		[learning rate: 0.00076736]
	Learning Rate: 0.000767362
	LOSS [training: 0.5793011096537681 | validation: 0.47453303559765275]
	TIME [epoch: 27.9 sec]
EPOCH 776/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46261529007828045		[learning rate: 0.00076465]
	Learning Rate: 0.000764648
	LOSS [training: 0.46261529007828045 | validation: 0.4672920094497445]
	TIME [epoch: 27.9 sec]
EPOCH 777/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47135139804004356		[learning rate: 0.00076194]
	Learning Rate: 0.000761944
	LOSS [training: 0.47135139804004356 | validation: 0.5673353761565654]
	TIME [epoch: 28 sec]
EPOCH 778/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5251852829020968		[learning rate: 0.00075925]
	Learning Rate: 0.00075925
	LOSS [training: 0.5251852829020968 | validation: 0.6035111309900419]
	TIME [epoch: 27.9 sec]
EPOCH 779/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5118377461942896		[learning rate: 0.00075656]
	Learning Rate: 0.000756565
	LOSS [training: 0.5118377461942896 | validation: 0.5028778185147047]
	TIME [epoch: 28 sec]
EPOCH 780/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45300766706464934		[learning rate: 0.00075389]
	Learning Rate: 0.00075389
	LOSS [training: 0.45300766706464934 | validation: 0.4527432182535462]
	TIME [epoch: 28 sec]
EPOCH 781/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42561637639328553		[learning rate: 0.00075122]
	Learning Rate: 0.000751224
	LOSS [training: 0.42561637639328553 | validation: 0.4733156511237388]
	TIME [epoch: 27.9 sec]
EPOCH 782/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44764007899209257		[learning rate: 0.00074857]
	Learning Rate: 0.000748567
	LOSS [training: 0.44764007899209257 | validation: 0.5275478278762558]
	TIME [epoch: 27.9 sec]
EPOCH 783/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4600302876444837		[learning rate: 0.00074592]
	Learning Rate: 0.00074592
	LOSS [training: 0.4600302876444837 | validation: 0.46488436802366345]
	TIME [epoch: 27.9 sec]
EPOCH 784/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4634591932833675		[learning rate: 0.00074328]
	Learning Rate: 0.000743282
	LOSS [training: 0.4634591932833675 | validation: 0.5481066198437723]
	TIME [epoch: 27.9 sec]
EPOCH 785/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4326084891847386		[learning rate: 0.00074065]
	Learning Rate: 0.000740654
	LOSS [training: 0.4326084891847386 | validation: 0.4509226105080089]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_785.pth
	Model improved!!!
EPOCH 786/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43930058458480353		[learning rate: 0.00073803]
	Learning Rate: 0.000738035
	LOSS [training: 0.43930058458480353 | validation: 0.6877636058768934]
	TIME [epoch: 27.9 sec]
EPOCH 787/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5960527612686072		[learning rate: 0.00073543]
	Learning Rate: 0.000735425
	LOSS [training: 0.5960527612686072 | validation: 0.4468216441660928]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_787.pth
	Model improved!!!
EPOCH 788/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43010218359618824		[learning rate: 0.00073282]
	Learning Rate: 0.000732824
	LOSS [training: 0.43010218359618824 | validation: 0.4467962883547422]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_788.pth
	Model improved!!!
EPOCH 789/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42260666130152635		[learning rate: 0.00073023]
	Learning Rate: 0.000730233
	LOSS [training: 0.42260666130152635 | validation: 0.47338429795210457]
	TIME [epoch: 27.9 sec]
EPOCH 790/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44632940899872126		[learning rate: 0.00072765]
	Learning Rate: 0.000727651
	LOSS [training: 0.44632940899872126 | validation: 0.4596124984458968]
	TIME [epoch: 27.9 sec]
EPOCH 791/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4299261068341653		[learning rate: 0.00072508]
	Learning Rate: 0.000725078
	LOSS [training: 0.4299261068341653 | validation: 0.47830738666247596]
	TIME [epoch: 27.9 sec]
EPOCH 792/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42781936484600525		[learning rate: 0.00072251]
	Learning Rate: 0.000722514
	LOSS [training: 0.42781936484600525 | validation: 0.43795377235488575]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_792.pth
	Model improved!!!
EPOCH 793/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4530269870027752		[learning rate: 0.00071996]
	Learning Rate: 0.000719959
	LOSS [training: 0.4530269870027752 | validation: 0.44996642342051263]
	TIME [epoch: 28 sec]
EPOCH 794/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4223934654486162		[learning rate: 0.00071741]
	Learning Rate: 0.000717413
	LOSS [training: 0.4223934654486162 | validation: 0.4427438226188491]
	TIME [epoch: 28 sec]
EPOCH 795/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6001180947649883		[learning rate: 0.00071488]
	Learning Rate: 0.000714876
	LOSS [training: 0.6001180947649883 | validation: 1.043112135423737]
	TIME [epoch: 28 sec]
EPOCH 796/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.7240802204935727		[learning rate: 0.00071235]
	Learning Rate: 0.000712348
	LOSS [training: 0.7240802204935727 | validation: 0.48555779250990333]
	TIME [epoch: 28 sec]
EPOCH 797/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47003746279547015		[learning rate: 0.00070983]
	Learning Rate: 0.000709829
	LOSS [training: 0.47003746279547015 | validation: 0.4960823159589805]
	TIME [epoch: 27.9 sec]
EPOCH 798/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5319549163478511		[learning rate: 0.00070732]
	Learning Rate: 0.000707319
	LOSS [training: 0.5319549163478511 | validation: 0.4738732343502142]
	TIME [epoch: 28 sec]
EPOCH 799/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44342147922847686		[learning rate: 0.00070482]
	Learning Rate: 0.000704818
	LOSS [training: 0.44342147922847686 | validation: 0.48405248079289775]
	TIME [epoch: 27.9 sec]
EPOCH 800/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.421178953934411		[learning rate: 0.00070233]
	Learning Rate: 0.000702326
	LOSS [training: 0.421178953934411 | validation: 0.4888475536429678]
	TIME [epoch: 27.9 sec]
EPOCH 801/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.453247727715951		[learning rate: 0.00069984]
	Learning Rate: 0.000699842
	LOSS [training: 0.453247727715951 | validation: 0.49956151369147295]
	TIME [epoch: 28 sec]
EPOCH 802/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44217461091448185		[learning rate: 0.00069737]
	Learning Rate: 0.000697367
	LOSS [training: 0.44217461091448185 | validation: 0.507863192830197]
	TIME [epoch: 27.9 sec]
EPOCH 803/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5893926558714785		[learning rate: 0.0006949]
	Learning Rate: 0.000694901
	LOSS [training: 0.5893926558714785 | validation: 0.4750859701607768]
	TIME [epoch: 27.9 sec]
EPOCH 804/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4683431230682086		[learning rate: 0.00069244]
	Learning Rate: 0.000692444
	LOSS [training: 0.4683431230682086 | validation: 0.466711840896283]
	TIME [epoch: 28 sec]
EPOCH 805/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4451550587964215		[learning rate: 0.00069]
	Learning Rate: 0.000689995
	LOSS [training: 0.4451550587964215 | validation: 0.47388881097755503]
	TIME [epoch: 27.9 sec]
EPOCH 806/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5216081547084224		[learning rate: 0.00068756]
	Learning Rate: 0.000687555
	LOSS [training: 0.5216081547084224 | validation: 0.6905141153711446]
	TIME [epoch: 27.9 sec]
EPOCH 807/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5474649659846672		[learning rate: 0.00068512]
	Learning Rate: 0.000685124
	LOSS [training: 0.5474649659846672 | validation: 0.5119070640494816]
	TIME [epoch: 27.8 sec]
EPOCH 808/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4517486830026294		[learning rate: 0.0006827]
	Learning Rate: 0.000682701
	LOSS [training: 0.4517486830026294 | validation: 0.5328791864650079]
	TIME [epoch: 27.8 sec]
EPOCH 809/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5182725790871159		[learning rate: 0.00068029]
	Learning Rate: 0.000680287
	LOSS [training: 0.5182725790871159 | validation: 0.4518840441074467]
	TIME [epoch: 27.7 sec]
EPOCH 810/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43975288869571544		[learning rate: 0.00067788]
	Learning Rate: 0.000677882
	LOSS [training: 0.43975288869571544 | validation: 0.5665458878658934]
	TIME [epoch: 27.9 sec]
EPOCH 811/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4492070234873383		[learning rate: 0.00067548]
	Learning Rate: 0.000675485
	LOSS [training: 0.4492070234873383 | validation: 0.4567435794509968]
	TIME [epoch: 27.9 sec]
EPOCH 812/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4944668542377991		[learning rate: 0.0006731]
	Learning Rate: 0.000673096
	LOSS [training: 0.4944668542377991 | validation: 0.5058814510461231]
	TIME [epoch: 27.9 sec]
EPOCH 813/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44654243823851264		[learning rate: 0.00067072]
	Learning Rate: 0.000670716
	LOSS [training: 0.44654243823851264 | validation: 0.45653748591832966]
	TIME [epoch: 28 sec]
EPOCH 814/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44194467438874285		[learning rate: 0.00066834]
	Learning Rate: 0.000668344
	LOSS [training: 0.44194467438874285 | validation: 0.5029338780781601]
	TIME [epoch: 27.9 sec]
EPOCH 815/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44453767428013424		[learning rate: 0.00066598]
	Learning Rate: 0.000665981
	LOSS [training: 0.44453767428013424 | validation: 0.4880411128643198]
	TIME [epoch: 27.9 sec]
EPOCH 816/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4254517423407921		[learning rate: 0.00066363]
	Learning Rate: 0.000663626
	LOSS [training: 0.4254517423407921 | validation: 0.47299356998059117]
	TIME [epoch: 27.9 sec]
EPOCH 817/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4576487672262004		[learning rate: 0.00066128]
	Learning Rate: 0.000661279
	LOSS [training: 0.4576487672262004 | validation: 0.5195238559791678]
	TIME [epoch: 27.9 sec]
EPOCH 818/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4700935953054155		[learning rate: 0.00065894]
	Learning Rate: 0.000658941
	LOSS [training: 0.4700935953054155 | validation: 0.5702781966177514]
	TIME [epoch: 28 sec]
EPOCH 819/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44192374755455793		[learning rate: 0.00065661]
	Learning Rate: 0.00065661
	LOSS [training: 0.44192374755455793 | validation: 0.4459283766040797]
	TIME [epoch: 28 sec]
EPOCH 820/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4174621913782428		[learning rate: 0.00065429]
	Learning Rate: 0.000654289
	LOSS [training: 0.4174621913782428 | validation: 0.45365624178939756]
	TIME [epoch: 28 sec]
EPOCH 821/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4688641143716997		[learning rate: 0.00065197]
	Learning Rate: 0.000651975
	LOSS [training: 0.4688641143716997 | validation: 0.5075075510234042]
	TIME [epoch: 27.9 sec]
EPOCH 822/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4374820464644443		[learning rate: 0.00064967]
	Learning Rate: 0.000649669
	LOSS [training: 0.4374820464644443 | validation: 0.44384978480384435]
	TIME [epoch: 28 sec]
EPOCH 823/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4282737430025599		[learning rate: 0.00064737]
	Learning Rate: 0.000647372
	LOSS [training: 0.4282737430025599 | validation: 0.4435451535938389]
	TIME [epoch: 28 sec]
EPOCH 824/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43011798880404084		[learning rate: 0.00064508]
	Learning Rate: 0.000645083
	LOSS [training: 0.43011798880404084 | validation: 0.4756121671432295]
	TIME [epoch: 28 sec]
EPOCH 825/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4693058786194513		[learning rate: 0.0006428]
	Learning Rate: 0.000642802
	LOSS [training: 0.4693058786194513 | validation: 0.45930713468301176]
	TIME [epoch: 28 sec]
EPOCH 826/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41767979444965647		[learning rate: 0.00064053]
	Learning Rate: 0.000640529
	LOSS [training: 0.41767979444965647 | validation: 0.48035589473480744]
	TIME [epoch: 28 sec]
EPOCH 827/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41879524183951944		[learning rate: 0.00063826]
	Learning Rate: 0.000638264
	LOSS [training: 0.41879524183951944 | validation: 0.507647257584142]
	TIME [epoch: 28 sec]
EPOCH 828/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43759421727630216		[learning rate: 0.00063601]
	Learning Rate: 0.000636006
	LOSS [training: 0.43759421727630216 | validation: 0.4285483908109339]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_828.pth
	Model improved!!!
EPOCH 829/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4404494989708884		[learning rate: 0.00063376]
	Learning Rate: 0.000633757
	LOSS [training: 0.4404494989708884 | validation: 0.5252170621594443]
	TIME [epoch: 28 sec]
EPOCH 830/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45714328426805184		[learning rate: 0.00063152]
	Learning Rate: 0.000631517
	LOSS [training: 0.45714328426805184 | validation: 0.48404141366677367]
	TIME [epoch: 28 sec]
EPOCH 831/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41676430920964885		[learning rate: 0.00062928]
	Learning Rate: 0.000629283
	LOSS [training: 0.41676430920964885 | validation: 0.4549757471169663]
	TIME [epoch: 27.9 sec]
EPOCH 832/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44387140244910217		[learning rate: 0.00062706]
	Learning Rate: 0.000627058
	LOSS [training: 0.44387140244910217 | validation: 0.7122595930877645]
	TIME [epoch: 27.9 sec]
EPOCH 833/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5213995963571818		[learning rate: 0.00062484]
	Learning Rate: 0.000624841
	LOSS [training: 0.5213995963571818 | validation: 0.4537701715136379]
	TIME [epoch: 28 sec]
EPOCH 834/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44233825140636235		[learning rate: 0.00062263]
	Learning Rate: 0.000622631
	LOSS [training: 0.44233825140636235 | validation: 0.4508742405618388]
	TIME [epoch: 27.9 sec]
EPOCH 835/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4698518521149774		[learning rate: 0.00062043]
	Learning Rate: 0.000620429
	LOSS [training: 0.4698518521149774 | validation: 0.4967366511969482]
	TIME [epoch: 28 sec]
EPOCH 836/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4468141273218313		[learning rate: 0.00061824]
	Learning Rate: 0.000618235
	LOSS [training: 0.4468141273218313 | validation: 0.46804313099829203]
	TIME [epoch: 27.9 sec]
EPOCH 837/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45558862425628044		[learning rate: 0.00061605]
	Learning Rate: 0.000616049
	LOSS [training: 0.45558862425628044 | validation: 0.4460522657620126]
	TIME [epoch: 28 sec]
EPOCH 838/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48057202983198205		[learning rate: 0.00061387]
	Learning Rate: 0.000613871
	LOSS [training: 0.48057202983198205 | validation: 0.45392133258968764]
	TIME [epoch: 27.9 sec]
EPOCH 839/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43467625607767574		[learning rate: 0.0006117]
	Learning Rate: 0.0006117
	LOSS [training: 0.43467625607767574 | validation: 0.44657289623571494]
	TIME [epoch: 28 sec]
EPOCH 840/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45945576174944613		[learning rate: 0.00060954]
	Learning Rate: 0.000609537
	LOSS [training: 0.45945576174944613 | validation: 0.5198601028692237]
	TIME [epoch: 28 sec]
EPOCH 841/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4749017424202636		[learning rate: 0.00060738]
	Learning Rate: 0.000607381
	LOSS [training: 0.4749017424202636 | validation: 0.5982221701424942]
	TIME [epoch: 28 sec]
EPOCH 842/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5767927140187492		[learning rate: 0.00060523]
	Learning Rate: 0.000605234
	LOSS [training: 0.5767927140187492 | validation: 0.4286894561515264]
	TIME [epoch: 28 sec]
EPOCH 843/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40661859952779456		[learning rate: 0.00060309]
	Learning Rate: 0.000603093
	LOSS [training: 0.40661859952779456 | validation: 0.5541245780474424]
	TIME [epoch: 28 sec]
EPOCH 844/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4770995343211115		[learning rate: 0.00060096]
	Learning Rate: 0.000600961
	LOSS [training: 0.4770995343211115 | validation: 0.44347505941859133]
	TIME [epoch: 27.9 sec]
EPOCH 845/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4938534783861902		[learning rate: 0.00059884]
	Learning Rate: 0.000598836
	LOSS [training: 0.4938534783861902 | validation: 0.45434720337718765]
	TIME [epoch: 27.9 sec]
EPOCH 846/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4131479738643497		[learning rate: 0.00059672]
	Learning Rate: 0.000596718
	LOSS [training: 0.4131479738643497 | validation: 0.44421332767895594]
	TIME [epoch: 27.9 sec]
EPOCH 847/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41033985047911553		[learning rate: 0.00059461]
	Learning Rate: 0.000594608
	LOSS [training: 0.41033985047911553 | validation: 0.446669768143709]
	TIME [epoch: 28 sec]
EPOCH 848/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40430707063729926		[learning rate: 0.00059251]
	Learning Rate: 0.000592505
	LOSS [training: 0.40430707063729926 | validation: 0.648267253455056]
	TIME [epoch: 28 sec]
EPOCH 849/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5192796028510757		[learning rate: 0.00059041]
	Learning Rate: 0.00059041
	LOSS [training: 0.5192796028510757 | validation: 0.4467765583066]
	TIME [epoch: 27.9 sec]
EPOCH 850/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40333925105814583		[learning rate: 0.00058832]
	Learning Rate: 0.000588323
	LOSS [training: 0.40333925105814583 | validation: 0.4965638619255398]
	TIME [epoch: 27.9 sec]
EPOCH 851/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472021781410026		[learning rate: 0.00058624]
	Learning Rate: 0.000586242
	LOSS [training: 0.4472021781410026 | validation: 0.43390709309087827]
	TIME [epoch: 28 sec]
EPOCH 852/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4089968671711199		[learning rate: 0.00058417]
	Learning Rate: 0.000584169
	LOSS [training: 0.4089968671711199 | validation: 0.4427113883585919]
	TIME [epoch: 27.9 sec]
EPOCH 853/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4477372531179029		[learning rate: 0.0005821]
	Learning Rate: 0.000582103
	LOSS [training: 0.4477372531179029 | validation: 0.4364449537375368]
	TIME [epoch: 27.9 sec]
EPOCH 854/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4044213599428781		[learning rate: 0.00058004]
	Learning Rate: 0.000580045
	LOSS [training: 0.4044213599428781 | validation: 0.463679152024739]
	TIME [epoch: 28 sec]
EPOCH 855/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41636610971784827		[learning rate: 0.00057799]
	Learning Rate: 0.000577994
	LOSS [training: 0.41636610971784827 | validation: 0.46485477956886273]
	TIME [epoch: 27.9 sec]
EPOCH 856/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42236756662223374		[learning rate: 0.00057595]
	Learning Rate: 0.00057595
	LOSS [training: 0.42236756662223374 | validation: 0.4710290340860421]
	TIME [epoch: 28 sec]
EPOCH 857/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4013648379893401		[learning rate: 0.00057391]
	Learning Rate: 0.000573913
	LOSS [training: 0.4013648379893401 | validation: 0.4652431809743962]
	TIME [epoch: 27.9 sec]
EPOCH 858/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44197463080656924		[learning rate: 0.00057188]
	Learning Rate: 0.000571884
	LOSS [training: 0.44197463080656924 | validation: 0.47215844444059185]
	TIME [epoch: 28 sec]
EPOCH 859/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45684062220378574		[learning rate: 0.00056986]
	Learning Rate: 0.000569861
	LOSS [training: 0.45684062220378574 | validation: 0.4643417302684617]
	TIME [epoch: 28 sec]
EPOCH 860/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5040305991917071		[learning rate: 0.00056785]
	Learning Rate: 0.000567846
	LOSS [training: 0.5040305991917071 | validation: 0.43275155711258323]
	TIME [epoch: 27.9 sec]
EPOCH 861/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.419446354794182		[learning rate: 0.00056584]
	Learning Rate: 0.000565838
	LOSS [training: 0.419446354794182 | validation: 0.4380094218544527]
	TIME [epoch: 28 sec]
EPOCH 862/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5041726997169492		[learning rate: 0.00056384]
	Learning Rate: 0.000563837
	LOSS [training: 0.5041726997169492 | validation: 0.5129124909553585]
	TIME [epoch: 28 sec]
EPOCH 863/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4472896444679721		[learning rate: 0.00056184]
	Learning Rate: 0.000561844
	LOSS [training: 0.4472896444679721 | validation: 0.45654810103551186]
	TIME [epoch: 28 sec]
EPOCH 864/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47611360313587536		[learning rate: 0.00055986]
	Learning Rate: 0.000559857
	LOSS [training: 0.47611360313587536 | validation: 0.4294563173554203]
	TIME [epoch: 27.9 sec]
EPOCH 865/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4566280404832759		[learning rate: 0.00055788]
	Learning Rate: 0.000557877
	LOSS [training: 0.4566280404832759 | validation: 0.42406186618035946]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_865.pth
	Model improved!!!
EPOCH 866/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.6314981479815468		[learning rate: 0.0005559]
	Learning Rate: 0.000555904
	LOSS [training: 0.6314981479815468 | validation: 0.6759001354987304]
	TIME [epoch: 27.9 sec]
EPOCH 867/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5153309170418814		[learning rate: 0.00055394]
	Learning Rate: 0.000553939
	LOSS [training: 0.5153309170418814 | validation: 0.44877158776289167]
	TIME [epoch: 28 sec]
EPOCH 868/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4165011785188325		[learning rate: 0.00055198]
	Learning Rate: 0.00055198
	LOSS [training: 0.4165011785188325 | validation: 0.4817794857734859]
	TIME [epoch: 28 sec]
EPOCH 869/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5289659910335027		[learning rate: 0.00055003]
	Learning Rate: 0.000550028
	LOSS [training: 0.5289659910335027 | validation: 0.4434845042669986]
	TIME [epoch: 28 sec]
EPOCH 870/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4360053617742881		[learning rate: 0.00054808]
	Learning Rate: 0.000548083
	LOSS [training: 0.4360053617742881 | validation: 0.5978072936061729]
	TIME [epoch: 28 sec]
EPOCH 871/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5801409090100327		[learning rate: 0.00054614]
	Learning Rate: 0.000546145
	LOSS [training: 0.5801409090100327 | validation: 0.47216139716288014]
	TIME [epoch: 28 sec]
EPOCH 872/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4340299166163254		[learning rate: 0.00054421]
	Learning Rate: 0.000544213
	LOSS [training: 0.4340299166163254 | validation: 0.467392987963996]
	TIME [epoch: 27.9 sec]
EPOCH 873/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44838524112733213		[learning rate: 0.00054229]
	Learning Rate: 0.000542289
	LOSS [training: 0.44838524112733213 | validation: 0.42231512156617884]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_873.pth
	Model improved!!!
EPOCH 874/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4170491709167813		[learning rate: 0.00054037]
	Learning Rate: 0.000540371
	LOSS [training: 0.4170491709167813 | validation: 0.4444455753158286]
	TIME [epoch: 27.9 sec]
EPOCH 875/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.394133854125195		[learning rate: 0.00053846]
	Learning Rate: 0.000538461
	LOSS [training: 0.394133854125195 | validation: 0.4347205241495879]
	TIME [epoch: 27.9 sec]
EPOCH 876/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42672069088399345		[learning rate: 0.00053656]
	Learning Rate: 0.000536556
	LOSS [training: 0.42672069088399345 | validation: 0.5366370652411956]
	TIME [epoch: 28 sec]
EPOCH 877/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4561813523971654		[learning rate: 0.00053466]
	Learning Rate: 0.000534659
	LOSS [training: 0.4561813523971654 | validation: 0.493297999766168]
	TIME [epoch: 28 sec]
EPOCH 878/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5931888653906903		[learning rate: 0.00053277]
	Learning Rate: 0.000532768
	LOSS [training: 0.5931888653906903 | validation: 0.4396119792378822]
	TIME [epoch: 27.9 sec]
EPOCH 879/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40794505661664954		[learning rate: 0.00053088]
	Learning Rate: 0.000530884
	LOSS [training: 0.40794505661664954 | validation: 0.41964466305406306]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_879.pth
	Model improved!!!
EPOCH 880/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.416186200472252		[learning rate: 0.00052901]
	Learning Rate: 0.000529007
	LOSS [training: 0.416186200472252 | validation: 0.47831127136859375]
	TIME [epoch: 28 sec]
EPOCH 881/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41991147008339325		[learning rate: 0.00052714]
	Learning Rate: 0.000527136
	LOSS [training: 0.41991147008339325 | validation: 0.45949293162841776]
	TIME [epoch: 27.9 sec]
EPOCH 882/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4336015226110157		[learning rate: 0.00052527]
	Learning Rate: 0.000525273
	LOSS [training: 0.4336015226110157 | validation: 0.49116828830318043]
	TIME [epoch: 28 sec]
EPOCH 883/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.437297554943016		[learning rate: 0.00052341]
	Learning Rate: 0.000523415
	LOSS [training: 0.437297554943016 | validation: 0.5253837374040436]
	TIME [epoch: 27.9 sec]
EPOCH 884/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45548043643724845		[learning rate: 0.00052156]
	Learning Rate: 0.000521564
	LOSS [training: 0.45548043643724845 | validation: 0.6256599061428308]
	TIME [epoch: 28 sec]
EPOCH 885/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5463702089436335		[learning rate: 0.00051972]
	Learning Rate: 0.00051972
	LOSS [training: 0.5463702089436335 | validation: 0.4220658613175924]
	TIME [epoch: 27.9 sec]
EPOCH 886/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4381097828204984		[learning rate: 0.00051788]
	Learning Rate: 0.000517882
	LOSS [training: 0.4381097828204984 | validation: 0.42869801922197653]
	TIME [epoch: 27.9 sec]
EPOCH 887/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44210115515623355		[learning rate: 0.00051605]
	Learning Rate: 0.000516051
	LOSS [training: 0.44210115515623355 | validation: 0.7188989198057933]
	TIME [epoch: 27.8 sec]
EPOCH 888/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5563993727430071		[learning rate: 0.00051423]
	Learning Rate: 0.000514226
	LOSS [training: 0.5563993727430071 | validation: 0.42983627538242525]
	TIME [epoch: 27.7 sec]
EPOCH 889/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46492867077578953		[learning rate: 0.00051241]
	Learning Rate: 0.000512407
	LOSS [training: 0.46492867077578953 | validation: 0.4308800468477206]
	TIME [epoch: 27.8 sec]
EPOCH 890/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4278107663333296		[learning rate: 0.0005106]
	Learning Rate: 0.000510596
	LOSS [training: 0.4278107663333296 | validation: 0.5061447742435099]
	TIME [epoch: 27.8 sec]
EPOCH 891/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43219697876262053		[learning rate: 0.00050879]
	Learning Rate: 0.00050879
	LOSS [training: 0.43219697876262053 | validation: 0.4194302797799305]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_891.pth
	Model improved!!!
EPOCH 892/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41046000307241914		[learning rate: 0.00050699]
	Learning Rate: 0.000506991
	LOSS [training: 0.41046000307241914 | validation: 0.44596341584057136]
	TIME [epoch: 27.9 sec]
EPOCH 893/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42198634036163596		[learning rate: 0.0005052]
	Learning Rate: 0.000505198
	LOSS [training: 0.42198634036163596 | validation: 0.5362867427780558]
	TIME [epoch: 27.9 sec]
EPOCH 894/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4297944574165961		[learning rate: 0.00050341]
	Learning Rate: 0.000503412
	LOSS [training: 0.4297944574165961 | validation: 0.4223693512643527]
	TIME [epoch: 28 sec]
EPOCH 895/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4232803956957524		[learning rate: 0.00050163]
	Learning Rate: 0.000501631
	LOSS [training: 0.4232803956957524 | validation: 0.4370982263522609]
	TIME [epoch: 27.9 sec]
EPOCH 896/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40650120619628655		[learning rate: 0.00049986]
	Learning Rate: 0.000499857
	LOSS [training: 0.40650120619628655 | validation: 0.4234911767732149]
	TIME [epoch: 27.9 sec]
EPOCH 897/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39016826672064003		[learning rate: 0.00049809]
	Learning Rate: 0.00049809
	LOSS [training: 0.39016826672064003 | validation: 0.4187554692926109]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_897.pth
	Model improved!!!
EPOCH 898/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41983048866303696		[learning rate: 0.00049633]
	Learning Rate: 0.000496329
	LOSS [training: 0.41983048866303696 | validation: 0.4559505898675325]
	TIME [epoch: 27.9 sec]
EPOCH 899/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4627920166385069		[learning rate: 0.00049457]
	Learning Rate: 0.000494573
	LOSS [training: 0.4627920166385069 | validation: 0.49770840591993853]
	TIME [epoch: 27.9 sec]
EPOCH 900/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4351678380184666		[learning rate: 0.00049282]
	Learning Rate: 0.000492825
	LOSS [training: 0.4351678380184666 | validation: 0.5273971100789122]
	TIME [epoch: 27.9 sec]
EPOCH 901/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4302766496041117		[learning rate: 0.00049108]
	Learning Rate: 0.000491082
	LOSS [training: 0.4302766496041117 | validation: 0.45635878718669837]
	TIME [epoch: 27.9 sec]
EPOCH 902/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5377322899261724		[learning rate: 0.00048935]
	Learning Rate: 0.000489345
	LOSS [training: 0.5377322899261724 | validation: 0.4127657701437198]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_902.pth
	Model improved!!!
EPOCH 903/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.427070734822803		[learning rate: 0.00048761]
	Learning Rate: 0.000487615
	LOSS [training: 0.427070734822803 | validation: 0.6239166249247567]
	TIME [epoch: 27.9 sec]
EPOCH 904/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.570182947966344		[learning rate: 0.00048589]
	Learning Rate: 0.000485891
	LOSS [training: 0.570182947966344 | validation: 0.45551083471846526]
	TIME [epoch: 28 sec]
EPOCH 905/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5161047921824038		[learning rate: 0.00048417]
	Learning Rate: 0.000484172
	LOSS [training: 0.5161047921824038 | validation: 0.48751564714004403]
	TIME [epoch: 28 sec]
EPOCH 906/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40024729442112406		[learning rate: 0.00048246]
	Learning Rate: 0.00048246
	LOSS [training: 0.40024729442112406 | validation: 0.4194261488823894]
	TIME [epoch: 27.9 sec]
EPOCH 907/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976102229399876		[learning rate: 0.00048075]
	Learning Rate: 0.000480754
	LOSS [training: 0.3976102229399876 | validation: 0.42727665590121816]
	TIME [epoch: 27.9 sec]
EPOCH 908/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39860916546466896		[learning rate: 0.00047905]
	Learning Rate: 0.000479054
	LOSS [training: 0.39860916546466896 | validation: 0.40689156827245887]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_908.pth
	Model improved!!!
EPOCH 909/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49217312356225373		[learning rate: 0.00047736]
	Learning Rate: 0.00047736
	LOSS [training: 0.49217312356225373 | validation: 0.604610046322553]
	TIME [epoch: 27.9 sec]
EPOCH 910/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4721734597738589		[learning rate: 0.00047567]
	Learning Rate: 0.000475672
	LOSS [training: 0.4721734597738589 | validation: 0.42950062313270465]
	TIME [epoch: 27.9 sec]
EPOCH 911/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43668954030319984		[learning rate: 0.00047399]
	Learning Rate: 0.00047399
	LOSS [training: 0.43668954030319984 | validation: 0.5836623885683048]
	TIME [epoch: 27.9 sec]
EPOCH 912/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.513185170942567		[learning rate: 0.00047231]
	Learning Rate: 0.000472314
	LOSS [training: 0.513185170942567 | validation: 0.4802085679085646]
	TIME [epoch: 27.9 sec]
EPOCH 913/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49612386539639103		[learning rate: 0.00047064]
	Learning Rate: 0.000470644
	LOSS [training: 0.49612386539639103 | validation: 0.5061866076666466]
	TIME [epoch: 27.9 sec]
EPOCH 914/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4132046880405753		[learning rate: 0.00046898]
	Learning Rate: 0.00046898
	LOSS [training: 0.4132046880405753 | validation: 0.4213174119236293]
	TIME [epoch: 27.9 sec]
EPOCH 915/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38886848307125566		[learning rate: 0.00046732]
	Learning Rate: 0.000467321
	LOSS [training: 0.38886848307125566 | validation: 0.44635160522873174]
	TIME [epoch: 27.9 sec]
EPOCH 916/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4258419609269577		[learning rate: 0.00046567]
	Learning Rate: 0.000465669
	LOSS [training: 0.4258419609269577 | validation: 0.4188380107747324]
	TIME [epoch: 27.9 sec]
EPOCH 917/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42872821666196737		[learning rate: 0.00046402]
	Learning Rate: 0.000464022
	LOSS [training: 0.42872821666196737 | validation: 0.41110390142715475]
	TIME [epoch: 27.9 sec]
EPOCH 918/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39945303941979937		[learning rate: 0.00046238]
	Learning Rate: 0.000462381
	LOSS [training: 0.39945303941979937 | validation: 0.5002649017264514]
	TIME [epoch: 27.9 sec]
EPOCH 919/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4614555566673279		[learning rate: 0.00046075]
	Learning Rate: 0.000460746
	LOSS [training: 0.4614555566673279 | validation: 0.44840788564507433]
	TIME [epoch: 27.9 sec]
EPOCH 920/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4293678734296238		[learning rate: 0.00045912]
	Learning Rate: 0.000459117
	LOSS [training: 0.4293678734296238 | validation: 0.4566147416283296]
	TIME [epoch: 27.9 sec]
EPOCH 921/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4538101530009062		[learning rate: 0.00045749]
	Learning Rate: 0.000457493
	LOSS [training: 0.4538101530009062 | validation: 0.44584383303240516]
	TIME [epoch: 27.9 sec]
EPOCH 922/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41351667398694064		[learning rate: 0.00045588]
	Learning Rate: 0.000455875
	LOSS [training: 0.41351667398694064 | validation: 0.5854293399723848]
	TIME [epoch: 27.9 sec]
EPOCH 923/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.48350988677557233		[learning rate: 0.00045426]
	Learning Rate: 0.000454263
	LOSS [training: 0.48350988677557233 | validation: 0.4288824408915256]
	TIME [epoch: 27.9 sec]
EPOCH 924/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40384513648938336		[learning rate: 0.00045266]
	Learning Rate: 0.000452657
	LOSS [training: 0.40384513648938336 | validation: 0.41111694999854154]
	TIME [epoch: 27.9 sec]
EPOCH 925/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3970326279227628		[learning rate: 0.00045106]
	Learning Rate: 0.000451056
	LOSS [training: 0.3970326279227628 | validation: 0.4849706728116205]
	TIME [epoch: 27.9 sec]
EPOCH 926/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44064470827826474		[learning rate: 0.00044946]
	Learning Rate: 0.000449461
	LOSS [training: 0.44064470827826474 | validation: 0.4103147754067716]
	TIME [epoch: 27.8 sec]
EPOCH 927/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39360496522645194		[learning rate: 0.00044787]
	Learning Rate: 0.000447872
	LOSS [training: 0.39360496522645194 | validation: 0.45254869074833665]
	TIME [epoch: 27.9 sec]
EPOCH 928/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49164223881136426		[learning rate: 0.00044629]
	Learning Rate: 0.000446288
	LOSS [training: 0.49164223881136426 | validation: 0.43639729401352645]
	TIME [epoch: 27.9 sec]
EPOCH 929/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41188797142054745		[learning rate: 0.00044471]
	Learning Rate: 0.00044471
	LOSS [training: 0.41188797142054745 | validation: 0.4149743914221189]
	TIME [epoch: 27.8 sec]
EPOCH 930/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4190760670880126		[learning rate: 0.00044314]
	Learning Rate: 0.000443138
	LOSS [training: 0.4190760670880126 | validation: 0.4472378501868757]
	TIME [epoch: 27.9 sec]
EPOCH 931/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4000642962172234		[learning rate: 0.00044157]
	Learning Rate: 0.000441571
	LOSS [training: 0.4000642962172234 | validation: 0.4154128139477048]
	TIME [epoch: 27.9 sec]
EPOCH 932/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40775158605581		[learning rate: 0.00044001]
	Learning Rate: 0.000440009
	LOSS [training: 0.40775158605581 | validation: 0.40780138215415324]
	TIME [epoch: 27.9 sec]
EPOCH 933/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45985768075922784		[learning rate: 0.00043845]
	Learning Rate: 0.000438453
	LOSS [training: 0.45985768075922784 | validation: 0.502181840015123]
	TIME [epoch: 27.9 sec]
EPOCH 934/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4655126282924318		[learning rate: 0.0004369]
	Learning Rate: 0.000436903
	LOSS [training: 0.4655126282924318 | validation: 0.508699150398091]
	TIME [epoch: 27.9 sec]
EPOCH 935/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5613960722018693		[learning rate: 0.00043536]
	Learning Rate: 0.000435358
	LOSS [training: 0.5613960722018693 | validation: 0.6106859081321805]
	TIME [epoch: 27.9 sec]
EPOCH 936/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4633578871391949		[learning rate: 0.00043382]
	Learning Rate: 0.000433818
	LOSS [training: 0.4633578871391949 | validation: 0.447086629020353]
	TIME [epoch: 27.9 sec]
EPOCH 937/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4375726441010181		[learning rate: 0.00043228]
	Learning Rate: 0.000432284
	LOSS [training: 0.4375726441010181 | validation: 0.4147358851431207]
	TIME [epoch: 27.9 sec]
EPOCH 938/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3936431031927991		[learning rate: 0.00043076]
	Learning Rate: 0.000430755
	LOSS [training: 0.3936431031927991 | validation: 0.5524348729938015]
	TIME [epoch: 27.9 sec]
EPOCH 939/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5035040159522741		[learning rate: 0.00042923]
	Learning Rate: 0.000429232
	LOSS [training: 0.5035040159522741 | validation: 0.41984009247533466]
	TIME [epoch: 27.9 sec]
EPOCH 940/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3933761734159028		[learning rate: 0.00042771]
	Learning Rate: 0.000427714
	LOSS [training: 0.3933761734159028 | validation: 0.41839109582557554]
	TIME [epoch: 28 sec]
EPOCH 941/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39071179695527675		[learning rate: 0.0004262]
	Learning Rate: 0.000426202
	LOSS [training: 0.39071179695527675 | validation: 0.43277231593690274]
	TIME [epoch: 27.9 sec]
EPOCH 942/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39937891061772335		[learning rate: 0.00042469]
	Learning Rate: 0.000424695
	LOSS [training: 0.39937891061772335 | validation: 0.4204725966212689]
	TIME [epoch: 28 sec]
EPOCH 943/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4150703846473134		[learning rate: 0.00042319]
	Learning Rate: 0.000423193
	LOSS [training: 0.4150703846473134 | validation: 0.5721331679033258]
	TIME [epoch: 28 sec]
EPOCH 944/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5402440596545772		[learning rate: 0.0004217]
	Learning Rate: 0.000421697
	LOSS [training: 0.5402440596545772 | validation: 0.43624878016573787]
	TIME [epoch: 27.9 sec]
EPOCH 945/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38804505988554217		[learning rate: 0.00042021]
	Learning Rate: 0.000420205
	LOSS [training: 0.38804505988554217 | validation: 0.4569759241330683]
	TIME [epoch: 28 sec]
EPOCH 946/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4678773181596684		[learning rate: 0.00041872]
	Learning Rate: 0.000418719
	LOSS [training: 0.4678773181596684 | validation: 0.44082306167218804]
	TIME [epoch: 27.9 sec]
EPOCH 947/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41235373179758855		[learning rate: 0.00041724]
	Learning Rate: 0.000417239
	LOSS [training: 0.41235373179758855 | validation: 0.5510779911606507]
	TIME [epoch: 28 sec]
EPOCH 948/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43631161238587657		[learning rate: 0.00041576]
	Learning Rate: 0.000415763
	LOSS [training: 0.43631161238587657 | validation: 0.5092381860320391]
	TIME [epoch: 27.9 sec]
EPOCH 949/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5217279624779493		[learning rate: 0.00041429]
	Learning Rate: 0.000414293
	LOSS [training: 0.5217279624779493 | validation: 0.40298503217645876]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_949.pth
	Model improved!!!
EPOCH 950/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3904073321073608		[learning rate: 0.00041283]
	Learning Rate: 0.000412828
	LOSS [training: 0.3904073321073608 | validation: 0.4456766608422858]
	TIME [epoch: 28 sec]
EPOCH 951/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.420316940545822		[learning rate: 0.00041137]
	Learning Rate: 0.000411368
	LOSS [training: 0.420316940545822 | validation: 0.4232873985448357]
	TIME [epoch: 27.9 sec]
EPOCH 952/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3884672229771489		[learning rate: 0.00040991]
	Learning Rate: 0.000409914
	LOSS [training: 0.3884672229771489 | validation: 0.4128004080401364]
	TIME [epoch: 27.9 sec]
EPOCH 953/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3877676753287971		[learning rate: 0.00040846]
	Learning Rate: 0.000408464
	LOSS [training: 0.3877676753287971 | validation: 0.4605793129446562]
	TIME [epoch: 28 sec]
EPOCH 954/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.409647490711649		[learning rate: 0.00040702]
	Learning Rate: 0.00040702
	LOSS [training: 0.409647490711649 | validation: 0.4262760477564102]
	TIME [epoch: 28 sec]
EPOCH 955/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39668763786655664		[learning rate: 0.00040558]
	Learning Rate: 0.00040558
	LOSS [training: 0.39668763786655664 | validation: 0.43157962421892143]
	TIME [epoch: 28 sec]
EPOCH 956/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39833976239553137		[learning rate: 0.00040415]
	Learning Rate: 0.000404146
	LOSS [training: 0.39833976239553137 | validation: 0.41734103552198265]
	TIME [epoch: 28 sec]
EPOCH 957/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4168113909947701		[learning rate: 0.00040272]
	Learning Rate: 0.000402717
	LOSS [training: 0.4168113909947701 | validation: 0.4744974653721137]
	TIME [epoch: 27.9 sec]
EPOCH 958/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40724512523218975		[learning rate: 0.00040129]
	Learning Rate: 0.000401293
	LOSS [training: 0.40724512523218975 | validation: 0.4196001638006015]
	TIME [epoch: 27.9 sec]
EPOCH 959/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.432424481541555		[learning rate: 0.00039987]
	Learning Rate: 0.000399874
	LOSS [training: 0.432424481541555 | validation: 0.4054002573655703]
	TIME [epoch: 27.9 sec]
EPOCH 960/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4001522879866178		[learning rate: 0.00039846]
	Learning Rate: 0.00039846
	LOSS [training: 0.4001522879866178 | validation: 0.4730203685186234]
	TIME [epoch: 27.9 sec]
EPOCH 961/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4148603708953333		[learning rate: 0.00039705]
	Learning Rate: 0.000397051
	LOSS [training: 0.4148603708953333 | validation: 0.42351185242680317]
	TIME [epoch: 28 sec]
EPOCH 962/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4244685034916239		[learning rate: 0.00039565]
	Learning Rate: 0.000395647
	LOSS [training: 0.4244685034916239 | validation: 0.41444270710223935]
	TIME [epoch: 27.9 sec]
EPOCH 963/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3976728410693392		[learning rate: 0.00039425]
	Learning Rate: 0.000394248
	LOSS [training: 0.3976728410693392 | validation: 0.415248558045735]
	TIME [epoch: 28 sec]
EPOCH 964/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4100488080146871		[learning rate: 0.00039285]
	Learning Rate: 0.000392854
	LOSS [training: 0.4100488080146871 | validation: 0.6487965299154024]
	TIME [epoch: 27.9 sec]
EPOCH 965/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5125915099865777		[learning rate: 0.00039146]
	Learning Rate: 0.000391464
	LOSS [training: 0.5125915099865777 | validation: 0.41237689899296476]
	TIME [epoch: 28 sec]
EPOCH 966/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3809149414801179		[learning rate: 0.00039008]
	Learning Rate: 0.00039008
	LOSS [training: 0.3809149414801179 | validation: 0.45515997242224565]
	TIME [epoch: 27.9 sec]
EPOCH 967/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4230799699516594		[learning rate: 0.0003887]
	Learning Rate: 0.000388701
	LOSS [training: 0.4230799699516594 | validation: 0.5316561048575341]
	TIME [epoch: 27.9 sec]
EPOCH 968/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4634655096096248		[learning rate: 0.00038733]
	Learning Rate: 0.000387326
	LOSS [training: 0.4634655096096248 | validation: 0.5257233929179639]
	TIME [epoch: 27.9 sec]
EPOCH 969/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.45513510976489063		[learning rate: 0.00038596]
	Learning Rate: 0.000385957
	LOSS [training: 0.45513510976489063 | validation: 0.49895951901758157]
	TIME [epoch: 27.9 sec]
EPOCH 970/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4395968674512628		[learning rate: 0.00038459]
	Learning Rate: 0.000384592
	LOSS [training: 0.4395968674512628 | validation: 0.44891522018443597]
	TIME [epoch: 27.9 sec]
EPOCH 971/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40993256780069587		[learning rate: 0.00038323]
	Learning Rate: 0.000383232
	LOSS [training: 0.40993256780069587 | validation: 0.42870226968955105]
	TIME [epoch: 28 sec]
EPOCH 972/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3919200192380668		[learning rate: 0.00038188]
	Learning Rate: 0.000381877
	LOSS [training: 0.3919200192380668 | validation: 0.44051863349739945]
	TIME [epoch: 27.9 sec]
EPOCH 973/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43102288569722425		[learning rate: 0.00038053]
	Learning Rate: 0.000380526
	LOSS [training: 0.43102288569722425 | validation: 0.5226768907823885]
	TIME [epoch: 27.9 sec]
EPOCH 974/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4333850441889485		[learning rate: 0.00037918]
	Learning Rate: 0.000379181
	LOSS [training: 0.4333850441889485 | validation: 0.44405885002688494]
	TIME [epoch: 27.9 sec]
EPOCH 975/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42578812862040394		[learning rate: 0.00037784]
	Learning Rate: 0.00037784
	LOSS [training: 0.42578812862040394 | validation: 0.4317527003022433]
	TIME [epoch: 27.9 sec]
EPOCH 976/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39990341149415687		[learning rate: 0.0003765]
	Learning Rate: 0.000376504
	LOSS [training: 0.39990341149415687 | validation: 0.4314390923024955]
	TIME [epoch: 27.9 sec]
EPOCH 977/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4056540581457504		[learning rate: 0.00037517]
	Learning Rate: 0.000375172
	LOSS [training: 0.4056540581457504 | validation: 0.4194249005763777]
	TIME [epoch: 27.9 sec]
EPOCH 978/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3881657044963986		[learning rate: 0.00037385]
	Learning Rate: 0.000373846
	LOSS [training: 0.3881657044963986 | validation: 0.4394838804697056]
	TIME [epoch: 27.9 sec]
EPOCH 979/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43106118548821964		[learning rate: 0.00037252]
	Learning Rate: 0.000372524
	LOSS [training: 0.43106118548821964 | validation: 0.4272435743520666]
	TIME [epoch: 27.9 sec]
EPOCH 980/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4213589258922502		[learning rate: 0.00037121]
	Learning Rate: 0.000371206
	LOSS [training: 0.4213589258922502 | validation: 0.4393458457980281]
	TIME [epoch: 27.9 sec]
EPOCH 981/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4060212301916507		[learning rate: 0.00036989]
	Learning Rate: 0.000369894
	LOSS [training: 0.4060212301916507 | validation: 0.48309802804440116]
	TIME [epoch: 27.9 sec]
EPOCH 982/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4141954779685155		[learning rate: 0.00036859]
	Learning Rate: 0.000368586
	LOSS [training: 0.4141954779685155 | validation: 0.4649082743103407]
	TIME [epoch: 27.9 sec]
EPOCH 983/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4704179356471704		[learning rate: 0.00036728]
	Learning Rate: 0.000367282
	LOSS [training: 0.4704179356471704 | validation: 0.4205106046779982]
	TIME [epoch: 27.9 sec]
EPOCH 984/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.410164480200055		[learning rate: 0.00036598]
	Learning Rate: 0.000365984
	LOSS [training: 0.410164480200055 | validation: 0.4232613930241477]
	TIME [epoch: 27.9 sec]
EPOCH 985/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.396796045216535		[learning rate: 0.00036469]
	Learning Rate: 0.000364689
	LOSS [training: 0.396796045216535 | validation: 0.42385077514444264]
	TIME [epoch: 27.9 sec]
EPOCH 986/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43568342666771526		[learning rate: 0.0003634]
	Learning Rate: 0.0003634
	LOSS [training: 0.43568342666771526 | validation: 0.4738579570168894]
	TIME [epoch: 27.9 sec]
EPOCH 987/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44321960056046295		[learning rate: 0.00036211]
	Learning Rate: 0.000362115
	LOSS [training: 0.44321960056046295 | validation: 0.4563523846288282]
	TIME [epoch: 27.9 sec]
EPOCH 988/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3990967219469357		[learning rate: 0.00036083]
	Learning Rate: 0.000360834
	LOSS [training: 0.3990967219469357 | validation: 0.4386164291431044]
	TIME [epoch: 28 sec]
EPOCH 989/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39403317675090344		[learning rate: 0.00035956]
	Learning Rate: 0.000359558
	LOSS [training: 0.39403317675090344 | validation: 0.41439953754517894]
	TIME [epoch: 27.9 sec]
EPOCH 990/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3794767756913451		[learning rate: 0.00035829]
	Learning Rate: 0.000358287
	LOSS [training: 0.3794767756913451 | validation: 0.4378078184797211]
	TIME [epoch: 27.8 sec]
EPOCH 991/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.404292718406777		[learning rate: 0.00035702]
	Learning Rate: 0.00035702
	LOSS [training: 0.404292718406777 | validation: 0.41227560829507715]
	TIME [epoch: 27.9 sec]
EPOCH 992/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38939749395418205		[learning rate: 0.00035576]
	Learning Rate: 0.000355757
	LOSS [training: 0.38939749395418205 | validation: 0.4165283667990059]
	TIME [epoch: 27.9 sec]
EPOCH 993/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.391735767770818		[learning rate: 0.0003545]
	Learning Rate: 0.000354499
	LOSS [training: 0.391735767770818 | validation: 0.42182264780587575]
	TIME [epoch: 27.9 sec]
EPOCH 994/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3894154424992095		[learning rate: 0.00035325]
	Learning Rate: 0.000353246
	LOSS [training: 0.3894154424992095 | validation: 0.42235062854799393]
	TIME [epoch: 27.9 sec]
EPOCH 995/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4367387073205073		[learning rate: 0.000352]
	Learning Rate: 0.000351997
	LOSS [training: 0.4367387073205073 | validation: 0.4586500877142467]
	TIME [epoch: 27.9 sec]
EPOCH 996/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4426292879838216		[learning rate: 0.00035075]
	Learning Rate: 0.000350752
	LOSS [training: 0.4426292879838216 | validation: 0.4094549168327811]
	TIME [epoch: 27.9 sec]
EPOCH 997/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40319135523676414		[learning rate: 0.00034951]
	Learning Rate: 0.000349512
	LOSS [training: 0.40319135523676414 | validation: 0.5209663391570112]
	TIME [epoch: 27.8 sec]
EPOCH 998/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4155721038524288		[learning rate: 0.00034828]
	Learning Rate: 0.000348276
	LOSS [training: 0.4155721038524288 | validation: 0.4118178616108203]
	TIME [epoch: 27.9 sec]
EPOCH 999/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39807748295260104		[learning rate: 0.00034704]
	Learning Rate: 0.000347044
	LOSS [training: 0.39807748295260104 | validation: 0.41879069946638886]
	TIME [epoch: 27.9 sec]
EPOCH 1000/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3988507175058521		[learning rate: 0.00034582]
	Learning Rate: 0.000345817
	LOSS [training: 0.3988507175058521 | validation: 0.4090799102017132]
	TIME [epoch: 27.9 sec]
EPOCH 1001/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49772976517506234		[learning rate: 0.00034459]
	Learning Rate: 0.000344594
	LOSS [training: 0.49772976517506234 | validation: 0.6276255749968997]
	TIME [epoch: 27.9 sec]
EPOCH 1002/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5227512337628616		[learning rate: 0.00034338]
	Learning Rate: 0.000343375
	LOSS [training: 0.5227512337628616 | validation: 0.4602541987525353]
	TIME [epoch: 27.9 sec]
EPOCH 1003/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3929713876681111		[learning rate: 0.00034216]
	Learning Rate: 0.000342161
	LOSS [training: 0.3929713876681111 | validation: 0.4229735029073312]
	TIME [epoch: 27.9 sec]
EPOCH 1004/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4114035781529699		[learning rate: 0.00034095]
	Learning Rate: 0.000340951
	LOSS [training: 0.4114035781529699 | validation: 0.41961153733160494]
	TIME [epoch: 27.9 sec]
EPOCH 1005/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3984748466057584		[learning rate: 0.00033975]
	Learning Rate: 0.000339746
	LOSS [training: 0.3984748466057584 | validation: 0.422398702578463]
	TIME [epoch: 27.8 sec]
EPOCH 1006/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3971686954443642		[learning rate: 0.00033854]
	Learning Rate: 0.000338544
	LOSS [training: 0.3971686954443642 | validation: 0.4042656415795025]
	TIME [epoch: 27.9 sec]
EPOCH 1007/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4095282386532764		[learning rate: 0.00033735]
	Learning Rate: 0.000337347
	LOSS [training: 0.4095282386532764 | validation: 0.5375151613081048]
	TIME [epoch: 27.9 sec]
EPOCH 1008/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.43980437809506173		[learning rate: 0.00033615]
	Learning Rate: 0.000336154
	LOSS [training: 0.43980437809506173 | validation: 0.4237606197361558]
	TIME [epoch: 27.9 sec]
EPOCH 1009/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38104616390663804		[learning rate: 0.00033497]
	Learning Rate: 0.000334965
	LOSS [training: 0.38104616390663804 | validation: 0.4308012514489873]
	TIME [epoch: 28 sec]
EPOCH 1010/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4423583036126595		[learning rate: 0.00033378]
	Learning Rate: 0.000333781
	LOSS [training: 0.4423583036126595 | validation: 0.40633184320812804]
	TIME [epoch: 27.9 sec]
EPOCH 1011/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39577676105812487		[learning rate: 0.0003326]
	Learning Rate: 0.000332601
	LOSS [training: 0.39577676105812487 | validation: 0.4022621728104481]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_1011.pth
	Model improved!!!
EPOCH 1012/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3992300946293946		[learning rate: 0.00033142]
	Learning Rate: 0.000331425
	LOSS [training: 0.3992300946293946 | validation: 0.590111596769519]
	TIME [epoch: 27.9 sec]
EPOCH 1013/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5101420059262166		[learning rate: 0.00033025]
	Learning Rate: 0.000330253
	LOSS [training: 0.5101420059262166 | validation: 0.4626007336527825]
	TIME [epoch: 27.9 sec]
EPOCH 1014/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4124249967704096		[learning rate: 0.00032908]
	Learning Rate: 0.000329085
	LOSS [training: 0.4124249967704096 | validation: 0.40664514411458624]
	TIME [epoch: 27.9 sec]
EPOCH 1015/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3930493975195316		[learning rate: 0.00032792]
	Learning Rate: 0.000327921
	LOSS [training: 0.3930493975195316 | validation: 0.4441220831009073]
	TIME [epoch: 27.9 sec]
EPOCH 1016/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41500378358421003		[learning rate: 0.00032676]
	Learning Rate: 0.000326761
	LOSS [training: 0.41500378358421003 | validation: 0.46056353376049025]
	TIME [epoch: 27.8 sec]
EPOCH 1017/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4737473721681345		[learning rate: 0.00032561]
	Learning Rate: 0.000325606
	LOSS [training: 0.4737473721681345 | validation: 0.4767700114109833]
	TIME [epoch: 27.8 sec]
EPOCH 1018/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4125195250917638		[learning rate: 0.00032445]
	Learning Rate: 0.000324455
	LOSS [training: 0.4125195250917638 | validation: 0.42701446103976765]
	TIME [epoch: 27.8 sec]
EPOCH 1019/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3947509351844121		[learning rate: 0.00032331]
	Learning Rate: 0.000323307
	LOSS [training: 0.3947509351844121 | validation: 0.43464490635625697]
	TIME [epoch: 27.8 sec]
EPOCH 1020/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39608783037127054		[learning rate: 0.00032216]
	Learning Rate: 0.000322164
	LOSS [training: 0.39608783037127054 | validation: 0.4808635805684792]
	TIME [epoch: 27.8 sec]
EPOCH 1021/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41880664967698505		[learning rate: 0.00032102]
	Learning Rate: 0.000321025
	LOSS [training: 0.41880664967698505 | validation: 0.447470784410844]
	TIME [epoch: 27.9 sec]
EPOCH 1022/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41420535252399676		[learning rate: 0.00031989]
	Learning Rate: 0.00031989
	LOSS [training: 0.41420535252399676 | validation: 0.4493068646674774]
	TIME [epoch: 27.9 sec]
EPOCH 1023/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.46901895164001184		[learning rate: 0.00031876]
	Learning Rate: 0.000318758
	LOSS [training: 0.46901895164001184 | validation: 0.4784506690997247]
	TIME [epoch: 27.9 sec]
EPOCH 1024/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4840061497572187		[learning rate: 0.00031763]
	Learning Rate: 0.000317631
	LOSS [training: 0.4840061497572187 | validation: 0.45700896202746394]
	TIME [epoch: 27.9 sec]
EPOCH 1025/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4080085907804436		[learning rate: 0.00031651]
	Learning Rate: 0.000316508
	LOSS [training: 0.4080085907804436 | validation: 0.4514478551505684]
	TIME [epoch: 27.9 sec]
EPOCH 1026/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4557242907580479		[learning rate: 0.00031539]
	Learning Rate: 0.000315389
	LOSS [training: 0.4557242907580479 | validation: 0.46095807051365967]
	TIME [epoch: 27.9 sec]
EPOCH 1027/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39099411172968623		[learning rate: 0.00031427]
	Learning Rate: 0.000314274
	LOSS [training: 0.39099411172968623 | validation: 0.4149884336286139]
	TIME [epoch: 27.9 sec]
EPOCH 1028/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3795541178082918		[learning rate: 0.00031316]
	Learning Rate: 0.000313162
	LOSS [training: 0.3795541178082918 | validation: 0.4183022644065278]
	TIME [epoch: 27.9 sec]
EPOCH 1029/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3824633966360144		[learning rate: 0.00031205]
	Learning Rate: 0.000312055
	LOSS [training: 0.3824633966360144 | validation: 0.4249409726424287]
	TIME [epoch: 27.9 sec]
EPOCH 1030/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44338273872408607		[learning rate: 0.00031095]
	Learning Rate: 0.000310951
	LOSS [training: 0.44338273872408607 | validation: 0.5225536038828458]
	TIME [epoch: 27.9 sec]
EPOCH 1031/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40293535422877935		[learning rate: 0.00030985]
	Learning Rate: 0.000309852
	LOSS [training: 0.40293535422877935 | validation: 0.40187499402164023]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_1031.pth
	Model improved!!!
EPOCH 1032/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39065944271342434		[learning rate: 0.00030876]
	Learning Rate: 0.000308756
	LOSS [training: 0.39065944271342434 | validation: 0.4114613274530441]
	TIME [epoch: 27.9 sec]
EPOCH 1033/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3837970055718004		[learning rate: 0.00030766]
	Learning Rate: 0.000307664
	LOSS [training: 0.3837970055718004 | validation: 0.40697405268563275]
	TIME [epoch: 27.9 sec]
EPOCH 1034/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3946499585696188		[learning rate: 0.00030658]
	Learning Rate: 0.000306576
	LOSS [training: 0.3946499585696188 | validation: 0.42037163526686644]
	TIME [epoch: 27.9 sec]
EPOCH 1035/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3924168033808014		[learning rate: 0.00030549]
	Learning Rate: 0.000305492
	LOSS [training: 0.3924168033808014 | validation: 0.4066018805145617]
	TIME [epoch: 27.9 sec]
EPOCH 1036/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3957950002328823		[learning rate: 0.00030441]
	Learning Rate: 0.000304412
	LOSS [training: 0.3957950002328823 | validation: 0.41179277228334416]
	TIME [epoch: 27.9 sec]
EPOCH 1037/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3925591981999621		[learning rate: 0.00030334]
	Learning Rate: 0.000303335
	LOSS [training: 0.3925591981999621 | validation: 0.4662075265528493]
	TIME [epoch: 27.9 sec]
EPOCH 1038/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.44980289850555094		[learning rate: 0.00030226]
	Learning Rate: 0.000302263
	LOSS [training: 0.44980289850555094 | validation: 0.4257233501246118]
	TIME [epoch: 27.9 sec]
EPOCH 1039/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3843356970852741		[learning rate: 0.00030119]
	Learning Rate: 0.000301194
	LOSS [training: 0.3843356970852741 | validation: 0.4188184108985115]
	TIME [epoch: 27.9 sec]
EPOCH 1040/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41289223201456965		[learning rate: 0.00030013]
	Learning Rate: 0.000300129
	LOSS [training: 0.41289223201456965 | validation: 0.48681034834453557]
	TIME [epoch: 27.9 sec]
EPOCH 1041/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.49075340254406064		[learning rate: 0.00029907]
	Learning Rate: 0.000299068
	LOSS [training: 0.49075340254406064 | validation: 0.4771056408953237]
	TIME [epoch: 27.9 sec]
EPOCH 1042/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3980154164036667		[learning rate: 0.00029801]
	Learning Rate: 0.00029801
	LOSS [training: 0.3980154164036667 | validation: 0.4217954702137994]
	TIME [epoch: 27.9 sec]
EPOCH 1043/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39585322848510385		[learning rate: 0.00029696]
	Learning Rate: 0.000296956
	LOSS [training: 0.39585322848510385 | validation: 0.49828394909438706]
	TIME [epoch: 27.9 sec]
EPOCH 1044/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.411412124499237		[learning rate: 0.00029591]
	Learning Rate: 0.000295906
	LOSS [training: 0.411412124499237 | validation: 0.40175890653890134]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_1044.pth
	Model improved!!!
EPOCH 1045/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4053334984836885		[learning rate: 0.00029486]
	Learning Rate: 0.00029486
	LOSS [training: 0.4053334984836885 | validation: 0.42588999384423604]
	TIME [epoch: 27.9 sec]
EPOCH 1046/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4321304541258921		[learning rate: 0.00029382]
	Learning Rate: 0.000293817
	LOSS [training: 0.4321304541258921 | validation: 0.431591186133999]
	TIME [epoch: 27.9 sec]
EPOCH 1047/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41142443508501647		[learning rate: 0.00029278]
	Learning Rate: 0.000292778
	LOSS [training: 0.41142443508501647 | validation: 0.6330724796896307]
	TIME [epoch: 27.9 sec]
EPOCH 1048/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.526070492702986		[learning rate: 0.00029174]
	Learning Rate: 0.000291743
	LOSS [training: 0.526070492702986 | validation: 0.43080431249420953]
	TIME [epoch: 27.9 sec]
EPOCH 1049/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38023370910940374		[learning rate: 0.00029071]
	Learning Rate: 0.000290711
	LOSS [training: 0.38023370910940374 | validation: 0.397350051646127]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_1049.pth
	Model improved!!!
EPOCH 1050/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37018397440047457		[learning rate: 0.00028968]
	Learning Rate: 0.000289683
	LOSS [training: 0.37018397440047457 | validation: 0.41534250756837476]
	TIME [epoch: 27.9 sec]
EPOCH 1051/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3743983710954208		[learning rate: 0.00028866]
	Learning Rate: 0.000288659
	LOSS [training: 0.3743983710954208 | validation: 0.3965275088816378]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_1051.pth
	Model improved!!!
EPOCH 1052/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3733302047437275		[learning rate: 0.00028764]
	Learning Rate: 0.000287638
	LOSS [training: 0.3733302047437275 | validation: 0.3936444413961989]
	TIME [epoch: 28 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_1052.pth
	Model improved!!!
EPOCH 1053/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41023046820787423		[learning rate: 0.00028662]
	Learning Rate: 0.000286621
	LOSS [training: 0.41023046820787423 | validation: 0.4491491368384456]
	TIME [epoch: 27.9 sec]
EPOCH 1054/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4049038531028736		[learning rate: 0.00028561]
	Learning Rate: 0.000285607
	LOSS [training: 0.4049038531028736 | validation: 0.4092838876457104]
	TIME [epoch: 27.9 sec]
EPOCH 1055/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3900722911801795		[learning rate: 0.0002846]
	Learning Rate: 0.000284597
	LOSS [training: 0.3900722911801795 | validation: 0.40010218456144886]
	TIME [epoch: 27.9 sec]
EPOCH 1056/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3725910940431494		[learning rate: 0.00028359]
	Learning Rate: 0.000283591
	LOSS [training: 0.3725910940431494 | validation: 0.4159165492994153]
	TIME [epoch: 27.9 sec]
EPOCH 1057/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3839270571958044		[learning rate: 0.00028259]
	Learning Rate: 0.000282588
	LOSS [training: 0.3839270571958044 | validation: 0.41482085292798515]
	TIME [epoch: 27.9 sec]
EPOCH 1058/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37242614081194675		[learning rate: 0.00028159]
	Learning Rate: 0.000281589
	LOSS [training: 0.37242614081194675 | validation: 0.4123052206045395]
	TIME [epoch: 27.9 sec]
EPOCH 1059/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38003277235080923		[learning rate: 0.00028059]
	Learning Rate: 0.000280593
	LOSS [training: 0.38003277235080923 | validation: 0.478366411591698]
	TIME [epoch: 27.9 sec]
EPOCH 1060/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4149220987287163		[learning rate: 0.0002796]
	Learning Rate: 0.000279601
	LOSS [training: 0.4149220987287163 | validation: 0.4039162999758149]
	TIME [epoch: 27.9 sec]
EPOCH 1061/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38264315298986074		[learning rate: 0.00027861]
	Learning Rate: 0.000278612
	LOSS [training: 0.38264315298986074 | validation: 0.40919116009869816]
	TIME [epoch: 27.9 sec]
EPOCH 1062/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.388460597672469		[learning rate: 0.00027763]
	Learning Rate: 0.000277627
	LOSS [training: 0.388460597672469 | validation: 0.45249391068398354]
	TIME [epoch: 27.9 sec]
EPOCH 1063/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4273562665703041		[learning rate: 0.00027665]
	Learning Rate: 0.000276645
	LOSS [training: 0.4273562665703041 | validation: 0.4121057654529794]
	TIME [epoch: 27.9 sec]
EPOCH 1064/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3765639991365154		[learning rate: 0.00027567]
	Learning Rate: 0.000275667
	LOSS [training: 0.3765639991365154 | validation: 0.39846651180696363]
	TIME [epoch: 27.9 sec]
EPOCH 1065/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37969024423755715		[learning rate: 0.00027469]
	Learning Rate: 0.000274692
	LOSS [training: 0.37969024423755715 | validation: 0.4083265618900424]
	TIME [epoch: 27.9 sec]
EPOCH 1066/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39148423670678445		[learning rate: 0.00027372]
	Learning Rate: 0.000273721
	LOSS [training: 0.39148423670678445 | validation: 0.40673683791241727]
	TIME [epoch: 27.9 sec]
EPOCH 1067/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3771354388534905		[learning rate: 0.00027275]
	Learning Rate: 0.000272753
	LOSS [training: 0.3771354388534905 | validation: 0.41957592331609517]
	TIME [epoch: 27.9 sec]
EPOCH 1068/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3844978047097218		[learning rate: 0.00027179]
	Learning Rate: 0.000271788
	LOSS [training: 0.3844978047097218 | validation: 0.4103128224781477]
	TIME [epoch: 27.8 sec]
EPOCH 1069/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4005453601414949		[learning rate: 0.00027083]
	Learning Rate: 0.000270827
	LOSS [training: 0.4005453601414949 | validation: 0.4248872085363732]
	TIME [epoch: 27.9 sec]
EPOCH 1070/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4053326244653511		[learning rate: 0.00026987]
	Learning Rate: 0.00026987
	LOSS [training: 0.4053326244653511 | validation: 0.4169283666739223]
	TIME [epoch: 27.9 sec]
EPOCH 1071/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38460403530945153		[learning rate: 0.00026892]
	Learning Rate: 0.000268915
	LOSS [training: 0.38460403530945153 | validation: 0.4160664304460639]
	TIME [epoch: 27.9 sec]
EPOCH 1072/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38814409259220806		[learning rate: 0.00026796]
	Learning Rate: 0.000267964
	LOSS [training: 0.38814409259220806 | validation: 0.41259474199228846]
	TIME [epoch: 27.9 sec]
EPOCH 1073/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40398855567096903		[learning rate: 0.00026702]
	Learning Rate: 0.000267017
	LOSS [training: 0.40398855567096903 | validation: 0.43307145576218403]
	TIME [epoch: 27.9 sec]
EPOCH 1074/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3740152739581596		[learning rate: 0.00026607]
	Learning Rate: 0.000266073
	LOSS [training: 0.3740152739581596 | validation: 0.4392609435006313]
	TIME [epoch: 27.9 sec]
EPOCH 1075/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40206683625940653		[learning rate: 0.00026513]
	Learning Rate: 0.000265132
	LOSS [training: 0.40206683625940653 | validation: 0.40972256108122634]
	TIME [epoch: 27.9 sec]
EPOCH 1076/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3743964089167544		[learning rate: 0.00026419]
	Learning Rate: 0.000264194
	LOSS [training: 0.3743964089167544 | validation: 0.40148655608987227]
	TIME [epoch: 27.9 sec]
EPOCH 1077/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3852771864019583		[learning rate: 0.00026326]
	Learning Rate: 0.00026326
	LOSS [training: 0.3852771864019583 | validation: 0.4017158614437919]
	TIME [epoch: 27.9 sec]
EPOCH 1078/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38505601824130153		[learning rate: 0.00026233]
	Learning Rate: 0.000262329
	LOSS [training: 0.38505601824130153 | validation: 0.40716429801396686]
	TIME [epoch: 27.9 sec]
EPOCH 1079/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38773668036646564		[learning rate: 0.0002614]
	Learning Rate: 0.000261401
	LOSS [training: 0.38773668036646564 | validation: 0.4037814367165737]
	TIME [epoch: 27.9 sec]
EPOCH 1080/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3696128691839906		[learning rate: 0.00026048]
	Learning Rate: 0.000260477
	LOSS [training: 0.3696128691839906 | validation: 0.41165261308473516]
	TIME [epoch: 27.9 sec]
EPOCH 1081/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40040911374271854		[learning rate: 0.00025956]
	Learning Rate: 0.000259556
	LOSS [training: 0.40040911374271854 | validation: 0.5104793913236422]
	TIME [epoch: 27.8 sec]
EPOCH 1082/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4195048539745353		[learning rate: 0.00025864]
	Learning Rate: 0.000258638
	LOSS [training: 0.4195048539745353 | validation: 0.39676652031412696]
	TIME [epoch: 27.8 sec]
EPOCH 1083/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38933410692608084		[learning rate: 0.00025772]
	Learning Rate: 0.000257723
	LOSS [training: 0.38933410692608084 | validation: 0.4635484605565421]
	TIME [epoch: 27.8 sec]
EPOCH 1084/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4549662155139159		[learning rate: 0.00025681]
	Learning Rate: 0.000256812
	LOSS [training: 0.4549662155139159 | validation: 0.4014038815096555]
	TIME [epoch: 27.8 sec]
EPOCH 1085/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4046007757419986		[learning rate: 0.0002559]
	Learning Rate: 0.000255904
	LOSS [training: 0.4046007757419986 | validation: 0.4378326900035786]
	TIME [epoch: 27.8 sec]
EPOCH 1086/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3853693321193636		[learning rate: 0.000255]
	Learning Rate: 0.000254999
	LOSS [training: 0.3853693321193636 | validation: 0.4233907853547777]
	TIME [epoch: 27.8 sec]
EPOCH 1087/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41783181166859745		[learning rate: 0.0002541]
	Learning Rate: 0.000254097
	LOSS [training: 0.41783181166859745 | validation: 0.41506166736524114]
	TIME [epoch: 27.9 sec]
EPOCH 1088/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3793350537256546		[learning rate: 0.0002532]
	Learning Rate: 0.000253199
	LOSS [training: 0.3793350537256546 | validation: 0.39717625870483275]
	TIME [epoch: 27.9 sec]
EPOCH 1089/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3740449192127989		[learning rate: 0.0002523]
	Learning Rate: 0.000252303
	LOSS [training: 0.3740449192127989 | validation: 0.41606319182471185]
	TIME [epoch: 28 sec]
EPOCH 1090/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3704961842294937		[learning rate: 0.00025141]
	Learning Rate: 0.000251411
	LOSS [training: 0.3704961842294937 | validation: 0.39809143672059244]
	TIME [epoch: 28 sec]
EPOCH 1091/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3804133337564912		[learning rate: 0.00025052]
	Learning Rate: 0.000250522
	LOSS [training: 0.3804133337564912 | validation: 0.4096845248590927]
	TIME [epoch: 27.9 sec]
EPOCH 1092/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38649123290188814		[learning rate: 0.00024964]
	Learning Rate: 0.000249636
	LOSS [training: 0.38649123290188814 | validation: 0.4733476615872992]
	TIME [epoch: 28 sec]
EPOCH 1093/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3892192681780817		[learning rate: 0.00024875]
	Learning Rate: 0.000248754
	LOSS [training: 0.3892192681780817 | validation: 0.4198746832801218]
	TIME [epoch: 27.9 sec]
EPOCH 1094/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3997000595692053		[learning rate: 0.00024787]
	Learning Rate: 0.000247874
	LOSS [training: 0.3997000595692053 | validation: 0.41775904605402203]
	TIME [epoch: 27.9 sec]
EPOCH 1095/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3875151725283282		[learning rate: 0.000247]
	Learning Rate: 0.000246997
	LOSS [training: 0.3875151725283282 | validation: 0.4557329317656161]
	TIME [epoch: 27.9 sec]
EPOCH 1096/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3789217515927821		[learning rate: 0.00024612]
	Learning Rate: 0.000246124
	LOSS [training: 0.3789217515927821 | validation: 0.40453861668595337]
	TIME [epoch: 27.9 sec]
EPOCH 1097/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3746348582214988		[learning rate: 0.00024525]
	Learning Rate: 0.000245254
	LOSS [training: 0.3746348582214988 | validation: 0.4121774994010245]
	TIME [epoch: 27.9 sec]
EPOCH 1098/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3811476397321238		[learning rate: 0.00024439]
	Learning Rate: 0.000244386
	LOSS [training: 0.3811476397321238 | validation: 0.4160269136468908]
	TIME [epoch: 27.9 sec]
EPOCH 1099/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3773013647332872		[learning rate: 0.00024352]
	Learning Rate: 0.000243522
	LOSS [training: 0.3773013647332872 | validation: 0.4075189745659381]
	TIME [epoch: 27.9 sec]
EPOCH 1100/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3845760973564697		[learning rate: 0.00024266]
	Learning Rate: 0.000242661
	LOSS [training: 0.3845760973564697 | validation: 0.3921315183656959]
	TIME [epoch: 27.9 sec]
	Saving model to: out/transition_rate_study_model_training_kl1/tr_study6/model_tr_study6_r3_20240310_003042/states/model_tr_study6_1100.pth
	Model improved!!!
EPOCH 1101/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3672951006734698		[learning rate: 0.0002418]
	Learning Rate: 0.000241803
	LOSS [training: 0.3672951006734698 | validation: 0.39553204616197707]
	TIME [epoch: 27.9 sec]
EPOCH 1102/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37685893403284276		[learning rate: 0.00024095]
	Learning Rate: 0.000240948
	LOSS [training: 0.37685893403284276 | validation: 0.40530739128075854]
	TIME [epoch: 27.9 sec]
EPOCH 1103/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3737305011631117		[learning rate: 0.0002401]
	Learning Rate: 0.000240096
	LOSS [training: 0.3737305011631117 | validation: 0.4161101401259468]
	TIME [epoch: 27.9 sec]
EPOCH 1104/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3710230891907681		[learning rate: 0.00023925]
	Learning Rate: 0.000239247
	LOSS [training: 0.3710230891907681 | validation: 0.41744702812427803]
	TIME [epoch: 27.9 sec]
EPOCH 1105/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39735444029202327		[learning rate: 0.0002384]
	Learning Rate: 0.000238401
	LOSS [training: 0.39735444029202327 | validation: 0.4082920662491816]
	TIME [epoch: 27.9 sec]
EPOCH 1106/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37291548298646354		[learning rate: 0.00023756]
	Learning Rate: 0.000237558
	LOSS [training: 0.37291548298646354 | validation: 0.4098663585712554]
	TIME [epoch: 27.9 sec]
EPOCH 1107/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4267858625974854		[learning rate: 0.00023672]
	Learning Rate: 0.000236718
	LOSS [training: 0.4267858625974854 | validation: 0.4678230451280001]
	TIME [epoch: 27.9 sec]
EPOCH 1108/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4000525010994501		[learning rate: 0.00023588]
	Learning Rate: 0.000235881
	LOSS [training: 0.4000525010994501 | validation: 0.3978809110423205]
	TIME [epoch: 27.9 sec]
EPOCH 1109/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3774721310006006		[learning rate: 0.00023505]
	Learning Rate: 0.000235047
	LOSS [training: 0.3774721310006006 | validation: 0.4065554827957753]
	TIME [epoch: 27.9 sec]
EPOCH 1110/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3749518467772233		[learning rate: 0.00023422]
	Learning Rate: 0.000234215
	LOSS [training: 0.3749518467772233 | validation: 0.40512170686108323]
	TIME [epoch: 27.9 sec]
EPOCH 1111/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3698313793802823		[learning rate: 0.00023339]
	Learning Rate: 0.000233387
	LOSS [training: 0.3698313793802823 | validation: 0.40708097748242467]
	TIME [epoch: 27.9 sec]
EPOCH 1112/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3916474065444101		[learning rate: 0.00023256]
	Learning Rate: 0.000232562
	LOSS [training: 0.3916474065444101 | validation: 0.40725248913423023]
	TIME [epoch: 27.9 sec]
EPOCH 1113/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37693519582519486		[learning rate: 0.00023174]
	Learning Rate: 0.00023174
	LOSS [training: 0.37693519582519486 | validation: 0.4214650296971309]
	TIME [epoch: 27.9 sec]
EPOCH 1114/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3820102257016881		[learning rate: 0.00023092]
	Learning Rate: 0.00023092
	LOSS [training: 0.3820102257016881 | validation: 0.45468628675137235]
	TIME [epoch: 27.9 sec]
EPOCH 1115/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.416469467282706		[learning rate: 0.0002301]
	Learning Rate: 0.000230103
	LOSS [training: 0.416469467282706 | validation: 0.43988729168092533]
	TIME [epoch: 27.9 sec]
EPOCH 1116/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38875607240722054		[learning rate: 0.00022929]
	Learning Rate: 0.00022929
	LOSS [training: 0.38875607240722054 | validation: 0.46926328936880235]
	TIME [epoch: 27.8 sec]
EPOCH 1117/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38448657625069804		[learning rate: 0.00022848]
	Learning Rate: 0.000228479
	LOSS [training: 0.38448657625069804 | validation: 0.405054050388229]
	TIME [epoch: 27.8 sec]
EPOCH 1118/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3657720260002873		[learning rate: 0.00022767]
	Learning Rate: 0.000227671
	LOSS [training: 0.3657720260002873 | validation: 0.41083130474527435]
	TIME [epoch: 27.8 sec]
EPOCH 1119/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38408876926046376		[learning rate: 0.00022687]
	Learning Rate: 0.000226866
	LOSS [training: 0.38408876926046376 | validation: 0.4314757333144007]
	TIME [epoch: 27.8 sec]
EPOCH 1120/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4243468400748276		[learning rate: 0.00022606]
	Learning Rate: 0.000226064
	LOSS [training: 0.4243468400748276 | validation: 0.5570590248153232]
	TIME [epoch: 27.9 sec]
EPOCH 1121/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.47802487151798917		[learning rate: 0.00022526]
	Learning Rate: 0.000225264
	LOSS [training: 0.47802487151798917 | validation: 0.4419747641558607]
	TIME [epoch: 27.9 sec]
EPOCH 1122/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3859832539965379		[learning rate: 0.00022447]
	Learning Rate: 0.000224468
	LOSS [training: 0.3859832539965379 | validation: 0.4490296631302357]
	TIME [epoch: 28 sec]
EPOCH 1123/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.5333034758476758		[learning rate: 0.00022367]
	Learning Rate: 0.000223674
	LOSS [training: 0.5333034758476758 | validation: 0.42601255908329194]
	TIME [epoch: 27.9 sec]
EPOCH 1124/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38824349306561556		[learning rate: 0.00022288]
	Learning Rate: 0.000222883
	LOSS [training: 0.38824349306561556 | validation: 0.4083665868138353]
	TIME [epoch: 27.9 sec]
EPOCH 1125/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38153613342069825		[learning rate: 0.00022209]
	Learning Rate: 0.000222095
	LOSS [training: 0.38153613342069825 | validation: 0.41975438138433246]
	TIME [epoch: 28 sec]
EPOCH 1126/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4054586371777428		[learning rate: 0.00022131]
	Learning Rate: 0.00022131
	LOSS [training: 0.4054586371777428 | validation: 0.4368038875318478]
	TIME [epoch: 27.9 sec]
EPOCH 1127/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4069635033119999		[learning rate: 0.00022053]
	Learning Rate: 0.000220527
	LOSS [training: 0.4069635033119999 | validation: 0.4124171016542087]
	TIME [epoch: 27.9 sec]
EPOCH 1128/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3740987327429466		[learning rate: 0.00021975]
	Learning Rate: 0.000219747
	LOSS [training: 0.3740987327429466 | validation: 0.4058211940822767]
	TIME [epoch: 27.9 sec]
EPOCH 1129/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3824453938583544		[learning rate: 0.00021897]
	Learning Rate: 0.00021897
	LOSS [training: 0.3824453938583544 | validation: 0.4001256872593285]
	TIME [epoch: 27.9 sec]
EPOCH 1130/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38367688541387657		[learning rate: 0.0002182]
	Learning Rate: 0.000218196
	LOSS [training: 0.38367688541387657 | validation: 0.42061576004302836]
	TIME [epoch: 27.9 sec]
EPOCH 1131/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3780370252457943		[learning rate: 0.00021742]
	Learning Rate: 0.000217424
	LOSS [training: 0.3780370252457943 | validation: 0.3947225802895737]
	TIME [epoch: 27.9 sec]
EPOCH 1132/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38545866921352134		[learning rate: 0.00021666]
	Learning Rate: 0.000216655
	LOSS [training: 0.38545866921352134 | validation: 0.40867993644561085]
	TIME [epoch: 27.9 sec]
EPOCH 1133/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38009905394992227		[learning rate: 0.00021589]
	Learning Rate: 0.000215889
	LOSS [training: 0.38009905394992227 | validation: 0.40160358004399227]
	TIME [epoch: 28 sec]
EPOCH 1134/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3786378599543646		[learning rate: 0.00021513]
	Learning Rate: 0.000215126
	LOSS [training: 0.3786378599543646 | validation: 0.4015720049611906]
	TIME [epoch: 27.9 sec]
EPOCH 1135/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37213054997389683		[learning rate: 0.00021436]
	Learning Rate: 0.000214365
	LOSS [training: 0.37213054997389683 | validation: 0.42827943875131963]
	TIME [epoch: 27.9 sec]
EPOCH 1136/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38327421190403055		[learning rate: 0.00021361]
	Learning Rate: 0.000213607
	LOSS [training: 0.38327421190403055 | validation: 0.44809483141606665]
	TIME [epoch: 27.8 sec]
EPOCH 1137/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37540468054336185		[learning rate: 0.00021285]
	Learning Rate: 0.000212852
	LOSS [training: 0.37540468054336185 | validation: 0.4077331297089043]
	TIME [epoch: 27.8 sec]
EPOCH 1138/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38248620724590465		[learning rate: 0.0002121]
	Learning Rate: 0.000212099
	LOSS [training: 0.38248620724590465 | validation: 0.5249480804366033]
	TIME [epoch: 27.8 sec]
EPOCH 1139/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4603927029342035		[learning rate: 0.00021135]
	Learning Rate: 0.000211349
	LOSS [training: 0.4603927029342035 | validation: 0.5104296168675719]
	TIME [epoch: 27.8 sec]
EPOCH 1140/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.41053878648461634		[learning rate: 0.0002106]
	Learning Rate: 0.000210602
	LOSS [training: 0.41053878648461634 | validation: 0.4042488757123111]
	TIME [epoch: 27.9 sec]
EPOCH 1141/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3748380838171415		[learning rate: 0.00020986]
	Learning Rate: 0.000209857
	LOSS [training: 0.3748380838171415 | validation: 0.41681574826378837]
	TIME [epoch: 27.9 sec]
EPOCH 1142/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39253123226282677		[learning rate: 0.00020911]
	Learning Rate: 0.000209115
	LOSS [training: 0.39253123226282677 | validation: 0.42276441156341193]
	TIME [epoch: 27.9 sec]
EPOCH 1143/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3877961157651641		[learning rate: 0.00020838]
	Learning Rate: 0.000208375
	LOSS [training: 0.3877961157651641 | validation: 0.41233387564175955]
	TIME [epoch: 27.9 sec]
EPOCH 1144/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3870698907778126		[learning rate: 0.00020764]
	Learning Rate: 0.000207638
	LOSS [training: 0.3870698907778126 | validation: 0.44139331102085594]
	TIME [epoch: 27.9 sec]
EPOCH 1145/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3897778595172987		[learning rate: 0.0002069]
	Learning Rate: 0.000206904
	LOSS [training: 0.3897778595172987 | validation: 0.4852457585086523]
	TIME [epoch: 27.9 sec]
EPOCH 1146/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.40601769995640935		[learning rate: 0.00020617]
	Learning Rate: 0.000206173
	LOSS [training: 0.40601769995640935 | validation: 0.4418631510263515]
	TIME [epoch: 27.9 sec]
EPOCH 1147/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3773004084765177		[learning rate: 0.00020544]
	Learning Rate: 0.000205444
	LOSS [training: 0.3773004084765177 | validation: 0.40801240899981334]
	TIME [epoch: 27.9 sec]
EPOCH 1148/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3756088486135492		[learning rate: 0.00020472]
	Learning Rate: 0.000204717
	LOSS [training: 0.3756088486135492 | validation: 0.41889562663448765]
	TIME [epoch: 27.9 sec]
EPOCH 1149/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3747677240334643		[learning rate: 0.00020399]
	Learning Rate: 0.000203993
	LOSS [training: 0.3747677240334643 | validation: 0.4104105550747844]
	TIME [epoch: 27.9 sec]
EPOCH 1150/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.39345416741473693		[learning rate: 0.00020327]
	Learning Rate: 0.000203272
	LOSS [training: 0.39345416741473693 | validation: 0.412474469501156]
	TIME [epoch: 27.9 sec]
EPOCH 1151/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.37763953001065953		[learning rate: 0.00020255]
	Learning Rate: 0.000202553
	LOSS [training: 0.37763953001065953 | validation: 0.445694941788128]
	TIME [epoch: 28 sec]
EPOCH 1152/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.4265244394783634		[learning rate: 0.00020184]
	Learning Rate: 0.000201837
	LOSS [training: 0.4265244394783634 | validation: 0.4878543158062279]
	TIME [epoch: 27.9 sec]
EPOCH 1153/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38951150389765343		[learning rate: 0.00020112]
	Learning Rate: 0.000201123
	LOSS [training: 0.38951150389765343 | validation: 0.4177639695718277]
	TIME [epoch: 27.8 sec]
EPOCH 1154/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3833154069184983		[learning rate: 0.00020041]
	Learning Rate: 0.000200412
	LOSS [training: 0.3833154069184983 | validation: 0.40690143353673996]
	TIME [epoch: 27.8 sec]
EPOCH 1155/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3748527361448961		[learning rate: 0.0001997]
	Learning Rate: 0.000199703
	LOSS [training: 0.3748527361448961 | validation: 0.4171036993818345]
	TIME [epoch: 27.8 sec]
EPOCH 1156/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42488113069127775		[learning rate: 0.000199]
	Learning Rate: 0.000198997
	LOSS [training: 0.42488113069127775 | validation: 0.4080764100733524]
	TIME [epoch: 27.8 sec]
EPOCH 1157/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3697264465976081		[learning rate: 0.00019829]
	Learning Rate: 0.000198293
	LOSS [training: 0.3697264465976081 | validation: 0.416921484625897]
	TIME [epoch: 27.8 sec]
EPOCH 1158/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.42380207505976997		[learning rate: 0.00019759]
	Learning Rate: 0.000197592
	LOSS [training: 0.42380207505976997 | validation: 0.4327404639469545]
	TIME [epoch: 27.9 sec]
EPOCH 1159/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3878817385788236		[learning rate: 0.00019689]
	Learning Rate: 0.000196893
	LOSS [training: 0.3878817385788236 | validation: 0.4209166792515189]
	TIME [epoch: 27.9 sec]
EPOCH 1160/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38454549345228356		[learning rate: 0.0001962]
	Learning Rate: 0.000196197
	LOSS [training: 0.38454549345228356 | validation: 0.3973045334416287]
	TIME [epoch: 27.9 sec]
EPOCH 1161/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36208083360672805		[learning rate: 0.0001955]
	Learning Rate: 0.000195503
	LOSS [training: 0.36208083360672805 | validation: 0.39987777960885745]
	TIME [epoch: 27.8 sec]
EPOCH 1162/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3655783763790259		[learning rate: 0.00019481]
	Learning Rate: 0.000194812
	LOSS [training: 0.3655783763790259 | validation: 0.4031754270004212]
	TIME [epoch: 27.8 sec]
EPOCH 1163/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3660247912093394		[learning rate: 0.00019412]
	Learning Rate: 0.000194123
	LOSS [training: 0.3660247912093394 | validation: 0.4132179750868386]
	TIME [epoch: 27.8 sec]
EPOCH 1164/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3607105474088641		[learning rate: 0.00019344]
	Learning Rate: 0.000193437
	LOSS [training: 0.3607105474088641 | validation: 0.4500507393194164]
	TIME [epoch: 27.8 sec]
EPOCH 1165/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.3894460593602911		[learning rate: 0.00019275]
	Learning Rate: 0.000192753
	LOSS [training: 0.3894460593602911 | validation: 0.41094629596984905]
	TIME [epoch: 27.8 sec]
EPOCH 1166/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.36459612289347554		[learning rate: 0.00019207]
	Learning Rate: 0.000192071
	LOSS [training: 0.36459612289347554 | validation: 0.4240508727267631]
	TIME [epoch: 27.9 sec]
EPOCH 1167/2000:
	Training over batches...
		[batch 4/4] avg loss: 0.38651790712681877		[learning rate: 0.00019139]
	Learning Rate: 0.000191392
	LOSS [training: 0.38651790712681877 | validation: 0.3951077639539443]
	TIME [epoch: 27.9 sec]
EPOCH 1168/2000:
	Training over batches...
